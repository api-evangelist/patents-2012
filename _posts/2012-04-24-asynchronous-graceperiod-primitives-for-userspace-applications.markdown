---

title: Asynchronous grace-period primitives for user-space applications
abstract: A technique for implementing user-level read-copy update (RCU) with support for asynchronous grace periods. In an example embodiment, a user-level RCU subsystem is established that executes within threads of a user-level multithreaded application. The multithreaded application may comprise one or more reader threads that read RCU-protected data elements in a shared memory. The multithreaded application may further comprise one or more updater threads that perform updates to the RCU-protected data elements in the shared memory and register callbacks to be executed following a grace period in order to free stale data resulting from the updates. The RCU subsystem may implement two or more helper threads (helpers) that are created or selected as needed to track grace periods and execute the callbacks on behalf of the updaters instead of the updaters performing such work themselves.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09250979&OS=09250979&RS=09250979
owner: International Business Machines Corporation
number: 09250979
owner_city: Armonk
owner_country: US
publication_date: 20120424
---
This application is a continuation under 35 U.S.C. 120 of application Ser. No. 13 169 570 filed Jun. 27 2011 entitled Asynchronous Grace Period Primitives For User Space Applications. 

The present disclosure relates to computer systems and methods in which data resources are shared among data consumers while preserving data integrity and consistency relative to each consumer. More particularly the disclosure concerns an implementation of a mutual exclusion mechanism known as read copy update in a user level computing environment.

By way of background read copy update also known as RCU is a mutual exclusion technique that permits shared data to be accessed for reading without the use of locks writes to shared memory memory barriers atomic instructions or other computationally expensive synchronization mechanisms while still permitting the data to be updated modify delete insert etc. concurrently. The technique is well suited to both uniprocessor and multiprocessor computing environments wherein the number of read operations readers accessing a shared data set is large in comparison to the number of update operations updaters and wherein the overhead cost of employing other mutual exclusion techniques such as locks for each read operation would be high. By way of example a network routing table that is updated at most once every few minutes but searched many thousands of times per second is a case where read side lock acquisition would be quite burdensome.

The read copy update technique implements data updates in two phases. In the first initial update phase the actual data update is carried out in a manner that temporarily preserves two views of the data being updated. One view is the old pre update data state that is maintained for the benefit of read operations that may have been referencing the data concurrently with the update. The other view is the new post update data state that is seen by operations that access the data following the update. In the second deferred update phase the old data state is removed following a grace period that is long enough to ensure that the first group of read operations will no longer maintain references to the pre update data. The second phase update operation typically comprises freeing a stale data element to reclaim its memory. In certain RCU implementations the second phase update operation may comprise something else such as changing an operational state according to the first phase update.

It is assumed that the data element list of is traversed without locking by multiple readers and occasionally updated by updaters that delete insert or modify data elements in the list. In the data element B is being referenced by a reader r as shown by the vertical arrow below the data element. In an updater u wishes to update the linked list by modifying data element B. Instead of simply updating this data element without regard to the fact that r is referencing it which might crash r u preserves B while generating an updated version thereof shown in as data element B and inserting it into the linked list. This is done by u acquiring an appropriate lock to exclude other updaters allocating new memory for B copying the contents of B to B modifying B as needed updating the pointer from A to B so that it points to B and releasing the lock. In current versions of the Linux kernel pointer updates performed by updaters can be implemented using the rcu assign pointer primitive. As an alternative to locking during the update operation other techniques such as non blocking synchronization or a designated update thread could be used to serialize data updates. All subsequent post update readers that traverse the linked list such as the reader r will see the effect of the update operation by encountering B as they dereference B s pointer. On the other hand the old reader r will be unaffected because the original version of B and its pointer to C are retained. Although r will now be reading stale data there are many cases where this can be tolerated such as when data elements track the state of components external to the computer system e.g. network connectivity and must tolerate old data because of communication delays. In current versions of the Linux kernel pointer dereferences performed by readers can be implemented using the rcu dereference primitive.

At some subsequent time following the update r will have continued its traversal of the linked list and moved its reference off of B. In addition there will be a time at which no other reader process is entitled to access B. It is at this point representing an expiration of the grace period referred to above that u can free B as shown in .

In the context of the read copy update mechanism a grace period represents the point at which all running tasks e.g. processes threads or other work having access to a data element guarded by read copy update have passed through a quiescent state in which they can no longer maintain references to the data element assert locks thereon or make any assumptions about data element state. By convention for operating system kernel code paths a context switch an idle loop and user mode execution all represent quiescent states for any given CPU running non preemptible code as can other operations that will not be listed here . The reason for this is that a non preemptible kernel will always complete a particular operation e.g. servicing a system call while running in process context prior to a context switch.

In four tasks and running on four separate CPUs are shown to pass periodically through quiescent states represented by the double vertical bars . The grace period shown by the dotted vertical lines encompasses the time frame in which all four tasks that began before the start of the grace period have passed through one quiescent state. If the four tasks and were reader tasks traversing the linked lists of or none of these tasks having reference to the old data element B prior to the grace period could maintain a reference thereto following the grace period. All post grace period searches conducted by these tasks would bypass B by following the updated pointers created by the updater.

Grace periods may be synchronous or asynchronous. According to the synchronous technique an updater performs the first phase update operation blocks waits until a grace period has completed and then implements the second phase update operation such as by removing stale data. According to the asynchronous technique an updater performs the first phase update operation specifies the second phase update operation as a callback then resumes other processing with the knowledge that the callback will eventually be processed at the end of a grace period. Advantageously callbacks requested by one or more updaters can be batched e.g. on callback lists and processed as a group at the end of an asynchronous grace period. This allows asynchronous grace period overhead to be amortized over plural deferred update operations.

In operating system kernel implementations of RCU callback registration and processing is performed by code sections whose execution is well defined and highly deterministic. An example of such code is the call rcu primitive that registers a callback for deferred processing following an asynchronous grace period and then invokes a callback processing primitive such as process callbacks to execute one or more pending callbacks at the end of a grace period. The situation is less favorable when RCU is run in user space. Current user level versions of the call rcu primitive have limitations due to the fact that user level applications generally do not have the degree of control over execution that is typically found in kernels.

For example the user space rcu library for the LTTng Linux Trace Toolkit Project includes a defer rcu primitive that updaters use to queue RCU callbacks see the urcu defer.c and urcu defer.h files at git lttng.org usrspace rcu.git . The urcu defer.c file contains a primitive named rcu defer register thread that calls a primitive named start defer thread to create a thread for executing callbacks. However within the defer rcu primitive itself a call is made to synchronize rcu to force a synchronous grace period if there are too many pending callbacks. The advantage of forcing a synchronous grace period is that it avoids out of memory conditions that could otherwise result in cases where there were never any naturally occurring synchronize rcu invocations. Unfortunately the above described implementation of defer rcu will block updaters in some cases and is therefore not fully deterministic. This may not be desirable for the critical path of a real time application. In FIG. 11 of M. Desnoyers et al. User Level Implementations of Read Copy Update IEEE Transactions On Parallel And Distributed Systems Vol. X No. Y July 2009 pp. 1 14 a user space call rcu primitive is proposed that would invoke a primitive named call rcu cleanup to process callbacks in a separate thread following a grace period so that updaters invoking call rcu will be wait free. However this proposal envisions only a single global callback processing thread which could become overwhelmed in large multiprocessor systems and would suffer gratuitous cache miss overhead when invoking callbacks registered on other processors. Implementing this approach would be problematic if real time response is desired.

A method system and computer program product are provided for implementing user level read copy update RCU with support for asynchronous grace periods. In an example embodiment a user level RCU subsystem is established that executes within threads of a user level multithreaded application. The multithreaded application may comprise one or more reader threads that read RCU protected data elements in a shared memory. The multithreaded application may further comprise one or more updater threads that perform updates to the RCU protected data elements in the shared memory and register callbacks to be executed following a grace period in order to free stale data resulting from the updates. The RCU subsystem implements two or more helper threads helpers that can be created or selected as needed to track grace periods and execute callbacks on behalf of the updaters instead of the updaters performing such work themselves.

In another embodiment the two or more helper threads may include a default helper and one or more of a per thread helper a per CPU helper or a per node helper. In another embodiment a single one of the two or more helper threads may be assigned to operate as the default thread and as one or more of the per thread helper the per CPU helper or the per node helper. In another embodiment the two or more helper threads may each have an associated helper thread data structure whose fields may include a callback list header field a flags field a lock field a condition field a callback list length field a helper thread identifier field and a list head field. In another embodiment the RCU subsystem may comprise a register callback component that enqueues a callback on a callback list of one of the helper thread data structures and wakes up the data structure s associated helper thread. In another embodiment the RCU subsystem comprises a grace period detection callback processing component that is implemented by the two or more helper threads on behalf of the updaters. In another embodiment the grace period detection callback processing component processes callbacks while they are pending then either 1 polls for a specified time period to await new callbacks if a real time updater is being serviced or 2 sleeps to await awakening if a non real time updater is being serviced. In another embodiment the RCU subsystem comprises a set of helper thread functions for creating ending waking querying and assigning the two or more helper threads.

The present disclosure describes an efficient technique for supporting asynchronous grace periods in user level RCU implementations. According to example embodiments described in more detail below the technique optionally provisions two or more helper threads to handle the RCU callbacks of one or more worker threads. In this context a worker thread can be any thread that registers a callback for processing following an asynchronous grace period such as by invoking a register callback component see below . In most cases worker threads will be updaters. However the register callback component could also be invoked by readers while performing an update within an RCU read side critical section or could even be invoked during the processing of an RCU callback. In the former case readers that invoke the register callback component would also be worker threads. In the latter case helper threads that invoke the register callback component during callback processing would also be worker threads. However such helper threads would most likely process new callbacks that they registered on their own behalf but could conceivably invoke additional helper threads if desired.

The helper threads may have varying scope according to the number of worker threads they support. At one extreme a single default system wide helper thread may be provided to support all worker threads. At the other extreme per thread helper threads may be exclusively assigned to individual worker threads. Between these extremes it would be possible to create many other worker thread helper thread relationships including but not limited to per processor helper threads that are assigned to worker threads on a given processor per node worker threads that are assigned to worker threads on a given node e.g. for NUMA systems etc. Helper threads may also be assigned to worker threads other means including random or round robin.

In an embodiment each helper thread has a corresponding data structure whose elements may include a 1 helper thread callback list 2 a helper thread identifier 3 a helper thread lock 4 a helper thread condition indicator 5 a set of helper thread flags 6 a helper thread callback counter and 7 a list head for maintaining the helper thread data structure on a list of helper thread data structures. Details of the helper thread data structures are described in more detail below.

In an embodiment helper threads may be created in advance of any worker threads invoking the register callback component. Alternatively the register callback component may be implemented so that it will create a new helper thread the first time it is invoked by a worker thread if there are no existing helper threads available. Prior to creating a new helper thread the register callback component may look for existing helper threads that can be used on the worker thread s behalf. By way of example the register callback component may look first for a per thread helper thread that has already been assigned to the worker thread then a per CPU helper thread and finally the system default helper thread. Once a suitable helper thread has been identified or created if necessary the register callback component can wake up the thread and cause it to perform the appropriate callback operations. These operations include registering a new callback waiting for the end of a grace period and processing the callbacks on its callback list. In an embodiment a new helper thread may be assigned to a worker thread if the worker thread is migrated away from the part of the system serviced by its current helper thread. This feature as well as others may be implemented by way of a set of one or more helper thread support functions such as those that are described in more detail below .

Turning now to the figures wherein like reference numerals represent like elements in all of the several views illustrates a symmetrical multiprocessor SMP computing system is shown in which multiple processors . . . are connected by way of a common bus to a shared memory . Respectively associated with each processor . . . is a conventional cache memory . . . and a cache controller . . . . A conventional memory controller is associated with the shared memory . As shown the memory controller may reside separately from processors . . . e.g. as part of a chipset . Alternatively the memory controller could be provided by plural memory controller instances respectively integrated with the processors . . . as is known in the art . The computing system is assumed to be under the management of a multitasking operating system adapted for use in an SMP environment. shows a uniprocessor system A that is similar to multiprocessor system except there is only a single processor and a corresponding cache memory and cache controller .

In each of the example computing systems and A may represent any type of computing apparatus including but not limited to general purpose computers special purpose computers portable computing devices communication and or media player devices set top devices embedded systems to name but a few. In the processors . . . may each be implemented as an integrated single core or multi core CPU Central Processing Unit devices. Alternatively the processors . . . could represent individual cores within a single multi core CPU device. In the processor may be a single core or multi core CPU device. Each processor of is operable to execute program instruction logic under the control of a software program stored in the memory or elsewhere . The memory may comprise any type of tangible storage medium capable of storing data in computer readable form including but not limited to any of various types of random access memory RAM various flavors of programmable read only memory PROM such as flash memory and other types of primary storage. In the processor and the memory may be situated within a single computing device or node. In the processors . . . may be situated within a single computing device or node e.g. as part of a single node SMP system or they may be distributed over plural nodes e.g. as part of a NUMA system a cluster a cloud etc. .

It is further assumed in that update operations executed within a user level threads or other user level execution contexts will periodically perform updates on a set of shared data stored in the shared memory . Reference numerals . . . illustrate individual user level data update operations updaters that may periodically execute on the several processors . . . . Alternatively the updaters . . . could all run on a single processor that is either part of the multiprocessor computing system or is the sole processor of theft uniprocessor computing system A of . As described by way of background above the updates performed by the data updaters . . . can include modifying elements of a linked list inserting new elements into the list deleting elements from the list and many other types of operations. To facilitate such updates the several processors . . . of and the single processor of are programmed to implement a user level read copy update RCU subsystem as part of their user level application functions. In the RCU subsystem comprises RCU instances . . . that periodically execute on the several processors . . . . In there is but one instance of the RCU subsystem . Each of the processors . . . of and the single processor of also periodically execute user level read operations readers . . . on the shared data . Such read operations will typically be performed far more often than updates insofar as this is one of the premises underlying the use of read copy update.

The updaters . . . the readers . . . and the RCU subsystem including each of the RCU subsystem instances . . . can be implemented as user level threads within a multithreaded user level program. As persons skilled in the art will appreciate multithreaded programming is a form of parallel programming wherein several threads of control also known as lightweight processes may execute separately within a single application program. All threads share the same memory space and can therefore work concurrently with shared data. The POSIX threads pthreads library is one example of a multithreaded implementation wherein each user level thread is implemented with scheduling support being provided by the underlying operating system e.g. Linux . In an alternate embodiment the user level threads could be provided entirely at the user level via implementations such as Green threads. In the example embodiments described hereinafter a POSIX pthreads implementation is assumed for purposes of illustration only and not by way of limitation.

The RCU subsystem supports asynchronous grace periods. This type of grace period processing entails the management of callback lists that accumulate callbacks registered by the updaters . . . until they are ripe for batch processing at the end of a given grace period. Updaters may register callbacks using a user level variant of the call rcu primitive found in existing RCU implementations. As discussed in the Introduction section above the registered callbacks occasionally need to be processed in order to free the memory associated with stale data elements. In accordance with the present disclosure callback processing efficiency is improved by offloading callback processing from the updaters . . . worker threads to two or more helper threads that can be created or selected as needed. This offloading is illustrated in which collectively depict two or more helper threads that may be used by the updaters . . . in the system of to perform callback processing.

In each updater . . . has a corresponding per thread helper thread A A. . . A. In updaters and on processor share a per cpu helper thread B and updaters and on processor share a per cpu helper thread B. In updaters and on processor and updaters and on processor in a node of the system share a per node cpu helper thread C. Although not shown other nodes in the system could likewise have per node helper threads C. . . C. In updaters and on processor and updaters and on processor in the system share a system wide default helper thread D.

It should be pointed out that the above listed types of helper threads A B C and D are not necessarily provided by separate mutually exclusive helper threads . In fact any given helper thread may be assigned to serve as a per thread helper A a per CPU helper B a per node helper C and as the default helper D. In some cases a given helper thread might have overlapping assignments for example as a both per thread helper A and as a per CPU helper B and so on. Indeed it would be possible for a single helper thread to be assigned to play the role of all helper thread types listed above.

Turning now to example components of the RCU subsystem are shown. These components include several RCU subsystem data structures and a set of RCU subsystem support functions . The RCU subsystem data structures include two or more helper thread data structures . The RCU subsystem support functions include an RCU reader API Application Programming Interface an RCU updater API a grace period detection callback processing component and a helper thread API .

The two or more helper thread data structures respectively correspond to the two or more helper threads shown in . For example per thread data structures A A. . . Amay be respectively associated with the per thread helper threads A A. . . Aof . Per CPU data structures B B. . . Bmay be respectively associated with the per CPU helper threads B B. . . Bof . Per node data structures C C. . . Cmay be respectively associated with the per node helper threads C C. . . Cof . Finally a default data structure D may be associated with the default helper thread D. Each of the foregoing helper thread data structures may be linked together in a linked list such as by incorporating a list head structure in each such data structure.

Because the helper threads may serve in various roles their associated helper thread data structures may likewise play different roles. Indeed the helper thread data structures may be used to assign the helper threads to their various roles. For example to assign a helper thread to the role of a per thread helper A a pointer to the associated helper thread data structure may be stored as a per thread variable for a worker thread that will use the helper thread e.g. an updater . This will cause the helper thread data structure to assume the role of a per thread data structure A. To assign a helper thread to the role of a per CPU helper B a pointer to the associated helper thread data structure may be stored in an array of pointers to per CPU data structures B with each array position corresponding to a particular processor . This will cause the helper thread data structure to assume the role of a per CPU data structure B. To assign a helper thread to the role of a per node helper C pointers to the associated helper thread data structure may be stored in the per CPU pointer array in association with each processor located in a given node . This will cause the helper thread data structure to assume the role of a per node data structure C. To assign a helper thread to the role of the default helper D a pointer to the associated helper thread data structure may be stored as a global variable that is accessible by all threads. This will cause the helper thread data structure to assume the role of the default data structure D.

Turning now to an example template for each of the helper thread data structures is shown that may include seven fields. A first field is a callback list header for a list of callbacks that an associated helper thread will manage and process at the end of a grace period. A second field is used to store various thread flags indicating the status of the associated thread. In an example embodiment the following status flags may be represented by setting clearing bits in this field 

The URCU CALL RCU RT flag indicates whether the helper thread requires real time response. In an example embodiment this flag may be set by the least significant lowermost bit of the flags field . The URCU CALL RCU RUNNING flag indicates whether the associated helper thread is running. In an example embodiment this flag may be set by the second lowermost bit of the flags field . The URCU CALL RCU STOP flag tells the associated helper thread to stop. In an example embodiment this flag may be set by the third lowermost bit of the flags field . The URCU CALL RCU STOPPED flag is set by the helper thread when it does stop. In an example embodiment this flag may be set by the fourth lowermost bit of the flags field .

The third field of the helper thread data structure is a lock for serializing access by the associated helper thread to variables that are shared with other helper threads. In an example embodiment the lock may be implemented as a pthread mutex mutual exclusion lock. The fourth field holds conventional pthread condition variables that are protected by the lock and set by conventional pthread condition functions to support synchronization of the associated helper thread with respect to other helper threads. Such condition functions allows the helper thread to suspend execution and relinquish its processor until some predicate on shared data is satisfied. The basic operations on conditions are to 1 signal the condition when the predicate becomes true and 2 wait for the condition suspending the thread execution until another thread signals the condition. Examples condition functions include pthread cond init pthread cond signal and pthread cond wait. The pthread cond init function initializes the condition variable . The pthread cond signal function restarts the helper thread when the condition indicated by the condition variable has occurred. The pthread cond wait function waits for the condition variable to be signaled.

The fifth field of the helper thread data structure is callback count variable that indicates the length of the callback list linked to the callback list header . The sixth field is a helper thread identifier that contains the pthread id number of the associated helper thread . The seventh field is a list head structure for queuing the helper thread data structure on a list of helper thread data structures.

Turning now to individual components of the RCU subsystem support functions are shown. These components may be implemented in any suitable fashion including within the readers and updaters themselves or as library functions in a user level library such as the POSIX threads library. The RCU reader API comprises a reader registration component and a reader unregistration component . These components are respectively invoked by readers as they enter and leave their RCU read side critical sections in order to allow the RCU subsystem to track reader quiescent states with all processing performed outside of a set of bounded calls to the reader registration and reader unregistration components being treated as a quiescent state. The operational details of the reader registration component and the reader unregistration component are not germane to the present disclosure and will therefore not be described. Suffice it to say that there are existing user level RCU implementations whose reader registration and reader unregistration components may be used to implement the user level RCU implementation described herein. See for example the user level versions of rcu read lock and rcu read unlock described in commonly owned U.S. Published Patent Application No. 2010 0023946A1.

The RCU updater API comprises a register callback component for use in connection with asynchronous grace period processing and may also include a synchronous grace period component . The latter component may be implemented in conventional fashion and its details will therefore not be described. Any suitable user level version of an RCU primitive such as synchronize rcu may be used. See for example the user level version of synchronize rcu described in commonly owned U.S. Published Patent Application No. 2010 0023946A1. During update operations an updater may perform a first phase update to a shared data element and then invoke the synchronous grace period component to to force a grace period. The updater would block until the synchronous grace period has ended then perform a second phase update to free stale data from memory or take other actions .

The register callback component is used by updaters to register a callback following a first phase update to a shared data element . A user level version of the call rcu primitive may be used for this purpose. The details of this primitive will be described in more detail below in connection with . Its principal operations are to identify a helper thread to act on behalf of the updater or create one if necessary enqueue a callback on the callback list of the associated helper thread data structure and wake up the helper thread to perform asynchronous grace period detection and callback processing i.e. by implementing the RCU grace period detection callback processing component .

The RCU grace period detection callback processing component performs the asynchronous grace period processing referred to in the previous paragraph. These operations are performed by the helper thread that was invoked by the register callback component . As described in more detail below these operations comprise waiting for the end of an asynchronous grace period at which point the callback list of the associated helper thread data structure is traversed in order to execute each callback that is ripe for processing.

The helper thread API comprises various helper functions that provide an infrastructure for invoking and using the helper threads . These helper functions may include a create helper component a create per CPU helper component a free helper component a wake up helper component a get current helper component a get assigned helper component a get per CPU helper component a get default helper component a set current helper component and a set per CPU helper component .

Example operations of the create helper component are shown in . Block creates a new helper thread data structure . Block initializes the helper thread data structure . This initialization may include initializing the callback list setting the flag field to indicate the URCU CALL RCU RUNNING state initializing the attributes of the lock and initializing the condition variable . Block adds the helper thread data structure to a linked list of such data structures. Block launches the new helper thread such as by calling the POSIX pthread create function. The arguments to the pthread create function will specify the helper thread routine to be performed and the arguments to that routine. In accordance with the present disclosure the helper thread routine is the grace period detection and callback processing component and the argument to that routine is the new helper thread data structure . The operations of the grace period detection and callback processing component are described in more detail below.

The create per cpu helpers component is used to create a separate per CPU helper thread B for each processor that may be present. Example operations are shown in in which block allocates an array of pointers to the per CPU helper threads B and then block populates the array by creating one such helper thread for each processor that does not already have a per CPU helper thread.

The free helper component ends a helper thread and frees its associated helper thread data structure . The caller should ensure that the helper thread is no longer in use before invoking this component. Example operations are shown in beginning with block which returns if an attempt is made to free the default helper thread D or if the specified helper thread does not exist . In block a check is made to see if the helper thread has any pending callbacks that need to be processed. If there are such callbacks they are transferred to the default helper thread in block . Following block or if there were no remaining callbacks in block the associated helper thread data structure is freed from memory.

The wake up helper component wakes up a helper thread in order to perform callback processing but only if the helper thread is servicing a non real time worker thread. If the helper thread is servicing a real time worker thread as indicated by the flags field of the associated helper thread data structure being set to URCU CALL RCU RT a wake up signal is not used. Instead the helper thread polls to await new callbacks as described in more detail below in connection with . The wake up helper component is invoked by the register callback component . Its wake up operation is shown by block in which calls pthread condition signal to wake the helper thread provided that the helper thread is not already running.

The get current helper component is invoked by updaters . It returns a pointer to a helper thread data structure for the updater s current helper thread . Any per thread helper A assigned specifically to the updater has first priority followed by any per CPU helper B for the processor which the updater is running followed by the default helper D if their are no other helpers. Provision could also be made to check for a per node helper C if so desired. Example operations are shown in . Block returns a pointer to the current per thread data structure A being used by the updater if there is one. If the updater is not currently using a per thread helper A block returns a pointer to the current per CPU data structure B being used by the updater if there is one. If the updater is not currently using a per CPU helper B block returns a pointer to the default data structure D. If for some reason there is no default helper D block will create it. As indicated above the get current helper component could be modified to check for and return a pointer the current per node helper C being used by the updater if there is one.

The get assigned helper component returns a pointer to a per thread data structure A whose associated per thread helper A is hard assigned to an updater . A NULL pointer may be returned if the updater is instead using a per CPU helper B or the default helper D. This operation is shown by block in .

The get per CPU helper component returns a pointer to a per CPU data structure B for a specified processor . A NULL pointer may be returned if there is no per CPU helper B for the indicated processor. This operation is shown by block in .

The get default helper component returns a pointer to the default data structure D or creates such a data structure if necessary. This operation is shown by block in .

The set current helper component is called by an updater . It sets the updater s helper thread using a local thread pointer variable that references a specified helper thread data structure . The helper thread data structure will thereafter serve as a hard assigned per thread data structure A. This operation is shown by block in .

The set per CPU helper component is used to set a processor s per CPU helper thread B. This may be done by setting a pointer to a specified helper thread data structure in the previously mentioned pointer array that stores pointers to per CPU data structures B. The specified data structure will be assigned to role of a per CPU thread data structure B. This operation is shown by block in . Note that the set per CPU helper component may be used to establish a per node helper thread C. For example a helper thread may be created using the create helper component for the node . Then the set per CPU helper component may be invoked to assign the newly created helper thread to each of the node s processors .

Having now described the various components that may be used to implement the helper thread API the operations of the register callback component and the RCU grace period detection and callback processing component may be described in more detail.

The register callback component is invoked by updaters to schedule a callback function to be executed following the end of a grace period. These operations are performed by a helper thread acting on behalf of worker threads that implement the updaters . In most cases the register callback component will be the only function that an updater needs to call in order to invoke a helper thread . The various above described components . . . of the helper thread API are only needed by the updaters to tune their use of RCU for maximum performance. Example operations of the register callback component are shown in . Updaters call this function with callback and its execution function serving as the function parameters. In block the register callback component prepares the callback for enqueuing on a callback list. Block parameters calls the get current helper component described above in connection with . As previously described this component will return the updater s current helper thread which may be a per thread helper A a per CPU helper B a per node helper C or the default helper D . Block enqueues the callback on the callback list that is linked to the callback list header of the helper thread s associated helper thread data structure . This enqueuing may be performed using a conventional non blocking enqueuing technique as disclosed for example in M. Micheal et al. Nonblocking algorithms and preemption safe locking on multiprogrammed shared memory multiprocessors J. Parallel Distrib. Comput. vol. 51 no. 1 pp. 1 26 1998. According to this technique an atomic exchange operation is used to atomically update the callback list s tail pointer to reference the next pointer of the new callback returning a pointer to the next pointer of the previous callback or a pointer to the list header if there is no previous element . Then a pointer to the new element is non atomically updated into the next pointer returned by the atomic exchange operation. This allows unconditional enqueuing in a fixed number of instructions. In block the callback counter in the helper thread data structure is incremented to reflect the addition of the new callback. Block calls the wake up helper component described above in connection with . This wakes up the helper thread so that it can implement the RCU grace period detection callback processing component .

Example operations of the RCU grace period detection callback processing component are shown in . As discussed above it is invoked by the register callback component with a pointer to a helper thread data structure being passed as a parameter. In block a check is made for pending callbacks. If there are none which is possible if the helper thread was recently invoked by another worker thread to process callbacks processing returns. If there are pending callbacks block separates them from the callback list linked to the callback list header of the helper thread s associated helper thread data structure . This allows new callbacks to accumulate for subsequent execution following a later grace period. Block then forces a synchronous grace period and block processes the callbacks when the grace period ends. At this point it is desirable to have the helper thread wait until there are more callbacks to processes. How this is handled depends on whether or not the helper thread is servicing a real time worker thread. Block performs this check by inspecting the flags field of the associated helper thread data structure to see if the URCU CALL RCU RT flag is set. If this is the case it means that the worker thread will not explicitly signal the helper thread to wakeup. The helper thread may therefore poll for a selected time period in block before returning to block to check for more callbacks. On the other hand if block determines that the helper thread is servicing a non real time thread and provided there is no further work to do i.e. there are no pending callbacks the helper thread will be put to sleep in block and the condition field of the associated helper thread data structure will be set to indicate this condition. Assuming the helper thread is put to sleep processing will return to block after the thread is reawakened.

Accordingly a technique for has been disclosed for effectively implementing asynchronous grace periods in a user level RCU implementation. It will be appreciated that the foregoing concepts may be variously embodied in any of a data processing system a machine implemented method and a computer program product in which programming logic is provided by one or more machine useable storage media for use in controlling a data processing system to perform the required functions. Example embodiments of a data processing system and machine implemented method were previously described in connection with . With respect to a computer program product digitally encoded program instructions may be stored on one or more computer readable data storage media for use in controlling a computer or other digital machine or device to perform the required functions. The program instructions may be embodied as machine language code that is ready for loading and execution by the machine apparatus or the program instructions may comprise a higher level language that can be assembled compiled or interpreted into machine language. Example languages include but are not limited to C C assembly to name but a few. When implemented on a machine comprising a processor the program instructions combine with the processor to provide a particular machine that operates analogously to specific logic circuits which themselves could be used to implement the disclosed subject matter.

Example data storage media for storing such program instructions are shown by reference numerals memory and cache of the multiprocessor system of and the uniprocessor system A of . The systems and A may further include one or more secondary or tertiary storage devices not shown that could store the program instructions between system reboots. A further example of media that may be used to store the program instructions is shown by reference numeral in . The media are illustrated as being portable optical storage disks of the type that are conventionally used for commercial software sales such as compact disk read only memory CD ROM disks compact disk read write CD R W disks and digital versatile disks DVDs . Such media can store the program instructions either alone or in conjunction with an operating system or other software product that incorporates the required functionality. The data storage media could also be provided by portable magnetic storage media such as floppy disks flash memory sticks etc. or magnetic storage media combined with drive systems e.g. disk drives . As is the case with the main memory and the cache memories of the storage media may be incorporated in data processing platforms that have integrated random access memory RAM read only memory ROM or other semiconductor or solid state memory. More broadly the storage media could comprise any electronic magnetic optical infrared semiconductor system or apparatus or device or any other tangible entity representing a machine manufacture or composition of matter that can contain store communicate or transport the program instructions for use by or in connection with an instruction execution system apparatus or device such as a computer. For all of the above forms of storage media when the program instructions are loaded into and executed by an instruction execution system apparatus or device the resultant programmed system apparatus or device becomes a particular machine for practicing embodiments of the method s and system s described herein.

Although various example embodiments have been shown and described it should be apparent that many variations and alternative embodiments could be implemented in accordance with the disclosure. It is understood therefore that the invention is not to be in any way limited except in accordance with the spirit of the appended claims and their equivalents.

