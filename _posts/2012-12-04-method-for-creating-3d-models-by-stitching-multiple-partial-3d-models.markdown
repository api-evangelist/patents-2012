---

title: Method for creating 3-D models by stitching multiple partial 3-D models
abstract: A method of creating a 3-D model by capturing partial 3-D models each comprising a sequence of 2-D images, analyzing each of the partial 3-D models to identify image features in the sequence of 2-D images of each of the partial 3-D models, identifying pairs of overlapping image features between the 2-D mages of each of the partial 3-D models by identifying image features in each 2-D image in the sequence of 2-D images of each of the partial 3-D models that overlaps image features in 2-D images of the sequence of 2-D images of the other partial 3-D models and selecting a 2-d image from each of the partial 3-D models, computing an initial transformation between 3-D coordinates of individual pairs of identified image features between the selected 2-D image from each of the partial 3-D models; and generating a final 3-D model based on the initial transformation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09129435&OS=09129435&RS=09129435
owner: FUJI XEROX CO., LTD.
number: 09129435
owner_city: Tokyo
owner_country: JP
publication_date: 20121204
---
Aspects of the example embodiments are directed to 3 D model creations and more specifically 3 D model creation by stitching together multiple partial 3 D models.

Recently a variety of devices have emerged that can capture 3 D structures such as laser lidar sensors stereo cameras and low cost consumer RGB depth cameras such as the MICROSOFT KINECT. These devices are able to capture 3 D structures in their field of view in the form of point clouds or depth maps. Such devices have greatly reduced the effort required to capture 3 D structures. However while these devices are able to capture 3 D structures from a single viewpoint these devices typically do not provide a method to capture 3 D from multiple viewpoints and or locations.

Further services utilizing 3 D models such as GOOGLE EARTH and APPLE MAPS are becoming increasingly popular. Uses for 3 D models can include navigation site promotion and virtual or mirrored reality. In order to provide such services there needs to be a method to create a 3 D model that represents the physical environment. Traditionally 3 D models were created manually which was time consuming and costly. Therefore there may be a need to automate the process of model creation.

This application relates to a method to automatically create full 3 D models by stitching together partial 3 D models captured from multiple viewpoints and locations. Such partial 3 D models can come from any of the above mentioned sources in raw or processed form. An exemplary method stitches partial 3 D models by estimating relative transformations between partial 3 D models and applying transformations to partial models to stitch them into a full 3 D model. The relative transformations can be estimated from feature matches which may be found using 2 D image features. Throughout the present application the terms 3 D models and 3 D partial models may refer to 3 D structures represented as point clouds meshes or volumetric structures.

Aspects of certain example embodiments include a method of creating a 3 D model by combining multiple partial 3 D models each partial 3 D model comprising a sequence of 2 D images each 2 D image associated with 3 D coordinates mapped onto the 3 D model the method including analyzing each of at least three partial 3 D models to identify image features in the sequence of 2 D images of each of the partial 3 D models identifying pairs of overlapping image features between the 2 D images of each of the partial 3 D models by identifying image features in each 2 D image in the sequence of 2 D images of each of the partial 3 D model that overlaps or matches image features in 2 D images of the sequence of 2 D images of the other partial 3 D models and selecting a 2 D image from each of the partial 3 D models computing an initial global transformation between 3 D coordinates of individual pairs of the identified overlapping image features between the selected 2 D image from each of the at least three partial 3 D models and generating a final 3 D model based on the initial global transformation.

Aspects of certain example embodiments include a computer readable medium having stored therein executable instructions for performing a method of creating a 3 D Model by combining multiple partial 3 D models each partial 3 D model comprising a sequence of 2 D images each 2 D image associated with 3 D coordinates mapped onto the 3 D model the method including analyzing each of at least three partial 3 D models to identify image features in the sequence of 2 D images of each of the partial 3 D models identifying pairs of overlapping image features between the 2 D images of each of the partial 3 D models by identifying image features in each 2 D image in the sequence of 2 D images of each of the partial 3 D models that overlaps or matches image features in 2 D images of the sequence of 2 D images of the other partial 3 D models and selecting a 2 D image from each of the partial 3 D models computing an initial global transformation between 3 D coordinates of individual pairs of the identified overlapping image features between the selected 2 D image from each of the at least three partial 3 D models and generating a final 3 D model based on the initial global transformation.

Aspects of certain example embodiments include an apparatus for creating a 3 D Model by combining multiple partial 3 D models each partial 3 D model comprising a sequence of 2 D images each 2 D image associated with 3 D coordinates mapped onto the 3 D model the apparatus including an image feature analyzer that analyzes each of at least three partial 3 D models to identify image features in the sequence of 2 D images of each of the partial 3 D models an overlapping image feature identification device that identifies pairs of overlapping image features between the 2 D images of each of the partial 3 D models by identifying image features in each 2 D image in the sequence of 2 D images of each of the partial 3 D models that overlaps or matches image features in 2 D images of the sequence of 2 D images of the other partial 3 D models and selecting a 2 D image from each of the partial 3 D models a controller configured to compute an initial global transformation between 3 D coordinates of individual pairs of the identified overlapping image features between the selected 2 D image from each of the at least three partial 3 D models and a display to display a final 3 D model generated based on the initial global transformation.

Aspects of certain example embodiments include a method of providing a viewable 3 D model the method including receiving a plurality of 2 D images each encoded with associated 3 D coordinates in a 3 D space analyzing each of the plurality of 2 D images to identify image features in each of the plurality of 2 D images identifying pairs of overlapping image features between the 2 D images of each of the partial 3 D models by identifying image features in each 2 D image in the sequence of 2 D images of each of the partial 3 D models that overlaps or matches image features in 2 D images of the sequence of 2 D images of the other partial 3 D models and selecting a 2 D image from each of the partial 3 D models computing by a processor an initial global transformation between 3 D coordinates of individual pairs of the identified overlapping image features between the selected 2 D image from each of the at least three partial 3 D models and providing the final 3 D model in a browsable format based on the initial global transformation.

In the following detailed description reference will be made to the accompanying drawing s in which identical functional elements are designated with like numerals. The aforementioned accompanying drawings show by way of illustration and not by way of limitation specific embodiments and implementations consistent with principles of an example embodiment. These implementations are described in sufficient detail to enable those skilled in the art to practice an example embodiment and it is to be understood that other implementations may be utilized and that structural changes and or substitutions of various elements may be made without departing from the scope and spirit of an example embodiment. The following detailed description is therefore not to be construed in a limited sense. Additionally the various embodiments of the invention as described may be implemented in the form of software running on a general purpose computer in the form of a specialized hardware or combination of software and hardware.

In this application an example method and apparatus for providing a 3 D model by stitching together multiple unordered partial 3 D models are described. Thus as an initial matter multiple unordered partial 3 D models are captured or received from a 3 D model input source. The present method is not particularly limited to a specific type of 3 D input source and may handle a 3 D model from various sources. Examples of the possible sources of inputs include but are not limited to 

Further in addition to the above discussed 3 D measurement sources a sequence of calibrated 2 D images sequence could also be used as a source of a partial 3 D model. As used herein a calibrated 2 D image sequence means a sequence of 2 dimensional images that that for any given point in the 2 D images a 3 D position has been encoded from a 3 D measurement source.

In the example method of multiple partial 3 D models of an environment are captured in . The partial 3 D models may be collected from one or more sources discussed above or any other 3 D model source as would be apparent to a person of ordinary skill in the art. Each partial 3 D model includes one or more associated 2 D or 3 D images. In other words each partial 3 D model includes a 3 D structure represented as point clouds meshes or volumetric structures and 2 D image information from one or more images associated with 3 D coordinates within the partial 3 D model so that the 2 D image information can be overlaid on top of the 3 D structure.

Identify Image Features within the Partial 3 D Models and Find Overlapping Pairwise Image Matches Between Partial 3 D Models

After the multiple partial 3 D models are captured in each partial 3 D model is processed to identify image features in . As discussed above each partial 3 D model includes one or more associated 2 D images. In each of the 2 D images associated with the each of the partial 3 D models is processed using one or more image recognition techniques to identify objects and features of the image. For example each of the images associated with each of the partial 3 D models may be analyzed using a Scale Invariant Feature Transform SIFT image recognition process to identify features of each of the images. Other methods of analysis may be used in .

Once each of the images associated with each of the partial 3 D models has been processed to identify image features in image features identified in one of the partial 3 D models for example which overlap or match features identified in another of the partial 3 D models for example are identified as overlapping image features in . In other words the image or images associated with each of a pair of partial models and are analyzed to determine if features match or overlap. Thus features within each of the images of one of the partial 3 D models that are common to one or more images of another of the partial 3 D models are identified as the overlapping features.

Once common features have been identified between images of different partial 3 D models the 3 Dimensional coordinates of the images within the partial 3 D models is analyzed. The pair of partial models and are identified as being overlapping partial 3 D models when images associated with each partial model contain one or more matching image features and a large enough spread such that features are not collinear or coplanar is determined. This spread is quantified by a measure as discussed below. Further if the partial models have more than one associated image there are several pairs of images from the pair of partial models that have a sufficient number of matching image features one pair of images which best constrains the relative pose is chosen.

The spread between the features and constraint of the relative pose is determined by performing Principal Component Analysis PCA on the 3 D coordinates of matching image features within each of the partial 3 D models. Then the pair of image features which has the largest smallest 3rd eigenvalue based on a covariance matrix of the 3 D coordinates associated with the image features is selected as the image features to be used in subsequent analysis discussed above. As mentioned above this may prevent the features from being collinear or coplanar which does not adequately constrain the relative pose.

In this embodiment one image is selected from each of partial 3 D models as the best overlapping image pairs and is used for the subsequent analysis discussed above. However embodiments of the present application need not use only one image selected from each of the partial 3 D models and instead may use more than one image selected from each of the partial 3 D models.

Overlapping partial 3 D models have been identified the transformation relating the two partial 3 D models can be estimated. Specifically the transformation that minimizes a 3 D Euclidean distance between corresponding or matching image features using Random Sample Consensus RANSAC procrustes analysis.

Once transformations for all pairs of overlapping partial models are estimated in an initial global transformation for the whole set of partial models is calculated in . shows an initial global transformation computed as an initial estimate by propagating pairwise transformations along a spanning tree approach. In other words the partial models are arranged such that connections are established between overlapping partial models by attempting to connect each of the partial through a single model which can function as a trunk to which as many other models can be connected as branches .

Thus the set of partial models is analyzed to determine which partial model overlaps with the most other partial models. As shown in the example embodiment in partial model overlapped with four of the other partial models and thus is selected as the trunk of the spanning tree. The four partial models which overlap with partial model are arranged with respect to the partial model based on the estimated transformations calculated in and connections to the trunk partial model are established. Further once the branch partial models which overlap the trunk partial model are arranged any partial model that does not overlap the trunk partial model but overlaps one of the branch partial models is arranged with respect to the branch partial model to which it overlaps and a connection there between is established. Thus an initial pose or arrangement of the partial models is created. By using a spanning tree approach as discussed above global transformation of the partial models can be computed by compounding pairwise transforms along the edges of the spanning tree.

Once the initial global transformation is calculated in to create the initial pose or arrangement as shown in the global transformation is refined in using all of the overlapping image features among all pairs of overlapping partial models. shows an example embodiment showing the connections between all pairs of overlapping partial models . Specifically connections and are established between partial models and which were not connected using the spanning tree approach in once the initial pose or arrangement is determined. Further the initial Global transformations are refined by running a global optimization routine that minimizes the sum of all distances i.e. connections between overlapping image features of all of the partial models by minimizing the function 

In the above discussed embodiment the initial global transformation was refined using all pairs of overlapping features in all of the partial 3 D models. However an example embodiment of the present application need not use all pairs of overlapping features to refine the initial global transformation. Instead an example embodiment may refine the initial global transformation using as few as pairs of overlapping features in the partial 3 D models. Using at least 3 pairs of overlapping features allows the rotation of 3 D coordinates to be prevented.

After the initial global transformation is refined in the global transformations can be further refined in using pairs of points of the overlapping partial models which do not correspond to overlapping image features. Specifically the global transformations may be further refined by using Iterative Closest Points ICP analysis on corresponding points of the partial models that do not correspond with previously identified overlapping image features. In some embodiments ICP analysis may be performed on all corresponding points of the partial models. By using more corresponding points i.e. points not associated with overlapping image features or all points of the partial models improved alignment of the final model may be achieved.

In embodiments where point clouds are used to represent the individual partial 3 D models all point clouds can be put together into a single coordinate system using the calculated final global transformation to generate or create the final model. Additionally in some embodiments an optional down sampling method may be run to reduce the point density when desired.

In embodiments where meshes or other volumetric structures are used to represent the individual partial 3 D models additional processing may be performed on the partial 3 D models to create the final model. For example the image information associated with the individual partial 3 D models may be re meshed to smooth the collected partial models into a single final model.

In the above embodiment 6 partial models are used to create the final 3 D model. However an embodiment of the present application is not limited to using 6 partial models and can include any number of models. For Example shows a model stitched together from 10 partial models and shows a model stitched together from 14 partial models.

Once the final 3 D model is generated based on the final global transformation the use of the final 3 D model is not particularly limited. For Example the Final 3 D model may be displayed on a 3 Dimensional image display device. Alternatively the final 3 D model may be provided to consumers in a browsable digital format.

Computing device can be communicatively coupled to input user interface output device interface and a partial model image capture device . Either one or all of the input user interface output device interface or partial model image capture device can be wired or wireless connected and can be detachable. The Input user interface may include any device component sensor or interface physical or virtual that can be used to provide input e.g. keyboard a pointing cursor control e.g. a mouse microphone camera braille motion sensor optical reader and or the like . Output device interface may include a display monitor printer speaker braille or the like. The partial model image capture device may include any device component or sensor that can be used to capture a 3 D model as discussed above. In some example embodiments input user interface and output device interface can be embedded with or physically coupled to the computing device e.g. a mobile computing device with buttons or touch screen input user interface and an output or printing display or a television . Additionally in some example embodiments a partial model image capture device may also be embedded with or physically coupled to the computing device e.g. a mobile computing device with an integrated camera .

Computing device can be communicatively coupled to external storage and network for communicating with any number of networked components devices and systems including one or more computing devices of same or different configuration. Computing device or any connected computing device can be functioning as providing services of or referred to as a server client thin server general machine special purpose machine or by other label.

I O interface can include but is not limited to wired and or wireless interfaces using any communication or I O protocols or standards e.g. Ethernet 802.11x Universal System Bus WiMax modem a cellular network protocol and the like for communicating information to and or from at least all the connected components devices and network in computing environment . Network can be any network or combination of networks e.g. the Internet local area network wide area network a telephonic network a cellular network satellite network and the like .

Computing device can use and or communicate using computer usable or computer readable media including transitory media and non transitory media. Transitory media include transmission media e.g. metal cables fiber optics signals carrier waves and the like. Non transitory media include magnetic media e.g. disks and tapes optical media e.g. CD ROM digital video disks Blu ray disks solid state media e.g. RAM ROM flash memory solid state storage and other non volatile storage or memory.

Computing device can be used to implement techniques methods applications processes or computer executable instructions to implement at least one embodiment e.g. a described embodiment . Computer executable instructions can be retrieved from transitory media and stored on and retrieved from non transitory media. The executable instructions can be originated from one or more of any programming scripting and machine languages e.g. C C C Java Visual Basic Python Perl JavaScript and others .

Processor s can execute under any operating system OS not shown in a native or virtual environment. To implement a described embodiment one or more applications can be deployed that include logic unit application programming interface API unit input unit output unit image feature identification unit overlapping model identification unit initial global transformation calculation unit global transformation optimization final global transformation calculation unit and inter unit communication mechanism for the different units to communicate with each other with the OS and with other applications not shown . For example the image feature identification unit overlapping model identification unit initial global transformation calculation unit global transformation optimization final global transformation calculation unit may implement one or more processes discussed above and shown in . The described units and elements can be varied in design function configuration or implementation and are not limited to the descriptions provided.

Though certain embodiments of the present invention may be implemented as software running on for example a mobile device example embodiments are not limited to software implementations. illustrates an example hardware implementation of an example embodiment.

In a 3 D model creating apparatus is shown. The 3 D model creating apparatus includes a partial model capture device image feature analyzer Image identification device display controller and display controller . The partial model capture device may capture multiple partial 3 D models and may be any 3 D source as discussed above. Further the image feature analyzer may analyze the images making up the 3 D models to detect the image features using the processes discussed above with respect to . Similarly the overlapping image feature identification device may identify image features in the partial 3 D models that overlap image features in other partial 3 D models using the processes discussed above with respect to .

Additionally the controller that may estimate a relative transformation between overlapping image features of the partial 3 D models computes an initial global transformation between the partial 3 D models using a spanning tree refine the initial global transformation by optimizing distances between all pairs of overlapping image features and compute a final global transformation using processes discussed above with respect to . Additionally the display controller may control the display to display a final 3 D model generated based on the final global transformation. The display is not particularly limited and could include but is not limited to a LCD display an LED display a Plasma display and Cathode ray display etc. as would be apparent to a person of ordinary skill in the art.

Although a few example embodiments have been shown and described these example embodiments are provided to convey the subject matter described herein to people who are familiar with this field. It should be understood that the subject matter described herein may be embodied in various forms without being limited to the described example embodiments. The subject matter described herein can be practiced without those specifically defined or described matters or with other or different elements or matters not described. It will be appreciated by those familiar with this field that changes may be made in these example embodiments without departing from the subject matter described herein as defined in the appended claims and their equivalents.

Aspects related to the example embodiment have been set forth in part in the description above and in part should be apparent from the description or may be learned by practice of the invention. Aspects of the example embodiment may be realized and attained by means of the elements and combinations of various elements and aspects particularly pointed out in the following detailed description and the appended claims.

It is to be understood that both the foregoing descriptions are exemplary and explanatory only and are not intended to be limiting.

