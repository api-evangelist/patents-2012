---

title: Providing a fault tolerant system in a loosely-coupled cluster environment using application checkpoints and logs
abstract: An approach to providing failure protection in a loosely-coupled cluster environment. A node in the cluster generates checkpoints of application data in a consistent state for an application that is running on a first node in the cluster. The node sends the checkpoint to one or more of the other nodes in the cluster. The node may also generate log entries of changes in the application data that occur between checkpoints of the application data. The node may send the log entries to other nodes in the cluster. The node may similarly receive external checkpoints and external log entries from other nodes in the cluster. In response to a node failure, the node may start an application on the failed node and recover the application using the external checkpoints and external log entries for the application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09098439&OS=09098439&RS=09098439
owner: International Business Machines Corporation
number: 09098439
owner_city: Armonk
owner_country: US
publication_date: 20120105
---
The subject matter disclosed herein relates to approaches to recovering from node failures in loosely coupled clusters.

A computer cluster generally refers to a group of linked computing devices that work together to perform various computational tasks. The computing devices in the cluster are often connected to each other through local area networks. In many situations the computer cluster as a whole operates as if it were a single computer. By using multiple computing devices a cluster can often provide high performance and high availability in a cost effective manner. Indeed many of the fastest computers are in fact clusters.

Many clusters use some form of shared memory or shared storage to support their operations. However other varieties of clusters do not have shared memory. These clusters lacking shared memory are called loosely coupled clusters. Lack of shared memory can make recovery from node failures in the loosely coupled cluster difficult.

An approach to node failure recovery in a loosely coupled cluster is disclosed. The summary that follows is for convenience and is not a limitation on the claims.

The invention may be realized as a computer program product stored on a computer readable storage medium. The computer program product may comprise various instructions including instructions for generating a checkpoint of application data that is in a consistent state on a first node in a loosely coupled cluster that comprises a plurality of nodes separate from the first node. The application data is data of an application running on the first node. The computer program product may further comprise instructions for sending the checkpoint to one or more nodes of the plurality of nodes and for generating one or more log entries of changes in the application data between checkpoints of the application data. The instructions may further cause sending the log entries to the one or more nodes.

The invention may also be realized as a system that includes a first event manager running on a first node in a loosely coupled cluster that also comprises a second node separate from the first node. The first event manager may generate a checkpoint of application data that is in a consistent state on the first node and may generate one or more log entries of changes in the application data between checkpoints of the application data. A first replicating service may send the checkpoint to a second node for storage in local storage of the second node and send the log entries to the second node for storage in the local storage of the second node.

The system may also include a second event manager running on the second node in the loosely coupled cluster. The second event manager may monitoring for failure of the first node and recover on the second node the first application from the checkpoint sent to the second node and from the log entries sent to the second node.

The invention may further be realized as a computer implemented method that involves generating a checkpoint of application data that is in a consistent state on a first node in a loosely coupled cluster comprising a plurality of nodes separate from the first node. The method may also involve sending the checkpoint to the one or more nodes of the plurality of nodes wherein the checkpoint is saved in local storage of the one or more nodes. The method may further involve generating one or more log entries of changes in the application data between checkpoints of the application data and sending the log entries to the one or more nodes wherein the log entries are saved in local storage of the one or more nodes.

The present invention may be realized in a variety of forms. The present invention may be realized as a computer program product a system a method or other form. References throughout this specification to features advantages or similar language do not imply that all of the features and advantages may be realized in any single embodiment. Rather language referring to the features and advantages is understood to mean that a specific feature advantage or characteristic is included in at least one embodiment. Thus discussion of the features and advantages and similar language throughout this specification may but do not necessarily refer to the same embodiment.

Furthermore the described features advantages and characteristics of the embodiments may be combined in any suitable manner. One skilled in the relevant art will recognize that the embodiments may be practiced without one or more of the specific features or advantages of a particular embodiment. In other instances additional features and advantages may be recognized in certain embodiments that may not be present in all embodiments.

These features and advantages of the embodiments will become more fully apparent from the following description and appended claims or may be learned by the practice of embodiments as set forth hereinafter.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Many of the functional units described in this specification have been labeled as modules in order to more particularly emphasize their implementation independence. For example a module may be implemented as a hardware circuit comprising custom VLSI circuits or gate arrays off the shelf semiconductors such as logic chips transistors or other discrete components. A module may also be implemented in microcode firmware or the like of programmable hardware devices such as field programmable gate arrays programmable array logic programmable logic devices or the like.

Modules may also be implemented in software for execution by various types of processors. An identified module of computer readable program code may for instance comprise one or more physical or logical blocks of computer instructions which may for instance be organized as an object procedure or function. Nevertheless the executables of an identified module need not be physically located together but may comprise disparate instructions stored in different locations which when joined logically together comprise the module and achieve the stated purpose for the module.

Indeed a module of computer readable program code may be a single instruction or many instructions and may even be distributed over several different code segments among different programs and across several memory devices. Similarly operational data may be identified and illustrated herein within modules and may be embodied in any suitable form and organized within any suitable type of data structure. The operational data may be collected as a single data set or may be distributed over different locations including over different storage devices and may exist at least partially merely as electronic signals on a system or network. Where a module or portions of a module are implemented in software the computer readable program code may be stored and or propagated on in one or more computer readable medium s .

The computer readable medium may be a tangible computer readable storage medium storing the computer readable program code. The computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared holographic micromechanical or semiconductor system apparatus or device or any suitable combination of the foregoing. The computer readable medium may be non transitory.

More specific examples of the computer readable medium may include but are not limited to a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory a portable compact disc read only memory CD ROM a digital versatile disc DVD a Blu Ray Disc BD an optical storage device a magnetic storage device a holographic storage medium a micromechanical storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain and or store computer readable program code for use by and or in connection with an instruction execution system apparatus or device.

The computer readable medium may also be a computer readable signal medium. A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electrical electro magnetic magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport computer readable program code for use by or in connection with an instruction execution system apparatus or device. Computer readable program code embodied on a computer readable signal medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fibre cable Radio Frequency RF or the like or any suitable combination of the foregoing.

In one embodiment the computer readable medium may comprise a combination of one or more computer readable storage mediums and one or more computer readable signal mediums. For example computer readable program code may be both propagated as an electro magnetic signal through a fibre optic cable for execution by a processor and stored on RAM storage device for execution by the processor.

Computer readable program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The computer readable program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Reference throughout this specification to one embodiment an embodiment or similar language means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. Thus appearances of the phrases in one embodiment in an embodiment and similar language throughout this specification may but do not necessarily all refer to the same embodiment but mean one or more but not all embodiments unless expressly specified otherwise. The terms including comprising having and variations thereof mean including but not limited to unless expressly specified otherwise. An enumerated listing of items does not imply that any or all of the items are mutually exclusive unless expressly specified otherwise. The terms a an and the also refer to one or more unless expressly specified otherwise.

Furthermore the described features structures or characteristics of the embodiments may be combined in any suitable manner. In the following description numerous specific details are provided such as examples of programming software modules user selections network transactions database queries database structures hardware modules hardware circuits hardware chips etc. to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize however that embodiments may be practiced without one or more of the specific details or with other methods components materials and so forth. In other instances well known structures materials or operations are not shown or described in detail to avoid obscuring aspects of an embodiment.

Aspects of the embodiments are described below with reference to schematic flowchart diagrams and or schematic block diagrams of methods apparatuses systems and computer program products according to embodiments of the invention. It will be understood that each block of the schematic flowchart diagrams and or schematic block diagrams and combinations of blocks in the schematic flowchart diagrams and or schematic block diagrams can be implemented by computer readable program code. These computer readable program code may be provided to a processor of a general purpose computer special purpose computer sequencer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the schematic flowchart diagrams and or schematic block diagrams block or blocks.

The computer readable program code may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the schematic flowchart diagrams and or schematic block diagrams block or blocks.

The computer readable program code may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the program code which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The schematic flowchart diagrams and or schematic block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of apparatuses systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the schematic flowchart diagrams and or schematic block diagrams may represent a module segment or portion of code which comprises one or more executable instructions of the program code for implementing the specified logical function s .

It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the Figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. Other steps and methods may be conceived that are equivalent in function logic or effect to one or more blocks or portions thereof of the illustrated Figures.

Although various arrow types and line types may be employed in the flowchart and or block diagrams they are understood not to limit the scope of the corresponding embodiments. Indeed some arrows or other connectors may be used to indicate only the logical flow of the depicted embodiment. For instance an arrow may indicate a waiting or monitoring period of unspecified duration between enumerated steps of the depicted embodiment. It will also be noted that each block of the block diagrams and or flowchart diagrams and combinations of blocks in the block diagrams and or flowchart diagrams can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer readable program code.

The term computing devices refers to physical devices that include processors and memory and that are capable of executing instructions. The computing devices may be laptop computers desktop computers server devices such as blade servers video game consoles or other suitable computing devices . The term node refers to a computing device that is a member of a cluster.

Rather than have a shared memory the computing devices have local storage . The term local storage refers to storage that is used by a particular computing device and that is not shared with the other computing devices in the cluster. The local storage may include physical storage media that is part of the computing device . The local storage may also include a file system for accessing the physical media. The local storage is not addressed as one address space for all computing devices in the loosely coupled cluster.

The computing devices are communicatively connected by a connection . The connection allows the computing devices to share information and data. The connection may be a local area network LAN wide area network WAN or other network. The connection may use Ethernet Fibre Channel or other suitable communications technologies.

The computing devices also include appropriate hardware for executing instructions such as one or more processors and may include additional components. The computing devices may also include cluster modules that cause the computing devices to operate as a loosely coupled cluster. The cluster modules may configure the computing devices to act as a single virtual machine. The cluster modules may configure the computing devices to provide load balancing and to distribute requests initiated by a user among the computing devices 

The computing devices may also run applications . The applications are computer programs that run on the computing devices and that access create and or alter data in the local storage . Each computing device may run a different application . Each computing device may have the application software necessary to start and run multiple applications at a given time. However at a given time the computing devices may be running different applications 

The computing devices may also include recovery apparatus . As explained further herein the recovery apparatus may be responsible for generating and sharing checkpoints and log entries for applications running on the computing device . In the event that a node such as computing device in the cluster fails the recovery apparatus may be responsible for using the checkpoints and log entries to recover from the failure by having the applications running on the failed node started on a separate node using the checkpoints and log entries for the applications that were running on the failed node.

The recovery apparatus generates a checkpoint of application data that is in a consistent state on the computing device which is a node in the loosely coupled cluster. The application data is data generated by the application . The checkpoint is a collection of application data in a consistent state which the application can use to recover in the event of a failure. The application data may include a snapshot of the application state. The application data may also include a snapshot of data for the application stored in the local storage

The recovery apparatus may send the checkpoint designated checkpoint in to the computing device . In one embodiment the checkpoint is sent to the recovery apparatus . The recover apparatus may receive the checkpoint and cause the checkpoint to be stored in the local storage for the computing device . In certain embodiments the recovery apparatus may send the checkpoint to the computing device as a background process. The recovery apparatus may send the checkpoint to the computing device over the connection .

The recovery apparatus may also generate log entries of changes in the application data for the application that occur between checkpoints of the application data. For example the recovery apparatus may be configured to take a checkpoint every two hours. The recovery apparatus may create a log of log entries of the changes in the application data during the two hour interval. The recovery apparatus may also send the log entries to the computing device . The log entries may be sent as part of a background process.

The recovery apparatus may create log entries by saving a sequence of records for the changes in the application data. In certain embodiments each log entry is small and can be synched among all nodes in the cluster as described below. The log entries may be replayable by the application which allows the application data for the application to be updated using the log entries . The process of creating and managing log entries may involve preparing the relevant environment for saving the log entries and appending log entry records to a log file.

The recovery apparatus may be configured to delete the log entries when a new checkpoint is taken for the application which new checkpoint accounts for the changes in application data represented by the log entries . For example a first checkpoint may be taken at time t. After the first checkpoint is taken the recovery apparatus may generate log entries that represent the changes in the application data that occur after the first checkpoint is taken. At a time t l the recovery apparatus may take a second checkpoint . This second checkpoint accounts for the changes in the application data that were recorded in the log entries . The recovery apparatus may delete the log entries and generate new log entries that occur after the second checkpoint .

The recovery apparatus may also be configured to receive an external checkpoint from the computing device . Checkpoints received from another node in the cluster are referred to as external checkpoints . The external checkpoint may include the application data for an application running on the computing device that is a node in the cluster. The recovery apparatus may receive the checkpoint and store the checkpoint in the local storage

The recovery apparatus may also receive external log entries for the application that were generated on the computing device . The external log entries may account for changes in the application data that are made after the checkpoint is generated and before another checkpoint is generated by the recovery apparatus . The recovery apparatus may store the log entries in local storage

While the above example shows only a single application on the computing device and a single application on the computing device the computing devices and may have multiple applications . The respective computing devices and may generate checkpoints and log entries for each of the applications that are running on the computing devices and

The recovery apparatus may be configured to monitor for node failures in the loosely coupled cluster that result in a failed node. The recovery apparatus may be further configured to determine in response to detecting a node failure that the node on which the recovery apparatus runs is the failover node for the failed node. Node failure can encompass a range of failures including hardware failure on the computing device and software failures.

For example the recovery apparatus may monitor for failure of the computing devices . In certain embodiments the cluster module can determine whether the computing device has failed. In such embodiments monitoring for failure may involve receiving a message from the cluster module that indicates that the computing device has failed. In other embodiments the recovery apparatus may directly monitor the computing device . For example the recovery apparatus may receive heartbeats from the recovery apparatus and determine that the computing device has failed if the recovery apparatus does not receive a heartbeat for a specified period of time. Other approaches to monitoring for node failure can also be used.

The recovery apparatus may determine that the computing device has failed. The recovery apparatus may further determine that it is the failover node for the computing device . The recovery apparatus may determine that the computing device is the failover node for the computing device based on user definitions of which nodes are to be failover nodes in the loosely coupled cluster. In another embodiment determining that the computing device is the failover node for the computing device may involve determining that the computing device has the necessary instructions to execute the application . In certain embodiments more than one computing device in the loosely coupled cluster may be the failover node for the computing device for example one computing device may be responsible for recovering a one application that was running on the failed node while another computing device may be responsible for recovery another application that was running on the failed node. In such an embodiment both computing devices are failover nodes for the failed node.

The recovery apparatus may recover on the computing device the application on the failed computing device from the checkpoint received from the computing device . The recovery apparatus may initiate the application on the computing device as part of the recovery if the application is not already running on the computing device . The recovery apparatus may also provide the application with the checkpoint such that the application can recover to the state consistent with the application data in the checkpoint

In another embodiment the application may be running on the computing device at the time of failure however the application on the computing device may be working with different application data than the application data of the application instance running on the computing device . In such an embodiment the recovery apparatus may cause the application on the computing device to take responsibility for the application data previously being managed on the computing device . The recovery apparatus may recover on the computing device the instance of the application on the failed computing device from the checkpoint received from the computing device

The recovery apparatus may further recover the application from the external log entries received by the computing device . In certain embodiments the recovery apparatus provides the log entries to the application after the application has recovered to the state consistent with the application data in the checkpoint . The application may then recover to a state that occurred after the checkpoint was taken by using the log entries to make additional changes to the application data. As a result the recovery apparatus may allow the application to recover to a point after the checkpoint was taken.

The application may thereafter run on the computing device while the computing device is a failed node. In certain embodiments the recovery apparatus continues to monitor the status of the computing device . If the recovery apparatus determines that the computing device has recovered from the failure the recovery apparatus may cause the application to failback to the computing device . Failing the application back to the computing device may involve taking a checkpoint for the application running on the computing device and sending the checkpoint to the computing device . The failback operation may also involve causing the application to restart on the computing device from the checkpoint . The failback operation may further involve shutting down the application on the computing device in response to the application on the computing device starting.

While the above example discussed taking checkpoints and log entries for a single application checkpoints and log entries may be taken at a group level as well. In certain embodiments checkpointing and logging may be done for consistency groups that include a plurality of applications . For example a user may designate three applications to be in a consistency group. Checkpoints may be generated for the entire consistency group. The checkpoints may be generated when the application data for the applications in the consistency group is consistent at a group level.

For example a transaction may involve a first step by a first application and a second step by a second application in a consistency group. The application data for the first application may be consistent after the first step is executed. The application data for the second application may be consistent after the second step is executed. The recovery apparatus may wait until the second step is executed before taking the checkpoint for the consistency group in order to ensure that the data is consistent for all applications in the consistency group at the time the checkpoint is taken.

The event manager is a component with which the applications other components of the recovery apparatus and the cluster module communicate. The event manager may be registered to the cluster module that facilitates operation of the cluster that includes the computing devices and as nodes. The event manager may watch for cluster system events cluster state transitions e.g. node removals and node additions and make data recovery decisions. The applications on the computing device may register with the event manager

The event manager may trigger the taking of a checkpoint for an application . The event manager may trigger the taking of a checkpoint for one or more applications in the consistency group. The application may take the checkpoint itself using the checkpoint and logging framework . In certain embodiments the applications are responsible for generating log entries .

In the event of a node failure on computing device the event manager may determine that the computing device has failed. The event manager may receive one or more messages from the cluster module indicating that the computing device has failed. The event manager may be responsible for determining that the computing device is the failover node for the computing device and to initiate data recovery procedures.

In certain embodiments the event manager may communicate with other event managers such as event manager in the cluster. The event manager may determine whether the checkpoint in local storage for the computing device is the most current checkpoint . In one embodiment the event manager requests a timestamp for the most current checkpoints of the other event mangers in the cluster. The event manager may use the timestamp to determine which computing device in the cluster has the most current checkpoint . Other approaches to determining which computing device has the most current checkpoint may also be used. The checkpoints need not have an associated time stamp.

The event manager may also determine which computing device has the most current log entries . The event manger may be responsible for tracking the data versions of the checkpoints and the log entries . The event manager may for example request timestamps for the latest log entry in the local storage of each computing device in the node that is functioning. The event manager may determine that the computing device with the latest time stamp for log entries has the most current log entries . As above other approaches to determining which computing device has the most current log entries may also be used.

The event manager may designate the computing device with the most current checkpoint as the failover node for the failed node. The event manager on the failover node may request the most current log entries from other computing devices in the cluster if other computing devices have more current log entries . In other embodiments a particular computing device may be designated the failover node for the failed node even if the computing device does not have the most current checkpoint or the most current log entries . In such an embodiment the event manager on the failover node may request the most current checkpoint from one or more running nodes in the cluster. The event manager may similarly request the most current log entries from one or more running nodes in the cluster.

The recovery apparatus may also include a checkpoint and logging framework . The checkpoint and logging framework is a collection of software libraries providing an application programming interface API that applications use to generate checkpoints and log entries . The interface provided by the checkpoint and logging framework may also allow applications to recover using checkpoints and log entries . In one embodiment the application invokes a method or function of the checkpoint and logging framework to generate a checkpoint and or log entry . The application may similarly invoke a method or function of the checkpoint and logging framework to obtain the data stored in a checkpoint and or one or more log entries allowing the application to recover using the application data represented by the checkpoint and or log entries .

Implementing a checkpoint and logging framework may make the benefits of checkpoints and log entries available to a wide range of applications without requiring extensive new code in the applications . In certain embodiments the applications may gain this additional functionality through the insertion of method and or function calls to the checkpoint and logging framework in the existing code. The checkpoint and logging framework may thus provide more general availability of checkpointing and logging in the cluster.

The recovery apparatus may also include a replicating service that transfers the checkpoints and the log entries to the nodes in the cluster. The replicating service may transfer the checkpoints and the log entries to the computing device as a background operation. The replicating service may send the checkpoints and the log entries by broadcasting the checkpoints and the log entries . The replicating service may send the checkpoints and the log entries to only select nodes within the cluster.

The replicating service may also be responsible for receiving checkpoints from other nodes in the cluster and for saving the checkpoints to local storage . The replicating service may further be responsible for receiving log entries from other nodes in the cluster and saving the log entries in the local storage . The replicating service may also notify the event manager when a checkpoint is received and when a log entry is received. The event manager may use this information to provide software version control for the checkpoints and the log entries received by the computing device and stored in the local storage

The cross node communication module provides communications between the nodes in the cluster. The cross node communication module may be part of the cluster module . The cross node communication module may allow the checkpoints and log entries to be passed from one node in the cluster to another.

At some point the computing device may become a failed node in the cluster as represented by the X in . The recovery apparatus may detect the node failure of the computing device . In certain embodiments the recovery apparatus may determine that the computing device has failed and that the computing device is the failover node for the computing device . The recovery apparatus may determine one or more applications that were running on the computing device that need to recover.

In one embodiment the application may have been running on the computing device at the time of the node failure and the application may have been running on the computing device at the time of the node failure. The recovery apparatus may determine that the application should be recovered on the computing device . In one embodiment the recovery apparatus initiates the application on the computing device as part of the recovery process. The recovery apparatus may further cause the application to recover from the external checkpoint for the application that was received from another node in the cluster. The recovery apparatus may further cause the application to further recover from the external log entries in the local storage of the computing device that were received from other nodes in the cluster. The application may continue normal operations once it has recovered from the external checkpoint and the external log entries .

In certain embodiments the recovery apparatus may continue to monitor the status of the computing device . In one embodiment the recovery apparatus performs a failback operation in response to the computing device recovering from the failure. A failback operation refers to the process of restarting the application on the computing device

In one embodiment the recovery apparatus after determining that the computing device has recovered from the node failure sends a checkpoint for the application to the computing device . The recovery apparatus may send a most current checkpoint taken while the application was executing on the computing device after the computing device failed to the computing device . The recovery apparatus may further send log entries for the application generated while the application was executing on the computing device after the failure of computing device . The recovery apparatus may then pass control to a recovery apparatus operating on the computing device

In response the recovery apparatus on the computing device may cause the application executing on the computing device to recover using the application data in the checkpoint and the log entries received from the recovery apparatus . In one embodiment the recovery apparatus may report to the recovery apparatus once the recovery process for the application on the computing device is complete. The recovery apparatus may stop the application in response to receiving the report from the recovery apparatus

The method may also involve sending the checkpoint for storage in the local storage of one or more nodes in the cluster. In one embodiment the checkpoint is sent by a replicating service to other recovery apparatus implemented on the nodes in the cluster. The replicating service may send the checkpoint to the other nodes in the cluster as a background process. An event manager on the nodes may be responsible for maintaining version control of the checkpoints .

The method may also involve generating log entries of changes in the application data for the application that occur between checkpoints of the application data. In certain embodiments log entries are generated when the changed data represented by the log entry is in a consistent state for example a transaction may involve three or more operations that change application data. The log entry representing the transaction may only be generated when the transaction is committed.

The method may also involve sending the log entries for storage in the local storage of one or more nodes in the cluster. In one embodiment the log entries are sent by the replicating service to other recovery apparatus implemented on the nodes in the cluster. The replicating service may send the log entries to the other nodes in the cluster as a background process. An event manager on the nodes may be responsible for maintaining version control of the log entries .

The method may further involve generating a new checkpoint of the application data that is in a consistent state. The recovery apparatus may be configured to cause applications to take checkpoints at certain times. In other embodiments the applications may determine when to generate the checkpoints . In other embodiments a new checkpoint is generated in response to a log of log entries reaching a certain size.

The method may also involve deleting the old log entries whose changes are accounted for in the new checkpoint in response to the new checkpoint being generated. In other embodiments the log entries are archived for the cluster. Deleting the log entries may involve physically erasing the log entries from the storage media in the local storage or simply designating the addresses that store the log entries as free space. The method may continue with sending the new checkpoint and repeating the process as shown in .

In certain embodiments each recovery apparatus on each node broadcasts the checkpoints and the log entries to all other nodes in the cluster. In other embodiments the recovery apparatus may send the checkpoints and the log entries to only select nodes in the cluster. Similarly the recovery apparatus may receive external checkpoints and external log entries from only a subset of the nodes in the cluster.

The recovery apparatus may receive multiple external checkpoints and multiple log entries . The recovery apparatus may be responsible for performing version maintenance operations for the external checkpoints and the multiple log entries . In certain embodiments the recovery apparatus keeps only a most current checkpoint and the log entries that document changes occurring after the most current checkpoint.

The method may also involve determining whether there is a node failure in the cluster. If there is no node failure the method may involve the recovery apparatus continuing to receive external checkpoints and external log entries .

The method may involve in response to a node failure recovering the application running on the failed node using the external checkpoint for the application . The method may also involve further recovering the application running on the failed node using the external log entries for the application . The application may be recovered on a node that is separate from the failed node and be recovered using the external checkpoints and the external log entries received from the failed node.

The method may also involve monitoring the failed node and determining whether the failed node is recovered. The method may involve continuing the monitor the failed node until the failed node is recovered. The method may further involve failing back to the failed node in response to the failed node recovering.

The embodiments may be practiced in other specific forms. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is therefore indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

