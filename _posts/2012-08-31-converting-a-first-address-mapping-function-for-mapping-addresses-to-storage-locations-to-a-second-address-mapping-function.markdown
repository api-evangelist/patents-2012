---

title: Converting a first address mapping function for mapping addresses to storage locations to a second address mapping function
abstract: Provided are a computer program product, system, and method for converting a first address mapping function for mapping addresses to storage locations to a second address mapping function. For each of a plurality of addresses allocated in the storage using the first address mapping function, a node is generated in the second address mapping function. Each node in the second address mapping function associates a logical address with a physical location for the logical address. A determination is made of addresses having unused space and storage space is freed for the determined addresses having the unused space. Indication is made in the second address mapping function that the storage space for the determined addresses has been freed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08943283&OS=08943283&RS=08943283
owner: International Business Machines Corporation
number: 08943283
owner_city: Armonk
owner_country: US
publication_date: 20120831
---
The present invention relates to a computer program product system and method for converting a first address mapping function for mapping addresses to storage locations to a second address mapping function.

In a storage environment logical addresses may be mapped to physical locations of a volume using a fixed formula where all the storage space and logical addresses are allocated in advance and the fixed formula maps the logical address to a physical location. This fixed formula mapping is used for a thick provisioned volume in which all data for the volume is allocated in advance even before the logical addresses are used by an application. In a thin provisioned volume storage space is allocated to a logical address only when the logical addresses are used. In this way logical addresses are not allocated that point to free or unused space unlike in a thick provisioned volume where physical space is pre allocated.

Thin provisioned volumes provide a more space efficient allocation of storage space that is often used in virtual storage systems where storage space is only allocated when needed and space is not wasted by allocating in advance of being used or needed. Thin provisioned volumes may use a B tree to represent logical address to physical address mapping. If a requested logical address is not represented in the B tree then storage space is allocated to the requested logical address and a new leaf node is added to the B tree for the new logical address that identifies the allocated physical storage space. Some B trees might have free space in existing nodes to add mappings so that a new mapping might not always require a new B tree node.

It has been reported that in many thick provisioned volumes on average only 40 45 of the allocated volume is used resulting in a substantial amount of unused physical spaced allocated and not utilized.

Solutions are provided to migrate a thick provisioned volume to the more space efficient thin provisioned volume. Current solutions first scan the thick provisioned volume being migrated for zeros to determine unused space and those regions deemed to have free space are not migrated or written to the target provisioned thin volume. The B tree for the thin provisioned volume is then constructed from the migrated data which excludes free space so in the thin provisioned volume only logical addresses pointing to user data are allocated and free space is not allocated.

There is a need in the art for improved techniques for converting an address mapping function that allocates storage space to logical addresses in advance to an address mapping function that does not allocate the storage space until the logical addresses are used.

Provided are a computer program product system and method for converting a first address mapping function for mapping addresses to storage locations to a second address mapping function. For each of a plurality of addresses allocated in the storage using the first address mapping function a node is generated in the second address mapping function. Each node in the second address mapping function associates a logical address with a physical location for the logical address. A determination is made of addresses having free space and storage space is freed for the determined addresses having the free space. Indication is made in the second address mapping function that the storage space for the determined addresses has been freed.

Prior art solutions that use scanning to determine unused space to migrate from the thick provisioned volume to the thin provisioned volume involve an expensive resource intensive operation to scan the entire volume to identify free unused space. This operation may slow down the migration process and application requests until the scanning operation has completed. Further if unused regions have not been zeroed out then the scanning operation may not be able to detect those regions as having free space.

To address these concerns and others described embodiments provide techniques to change the address mapping scheme used to map logical addresses to physical locations from a first address mapping function which may pre allocate storage space to logical addresses in advance to a second address mapping function which may allocate storage space to logical addresses only when the logical address is needed by an application. With described embodiments after generating a second address mapping function having nodes for all logical addresses allocated according to the first logical mapping function a determination is made of logical addresses having free space by an application using the volume . Commands may then be issued to deallocate those logical addresses addressing free space to return the free space to a free space storage pool and remove the nodes from the second address mapping function for the deallocated logical addresses.

Initially a first address mapping function is used to map logical addresses to physical locations in the storage . In one embodiment the first address mapping function uses a fixed formula to map logical addresses to fixed addresses such that all logical addresses are allocated in the storage in advance before being accessed. This fixed formula may be determined based on the configuration of the underlying volume e.g. stripe Redundant Array of Independent Disks RAID RAID etc. For example if there is a stripe volume created out of three physical disks and the stripe size is 24 MB each disk contains 8 MB of data for a specific stripe. The fixed formal may then map the physical LBA corresponding to start virtual LBA 18 MB to physical disk starting at offset 2 MB on that physical disk. In further embodiments the fixed formal may be more complex depending on the underlying configuration.

The memory further includes an address mapping convertor comprising a program to convert the first address mapping function used to determine storage locations in storage for the logical addresses to a second address mapping function . In certain embodiments the second address mapping function my implement a tree structure such as a B tree data structure where the nodes that map logical addresses to physical locations comprise leaf nodes. In alternative embodiments other tree structures may be used. In certain embodiments the second address mapping function only allocates logical addresses and storage space when they are requested and needed.

The storage controller may maintain a free storage space pool identifying storage space in the storage available for allocation to logical addresses. In this way storage space is not allocated in advance to logical addresses and free storage space is maintained in the free storage space pool available for allocation to logical addresses. When a logical address is added to the second address mapping function when requested for the first time i.e. in response to an access request to the logical address storage space from the free storage space pool may be allocated to the requested logical address. After the address mapping convertor converts the address mapping to the second address mapping function the second address mapping function only includes nodes for logical addresses having user data no nodes for free space and going forward storage space is only allocated to a logical address in response to an access request to the logical address.

The target memory includes a migration program to migrate source volumes to target volumes in the target storage . The migration program may build a target file system for the volume being migrated from the metadata information in the source file system . The target memory further maintains a second address mapping function which has nodes mapping logical addresses to storage where storage is allocated from a free space storage pool of available space in the target storage allocated when a logical address is requested i.e. a thin provisioned volume. In certain embodiments the second address mapping function may comprise a B tree or other tree structure.

The storage controllers may comprise storage controllers and enterprise storage servers known in the art. The storages may each comprise one or more storage devices known in the art such as interconnected storage devices where the storage devices may comprise hard disk drives solid state storage device SSD comprised of solid state electronics such as a EEPROM Electrically Erasable Programmable Read Only Memory flash memory flash disk Random Access Memory RAM drive storage class memory SCM etc. magnetic storage disk optical disk tape etc.

The storages may store tracks in a Redundant Array of Independent Disks RAID configuration where strides of tracks are written across multiple storage devices comprising the storages . Strides comprise tracks written across disks in a RAID rank where a stride of track includes data and parity information calculated form the data in the stride striped across the storage devices. A RAID rank comprises a group of storage devices configured to work as a RAID set such that the stride of tracks including data and parity tracks are striped across the storage devices in the RAID rank. The storages may include one or more configured RAID ranks.

The memories may comprise one or more volatile or non volatile storage devices such as a Dynamic Random Access Memory DRAM Random Access Memory RAM or a non volatile memory e.g. battery backed up Random Access Memory RAM static RAM SRAM solid state storage devices SSDs etc.

The network may comprise a network such as a Local Area Network LAN Storage Area Network SAN Wide Area Network WAN peer to peer network wireless network etc. Further the network may be separated into separate networks between the controllers 

The storages may be connected to their respective storage controllers by a direct line connection or over a network.

The address mapping converter and migration program may be implemented in programs in memory executed by a processor such as shown in . Alternatively the programs and may be implemented in whole or in part with hardware logic such as an Application Specific Integrated Circuit ASIC Field Programmable Gate Array FPGA etc. or firmware in the storage controller 

Further in described embodiments the functionality to convert the address mapping from the first to the second address mapping function may be delivered to the storage controllers by updating firmware and or software in the storage controllers to include the functionality of the programs . In redundant storage controller configurations one controller may be updated first and the other redundant controller updated subsequently to provide a non disruptive upgrade of the address mapping functionality of the storage controllers.

The address mapping converter determines at block addresses in the second address mapping function having free space in the volume . In certain embodiments this may be done by sending a command to the file system requesting a free block list indicating regions of logical addresses having free space. For instance the converter may use an application programming interface API such as return list of free blocks device ID pointer to list of free regions and the returned pointer to list of free regions may specify one or more start logical addresses e.g. logical block addresses LBAs and a byte size or length of the region of free space. In alternative embodiments the logical addresses having free space may be determined from an application other than the file system such as from a database which returns a list of unused records. Other tracking mechanisms may be used to determine logical addresses addressing free space. For instance the International Business Machines Corporation IBM XIV Storage System deploys a WRITE track mechanism for thick provisioned volumes to find regions of the volume that have unused space. XIV and IBM are registered trademarks of International Business Machines Corporation in the United States and other countries .

The address mapping converter frees at block the storage space for the determined address having the free space. In one embodiment the converter may issue space deallocation commands for the determined regions to free the storage space and remove the nodes in the second address mapping function for the determined regions having the free space. For example a space deallocation command such as a Small Computer System SCSI UNMAP and WRITE ZEROS commands may be used to free the space and return the freed space to a free storage pool.

After deallocating space and removing nodes the storage space addressed by the removed nodes is indicated in the free storage space pool where it is available for later allocations to logical addresses requested that are not represented as nodes in the second address mapping function .

The migration program creates at block a node in the second address mapping function for address copied from the source volume indicating the storage location in the target volume where data for the address used in the first address mapping function is stored. Because the source volume had addresses allocated according to the first address mapping function where all logical addresses are allocated in advance i.e. thick provisioned the second address mapping function would have nodes for addresses having user data as well as free space. Further the migration program may construction a file system for the migrated data. This operation of generating the second address mapping function may be performed instantaneously because physical storage of the volume space has already been allocated and each node in the address mapping function may point to a pre allocated region. The result of operation is an initial fully populated second address mapping function for all addresses in the migrated volume such as a fully populated B tree.

The migration program may then determine at block addresses having free space in the volume . In one embodiment the migration program may send a command to a file system requesting a free block list indicating regions of logical addresses having free space such as described with respect to block in . The migration program may free at block storage space for the determined addresses having the free space. The freed storage space may be indicated in the free storage space pool used by the target storage controller to allocate new space to logical addresses. In one embodiment space may be freed by issuing space deallocation commands for the determined regions to free the storage space and remove the nodes in the second address mapping function for the determined regions having the free space such as described with respect to block in .

Using migration to convert a thick provisioned volume in a source storage to a thin provisioned volume may be useful in situations where the source storage controller does not have the capability to generate a second address mapping function e.g. B tree that only allocates storage space to logical addresses when the logical address is requested by an application. Further the migration operation may also be suitable when the source storage controller does not support space deallocation APIs to deallocate space for logical addresses pointing to unused data and return to a free storage space.

Described embodiments provide techniques for converting the address mapping function used by a volume from a fixed formula type allocation where all logical addresses in the volume are allocated in advance to an address mapping that only allocates logical addresses and storage space when needed.

Described embodiments build a second address mapping function such as a tree of nodes to represent the volume mapped according to the second address mapping function and then issues commands to free logical addresses addressing free storage space. In this way the resulting second address mapping function only has nodes for logical addresses pointing to used data so that any storage having free space is deallocated and returned to an available space storage pool.

With the described embodiments a thick provisioned volume may be converted to a thin provisioned volume where free space is freed resulting in a substantial amount of storage space being made available. Freed storage space may be returned to a free storage pool used by the storage controller to assign storage space to newly provisioned logical addresses. Further the conversion process is almost instantaneous because the second address mapping function is created from the pre allocated volume to be fully populated.

The described operations may be implemented as a method apparatus or computer program product using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof. Accordingly aspects of the embodiments may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the embodiments may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described above with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The terms an embodiment embodiment embodiments the embodiment the embodiments one or more embodiments some embodiments and one embodiment mean one or more but not all embodiments of the present invention s unless expressly specified otherwise.

The terms including comprising having and variations thereof mean including but not limited to unless expressly specified otherwise.

The enumerated listing of items does not imply that any or all of the items are mutually exclusive unless expressly specified otherwise.

Devices that are in communication with each other need not be in continuous communication with each other unless expressly specified otherwise. In addition devices that are in communication with each other may communicate directly or indirectly through one or more intermediaries.

A description of an embodiment with several components in communication with each other does not imply that all such components are required. On the contrary a variety of optional components are described to illustrate the wide variety of possible embodiments of the present invention.

Further although process steps method steps algorithms or the like may be described in a sequential order such processes methods and algorithms may be configured to work in alternate orders. In other words any sequence or order of steps that may be described does not necessarily indicate a requirement that the steps be performed in that order. The steps of processes described herein may be performed in any order practical. Further some steps may be performed simultaneously.

When a single device or article is described herein it will be readily apparent that more than one device article whether or not they cooperate may be used in place of a single device article. Similarly where more than one device or article is described herein whether or not they cooperate it will be readily apparent that a single device article may be used in place of the more than one device or article or a different number of devices articles may be used instead of the shown number of devices or programs. The functionality and or the features of a device may be alternatively embodied by one or more other devices which are not explicitly described as having such functionality features. Thus other embodiments of the present invention need not include the device itself.

The illustrated operations of the figures show certain events occurring in a certain order. In alternative embodiments certain operations may be performed in a different order modified or removed. Moreover steps may be added to the above described logic and still conform to the described embodiments. Further operations described herein may occur sequentially or certain operations may be processed in parallel. Yet further operations may be performed by a single processing unit or by distributed processing units.

The foregoing description of various embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto. The above specification examples and data provide a complete description of the manufacture and use of the composition of the invention. Since many embodiments of the invention can be made without departing from the spirit and scope of the invention the invention resides in the claims herein after appended.

