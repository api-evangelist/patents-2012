---

title: Integrated cross-tester analysis and real-time adaptive test
abstract: Processing test results from a plurality of individual semiconductor testers by analyzing each test result at an adaptive test engine. A centralized system jointly analyzes all the test results from the plurality of individual semiconductor testers. The adaptive test engine or the centralized system identifies, based on the analysis of each test result or the joint analysis of all the test results, one or more of: a test environmental issue, a tester variability issue, a tester calibration issue, a product variability issue, and a manufacturing process variability issue. The adaptive test engine or the centralized system determines whether one or more of the plurality of individual semiconductor testers causes one or more of the identified issues or whether semiconductor products tested by the plurality of individual semiconductor testers causes one or more of the identified issues.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08862424&OS=08862424&RS=08862424
owner: International Business Machines Corporation
number: 08862424
owner_city: Armonk
owner_country: US
publication_date: 20120905
---
This application is a continuation of U.S. patent application Ser. No. 12 871 429 filed Aug. 30 2010 the entire content and disclosure of which is incorporated herein by reference.

The present invention generally relates to testing at least one semiconductor product. More particularly the present invention relates to analyzing test results of at least one semiconductor product.

A semiconductor product includes but is not limited to a semiconductor chip a semiconductor wafer and a semiconductor wafer lot. An individual semiconductor tester includes but is not limited to an Automatic Test Equipment ATE station. An ATE station refers to any automated device that is used to test printed circuit boards semiconductor wafers semiconductor chips integrated circuits ICs or any other electronic components. Agilent Medalist i1000D Agilent Medalist i3070 Teradyne Catalyst Teradyne Tiger Teradyne FLEX and Teradyne UltraFLEX are examples of commercially available ATE stations.

An ATE station requires an active monitoring to ensure that the tester ATE station and or a test program i.e. a software program directing the tester are operating under proper conditions. These conditions involve appropriate control of mechanical physical electrical programmatic and environmental aspects. Some examples of these conditions include a proper calibration of the tester probe instrument cleanliness and alignment proper test limits and test parameters applied during the testing and proper environment temperature settings. The probe instrument is part of the device interface board DIB that is used to connect the semiconductor device under test DUT to the tester. For example a tester s pin parametric measuring units need the probes to be in proper condition to properly measure electrical characteristics. Control and monitoring problems encountered in the testing lead to wasted resources including but not limited to a semiconductor product loss an increased test time increased labor hours i.e. increased labor cost overly stressed equipment augmented schedules improperly tested devices and increased cost.

Therefore it is highly desirable that the testing is properly operated monitored and controlled either manually by operators or automatically using systems for Statistical Process Control SPC and Adaptive Test.

The present invention describes a system and computer program product for processing test results from a plurality of individual semiconductor testers to properly operate monitor and control the testers by using the SPC and Adaptive Test.

In one embodiment there is provided a computer implemented system for processing test results from a plurality of individual semiconductor testers for testing a semiconductor product. The system receives the test results from the plurality of individual semiconductor testers. At least one local adaptive test engines analyzes each test result at a local adaptive test engine corresponding to an individual semiconductor tester. A centralized system jointly analyzes a plurality of the test results from the plurality of individual semiconductor testers. The local adaptive test engine and or the centralized system identifies based on the analysis of each test result or the joint analysis of all the test results one or more of a test environmental issue a tester variability issue a tester calibration issue a product variability issue and a manufacturing process variability issue. The centralized system and or local adaptive test engine determines a cause of the one or more of the identified issues.

In a further embodiment the test environmental issue is one or more of a hardware issue an electrical issue a mechanical issue and a maintenance issue.

In a further embodiment the system determines the cause by comparing the test results of the semiconductor product tested across the individual semiconductor testers.

In a further embodiment the system changes a testing schedule of the semiconductor products on said each individual semiconductor tester according to the determined cause.

The SPC refers to using statistical methods to measure and analyze variations in processes e.g. a testing process or a manufacturing process . The SPC involves real time monitoring and analysis of a testing to detect outliers and anomalies and to build statistical models for a predictive control of the testing. The predictive control refers to computing future behaviors according to a model of data e.g. test results . Aspen Real Time Statistical Process Control Analyzer is one type of commercially available product performing the SPC. Sherry F. Lee et al. RTSPC A Software Utility for Real Time SPC and Tool Data Analysis IEEE Transaction on Semiconductor Manufacturing February 1995 wholly incorporated by reference as if set forth herein also describes software performing the SPC in real time. The Adaptive Test refers to a methodology for adapting a tester to characteristics of a product under the testing based on real time test results and modeling of historical data e.g. past test results . The Adaptive Test involves a dynamic adaptation of the testing in order to minimize time to detect faults save test time and improve product quality and yield. Methods for the Adaptive Test include but not limited to a test flow sequence manipulation a test control limit adaptation and using statistics to dispose i.e. prepare the product appropriately. Mihai G. Satovici et al. Self Adaptive Test Program U.S. Pat. No. 6 167 545 wholly incorporated by reference as if set forth herein describes software performing the Adaptive Test.

The test flow sequence manipulation can be achieved in ways such as removing tests from a test flow based on fail statistics a test pattern reduction i.e. removing testing patterns based on fail statistics a test pattern redundancy or a testing cost adaptive test scheduling i.e. changing an order in which tests are applied based on the fail statistics and predictive control and adding additional tests for a characterization of semiconductor products being tested or for further testing the semiconductor products that have electrical properties that could indicate reliabilities of the semiconductor products.

Test control limit adaptation refers to adjusting control values i.e. parameter values used for controlling of testers based on current data i.e. test results that are obtained from testers in real time . The control values are usually parametric measurements i.e. outputs obtained from specific pins of the testers or ATEs via PPMUs Pin Parametric Measurement Units as a result of applying some electrical signal inputs into semiconductor products under a test and can vary from a wafer to a wafer and from a wafer region to a wafer region. Test limits i.e. thresholds that are considered while conducting the test may also be adapted to the semiconductor products under the test as long as the test limits do not violate customer specifications.

Sorting binning and dispositioning are processes of specifying a condition of the individual semiconductor chip tested. Dispositioning is a process of specifying a condition of a semiconductor wafer wafer lot i.e. a set of wafers or module lot i.e. a set of modules and may affect how a wafer or wafer lot proceeds in a semiconductor manufacturing process. A disposition result may be obtained during a test or during a post test analysis by applying a set of algorithms e.g. SPC and or Adaptive Test and rules to any pertinent data associated with the semiconductor product under test such as raw test data sorts and manufacturing data. Post test statistical analysis may result in a change of any individual semiconductor chip s sort bin defined during test e.g. the statistical analysis finds irregularities in a semiconductor chip s data and its test result bin is changed from pass to fail . Disposition results determine follow on actions including but not limited to fail a chip hold a wafer retest a wafer hold a wafer or module lot or move a wafer or module lot to a next operation. Semiconductor products put on a hold for a further review may eventually be scrapped discarded .

The Adaptive Test may further involve an adaptation i.e. adapting a tester to characteristics of a product under the test at different time granularities e.g. milliseconds per a semiconductor chip for an adaptation versus hours days for an adaptation across a semiconductor wafer etc. . Both the SPC and the Adaptive Test include a feedforward and feedback control for monitoring analyzing and or modifying a test.

According to one embodiment of the present invention a computing system e.g. a computing system in performs an integrated analysis of the parametric measurements and the test results from multiple testers to dynamically drive the Adaptive Test in real time. The computing system receives a data stream including test results from a plurality of testers in the same or different locations performs statistical analyses on the data stream and feeds back results of the analyses to the testers to run the Adaptive Test. The receiving performing and feeding are done in real time.

A test floor includes a plurality of testers testing semiconductor products e.g. semiconductor wafers and semiconductor chips in parallel. These testers may be distributed in multiple locations and may have different environmental and physical conditions e.g. different temperatures . There are several characteristics of tests i.e. tests done by the testers that are similar across the testers depending on types of the products under the tests. The computing system analyzes test results from the plurality of testers jointly to identify a test environmental issue a tester variability issue a tester calibration issue a product variability issue and a manufacturing process variability issue etc. These issues are described in detail below. Furthermore the computing system uses results of the analysis to run the Adaptive Test on each individual tester.

The local adaptive test engine includes but is not limited to the source connect data parsing unit an analytics unit a decision logic unit and a sink connect unit . The source connection data parsing unit receives parses and formats data i.e. test results from the test cell for various statistical analyses which may be industry standards. The analytics unit performs the statistical analyses on the test results. The statistical analyses includes but is not limited to mutual information over time descriptive statistics causal models classification and regression trees cost sensitive learning ridge lasso elastic net correlation coefficient hypothesis tests including Student s T test i.e. a test assessing whether the means of two groups are statistically different each other predictive tracking filters e.g. Kalman Filters Correlations and Time Series Clustering.

The mutual information refers to an information theory measuring a relationship between two different distributions. Descriptive statistics or hypothesis testing refers statistical characterizations or tests to detect differences in data distributions including tests for differences in means. A causal model includes an Engle Granger regression method which is an approach selecting an arbitrary normalization and regressing a variable over others. Classification and regression trees include a binary space partitioning methods which recursively performs hierarchical partitioning or subdivision of a n dimensional space into subspaces. Cost sensitive learning addresses prediction tasks for which penalties associated with prediction errors depend on a nature of the errors. Ridge lasso and elastic network is a linear modeling technique that allows rapid evaluation and inclusion of large numbers e.g. thousands or millions of correlated variables. Kalman filter is a recursive filter that estimates a state of a linear system forming a series of noise measurements. Correlations represent a strength or direction of a linear relationship between two random variables. Time Series Clustering refers to classifying or grouping a times series i.e. a sequence of data measured at successive and uniform time intervals .

Once the analytics unit completes one more of the statistical analyses the analytics unit provides results of the analyses called summary statistics to the decision logic unit . Upon receiving the summary statistics the decision logic unit determines what action should be taken under the test results. The action to be taken includes but is not limited to changing a testing schedule i.e. a sequence of tests on the testers changing hardware or software in one or more testers shutting down one or more testers stopping one or more tests and changing test limits on one or more tests. The action to be taken is provided from the decision logic as control instructions or commands to the tool control unit through the sink connection unit which is an interface e.g. API of the local adaptive test engine e.g. by utilizing an electronic messaging method e.g. an email instant messaging electronic alert packet messaging etc. . Then the tester performs the action. The decision logic unit may also initiate its own actions such as changing or modifying tests changing control limits or sending alerts etc.

Instead of limiting actions at the local adaptive test engines the centralized system obtains test results from all the test cells and integrates and analyzes these test results to identify irregularities on the test floor and or to understand anomalies in the semiconductor products tested in the test cells . In this embodiment the analytic module in the centralized system performs the statistical analyses on the integrated test results. Based on results of the statistical analyses the decision logic module in the centralized system determines one or more actions. These actions may be specific to a particular test cell and or local adaptive test engine. Alternatively these actions are applied to all the test cells and or local adaptive engines . Examples of these actions are described above. The centralized system communicates with one or more of the test cells and or one or more of the local adaptive test engines through the communication network e.g. Internet Wi Fi Intranet LAN WAN wireless LAN satellite communication etc. .

The centralized system applies the determined actions to one or more of the local adaptive test engines in real time. The centralized system also applies the determined actions to one or more of the test cells in real time. The centralized system may store the determined actions as history data to the data warehouse for future purpose e.g. future tests . The application of the determined action to the one or more of test cells may cause a change in a testing schedule of the semiconductor products being tested or to be tested on the test cells .

In another embodiment the local adaptive test engines analyze data streams including the test results from the test cells e.g. by running at least one local analytic algorithm e.g. Time Series Clustering described above specific to a particular test cell. The at least one algorithm performs statistical analyses on the data streams in conjunction with historical data e.g. the number of semiconductor products tested trace data i.e. data obtained during manufacturing from manufacturing tools obtained from a data warehouse to identify an optimal schedule of tests. A commonly assigned application Johnson et al Optimal test flow scheduling within automated test equipment for minimized mean time to detect failure U.S. Pat. No. 12 784 142 wholly incorporated by reference as if fully set forth herein describes the identifying the optimal test schedule of tests in detail. After these local adaptive test engines complete the statistical analyses on the data streams the centralized system also analyzes the data streams jointly through a set of analytic algorithms e.g. the Kalman filter the Student s T test etc. to identify one or more of the test environmental issue the tester variability issue the tester calibration issue the product liability issue and the manufacturing process variability issue. These issues and how to identify these issues are described in detail below.

Then the centralized system determines a cause s of these issues e.g. by comparing test results from a same semiconductor product across the test cells . This comparison leads to the determination of whether a particular test cell causes one or more of these issues or whether the particular semiconductor product causes one or more of these issues. Thus the centralized system can determine whether one or more of the test cells cause one or more of these issues and or whether a particular semiconductor product tested by the one or more of test cells causes one or more of these issues. For example if a plurality of test cells shows a particular issue then the centralized system decides that the particular semiconductor product tested by the test cells causes the particular issue. If only a particular test cell shows a certain issue then the centralized system decides that the particular test cell causes the certain issue.

In one embodiment the centralized system is implemented as a computing system e.g. a computing system in . In an alternative embodiment the centralized system is implemented as a distributed computing system i.e. multiple computers that communicate through a network .

The test environmental issue includes but not limited to a hardware issue an electrical issue a mechanical issue and a maintenance issue. The hardware issue is detectable e.g. by performing the analyses in the local adaptive test engines and or the joint analyses e.g. integrating or compiling test results from a same semiconductor product across the test cells and then performing statistical analyses the integrated or compiled the test results in the centralized system . For example consider that test hardware is interchangeable for any given product. In this example transformers and or probe head are interchangeable between testers. A transformer converts and directs tester channels e.g. power sources test pins control pins etc. to appropriate probe pins that are contacted to correct product pins e.g. correct pins on a semiconductor chip or module . The probe pins are grouped in a probe card or probe head. Each semiconductor product has multiple or many copies of the transformer and probe head and they are all designed to be interchangeable such that there can be many combinations of a tester a transformer and a probe card that need to be examined for possible hardware issues. Because these three hardware components the tester the transformer and the probe head can be mixed or interchanged the centralized system performs the joint analyses to identify which combinations of these hardware components lead to the worst test result s and then further identify which hardware component is common to these combinations. The centralized system may recommend what combinations to use. The joint analyses also identify a specific pin failure on a semiconductor product that has been tested by the test cells each of which may conduct each different or same test. The test conducted by the test cells includes but not limited to measuring leakage current inspecting open and or short circuits measuring speed of the semiconductor product measuring power consumption of the semiconductor product etc.

The centralized system or one or more of the local adaptive test engines identifies the electrical issues including but not limited to unstable power supplies and temperature control units e.g. by analyzing electrical parameters e.g. voltages thermal resistance etc. through a scan a core test a performance sort ring oscillator PSRO a logic test that captures at least one clock signal on the semiconductor product that is currently or already tested or other tests that measure a current drain voltage drain or power drain on the power supplies. The scan is a process of loading the semiconductor product with data as synchronized with a clock signal. The core test evaluates a functional logic e.g. PLL Phase Locked Loop or DLL Delayed Locked Loop of the semiconductor product. The PSRO includes electric circuits designed based on a physical technology e.g. CMOS 45 nm technology of the semiconductor product. These electric circuits in the PSRO count oscillation cycles of a signal e.g. a clock signal to determine a speed of the signal in a particular area. These electric circuits may be spread throughout the semiconductor product.

The centralized system or one or more of the local adaptive test engines identifies the mechanical issue e.g. an unstable compressor by testing a physical module e.g. the semiconductor module or performing a wafer test i.e. testing all individual integrated circuits presented on the wafer to detect functional defects by applying test patterns to the circuits . The mechanical issue results in an improper or unbalanced contact between the probe pins and semiconductor chip pads. The mechanical issue can also damage the probe pins causing the electrical issues as further tests pass.

The centralized system or one or more of the local adaptive test engines also identify the maintenance issue e.g. a lack of coolant in a cooling system . The coolant keeps the test floor e.g. test floor or at a specific temperature and also keeps a semiconductor product under a test at a specific temperature. When the coolant runs low a large number of semiconductor products elevate their temperatures. However a manufacturing process variation e.g. process or temperature variation in polysilicon deposited in the semiconductor product in a FAB can also cause the temperature elevation in the semiconductor product. Therefore the centralized system verifies whether the temperature elevation is due to the semiconductor itself or due to the testers e.g. by performing the joint analyses.

The tester calibration issue includes but not limited to a skew in pin signal delays from a DUT Device under test to a tester and vice versa. A length of each path from a tester electronic to a semiconductor chip pin varies based on wiring in the tester and a device interface board DIB including at least one transformer and probe head . Signal propagation delays for each path are measured and then compensated for within the tester electronic to insure timing on all the signals to and from the DUT arrive precisely relative to each other. Therefore it is possible for tests specifically high speed tests to fail if any given clock pin or data pin has not been calibrated for an excessive delay path. The centralized system or one or more of the local adaptive test engines may detect that a tester is showing a large number high speed logical fails while the contact PSRO and PLL measurements are fine. Therefore the centralized system may determine a tester needs to be calibrated for pin signal propagation delay.

A tester software issue includes but not limited to corrupted or incorrect PNPs Part Number Programs in one or more testers. The centralized system or one or more of the local adaptive test engines monitors Part Number Programs PNPs loaded on each tester. Incorrect or corrupted PNPs may be loaded on a tester. In a traditional system PNP issues may not be detected until a large number e.g. a million of semiconductor products have been tested. According to one embodiment of the present invention the centralized system performs the joint analyses on a list of tests and test limits that are being used across the test floor to determine if a tester is running what is expected.

The centralized system or one or more of the local adaptive test engines determines variability e.g. uneven qualities in semiconductor products being tested or already tested across the test cells e.g. by predictive modeling the correlation or a transfer of learning. The predictive modeling is a process by which a model is created or chosen to try to predict a probability of an outcome. The transfer of learning refers to an application of skills knowledge or experiences that gained in one situation to another situation. A user e.g. an engineer may use the determined variability for a semiconductor technology transition e.g. moving from CMOS 65 nm technology to CMOS 45 nm technology within a same semiconductor product family. For example assume that a user currently uses 65 nm technology and plans to bring up 45 nm technology. Further assume that machine used for manufacturing semiconductor products under 45 nm technology is being tested with identical test programs but requires some adjustments with parametric limits. These parametric limits are test control or specification limits or other trigger limits established by at least one engineer. The limits refer to thresholds maximum values or minimum values that are given numerical values. In this example the joint analyses can be used adaptively and test specifications e.g. documents that describe how to implement test s can be defined based on differences in test results of the two technologies. The centralized system can also concurrently analyze test results from diverse semiconductor products even if these diverse semiconductor products use a same semiconductor technology to evaluate electrical properties of these diverse products to determine if common semiconductor material used in these diverse products is behaving correctly e.g. by running a stream computing middleware on the centralized system .

By processing test results from the test cells the centralized system detects manufacturing process variability issues. The centralized system detects these process variability issues and indentify underlying root causes of the process variability e.g. by correlating the test results with data streams from inline tests. The data streams from inline tests refer to test data obtained semiconductor manufacturing stages processes and or trace data from semiconductor manufacturing tools and the summary statistics. The centralized system can also detect these process variability issues e.g. by tracking the statistic summaries or running a change detection algorithm. The change detection algorithm refers to a statistical analysis algorithm that identifies a change or anomaly in a process or distribution. The change algorithm may filter out anomalies that are random and identify anomalies that have a systematic nature e.g. anomalies related to semiconductor testing tools .

Diverse variations of applications and architecture of can be made. These variations include but not limited to 

According to one embodiment the centralized system and or one or more of the local adaptive test engines includes IBM s stream computing middleware System S. The System S is described in detail in System S Stream Computing at IBM Research IBM 2008 http www 01.ibm.com software sw library en US detail R924335M43279V91.html wholly incorporated by reference as if set forth herein. The system S provides support for both several types of extensible stream data analytics as well as infrastructure mechanisms for collecting and parsing data streams from diverse sources distributing monitoring and managing analytics across distributed computing resources and their associated communications as well as dealing with issues such as load balancing and failure resilience. The failure resilience of System S is that if the System S hangs or shuts down the System S is capable of coming back and resuming operations where it left off with little difficulty. Alternatively if input data itself is irregular System S can quickly handle or flush the input data to resume normal analysis function. The system S also provides support for multiple users e.g. test engineers to dynamically modify and incrementally deploy different types of analyses based on observations.

At step a tester in a test cell sends data i.e. the test results and or test instances for each test to a corresponding local adaptive test engine. A test instance refers to all the defined features of a test. At step the local adaptive test engine begins by identifying the test and retrieving all control information e.g. information describing how the test is conducted and what the limits are for that test. The control information includes at least the control limits for the test. After step the control goes from steps to step . At step the local adaptive test engine stores that data until the minimum number of results for a single test are available user defines the minimum sample size . Upon having minimum sample of test results for any specific test at step the local adaptive test engine performs statistical analyses on the data . Based on the analyses of step step determines if the specific test s control limits should be changed to new control limits for the semiconductor product being tested. If not at step no action is taken at that time. If the control limits for the specific test are changed at step the new limits are created and made available for an application e.g. a tester . At steps the test result is compared to the new control limits to determine if a limit is exceeded. If the limit or threshold is not exceeded at step no action is taken. If a limit is exceeded at step outlier data is sent to the centralized system for a further analysis.

Results from analytics in step are also used to determine whether the test limits of the test i.e. test result or test instance should be adapted to the current product under the test e.g. after evaluating a minimum sample size of test data it is determined the test limits should be tighter to improve the quality of chips binned as good . If the test limits of the test needs not be adapted to the current product under the test at step no action is taken on the semiconductor product. Otherwise the test limits of the test are adapted to the current product under the test and the control goes to step .

Before the centralized system acts on data from step specific rules of engagement must be met at step . These rules include any conditions that must be met before the centralized system performs any analysis. The rules are defined by a user and at least includes without limitation 1 a criteria that identifies when the joint analyses is beneficial and will be performed e.g. a very large number of outlier measures are being detected and 2 there is correlation data available from other testers on any accessible test floor with the same test cell configurations. The correlation data includes but is not limited to semiconductor chip test data of the same product being concurrently tested different wafers or modules of the same product or having been recently tested could be the same wafers or modules or different wafers or modules of the same product on other testers to compare test results any semiconductor chip test data from the same tester cell configuration from which correlations and be extrapolated e.g. evaluate pin fails as a correlation to tester channel fails across multiple testers and products test environment conditions e.g. mechanical operation metrics such as temperature control calibration information hardware repair information etc. .

Steps perform a similar process as described for steps except the test data is now pulled from multiple testers to be accumulated and joined for analysis. The test data may be tagged with the product code. Therefore when concurrent test data is needed the centralized system can quickly identify which testers are testing the same product or whether recently tested product is readily available in a data warehouse.

In one embodiment each tester e.g. a tester tester tester tester N has a unique identification. Test results generated by a tester may include the tester s identification and information of tests conducted. Thus the centralized system identifies a particular tester that detects the outliers and particular tests performed by the particular tester based on the test results. At step the centralized system may further accumulate the test results for one or more specific tests from a local adaptive test engine or a tester before running the joint analyses. At step the centralized system performs the joint analyses e.g. by comparing specific test results from the tester in question to test results from the same test collected at other testers. For example the centralized system compares test results of a test A from a tester to test results of the test A from other testers testers .

If the centralized system finds that a semiconductor product tested on a specific tester has anomalies in any test results or test environment conditions as compared to other testers that indicate a tester cell issue at steps the centralized system initiates an alert and an action for the specific tester e.g. if the thermal measure on product on one tester is consistently elevated compared to other testers the proper personnel are notified and the tester is stopped until corrective action is taken . If the centralized system finds that the product has a similar characteristic across all the testers at steps and the centralized system may determine that the product has experienced an overall electrical shift based on a variation in the fabrication process. The test results of the product may be flagged. That process shift may be minor i.e. a minor process shift which does not affect performance of the product or major i.e. a major process shift which affects the performance of the product . If the process shift is major at steps and the centralized system initiates an alert for the product according to a rule or standard e.g. X out of N samples exceed a specific limit for initiating an alert. If the shift is minor steps the centralized system may change the control limits to prevent these alerts from reoccurring and also change the test limits to better accommodate the product. In one embodiment at the centralized system evaluates whether a control limit change should be applied and at to what extent i.e. globally all testers for this product only specific testers from or no change . At step the centralized system chooses which testers should use the changed control limits. At step the centralized system reports the changed or tightened test limits to the chosen testers for updating the control limits applied at step .

At step the centralized system evaluates whether the test limits are set according to customer specification. If the test limit is not a customer specification e.g. test limit based on product characterization at step the centralized system adjusts the test limits based on summary statistics obtained from the analyses. Otherwise at step the centralized system may only tighten the test limits within the customer s specification. If the test limits should not be tightened at step no change is made. At step the centralized system chooses which testers should use the adjusted or tightened test limits. At step the centralized system reports the adjusted or tightened test limits to the chosen testers for updating their test limits.

In one embodiment the method step in is implemented in hardware or reconfigurable hardware e.g. FPGA Field Programmable Gate Array or CPLD Complex Programmable Logic Device using a hardware description language Verilog VHDL Handel C or System C . In another embodiment the method step in is implemented in a semiconductor chip e.g. ASIC Application Specific Integrated Circuit using a semi custom design methodology i.e. designing a chip using standard cells and a hardware description language. Thus the hardware reconfigurable hardware or the semiconductor chip operates the method steps described in . In a further embodiment one or more of the test cells is implemented in hardware e.g. FPGA CPLD or ASIC. One or more of the local adaptive test engines is implemented in hardware e.g. FPGA CPLD or ASIC. The centralized system is also implemented in hardware e.g. FPGA CPLD or ASIC.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with a system apparatus or device running an instruction.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with a system apparatus or device running an instruction.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may run entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which run via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks. These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which run on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more operable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be run substantially concurrently or the blocks may sometimes be run in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

