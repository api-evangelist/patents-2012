---

title: Interactive media streaming
abstract: A live rendering system can execute a process of buffering received data at the client to avoid needing to transfer the same data multiple times. If the client does not have data available for a wanted playback position (either compressed or decoded) then this data needs to be transferred from the server, including any overlaps needed for producing a continuous stream. The client stores the data in the event that it is needed again, but can discard the data if it receives notice that the stream content has changed. The buffering process can operate with a first priority to buffer data ahead of a currently selected playback position which is the most likely to be needed next, to minimize any delay or pauses in playback if needed data has not yet arrived. The download can be managed to preserve the known good part of decoded data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08745259&OS=08745259&RS=08745259
owner: Ujam Inc.
number: 08745259
owner_city: Dover
owner_country: US
publication_date: 20120802
---
The present invention relates to technology for computer based streaming of media data which can be used in a live rendering destination.

One use of networks like the Internet involves delivering media data such as audio and video from a server to a client where the client can render the data for playback including live rendering as the data is streamed. In some settings the client and server are configured to send an encoded media stream from the server to the client with transport controls play pause position etc. so the user can play any part of the stream with minimal delay.

The stream may be pre existing e.g. a file on disk generated in real time e.g. video from a live event or generated as needed e.g. the stream contents are generated based on user interaction and parts of the stream may never be generated if the client does not request them . Normally the data will be encoded e.g. MP3 for audio H.264 for video to reduce the total amount of data that needs to be transferred with a corresponding decoding required for playback.

One possible approach would be to send data for the whole stream in advance to the client. Playback is then handled completely by the client so can be very responsive but there is a long initial delay latency while the whole stream is sent and another long delay if the stream contents change and need to be sent again.

Another possible approach is to send data only when needed for playback. If the transport position changes the server can send stream data starting at that position to the client sending more as needed as the playback position advances. This is how video streaming on the web commonly works. Storage requirements on the client side are minimized but there is a short buffering delay before playback can start at a new position and potentially the same data is sent multiple times if the user wants to play part of the stream repeatedly.

A web browser may have limited facilities for handling and decoding compressed stream data for example a decoder may only be able to decode a complete media stream rather than the parts of a stream that have arrived at the client so far. The decoder may also corrupt the start or end of the stream add or remove part of the length and apply a time offset and or time scaling to the decoded data.

In interactive environments situations occur where parts of the stream are likely to be repeated and where the contents of the stream may change. Treating the limited facilities for decoding compressed stream data on the client side as a black box as can be a practical requirement for Internet based streaming systems may introduce a variety of unwanted effects.

Taking the example of MP3 encoded audio nominally 1152 uncompressed audio signal samples are compressed to 1 encoded frame of MP3 data. Encoded frames of MP3 data are sent to the client and decoded back to audio data. However individual frames cannot be decoded successfully without the context of the surrounding frames.

Consider an audio stream where the first 11520 audio samples are compressed to 10 MP3 frames which are transferred to the client and passed to the black box MP3 decoder. The decoder outputs 11600 samples of audio data instead of the expected 11520. What has happened Typically the start of the audio data will be silent as there was no previous input context for the decoder and some internal buffering needs to take place before output can be produced there may be a short fade in at the start of the data a short fade out at the end maybe followed by some more silence. Perhaps because of the wanted 11520 samples of audio only samples to have been decoded correctly and are available from frame onwards in the decoded data. The exact lengths of fades and silences will depend on the implementation of the decoder and may also produce different results for the same audio data compressed by different encoders. While the resulting decoded data may have an offset in time relative to the original usually negligible for the purposes of playback positioning for any reasonable decoder this offset will be constant for a given input stream.

So a live streaming configuration may not be able to correctly account for variations in the decoding performance of the wide variety of decoders used in the network when it treats the decoders as a black box. 

It is desirable to provide an efficient and flexible scheme for streaming and buffering media data in an interactive environment.

Technologies are described here for streaming media data in interactive environments such as a live rendering environment where a user can randomly select start points in a media data and move around during playback.

Live rendering can be supported by a process in which the server sends optionally overlapping sections of stream data to the client which can optionally pre pend previously received stream data and pass the stream data to the black box decoder. The client can take the section or sections of decoded data known to be good and merge them to form a continuous stream of decoded media data. The good section can be taken as the known worst case minimum the worst case for the particular client web browser and operating system or can be measured by decoding a known media stream for example a continuous tone and increasing the amount of overlap of blocks of encoded data while increasing the amount of decoded data discarded until properties of the decoded stream e.g. amplitude envelope match the known stream or match a wanted criteria e.g. constant within a margin of error .

Also a live rendering system can execute a process of buffering received data at the client to avoid needing to transfer the same data multiple times. If the client does not have data available for a wanted playback position either compressed or decoded then this data needs to be transferred from the server including any overlaps needed for producing a continuous stream. The client stores the data in case it is needed again but can discard the data if it receives notice that the stream content has changed. The buffering process can operate with a first priority to buffer data ahead of a currently selected playback position which is the most likely to be needed next to minimize any delay or pauses in playback if needed data has not yet arrived. When a sufficient amount of data is buffered ahead of the playback position and the client has storage space available additional stream data can be transferred from the server and buffered. This can happen in the background whether playback is running or not. The best parts of the stream to buffer are those most likely to be played the start of the stream any previous playback start positions and the start of any marked region such as a region that will be played continuously in a loop.

Management of buffered data can be implemented using a data structure such as a binary tree where initially there is one node representing playback of the whole stream. In a binary tree example selecting a new playback startpoint creates two child nodes of an existing node splitting the parent node s playback range into the part before and the part after the new startpoint. Stream data is buffered for each node in turn and when all the stream data for two child nodes has been collected they can be removed and the buffered data associated with the parent node. An alternative data structure would be a linked list of startpoints where adjacent startpoints can be merged when all the stream data between those points has been buffered.

Other aspects of the technology described herein can be understood from review of the drawings the detailed description and the claims which follow.

User interface input devices may include a keyboard pointing devices such as a mouse trackball touchpad or graphics tablet a scanner a touchscreen incorporated into the display audio input devices such as voice recognition systems microphones and other types of input devices. In general use of the term input device is intended to include possible types of devices and ways to input information into computer system or onto communication network .

User interface output devices may include a display subsystem a printer a fax machine or non visual displays such as audio output devices. The display subsystem may include a cathode ray tube CRT a flat panel device such as a liquid crystal display LCD a projection device or some other mechanism for creating a visible image. The display subsystem may also provide a non visual display such as via audio output devices. In general use of the term output device is intended to include all possible types of devices and ways to output information from computer system to the user or to another machine or computer system.

Storage subsystem includes memory accessible by the processor or processors and by other servers arranged to cooperate with the system . The storage subsystem stores programming and data constructs that provide the functionality of processes described with reference to including server management modules and other functions supporting streaming of media data such as an audio processor a video processor and an encoder like an MP3 encoder and an H.264 encoder. In some embodiments a media library including audio and video data which may be encoded in advance may be included to act as a source of media data. Also in some embodiments the storage subsystem stores web pages with scripts and other resources and links to scripts and other resources that can be delivered to clients via the network interface .

Storage subsystem may also include other programs and data utilized in audio and or visual media processing environments such as automated music composition and editing technologies.

The software modules stored in the storage subsystem are generally executed by processor alone or in combination with other processors in the computer system or distributed among other servers in a cloud based system.

Memory used in the storage subsystem can include a number of memories arranged in a memory subsystem including a main random access memory RAM for storage of instructions and data during program execution and a read only memory ROM in which fixed instructions are stored. A file storage subsystem can provide persistent storage for program and data files and may include a hard disk drive a floppy disk drive along with associated removable media a CD ROM drive an optical drive or removable media cartridges. The modules implementing the functionality of certain embodiments may be stored by a file storage subsystem in the storage subsystem or in other machines accessible by the processor.

Bus subsystem provides a mechanism for letting the various components and subsystems of computer system communicate with each other as intended. Although bus subsystem is shown schematically as a single bus alternative embodiments of the bus subsystem may use multiple busses. Many other configurations of computer system are possible having more or less components than the computer system depicted in .

The computer system can comprise one of a plurality of servers which are arranged for distributing the processing of data among available resources. The servers include memory for storage of data and software applications and a processor for accessing data and executing applications to invoke its functionality.

The system in shows a plurality of client computer systems arranged for communication with the computer system via network . The client computer system e.g. can be of varying types including a personal computer a portable computer a workstation a computer terminal a network computer a television a mainframe a smartphone a mobile device a touch pad or any other data processing system or computing device. Typically the client computer system will include a browser or other application enabling interaction with the computer system media decoders for decoding encoded media data including encoded audio data for live rendering and playback audio playback devices which produce sound from rendered audio data or compositions and audio input devices such as a microphone which provide input audio data that can be utilized in the composition of music. In some embodiments a client computer system includes audio input devices such as a keyboard other electronic audio input devices audio synthesis sources and the like which can be applied to produce audio data used in the composition process.

In a client server architecture the computer system provides an interface to a client via the network . The client executes a browser and renders the interface on the local machine. For example a client can render a graphical user interface in response to a webpage programs linked to a webpage and other known technologies delivered by the computer system to the client computer system . The graphical user interface provides a tool by which a user is able to receive information and provide input using a variety of input devices. The input can be delivered to the computer system in the form of commands data files such as audio recordings parameters for use in managing the streaming and buffering processes described herein and the like via messages or sequences of messages transmitted over the network .

Different protocols that can be used for communication with the servers include remote procedure call RPC streaming via Realtime Messaging Protocol RTMP with data encoded in AMF Action Message Format Websocket on a NodeJS Server and Representational State Transfer REST via hypertext transfer protocol HTTP with data encoded as JavaScript Object Notation in Extensible Markup Language JSON XML .

Although the computing resources are described with reference to as being implemented in a distributed client server architecture the technologies described herein can also be implemented using locally installed software on a single data processing system including one or more processors such as a system configured as a personal computer as a workstation or as any other machine having sufficient data processing resources. In such system the single data processing system can provide an interface on a local display device and accept input using local input devices via a bus system like the bus subsystem or other local communication technologies.

The web server can provide for packaging and streaming of the encoded data which can be implemented using a protocol of flow control messages such as are supported by Websocket on a NodeJS Server for example. A chunk as the term is used herein can comprise a set of encoded frames or other units of encoding having from one to many members depending on the media type encoding technologies and a variety of design choices. For an MP3 embodiment a chunk can consist of twelve frames each from of which encodes nominally 1152 samples. Also the web server can include a flow control mechanism for marking or indexing the beginning end of stream portions.

The client side resources shown in include a client program such as a web browser. The client side also includes a decoder which is coupled to buffer management logic and region management logic . The buffer management logic can deliver decoded samples to the audio output at the client for live rendering. The client program includes resources for receiving encoded audio stream via a tool such as Websocket. The decoder can operate to decode chunks using a Web Audio API for example.

A data flow can include encoded data chunks received from web server . A current chunk may be attached to a previous chunk received in an intermediate buffer. That buffer is used for decoding. The client can support on demand download regions by play head position . In one approach to supporting on demand download regions a binary tree is used to intelligently buffer streamed audio when the user sets the play head.

In buffer management logic and region management logic region boundaries are adjusted if necessary to minimize glitches cracks. For example in MP3 audio the decoded portions of the audio data can be adjusted to frame discrete sizes. Flow management processes can establish stream start positions that enable overlapping of sections of the media data that are downloaded out of order. Region boundaries can be patched by crossfading overlapped sequences of samples from the previous regions.

In some embodiments the live streaming process is driven by client commands while server messages are sent to notify the client that a certain event occurred. For example audio control commands and stream control commands can be issued by the client. Audio control commands can include 

These flow control messages account for the asynchronous nature of the streaming approach. For instance once the server has started pushing packages of data it cannot stop immediately when the client issues a STOP STREAM message. More packages than needed might have been transmitted already and the client and server can synchronize this by employing the outlined messages.

In the server has a loaded song and is in an idle state. The client is in a position of selecting audio data for downloading and establishes a data structure having a single node in an active download state. The client and server exchange flow control messages . The client sends flow control messages to the server including START FRAME N indicating a starting position Nas shown on the play head and a START STREAM message. The server begins sending encoded data. The decoded data are loaded into a decode buffer for region .

In a next stage as shown in while the client is buffering and the server is streaming the encoded audio data the user at the client selects a second play head position N which results in a split of region into regions and in this example with the region having some completed downloaded data going to the left in the binary tree. The flow control messages exchanged include a stop stream message a START FRAME N message and a START STREAM message from the client to the server and encoded data from the server to the client beginning at the new start position N. The new start position Ncan be determined according to the particular encoding scheme being applied. For an MP3 scheme using chunks of 12 frames each the new start position Ncan be calculated by identifying the closest frame boundary in advance of a user selected start position and then adding one chunk of 12 frames in advance of that closest frame boundary. In other embodiments the new start position Ncan be set to any number of frames in advance of the start position other than the number of frames per chunk. The added frame or frames in advance of the user selected start position can be used to provide a pre pended stream of audio data which can be discarded so that the user selected start position falls within the known good part of the decoded stream and also to produce an overlap region that can be applied for merging the download regions in a manner that avoids or minimizes audible seams in the merged data. Other techniques for creating overlap regions can be used including techniques that add extra frames or extra chunks to the end of streaming segments. shows this overlap of regions in the decode buffer in a heuristic manner. In one embodiment as the data is decoded and stored in the decode buffer for the current region a constant amount of data is discarded leaving a known good part in the buffer. For example the constant amount of data can include 2 frames or 2304 samples. For an embodiment that pre pends a 12 frame chunk this results in a 10 frame overlap region.

At the point that the flow control messages transition the flow to region based on the new user selected start position region can be tagged in the data structure as the active download region and the encoded data is loaded for region and decoded data are loaded into a region decode buffer .

The location at which the stream for region was interrupted can be logged in the data structure as an interrupt start position in region and can be used when the procedure returns to complete downloading of the skipped portions of the data. To support a case in which the initial start position is not the beginning of a media data then the logic can be included that responds to the condition that the initial starting position is not the beginning of the media data by splitting the media data into an initial region and an incomplete region.

The transition from streaming a segment of the data for region into a segment for region can involve procedures that deal with the asynchronous nature of the streaming and decoding process. For example the Web Audio API decoder works asynchronously it is fed with chunks of encoded data which it passes to a callback function once they are decoded. Flow control messages are not passed to the decoder but are handled directly as a message that consists of a plain string e.g. stopped .

For example assume the client has the following input via a WebSocket connection . . . Chunk Chunk Chunk DONE. In this situation the last three data chunks of a stream are fed to the decoder. The decoder asynchronously calls back for each decoded chunk which is then handled by a client side controller. The DONE message is directly handled by the controller without passing it to the decoder. Hence it is quite likely that the DONE message is handled before the last data chunks are completely decoded. The message DONE means to the controller that the stream has finished and so an index in the controller for the download head can be moved and a new stream started. To make sure that data in the decoding process is not lost the flow control process can wait for the decoder. To achieve this the controller can keep track of the number of chunks in the decoder by for example counting up for arriving encoded data chunks and counting down for decoded data chunks passing the callback. So before DONE is actually handled the number of chunks in the decoder has to be 0.

In a next stage as shown in the user selects yet another new play head position N. This results in a further split of region into two new regions and . The flow control messages exchanged include a STOP STREAM message a START FRAME N message and a START STREAM message from the client to the server and encoded data from the server to the client beginning at the new start position N. At this point region becomes the active download region and the encoded data is loaded into region of the play head and decoded data are loaded into a region decode buffer . The interrupt location from region is logged for region .

As shown in traversing the binary tree from left to right the region management logic selects region as the active download region and sends flow control messages including a STOP STREAM message a START FRAME N message and a START STREAM message. The server responds by sending the encoded data. As with region the START FRAME message can select the interrupt location for region in place of the original play head set position N to begin filling of the decode buffer for Region .

As illustrated in on completion of the downloading for region the client sends a STOP STREAM flow control message to the server and the nodes and in the binary tree are merged back into their parent node . Likewise the decode buffers for regions and are merged into a single decode buffer for region .

Next as shown in the region management logic merges the completed nodes and into their parent node with the channel between the client and the server being idle . As shown in the decode buffers for region and region are likewise merged into a single decode buffer for region with the channel between the client and the server being idle .

So a basic process for downloading encoded media data for playback can be understood with reference to .

If the media data are changed during the streaming process then the data structure and the buffers for the data can be reset. After the reset has been done the client decode buffer is empty. The client can then send START FRAME and start messages to populate it with new data.

In one aspect the process can be considered from the point of view of three flow control sequences. In this aspect the process includes sending a first flow control message to a source of encoded media data requesting download of a first set of chunks of the encoded media data. The client receives and decodes the first set of chunks of the encoded media data to provide decoded data of a first portion of the media data while buffering the decoded data of the first portion of the media data. If during this process a signal indicating a new starting position is received the download of the first set of chunks is interrupted and a second flow control message is sent to the source requesting download of a second set of chunks of the encoded media data based on the new starting position. The client receives and decodes the second set of chunks of the encoded media data to provide decoded data and buffers the decoded data for the second portion. After completion of the download of the second set of chunks assuming no interruptions a third flow control message is sent to the source requesting download of the data between the interruption position and the beginning of the second flow. This third flow control message can occur after several iterations of splitting and buffering the regions as discussed above as new play head set signals are received. The third flow control message results in downloading of the media data which can be received and decoded at the client. The client buffers the decoded data to provide a third portion of the media data. The client merges the first second and third portions of the media data to compile a complete set of the media data. A leading part of the data of at least the second portion and preferably both the second portion and the third portion of the decoded media data can be discarded so that only known good parts of the decoded audio data are merged to compile the completed set.

During the downloading the client monitors for the receipt of new starting positions . If a new starting position is received then the defined region is split to form an incomplete region and the current region . Flow control messages are sent to the server to begin downloading the encoded audio data for the current region . The process then returns to block to watch for new starting positions. If at block it is determined that no new starting position has been received then the algorithm determines whether the current region is complete . If the current region is not complete the process returns to block to look for a new starting position. If the current region is complete at block then the binary tree is updated while the buffers are merged. Then the tree is walked to find other incomplete regions . If there are more incomplete regions as indicated block then flow control messages are sent to recover the encoded data for the incomplete region block . If at block there are no more incomplete regions then the region management logic finishes while the buffers are merged to form the complete decoded audio data.

When there is sufficient data in a receive buffer to begin decoding and the receive buffer holds data for the current play head position or otherwise is ready for decoding the encoded data are sent to a decoder and decoded data are received in return . Each receive buffer can be handled in the sequence determined by the region management logic. The known good part of the decoded data is stored in a decode buffer for the region being downloaded . The result is then sent to the region management system where the decode buffers can be used in the merger process.

In order to facilitate merger of the buffers using known good data a segment of the audio data in advance of the point is also downloaded. For example chunk is downloaded as the leading chunk in the sequence beginning at point . Upon receiving chunk at the end of the stream the region management logic returns to download the incomplete portion beginning at the interrupt point as illustrated by stage in . The flow control messages begin downloading in advance of the sequence beginning at point by downloading chunk and continuing to chunk and storing them in a third receive buffer. The decoding of the received chunks can be buffered to create overlapping regions of decoded audio data.

As mentioned above a leading segment of the decoded data is discarded during merger of the decoded data for each set of chunks e.g. each set assigned to a receive buffer except for the first chunk chunk in a stream preserving a known good part of the decoded data. The discard data are provided by decoded data from the last chunk of the previous set of chunks and is thus known to be good.

In one example using MP3 decoding the known good part can be estimated by a static value such as two 1152 sample frames. The decoded data for chunk received during stage are reduced on movement from the decode buffer to the merge buffer therefore by the amount of samples that are discarded to preserve the known good part of the stream. So the portion of chunk from stage saved in the second decode buffer of the streaming example in will be reduced to 10 frames from 12 frames. Likewise the decoded data for chunk received during stage saved in the third decode buffer are reduced therefore by the amount of samples that are discarded to preserve the known good part of the stream to 10 frames from 12 frames in the example.

In one example merger of the decode buffers as illustrated in stage part of the overlapping data in the third decode buffer from the second instance of chunk at the beginning of the segment received during stage are combined with decoded data in the first decode buffer from the first instance of chunk received during stage at the end of the segment such as by crossfading. The balance of the data in the third decode buffer from second instance of chunk received during stage can be discarded. Also part of the overlapping data in the second decode buffer from the first instance of chunk during stage at the beginning of the second segment are combined with data from second instance of chunk in the third decode buffer received at the end of the segment during stage . In an MP3 encoding example the parts and can comprise just 2304 samples of the 11520 which produces about 50 milliseconds of audio in one example which are crossfaded to match or mask the seams between the decoded regions. The size of the overlap parts and can vary according to other design choices including for example choices to suit a particular combination of media data encoding scheme and decoder schemes used to merge the overlapping buffers and the tastes of the designer.

The region boundaries are unlikely to fall on discrete chunk boundaries. Thus the ends of the downloaded data can be trimmed by deleting data beyond the ending boundary of the region. In some embodiments the samples at the ends of audio chunks beyond the region boundaries are not discarded until a following chunk is received in case the end of the stream is reached.

Decoding 12 MP3 frames does not always result in 13824 12 1152 samples. Sometimes the decoded data contains just 13823 samples. Therefore a process of discarding a fixed number of samples at the lead of each set of chunks can result in odd sized chunks added to the buffer. However it can be easier to handle the data especially for calculations in the crossfade logic if it is added in frame discretized units multiples of 1152.

So in an alternative approach in order to always get frame discretized units of samples the amount of skipped samples is dynamic. The amount to skip must be at least enough that the remaining samples can be considered a known good part so for one MP3 example at least one frame must be skipped to make sure to get rid of the decoding error at the beginning One approach to determining the number of samples to discard or skip can include simply determining the size of the decoded sample set and applying a modulo frame size function. If the modulo function returns zero then the sample set is frame discrete already and only one frame needs to be discarded. If the modulo function returns a non zero value ss then the number of samples to be discarded is the sum of the value ss and the frame size. In this case for an MP3 encoded example the number of samples discarded at the leading edge of the region can vary between 1152 and 2304.

The amount of data produced on decoding the first chunk of a stream in some MP3 decoder embodiments is always 13 823 one sample short of 12 frames . So the amount of samples skipped from the end of the decode buffer of the first chunk chunk 0 of a data can be always exactly 2 303. To obtain frame discrete units in the merge buffer and skip at least 1 152 samples one can skip 2 303 samples from chunk . This results in 11 520 samples 10 frames added to the merge buffer. When the second chunk is decoded the start index in the merger logic can be set so that the skipped samples are recovered from the middle of the decoded data of two concatenated chunks in the decode buffer for the stream the previous one and the current one. In one example process for an MP3 stream using 12 frame chunks the first chunk is decoded and adjusted to a frame discrete size by discarding 2303 samples from the last two frames in the chunk and moving it to a merge buffer. The decoding of a second chunk in the receive buffer is set to decode starting at the beginning of the first chunk again for the purposes of aligning the data for the logic that merges the decode buffers. The data from the first 10 frames are not needed in this second pass as they were produced from the decoding of the first chunk in the first pass while the data of the last two frames of the first chunk are moved to the merge buffer along with the first 10 frames from the second chunk. The last frame or frames of each chunk is are held in the decode buffer until the following chunk is decoded where they are available for use in the merger process in case it is the last chunk in the set. As each succeeding chunk is decoded the data are moved to the merge buffer while a trailing part is held until the next chunk is decoded or until a signal is received indicating it is the last frame in the stream e.g. a DONE signal from the source . If the end is reached then the held trailing part is moved to the merge buffer.

While the present invention is disclosed by reference to the preferred embodiments and examples detailed above it is understood that these examples are intended in an illustrative rather than in a limiting sense. Computer assisted processing is implicated in the described embodiments. Accordingly the present invention may be embodied in methods for perform processes described herein systems including logic and resources to perform processes described herein systems that take advantage of computer assisted methods for performing processes described herein media impressed with logic to perform processes described herein data streams impressed with logic to perform processes described herein or computer accessible services that carry out computer assisted methods for perform processes described herein. It is contemplated that modifications and combinations will readily occur to those skilled in the art which modifications and combinations will be within the spirit of the invention and the scope of the following claims.

