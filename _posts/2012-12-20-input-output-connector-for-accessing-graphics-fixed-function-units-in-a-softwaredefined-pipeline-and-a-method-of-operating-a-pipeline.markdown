---

title: Input output connector for accessing graphics fixed function units in a software-defined pipeline and a method of operating a pipeline
abstract: An input output connector for a graphics processing unit having a graphics pipeline including fixed function units and programmable function units is disclosed. Additionally, a graphics processing unit and a method of operating a graphics pipeline are disclosed. In one embodiment, the input output connector includes: (1) a request arbiter configured to connect to each of the programmable function units, receive fixed function requests therefrom and arbitrate the requests and (2) fixed unit converters, wherein each of the fixed unit converters is dedicated to a single one of the fixed function units and is configured to convert the requests directed to the single one to an input format for the single one.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09019284&OS=09019284&RS=09019284
owner: Nvidia Corporation
number: 09019284
owner_city: Santa Clara
owner_country: US
publication_date: 20121220
---
This application is directed in general to graphics processing units GPUs and more specifically to graphic pipelines of a GPU.

In traditional GPUs fixed function units are statically connected together to form a fixed function graphics pipeline. The output packets of each of the fixed function units or fixed function stages are designed to match the input packets of the downstream fixed function unit. In some conventional GPUs programmable function stages are statically connected with fixed function units to form a graphics pipeline. Programmable function stages are implemented by writing fixed function outputs into a software visible buffer running the program and reading the program outputs back into the next fixed function stage. This arrangement provides efficient flow of state and data through a graphics pipeline having programmable function stages. However major changes to the way the graphics pipeline operates require hardware modifications to the static connections.

A more flexible approach is to define the graphics pipeline in software as a program or programs running on a programmable processor. In such a pipeline the functional stages are implemented in software with data being moved via a regular general purpose memory system.

In one aspect an input output connector for a graphics processing unit having a graphics pipeline including fixed function units and programmable function units is disclosed. In one embodiment the input output connector includes 1 a request arbiter configured to connect to each of the programmable function units receive fixed function requests therefrom and arbitrate the requests and 2 fixed unit converters wherein each of the fixed unit converters is dedicated to a single one of the fixed function units and is configured to convert the requests directed to the single one to an input format for the single one.

In another aspect a method of operating a graphics pipeline having fixed function units and programmable function units is disclosed. In one embodiment the method includes 1 receiving a request from one of the programmable function units for one of the fixed function units to generate a response 2 obtaining parameters and state information for the request 3 routing the request including the parameters and the state information to one of multiple interface logic wherein each of the multiple interface logic is dedicated for a single one of the fixed function units and 4 converting the request employing the interface logic to a unit specific input format for the one of the fixed function units.

In yet one other aspect a graphics processing unit is disclosed. In one embodiment the graphics processing unit includes 1 fixed function units 2 programmable function units and 3 a single input output connector configured to connect each of the programmable function units to each of the fixed function units.

Though software defined graphics pipelines are flexible such a pipeline still requires certain fixed function blocks or units to accelerate work intensive routines in order to provide competitive performance. To utilize existing fixed function units in a graphics pipeline with software defined stages and to efficiently add new fixed function units various problems need to be addressed.

As such disclosed herein is an IO connector that provides a programmable pipeline with dynamically defined connections between stages instead of static connections. The disclosed IO connector communicates inputs and outputs between fixed function units and processor grids or cores used for the programmable function stages or units . Additionally the IO connector communicates various states between the programmable function units and the fixed function units. Inputs and outputs are also translated between a software friendly format of the programmable function units and a hardware friendly format of the fixed function units. Furthermore the IO connector translates states between a software friendly format and a hardware friendly format.

In one embodiment the IO connector advantageously provides all of the above noted functions in a single processing block that is shared across all fixed function units and multiple programmable function units. A programmable function unit is a processor or a portion thereof that can be programmed to perform fixed function tasks. The processor can be a special purpose processor that is specifically designed to operate with highly parallel code. A programmable function unit is referred to herein as a streaming multiprocessor SM . A SM is capable of executing a relatively large number of threads concurrently. Advantageously each streaming multiprocessor can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying of physics to determine position velocity and other attributes of objects and so on. Examples of function units fixed function or programmable include a pixel shader a vertex shader a geometry shader etc.

The IO connector advantageously provides a single interface that includes the necessary logic to dynamically connect multiple SMs and fixed function units to form a graphics pipeline and manage instruction level communications therebetween. The IO connector includes multiple components that provide bi directional connections including bi directional control connections to SMs bi directional data connections to shared memories associated with the SMs and a bi directional connection into a global memory system associated with a graphic processing unit. The IO connector also includes arbiters for managing connections including a request arbiter and a response arbiter. In addition the novel IO connector includes additional logic including shared conversion logic per unit conversion logic shadow state logic and a request data fetch unit. A state cache is also included.

Before describing various embodiments of the novel IO connector and methods associated therewith a computing system within which the IO connector may be embodied or a method of operating a graphics pipeline is carried out will be described.

As shown the system data bus connects the CPU the input devices the system memory and the graphics processing subsystem . In alternate embodiments the system memory may connect directly to the CPU . The CPU receives user input from the input devices executes programming instructions stored in the system memory operates on data stored in the system memory and sends instructions and or data i.e. work or tasks to complete to a graphics processing unit to complete. The system memory typically includes dynamic random access memory DRAM used to store programming instructions and data for processing by the CPU and the graphics processing subsystem . The graphics processing subsystem receives the transmitted work from the CPU and processes the work employing a graphics processing unit GPU thereof. In this embodiment the GPU completes the work in order to render and display graphics images on the display devices . In other embodiments the GPU or the graphics processing subsystem as a whole can be used for non graphics processing.

As also shown the system memory includes an application program an application programming interface API and a graphics processing unit GPU driver . The application program generates calls to the API in order to produce a desired set of results typically in the form of a sequence of graphics images.

The graphics processing subsystem includes the GPU an on chip GPU memory an on chip GPU data bus a GPU local memory and a GPU data bus . The GPU is configured to communicate with the on chip GPU memory via the on chip GPU data bus and with the GPU local memory via the GPU data bus . The GPU may receive instructions transmitted by the CPU process the instructions in order to render graphics data and images and store these images in the GPU local memory . Subsequently the GPU may display certain graphics images stored in the GPU local memory on the display devices .

The GPU includes fixed function units programmable processing units and an IO connector . The fixed function units include conventional fixed function units having circuitry configured to perform a dedicated function. The fixed function units are implemented in hardware. The programmable processing units include the necessary processors and memory to perform dedicated functions of a pipeline stage. The processors can be specifically configured for processing highly parallel code. The fixed function units and the programmable processing units can be conventional components of a graphics pipeline.

The GPU also includes a single IO connector . The IO connector is configured to couple each of the programmable processing units to each of the fixed function units and provide the necessary conversions between software and hardware formats to allow communication of requests and responses between the programmable processing units and the fixed function units . More detail of an embodiment of IO connector is discussed below with respect to .

The GPU may be provided with any amount of on chip GPU memory and GPU local memory including none and may use on chip GPU memory GPU local memory and system memory in any combination for memory operations.

The on chip GPU memory is configured to include GPU programming code and on chip buffers . The GPU programming may be transmitted from the GPU driver to the on chip GPU memory via the system data bus .

The GPU local memory typically includes less expensive off chip dynamic random access memory DRAM and is also used to store data and programming used by the GPU . As shown the GPU local memory includes a frame buffer . The frame buffer stores data for at least one two dimensional surface that may be used to drive the display devices . Furthermore the frame buffer may include more than one two dimensional surface so that the GPU can render to one two dimensional surface while a second two dimensional surface is used to drive the display devices .

The display devices are one or more output devices capable of emitting a visual image corresponding to an input data signal. For example a display device may be built using a cathode ray tube CRT monitor a liquid crystal display or any other suitable display system. The input data signals to the display devices are typically generated by scanning out the contents of one or more frames of image data that is stored in the frame buffer .

Having described a computing system within which the disclosed IO connector and methods may be embodied or carried out a particular embodiment of an IO connector will be described in the environment of a GPU .

The global memory system crossbar provides an interface to a graphics processing system or computing system such as disclosed in . For example considering the global memory system crossbar can provide connections to the system memory GPU local memory and on chip GPU memory . The programmable processing units include a SM memory a SM a SM memory and a SM . The SM memories are memories that include the data to be processed by the SM SM respectively or data to be sent to the fixed function units for processing. In different embodiments the SM memories are a random access memory RAM a register file or a scratchpad. The SM SM are streaming multiprocessors that are programmed to operate as a fixed function unit. The SM and the SM are coupled to the global memory system crossbar and the SM memories . The global memory system crossbar and the programmable processing units can be conventional devices typically included in a GPU.

The fixed function units can also be fixed function units that are typically found in a GPU. The fixed function units include three different fixed function units fixed function unit fixed function unit and fixed function unit that are each configured with the necessary circuitry dedicated to perform a particular function of a graphics pipeline. The fixed function units can also be conventional components found in a typical GPU.

The IO connector includes multiple components that are configured to provide non permanent connections between the programmable processing units and the fixed function units and provide the proper conversions to allow communication and processing of requests and responses therebetween. In one embodiment the IO connector or components thereof include the necessary logic or logic circuitry to perform the functions described herein.

In one embodiment the IO connector provides dynamic connections between the programmable processing units and the fixed function units for each request generated by the programmable processing units . A request is an instruction or command to perform an action or work on data. A request is generated by SM and or SM of the programmable processing units for one of the fixed function units to perform. A response is generated by one of the particular fixed function units as a result of the request. Associated with each request are parameters and state information that the fixed function units use to process the requests.

The IO connector includes an input output IO arbiter a parameter fetch unit a shared format converter a state cache and a request expander .

The IO arbiter provides a single interface for each of the programmable processing units of the GPU to form a graphics pipeline with the fixed function units . The IO arbiter is connected to the SM memory and the SM memory via bi directional data connections and . The IO arbiter is also connected to the SM and the SM via bi directional control connections respectively. In addition to providing a single connection interface with the programmable processing units the IO arbiter is also configured to arbitrate between various requests generated from different SMs such as the SMs .

The fetch unit is configured to fetch or obtain parameters of the requests from the SM memories . The fetch unit obtains the request parameters from the SM memories via the bi directional data connections and the IO arbiter . The primary flow of requests is uni directional from the IO arbiter to the fetch unit . However control information also flows from the fetch unit to the IO arbiter . As such the connecting path therebetween is shown as bidirectional. The fetch unit is also configured to extract state pointers from the requests and forward the state pointers to the state cache .

The shared format converter is logic configured to perform common transformations to the request parameters. The shared format converter performs common transformations for requests from all of the SMs coupled thereto i.e. SM and SM . A common transformation is a transformation from one common format to a second common format. The second common format is not specific to a particular input format of one of the fixed function units . Examples of common transformations include translations from floating point to fix point formats e.g. IEEE FP32 to 24.8 fixed point or from high to low precision floating point 32 bit floating point to 16 bit floating point . These common transformations are performed since software typically operates on higher precision floating point data fp32 but hardware more commonly uses fixed point or low precision floating point. Since complex circuitry is typically needed for these common transformations require complex circuitry the shared format converter is beneficially shared circuitry for all of the units.

The state cache receives the state pointers from the fetch unit and retrieves state information based thereon. In one embodiment the state cache is configured to obtain the state information via the global memory system crossbar across a bi directional memory connection . In some embodiments the state information is stored in a GPU local memory such as GPU local memory of . In other embodiments the state information is stored in a system memory such as system memory of .

The request expander is configured to expand a single request from a SM into multiple fixed functional unit requests. In one embodiment the request expander is a finite state machine FSM that is programmed to expand the request. In some embodiments the request expander is a macro FSM and the expansion is defined via micro code macros.

The IO connector also has buffers including a request first in first out FIFO a state FIFO and a bypass FIFO buffer . The request FIFO buffer receives and stores the requests from the shared format converter and if applicable the request expander . The state FIFO receives and stores the state information from the state cache and the request expander if applicable. The bypass FIFO receives and stores expanded requests from the request expander and converted responses from the fixed function units i.e. outputs from the fixed function units . The bypass FIFO is connected to a shared format converter via a bypass connection . The bypass connection provides a bypass path that sends responses from one of the fixed function units to the input of a second one of the fixed function units and combines them with SM inputs or requests from a SM .

The bypass path and the request expander provide additional features for the IO connector that improve efficiency of the graphics pipeline above just the connections and conversions. For example these features can be used to implement different embodiments for a blitter HW accelerated clears fast solid color triangles and fast Z only rendering. In each of the below embodiments the noted shader stages can be performed by a particular one of the fixed function units . For example for blits the fixed function unit can be the texture unit.

Considering blits for example the request expander is configured to expand a single SM request into a 4 4 quads that are sent to a texture unit. The texture results are combined with the coordinates of the SM request and sent to a surface processor to be rendered to a display screen.

For clear for example the request expander can expand a single SM request into a number of 8 8 tiles that are sent to a raster unit to be tested against clipping rectangle. The results are sent to a depth processor to clear the tile.

For solid color triangles for example a SM sends in a triangle to tile. The request expander sends the triangle information to a raster unit to generate a coverage mask. This is combined with a Z plane equation. In one embodiment the bypass FIFO combines the coverage mask with the Z plane equation wherein the Z Plane is placed there by the request expander and the coverage mask is placed there by the shared format conversion block . The combination can then be sent to ZROP. The result coverage mask is expanded by the request expander into 4 4 quads and sent to a surface processor to be rendered to a display screen.

Each of the above noted FIFO buffers are coupled to a fixed function arbiter that is coupled to interface logic for the fixed function units . The interface logic is coupled to and configured for a specific one of the fixed function units . In one embodiment each interface logic is configured or built for a specific fixed function unit. Thus the interface logic includes specific logic that is dedicated for connecting to a particular fixed function unit. The interface logic includes interface logic interface logic and interface logic . The interface logic includes a request converter shadow state logic and a response converter . Similarly the interface logic includes a request converter shadow state logic and a response converter and the interface logic includes a request converter shadow state logic and a response converter .

Each of the request converters are configured to convert the requests to a unit specific input format for the corresponding fixed function units and . As such the fixed function units and can execute the requests as in a fixed function pipeline. In one embodiment the request converters map the pre converted requests to the unit specific input format.

The shadow state logic are configured to provide the proper state for the respective fixed function units . In one embodiment the shadow state logic are configured to compare the retrieved state information to the shadow state of the particular fixed function units and generate necessary state updates based on the comparison.

At least some of the above noted components of the IO connector are employed when sending requests from the programmable processing units to the fixed function units . The IO connector also includes additional components that are employed when sending outputs i.e. responses to the requests from the fixed function units to the programmable processing units . These components include the response converters that are configured to convert responses or outputs from the output format of the specific fixed function units to an intermediate format. The intermediate format is identical to or at least comparable to a final format for the programmable processing units except that conversions performed by a shared format converter have not been applied yet. Specifically unit outputs are still in low precision floating point or fixed point format depending on the unit specific output. The shared format converter converts these to software friendly values such as fp32 values.

In addition to the shared format converter the additional components of the IO connector include the response arbiter a response FIFO and an output commit unit . The response arbiter is configured to arbitrate between the fixed function units that have outputs ready and have been converted to the intermediate format by the applicable response converters . The response arbiter directs the responses in the intermediate format to the shared format converter . The shared format converter is configured to convert from the unit specific intermediate format to a final software friendly format for the programmable processing units . Thus the shared format converter similar to the shared format converter is employed to convert the responses from all of the fixed function units to a software friendly format. This is in contrast to the individual response converters that are specifically designed to perform format conversion for a single one of the fixed function units .

The response FIFO receives and stores the software friendly format responses to deliver to the appropriate programmable processing units .

The output commit unit is configured to deliver the software friendly format responses stored in the response FIFO to the appropriate programmable processing units . The output commit unit is also configured to send an acknowledgement signal to the appropriate programmable processing units after all response data has been written.

The following figure provides embodiments of methods of communicating between programmable processing units and fixed functions unit. The IO connector of can be employed for these methods.

In a step a block of requests are written into a shared memory. The requests are work requests to be performed by one of the fixed functional units. A SM or multiple SMs write the block of requests. The shared memory can be a RAM such as a register file a L1 or a scratchpad. The requests contain request parameters in a format defined as part of the SM s ABI and a global memory pointer to the request state which is stored in a memory associated with the graphics pipeline.

At least one request is sent to an IO interface in a step . The request defines the target unit i.e. the target fixed function unit the location or address of the request stored in a SM memory such as the SM memory and the length of the request. In one embodiment a SM sends the request via a control connection such as one of the control connections .

In a step the received requests are arbitrated. The requests can be received from different SMs coupled thereto such as the SM and the SM . An IO arbiter such as the IO arbiter can receive the requests and arbitrate between the requests.

Once a request has been accepted request parameters are fetched in a step . The request parameters can be fetched from a shared memory via a data connection by the IO interface. In one embodiment the parameter fetch unit fetches or obtains the request parameters from one of the shared memories via the corresponding data connection or and the IO arbiter .

State information is retrieved in a step . In one embodiment the state pointer is extracted from the request and sent to a state cache. The state cache retrieves the state information stored thereon or fetches the state information from another cache or memory via a global memory system connection. In one embodiment the state cache or the global memory system crossbar are employed by the IO connector to retrieve the state information.

In a step common transformations of the request parameters are performed. Dedicated logic such as shared conversion logic of the IO interface can perform the common transformations such as floating to fixed point conversion of the request parameters. In one embodiment the IO connector employs the shared format conversion logic to perform the format conversion. In some embodiments there are graphics specific conversions such as color space conversions RGB YUV that are performed. Other common transformations include changes in numeric precision or simple reordering of values e.g. from struct of arrays to arrays of structs within the request.

The request is routed to the appropriate fixed function unit in a step . After conversion of the request parameters the transformed parameters can be stored in a request buffer. Additionally the obtained state information can be stored in a state buffer. An arbiter for the fixed function units can receive the request in its transformed state and direct the request to the interface logic for the appropriate fixed function unit. The target fixed function unit is part of the request since the request defines the target unit. In one embodiment the request includes a fixed function ID field to identify the target fixed function unit. In one embodiment the IO connector employs the request FIFO the state FIFO and the fixed function arbiter to direct the request to either the interface logic the interface logic or the interface logic .

In a step the state object associated with the request is compared to the shadow state of the appropriate fixed function unit and necessary state updates are generated. A shadow state is an accessible copy which is typically an easily accessible copy of the state that the unit is currently configured in. Interface logic for the particular fixed function unit can compare the states and generate the necessary updates. In one embodiment shadow state logic or generates the necessary updates after comparing the state information to shadow states.

Conversion of the requests to the specific input format of the appropriate fixed function unit is performed in a step . In one embodiment per unit conversion logic can map the pre converted request for conversion to the unit specific input format. In some embodiments the per unit conversion logic includes or is associated with a look table that is used for the mapping and the conversion. In one embodiment the request converter logic or is employed for the mapping conversion.

The particular or target fixed function unit executes the request in a step . Accordingly the fixed function unit generates an output or response to the request. In one embodiment the IO interface successfully converts the software based request into the proper format for the fixed function unit to execute the request in the exact same way as in a fixed function pipeline. The IO connector for example can provide the proper conversion at an instruction by instruction level.

In a step the output is converted from a fixed function unit output format to a unit specific intermediate format. In one embodiment unit specific conversion logic converts the output to the unit specific intermediate format. For example the response converter or of can perform the conversion.

Arbitration between outputs from the fixed function units is performed in a step . In one embodiment the response arbiter arbitrates between the fixed function units that have generated outputs. At this point the outputs have already been converted into the unit specific intermediate format via unit specific conversion logic.

In a step conversion between the unit specific intermediate format to a final software friendly format of the response is performed. In one embodiment shared format conversion logic is used for this conversion such as the shared format conversion logic of . The response in the software friendly format can be stored in a buffer such as the response FIFO .

The converted response data is written back into the shared memory in a step . The converted response data can be written from a buffer such as the response FIFO . In one embodiment the output commit unit is employed to write the converted response data to a shared memory or via the input output arbiter and the bi directional data connections respectively.

An acknowledgment signal is sent to the SM in a step . The acknowledgment signal is sent after all response data has been written to the shared memory. In one embodiment the IO connector can send the acknowledgement signal to a SM via the control bus or . In a step the SM reads the response from the shared memory. The method then ends in a step .

While the method disclosed herein has been described and shown with reference to particular steps performed in a particular order it will be understood that these steps may be combined subdivided or reordered to form an equivalent method without departing from the teachings of the present disclosure. Accordingly unless specifically indicated herein the order or the grouping of the steps is not a limitation of the present disclosure.

A portion of the above described apparatuses systems or methods may be embodied in or performed by various such as conventional digital data processors or computers wherein the computers are programmed or store executable programs of sequences of software instructions to perform one or more of the steps of the methods. The software instructions of such programs may represent algorithms and be encoded in machine executable form on non transitory digital data storage media e.g. magnetic or optical disks random access memory RAM magnetic hard disks flash memories and or read only memory ROM to enable various types of digital data processors or computers to perform one multiple or all of the steps of one or more of the above described methods or functions of the apparatuses described herein. As noted above a SM can be implemented on a special purpose processor that is well suited for highly parallel code.

Portions of disclosed embodiments may relate to computer storage products with a non transitory computer readable medium that have program code thereon for performing various computer implemented operations that embody a part of an apparatus system or carry out the steps of a method set forth herein. Non transitory used herein refers to all computer readable media except for transitory propagating signals. Examples of non transitory computer readable media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROM disks magneto optical media such as floptical disks and hardware devices that are specially configured to store and execute program code such as ROM and RAM devices. Examples of program code include both machine code such as produced by a compiler and files containing higher level code that may be executed by the computer using an interpreter.

Those skilled in the art to which this application relates will appreciate that other and further additions deletions substitutions and modifications may be made to the described embodiments.

