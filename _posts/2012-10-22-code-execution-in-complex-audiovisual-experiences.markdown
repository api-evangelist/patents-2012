---

title: Code execution in complex audiovisual experiences
abstract: In one embodiment, a method includes obtaining a link to a video program; obtaining metadata that relates to the program and that defines, for a specified time point in the program, annotations to be invoked at the specified time point; wherein the annotations comprise: a graphic image; one or more filters, each of the filters comprising a key and one or more matching values; and optionally a reference to a video segment, an electronic document, program code statements, or a programmatic call; during playing the video, detecting that the video program is playing at the specified time point; in response to the detecting: for each particular annotation for the specified time point, retrieving a current value for the key, and causing to display the graphic image associated with that particular annotation only when the current value of the key matches one of the matching values of one of the filters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09031382&OS=09031382&RS=09031382
owner: Coincident.tv, Inc.
number: 09031382
owner_city: San Francisco
owner_country: US
publication_date: 20121022
---
This application claims the benefit under 35 U.S.C. 119 of prior provisional application 61 549 582 filed Oct. 20 2011 the entire contents of which is hereby incorporated by reference for all purposes as if fully set forth herein.

A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever. Copyright 2008 2012 Coincident.TV Inc.

The present disclosure generally relates to video playing video editing and displaying hyperlinked media.

Commercial television broadcasting has been supported by advertising revenue since its inception. More recently providers of video programs and video clips in Internet sites have embedded advertising within video programs or next to video programs in web pages at which the video programs are viewed. However a continuing problem involved in these technologies is that the advertisements are not closely personalized for the viewer. Instead commercial broadcasters attempt to define in terms of rough demographic characteristics a sub population of a mass audience that is expected to be interested in a particular program advertisers who believe that their products appeal to the same rough demographic will purchase advertising slots in the program. Unfortunately a continuing result of this system is that at least some viewers who do not fit the rough demographic are shown advertisements that are irrelevant to the viewers interests.

Internet technologies also have attempted to tailor advertisements displayed in World Wide Web sites more closely to the preferences of Internet users based on collecting explicitly specified preference data based on a user profile or by inferring preferences through collecting metadata that is derived as the Internet user selects pages or performs online actions. However these technologies are not fully accurate because they rely on algorithms that attempt to match known characteristics of ads with user preferences that can be only roughly inferred from the data that the users provide.

Video editors such as Adobe Premiere Pro and Final Cut Pro enable users to select multiple video clips join the clips and annotate the clips by defining cue points and associating text notes with the cue points.

The approaches described in this section are approaches that could be pursued but not necessarily approaches that have been previously conceived or pursued. Therefore unless otherwise indicated it should not be assumed that any of the approaches described in this section qualify as prior art merely by virtue of their inclusion in this section.

APPENDICES. All appendices and other documents filed as part of the above referenced provisional applications form a part of the disclosure herein. The appendices describe example embodiments and other embodiments may vary from the descriptions in the appendices.

In the following description for the purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent however that the present invention may be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention. Embodiments are described according to the following outline although the following description does not reproduce as section headings each and every item in the outline.

Various embodiments provide an editor a player and a metadata format. In an embodiment the editor implements a method of creating for a video file consisting of multiple segments metadata describing one or more display operations decision operations branching operations video linking operations and web media linking operations and associating the metadata with the video file. In an embodiment the player implements a method of interpreting the metadata during playback of the video file and performing the operations in coordination with playback. In an embodiment the metadata format comprises computer readable data storage media encoded with tags and values which when interpreted cause performing particular display decision branching video linking and web media linking operations. Metadata may comprise cue point type names for various cue point types and attribute values associated with the cue point types that control the particular behavior of the player in performing the operations.

Computer hosts or executes an operating system that supervises I O storage management and execution of application logic. In an embodiment computer further comprises a video editor . Commercially available examples of video editor include Adobe Premiere and Final Cut Pro. In an embodiment computer comprises a browser . Commercially available examples of browser include Firefox Safari Chrome and Internet Explorer.

In an embodiment computer is coupled to storage which broadly represents any data storage device storage area network SAN network attached storage NAS or network file system NFS unit or server. Storage may reside on network or on a server coupled to the network. Storage stores video files graphics files and metadata files .

In an embodiment computer further comprises video linking editor logic and metadata capable video player logic . In other embodiments computer only comprises player logic and does not have an editor such an embodiment might be used by an end user who is viewing video programs that have been prepared by someone else. Thus the use of video linking editor logic is not required.

The video linking editor logic is generally configured to cause one or more processors in computer to receive user input specifying links between segments of a video file and other media such as other segments in the same file other segments of other video files graphics files online content such as web sites or web applications and other rich media content to create representations of the links in metadata and to store the metadata and link related information in the metadata files in association with related video files. For example a user of computer may interact with video linking editor logic to select one or more of the video files from storage or file server create links using editing functions that the editor logic provides integrate graphics files and references to content on web server and then store metadata files either at storage or in file server . The metadata files identify the associated video files and contain metadata defining links among segments link types and link related information to support novel playback functions and other user experiences. Other more specific functions of video editor linking logic are described in other sections herein.

The metadata capable video player logic is generally configured to open metadata files and associated video files and to play the video files while interpreting and responding to links and related information and instructions in the associated metadata files. Other more specific functions of metadata capable video player logic are described in other sections herein. The metadata capable video player logic may be implemented within a web browser and comprising a browser support library and browser executable code such as JavaScript that is received in and executed by the browser at the time that an end user selects a video for playing. The browser support library may be any video playing plug in component for a browser. Examples include Macromedia Flash and Silverlight. Alternatively web browsers may use the VIDEO tag of HTML version 5 to render video and HTML and JavaScript to implement the player logic . In some embodiments the player logic may be partially implemented on server or another server using dynamic AJAX techniques. For example the server may convert data defining annotations into HTML to be displayed in the player. Alternatively the metadata capable video player logic is implemented as a standalone program application that may be installed locally in computer . For such native applications any software development kit SDK that is capable of displaying video could be used to implement the player. Examples include SDKs for Apple Mac OS X Microsoft WINDOWS and Linux.

Each of the computer video linking editor logic and metadata capable video player logic may be implemented in various embodiments using a computer one or more application specific integrated circuits ASICs or other digital electronic logic one or more computer programs modules objects methods or other software elements. For example in one embodiment computer may comprise a special purpose computer having particular logic configured to implement the elements and functions described herein. In another embodiment service computer may comprise a general purpose computer as in loaded with one or more stored programs which transform the general purpose computer into a particular machine upon loading and execution.

In an embodiment video linking is facilitated by creating in metadata files associated with video files executable instructions and or descriptive information that are linked to cue points in the video files. A cue point generally comprises an association of a name to a position within a video file wherein the position is typically expressed as a time value or timestamp. In an embodiment cue points are created for a particular video file using video editor the names and values of cue points become part of the video file through conventional operation of the video editor. Thereafter user interaction with the video linking editor logic can create links operations and link related metadata information for one or more of the cue points. At any later time the metadata capable video player logic may be invoked to play the video and to concurrently detect cue points identify the previously created metadata information relating to links and operations and execute the operations.

Referring first to in one embodiment at step a video editor creates and stores one or more cue points in a video file. Thus presumes that at least one video file has been created and stored on a computer such as computer . Step may comprise a user interacting with the video editor to create and store named cue points in the video file as further described herein. Alternatively step can involve a process or logic in computer or another computer creating cue points in a video file using programmatic techniques or electronic communication of messages to the computer.

In step the computer receives user input identifying a video file. Step may involve invoking the video linking editor logic and specifying the file name of one of the video files or specifying the name of one of the metadata files which will include an internal reference to an associated one or more of the video files.

At step the video linking editor logic reads the video file finds or creates an associated metadata file displays data for cue points in the video file and displays any associated metadata relating to links to other segments or content. If one of the video files is specified at step and no existing metadata file is found then the video linking editor logic creates a related metadata file. If an existing related metadata file is found then that file is read and metadata relating to cue points is displayed on a display unit that is coupled to computer . An example graphical user interface that may be generated to display the metadata is further described herein in connection with but the approach of does not require that particular GUI.

At step the computer receives user input specifying for a particular cue point a cue point type. For example interacting with the GUI of or through other means a user or external computer process or logic selects one of the previously created cue points of the video file and provides input specifying a cue point type value. At a cue point any of several types of operations may be defined to be performed at the time of playback using the metadata capable video player logic . In this document a cue point within a video file and the operations performed at the cue point are sometimes collectively termed a cue point. Cue points as defined herein can refer to video coupled video web contexts or non temporal web locations or web points as further described .

In an embodiment cue points enable a user at playback to jump forward and backward in time in a video and jump between web content and video content. Since the user and the environment can change the order in which media is played the metadata capable video player logic maintains data indicating the user s prior location so that the player can transfer control to a prior location.

In an embodiment web points define an end for web content that specify where to transfer the user when the user has reached the end of a navigation path. Both video and web content can be displayed on the screen at the same time overlaid over web content or using a picture in picture representation and time can be running or paused. When web content is displayed selecting a back operation transfers control to a previously viewed page but when the earliest page is reached then a subsequent back operation transfers control away from web content and to the previously viewed video segment. When video is displayed performing a back operation returns to the beginning of the current video segment.

In an embodiment interest URL refers to an online electronic document that is loaded and displayed at playback time if the user requests additional information about the data shown at the web point. In an embodiment query string comprises a database query that is submitted to an online engine if the web point is selected to generate a search result so that the user receives current search result information associated with the web point. The target field defines a target cue point to which the user is directed at playback time after having viewed a web document associated with the web point. The web view layout definition field identifies a layout format for the player to be used when displaying web information in an embodiment the layout format is one of the formats shown in which is described further herein. The description field is a text description of the web point to display and the thumbnail graphic image is a graphic image to display in the player to denote the web point.

In an embodiment any of the following operations may be defined in the metadata for association with a cue point 

In an embodiment metadata capable video player logic interprets metadata such that when the user is watching video a web link to some form of related content is always available. If the user selects the web link and views the web content the player displays the video in a reduced size picture in picture form. Further description of the foregoing cue point types is provided in other sections of this disclosure.

Referring again to at step the video linking editor logic updates the computer display based on the cue point type to provide input fields and display fields for metadata values that are associated with the specified cue point type. Thus a context sensitive display of input fields and display fields is provided depending on the cue point type. Step may also include receiving user input that indicates particular metadata values for the input fields. For example if the cue point type provided at step is modal story branch then at step an input is received to specify two or more target cue points that represent branch destinations.

At step the video linking editor logic creates and stores the cue point type and the associated metadata values in the metadata file that is associated with the video file. As shown in optional step the type and values may be stored in one or more XML script s within one of the metadata files . However XML is not required in all embodiments and the metadata files may represent cue point names types and metadata values in other forms that can be read by the metadata capable video player logic and used to control linking branching decisions web interaction and other content operations when cue points are reached.

Step represents testing whether a user has requested to exit or discontinue using the video linking editor logic . If no exit request is received then control is transferred to step or step for the computer to await further user input relating to cue points. Alternatively the computer may perform an exit operation at step for example by closing the video file and metadata file.

As indicated in step during all operations previously described for the method is configured to asynchronously process user input requesting video playback trick play functions or loading other video files or metadata files. Thus in an embodiment a playback mechanism may be integrated into the process so that a user can play and view a video program or segment while determining what cue point types and values to specify. The playback mechanism supports non linear playback of video so that the player can execute branch operations play one of a plurality of different alternative video segments at a branch point or decision point return to a prior point and continue playing the next segment thereafter and other complex operations consistent with the rich media authoring capabilities described herein. At any time during the process of the user may request playing a video segment or performing trick play functions such as fast forward or rewind. In an embodiment selecting a different named cue point at step causes the player mechanism to display a first frame of the video segment that starts at the selected cue point or to begin playing the video from that point.

As a result of the process of a video file having internally stored named cue points becomes associated with a separate metadata file that specifies cue point types and metadata values relating to control functions for the video file related networked content and other user interactions. The metadata capable video player logic is configured to play the video and as each cue point is reached perform the control functions based on the cue point types and metadata values that are specified in the metadata file.

In one embodiment of a playback process at step the computer initiates executing the metadata capable video player logic . Initiating execution may occur in response to user input or in response to an instruction from other hardware logic or computer processes. For example a user logic or process may select and invoke one of the metadata files or video files and in computer the files may be associated with the metadata capable video player logic as an application that is launched when the files are invoked.

Optionally in step the metadata capable video player logic locates any existing metadata files and displays a list of the metadata files. Each metadata file may be represented visually in the list using a still image or other graphics file that is referenced within the metadata file. Thus the metadata capable video player logic may generate a display of thumbnail images each image representing an associated metadata file. At step the metadata capable video player logic receives user input selecting a metadata file from the list. For example the graphic images may comprise selectable links and the user may select one of the images using a pointing device. Steps and are described as optional because a selection of a metadata file may be unnecessary if the metadata capable video player logic is invoked by a user or process launching one of the metadata files rather than launching or invoking the metadata capable video player logic independently.

In step the selected metadata file is opened. Each of the metadata files is configured to internally name or reference at least one of the video files . Therefore the metadata capable video player logic reads the selected metadata file identifies the referenced video file and opens the referenced video file at step .

At step the metadata capable video player logic enters a loop that begins when the video player logic plays the video file that was found and opened at step . At step a test is performed to determine whether a cue point has been reached. Step represents the occurrence of an interrupt or other event indicating that a cue point was reached. As an alternative to interrupts step may be implemented by examining stored metadata values relating to a segment and setting timers that cause generic non video events to occur when the video events would have occurred. The timers are adjusted as the user moves among video segments and plays video segments as the amount of time to a given video event changes as a result of such movement. However this approach enables content to play correctly even if the cue points have been removed from the video in the course of transmission or transcoding. For example preparing video for the YouTube online player results in the YouTube system discarding the cue points and the present approaches enable video productions to play properly on YouTube.

The NO control path of step represents continuing playback and waiting until the next cue point is reached.

At step when a cue point has been reached the metadata capable video player logic determines the name of the cue point that has been reached. At step based on the cue point name the metadata capable video player logic reads and executes one or more metadata scripts and or values associated with the current cue point based on functions and behavior configured in the video player logic. Thus in one embodiment the metadata capable video player logic comprises logic or program instructions that define what functions are performed for all cue point types and the metadata files specify cue point types and attribute values that control how the functions are performed such as specific video displays graphical displays user interactions branches links or other control functions.

After step control returns to step to continue playing the current video segment. As a consequence of the processing in step the current video segment after step may be a different video segment than earlier depending on the cue point type and its associated metadata values. As with during any part of the loop from step to step the process of and the metadata capable video player logic may be configured to asynchronously process user input requesting trick play functions or loading other video files or metadata files.

As a result the approach of enables playing a video with a rich set of controls and user interactions including branching to different video segments automatically presenting a user with a branch selection menu and branching to particular video segments in response to user selection determining a branch or different video segment using a web service presenting web content that is related or associated with a video segment and other controls and user interactions. The video file does not require internal modification and can be used with other players that do not provide the controls and user interactions. The controls and user interactions can be authored using an editing process as shown for enabling video producers to rapidly create rich video productions without detailed knowledge of programming.

In one embodiment video linking editor logic uses one or more cue points that have been previously defined for video files on which the video linking editor logic operates in other embodiments as further described herein cue points may be defined independently of the video using the video linking editor logic and are stored in metadata separate from the video files. In an embodiment users create cue points and cue point names using the video editor . For purposes of this document a video is a single piece of video content a file or a URL typically with many cue points within a video each segment begins and ends with a cue point without any cue points in between. A compound segment or inLine segment has cue points within it i.e. cue points in addition to the beginning and ending cue points. An external video specified by a URL may also contain cue points and depending upon their organization these cue points may be segments or compound segments. The player can refer to internal and external cuePoints transparently.

In an embodiment video editor is used to organize one or more video files into pieces each having a cue point at the start at the end and at any point to or from which the current time head can jump. Cue points have an attribute canBeDestination. If this is set to false the cue point cannot be a destination of any action which causes the playhead to jump. Cue points with canBeDestination set to false are typically used as markers for overlaying annotations but where the author does not want that point in the video to be a destination for a chapter jump.

There are also cue points with cue type null . These are used to place markers in the video at precise points that the author may at some future time want to use. Null cue points require less processing. For example when a logger the first and least expensive person in the workflow on professional video shoots logs the shots of the raw footage they can put Null cue points at every shot without adding undue computational overhead. After rendering a step that takes many hours of computation these cue points are all available and can selectively be changed into meaningful cue points like regular or insertPt without re rendering.

A user creates one or more cue points as desired using a cue point tool within the video editor . For example in Premiere a cue point is created by moving an icon representing a playback head to a particular point in the video file and selecting Cue Point. 

In an embodiment a last video segment in a video file is supplemented with a terminal video segment denoted endNote. For example an endNote may comprise short piece of junk video positioned about two seconds after the last usable video segment. The endNote is created with zero cue points to prevent confusion with an automatic invisible cue point that the video editor automatically inserts at the end of the last piece of media. In an embodiment the endNote is positioned about two seconds after the last usable video segment to prevent reaching the actual end of the video file under certain conditions user experience has determined that when the metadata capable video player logic issues a command to pause or stop the virtual head keeps moving for a short time interval.

In an embodiment video linking editor logic is configured to enable a user to define one or more cue points independent of the video for storage in metadata files . A cue point that is defined and stored in metadata rather than stored within a video segment and previously created in the video segment using a separate video editor may be termed a soft cue point. Soft cue points allow the user to insert delete and change the time of cue points directly into a video that has already been imported into storage associated with the editor logic .

In an embodiment a soft cue point is created using editor logic by selecting the Cue tab and selecting an add cue point control . Selecting the add control causes editor logic to create and store metadata for a new cue point at the default time of 00 00 00 00. Selecting the Description tab enables a user to insert a particular time for the cue point. The time can be determined by scrolling through the video using the trick play controls .

In an embodiment a cue point is a named marker for a particular point in a video segment. A cue points may comprise a name a time value indicating the particular point and other metadata that defines what actions occur when that point is reached during playing the video. During playing the video video player logic continuously compares the time value of a current position of a logical playback head within a video segment and determines if the current time value is equal to any soft cue point that has been previously defined and stored in the metadata file that is associated with the video segment. When a cue point is reached the video player logic performs one or more particular operations that are defined in the metadata of the cue point.

In this manner an author can build a complete interactive video experience from existing video files without needing to use complex tools like Adobe Premiere or Final Cut to create cue points. For example an author can select and use video files that are maintained on a third party video server or hosting site such as YouTube and streamed from that server or site to an end user using the video player logic at the time of playback. The video files do not need to have cue points previously defined for and stored in them. Instead the user uses video linking editor logic to create cue points and store the created cue points in the metadata files . The metadata files can be launched and can invoke the video player logic to cause the video player logic to invoke streaming the video segments from the third party video server or hosting site while concurrently performing one or more operations as cue points are reached in playing the video segments.

In an embodiment video linking editor logic is configured to enable a particular metadata file to reference cue points that are defined in other metadata files . In an embodiment a cue point may comprise a contained element termed a target which specifies a cue point by name and optionally links it with an association attribute. An attribute of a target may be a cue point reference which may reference cue points that are in other metadata files. In an embodiment a cue point reference is formed as a URL comprising a file location path file name and a URL fragment that identifies a particular cue point. For example the cue point reference http www.coincident.tv cplfiles foo.cpl DadArrivesHome identifies a cue point named DadArrivesHome within a metadata file named foo.cpl that is stored in the folder or director cplfiles of the coincident.tv domain. In this embodiment in any metadata file definition in which a cue point can be a target for example as the target of an annotation insert point goto cue point or directory or user choice entry that target can be in another file referenced by relative URL.

External cue points beneficially enable authors to work with cue points that otherwise might require multiple other steps to re define for a particular audiovisual work. For example a 2 hour video program might contain dozens of cue points but a particular author might wish to reference only a few of the cue points. The author need not re define the same cue points in a new metadata file for a new audiovisual project but can reference previously defined cue points within other previously created metadata files. Therefore the author can create a cross linked metadata control structure that can simplify video program development based on other files or segments.

The structure and operation of an embodiment of video linking editor logic is now described. In an embodiment video linking editor logic generates and causes displaying a graphical user interface GUI on a computer display unit and the GUI provides cue point editing functions that can be used to link video segments and other content in a plurality of ways. The editor logic is also configured to create and store based on user input interacting with the editing functions and providing selections and values metadata describing the links. In an embodiment the metadata comprises one or more scripts expressed in a Cue Point Language CPL . In an embodiment CPL comprises an XML based language that describes non linear structures in a mixture of video and web media. CPL can be embedded into digital video content that is available from a plurality of sources such as broadcast DVR DVD broadband game consoles. CPL can be associated with web content also. The resulting metadata may be played back with a CPL capable player to create a playback experience that integrates video and interactive web based graphic elements in such a manner that the sequence of playback is influenced by user interaction run time execution of code embedded in the video run time interaction with code referenced by data embedded in the video and calls to remote web services in combination with jump tables authored in the editor and embedded or embedded by reference in the video.

The CPL may be viewed as an architecture rather than a user interface. For example while CPL implements a mechanism for a modal n way branch the author can use that mechanism to provide a video production that is graceful and easy to use or confusing and user hostile. CPL is compatible with a variety of playback platforms asset locations and video formats. For example in emerging systems video content can be viewed using screens that are attached to processors disks or network connections. Platforms may consist of computers game consoles set top boxes or mobile devices. CPL is format independent with the assumption that all digital video formats define cue points and have ways to associate events and text with the cue point. CPL is location independent and can interoperate with video that originates from any desired source.

Video window is configured to play and show one or more video segments representing a linked video project and comprises buttons that are configured to receive user input selecting a playback function and trick play functions such as jumping to different segments that are forward or backward in time. In this context a video project refers to an association of a video file and a metadata file.

Metadata panel receives and displays metadata values that pertain to a project as a whole. In an embodiment metadata panel comprises unique id field video file field and web service field . The unique id field is configured to receive a name number or other character sequence that uniquely identifies the current video project and the unique id value is used in naming the metadata file that the editor creates and associates with a video file and to coordinate dynamic updates with a server. The video file field displays a name of a video file that has been loaded using the File menu and previously created with cue points in a video editor. The name may comprise a pathname in a filesystem accessible to the computer that is hosting the video linking editor logic a URL identifying video in a web server or another form of location identifier specifying a location of video. In an embodiment selecting the File menu item initiates a File Open dialog and after a file selection is made the logic displays a value in the video file field and opens and displays the named video file in video window . Alternatively a user may direct logic to load a previously created metadata file and in response the video linking editor logic locates a video file that is referenced within the metadata file and displays the name of that referenced video file in video file field .

The web service field is configured to receive user input identifying a web service in the form of a URL. The specified web service may be hosted on computer or on a remotely located computer. The web service may comprise a web application or a script file. The web service provides a control mechanism for interacting with insert points overlays and other types of cue points that are further described in other sections herein.

Cue point list is configured to display a list of cue points that have been previously defined in the video that is shown in video window . In an embodiment in response to user input opening a video file video linking logic loads and displays the named video in video window and concurrently reads and displays the cue point data that was embedded in the video file as a result of creating cue points using the video editor. Cue points found in the video file are listed in one or more rows of list and each row includes time of the associated cue point in a time column and a name in name column .

In an embodiment existing web points in the video are displayed in a separate list and cue point annotations are displayed. The form and use of annotations are described more fully in the section herein entitled ANNOTATIONS and in the Appendix and other documents of record in the provisional disclosure.

Further in an embodiment the first cue point in list is automatically selected and highlighted in the list. Video linking logic is further configured to search for an existing cue point metadata file that may have been created in an earlier user session with video linking logic . If an existing cue point metadata file is found then cue point data is loaded and the video linking logic displays in cue point data panel cue point data for the first cue point in list that was automatically selected and highlighted.

Cue point data is configured to receive user input specifying one or more metadata values relating to a particular link or transfer of control associated with one of the cue points in cue point list that is currently selected or highlighted in the cue point list. In an embodiment a user may operate a pointing device such as a mouse or trackball to select other cue points in list and in response to selection of a different cue point the video linking logic automatically updates cue point data panel to display cue point metadata for the newly selected cue point.

Cue point data panel comprises a cue name field and cue time field that reproduce the data shown in cue point list for a selected cue point. Cue point data panel comprises a cue type combo box . Particular types of cue points are described further in other sections below. Cue point data panel is context sensitive so that the particular fields displayed as part of the panel will vary according to the value of the cue type combo box and a content type combo box . For example when the cue type is Regular and the content type is ad Inline referring to an advertisement within a video segment then the cue point data comprises an interest URL field query string field story text field and story picture field as shown in the example of .

Alternatively the fixed content types represented in may be omitted and an author may tag cue points with arbitrary content types as further described in the Appendix.

The interest URL field is configured to receive user input specifying a website or other URL to which a viewer may be directed at playback time in response to receiving input indicating interest in other information relating to the video. The query string field is configured to receive user input specifying a search engine query string which at playback time the metadata capable video player logic may submit to an Internet search engine for the purpose of generating search results in which a viewer may have interest or that relate to the video. The story text field is configured to receive user input specifying a story to display to a viewer using the player logic at the time the video is played. The story picture field is configured to receive user input specifying a graphics file or still image and a text string to display to the viewer using the player logic at the time the video is played.

An example of using the video linking editor logic and interacting with the screen display is now provided. graphically illustrates an example video linking arrangement that can be configured using the mechanisms now described. For purposes of illustrating a clear example describes relatively few video segments and cue points in a practical embodiment the techniques herein can be used to create video projects having any number of video segments and cue points.

The example of represents a non linear video program in which the viewer arrives at a choice point and selects one of three possible videos at the end of the selected video the video project continues with the program. The video project comprises a first program video segment having a start cue point and ending in a modal story branch cue point which is configured in video linking editor logic to permit an N way branch to other video or content but in the example of is configured as a three way branch. A first branch leads to a first video advertisement relating to hair care products. A second branch leads to a second advertisement relating to face products. A third branch leads to a second program video segment .

To create a video project in which the foregoing logical structure is achieved at playback a user activates video editor and authors a video project that includes segments and advertisements in the same video file. The user creates and stores a Flash navigation type cue point with a name at a plurality of locations in the video file. illustrates a screen display in the Adobe Premiere video editor in which a video file has been created with the segments and advertisements and appropriate cue points. After creating the cue points the user saves the video project in Premiere and encodes the video.

The user then activates video linking editor logic and in response the user interface of is displayed. The user selects a Load File function in screen display and selects the video project that was created. In response the video linking editor logic loads the specified video file and displays data for cue points that are found in the file. illustrates a portion of screen display showing cue point list for the video of . Assume the user selects the Start cue point. In response video linking editor logic displays metadata associated with that cue point in the metadata panel . illustrates the metadata panel populated with data for the Start cue point of the example. The user may edit the values in the metadata panel by selecting fields and entering new values or selecting pull down menus.

Assume that the user wishes to create the modal story branch cue point . illustrates the cue point data configured with values from user input that create such a cue point. A name may be entered in the Cue Name field. The Cue Time field is not modified and shows the value obtained from the video file. The cue type is selected as modalStoryBranch. A branch cue type is associated with no content so the Content Type field is grayed out. A Targets list identifies possible destinations or targets to which control is transferred at the branch point. A Background Picture field and Text field receive an identification of a picture to display to the user in a background area while the user is determining which selection to make and a text string that can serve as a prompt.

At any point after creating and storing the metadata file the user may invoke the video linking editor logic reload the metadata file modify the cue points save an updated metadata file with modified cue point data and replay the video based on the updated metadata file. Such updates may be performed without re encoding the video because the video file is maintained entirely separate from the metadata file.

In an embodiment a goto cue point may be defined and at playback the goto cue point causes a jump to another video segment when the play head reaches the cue point. The destination location for the jump is defined in a cue point group cpGroup and discussed below. In an embodiment a goto cue point has the following associated metadata 

An example script code excerpt including a goto cue point which may be included in a metadata file is 

In an embodiment a gotoAutoReturnButton cue point supports a mechanism for the user to obtain more information relating to a particular video. From the gotoAutoReturnButton until the next cue point the player causes the video to be overlaid with a graphical button user input selecting the button causes the player to perform a goto branch operation to reach another cue point with an automatic return. In an automatic return at the end of the more information video segment the player causes the playhead to jump back reaching the beginning of a video segment that just fallows the end of the calling video segment. For example a first video segment might comprise a 30 second automobile commercial 10 seconds into it the user selects the more info button jumps to a 5 minute extended commercial about the car and at the end of the extended commercial the player jumps back to the programming that followed the original 30 second commercial.

In an embodiment an insertPt may be used to include one of several pieces of media at a certain point in time. A selection of one of the pieces of media is made by a call to a web service. When reached the cue point at the end of a target piece of media determines what happens next. The cue point at the end may comprise a returnEnd goto or progEnd cue point.

In an embodiment the media consists of one or more video segments with cueType reg to begin and a returnEnd goto or progEnd to end and one or more web points with cueType webFocus to begin and a valid cue point name specified in the gotoWebFocusEndName attribute.

The group of media points is specified as a cpGroup. The cpGroup must have uniform endings for the segments it contains. For example every cue point identifies a contain segments or compound segments and every segment implies an ending cue point. For a cpGroup all of the ending cue points are either goto cue points returnEnd cue points or progEnd cue points or a mixture of these types of segment ending cue points.

In an embodiment when the player reaches an insertPt the player invokes the web service specified in the progLevelMetadata element described below with an operation specified with the cpGroup. The result of this call is used to select which media to display the target .

For example assume the user has provided zip code information when registering for NBC.com and the user is watching an episode of Saturday Night Live using the player disclosed herein. At an insertPt for a commercial the player calls a web service to obtain the user s zip code. Based on the received zip code value the player selects from among Bronco Escalade and Hummer commercials. In an embodiment the cpGroup is stated in script code as 

In an embodiment the cpGroup is a table of targets in which an association attribute configured as a string is linked to a media point. The result of the web service call a string is tested against the association values until a match is found and the first match is used. The matching function implements a many to one matching as detailed in the cpGroup element description. If no match is found then the association default is checked against the table. If there is no match for the string or for default then nothing is inserted and the video plays on.

In an embodiment the end of a video segment is its ending cue point. With cueType returnEnd control returns to the calling point. A goto end cue point jumps to wherever specified and a progEnd stops playback. In an embodiment the end of a cue point with cueType webFocus is explicitly specified. It is reached by user action back or goto TV . In an embodiment the insertPt cue point has the following metadata attributes 

In an embodiment a modal story branch cue point causes the player to pause the video and to present the user with an n way branch. The user selects an image representing the cue point to go to that cue point. The cue points can be either video or web points. The type for the cue points at the end of the targets are for video is goto or progEnd. In an embodiment the cue point has the following attributes 

In an embodiment illustrates an example screen display resulting from the use of a modal story branch cue point and example script code follows.

In an embodiment an MXML Macromedia eXtensible Markup Language overlay cue point allows use of a web development tool to define overlays with web aware bindings. An example development tool is Flex from Adobe Systems Inc. San Jose Calif. Flex provides for content layout and code within an asynchronous architecture. In an embodiment in the MXMLOverlay cue point MXML code is passed to the player via the mxmlInCPL element in the cue point. The code is executed to make the UI element overlays. For example the metadata capable video player logic is configured to read a MXML user interface markup language script from the metadata file parse and interpret the MXML script and generate and display one or more overlay graphical elements in the video window of the player GUI based on the parsing and interpreting.

User interaction is processed using a web service that is specified in the progLevelMetadata attribute. User interaction with each component such as a button is handled by invoking an operation within the web service named on concatenated with the id property of the component. In an embodiment the operation is called with the data relevant to the component.

In an embodiment tags that descend from UlComponent and RadioButtonGroup within Flex are used. MXML authoring is further described in Adobe developer network documents relating to Flex. In an embodiment the cue point has the following attributes 

In an embodiment progEnd end returnEnd cue points define the end of a video segment and upon reaching the cue points the player stops playing video and does not provide a rewind option. There can multiple progEnd s in a media program.

In an embodiment the returnEnd cue point is used at the end of a segment. Reaching a returnEnd causes a jump to the point that initiated the jump to the start of the segment. In an embodiment the returnEnd and progEnd cue points have the following attributes 

In an embodiment a webFocus cue point can specify a URL for a web point and with a story element associate an image and text e.g. for a call out with the web URL. webFocus cue points can be used as targets in modalStoryBranch cue points and insertPt cue points. webFocus cue points can appear in directories. webFocus cue points can have a gotoWebPointEndName attribute value to specify what to show at the end of a webFocus.

In an embodiment during playback a user indicates that the user is at the end of a webFocus by selecting a back browser function or by selecting a TV button. If the video media is in an operational state the player switches to the video maintaining the playhead time and play pause status. If the video is not in an operational state because for example a zeroLen cue point has been reached the player executes a goto to the media point specified by the gotoWebPointEndName.

In an embodiment a cpGroup is used anywhere a group of cue points is needed. The cpGroups are made up of some attributes and a collection of targetSeg elements. A targetSeg contains a cue point name and an optional association attribute.

Some cue points for example insertPt use cpGroups where each cue point in the cpGroup has an association that is used to select the cue points. In operation the player searches the table to match the string provided as a key with the association attribute and then returns the cue point name contained in the first match. Thus a many to one matching is performed. The key may come from a web service as explained in the insertPt cue point section. As an example with the following targetSeg s in a cpGroup 

ZZZZ or anything or nothing matches D because after looking for the string key the player attempts to match the string default as a key.

In an embodiment a targetSeg may be used to specify a cue point name and optionally associate it with an association attribute. When a group of cue points are needed e.g. a modalStoryBlock where the user makes the choice the association attribute can be omitted. In an insertPt the association attribute is needed to determine which cue point to goto. The association attribute can be of the form aaa bbb ccc where each substring would match the cuePointName. See cpGroup for an explanation of how the association attribute is used to select a cuePointName.

In an embodiment a mxmlInCPL element may be used to hold executable MXML code. There are no sub elements and attributes defined. Instead a user can include anything that descends from the UlComponent in mx MXML. An example definition is now provided followed by comments 

In an embodiment a progLevelMetadata element is required. It contains data associated with the overall program. Example attributes include 

In an embodiment a story element packages data used to display a cue point web or video . Example attributes include 

In an embodiment a gotoAutoReturnButton element and cue point support a more info operation. Example attributes include 

In an embodiment an annotation element is used to display a graphic on screen. The graphic can be actionable. An annotation element is a graphic object that appears on screen starting at a cue point when the next cue point is processed the annotation is removed although it could be reapplied . It is used to overlay the display with a graphic while in video view and may optionally implement a goto behavior in response to a click. The structure of the annotation element is similar to cuePoints in that it contains the same targetList and story elements. Clicks on an annotation can cause three things to happen depending on the value of the clickBehavior attribute. See the attribute description. Example attributes include 

In an embodiment an audiovisual work may include one or more annotations that specify interactions available to a viewer. Annotations may comprise graphical images buttons text messages labels and other elements that may be displayed in a variety of locations overlaid on a video segment or near a video player window that is showing a video segment. One or more annotations may be assigned to a cue point when the cue point is reached during playing the annotations are activated and remain active until the next cue point. Annotations have flexible attributes relating to where they can be shown what they can show and how they behave. Graphic images associated with annotations may include images such as PNG and JPEG files or SWF files or any other files that can be rendered on the system on which the player logic is hosted.

In an embodiment an annotation has one of four types decoration goto returnEnd and overlay. Details of annotation types are disclosed in the Appendix. Annotations may be displayed as static graphical images or animated graphics. Annotations may be positioned anywhere in the video windows that the player logic displays during playing.

In an embodiment annotation frames allow placement of an annotation outside of the video window an annotation frame can provide a larger area outside the video in which annotations can appear without covering up the video. In an embodiment a user may use the video linking editor logic to define an annotation frame as a rectangle within which the video window is placed. If the annotation frame is larger than the video frame then space is displayed around the video and annotations can be placed in the resulting space without obscuring the video. With annotation frames an author is not required to re encode a video segment to create space to place annotations.

A goto annotation may be associated with a target and one of several different kinds of return behavior a target specifies where the player branches when a viewer clicks on the annotation and the return behavior specifies where the viewer returns after viewing the video or web page associated with the annotation. For example the return behavior of a goto annotation may be set to Skip. With skip on return behavior after a viewer returns from the annotation s target video segment or web point the player skips to the next cue point after the one that includes the goto annotation.

An annotation of any type may be configured with modal behavior. A modal cue point has two different playback modes comprising an initial entry mode and a return or overlay completion mode. When an annotation is modal each annotation type causes the video player logic to operate differently depending upon the then current mode as defined by how the player arrived at the associated cue point. For example initial entry mode refers to the player arriving at the cue point via normal program flow or as the result of a direct jump. In initial entry mode the video player logic is configured to display all annotations that are configured as modal pause and wait for the user to select a non decoration annotation such as a goto annotation or a returnEnd annotation. In contrast return or overlay completion model occurs when the player returns to the cue point via a returnEnd cue point or annotation after a jump from it or when a viewer selects the Continue button to close an overlay data entry form. Further details are provided in the Appendix. 

In an embodiment external data may control which annotations or overlays are played back. In various embodiments external data may be used to control a level of user interactivity with an audiovisual work or to selectively display annotations such as subtitles in particular foreign languages. In an embodiment an author uses a switched annotation identifier to set up switched annotations and also specifies two or more different annotations to display based on the value of an external data item. At playback an external data value is obtained and the user experience changes depending on the value of the external data and the particular switching path specified by the switched annotation identifier for that external data value. Thus the term switched annotation refers to the fact that any annotation as otherwise disclosed herein may have its visibility on the screen determined by the value of a key in the data store thus the annotation can be switched on or off using its associated key.

In an embodiment a switched annotation may be used to include or display one of several annotations at a certain point in time. A selection of one of the annotations is made by a call to a web service. A switched annotation may be implemented using the techniques described above for the insertPt cue point except that the switched annotation affects display of annotations rather than pieces of media. In an embodiment when the player reaches a switched annotation the player invokes a specified web service with a specified operation. The result of this call is used to select which annotation to display the target annotation .

In an embodiment at a given cue point the properties of a switched annotation are controlled by a key. The key acts as a control variable and can be local to the CTV content or can be external to the CTV content and reached by for example an HTTP request. In an embodiment at every cue point and every annotation when clicked code can potentially execute.

As an example assume that the key is labeled Language and can take the value English French etc. When an audiovisual work is played in rendering the annotation the player examines at the key to determine which annotation to show. The author has previously defined an annotation value corresponding to each possible value for the key or key value. For example the following table associates example Language keys with example annotations 

Assume that an audiovisual work is playing and reaches a particular cue point for which a switched annotation has been defined. illustrates a screen display in schematic form that could be displayed at a particular cue point. In the example of a character is displayed with the subtitle I am here in English. The screen display also includes icons representing annotations labeled English and French and having highlighting coloring or other graphical indications that the English icon is enabled and the French icon is disabled. Assume that the user selects the French icon by directing a mouse cursor to it and clicking. In response the key Language is set to French and the screen is redrawn so that the subtitle Je suis ici appears in place of the English subtitle.

Alternatively the key may be set by issuing a Web Services request that returns a string value of English or French . In an embodiment the annotations that are represented by icons for selection of the language are also switched annotations. For example a first annotation may be labeled FirstLanguage and may receive its value from a Web Services request or from a previously defined table of values.

Switched annotations are defined and operate in a manner similar to the insertPt cue point type that is described elsewhere in this disclosure. However an insertPt cue point type is used to pick which video segment is inserted at playback at a particular cue point and a switched annotation is used to select which annotation to use at a particular cue point.

In an embodiment a switched annotation is implemented by including in a CTV file or other metadata that defines an annotation a filter tag. The filter tag has two attributes key the name of the variable in the datastore to match against value the pattern to match against. The annotation is displayed if the value of the keyword in the datastore is contained within the value attribute string.

For example if the value in the datastore is bike that value match the filter value bike bike default and car bike but not b . As a convenience if the datastore does not have a value for the given key the string default is used as the value.

In an embodiment the audiovisual experience authoring platform described herein is integrated into a social networking platform such as Facebook.

1. While watching a video as shown in player window a user can log in to Facebook from within the player and post a comment on what the user is seeing. For example player control bar may include a graphical icon which when selected causes issuing a network request to the Facebook server to perform a login sequence and causes displaying a panel in which the user can enter login details.

2. Images representing comments of the user or the user s social networking friends on a particular video are shown at the point in playback that corresponds to what the user was watching when the comment was posted. In an embodiment player window includes a set of thumbnail images . Each thumbnail image is obtained from the Facebook social graph. Each thumbnail image represents and identifies a comment that was made at that point in the video by the Facebook user who is depicted in the thumbnail image. As the video plays the set of thumbnail images moves across the screen from right to left. Thus when playing the video advances to a scene that is later in time than a particular comment the thumbnail image associated with that comment will disappear to the left side of the player window and new thumbnail images will come into view on the right side of the player window. The images on the right side represent comments that were made about later points in the video. The thumbnail images that appear at or near the center of the video as in the case of images represent comments that were made at the current playback point of the video.

3. When multiple users have entered comments at the same time point in the video the thumbnail images are displayed in a stack as seen for images . Rounding of time point values may be used so that multiple comments within a range of a few seconds will appear in an ordered vertical stack at the same position.

4. In an embodiment a message window may be displayed in a screen position near the player window and may receive a message from the current user to another user of a social media system. In an embodiment the player and server computer are configured to send network requests that post messages or short messages such as Twitter tweets to the social media system social graph or short message service such as Twitter and are configured to poll for or automatically receive messages or short messages from the social graph or short message service. Consequently in an embodiment if another user sends a live comment at the time that the current user is viewing the video then the player window also shows such live tweets and comments as indicated for example by tweet .

In an embodiment hovering a cursor associated with a pointing device such as the arrow cursor seen in causes the video player logic to retrieve and display a comment or tweet that a user indicated by the associated image had previously made. In other words each image may represent a comment and hovering over that image causes the video player logic to retrieve the associated comment from the social graph and display it as seen for tweet .

In an embodiment selecting one particular friend opens up private messaging to that friend for example using message window . Alternatively selecting an icon in the display of adjacent to an image that has cursor focus such as the icon of creates a new image stacked above the prior image and opens a bubble or other graphical widget that accepts a new comment from the current user.

5. The color and opacity of the thumbnail images may indicate the time of posts. For example a thumbnail image that is displayed in partly transparent form or grayed out rather than in full color may represent a post that was made at a much earlier time.

6. Virtual goods may be displayed in association and allow for game like interactions. For example images representing virtual goods may be displayed over screen display . illustrates an example of the screen display of in which data relating to virtual goods is displayed. In an embodiment virtual goods images indicate one or more virtual goods that the current user has purchased and each image may be associated with a stored comment from the current user that is displayed when the cursor associated with a pointing device hovers over a particular image. A total message may indicate a total amount of virtual goods associated with the current user. For example the message Bruce s Fox Buck 10 indicates that the current user Bruce has purchase 10 units of virtual currency denoted Fox Buck . A virtual goods option region may display image icons representing available virtual goods and the cost of the available virtual goods. In an embodiment selecting one of the virtual goods in region causes the video player logic to initiate a purchase dialog that can debit funds from a previously established account of the current user or obtain payment information after completing a payment transaction the video player logic updates the screen display to show a new or updated image and message .

7. Displayed friends may be filtered using switched annotations. In an embodiment each of the thumbnail images is a switched annotation that is displayed in the player window or not displayed based on the current value of a filter key. In an embodiment the video program displayed in the player window is associated with metadata that defines an annotation that displays one or more filter tags with associated radio buttons. Selecting a particular radio button causes annotation in response to set the value of the filter key to the selected value.

For example as seen in the filter key may be labeled FilterTag and may be defined as receiving values friends from CTV friends from Cal friends from SHP friends from SF. Further a particular annotation defining friend David may have the following filter tag defined 

Selecting the radio button labeled Friends from CTV causes setting the value in the datastore of the key FilterTag to friends from CTV. Thereafter the filter tag defined for David will match the current value of the key FilterTag so David s image will be displayed. The player logic is configured to display a particular annotation for a particular one of the thumbnail images only when the current value in the datastore of the filter key specified in that particular annotation matches one of the values that are also defined in the filter tag for that particular annotation.

Although the examples above specify a single value in the filter tag for an annotation other embodiments may use lists of multiple values. Thus for example David could be defined as both a friend from CTV and a friend from California by appropriate definitions in the filter tag. Definitions in the filter tags may be constructed programmatically by the server computer in response to querying the social graph for the current user. For example the player logic may be configured to perform in response to determining that the user has logged into a social media system such as Facebook issuing a query to the social graph to retrieve a list of the user s friends and attributes of the friends such as group membership or location. Based on data received in response to the social graph query the player logic may generate and store metadata on the fly that defines an annotation for each friend and defines a filter tag containing matching values for each attribute of that friend that has been obtained from the social graph.

The result is that only thumbnail images corresponding to the selected value in the filter tag annotation are displayed in the player window and as the value selected in the filter tag annotation changes the displayed thumbnail images turn on and off in accordance with whether the key is matched.

In step the computer is caused to play the video program from the link. At step during playing the video program on a computer the process detects that the video program is playing at the specified time point. At step in response to the detecting for each particular annotation among the annotations for the specified time point the process obtains a current value for the key. In various embodiments obtaining a current value for the key may comprise issuing a query to a database directory or other data store. In other embodiments obtaining the current value of the key comprises issuing a Web Services request and obtaining the current value of the key from a response message that is received in response to the Web Services request. In yet another embodiment obtaining the current value of the key comprises issuing a Web Services request and determining the current value of the key based on one or more values in a response message that is received in response to the Web Services request.

At step the process causes the computer to display the graphic image associated with that particular annotation only when the current value of the key matches one of the matching values of one of the filters of that particular annotation. When displayed as with other annotations disclosed herein the annotation is displayed in the video player window at a particular position size and with other attributes as otherwise defined in the annotation.

Using the techniques herein a video program played on a computer may be supplemented with graphics links references to code or programmatic calls that are selectively displayed based on the value of a stored key. In this manner annotations to the video program may be switched on and off to yield a variety of graphical experiences and provide for a dynamic changing video experience that can respond to user input and implement many useful services.

A content type value associated in metadata with a cue point causes differentiated operation of the metadata capable video player logic at the time of playback. In particular within the player the content type zeroLen is treated differently than all others ad Inline segment Inline prog Inline prog Segment . For example ad Inline and ad Segment are used to skip advertising content coming back from an insertPt.

In an embodiment a computer program can create one or more cue points and store the cue points in a metadata file rather than a user obtaining cue points from encoded video or the user creating the cue points using the video linking editor logic . In an embodiment cue points can be added updated or completely replaced dynamically using web applications processes or other computers that are coupled to computer . For example the unique identifier of a television program as specified by Society of Cable Telecommunications Engineers could be used in an update message providing new cut points.

In another example one or more computer programs can access video and other content databases and use the information gather to generate interactive video experiences based on the cue point language schema that is defined herein. As one example a Perl script may be configured to access YouTube metadata APIs to construct an interactive video experience based on playing all video matching a particular keyword. In this example the script may be configured to issue an HTTP based query to a YouTube server in which the query conforms to YouTube s APIs to retrieve a list of all stored videos that include a particular keyword in the metadata maintained by YouTube for the stored videos. In response the YouTube server sends a responsive dataset. The script may be configured to identify a URL for each video on the YouTube servers that is identified in the responsive dataset and to write a metadata file that specifies an audiovisual program consisting of a concatenation of all the matching videos. The script could be configured to automatically generate a plurality of annotations in which each annotation graphically represents a first frame of a different one of the matching videos. In this manner at playback the user would see a visual menu of each matching video and could activate any desired video by selecting on the image associated with an annotation for one of the videos.

In another example a program is configured to receive a user query for a particular keyword or phrase and to search a database of movie metadata for matches to the user query. For each match to the user query an associated database record is selected and retrieved. From each database record the program retrieves a URL of a video that is stored in third party hosted storage such as YouTube. The program creates and stores a metadata file that plays the matching videos. For example the program could be configured to receive a user query to find all video clips in which a character says Bond James Bond assuming such phrases are represented in the database of movie metadata.

In another example a computer program may be configured to create multiple metadata files based on a single video. For example a Perl script may be configured to generate multiple versions metadata files for a single video in which each metadata file comprises definitions of annotations for subtitle data in a different language and the subtitle data is displayed at playing time using the annotations as the subtitle display widget. Additionally or alternatively automatic creation of cue points may take user behavior into account to create customized cue points for a particular user based upon what is known about the user s behavior as represented in server side stored data. User behavior can include information what previous cue points have been selected the elapsed time between selections whether certain video segments have been skipped navigation paths as represented by user selections of different video segments in succession etc.

Thus embodiments provide flexible means to use output from a database coupled to a script or other program wherein the output is optionally selected based on matching user input or queries to result in automatically creating and storing one or more metadata files which when played using the video player logic result in displaying enriched interactive videos. While certain examples have stated that the program may cause displaying a concatenation of videos matching a query concatenation is not required. Instead a program or script may have any level of complexity and may be configured to write a metadata file consisting of any number of cue points annotations or other information based upon the language description that is provided herein. In this approach metadata may be created dynamically and transmitted to the player over a network connection without storing or saving the metadata in file format. Further the examples provided herein are merely representative and countless other applications are possible.

A directory comprises in one embodiment a selectable scrollable column on the right part of the video display that appears at cue point boundaries and for a specified period of time such as four 4 seconds in response to a movement of a pointing device. illustrates an example screen display that includes a directory.

Player logic attempts to generate and display a cue point specific non modal directory on a cue point by cue point basis. The media points video and web within the directory are specified as a cpGroup and must contain story elements if they are to appear in the directory. These points can be whatever the author chooses to make them and are an opportunity to guide the user into interesting tangentially related information. For example in a news show when a story about Great Britain is shown the directory could contain the related online encyclopedia entry and several video segments when the news program shifts to the next story the cue point specific directory changes.

In one embodiment web services may be implemented using a ColdFusion web server. In an embodiment web services are called with two string arguments comprising the called operation or function and the type of service. The web service returns a string with three fields comprising an operation specific field e.g. serviced for MXMLOverlay calls a result and the type of service string.

In an embodiment an author may customize the positioning of a video window and a web window within an overall player window. In an embodiment dynamic layout is accomplished through user interaction with the video linking editor logic .

A user selects a Dynamic Layout feature under a Layout tab of an editor screen display as seen in . illustrates an example screen display that the video linking editor logic generates and causes displaying. An author selects a window size for the video to be displayed as part of an enriched video program. For example a window size may be 1024 pixels wide by 763 pixels tall. Generally a user selects a new layout control to create a new layout and assigns a unique name to the new layout. The author selects a Positioning function and may select one of a plurality of predetermined layouts of the video window web window and static surrounding graphical display space. The user may change the size of the video window or web video using an Advanced tab function. The user may change dimensions in pixels for video width video left position video horizontal center position and video right position. The editor logic stores the changed values in association with the layout name. Changing numeric values of dimensions later results in changing the position of a video window when displayed using the player logic. Each layout may have restrictions on repositioning based on the original layout in an embodiment the editor logic prevents the user from entering data for parameters that do not fit a particular layout.

In an embodiment example Editor window comprises a Layout tab that displays a list of names of selected layouts. Selecting an Add Layout control causes the editor logic to add a new layout name to the list. In an embodiment logic can access stored data defining a plurality of predefined player window layouts which are displayed in an information panel . In each predefined layout a relative size and position of a video window to be shown in the player window is indicated by a rectangle having a first color and a relative size and position of a web browser window to be shown in the player window is indicated by a rectangle having a different second color. In some layouts the video window has a reduced size as compared to a size of the browser window. In some layouts the video window is the same size as the browser window. In some layouts a background is defined that is logically behind or surrounds both the video window and browser window. In some layouts the video window is laterally or longitudinally adjacent to the browser window. In some layouts the video window is offset in a corner of the browser window or centered.

In an embodiment selecting a predefined layout from panel causes editor logic to display an enlarged view of the selected layout in which the relative size and position of the browser window and video window are shown. The author also can further customize the layout to obtain different effects using the parameters accessible using an Advanced tab of the editor window as shown in panel .

A layout may be linked to a particular cue point. In an embodiment a user selects a Cue tab in the editor screen display and selects a cue point to link to the layout. The user may select a Description tab in a Parameters pane and select a Browse button next to the Web View Layout and the user may select the Layout that the user created.

In this approach an author has control over the location of a video window and web window. Further a particular layout that the author deems aesthetically preferable for a particular combination of video and web content may be injected into the metadata so that the layout changes appropriately when a particular cue point is reached.

TABLE 1 presents an example of a complete metadata file of the type that can be created and stored as one of the metadata files .

In an embodiment the base element is MediaProgram and encloses all other elements. The element progLevelMetadata is required and specifies information that applies to the whole MediaProgram. In the sample code above in the cue point named B the cueType is insertPt which jumps to a cue point in this case D while establishing a return point. In B the target segment is specified within a cpGroup a cue point group in this case it has only one target and the association attribute is default . There is nothing to check and there is only one place to jump. In E the target segment is a cueType returnEnd which means it will return to where it came from rather than goto another target . Further anytime that no video immediately follows a cue point the cue point has a contentType zeroLen cue point C is also zeroLen .

In various embodiments the player screen display may be implemented as an application that is displayable within a web browser or using standalone application program logic in either case the player is not video specific and will work with various existing video formats Flash Silverlight QuickTime etc. and can be adapted to new video formats as they are defined.

Computer hosts or executes an operating system that supervises I O storage management and execution of application logic. In an embodiment computer optionally comprises a video editor as indicated by broken lines the video editor may be omitted. In an embodiment computer comprises a browser that hosts or can access a support library . Commercially available examples of support library include Macromedia Flash and Silverlight.

In an embodiment computer is coupled to storage which broadly represents any data storage device storage area network SAN network attached storage NAS or network file system NFS unit or server. Storage may reside on network or on a server coupled to the network. Storage stores application programs but is not required to store video files or metadata files instead video files may be received through streaming video delivery from file server and metadata files may be received on the fly directly to browser or support library under control of an instance of metadata capable video player logic .

In an embodiment computer optionally comprises video linking editor logic which may be omitted entirely as indicated by broken lines. In an embodiment a separate player control server comprises metadata capable video player logic and may comprise accounting logic . The metadata capable video player logic is generally configured to open metadata files and associated video files and to play the video files while interpreting and responding to links and related information and instructions in the associated metadata files. Other more specific functions of metadata capable video player logic are described in other sections herein. In an embodiment player control server controls delivery of instances of the player logic to authorized clients and in certain embodiments interactions with accounting logic determine whether a particular client in the form of computer can receive an instance of the player logic. Additionally or alternatively accounting logic determines amounts for invoices other billing or other charges to a video producer studio content owner or other party that owns or controls the file server and its contents.

In another embodiment computer comprises player logic and does not have an editor such as editor logic such an embodiment might be used by an end user who is viewing video programs that have been prepared by someone else and who does not use a browser to view video programs based on receiving the player logic over a network from a server computer as described above.

In one embodiment an end user or viewer invokes browser and connects to web server which offers links to play audiovisual media such as video files . The viewer selects a link for a particular video file . In response the browser downloads from the file server one or more elements of HTML and browser executable program code such as JavaScript code which the browser executes. Consequently the browser renders a page in the display unit of computer . The rendered page includes code to invoke an instance of metadata capable video player logic . The player logic accesses one or more metadata files and accesses video files . The video files may be on file server or stored in another networked location or on a third party server or quasi public hosting site such as YouTube. Based on instructions in the associated metadata files the player logic then streams the video files and provides metadata from metadata files to the support library of browser . As a result one or more of the player screen displays described herein appears and can play video within the browser in the manner described herein.

In an embodiment each time that browser invokes use of the player logic data is recorded at the player control server or at a third party server site to indicate the invocation. Invocation data may include data identifying a referring web site that is the web site at which the end user selected a video for playing such as web server . Invocation data also may identify a producer of the video if the producer is different than the owner or operator of the referring web site.

In an embodiment the end user of computer may be denoted a first party a second party may own or operate web server at which the first party selects videos for playing and the second party may comprise a producer of the videos and a third party may owner or operate the player control server and may control delivery and use of instances of the player logic and may be entitled to payment from the second party for each use of the player by the first party or each stream that the player facilitates delivering from the second party to the first party. Thus a copy of the player logic or other browser executable code may be delivered from the third party to first party browsers only a specified maximum number of times per day week month or year in consideration for payment of a specified fee attributable to each day week month or year. In an embodiment if the specified maximum number of first party video player invocations is reached then the third party may cease providing additional first parties with access to the browser executable code that implements or accesses the player. Additionally or alternatively the third party may deliver the browser executable code to an unlimited number of first parties who select videos at the second party s web site and may invoice the second party for a variable amount that is based upon or proportional to the actual number of first parties.

In this arrangement the invocation data is recorded in a database that is owned or operated by the third party. The third party configures one or more computer programs to periodically analyze or compile invoicing data from the database based on the number of streams that the second party delivered using the player or the number of first parties who connected and used the player. Based on the data analysis or compilation the third party may invoice the second party. In all such arrangements the third party retains control over use of the metadata capable video player logic and its use by second party producers or first party end users and the third party is entitled to collect fees or revenue from one or more of the second party and or the first party in consideration for the use of the metadata capable video player logic to provide enriched videos to end users.

In another embodiment computer logic and a video display unit may form a special purpose computer performing the functions described herein.

In one embodiment a player as in comprises a video display window a control bar comprising trick play icons a timeline and a web hyperlink . The video display window displays a video segment of a media program. The trick play icons may be selected through user input from a pointing device or remote control. In one embodiment trick play icons provide functions for video playback fast forward at one or more speeds and rewind at one or more speeds. Other controls may be provided including an end playback or eject control an audio volume adjustment control and a video window size control.

In an embodiment the timeline provides a graphical indication of the player s current position within a video segment the position of cue points and the relationship of branches to other cue points and other video segments. For example in one embodiment the timeline graphically displays cue points as dots or circles branches to other cue points as arcs and video segments as straight lines. The lines dots and arcs are arranged in a temporal order so that the first video segment is arranged at the far left side of the display and the last cue point of the last video segment to which a branch can occur is displayed at the far right. As the player plays video a graphical icon in the timeline moves from left to right in proportion to the time that has elapsed during playback or the amount of video that has been played. As cue points are reached and branches are traversed the player logic modifies the video display unit to update the timeline to indicate a user s current logical position in a media program as a physical icon shown among the lines arcs and dots. Therefore the timeline enables a user to visually identify upcoming cue points branches and branch destinations.

In an embodiment web hyperlink is continuously displayed in the screen display in an overlay manner over any video program that is shown in video window . Thus the web hyperlink is always available during operation of the player logic . In an embodiment selecting the web hyperlink causes the player logic to modify the display unit so that the video display window is redisplayed in a reduced size format for example in a small rectangular window at the bottom right corner of the screen display. Further the video display window is overlaid on a web browser window that displays web content associated with the web hyperlink . In this manner the player logic appears to generate a picture in picture form of display in which the background picture shows web content and the foreground reduced size picture shows the video program. The video program continually runs during such a transition.

In an embodiment the screen display of further comprises a TV button which when selected causes the player logic to restore the video display window in a large size as seen in and to discontinue displaying web content.

In an embodiment computer uses either a remote control or a computer keyboard to provide user input to the metadata capable video player logic .

In an embodiment user input selecting hot keys on the keyboard results in controlling playback. In an embodiment the following key commands cause the metadata capable video player logic to perform the following functions 

Various embodiments facilitate production of enriched audiovisual programs that combine Internet web content and video content. Examples of playback applications are now described.

In an embodiment buttons may be associated with an HTML document that applies a specialized appearance or skin to the buttons . In an embodiment skinning buttons is performed using the editor logic to display editor window selecting the Metadata tab selecting a Skin Buttons field and entering an HTML URL. With button skinning buttons may have a different appearance in different videos at playback for example comparing shows buttons with different styles and appearance.

Player window includes an audio icon which when selected causes muting sound from the video and a full screen icon which when selected causes displaying the video in full screen mode. In response to appropriately defined annotations and cue points associated with a video program which in this example is an excerpt from a program named The Hills metadata capable video player logic causes displaying an annotation that prompts a viewer to enter a viewer s name phone number and gender in data entry fields and using radio buttons. In an embodiment when a viewer enters values in the fields and selects the Go button metadata capable video player logic temporarily stores the values in memory for referencing and use by other logic when a particular cue point is reached that calls for invoking a text messaging function.

In an embodiment show and character icons each comprise a graphical image that is associated with an annotation. In an embodiment a first one of the show and character icons is an annotation associated with a URL for a web site of the show which in the example of is the MTV show The Hills that provides further information about the show. In an embodiment second and third ones of the show and character icons each comprise annotations that are associated with sequences of video segments relating to the characters that are depicted in the icons. In the example of selecting the Heidi icon causes the metadata capable video player logic to branch within the associated metadata file to a point associated with a sequence of video segments that feature the character Heidi. Playing the video program then continues with the sequence of segments that feature Heidi. Similarly selecting the Audrina icon causes the metadata capable video player logic to branch within the associated metadata file to a point associated with a sequence of video segments that feature the character Audrina. 

In an embodiment web site icons provide linkages to Internet sites that feature social networking and other services. For example in an embodiment the video linking editor logic may be used to create an annotation symbolized by a Twitter icon which is associated with the Twitter service and a web service to invoke the Twitter service. Thus in one example embodiment at playing time when a viewer selects the Twitter icon the metadata capable video player logic generates and displays a new window that contains a feed of Twitter posts relating to the video program of . The other web site icons similarly each comprise an annotation that is associated in metadata files with a web service URL or other reference to executable code that can cause integration and use of the web service that is represented by the icon.

In an embodiment each of the service icons is an annotation represented by a graphic image that provides access to an external service or web site. For example in one embodiment a music purchase icon may comprise an annotation that is associated with a web site that features downloads of songs as further described herein for . In an embodiment a commercial sponsor icon may comprise an annotation that is associated with a commercial advertising web site or online information about a commercial product. Additionally or alternatively the target of an annotation that is displayed as a commercial sponsor icon may be a video program segment comprising a commercial for a specified product. In the example of selecting the Dos Equis service icon causes the metadata capable video player logic to branch to and play a video segment containing a commercial for Dos Equis brand beer.

In an embodiment when a particular character is selected as a favorite character then the video segments featuring that particular character are also authored to include annotations identifying the other non selected characters for possible future selection. For example as seen in in a video segment in which Spencer has been selected as featured character the show and character icons display only icons for annotations associated with other characters namely Audrina and Heidi.

In contrast illustrates a frame of a video segment in a sequence for which Audrina is the featured character therefore show and character icons depict Heidi and Spencer but not Audrina and the icons are associated with annotations which when selected cause playing sequences of video segments featuring Heidi or Spencer respectively. also illustrates different service icons in which a third service icon is associated with a different commercial product or retailer. Thus an author using video linking editor logic may define different annotations in the position of service icons for different commercial products merchants retailers or other web sites or service providers in association with different cue points arising at different time points in a program. For example an annotation associated with a graphic image or icon depicting a first merchant or product may be associated with a cue point at the start of a first scene of a video program that somehow involves uses or shows the associated product which a second merchant product or service may be associated with a second cue point at another point in the program that shows uses or involves the second merchant product or service.

For example an author using the video linking editor logic may define a cue point at the frame shown in which is from a title scene in the show Glee that depicts the names of actors who portray characters in the show. At the frame of the name of actor Cory Monteith is displayed. A cue point may associate the time of that frame with a URL for an Internet Movie Database IMDB page containing information for the named actor. As the video continues to play in video window the metadata capable video player logic may reach other cue points referencing other URLs. At each cue point the metadata capable video player logic accesses a referenced URL and causes the browser window to display the referenced web page. In this manner cue points defined for a video segment can cause web content to be pushed to a browser window that underlies the video window. Content in the browser window thus changes dynamically as the video plays and as specified cue points are reached by the player.

The foregoing applications and others provide the capability to display video over web content or to display web content in association with video in entirely new and different ways. As a first example embodiments provide the capability to display video in a picture in picture layout in which a video plays in a video window that is reduced in size in comparison to a browser window that is concurrently showing related web content. The metadata capable video player logic is configured to allow the end user to watch video and scroll web content in the same screen without tabs or special windows. The author of the metadata files for the program has control of whether the video in video window plays or pauses and what is rendered in the video window and the browser window .

For purposes of illustrating a clear example shows a first rectangle comprising video window and a second rectangle comprising browser window . In other embodiments any number of rectangular display areas for video or browser content may be provided.

As another example annotations can be configured so that invoking the Twitter web site icon causes the metadata capable video player logic to display a third rectangle to the right of the video window while maintaining a display of the browser window conceptually behind the other rectangles or windows. The third rectangle displays a feed of Twitter posts using HTTP data transfers and rendering of HTML within the third rectangle. In this manner a streaming video may be played at the same time that an HTML window is dynamically updated. Both the video window and the browser window have equal conceptual weight within the player window .

The chapter selection images each represent an annotation that is associated with a branch to a different cue point in the video program associated with a different video segment for a chapter episode or other discrete video element. During playing selecting one of the chapter selection images causes the player logic to branch to and start playing an associated video segment.

The example of indicates an aspect of the flexibility inherent in the concept of annotations as described herein. Both the icons can be represented using annotations that define different positions graphic images and operational behavior. However even though the annotations are different an author is not required to learn and use a large number of different programming techniques instead the same features and functions are used to define all the annotations.

The web integration icons each represent an annotation that is associated with a static graphical image and an interactive operation relating to web content. For example a Facebook icon represents an annotation that defines a link to a Facebook page for the program shown in the video window . During playing the program in the video window selecting the Facebook icon causes the player logic to redisplay the video window in smaller form and to access and display a Facebook page for the program in a browser window that is conceptually or logically under the video window . The topic launch icons represent annotations that define branching behavior to other video program segments relating to topics such as costumes used on the program or show and the history of the show. Additionally or alternatively one or more of the topic launch icons may be associated with a web page thus selecting one of the topic launch icons can result in either playing a video segment or displaying web content in a browser window under the video window.

In an embodiment menu access link represents an annotation associated with branching behavior that causes the player logic to branch to code in a metadata file that causes displaying a list or menu of a plurality of video program episodes that are collected or associated with a subscription. In an embodiment during playing selecting the menu access link causes the player logic to display a video window having the form of .

An available episode icon represents an annotation that is associated with a static graphical image representing the particular episode and associated with branching behavior that causes the player logic to play the particular episode in video window replacing the icons . An unavailable episode icon represents an annotation that is associated with a static graphical image or decoration representing the particular episode that is unavailable. As decorations unavailable episode icons are not selectable and not associated with branching behavior or other action. In an embodiment the graphic images associated with unavailable episode icons may include an episode name and release date for the purpose of attracting viewer interest in future program material.

Thus multiple different kinds of annotations can be authored and associated with different graphics branching behavior and targets including static graphics and video programs. Annotations also can cause playing pages that consist solely of other annotations to await selection of one of the annotations to cause other navigation or to cause playing various program materials.

The browser window may include a scroll bar that is movable in response to user input from a pointing device such as a mouse touchpad or trackball. The scroll bar is scrollable to cause the web page in browser window to scroll up or down independent of the video window .

The browser window may comprise a plurality of browser navigation buttons . In an embodiment the browser navigation buttons include forward backward and magnification buttons. Selecting a backward navigation button causes the player logic to redisplay in the browser window a most recently displayed previous web page. If the most recently displayed previous web page was generated when the player logic was playing a different video program then it is possible that using the backward navigation button may cause displaying a web site that is unrelated to the current video program.

Thus in the example of a viewer who selects a page link for fashion critic Tim Gunn causes the player logic to access and display a web page associated with Tim Gunn in a separate browser window in the manner shown for . illustrates an example of displaying a separate browser window below or behind the video window of the player window . As in C the browser window is scrollable independent of the video window the video window is automatically displayed in a reduced size representation and the video window may be restored to fully occupy the player window by selecting a full screen icon in the video window.

If the viewer selects one of the video links player logic branches within the code of a metadata file and causes playing an associated video segment. In the example of the associated video segments may comprise commercials or infomercials associated with brands products or merchants but in other embodiments the video segments may be noncommercial.

In an embodiment voting buttons also represent annotations that cause the player logic to invoke a web service that communicates a vote indicated by a particular voting button to a vote collecting server. Thus provides an example of how annotations may be used to link a viewer through interactive services to Internet servers that collect information or perform specified actions.

In an embodiment HTML and HTTP may be used to display a graphical format termed a skin for the player window for a background area of the player window and for various user interface elements such as annotation icons. In an embodiment graphical backgrounds skins and UI elements all can be defined for and thus synchronized at any one or more of video cue points a metadata file that describes a collection of video segments that are rendered into a single file or a folder directory or collection of metadata files making up a complex media presentation.

For example an author can configure cue point level synchronization to show character background information as different characters come on stage. The author can use file level synchronization to have different backgrounds for commercials as compared to program content. The author can use folder or directory level synchronization to change the color scheme used in backgrounds windows and other UI elements on an episode by episode basis. In this context UI elements include annotations and associated graphic images.

In an embodiment a user may specify an HTML file to display in the background as the video is playing. In an embodiment specifying a background skin is performed by a user accessing a Metadata tab of screen display as seen in .

Metadata tab also displays and allows user entry of values for other parameters for other player functions that are described further herein. As an overview a Video File field identifies a filename of a video file with which the user is currently working and that is associated with the other metadata. A Video Size field identifies a size in pixels of a video window generated by the player logic and that will display the video program at playback time. A Web Service field displays a reference to a web service that can be invoked at one or more cue points to provide external functions or processing. A Coincident Web Point field may receive user input of a synchronized web reference to display at a particular cue point. A Skin Buttons field may receive a reference to an electronic document that defines an appearance for play and trick play buttons of the player.

In an embodiment video linking editor logic may be used to author and configure for playing using metadata capable player logic a live refreshable collection of media with navigation metaphors. A subscription video collection differs from a traditional magazine or program subscription in that time is an element of authoring thus the media elements that are available to a subscriber change over time. The media elements change over time not in the sense of an animation which involves changes frame to frame but for a season of a show. In a subscription video collection as provided herein the subscription may feature mixed HTML and video content authored to incorporate additions deletions and updates over time.

In an embodiment a subscription video collection is authored as at least a first video segment that comprises a plurality of annotations each annotation may be represented by a graphic image or animation which at playing time is overlaid on the first video segment. Each of the annotations is associated with a different one of a plurality of episodes or clips.

For example a show may have 22 planned episodes and at a particular time of year there may be 8 of 22 episodes available for viewing to a subscriber. An end user accesses a subscription at a web site associated with a producer or distributor of the show. The end user presents authentication credentials such as user name and password is authenticated and admitted to the subscription. In response the metadata capable video player logic plays a first video segment that features icons indicating episode names with graphics and 14 icons indicating Episode to be Available in the Future. The annotations may be authored in the same single one of the metadata files or may be in multiple different metadata files. For example a first metadata file for a show season may contain references to multiple other metadata files that contain actual annotations for each episode of the show. Selecting a particular episode to view is an invocation of the annotation associated with that episode and effectively causes a branch within the associated metadata file to result in playing the selected video episode.

According to one embodiment the techniques described herein are implemented by one or more special purpose computing devices. The special purpose computing devices may be hard wired to perform the techniques or may include digital electronic devices such as one or more application specific integrated circuits ASICs or field programmable gate arrays FPGAs that are persistently programmed to perform the techniques or may include one or more general purpose hardware processors programmed to perform the techniques pursuant to program instructions in firmware memory other storage or a combination. Such special purpose computing devices may also combine custom hard wired logic ASICs or FPGAs with custom programming to accomplish the techniques. The special purpose computing devices may be desktop computer systems portable computer systems handheld devices networking devices or any other device that incorporates hard wired and or program logic to implement the techniques.

For example is a block diagram that illustrates a computer system upon which an embodiment of the invention may be implemented. Computer system includes a bus or other communication mechanism for communicating information and a hardware processor coupled with bus for processing information. Hardware processor may be for example a general purpose microprocessor.

Computer system also includes a main memory such as a random access memory RAM or other dynamic storage device coupled to bus for storing information and instructions to be executed by processor . Main memory also may be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor . Such instructions when stored in storage media accessible to processor render computer system into a special purpose machine that is customized to perform the operations specified in the instructions.

Computer system further includes a read only memory ROM or other static storage device coupled to bus for storing static information and instructions for processor . A storage device such as a magnetic disk or optical disk is provided and coupled to bus for storing information and instructions.

Computer system may be coupled via bus to a display such as a cathode ray tube CRT for displaying information to a computer user. An input device including alphanumeric and other keys is coupled to bus for communicating information and command selections to processor . Another type of user input device is cursor control such as a mouse a trackball or cursor direction keys for communicating direction information and command selections to processor and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes a first axis e.g. x and a second axis e.g. y that allows the device to specify positions in a plane.

Computer system may implement the techniques described herein using customized hard wired logic one or more ASICs or FPGAs firmware and or program logic which in combination with the computer system causes or programs computer system to be a special purpose machine. According to one embodiment the techniques herein are performed by computer system in response to processor executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory from another storage medium such as storage device . Execution of the sequences of instructions contained in main memory causes processor to perform the process steps described herein. In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions.

The term storage media as used herein refers to any media that store data and or instructions that cause a machine to operation in a specific fashion. Such storage media may comprise non volatile media and or volatile media. Non volatile media includes for example optical or magnetic disks such as storage device . Volatile media includes dynamic memory such as main memory . Common forms of storage media include for example a floppy disk a flexible disk hard disk solid state drive magnetic tape or any other magnetic data storage medium a CD ROM any other optical data storage medium any physical medium with patterns of holes a RAM a PROM and EPROM a FLASH EPROM NVRAM any other memory chip or cartridge.

Storage media is distinct from but may be used in conjunction with transmission media. Transmission media participates in transferring information between storage media. For example transmission media includes coaxial cables copper wire and fiber optics including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves such as those generated during radio wave and infra red data communications.

Various forms of media may be involved in carrying one or more sequences of one or more instructions to processor for execution. For example the instructions may initially be carried on a magnetic disk or solid state drive of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system can receive the data on the telephone line and use an infra red transmitter to convert the data to an infra red signal. An infra red detector can receive the data carried in the infra red signal and appropriate circuitry can place the data on bus . Bus carries the data to main memory from which processor retrieves and executes the instructions. The instructions received by main memory may optionally be stored on storage device either before or after execution by processor .

Computer system also includes a communication interface coupled to bus . Communication interface provides a two way data communication coupling to a network link that is connected to a local network . For example communication interface may be an integrated services digital network ISDN card cable modem satellite modem or a modem to provide a data communication connection to a corresponding type of telephone line. As another example communication interface may be a local area network LAN card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation communication interface sends and receives electrical electromagnetic or optical signals that carry digital data streams representing various types of information.

Network link typically provides data communication through one or more networks to other data devices. For example network link may provide a connection through local network to a host computer or to data equipment operated by an Internet Service Provider ISP . ISP in turn provides data communication services through the world wide packet data communication network now commonly referred to as the Internet . Local network and Internet both use electrical electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link and through communication interface which carry the digital data to and from computer system are example forms of transmission media.

Computer system can send messages and receive data including program code through the network s network link and communication interface . In the Internet example a server might transmit a requested code for an application program through Internet ISP local network and communication interface .

The received code may be executed by processor as it is received and or stored in storage device or other non volatile storage for later execution.

Familiarity is assumed with the disclosures set forth in prior U.S. patent application Ser. No. 12 779 262 US patent application publication US 2010 0293190 A1 filed May 13 2010 U.S. provisional patent application 61 177 726 filed May 13 2009 and U.S. provisional patent application 61 321 076 the entire contents of which are hereby incorporated by reference for all purposes as if fully set forth herein.

CTV Coincident.TV or a computer of a service provider that is configured to implement the service techniques that are described further herein.

In an embodiment the video player logic and server computers are configured with instructions responsive to load and play videos based on requests that specify both a video and a particular time point or range within the video to play. For example in one embodiment universal resource locator URL format is used to specify a video and a time point or range. Such URLs may provide links to a player window with associated videos and web pages at a location other than the start of the video or experience. The technique facilitates interoperability with websites that use HTML. Further when the video player logic is installed on an end user computer and associated with a protocol handler of a video playing protocol reflected in such URLs a web browser receiving a URL that references a particular CPL compatible video time point or range can replace the screen with an audiovisual experience of the type described herein by recognizing the protocol identifier in the URL and invoking the support library to use video player logic to play the video. This also allows embedding an audiovisual experience with a defined structure that will be consistent whenever the web page is rendered.

In an embodiment a range parameter in the URL specifies a time range in seconds to show a portion of the video. Other parameters specify multiple cloud stored videos for annotations. These parameter values enable retrieving thumbnail images from cloud storage and showing them as icons. Further such links may support point and click authoring of interactive videos in the manner further described in other sections herein.

Prior sections of this document have described metadata files which may hold CPL instructions and may be termed CTV files as hand authored or created on the server side at web server or file server under program control. In an embodiment the server computers of may implement a Javascript client side API. In this approach an HTML document in browser running Javascript can create and store a metadata file on client side storage . In an embodiment the same format as for metadata files may be used with CPL and stored as a CTV file in storage . The browser with support library can use the local file from storage to control the audiovisual experience.

In an embodiment client side code running in browser can provide other more complex logic. For example assume that client side Javascript script code running in browser forms and submits a query to a CDN such as YouTube to find specified videos. The script then forms and plays an audiovisual experience with support library in browser that includes the search results.

A benefit of this approach is that a public video serving site is less likely to blacklist the client for submitting repeated searches. In contrast if the server computers send a high volume of queries from the same network address range then certain public video serving sites are likely to blacklist the network address range and decline to respond to the queries.

Embodiments also can be used to circumvent technical limitations of the computer . For example assume that computer has not installed the Flash player but browser supports HTML5. In this arrangement support library in conjunction with client side code running in browser can provide animation effects when Flash is not usable.

In an embodiment data relating to video usage is locally stored in storage or in a browser database in a form that is domain limited and organized. In this context domain limited means that data relating to videos originating from one domain is stored together in the browser database and servers at other domains cannot obtain the data for a different domain. An indexed database API or indexed DB may be used. In an embodiment support library is configured to periodically transfer data captured in the database and associated with a particular domain of the publisher of a video to that domain or publisher for use in determining user viewing characteristics. In this approach the domain or publisher can perform individualized evaluation of user viewing habits and can customize playback of videos on a per user basis to improve user experience based on that user s history of behavior.

For example assume that data in the browser database for videos originating from a particular domain indicates that past activity of a particular user involves always clicking on car ads but never clicking on travel ads. In response the publisher of the videos for that domain can select and provide videos to the user that relate to cars or that include car ads. Thus in one embodiment a server computer at the domain of the video publisher is configured for adjusting the content based on the user s history and also for performing the adjustment at the client side.

In various embodiments the insertion of advertisements into videos may be undesirable for certain content creators or for individuals who do not have access to advertising relationships contracts or content. In an embodiment the server computers may be configured to supplement the metadata files of a particular audiovisual experience to introduce advertisements in a layer or frame that surrounds the playback window of the video so the ad is associated with the video but not actually in it. Further this approach can introduce advertising content that is not available at a public online video storage site such as YouTube.

In an embodiment the support library video player logic and server computers are configured with logic to download a part of the video files graphics files and metadata files for an audiovisual experience rather than all of it. For example in some embodiments the CPL instructions in a particular one of the metadata files may comprise large XML files. Administrators or operators of a particular audiovisual experience may wish to modify or update the large XML files from time to time to cause changes in experiences. In an embodiment specified chunks of XML that define an experience in the metadata files can be selectively modified and replaced using the video editor . Consequently rapid changes in experiences are more easily managed.

In one approach a first metadata file comprises a just in time loading instruction in association with a reference to a second metadata file . When playing a particular video file the first metadata file is used to govern the audiovisual experience. Video player logic is configured to respond when reaching and reading the just in time loading instruction to load and process the second metadata file . The reference to the second metadata file may be a network location rather than a local file. In this manner the first metadata file may specify a particular location that causes the video player logic to make a network request to download a segment of metadata to substitute in at that point and immediately interpret and execute in the player. This approach greatly improves the dynamism of experiences for example the second metadata file could be updated and edited frequently or in real time to enable rapid modification of the user playback experience.

In an embodiment the Live Injector technique described further herein may be integrated with the technique of this section. The Live Injector technique may serve as an enabling concept for live unified media content.

In an embodiment video player logic is configured to detect mouse events or other pointing device movement events using operating system calls event interrupts or other techniques and to determine which region currently contains the cursor . When the cursor is within a particular region that particular region is considered to have the focus of the cursor. Video player logic is configured to detect a change in focus of the cursor to a different one of the regions such as through a mouse enter event indicating movement of the cursor to a different region and to take specified action in response to detecting a change in focus.

In various embodiments the specified action may include any of the following. The video stream that has the focus of the cursor may be made active and may change the audiovisual playback experience globally across all media to match that video s content. The video player logic may cause routing the audio associated with the stream having focus such as the stream of region to the active audio output device or audio subsystem of the computer and making inaudible other audio data associated with second or other video programs that are shown in the other regions . The video player logic may select and display chat text content that is associated with the region having focus such as region and not displaying or removing any chat text content that is associated with other regions . The video player logic may cause the other streams that do not have focus to be displayed as faded or with reduced intensity as compared to the region that has focus for example so that the region appears brighter.

As other examples of the specified action the video player logic may pause playback of the streams in regions other than the region with focus. The video player logic may display one or more stream specific advertisements that are related to the content shown in the stream of the region that has focus. The video player logic may cause displaying a scoreboard online links related media or other data from a non video stream on or near the region that has focus. The video player logic may cause changing one of the regions that does not have focus to show web content information from related videos graphical logos or any other desired data.

In an embodiment each sub stream of the regions is structured as a video annotation in one of the metadata files .

In an embodiment the video player logic is configured to respond to CPL instructions specifying annotations of multiple different media types that provide the capability of linking stories and actions to each other independently. As described in part above with respect to annotations in various embodiments any media type can be used in an annotation. Example media types include still image video stream CTV experience live video stream HTML insert SWF movie. Actions that occur in response to selecting an annotation may be static or dynamic. Examples of static actions include load and display a web page switch to playing another audiovisual experience execute specified executable code or scripts. Examples of dynamic actions include evaluating business rules or web services calls to result in selecting one of the static actions.

In the example of a screen display is generated by the video player logic for the computer and has a main video region in which a first video is played. In an embodiment an annotation in one of the metadata files associated with the audiovisual experience shown in may specify a second video and a second video region in which the second video is played. The video player logic may open multiple different streaming video connections to multiple video files or other networked video resources receive streaming data on the multiple connections and display the video in the screen display . Further in an embodiment an annotation in one of the metadata files associated with the audiovisual experience shown in may specify a plurality of images and an image region in which the images should be displayed. In the example of the images are unrelated to the second video in region . However annotations may be linked so that selecting one of the images could result in automatically updating second video region to display a different second video.

In an embodiment video player logic is configured with instructions which in operation can update the user interface displayed on computer dynamically in real time based on instructions in metadata files that use the cue point language CPL . illustrates an example live injection process.

In an embodiment the video player logic plays an audiovisual experience that comprises a plurality of user interface elements as shown at . For example assume that the audiovisual experience of which is a news show is played. In an embodiment at the video player logic is configured to listen to a data stream from metadata files or another source of instructions in CPL to obtain cue points that cause the video player logic to change operation as previously described in connection with cue points. Alternatively at the video player logic is configured to poll a file such as one of the metadata files on a server that contains one or more changes in CPL instructions.

For example an operator in a studio that is producing a news program could make periodic changes to one of the metadata files by editing the CPL in the file and saving the file in real time as the news program is going on as seen at . The video player logic may be configured to poll one of the metadata files every n seconds to determine if the file has changed. In response to detecting a change in the metadata file or stream as tested at the video player logic updates the user interface elements shown in without reloading the video or browser page as shown at . As a result an operator may cause the video player logic to inject new content into the audiovisual experience on demand or on a real time basis.

In an embodiment the present technique may be combined with the Fractional CTV technique that is described further herein. In an embodiment the present technique enables providing live cross media interactions.

Referring again to in an embodiment an audiovisual experience may include two or more streams of video displayed in multiple regions. For example the main window comprises first through fourth video regions each of which may display a different video streamed or played from among video files or from an internet resource. In an embodiment video player logic is configured with interface instructions that support obtaining and displaying multiple video streams in the main window . Further in an embodiment each video stream in the two or more regions may be obtained from a different content delivery network CDN . Examples of CDNs currently in commercial use include Akamai the Platform YouTube and Brightcove but any other CDN may be used.

Typically each CDN defines a URL format application programming interface API or other calling mechanism that is distinct and different as compared to other CDNs. Consequently in typical practice obtaining a video from a first CDN requires issuing a first kind of call over networks and obtaining a video from a second CDN may require making a completely different call or using a different format. In an embodiment video player logic is configured with instructions that issue calls for videos using a normalized request format. Player control server is configured with a plurality of interface units each configured to transform a request in the normalized request format into a particular API call format or other request format that is required by a particular one of the different CDNs. Consequently authors of metadata files and the video player logic do not need to know the particular call formats or APIs that are used by all the CDNs. Instead metadata files and the video player logic can use a single form of API call for a video and the player control server handles transformation of the single form of API call into one or more requests to any of the different CDNs.

In various embodiments a server computer such as web server or file server is configured with instructions providing data compilation analysis and display processes that may be used to generate and display a plurality of different charts reports and other interpretations of the data collectively analytics .

In one embodiment analytics involve displaying data about the lifetime of an annotation. illustrate screen displays that may be used with annotation lifetime analytics. Referring first to the server computer may be configured to receive data from a plurality of instances of the video player logic indicating which annotations users have selected clicked on during playback of a particular video and the time point at which a particular annotation was selected to store the data at the server side and to generate a histogram or bar chart in which bars represent the number of clicks at particular points in time during playback of the associated video in response to a request or command of an administrative user of the server computer.

In the example of an analytics chart which may form part of an administrative screen display comprises a plurality of bar graphs each associated with a particular annotation in video as indicated by icons . For example icons correspond to annotations in the video . In each of bar graphs the horizontal axis represents time and each bar such as bar represents a count of selections or clicks of all users who viewed video . In an embodiment the horizontal axis of bar graphs corresponds to the length in time of video and gaps or spacing between bars indicate that different counts of selections of a particular annotation occurred at different relative times during playback of the video. For example bar graph indicates that a user or groups of users tended to select one of the annotations at two different times spaced apart during playback of the video.

In an embodiment in a screen display with analytics chart each of the bars comprises a link which when selected causes the video player logic to retrieve and display the video at the relative time point indicated by the particular bar that was selected. For this purpose an administrative user of the server computer may execute an instance of the video player logic on an administrative computer that is connected to the server computer in the manner similar to an end user viewer of the video.

To facilitate operation of this function data stored at the server computer may combine multiple data points received from end users into a smaller set of time points or buckets. For example if a video is 180 seconds long and has been viewed by 500 different users who collectively selected a particular annotation at 100 different time points in the video the time points at which selection actually occurred may be rounded off to the nearest n second interval. For example n may be 10 seconds. This approach enables the bar graphs to have a reasonable number of bars each associated with a larger number of selections that will be meaningful for analysis rather than a very large number of bars each associated with relatively few selections.

In an embodiment the server computer is configured to build and display a burn down chart and allow the user to click on the bars to view the associated part of the video. A burn down chart reflects the common phenomenon that the number of users who continue to view a video tends to decrease in proportion to the length of the video although there are exceptions that the burn down chart can help isolate.

In the example of the general trend in values of the bars is downward as time progresses to the right of the chart. However chart also includes at least one peak bar that represents a departure from the downward left to right trend. In an embodiment in a screen display with analytics chart each of the bars comprises a link which when selected causes the video player logic to retrieve and display the video at the relative time point indicated by the particular bar that was selected. Consequently by selecting bar a user can jump to a point in the associated video at which an unusually large number of users ceased watching the video and can review the substantive video content at that point to determine whether the video needs revision or improvement in order to cause a larger number of users to continue watching.

In an embodiment the burn down chart approach of may be implemented as follows. For a particular video in video files an administrative user creates and stores a metadata file having cue points that are spaced apart approximately 2 to 3 seconds throughout the entire time of the video. Each such cue point is associated with a segment of executable code that is configured to cause the video player logic to notify a server computer such as web server when the associated cue point is reached as a user views the video. The web server or an analysis application on the web server is configured to store data in a database indicating that a user passed the cue point. The resulting data can be used to generate a burn down chart of the form shown in . The burn down chart can indicate whether the video has parts that are particular interesting and or how quickly viewers leave the experience.

In an embodiment similar techniques may be used to generate data indicating which parts of a video appear to be interesting or frequently viewed by significant numbers of users. As a user is viewing a video and a control bar is used to jump forward to another video the player of the audiovisual experience is configured to generate a signal or call to the server computer to provide and causing storing the time point at which a movement occurred in association with data about the user and identifying the movement but without stopping or otherwise interrupting playback of the audiovisual experience. Thus for example if a user is playing an audiovisual experience and then stops playing it or branches to another video segment within the same experience or selects web content the timepoint at which such an action occurred and the nature of the action are sent in a web services call or API call to the server computer. The server computer stores the data in a log database table or other repository.

The server computer may be configured to aggregate analyze and generate one or more reports based on data of this type for a group of users all of whom have viewed or interacted with same audiovisual experience for the purpose of illustrating viewing trends for that audiovisual experience. Examples include burn down reports cliff reports and others that show when and at what rate users ceased watching a video or moved from a particular location to other media content including web content. Examples include viewer retention reports video views from start to final section video views from start to first and final section episodic view views completion by section also termed cue point burn down annotation engagement reports indicating which annotations users clicked on by number or percentage of users or both types of annotation clicks within episodes numbers of website picture in picture launches using the player average time spent using the player picture in picture web pages that result in users pausing the video alone or in comparison to PIP web pages that result in users continuing to play the video Other analytics can provide valuable usage information for content providers such as television networks that provide online video experiences to internet users. Analytics may be used for example to determine how far through a particular video most users watched or whether a particular advertisement was viewed and by how many viewers.

For example in an embodiment the video player logic is configured to detect the use of a trick play control such as play pause seek back 10 seconds rewind or fast forward and to generate an event or send data to the server computer in response to detecting the use of a trick play control. Each such event or data set includes a time point within the video at which the use of a trick play control occurred. The server computer is configured to store records indicating which trick play event occurred and the time point in the video at which the trick play event occurred. The server computer is further configured to generate a report or chart that indicates a plurality of time points in the video and counts of numbers of users who performed a trick play function at the time point in association with actual play of the video.

As the video in window plays bars move from right to left when a particular bar is aligned with the play head indicator then the video in video player window corresponds to the point at which users performed a trick play function. Consequently an administrative user of screen display can perform analysis of the video content shown in window at the time of a large bar to determine whether action should be taken to change the content of the video or perform other actions in response to the use of trick play functions by the users. Thus in general bars may indicate interesting parts of the video .

In an embodiment in screen display each of the bars comprises a link which when selected causes the video player logic to retrieve and display the video in video player window at the relative time point indicated by the particular bar that was selected. For example selecting the first bar causes the video shown in window to jump to the time point associated with the first bar and immediately begin playing in the video player window concurrently the first bar and the video timeline move to the left so that the first bar is aligned with the play head indicator .

Using these techniques user interaction with the control bar of the video player logic such as the icons seen in may be stored in association with a user session identifier at a server computer such as web server or file server and then later used to report video analytics potentially for every second of a video. The analytics may comprise a plurality of data values stored in a spreadsheet database other data repository or output in a report. Analytics may comprise data for a group of users or for an individual and may describe who is watching a particular audiovisual experience and what part for how long. The analytics may be useful for example for teachers making educational videos to show what students were doing for example repeating video segments multiple times. For entertainment analytics data may reflect the relative effectiveness of the video. In an embodiment the current play head position is determined in response to a control bar interaction and sent to the server computer for storing in a data repository in association with data describing the video and the user.

Integrated with a social networking graph the data may be used to connect a user with other users who interacted with the control bar with the same video in the same way or emphasize what parts of the video their friends or a social networking group watched repeatedly. Face icons may indicate locations in the video timeline where friends interacted with the video. As an example in one embodiment a social networking application can display the player window within the social networking site page and show the social networking profile photo of a friend of the current user with an indication of what action that friend took in the playback of the audiovisual experience or with respect to the control bar. Profile information other than photos may be displayed for friends. Information for a plurality of friends may be shown.

Log entries stored at file server for control bar interactions may comprise values for time user video and an action indicator. In an embodiment video player logic may send values indicating only that a particular user has had some undefined form of interaction with the control bar at a particular time for a particular video reporting the log entry may be triggered at the video player logic by any form of interaction with the control bar. Example interactions may include selecting an annotation that is referenced in an audiovisual experience stopping pausing jumping forward or back and exiting. Other embodiments may include a skip indication and a first time value and second time value.

In an embodiment the server computer may be configured to analyze the log data and determine at least one output report that indicates that users have jumped backward in time in a particular audiovisual experience. This report provides the benefit of indicating when a group of users may have special interest in a particular video experience because the users have elected to view the experience starting from the beginning more than once. For example the log data may store both a time point in video time at which a control bar interaction occurred and a time point in real time for the particular user for example based on the system clock of the user computer when analysis of the log records indicates that the same user began viewing the same video at different system clock times or real times then logic in the server computer may determine that the user repeatedly watched the video or performed a control bar interaction equivalent to jumping backward to the beginning. The results may be used to reach a determination that a particular sub segment of an audiovisual experience is valuable or is correlated with particular social or consumer behavior. Inferences about user social interaction with other users may be determined Thus the viral impact of a particular sub segment of video on behavior of one person versus friends of that person may be determined Logic of the server computer may be configured to determine that a particular user is the source of responsive viral social interactions of other users and the particular number of responsive users fan out may be determined that particular user may be determined to be especially valuable to the content provider. Thus if a particular user is shown to repeatedly cause N other friends to perform responsive actions such as viewing the same audiovisual experience segment advertisement etc. then that particular user may be determined to be more valuable than other users.

In a related technique the player logic may be configured to accept user input representing a comment on a particular time point of the audiovisual experience and to cause storing the comment at the server computer in association with information identifying the video and the user. The server computer may be configured to cause publishing the comment to friends of the commenting user at the time that those friends view the same video with the comments and photo thumbnails of the commenting users displayed in association with the control bar of the video when the time points of comments is reached during playback.

For example assume that user John is viewing an audiovisual experience comprising an annotated online episode of the television show Glee. When John reaches time point 03 16 of the show John sees a funny scene. John accesses a function of the player that allows entering a comment about the scene. The player creates and sends a POST request to the server computer that identifies John Glee 03 16 and provides the text of the comment and the server computer stores the data. A few seconds or days later John s friend Susan is viewing the same episode of Glee. Each second or at another specified interval Susan s player sends a request to the server to deliver one or more comments that are associated with the current time point of playback. Therefore when Susan s player reaches time point 03 16 the server responds with John s comment. The player issues a call to the Facebook social graph server to retrieve John s profile photo thumbnail image. The player displays the thumbnail image in or near the control bar or another portion of the player window with the comment. The image and comment move leftward in the player window as the pointer in the control bar advances to later time points and eventually the image and comment disappear from the player window as Susan reaches much later time points.

If Susan has other friends who have also commented at 03 16 the profile thumbnail images of those friends and their comments may be displayed at the same point for example in a stack or row of images and comments. A priority ranking algorithm may be implemented to determine which friends comments are displayed when a large number of comments are available and the amount of screen space cannot accommodate displaying photo thumbnails of all friends who have provided comments.

In an embodiment metadata files may reference one or more arbitrary sets of computer program code for execution the code may comprise ordinary executables in storage or file server browser executed code such as Javascript to be executed in browser Adobe ActionScript actions or any other code that the browser can access and run or that the video player logic can access and run. In this embodiment for example a cue point may be configured using the user interface of with an additional field in which a file of computer program code may be specified. In various embodiments such cue points may be configured to execute arbitrary code based on reaching waypoints in a temporal map of the media experience and the user response to choices presented at those waypoints. For example embodiments may be configured to create a temporal map of user guided playback including interaction by segment and map or associate the temporal map to execution order of code segments. The code segments themselves can dynamically change the playback including manipulating these mechanisms.

In one example of use one of the metadata files for a particular audiovisual experience is configured with a plurality of cue points. Each of the cue points references a first executable code segment which when executed causes storing in database data indicating that a particular user has visited the associated cue point. Data identifying which user is active in a particular session may be obtained from computer via support library or player logic either of which may be configured to obtain a user name machine identifier machine address or other user identifying information. The metadata files also may be configured with a plurality of annotations each associated with a reference to a segment of executable code that is automatically executed at computer or in player control server when the associated annotation is selected. In this example the executable code causes storing in database data indicating that the associated annotation was selected.

An embodiment may further include code in script files that is configured to retrieve the data from database to determine based on dynamic business rules that are completely decoupled from the media which video to insert at an insert point. In this example when player logic is playing a media asset and reaches an insert point the player logic may query the database for the data indicating which prior cue points and annotations the user interacted with apply the data to business rules embodied in the script files or other logic and select one of a plurality of other media assets to play at that insert point.

In an embodiment invocation of code is implemented using metadata files that express an audiovisual experience in terms of cue points and annotations that generate events which in turn trigger actions. In an embodiment events include click enter fire and return. An annotation generates a click event when a user selects or clicks on an annotation. A text input annotation generates an enter event when a user selects the ENTER or RETURN key for the annotation. A cue point generates a fire event when the cue point is reached normally during playback of the associated video a return event is generated when the cue point is reached as a result of a return from another action.

In an embodiment actions may be inserted into any cue point or annotation. Each action is invoked based on whether its event attribute matches the event that occurred. An action s event attribute defaults to the default event for the object it is in. The default for cue points is fire . The default for annotations is click .

In one embodiment in a metadata file the actions for a particular object are set forth between tags. In an embodiment player control actions include 

In an embodiment actions may express invocation of a service or script code. Service or script invocation actions may have a regularized calling syntax for passing named arguments using the arg tag. The arg tag is used to specify which name value pairs to pass to the invocation function. The values can come from storage or file server or may be directly specified. In addition in an embodiment the following three arguments are passed  head the current playhead position  url the full URL of the current CTV file  cp the name of the current cuepoint.

In an embodiment the element takes several parameters including the name of the argument. If a value is given it is used as the arg s value. If a value is not given then the key is used to look up the value in storage. If the key is not given then it defaults to the name parameter. In summary arguments include required name the name for this argument optional key the key to use to look up the argument defaults to the name optional value the value of this argument defaults to the value contained in storage for the key .

A webservice action also has the URL to call in its href attribute. When this action is invoked the args are passed in the URL as url encoded POST data. An example of a webservice action is 

In an embodiment a Javascript action has a func attribute which specifies which Javascript function to call. This function is expected to exist within the player s HTML file. A single parameter is passed to the function which is a Javascript object containing the args as keywords and values. For the Javascript action an alternate invocation pattern may be used in which a script with its arguments is called directly. The script attribute contains the script to be called and any tags are ignored. For example 

In an embodiment actions expressed in Adobe ActionScript may be implemented in the player logic or a file such as an SWF file that implements the action may be dynamically loaded.

In an embodiment video player logic is configured to identify a tag value associated with a cue point and in response to perform a search for media assets that have been tagged with the tag value to select one or more of the media assets and do dynamically create and save updated metadata files that reference the selected media assets. Additionally or alternatively embodiments may be configured to use tags as a basis to retrieve sets of video files for use in subsequent processing.

As background embodiments recognize that many media assets such as video clips are available on the web or in public internet resources that may be accessed through networks . In some cases those who store media assets in online resources such as YouTube write and store tag values in association with the media assets. In other cases authors interacting with the system of may elect to create one or more tag values for video files . In any case authors can apply free form tags to media assets and these tags may be used to automate the creation of complex multimedia content.

As a result authoring audiovisual experiences using video editor involves a semantic domain in which the author performs creative activity by specifying ideas rather than media addresses. For example rather than performing a search for video clips that have a particular tag obtaining a URL of one of them and inserting the URL in a particular place in the audiovisual experience such as with a cue point or annotation video player logic is configured to automatically perform a search based on a tag and arrange for access to video clips that match the tag.

For example assume that an audiovisual experience consists of a news program that has a cue point named segment1 associated with playing a first news segment at a particular time. The cue point also includes metadata that identifies a particular tag values such as tag Gardening . When the audiovisual experience plays and the segment1 cue point is reached video player logic is configured to identify the tag value initiate a search either in video files internet sources via networks or both for videos that are tagged with the tag value. For internet searches parameterized search queries using URL formats or other interfaces specified by the internet resources may be used according to open protocols published by the internet resources.

In response video player logic receives responses typically identifying a plurality of URLs file names or other identifiers of video assets. Video player logic is configured to select a subset of the video assets. Selection logic may use various criteria such as selecting assets that are recent have usage rights granted are less than or greater than a specified size or playing time or simply the first n assets. Video player logic then automatically writes instructions in updated metadata files to associate and give access to the selected assets.

As another example a parameterized URL carrying a search tag value may be used to request and obtain a set of videos for use in authoring experiences or other aspects of the system here. For example video editor may be configured with logic that prompts the end user to enter a keyword such as Gardening. The video editor is configured to create an HTTP request that includes a parameterized URL comprising a search query and send the request to one or more internet resources. In response video editor receives responses typically identifying a plurality of URLs file names or other identifiers of video assets. Video editor may be configured to display a list of identifier of matching videos and to enable a user to select one or more of the video assets for use in authoring. In one embodiment the video editor is configured to enable the user to drag and drop a plurality of identifiers of videos into a specified set of slots buckets or other UI widgets. For example the request might return 50 results each indicating a video and the user might be allowed to drag 4 of the results into slots in an authoring application. The video editor or video player logic then automatically writes instructions in updated metadata files to associate and give access to the selected assets or to create a new audiovisual experience that includes the selected results. Thus using the techniques herein automated content creation becomes possible using a relatively simple user interface and automatic keyword based searching of video files in internet resources.

Referring to in an embodiment file server may be located in a data center server co location facility or any other suitable location coupled to networks and not necessarily owned or operated by the same party as player control server web server computer or other elements of . Cloud based or other networked data storage may be used for file server . In such an embodiment video editor may be configured to identify and use video files and or metadata files that are in networked cloud locations. For example rather than storing CPL instructions in metadata files that reference a local file in storage the instructions in the metadata files may reference networked storage locations for video files that are at a cloud based data center. Moreover the video files may be located in public content delivery networks or shared video storage sites that the user of computer does not own or operate and the video files may be controlled in accounts of parties other than the user of computer .

In particular video transition effects for an audiovisual experience may be created and modified based solely on cloud based streams with no local storage of the streams at storage . As an example assume that video files represent a first video and a second video that are stored at a public cloud based CDN such as YouTube. A metadata file may specify playing the first video by referencing a URL that uniquely identifies the first video at YouTube. The same metadata file may define a cue point located midway through the first video at which the user of computer acting as author of the metadata file wishes to transition to the second video. The cue point may reference the URL for the second video as the target of the cue point. Thereafter another user who loads and runs an instance of video player logic with the same metadata file will receive an audiovisual experience consisting of seeing the first video reaching the cue point midway through the first video and continuing with the second video.

Thus metadata files for the video player logic may be configured to define how to process transition between and otherwise use video files that are received as cloud stored streams. In this arrangement users can use video editor to accomplish the equivalent of non linear editing without having any local storage for video at storage .

In an embodiment video editor comprises instructions that implement a mechanism with which end users lacking media authoring skill can create multimedia content. In one embodiment video editor implements instructions to perform the following. A user watches a first video from among video files using video editor . An automatic authoring mechanism pauses the video either automatically at a preselected point indicated in the metadata files for the video and waits for user input specifying another video. The prompt for the user input may be configured as an annotation in the metadata files . In various embodiments the prompt may request the user to specify a particular second video for input or to select the second video from among a plurality of specified videos from a multiple choice list that is defined in the metadata files or to interact with a browse dialog for the purpose of selecting a local video file to be uploaded as the second video. In response to user input the metadata files are updated to identify the second video that the user selected specified or uploaded.

Thereafter during playback of the same first video the first video is not paused at the prior pause point but the second video is played immediately.

As a result an author having a relatively low skill level or who desires a simple and fast way to specify an audiovisual experience can build the audiovisual experience readily from among multiple video assets.

In another embodiment the video editor may be configured with a mechanism to select media from social networking sites and include it in the context described above. For example assume that a user watches the first video from among video files using video editor . An automatic authoring mechanism pauses the video either automatically at a preselected point indicated in the metadata files for the video and waits for user input specifying a social media element. The prompt for the user input may be configured as an annotation in the metadata files . For example in an embodiment a social media system profile picture is fetched and is applied as an icon for comments to be provided about the first video. The metadata files are updated either with a reference to graphics files at which the profile picture has been stored or a reference to a location in the social graph from which the profile picture can be retrieved again at a later time.

Thereafter when the first video is played again and the same pause point is reached the video player logic is instructed based on the metadata files to retrieve the profile picture either from graphics files or from the social graph and to immediately display the profile picture as an icon at the indicated location.

In an embodiment annotations may be used to automate the presentation of advertisements during playing a video with viewing an advertisement either optional or mandatory. For example referring again to the second video in region may comprise an advertisement video or a static graphic image that presents a video. Further an annotation in metadata files that governs presentation of the advertisement at region may be configured to cause the video player logic to automatically switch to and play an advertisement video when a cue point associated with the annotation is reached in playing the first video . The foregoing is an example of a mandatory advertisement.

Additionally or alternatively the cue point and annotation that cause presentation of the advertisement at region may configure the advertisement as a graphical image associated with a hyperlink so that only selection of the hyperlink associated with the region causes the video player to switch to playing the advertisement video. If no selection of the hyperlink at region occurs then the first video continues playing and in some embodiments later cue points may specify that the second region is removed from the player window . The foregoing is an example of a voluntary advertisement.

Video streams for advertisements used in any of the foregoing approaches may be obtained from CDN cloud storage so that an author of an audiovisual experience can introduce ad breaks that play other videos from the cloud. Ad breaks can be mandatory or optional an optional ad break plays only when the associated annotation is selected. The author does not need direct access to any of the videos.

In a related technique late binding of one video segment to another segment is provided. In such an embodiment the video experience that the author creates using CPL instructions in metadata files contains an abstract reference to an insertion that may be an advertisement or other video segment. The abstract reference to an insertion is bound to a real advertisement at a later time for example at the time that the audiovisual experience plays.

In an embodiment an author of an audiovisual experience specifies during authoring insertion points with references to advertisements or other video segments that can be inserted from networked storage such as cloud storage at the time of playback potentially based upon business rules or other conditions.

In an embodiment an editor for use in creating audiovisual experiences is configured to receive and store definitions of one or more video segments or sources that are located in network accessible locations. The definitions are stored in metadata that is associated with the audiovisual experience that the author is creating or editing. Network accessible locations may include internet content server locations or other server computers that are coupled to an internetwork and accessible using internet protocols. The network accessible locations may be public or may be subject to access security controls. The video sources may be in cloud storage or other online storage as opposed to locations in a LAN or LAN segment or sub domain that contains the computer on which the editor is running

Editing may involve defining one or more jump cuts or transitions from multiple video sources from different networked locations storing the definitions in metadata and implementing the cuts or transitions using the player logic at the time that the audiovisual experience is played. For example a single audiovisual experience may initially play a first media asset from a website associated with the British Broadcasting Company BBC and then cut to dissolve to or otherwise transition to another video segment that is stored on a networked server that is owned and operated by a studio such as Paramount. Any number of video assets stored on any of a plurality of internet accessible servers may be referenced using the editor logic in the metadata for a single audiovisual experience and played together with transitions using the player logic.

As an example the author creates and stores a cue point A that comprises a jump to a next cue point B and metadata for cue point B specifies a video source as a URL to an internet networked resource. The metadata further specifies a location within a video clip at the video source what to do with audiovisual content within the clip. At playback the audiovisual experience reaches cue point B and issues an access request to the video source that is specified in the metadata for the cue point. The audiovisual experience continues by playing video that is streamed from the specified networked video source.

In an embodiment video editor may be configured with template management logic that generally operates to open the metadata files for a particular audiovisual experience display the experience with the original media in place demote or remove the media while extracting the meta structure of the experience and build a new version of the experience with different media and timing.

As background often audiovisual experiences such as television episodes have the same general structure in terms of graphical windows or framing annotations and other non media visual elements and vary only in the specific media that is placed in the structure and the times though not the structure at which events occur. Therefore in an embodiment the editing and construction of multiple versions of a similar audiovisual experience can be made more efficient through a way to abstract and store the structure of an existing asset while allowing time points for playing media to change. As a result authoring tasks involved in episodic programs are simplified and involve replacing the media within a template structure and adjusting time points.

Templates also may be configured to provide mechanisms to maintain consistent branding and provide fine grained control over what elements and types of elements the author can change. For example a template may embody controls that specify whether a production assistant who is setting up multiple TV show episodes from a template is allowed to swap images change targets change target types change start time points or transition time points or perform other operations. Thus in an embodiment template authoring functions in video editor facilitate rapid and efficient authoring of audiovisual experiences. The method for hierarchical control of what distinct classes of people are allowed to change is also of broad applicability.

In an embodiment templates facilitate abstracting structure away from particular media. For example assume that using video editor a user has created and stored an audiovisual experience comprising a video promotion for a particular motion picture film titled Alpha which is a futuristic science fiction epic. The audiovisual experience includes background graphics button images and other stylization that is particular for the theme look and feel of Alpha. Now further assume that the user wishes to create an audiovisual experience for a second motion picture film Beta using a similar screen structure or layout but with completely different graphic stylization for Beta which is a Western film set in the 1880s. The video editor is configured to convert a particular audiovisual experience into a template that can be re populated with different media assets that may include different playable audiovisual segments as well as different graphical stylization and look and feel. The video editor may expose in its graphical user interface a Convert to Template or Make Template function for this purpose.

At in association with the copying all specific references to media assets that were the existing audiovisual experience are removed including time points but structural information such as the size in pixels of annotations or other elements is retained. At the resulting shadow content set is re displayed in a format in which locations for media assets are represented generically for example as gray rectangles.

The user then may select one or more of the media asset locations as seen at and access functions to assign different media assets to the media asset locations as seen at . The user can save the resulting modified shadow content set as a new audiovisual experience for example for Beta.

A more detailed implementation example is set forth in the document entitled Andromeda Functional Spec ver 0.5.8 which forms part of the provisional disclosure and this disclosure.

A benefit of this approach is that the user who creates the Beta audiovisual experience may have a lower degree of artistic skill or technical skill than the user who created the original Alpha audiovisual experience including defining the locations of media assets annotations or other elements in terms of screen position pixel sizes and interactive behavior. For example the user who creates Beta only needs to have the ability to select new media assets for Beta and assign them to existing media asset locations in the template there is no need for more advanced authoring skills such as defining the behavior of annotations. The same functional behavior is retained in the Beta audiovisual experience but references and uses different media assets. In one embodiment assigning new media assets to the template may include performing certain basic graphic operations such as rotation and scaling.

In an embodiment the editor logic is configured to enable a user working from a template to change the time points in new media assets at which specified interactions occur as seen at . This logic recognizes the fact that the particular time point within a Beta media asset such as a video segment at which a desired action should occur such as displaying an annotation or website item or jumping to another video segment is extremely unlikely to be the same time point as for the prior Alpha media asset. In an embodiment the user may access a cue point and may change the play head time point associated with a change in playback behavior.

Thus in certain embodiments templates may facilitate a process of rapid creation of audiovisual experiences that may be termed template based one click experience creation. The following process may be used. With video editor a user of computer selects a template by browsing among metadata files and using a file open dialog to identify and open a selected template file. The video editor displays the template in the form of a screen display structure defined in the template with gray rectangles or other indicators of placeholders in locations that the user is permitted to change. The user selects a particular one of the placeholders and selects a control that is configured to accept an identification of a video identifier. The user operates a file open dialog to specify a particular video asset among video files or in local storage . In response to the user selecting the particular video asset video editor associates the video asset with the selected placeholder location and the user may store a new metadata file representing the template with the particular video asset either in local storage or using file server . A similar technique may be used to select available placeholders for annotations and to select graphics or web pages as icon representations or targets for the annotations.

In some embodiments the author also may modify time points of the media assets so that the media assets start and end at desired times and the modified time points are stored as part of the metadata file .

As a result authoring a new audiovisual experience may consist of a simplified process of selecting placeholder locations within a defined structure and selecting media assets to plug into the template. Thus an author may use the generalized audiovisual experience authoring platform described herein with template based one click experience creation to rapidly create one or more applications for particular purposes. Further pop up audiovisual experiences may be authored using templates based on editor logic that is similarly configured and further described in the appendices that are submitted concurrently herewith.

In the foregoing specification embodiments of the invention have been described with reference to numerous specific details that may vary from implementation to implementation. Thus the sole and exclusive indicator of what is the invention and is intended by the applicants to be the invention is the set of claims that issue from this application in the specific form in which such claims issue including any subsequent correction. Any definitions expressly set forth herein for terms contained in such claims shall govern the meaning of such terms as used in the claims. Hence no limitation element property feature advantage or attribute that is not expressly recited in a claim should limit the scope of such claim in any way. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

