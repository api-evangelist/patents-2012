---

title: Fanning user interface controls for a media editing application
abstract: Some embodiments provide a method of presenting several user interface (UI) controls for editing images. Upon receiving a selection of an image to edit, the method displays the image in a display area for displaying edits to the image. At a first location, the method receives input to activate a UI tool includes the several UI tools. In response to the input, the method displays, at a second location, a fanning animation that fans the several UI controls from a fanned closed layout to a fanned open layout.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09189876&OS=09189876&RS=09189876
owner: APPLE INC.
number: 09189876
owner_city: Cupertino
owner_country: US
publication_date: 20120927
---
This application claims the benefit of U.S. Provisional Patent Application 61 607 524 filed Mar. 6 2012 U.S. Provisional Patent Application 61 607 525 filed Mar. 6 2012 U.S. Provisional Patent Application 61 607 554 filed Mar. 6 2012 U.S. Provisional Patent Application 61 607 569 filed Mar. 6 2012 U.S. Provisional Patent Application 61 607 574 filed Mar. 6 2012 U.S. Provisional Patent Application 61 607 540 filed Mar. 6 2012 U.S. Provisional Patent Application 61 607 580 filed Mar. 6 2012 and U.S. Provisional Patent Application 61 741 768 filed May 15 2012. U.S. Provisional Patent Applications 61 607 524 61 607 525 61 607 554 61 607 569 61 607 574 and 61 741 768 are hereby incorporated by reference.

Today many image editing applications provide a number of different tools to managed and manipulate digital images. Examples of such applications are iPhoto which is provided by Apple Inc. Picasa which is provided by Google Photoshop which is provided by Adobe Express Media which is provided by Microsoft etc. Some image editing applications allow the user to view images edit images and or organize images.

Users often wish to edit images in order to improve the appearance of the image to make the images appear a certain way to apply effects to the image etc. In many instances a user must iterate through many steps while using many different tools in order to modify the image in the way that the user desires. This usually results in the user spending an inordinate amount of time editing the image and at the end the user may still not be able to edit the image in way that the user wishes.

In many instances the user knows what the user wants the image to look like but the user either lacks the knowledge to produce the desired appearance of the image and or the user cannot find the tools in the image editing application that allows the user to produce the desired appearance. Thus many users may need to spend a large amount of time learning to use the media editing application.

When editing images with an image editing application the edits made to the images are typically permanent. Therefore if a user makes a mistake or wishes to changed or undo edits the user has to start over by editing the original image file or the user has to fix the mistake by further editing the image.

For an image editing application some embodiments of the invention provide a novel user interface UI tool that provides a set of fanning UI controls. In some embodiments when the UI tool is activated the UI tool provides an animation that fans the UI controls open. When one of the UI controls of the UI tool is selected to be used the UI tool provides a an animation that fans the UI controls closed to show the selected UI control

Different embodiments of the UI tool provide different types of fanning animations. For instance the UI tool of some embodiments fans the UI controls by fanning the UI controls in one direction about a fixed location. This way the UI controls appear like the UI controls are pinned at one end of the UI controls and the UI controls fan open and closed about the location at which the UI controls are pinned.

In some embodiments the UI tool fans the UI controls by fanning the UI controls two directions about a fixed location. In such embodiments the UI tool fans some of the UI controls in one direction about the fixed location and fans the other UI controls in the opposite direction about the fixed location.

While the fanning open the UI controls the UI tool of some embodiments displays the UI controls such that the UI controls appear to slide onto a display area e.g. the entire screen of a computing device from outside the display area. Similarly while the fanning closed the UI controls the UI tool of some embodiments displays the UI controls such that the UI controls appear to slide off of the display area from near the center of the display area.

The UI tool of different embodiments provides different types of UI controls. For example in some embodiments the UI tool provides UI controls for applying effects to an image. These types of UI controls will be interchangeably referred to as effects controls in this application. Examples of effects include various filter effects duotone effects non photorealistic desaturation gradient effects vignette effects tilt shift effect etc.

Different embodiments provide different types of effects controls. For example a first type of effects control displays a set of selectable thumbnail images of an image being edited. Each selectable thumbnail image displays a different extent of an effect associated with the effects control applied to the thumbnail image. Selecting a thumbnail image causes the application to apply the effect to the image being edited to the extent that the effect is applied to the thumbnail image. This way the selectable thumbnail images provide a preview of the effect applied to the image being edited before applying the effect to the image.

A second type of effects control includes a sliding region. Different locations along the sliding region are for applying different extents of the effect to the image being edited. A user may apply different extents of the effect to the image being edited by selecting different locations e.g. by touching the location on a touchscreen along the sliding region. Alternatively the user may apply different extents of the effect to the image by touching the sliding region and continuing to touch the sliding region while sliding along different locations of the sliding region.

For the second type of effects control a set of thumbnail images of the image being edited are displayed at different location along the sliding region. Each thumbnail image displays a different extent of the effect associated with the effects control applied to the thumbnail image. The location at or near a particular thumbnail image along the sliding region corresponds to the extent of the effect that is applied to the thumbnail image. Thus the location of a thumbnail image with a full extent of the effect to the thumbnail image is for applying a full extent of the effect to the image being edited the location of a thumbnail image with a half extent of the effect to the thumbnail image is for applying a half extent of the effect to the image being edited etc.

Another type of UI control that the UI tool of some embodiments provides is for applying brush effects to portions of an image. These types of UI controls will be interchangeably referred to as brush controls in this application. Examples of brush controls include brush controls to remove red eye and blemishes brush controls to saturate desaturate lighten darken sharpen or soften a portion of an image etc.

In some embodiments the image editing application of some embodiments provides various tools for editing an image. When different edits are made to the image using different tools the application applies the different edits in a particular order. For instance the application might apply exposure edits to an image before applying effects edits to the image. To ensure that a first type of edits are applied to the image before a second types of edits the application of some embodiments temporarily removes the second type of edits if any from the image when the user is wishes to apply the first type of edit to the image. After the user is finished applying the first type of edits the application applies back to the image the second type of edits that were removed from the image. In some embodiments the application provides a peeling on and peeling off animation to indicate to the user that edits are being removed or being applied back to the image.

The application of some embodiments stores information in a data structure that represents images managed by the application. In some embodiments the application stores the data structure in a manner that preserves the original image when the image is edited. To provide quick viewing of images in through the GUI of the application the application of some embodiments caches different versions of the image that are frequently accessed used and or displayed. In some embodiments the application provides a feature that allows the user to switch between the current edited version of the image and the original image. To facilitate the quick switching between the different versions of the image the application of some embodiments utilizes the non destructive method of storing images.

In addition to the features described above the application of some embodiments provides a feature that allows the user of the application to send images to users of other devices that are also running the application. In some embodiments the application sends the image in a data structure that stores the image in a non destructive manner. This way the recipient of the image may view the original image the version edited by the sender make additional and or different edits to the image send the image to other users etc.

The preceding Summary is intended to serve as a brief introduction to some embodiments of the invention. It is not meant to be an introduction or overview of all inventive subject matter disclosed in this document. The Detailed Description that follows and the Drawings that are referred to in the Detailed Description will further describe the embodiments described in the Summary as well as other embodiments. Accordingly to understand all the embodiments described by this document a full review of the Summary Detailed Description and the Drawings is needed. Moreover the claimed subject matters are not to be limited by the illustrative details in the Summary Detailed Description and the Drawing but rather are to be defined by the appended claims because the claimed subject matters can be embodied in other specific forms without departing from the spirit of the subject matters.

In the following detailed description of the invention numerous details examples and embodiments of the invention are set forth and described. However it will be clear and apparent to one skilled in the art that the invention is not limited to the embodiments set forth and that the invention may be practiced without some of the specific details and examples discussed.

For an image editing application some embodiments of the invention provide a novel user interface UI tool that provides a set of fanning UI controls. In some embodiments when the UI tool is activated the UI tool provides an animation that fans the UI controls open. When one of the UI controls of the UI tool is selected to be used the UI tool provides an animation that fans the UI controls closed to show the selected UI control.

Different embodiments of the UI tool provide different types of fanning animations. For instance the UI tool of some embodiments fans the UI controls by fanning the UI controls in one direction about a fixed location. This way the UI controls appear like the UI controls are pinned at one end of the UI controls and the UI controls fan open and closed about the location at which the UI controls are pinned.

In some embodiments the UI tool fans the UI controls by fanning the UI controls two directions about a fixed location. In such embodiments the UI tool fans some of the UI controls in one direction about the fixed location and fans the other UI controls in the opposite direction about the fixed location.

While the fanning open the UI controls the UI tool of some embodiments displays the UI controls such that the UI controls appear to slide onto a display area e.g. the entire screen of a computing device from outside the display area. Similarly while the fanning closed the UI controls the UI tool of some embodiments displays the UI controls such that the UI controls appear to slide off of the display area from near the center of the display area.

The UI tool of different embodiments provides different types of UI controls. For example in some embodiments the UI tool provides UI controls for applying effects to an image. These types of UI controls will be interchangeably referred to as effects controls in this application. Examples of effects include various filter effects duotone effects non photorealistic desaturation effects gradient effects vignette effects tilt shift effects etc.

Different embodiments provide different types of effects controls. For example a first type of effects control displays a set of selectable thumbnail images of an image being edited. Each selectable thumbnail image displays a different extent of an effect associated with the effects control applied to the thumbnail image. Selecting a thumbnail image causes the application to apply the effect to the image being edited to the extent that the effect is applied to the thumbnail image. This way the selectable thumbnail images provide a preview of the effect applied to the image being edited before applying the effect to the image.

A second type of effects control includes a sliding region. Different locations along the sliding region are for applying different extents of the effect to the image being edited. A user may apply different extents of the effect to the image being edited by selecting different locations e.g. by touching the location on a touchscreen along the sliding region. Alternatively the user may apply different extents of the effect to the image by touching the sliding region and continuing to touch the sliding region while sliding along different locations of the sliding region.

For the second type of effects control a set of thumbnail images of the image being edited are displayed at different location along the sliding region. Each thumbnail image displays a different extent of the effect associated with the effects control applied to the thumbnail image. The location at or near a particular thumbnail image along the sliding region corresponds to the extent of the effect that is applied to the thumbnail image. Thus the location of a thumbnail image with a full extent of the effect to the thumbnail image is for applying a full extent of the effect to the image being edited the location of a thumbnail image with a half extent of the effect to the thumbnail image is for applying a half extent of the effect to the image being edited etc.

Another type of UI control that the UI tool of some embodiments provides is for applying brush effects to portions of an image. These types of UI controls will be interchangeably referred to as brush controls in this application. Examples of brush controls include brush controls to remove red eye and blemishes brush controls to saturate desaturate lighten darken sharpen or soften a portion of an image etc.

In some embodiments the image editing application of some embodiments provides various tools for editing an image. When different edits are made to the image using different tools the application applies the different edits in a particular order. For instance the application might apply exposure edits to an image before applying effects edits to the image. To ensure that a first type of edits are applied to the image before a second types of edits the application of some embodiments temporarily removes the second type of edits if any from the image when the user is wishes to apply the first type of edit to the image. After the user is finished applying the first type of edits the application applies back to the image the second type of edits that were removed from the image. In some embodiments the application provides a peeling on and peeling off animation to indicate to the user that edits are being removed or being applied back to the image.

The application of some embodiments stores information in a data structure that represents images managed by the application. In some embodiments the application stores the data structure in a manner that preserves the original image when the image is edited. To provide quick viewing of images in through the GUI of the application the application of some embodiments caches different versions of the image that are frequently accessed used and or displayed. In some embodiments the application provides a feature that allows the user to switch between the current edited version of the image and the original image. To facilitate the quick switching between the different versions of the image the application of some embodiments utilizes the non destructive method of storing images.

In addition to the features described above the application of some embodiments provides a feature that allows the user of the application to send images to users of other devices that are also running the application. In some embodiments the application sends the image in a data structure that stores the image in a non destructive manner. This way the recipient of the image may view the original image the version edited by the sender make additional and or different edits to the image send the image to other users etc.

Several more detailed embodiments of the invention are described in the sections below. Section I conceptually describes details of UI tools that have fanning UI controls. Next Section II conceptually describes details of ordered edit processing according to some embodiments of the invention. Section III follows this with a description of a data structure that for representing images according to some embodiments. Next Section IV describes details of a beaming feature provided by the application of some embodiments. Section V describes an example image viewing editing and organization application of some embodiments. Finally Section VI describes several electronic systems that implement some embodiments of the invention.

As mentioned above the image editing application of some embodiments provides a UI tool that includes a set of fanning UI controls. Different embodiments of the UI tool provide different types of UI controls. The following section will describe examples of UI tools for applying effects to an image and examples of UI tools for applying brush effects to an image.

As shown the GUI includes a thumbnail display area an image display area a first toolbar a second toolbar and a third toolbar . The thumbnail display area displays thumbnails of the images in a selected collection. Thumbnails are small representations of a full size image and represent only a portion of an image in some embodiments. A user may select one or more images in the thumbnail display area e.g. by touching the thumbnail image . The selected thumbnails are displayed with a highlight or other indicator of selection. In thumbnail display area the thumbnail is selected.

The image display area displays the selected thumbnail image at a larger resolution. This will typically not be the full size of the image which are often of a higher resolution than the display screen of the device on which the application displays the image . In some embodiments the image in the image display area is displayed in the aspect ratio of the full size image.

The first toolbar displays title information e.g. the name of the collection shown in the GUI a caption that a user has added to the currently selected image etc. . In addition the toolbar includes a first set of UI items and a second set of UI items .

In the first set of items the back button enables the user to navigate back to a collection organization GUI. Selection of the grid button causes the application to move the thumbnail display area on or off of the GUI e.g. via a slide animation . In some embodiments users can also slide the thumbnail display area on or off of the GUI via a swipe gesture. The help button activates a context sensitive help feature that identifies a current set of tools active for the user and provides help indicators for those tools that succinctly describe the tools to the user. In some embodiments the help indicators are selectable to access additional information about the tools. Selection of the undo button causes the application to remove the most recent edit to the image whether this edit is a crop color adjustment etc.

In the second set of UI items the sharing button enables a user to share an image in a variety of different ways. In some embodiments the user can send a selected image to another compatible device on the same network e.g. Wi Fi or Bluetooth network upload an image to an image hosting or social media website and create a journal i.e. a presentation of arranged images to which additional content can be added from a set of selected images among others.

The information button activates a display area that displays additional information about one or more selected images. The information displayed in the activated display area may include Exif data stored for an image e.g. camera settings timestamp etc. . The show original button enables the user to toggle between the original version of an image and the current edited version of the image.

The edit button allows the user to enter or exit edit mode. When a user has selected one of the sets of editing tools in the toolbar the edit button returns the user to a viewing and organizing mode. When the user selects the edit button while in the viewing mode the application returns to the last used set of editing tools in the order shown in toolbar . That is the items in the toolbar are arranged in a particular order and the edit button activates the rightmost of those items for which edits have been made to the selected image.

The toolbar includes five UI items arranged in a particular order from left to right. The crop item activates a cropping and rotation tool that allows the user to align crooked images and remove unwanted portions of an image. The exposure item activates a set of exposure tools that allow the user to modify the black point shadows contrast brightness highlights and white point of an image. In some embodiments the set of exposure tools is a set of connected sliders that work together to modify the luminance histogram of an image. Details of exposure tools are described in concurrently filed U.S. patent application Ser. No. 13 629 514 entitled Unified Slider Control for Modifying Multiple Image Properties . U.S. patent application Ser. No. 13 629 514 is here incorporated by reference. The color item activates a set of color tools that enable the user to modify the saturation and vibrancy as well as color specific saturations e.g. blue pixels or green pixels and white balance. In some embodiments some of these tools are presented as a set of sliders. The brushes item activates a set of enhancement tools that enable a user to localize modifications to the image. With the brushes the user can remove red eye and blemishes and apply or remove saturation and other features to localized portions of an image by performing a rubbing action over the image. Finally the effects item activates a set of special effects that the user can apply to the image. These effects include gradients tilt shifts non photorealistic desaturation effects grayscale effects various filters etc. In some embodiments the application presents these effects as a set of items that fan out from the toolbar .

The toolbar includes a settings item . The settings button activates a context sensitive menu that provides different menu options depending on the currently active toolset. For instance in viewing mode the menu of some embodiments provides options for creating a new album setting a key photo for an album copying settings from one photo to another and other options. When different sets of editing tools are active the menu provides options related to the particular active toolset.

One of ordinary skill in the art will recognize that the GUI is only one example of many possible graphical user interfaces for an image editing application. For instance the various items could be located in different areas or in a different order and some embodiments might include items with additional or different functionalities. The thumbnail display area of some embodiments might display thumbnails that match the aspect ratio of their corresponding full size images etc.

An example activation operation of the effects tool will now be described by reference to the four stages illustrated in . The first stage of the GUI shows the activation of the effects tool . As shown a user is selecting the selectable effects tool UI item e.g. by touching the UI item to activate the effects tool .

The second stage illustrates the GUI after the effects tool is activated. As shown the GUI is displaying the start of the fanning open animation of effects controls of the effects tool and the effects tool UI item is highlighted. As shown the effects tool includes a set of effects controls and a selectable UI item . Each of the effects controls is for applying a set of effects to an image being edited the image in this example . The selectable UI item is for initiating a fanning open animation of the effects controls .

When the image editing application receives the selection of the effects tool UI item the application highlights the UI item and starts displaying the fanning open animation of the set of effects controls . In this example the starting position and location of the effects controls for the fanning open animation is the position of the effects control which positioned over the toolbar . That is all of the effects controls start at the location and position of the effects control at the beginning of the fanning open animation. The image editing application displays the fanning open animation of the effects controls by displaying rotations of different effects controls from the starting position and location by different amounts about a fixed location e.g. a pivot point . In this example the fixed location is the UI item . As shown each of the effects controls rotates about the fixed location in decreasing amounts and the effects control does not rotate at all. In other words the effects control rotates the largest amount about the fixed location the effects control rotates the second largest amount about the fixed location the effects control rotates the third largest amount about the fixed location the effects control rotates the fourth largest amount about the fixed location and the effects control does not rotate about the fixed location.

In some embodiments the image editing application displays the fanning open animation of the effects controls by displaying for a defined interval of time rotations of different effects controls about the fixed location at different speeds from the starting position and location. The effects control rotates at the fastest speed about the fixed location the effects control rotates at the second fastest speed about the fixed location the effects control rotates at the third fastest speed about the fixed location the effects control rotates at the fourth fastest speed about the fixed location and the effects control does not rotate about the fixed location.

The image editing application of some embodiments displays the fanning open animation of the effects controls by displaying rotations of the effects controls about the fixed location at the same speed from the starting position and location. To display a fanning open animation with the effects controls moving at the same speed the image editing application starts moving different effects controls at different times e.g. start moving a particular effects control after a defined amount of time . Under this approach the application starts moving the effects control first the effects control second the effects control third the effects control fourth and the effects control last.

The third stage illustrates the GUI near the end of the fanning open animation of the effects controls of the effects tool . As shown the position of the effects controls is fanned open more than the position of the effects controls illustrated in the second stage .

The fourth stage shows the GUI after the completion of the fanning open animation of the effects controls . As shown the effects control has rotated approximately 90 degrees clockwise about the UI item from its starting location and position the location and position of the effects control in this example the effects control has rotated approximately 67.5 degrees clockwise about the UI item from its starting location and position the effects control has rotated approximately 45 degrees clockwise about the UI item from its starting location and position and the effects control has rotated approximately 22.5 degrees clockwise about the UI item from its starting location and position.

The first stage of the GUI shows the selection of an effects control of the effects tool . As shown a user is selecting the effects controls e.g. by touching the effects control . When the image editing application receives the selection of the effects control the application highlights the selected effects control the effects control in this example and starts displaying a fanning closed animation of the set of effects controls .

The second stage illustrates the GUI after the effects control is selected and the fanning closed animation of the set of effects controls has started. The image editing application highlights the effects control by bolding the border of the effects control . In this example the positions and locations of the set of effects controls shown in the fourth stage of are the set of effects controls s starting positions and locations for the fanning closed animation.

The image editing application displays the fanning closed animation of the effects controls by displaying rotations of different effects controls from the effects controls starting positions and locations by different amounts about a fixed location the UI item in this example . As shown each of the effects controls rotates about the fixed location in decreasing amounts and the effects control does not rotate at all. In other words the effects control rotates the largest amount about the fixed location the effects control rotates the second largest amount about the fixed location the effects control rotates the third largest amount about the fixed location the effects control rotates the fourth largest amount about the fixed location and the effects control does not rotate about the fixed location. The direction of rotation of the effects control illustrated in counter clockwise in this example is opposite of the direction of the rotation of the effects control during the fanning open animation illustrated in .

In some embodiments the image editing application displays the fanning closed animation of the effects controls by displaying for a defined interval of time rotations of different effects controls about the fixed location at different speeds from the effects controls different starting positions and locations. The effects control rotates at the fastest speed about the fixed location the effects control rotates at the second fastest speed about the fixed location the effects control rotates at the third fastest speed about the fixed location the effects control rotates at the fourth fastest speed about the fixed location and the effects control does not rotate about the fixed location.

The image editing application of some embodiments displays the fanning closed animation of the effects controls by displaying rotations of the effects controls about the fixed location at the same speed from effects controls different starting positions and locations. To display a fanning closed animation with the effects controls moving at the same speed the application starts moving different effects controls at different times e.g. start moving a particular effects control after a defined amount of time . Under this approach the image editing application starts moving the effects control first the effects control second the effects control third the effects control fourth and the effects control last. In some embodiments the application starts moving the effects control second when the first effects control is at or near the position of the effects control . In this way the effects controls and appear to move together as one effects control. The image editing application starts moving the effects controls and in a similar manner the application starts moving the effects control when the effects controls and are at or near the position of the effects control and the application starts moving the effects control when the effects controls are at or near the position of the effects control .

The third stage illustrates the GUI near the end of the fanning closed animation of the effects controls of the effects tool . As shown the effects controls and have stopped rotating about the fixed location. The positions of the effects controls and which underlap the selected effects control are the same position as the position of the selected effects control . The effects controls and are still rotating counter clockwise about the fixed location. As shown in the third stage the position of effects controls is fanned closed more than the position of the effects controls illustrated in the second stage .

The fourth stage shows the GUI after the completion of the fanning closed animation of the effects controls . When the image editing application displays a fanning closed animation of the set of effects controls the application displays the effects controls that overlap the selected effects control rotating about the fixed location past the location and position of the effects controls . The fanning closed animation of the effects controls that overlap the selected effects control end at a position and location that is rotated approximately 90 degrees counter clockwise about the fixed location from the location and position at which the effects controls that underlap the selected effects control and the selected effects control end. At the end of the fanning closed animation of the set of the effects controls the effects controls that overlap the selected effects control appear to hang from the fixed location about which the effects controls rotated.

For the example illustrated in the fourth stage of the selected effects control is the effects control . Thus at the end of the fanning closed animation the effects controls end at the location and position illustrated in the fourth stage . In addition the effects controls and which overlap the selected effects control end at the location and position that is rotated approximately 90 degrees counter clockwise about the fixed location from the ending location and position of the effects controls .

While illustrates selecting a particular effects control of an effects tool one of ordinary skill in the art will recognize that any of the effects controls of the effects tool may be selected after the effects tool is activated. For example the user could have selected effects controls or .

After selecting an effects control of the effects tool a user might want to change the selection of the effects control. conceptually illustrates changing the selected effects control of the effects tool illustrated in . Specifically illustrates the GUI at four different stages of an effects control change operation.

The first stage of the GUI is similar to the fourth stage of the GUI illustrated in . That is the first stage shows the GUI after the effects control is selected the effects control is highlighted with a bolded border and a fanning closed animation of the set of effects controls has completed. In addition the first stage illustrates the invocation of an operation for changing the selection of the effects control of the effects tool . As shown a user is selecting the selectable UI item e.g. by touching the UI item to invoke the operation for changing the selection of the effects control.

The second stage illustrates the GUI after the image editing application has finished a fanning open animation of the set of effects controls . When the application receives the selection of the UI item the application displays a fanning open animation of the set of effects controls that is similar to the fanning open animation described above by reference to . As shown the effects control remains highlighted because the effects control is the current selected effects control of the effects tool .

In the third stage the GUI shows a selection of a different effects control of the effects tool . As shown the user is selecting the effects control e.g. by touching the effects control . When the image editing application receives the selection of the effects control the application highlights the effects control and displays a fanning closed animation of the set of effects controls that is similar to the fanning closed animation of the set of effects controls described above by reference to .

The fourth stage illustrates the GUI after the fanning closed animation of the set of effects controls is finished and the selected effects control is highlighted. In this example the set of effects controls rotate about the UI item and end the position of the selected effects control . Since none of the other effects controls i.e. the effects controls of the effects tool overlap the selected effects control the end positions of the effects controls are the same as the end position of the selected effects control . Therefore none of the effects controls appear to hang from the fixed location about which the effects controls rotated.

In some embodiments the image editing application provides the GUI described above in when the application is in a landscape viewing mode. The following figures will describe a GUI that the application of some such embodiments provides when the application is in a portrait viewing mode.

The stages of the GUI are similar to the stages described above by reference to . That is the first stage shows the activation of the effects tool the second stage shows the start of the fanning open animation of the effects controls the third stage shows the effects controls near the end of the fanning closed animation and the fourth stage shows the effects controls at the end of the fanning open animation.

In addition the fanning closed animation of the effects tool in the GUI when an effects control of the effects tool is similar to the animation described above by reference to . Also the technique for changing the selection of an effects control of the effects tool in the GUI and the accompanying animations are similar to the technique and animations described above by reference to .

In some embodiments the GUI for the example operations described above by reference to may be provided by an image editing application when the application is in a landscape viewing mode. The image editing application of some embodiments provides GUI described above by reference to for the example operations when the application is in a portrait viewing mode. However in some cases the image editing application provides a yet another GUI for the example operations. For instance the display screen of a mobile computing device e.g. a smartphone on which the application is running might not have enough space to display the example operations illustrated in .

The GUI is similar to the GUI that is described above by reference to except the thumbnail display area in the GUI is arranged below the image display area and above the toolbar . Also the GUI does not include the toolbar and thus the UI items are displayed in the toolbar instead.

The first stage of the GUI shows the activation of the effects tool . In this stage a user is selecting the selectable effects tool UI item e.g. by touching the UI item to activate the effects tool .

The second stage illustrates the GUI after the effects tool is activated. As shown the GUI is displaying the start of the fanning open animation of the set of effects controls and the effects tool UI item is highlighted. When the image editing application receives the selection of the effects tool UI item the application highlights the UI item removes the UI items from the toolbar e.g. by displaying an animation of the UI items sliding towards the left and off the toolbar and displays the UI item on the left side of the toolbar .

When the image editing application receives the selection of the effects tool UI item the application also starts displaying the fanning open animation of the set of effects controls . For this example the starting position of the effects controls for the fanning open animation indicated with a dashed rectangle in the toolbar . As the fanning open animation starts the image editing application displays the effects controls as rotating clockwise about a fixed location the selectable UI item in this example relative to the effects control . While fanning open the effects controls the application also moves the fixed location and in turn the effects controls towards the middle of the right side of the image display area . In other words the application displays the effects controls fanning open as the application displays the effects controls sliding the effects controls up and towards the middle of the right side of the image display area .

The image editing application displays the fanning open animation of the effects controls by displaying rotations of different effects controls from the starting position and location by different amounts about the fixed location. As shown the effects control each rotates about the fixed location in decreasing amounts relative to the effects control .

In some embodiments the image editing application displays the fanning open animation of the effects controls by displaying for a defined interval of time rotations of different effects controls about the fixed location at different speeds from the starting position and location. The interval of time is defined in some embodiments as the time that the application starts moving the effects controls from the toolbar until the application stops moving the effects controls off the middle of the right side of the image display area . In such embodiments the effects control rotates at the fastest speed about the fixed location the effects control rotates at the second fastest speed about the fixed location the effects control rotates at the third fastest speed about the fixed location the effects control rotates at the fourth fastest speed about the fixed location and the effects control does not rotate about the fixed location.

The image editing application of some embodiments displays the fanning open animation of the effects controls by displaying rotations of the effects controls about the fixed location at the same speed from the starting position and location. To display a fanning open animation with the effects controls moving at the same speed the application starts moving different effects controls at different times e.g. start moving a particular effects control after a defined amount of time . Under this approach the application starts moving the effects control first the effects control second the effects control third the effects control fourth and the effects control last.

The third stage illustrates the GUI near the end of the fanning open animation of the effects controls of the effects tool . As shown the position of the effects controls is fanned open more than the position of the effects controls illustrated in the second stage . Also the location of the fixed location and in turn the effects controls is farther towards the middle of the right side of the image display area than the location of the fixed location illustrated in the second stage .

The fourth stage shows the GUI after the completion of the fanning open animation of the effects controls . As shown the effects control has rotated approximately 90 degrees clockwise about the fixed location from its starting location and position the effects control has rotated approximately 67.5 degrees clockwise about the fixed location from its starting location and position the effects control has rotated approximately 45 degrees clockwise about the fixed location from its starting location and position and the effects control has rotated approximately 22.5 degrees clockwise about the fixed location from its starting location and position.

The first stage of the GUI shows the selection of an effects control of the effects tool . As shown a user is selecting the effects controls e.g. by touching the effects control . When the image editing application receives the selection of the effects control the application highlights the selected effects control the effects control in this example and starts displaying a fanning closed animation of the set of effects controls .

The second stage illustrates the GUI after the effects control is selected and the fanning closed animation of the set of effects controls has started. The application highlights the effects control by bolding the border of the effects control . In this example the positions and locations of the set of effects controls shown in the fourth stage of are the set of effects controls s starting positions and locations for the fanning closed animation.

As the fanning closed animation starts the image editing application displays the effects controls as rotating counter clockwise about the fixed location e.g. the UI item in this example relative to the effects control . While fanning the effects controls the application also moves the fixed location and in turn the effects controls from the middle of the right side of the image display area towards the right side of the toolbar . In other words the application displays the effects controls fanning closed as the application displays the fixed location sliding from the middle of the rights side of the image display area towards the right side of the toolbar .

The image editing application displays the fanning closed animation of the effects controls by displaying rotations of different effects controls from the effects controls starting positions and locations by different amounts about a fixed location. As shown the effects control each rotates about the fixed location relative to the effects control which is described above by reference to in decreasing amounts. The direction of rotation of the effects control illustrated in counter clockwise in this example is opposite of the direction of the rotation of the effects control during the fanning open animation illustrated in .

In some embodiments the image editing application displays the fanning closed animation of the effects controls by displaying for a defined interval of time rotations of different effects controls about the fixed location at different speeds from the effects controls different starting positions and locations. The interval of time is defined in some embodiments as the time that the application starts moving the fixed location and in turn the effects controls from the middle of the right side of the image display area and towards the right side of the toolbar until the application has moved the effects controls over the toolbar .

The image editing application of some embodiments displays the fanning closed animation of the effects controls by displaying rotations of the effects controls about the fixed location at the same speed from effects controls different starting positions and locations. To display a fanning closed animation with the effects controls moving at the same speed the application starts moving different effects controls at different times e.g. start moving a particular effects control after a defined amount of time . Under this approach the image editing application starts moving the effects control first the effects control second the effects control third the effects control fourth and the effects control last. In some embodiments the application starts moving the effects control second when the first effects control is at or near the position of the effects control . In this way the effects controls and appear to move together as one effects control. The image editing application starts moving the effects controls and in a similar manner the application starts moving the effects control when the effects controls and are at or near the position of the effects control and the application starts moving of the effects control when the effects controls are at or near the position of the effects control .

The third stage illustrates the GUI near the end of the fanning open animation of the effects controls of the effects tool . As shown the position of the effects controls is fanned closed more than the position of the effects controls illustrated in the second stage . Also the location of the fixed location and in turn the effects controls is farther towards the right side of the toolbar than the location of the fixed location illustrated in the second stage .

The fourth stage shows the GUI after the completion of the fanning closed animation of the effects controls . When the image editing application finishes the fanning closed animation the application displays the selected effects control over the toolbar . The application also displays the effects controls that overlap the selected effects control in a similar way that is illustrated in the fourth stage of . That is the image editing application displays the effects controls that overlap the selected effects control at a position and location that is rotated approximately 90 degrees counter clockwise about the selectable UI item from the location and position at which the application displays the selected effects control. At the end of the fanning closed animation of the set of the effects controls in the fourth stage the effects controls that overlap the selected effects control appear to hang from the selectable UI item .

For the example illustrated in the fourth stage of the selected effects control is the effects control . Thus the image editing application displays the effects controls and which overlap the selected effects control at the location and position that is rotated approximately 90 degrees counter clockwise about the UI item from the selected effects control .

While illustrates selecting a particular effects control of an effects tool one of ordinary skill in the art will recognize that any of the effects controls of the effects tool may be selected after the effects tool is activated. For example the user could have selected effects controls or .

As mentioned above after selecting an effects control of the effects tool a user might want to change the selection of the effects control. conceptually illustrates changing the selected effects control of the effects tool illustrated in . Specifically illustrates the GUI at four different stages of an effects control change operation.

The first stage of the GUI is similar to the fourth stage of the GUI illustrated in . That is the first stage shows the GUI after the effects control is selected the effects control is highlighted with a bolded border a fanning closed animation of the set of effects controls has completed and the selected effects control is displayed over the toolbar . In addition the first stage illustrates the invocation of an operation for changing the selection of the effects control of the effects tool . As shown a user is selecting the selectable UI item e.g. by touching the UI item to invoke the operation for changing the selection of the effects control.

The second stage illustrates the GUI after the image editing application has finished a fanning open animation of the set of effects controls . When the application receives the selection of the UI item the application displays a fanning open animation of the set of effects controls that is similar to the fanning open animation described above by reference to . As shown the effects control remains highlighted because the effects control is the current selected effects control of the effects tool .

In the third stage the GUI shows a selection of a different effects control of the effects tool . As shown the user is selecting the effects control e.g. by touching the effects control . When the image editing application receives the selection of the effects control the application removes the highlighting of the previously selected effects control highlights the newly selected effects control and displays a fanning closed animation of the set of effects controls that is similar to the fanning closed animation of the set of effects controls described above by reference to .

The fourth stage illustrates the GUI after the fanning closed animation of the set of effects controls is finished and the selected effects control is highlighted and displayed over the toolbar . Since none of the other effects controls i.e. the effects controls of the effects tool overlap the selected effects control the end positions of the effects controls are the same as the end position of the selected effects control . Therefore none of the effects controls appear to hang from the UI item .

The described above show several techniques for fanning UI controls open and fanning UI controls closed. For instance show selecting a UI item the UI item in those examples to fan open the UI controls in order to select a different UI control and selecting a UI control to fan closed the UI controls. However other techniques may be used to fan open and closed the UI controls in some embodiments. For example the UI tool of some embodiments allows a user to perform a gesture e.g. a swipe up gesture on the selected UI control in order to fan open the UI controls. Similarly in some embodiments the UI tool allows the user to perform a gesture e.g. a swipe down gesture on the image display area in order to fan closed the UI controls when the UI controls are fanned open and the user does not want to select a different UI control i.e. the user wants to keep the current selected UI control as selected . Other techniques are possible.

As noted above each effects control of an effects tool of some embodiments is for applying a set of effects to an image being edited. Different embodiments of effects tools include different types of effects controls. The following will illustrate several examples of different effects tools that include different types of effects controls.

As shown each UI item of a thumbnail slider control displays a thumbnail image of the image being edited e.g. a small representation of a full size version of the image being edited and an extent of an effect associated with the thumbnail slider control applied to the thumbnail image. In this example several of the effects are represented by different types of lines vertical lines horizontal lines and diagonal lines . The more lines displayed on an image represents a greater extent of the effect that is applied to the image and the less lines displayed on the image represents a lesser extent of the effect that is applied to the image.

For instance the thumbnail slider control is for applying an effect that is represented by displaying vertical lines on an image. Each UI item of the thumbnail slider control displays a thumbnail image of the image and an extent of the effect associated with the thumbnail slider control applied to the thumbnail image. The leftmost UI item of the thumbnail slider control does not have any vertical lines displayed on its thumbnail image to indicate that a very small extent of the effect is applied to the thumbnail image of the leftmost UI item. The second leftmost UI item of the thumbnail slider control has two vertical lines displayed on its thumbnail image to indicate that a small extent of the effect is applied to the thumbnail image of the second leftmost UI item. The middle UI item of the thumbnail slider control has three vertical lines displayed on its thumbnail image to indicate that a medium extent of the effect is applied to the thumbnail image of the middle UI item. The second rightmost UI item of the thumbnail slider control has six vertical lines displayed on its thumbnail image to indicate that a large extent of the effect is applied to the thumbnail image of the second rightmost UI item. The rightmost UI item of the thumbnail slider control has eleven vertical lines displayed on its thumbnail image to indicate that a very large extent of the effect is applied to the thumbnail image of the rightmost UI item.

The first stage of the GUI is similar to the fourth stage illustrated in except the effects tool in includes a set of thumbnail slider controls. As shown a user has activated the effects tool e.g. by selecting the UI item as indicated by the highlighting of the effects item . Additionally the user has selected a thumbnail slider control of the effects tool e.g. by touching the thumbnail slider control when the set of thumbnail slider controls of the effects tool were fanned out .

The thumbnail slider control is similar to the thumbnail slider controls described above by reference to . That is the thumbnail slider control includes a set of selectable UI items located at different positions along the thumbnail slider control . The set of selectable UI items are for applying different extents of an effect associated with the thumbnail slider control to the image being edited the image in this example . As shown each selectable UI item displays a thumbnail image of the image and an extent of an effect associated with the thumbnail slider control applied to the thumbnail image. Each UI item is for applying the effect to the image to the extent that the effect is applied to the UI item s thumbnail image. In this example the effect associated with the thumbnail slider control is represented by diagonal lines that run from the lower left to the upper right. The more diagonal lines displayed on an image represents a greater extent of the effect that is applied to the image and the less diagonal lines displayed on the image represents a lesser extent of the effect that is applied to the image.

The second stage illustrates the GUI after a selectable UI item of the thumbnail slider control is selected. Here the user has selected the UI item to apply the effect associated with the thumbnail slider control to the image . The selection of the UI item is indicated by a highlighting of the UI item . When the image editing application receives the selection of the UI item the application highlights the UI item and applies the effect to the image to the extent that the effect is applied to the UI item s thumbnail image. As shown in the second stage three diagonal lines are displayed on image which is the same number of diagonal lines displayed on the thumbnail image of the UI item to indicate that the effect associated with the thumbnail slider control is applied to the image .

Some effects may be difficult to notice or an effect is applied to an image at a very small extent. To indicate that an effect is applied to an image the image editing application of some embodiments displays an indicator e.g. a highlight above the effects tool UI item when the application applies an effect to the image. As illustrated in the second stage such an indicator is displayed above the effects tool UI item and represented by a thick white line with a black border. The application displays the indicator when the application receives the selection of the UI item . In some embodiments the application continues to display the indicator above the effects tool UI item as long as one or more effects are applied to the image being edited even if a different tool is activated .

The third stage illustrates the GUI after the user has selected another selectable UI item of the thumbnail slider control . In this stage the user has selected the UI item e.g. by touching the UI item to apply the effect associated with the thumbnail slider control to the image in order to increase the extent that the effect is applied to the image . The selection of the UI item is indicated by a highlighting of the UI item . When the image editing application receives the selection of the UI item the application highlights the UI item removes the highlighting of the UI item and applies the effect to the image to the same extent that the effect is applied to the UI item s thumbnail image. As shown in the third stage more diagonal lines are displayed on image compared to the number of diagonal lines displayed on the image in the second stage to indicate that a larger extent of the effect is applied to the image .

In the fourth stage the GUI illustrates that the user has selected another selectable UI item of the thumbnail slider control to change the extent that the effect is applied to the image . In the fourth stage the user has selected the UI item e.g. by touching the UI item to apply the effect associated with the thumbnail slider control to the image in order to decrease the extent that the effect is applied to the image . The selection of the UI item is indicated by a highlighting of the UI item . When the image editing application receives the selection of the UI item the application highlights the UI item removes the highlighting of the UI item and applies the effect to the image to the same extent that the effect is applied to the UI item s thumbnail image. As shown no diagonal lines are displayed on image to indicate that a smaller extent of the effect is applied to the image .

The first stage of the GUI is similar to the fourth stage illustrated in except the effects tool in includes a set of thumbnail slider controls. As shown a user has activated the effects tool e.g. by selecting the UI item as indicated by the highlighting of the effects item . In addition the user has selected a thumbnail slider control of the effects tool e.g. by touching the thumbnail slider control when the set of thumbnail slider controls of the effects tool were fanned out .

As shown the thumbnail slider control includes a selectable sliding region and a set of thumbnail images located at different positions along the selectable sliding region . The sliding region is for applying different extents of an effect associated with the thumbnail slider control to the image being edited the image in this example . Different locations along the horizontal axis of the sliding region are for applying different extents of the effect to the image being edited. For instance in some embodiments a first horizontal end of the sliding region corresponds to little or no effect applied to the image being edited a second horizontal end of the sliding region corresponds to a full extent of the effect applied to the image being edited and the incremental horizontal locations from the first end to the second end of the sliding region correspond to incremental extents of the effect applied to the image being edited. In this example the left side of the selectable sliding region corresponds to no extent of the effect applied to the image being edited and the right side of the selectable sliding region corresponds to a full extent of the effect applied to the image being edited.

As shown each of the thumbnail images displays a thumbnail image of the image and an extent of an effect associated with the thumbnail slider control applied to the thumbnail image. In this example the location in the middle of each thumbnail image in the selectable sliding region corresponds to the extent of the effect that is applied to the thumbnail image. This way the thumbnail images provide the user with a visual indication of the extent that the effect will be applied to the image being edited when the user selects the middle of the thumbnails. Different embodiments use different locations in the selectable sliding region relative to the thumbnail images to correspond to the extent of the effect that is applied to the thumbnail images. For instance some embodiments may use the location near the left of each thumbnail image in the selectable sliding region to correspond to the extent of the effect that is applied to the thumbnail image.

The second stage illustrates the GUI after a location on the sliding region of the thumbnail slider control is selected. Here the user has selected a location near the thumbnail image to apply the effect associated with the thumbnail slider control to the image . When a location on the sliding region is select the image editing application displays an indicator that indicates the selected location and highlights the thumbnail closest to the location. As shown the user has selected a location near the thumbnail image . When the application receives the selection of this location the application highlights the thumbnail image and applies the effect to the image to the extent that corresponds with the selected location. As shown in the second stage the extent of the effect applied to the image is similar to the extent that the effect is applied to the thumbnail image . In this example since no effect is applied to the image prior to the second stage the application displays an indicator above the effects tool UI item when the application receives the selection of the thumbnail image to indicate that an effect is applied to the image .

The third stage illustrates the GUI after the user has selected another location along the selectable sliding region of the thumbnail slider control . In this stage the user has selected a location on the sliding region to increase the extent that the effect is applied to the image . The user may select the location by continuing to touch the sliding region in the second stage and sliding along the sliding region to the location or by touching the location on the sliding region .

The selection of the location shown in the third stage is indicated by a highlighting of the thumbnail image which is the thumbnail image closest to the location. In instances where the user selects the location by sliding a finger along the sliding region the application of some embodiments continues to display the indicator at the location that is selected. That is as the finger is moving along the sliding region the application moves the location of the indicator along with the finger.

In some embodiments the application continues to highlight the nearest thumbnail image in the sliding region while the user is sliding a finger along the sliding region . Thus the application of such embodiments highlights the thumbnail image and removes the highlighting of the thumbnail image when the location of the sliding finger is closer to the thumbnail image than the thumbnail image . Similarly the application highlights the thumbnail image and removes the highlighting of the thumbnail image when the location of the sliding finger is closer to the thumbnail image than the thumbnail image .

The application of some embodiments applies the effect to the image to the extent that corresponds with the selected location while the user is sliding the finger along the sliding region . As shown in the third stage more diagonal lines are displayed on image compared to the number of diagonal lines displayed on the image in the second stage to indicate that a larger extent of the effect is applied to the image .

In the fourth stage the GUI illustrates that the user has selected another location along the selectable sliding region to change the extent that the effect is applied to the image . In the fourth stage the user has selected a location on the sliding region to reduce the extent that the effect is applied to the image . The user may select this location by continuing to touch the sliding region in the third stage and sliding along the sliding region to the location or by touching the location on the sliding region .

In some embodiments the image editing application highlights the thumbnail images displays the indicator and applies the effect to the image in a similar manner described above in the third stage . As shown in this stage no diagonal lines are displayed on image to indicate that a smaller extent of the effect is applied to the image .

In some embodiments the application provides a thumbnail slider control for applying several different effects to an image being edited. conceptually illustrates a thumbnail slider control of some embodiments and using the thumbnail slider control to apply different effects to an image. Specifically illustrates the GUI at four different stages of several effect application operations.

The first stage of the GUI is similar to the fourth stage illustrated in except the effects tool in includes a set of thumbnail slider controls. As shown a user has activated the effects tool e.g. by selecting the UI item as indicated by the highlighting of the effects item . In addition the user has selected a thumbnail slider control of the effects tool e.g. by touching the thumbnail slider control when the set of thumbnail slider controls of the effects tool were fanned out .

As shown in the thumbnail slider control includes a set of selectable UI items located at different positions along the thumbnail slider control . The set of selectable UI items are for applying different effects associated with the thumbnail slider control to the image being edited the image in this example . In this example several of the different effects are represented by different types of lines vertical lines horizontal lines left to right diagonal lines and right to left diagonal lines in this example . As shown each selectable UI item displays a thumbnail image of the image and a different effect applied to the thumbnail image.

In some embodiments the thumbnail slider control provides different effects of the same type. For instance the thumbnail slider control of some embodiments provides different painting effects different black and white effects different color effects etc. The thumbnail slider control provides different types of different effects in some embodiments.

The second stage illustrates the GUI after a selectable UI item of the thumbnail slider control is selected. Here the user has selected the UI item to apply an effect that corresponds to the UI item to the image . The selection of the UI item is indicated by a highlighting of the UI item . When the image editing application receives the selection of the UI item the application highlights the UI item and applies the effect that corresponds to the UI item to the image . In this example since no effect is applied to the image prior to the second stage the application displays an indicator above the effects tool UI item when the application receives the selection of the UI item to indicate that an effect is applied to the image .

The third stage illustrates the GUI after the user has selected another selectable UI item of the thumbnail slider control . In this stage the user has selected the UI item e.g. by touching the UI item to apply a different effect associated with the thumbnail slider control to the image . The selection of the UI item is indicated by a highlighting of the UI item . When the image editing application receives the selection of the UI item the application highlights the UI item removes the highlighting of the UI item and applies the effect that corresponds to the UI item to the image .

In the fourth stage the GUI illustrates that the user has selected another selectable UI item of the thumbnail slider control to change the effect that is applied to the image . In the fourth stage the user has selected the UI item e.g. by touching the UI item to apply the effect that corresponds to the UI item to the image . The selection of the UI item is indicated by a highlighting of the UI item . When the image editing application receives the selection of the UI item the application highlights the UI item removes the highlighting of the UI item and applies the effect that corresponds to the UI item to the image .

Details of effects that may be implemented by a thumbnail slider control for applying different types of effects to an image are described in concurrently filed U.S. patent application Ser. No. 13 629 383 entitled Overlaid User Interface Tools for Applying Effects to Image U.S. patent application Ser. No. 13 602 124 filed Sep. 1 2012 and U.S. patent application Ser. No. 13 602 135 filed Sep. 1 2012. U.S. patent application Ser. Nos. 13 629 383 13 602 124 and 13 602 135 are herein incorporated by reference.

The first stage of the GUI is similar to the fourth stage illustrated in except the effects tool in includes a set of thumbnail slider controls. As shown a user has activated the effects tool e.g. by selecting the UI item as indicated by the highlighting of the effects item . In addition the user has selected a thumbnail slider control of the effects tool e.g. by touching the thumbnail slider control when the set of thumbnail slider controls of the effects tool were fanned out .

As shown the thumbnail slider control includes a selectable sliding region a set of thumbnail images located at different positions along the selectable sliding region and a set of selectable UI items . The sliding region is for applying different extents of an effect associated with the thumbnail slider control to the image being edited the image in this example . Different locations along the horizontal axis of the sliding region are for applying different extents of the effect to the image being edited. For instance in some embodiments a first horizontal end of the sliding region corresponds to little or no effect applied to the image being edited a second horizontal end of the sliding region corresponds to a full extent of the effect applied to the image being edited and the incremental horizontal locations from the first end to the second end of the sliding region correspond to incremental extents of the effect applied to the image being edited. In this example the left side of the selectable sliding region corresponds to no extent of the effect applied to the image being edited and the right side of the selectable sliding region corresponds to a full extent of the effect applied to the image being edited.

As shown each of the thumbnail images displays a thumbnail image of the image and an extent of an effect associated with the thumbnail slider control applied to the thumbnail image. In this example the location in the middle of each thumbnail image in the selectable sliding region corresponds to the extent of the effect that is applied to the thumbnail image. This way the thumbnail images provide the user with a visual indication of the extent that the effect will be applied to the image being edited when the user selects the middle of the thumbnails. Different embodiments use different locations in the selectable sliding region relative to the thumbnail images to correspond to the extent of the effect that is applied to the thumbnail images. For instance some embodiments may use the location near the left of each thumbnail image in the selectable sliding region to correspond to the extent of the effect that is applied to the thumbnail image.

The set of selectable UI items are for applying different effects to the image being edited after an effect is applied to the image using the sliding region . In some embodiment set of selectable UI items may be used to apply the different effects to the image without having applied effects to the image using the sliding region . Examples of effects include a vignette effect a sepia effect a grain effect or any other effect for modifying the appearance of the image. While first stage shows the GUI displaying the set of UI items the application of some embodiments provides the UI items after an effect has been applied using the sliding region .

The second stage illustrates the GUI after a location on the sliding region of the thumbnail slider control is selected. Here the user has selected a location near the thumbnail image to apply the effect associated with the thumbnail slider control to the image . When a location of the sliding region is select the image editing application displays an indicator that indicates the selected location and highlights the thumbnail closest to the location. As shown the user has selected a location near the thumbnail image . When the application receives the selection of this location the application highlights the thumbnail image and applies the effect to the image to the extent that corresponds with the selected location. As shown in the second stage the extent of the effect applied to the image is similar to the extent that the effect is applied to the thumbnail image . In this example since no effect is applied to the image prior to the second stage the application displays an indicator above the effects tool UI item when the application receives the selection of the thumbnail image to indicate that an effect is applied to the image .

The third stage of the GUI illustrates that the user has selected one of the selectable UI items for applying and additional effect to the image begin edited. As shown the user has selected the UI item e.g. by touching the UI item to apply a vignette effect to the image . The third stage also shows that the vignette effect applied to the image as indicated by a darkening of the area around the border of the image .

Although illustrate several examples of thumbnail slider controls with thumbnails of an image being edited positioned in a straight line along the thumbnail slider control different embodiments position the thumbnails along the thumbnail slider control differently. For instance the thumbnail slider control of some embodiments has thumbnails of an imaged being edited positioned in a curved manner along the thumbnail slider control. As another example thumbnails of the image being edited may be positioned in a staggered fashion along the thumbnail slider control of some embodiments e.g. some thumbnails staggered up and some thumbnails staggered down . Many other ways of positioning thumbnails along a thumbnail slider controls are possible in other embodiments.

The above described illustrate examples of a continuous thumbnail slider control. Those examples show an indicator that indicates the selected location and a highlighting of the thumbnail closest to the location indicated by the indicator. Different embodiments use different techniques for highlighting the selected location. For example alternatively or in conjunction with highlighting the closest thumbnail the image editing application of some embodiments highlights the indicator. Other techniques for indicating the selected location are possible.

The process begins by identifying at an image from which to generate thumbnails. In some embodiments the process identifies the image that is being edited. Referring to as an example the process identifies the image since the image is the image being edited i.e. the image is the image that is displayed in the image display area .

Next the process identifies at a thumbnail slider control of an effects tool. Continuing with the example shown in the process identifies one of the thumbnail slider controls of the effects tool .

The process then identifies at an effect associated with the identified thumbnail slider control. Different effects may be associated with the thumbnail slider control. Examples of different effects include a black and white effect a sepia effect a duotone effect a gradient effect a vignette effect a tilt shift effect or any other effect that can be applied to an image.

Next the process generates at a set of thumbnail images based on the identified image and the identified effect. As described above the thumbnail slider control of some embodiments is for controlling different extents of a single effect that is applied to an image being edited. In such embodiments the process generates a set of thumbnail images of the identified image with different extents of the identified effect applied to different thumbnail images.

As noted above in some embodiments the thumbnail slider control is for applying several different effects to an image being edited. In these embodiments the process generates a thumbnail image of the identified image with the one of the different effects applied to the thumbnail image.

After generating the set of thumbnails the process determines at whether any effect is left to process. When the process determines that there is an effect left to process the process returns to to continue generating thumbnails for any remaining effects of the identified thumbnail slider control. For instance in cases where the thumbnail slider control is for applying several different effects to an image being edited the process performs and for each of the different effects associated with the thumbnail slider control. When the process determines that there is no effect left to process the process proceeds to .

At the process determines whether any thumbnail slider control is left to process. When the process determines that there is a thumbnail slider control left to process the process returns to to continue generating thumbnails for any remaining thumbnail slider controls of the effects tool. Referring to as an example the process performs for each of the thumbnail slider controls . When the process determines that there is no thumbnail slider control left to process the process ends.

At state the application is in an image editing viewing or organizing state. In some embodiments the application begins in the state when the application is first started. When the application is in the state the application is providing tools for editing viewing or organizing images. For example the application may be providing sharing tools for sharing images providing various editing tools e.g. a crop and rotate tool an exposure tool a color tool etc. providing tools for tagging images etc.

When the application activates the effects tool while the application is in a landscape viewing mode the application transitions from state to state . When the application activates the effects tool while the application is in a portrait viewing mode the application transitions from state to state . In some cases when the application activates the effects tool the application returns to the last used state. In some such cases the application transitions from state to state if the application is in a landscape viewing mode and transitions from state to state if the application is in a portrait viewing mode not shown in . As shown in when the application is in any of the states and the application disables the effects tool e.g. by activating another tool the application returns to state .

At state the application is in a landscape viewing mode and provides a GUI for displaying the effects controls of the effects tool in a fanned open layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of when in state .

When the application changes to state e.g. from state or state the application displays a fanning open animation of the effects controls of the effects tool . In some embodiments the application displays the fanning open animation similar to the animation described above by reference to .

If an effects control of the effects tool is selected when the application transitions to state e.g. the application transitioned from state the application continues to highlight the selected effects control while in state . When the application is in state and the application receives a selection of an effects control of the effects tool the application transitions to state . When the application is in state and the application changes from a landscape viewing mode to a portrait viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area decreasing the width of the display area increasing the height of the display area etc. the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state .

At state the application is in a landscape viewing mode and provides a GUI for displaying the effects controls of the effects tool in a fanned open layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of when in state .

When the application changes to state from state the application displays a fanning closed animation of the effects controls of the effects tool . In some embodiments the application displays the fanning closed animation similar to the animation described above by reference to . When the application transitions to state the application highlights the selected effects control of the effects tool .

When the application is in state and the application receives a selection of a UI item e.g. the UI item for fanning open the effects controls of the effects tool the application transitions to state . When the application is in state and the application changes from a landscape viewing mode to a portrait viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area decreasing the width of the display area increasing the height of the display area etc. the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state .

When the application is in state and the application receives input e.g. touch input through the selected effects control of the effects tool the application transitions to state . Referring to as an example when the application is in state the application might receive a selection of a selectable UI item of the thumbnail slider control to apply an extent of an effect associated with the thumbnail slider control to the image being edited. Referring to as another example when the application is in state the application might receive a sliding gesture through the selectable sliding region of the thumbnail slider control in order to apply an extent of an effect associated with the thumbnail slider control to the image being edited.

At state the application is in a portrait viewing mode and provides a GUI for displaying the effects controls of the effects tool in a fanned open layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of when in state .

When the application changes to state e.g. from state or state the application displays a fanning open animation of the effects controls of the effects tool . In some embodiments the application displays the fanning open animation similar to the animation described above by reference to .

If an effects control of the effects tool is selected when the application transitions to state e.g. the application transitioned from state the application continues to highlight the selected effects control while in state . When the application is in state and the application receives a selection of an effects control of the effects tool the application transitions to state . When the application is in state and the application changes the viewing mode from a portrait viewing mode to a landscape viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area increasing the width of the display area decreasing the height of the display area etc. the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state .

At state the application is in a portrait viewing mode and provides a GUI for displaying the effects controls of the effects tool in a fanned open layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of when in state .

When the application changes to state from state the application displays a fanning closed animation of the effects controls of the effects tool . In some embodiments the application displays the fanning closed animation similar to the animation described above by reference to . When the application transitions to state the application highlights the selected effects control of the effects tool .

When the application is in state and the application receives a selection of a UI item e.g. the UI item for fanning open the effects controls of the effects tool the application transitions to state . When the application is in state and the application changes from a portrait viewing mode to a landscape viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area increasing the width of the display area decreasing the height of the display area etc. the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state .

When the application is in state and the application receives input e.g. touch input through the selected effects control of the effects tool the application transitions to state . Referring to as an example when the application is in state the application might receive a selection of a selectable UI item of the thumbnail slider control to apply an extent of an effect associated with the thumbnail slider control to the image being edited. Referring to as another example when the application is in state the application might receive a sliding gesture through the selectable sliding region of the thumbnail slider control in order to apply an extent of an effect associated with the thumbnail slider control to the image being edited.

At state the application applies an effect to the image being edited based on input received through the selected effects control of the effects tool . For instance referring to if the application receives a selection of a UI item through the thumbnail slider control in state or state the application in state applies the effect associated with the thumbnail slider control to the image being edited to an extent of the effect that corresponds to the selected UI item. As another example referring to when the application is in state or state and the application receives a selection of a location along the selectable sliding region of the thumbnail slider control the application in state applies the effect associated with the thumbnail slider control to the image being edited to an extent that corresponds to the selected location along the sliding region . After applying the effect based on the received input through the selected effects control of the effects tool the application transitions back to the state from which the application transitioned to state . In other words the application transitions back to state when the application transitions to state from state and the application transitions back to state when the application transitions to state from state .

The state diagram illustrated in shows several different states of the image editing application of some embodiments. One of ordinary skill in the art will recognize that the various actions represented by the states and transitions in are only a subset of the possible actions that can be performed in the application in some embodiments. Additionally other functions that are not shown may be performed while in a particular state. For instance in some embodiments when the image editing application is in fanned closed state e.g. state or state and the application receives input to apply an effect to the image being edited that does not yet have any effects applied to the image the application displays an indicator above the effects tool UI item to indicate that an effect is applied to the image being edited.

The above Sub section A illustrates examples and embodiments of UI tool for applying effects to an image. The following Sub section B will illustrate examples and embodiments of a UI tool for applying brush effects to an image.

The first stage of the GUI shows the activation of the brushes tool . As shown a user is selecting the brushes tool UI item e.g. by touching the UI item to activate the brushes tool .

The second stage illustrates the GUI after the brushes tool is activated. As shown the GUI is displaying the start of the fanning open animation of brush controls of the brushes tool and the UI item is highlighted. As shown the brushes tool includes a set of brush controls . Each of the brush controls is for applying a set of brush effects to an image being edited the image in this example .

When the image editing application receives the selection of the brushes tool UI item the application highlights the UI item and starts displaying the fanning open animation of the set of brush controls . In this example the brush controls start the fanning open animation at the bottom of the image display area from a same vertical position and location and slide from the bottom of the image display area towards the center of the image display area while fanning open. As shown the brush controls are slightly fanned opened from the vertical position and location.

The image editing application displays the fanning open animation of the brush controls by displaying rotations of different brush controls by different amounts about a fixed location. As shown the brush controls and rotate about the fixed location towards the left in a counter clockwise direction with the brush control fanned out more than the brush control . The brush controls and rotate about the fixed location towards the right in a clockwise manner with the brush control fanned out more than the brush control . The brush control does not rotate at all.

In some embodiments the image editing application displays the fanning open animation of the brush controls by displaying for a defined interval of time rotations of different brush controls about the fixed location at different speeds from the starting position and location. The brush controls and rotate at the same speed about the fixed location and the brush controls and rotate at the same speed about the fixed location. The brush controls and rotate at a faster speed than the brush controls and .

The image editing application of some embodiments displays the fanning open animation of the brush controls by displaying rotations of the brush controls about the fixed location at the same speed from the starting position and location. To display a fanning open animation with the brush controls moving at the same speed the image editing application starts moving different brush controls at different times e.g. start moving a particular brush control after a defined amount of time . Under this approach the application starts moving the brush controls and and then starts moving the brush controls and at a later instance in time.

The third stage illustrates the GUI near the end of the fanning open animation of the brush controls of the brushes tool . As shown the brush controls are fanned open from the center more than the position of the brush controls illustrated in the second stage . Additionally the brush controls have slid farther up from the bottom of the image display area compared to the position of the brush controls shown in the second stage . That is between the second stage and the third stage the image editing application fans the brush controls farther open while sliding the brush controls farther up from the bottom of the image display area towards the center of the image display area .

The fourth stage shows the GUI after the completion of the fanning open animation of the brush controls . As shown the brush controls are fanned open from the center more than the position of the brush controls illustrated in the third stage . Also the brush controls have slid farther up from the bottom of the image display area compared to the position of the brush controls shown in the third stage . That is between the third stage and the fourth stage the image editing application fans the brush controls farther open while sliding the brush controls farther up from the bottom of the image display area towards the center of the image display area .

The first stage of the GUI shows the selection of a brush control of the brushes tool . As shown a user is selecting the brush controls e.g. by touching the brush control . When the image editing application receives the selection of the brush control the application highlights the selected brush control the brush control in this example and starts displaying a fanning closed animation of the set of brush controls .

The second stage illustrates the GUI after the brush control is selected and the fanning closed animation of the set of brush controls has started. The image editing application highlights the brush control by bolding the border of the brush control . In this example the positions and locations of the set of brush controls shown in the fourth stage of are the set of brush controls s starting positions and locations for the fanning closed animation.

The image editing application displays the fanning closed animation of the brush controls by displaying rotations of different brush controls by different amounts about a fixed location. As shown the brush controls and rotate about the fixed location towards the right in a clockwise direction with the brush control fanned in more than the brush control . The brush controls and rotate about the fixed location towards the left in a counter clockwise manner with the brush control fanned in more than the brush control . The brush control does not rotate at all.

In some embodiments the image editing application displays the fanning closed animation of the brush controls by displaying for a defined interval of time rotations of different brush controls about the fixed location at different speeds from the starting position and location. The brush controls and rotate at the same speed about the fixed location and the brush controls and rotate at the same speed about the fixed location. The brush controls and rotate at a faster speed than the brush controls and .

The image editing application of some embodiments displays the fanning closed animation of the brush controls by displaying rotations of the brush controls about the fixed location at the same speed from the starting position and location. To display a fanning open animation with the brush controls moving at the same speed the image editing application starts the movement of different brush controls at different times e.g. start moving a particular brush control after a defined amount of time . Under this approach the application starts the movement of the brush controls and and then starts the movement of the brush controls and at a later instance in time.

As shown in the second stage the brush controls are fanned closed towards the center more than the position of the brush controls illustrated in the first stage . Additionally the brush controls have slid farther down from the center of the image display area compared to the position of the brush controls shown in the first stage . That is between the first stage and the second stage the image editing application fans the brush controls farther closed while sliding the brush controls farther down from the center of the image display area toward the bottom of the image display area .

The third stage illustrates the GUI near the end of the fanning closed animation of the brush controls of the brushes tool . As shown the brush controls are fanned closed towards the center more than the position of the brush controls illustrated in the second stage . Additionally the brush controls have slid farther down from the center of the image display area towards the bottom of the image display area compared to the position of the brush controls shown in the second stage . That is between the second stage and the third stage the image editing application fans the brush controls farther closed while sliding the brush controls farther down from the center of the image display area towards the bottom of the image display area .

The fourth stage shows the GUI after the completion of the fanning closed animation of the brush controls . As shown the application displays the top portions of the brush controls in the toolbar . The image editing application displays the selected brush control a defined offset amount higher than the unselected brush controls and .

While illustrates selecting a particular brush control of a brushes tool one of ordinary skill in the art will recognize that any of the brush controls of the brushes tool may be selected after the brushes tool is activated. For example the user could have selected brush controls or .

After selecting a brush control of the brushes tool a user might want to change the selection of the brush control. conceptually illustrates changing the selected brush control of the brushes tool illustrated in . Specifically illustrates the GUI at four different stages of a brush control change operation.

The first stage of the GUI is similar to the fourth stage of the GUI illustrated in . That is the first stage shows the GUI after the brush control is selected the brush control is highlighted with a bolded border and a fanning closed animation of the set of brush controls has completed.

The second stage of the GUI illustrates a selection of a different brush control. As shown a user is selecting the brush control e.g. by touching the brush control . When the application receives the selection of the brush control the application removes the highlighting of the previously selected brush control the brush control in this example and highlights the newly selected brush control the brush control in this example . The highlighting of the brush control is indicated by a bolding of the border of the brush control .

In the third stage the GUI shows a selection of another brush control of the brushes tool . As shown the user is selecting the brush control e.g. by touching the brush control . When the application receives the selection of the brush control the application removes the highlighting of the previously selected brush control the brush control in this example and highlights the newly selected brush control the brush control in this example . The highlighting of the brush control is indicated by a bolding of the border of the brush control .

The fourth stage of the GUI illustrates a selection of another brush control. In this stage the user is selecting the brush control e.g. by touching the brush control . When the application receives the selection of the brush control the application removes the highlighting of the previously selected brush control the brush control in this example and highlights the selected brush control the brush control in this example . The highlighting of the brush control is indicated by a bolding of the border of the brush control .

The first stage of the GUI is similar to the fourth stage of the GUI illustrated in . That is the first stage shows the GUI after the brush control is selected the brush control is highlighted with a bolded border and a fanning closed animation of the set of brush controls has completed. In addition the first stage illustrates the invocation of an operation for changing the selection of the brush control of the brushes tool . As shown a user is selecting the selected brush control to fan open the set of brush controls .

The second stage illustrates the GUI after the image editing application has finished a fanning open animation of the set of brush controls . When the application receives the selection of the selected brush control the brush control in this example the application displays a fanning open animation of the set of brush controls that is similar to the fanning open animation described above by reference to . As shown the brush control remains highlighted because the brush control is the current selected brush control of the brushes tool .

In the third stage the GUI shows a selection of a different brush control of the brushes tool . As shown the user is selecting the brush control e.g. by touching the brush control . When the image editing application receives the selection of the brush control the application highlights the brush control and displays a fanning closed animation of the set of brush controls that is similar to the fanning closed animation of the set of brush controls described above by reference to .

The fourth stage illustrates the GUI after the fanning closed animation of the set of brush controls is finished and the selected brush control is highlighted. As shown the application displays the top portions of the brush controls in the toolbar and displays the selected brush control a defined offset amount higher than the unselected brush controls .

In the figures described above in this Sub section B the appearance of the brush controls are the same or similar. In some embodiments the brush controls of the brushes tool have different appearances to represent different types of brush controls. conceptually illustrates an example of such a brushes tool. In particular illustrates the GUI in a stage with the brush controls of the effects tool fanned open and a stage with the brush controls of the effects tool fanned closed. Moreover any of the operations described above by reference to may be performed on the brushes tool shown in .

In the stage the GUI shows the effects tool with a set of brush controls fanned open. Specifically in this example the stage shows the GUI after the image editing application displays a fanning open animation of the brush controls similar to the animation described above by reference to .

As shown the set of brush controls includes a repair brush control for removing blemishes from an image being edited a red eye brush control for removing red eye from the image a saturate brush control for increasing the saturation of portions of the image a desaturate brush control for decreasing the saturation of portions of the image a lighten brush control for increasing the brightness of portions of the image a darken brush control for decreasing the brightness of portions of the image a sharpen brush control for sharpening portions of the image and a soften brush control for softening and or blurring portions of the image. Details of brush controls are described in concurrently filed U.S. patent application Ser. No. 13 629 374 entitled User Interface Tools for Selectively Applying Effects to Image . U.S. patent application Ser. No. 13 629 374 is herein incorporated by reference.

In the stage the GUI shows the effects tool with the set of brush controls fanned closed. For this example the stage shows the GUI after the image editing application displays a fanning closed animation of the brush controls similar to the animation described above by reference to . As shown in the stage the top portions of the brush controls are displayed in the toolbar the selected brush control the red eye brush control in this example is highlighted and the selected brush control is displayed a defined offset amount above the unselected brush controls.

While illustrates an example of different appearances for brush controls one of ordinary skill will recognize that a brush control can have any number of different appearances to represent the brush control. For example a brush control can appear as a highlighter pen a pencil a fountain pen a paint roller a paint scraper etc.

In some embodiments the image editing application provides the GUI described above in when the application is in a landscape viewing mode. The following figures will describe a GUI that the application of some such embodiments provides when the application is in a portrait viewing mode.

The stages of the GUI are similar to the stages described above by reference to . That is the first stage shows the activation of the brushes tool the second stage shows the start of the fanning open animation of the brush controls the third stage shows the brush controls near the end of the fanning closed animation and the fourth stage shows the brush controls at the end of the fanning open animation.

The stages of the GUI are similar to the stages described above by reference to . That is the first stage shows the selection of the brush control the second stage shows the start of the fanning closed animation of the brush controls and the third stage shows the brush controls near the end of the fanning closed animation 

The fourth stage shows the GUI after the completion of the fanning closed animation of the brush controls . As shown the image editing application displays only the top portion of the selected brush control in the toolbar at the end of the fanning closed animation of the brush controls . In some embodiments the application uses a technique that is similar to the technique described above by reference to to change the selection of the brush control of the brushes tool. That is the user selects the selected brush control displayed in the tool bar in order to fan open the brush controls and then selects a different brush control from the fanned open brush controls.

In some embodiments the GUI for the example operations described above by reference to may be provided by an image editing application when the application is in a landscape viewing mode. The image editing application of some embodiments provides the GUI described above by reference to for the example operations when the application is in a portrait viewing mode. However in some cases the image editing application provides a yet another GUI for the example operations. For instance the display screen of a mobile computing device e.g. a smartphone on which the application is running might not have enough space to display the example operations illustrated in .

The first stage of the GUI shows the activation of the brushes tool . In this stage a user is selecting the selectable brushes tool UI item e.g. by touching the UI item to activate the brushes tool .

The second stage illustrates the GUI after the brushes tool is activated. As shown the GUI is displaying the start of the fanning open animation of the set of brush controls and the brushes tool UI item is highlighted. When the image editing application receives the selection of the brushes tool UI item the application highlights the UI item removes the UI items from the toolbar e.g. by displaying an animation of the UI items sliding towards the left and off the toolbar and displays the UI item on the left side of the toolbar .

In this example the brush controls start the fanning open animation at the bottom of the toolbar from a vertical position. As shown the brush controls are slightly fanned opened from the vertical position and location. The image editing application uses any of the fanning techniques described above by reference to to fan open the brush controls . While fanning open the brush controls the application moves a fixed location e.g. a pivot point relative to the brush controls about which the brush controls rotate. The application moves the fixed location towards the middle of the right side of the image display area . While fanning the brush controls and moving the fixed location during the fanning open animation the application also rotates the brushes tool counter clockwise.

The third stage illustrates the GUI near the end of the fanning open animation of the brush controls of the brushes tool . As shown the brush controls are fanned open from the center more than the position of the brush controls illustrated in the second stage . Additionally the fixed location about which the brush controls rotate has moved farther towards the middle of the right side of the image display area compared to the position of the fixed location in the second stage . Also the brushes tool has rotated farther in a counter clockwise manner. That is between the second stage and the third stage the image editing application fans the brush controls farther open while moving the fixed location farther towards the middle of the right side of the image display area while rotating the brushes tool counter clockwise.

The fourth stage shows the GUI after the completion of the fanning open animation of the brush controls . As shown the brush controls are fanned open from the center more than the position of the brush controls illustrated in the third stage . Also the fixed location about which the brush controls rotate has moved farther towards the middle of the right side of the image display area compared to the position of the fixed location in the third stage . Additionally the brushes tool has rotated farther in a counter clockwise manner. That is between the third stage and the fourth stage the image editing application fans the brush controls farther open while moving the fixed location farther towards the middle of the right side of the image display area while rotating the brushes tool counter clockwise.

The first stage of the GUI shows the selection of a brush control of the brushes tool . As shown a user is selecting the brush controls e.g. by touching the brush control . When the image editing application receives the selection of the brush control the application highlights the selected brush control the brush control in this example and starts displaying a fanning closed animation of the set of brush controls .

The second stage illustrates the GUI after the brush control is selected and the fanning closed animation of the set of brush controls has started. The image editing application highlights the brush control by bolding the border of the brush control . In this example the positions and locations of the set of brush controls shown in the fourth stage of are the set of brush controls s starting positions and locations for the fanning closed animation. As shown the brush controls are slightly fanned closed from the brush controls s starting positions and locations for the fanning closed animation. The image editing application uses any of the fanning techniques described above by reference to to fan open the brush controls .

The third stage illustrates the GUI near the end of the fanning closed animation of the brush controls of the brushes tool . As shown the brush controls are fanned closed towards the center more than the position of the brush controls illustrated in the second stage . Additionally the fixed location about which the brush controls rotate has moved farther from the middle of the right side of the image display area towards the middle of the toolbar compared to the position of the brush controls shown in the second stage . Also the brushes tool has rotated farther in a clockwise manner. That is between the second stage and the third stage the image editing application fans the brush controls farther closed while moving the fixed location towards the middle of the toolbar while rotating the brushes tool clockwise.

The fourth stage shows the GUI after the completion of the fanning closed animation of the brush controls . As shown the application displays only the top portion of the selected brush control in the toolbar at the end of the fanning closed animation of the brush controls . Between the third stage and the fourth stage the image editing application fans the brush controls farther closed while moving the fixed location towards the middle of the toolbar while rotating the brushes tool clockwise.

While illustrates selecting a particular brush control of a brushes tool one of ordinary skill in the art will recognize that any of the brush controls of the brushes tool may be selected after the brushes tool is activated. For example the user could have selected brush controls or .

The first stage of the GUI is similar to the fourth stage of the GUI illustrated in . That is the first stage shows the GUI after the brush control is selected the brush control is highlighted with a bolded border a fanning closed animation of the set of brush controls has completed and the selected brush control is displayed over the toolbar . In addition the first stage illustrates the invocation of an operation for changing the selection of the brush control of the brushes tool . As shown a user is selecting the selected brush control to fan open the set of brush controls .

The second stage illustrates the GUI after the image editing application has finished a fanning open animation of the set of brush controls . When the application receives the selection of the selected brush control the brush control in this example the application displays a fanning open animation of the set of brush controls that is similar to the fanning open animation described above by reference to . As shown the brush control remains highlighted because the brush control is the selected brush control of the brushes tool .

In the third stage the GUI shows a selection of a different brush control of the brushes tool . As shown the user is selecting the brush control e.g. by touching the brush control . When the image editing application receives the selection of the brush control the application removes the highlighting of the previously selected brush control highlights the newly selected brush control and displays a fanning closed animation of the set of brush controls that is similar to the fanning closed animation of the set of brush controls described above by reference to .

The fourth stage illustrates the GUI after the fanning closed animation of the set of brush controls is finished. As shown the application displays only a highlighted top portion of the selected brush control in the toolbar at the end of the fanning closed animation of the brush controls .

The above illustrates GUIs that the application of some embodiments provides when the application is in a portrait viewing mode. One of ordinary skill in the art will realize that the application of different embodiments provide different GUIs and animations when in different viewing modes. For instance in some embodiments when the application is in a landscape viewing mode the application provides a GUI similar to the GUI illustrated in except the layout of the UI items in the toolbars is similar to the toolbars shown in e.g. only the selected brush controls is displayed when the brush controls are fanned closed . In some embodiments the application displays animations in a similar manner as those shown in . One of ordinary skill in the art will realize that any of the animations illustrated in the above described may be used in any of the GUIs in the above described .

The described above show several techniques for fanning UI controls open and fanning UI controls closed. For instance show selecting the current selected UI control to fan open the UI controls in order to select a different UI control and selecting a UI control to fan closed the UI controls. However other techniques may be used to fan open and closed the UI controls in some embodiments. For example the UI tool of some embodiments allows a user to perform a gesture e.g. a swipe up gesture on the selected UI control in order to fan open the UI controls. Similarly in some embodiments the UI tool allows the user to perform a gesture e.g. a swipe down gesture on the image display area in order to fan closed the UI controls when the UI controls are fanned open and the user does not want to select a different UI control i.e. the user wants to keep the current selected UI control as selected . Other techniques are possible.

As noted above the brush controls of the brushes tool have different appearances to represent different types of brush controls in some embodiments. conceptually illustrates brush controls with different appearances. Specifically illustrates the GUI in a stage with the brush controls of the effects tool fanned open and a stage with the brush controls of the effects tool fanned closed. Moreover any of the operations described above by reference to may be performed on the brushes tool shown in .

The stage of the GUI shows the effects tool with the set of brush controls fanned open. Specifically in this example the stage shows the GUI after the image editing application displays a fanning open animation of the brush controls similar to the animation described above by reference to .

In the stage the GUI shows the effects tool with the set of brush controls fanned closed. For this example the stage shows the GUI after the image editing application displays a fanning closed animation of the brush controls similar to the animation described above by reference to . As shown in the stage only the top portion of the selected brush control the red eye brush control in this example is displayed in the toolbar and the selected brush control is highlighted.

The first stage of the GUI is similar to the fourth stage illustrated in . As shown a user has activated the brushes tool e.g. by selecting the UI item as indicated by the highlighting of the brushes item . Additionally the user has selected the brush control of the brushes tool e.g. by touching the brush control when the set of brush controls of the brushes tool were fanned out .

The second stage of the GUI illustrates a brush effect being applied to the image being edited. As shown the user is selecting a region of the image e.g. by touching the region of the image and performing a rubbing gesture to apply the brush effect to the region of the image . When the image editing application receives the selection of the region of the image the application applies the brush effect associated with the brush control to the region of the image . In addition upon receiving the selection of the region of the image the application displays an indicator above the brush control to indicate that a brush effect has been applied to the image with the brush control and displays an indicator above the brushes tool UI item to indicate that edits have been applied to the image with the brushes tool .

The third stage illustrates the GUI after the user has finished applying the brush effect to the image . As shown the region of the image with the brush effect applied is indicated with diagonal lines.

The third stage also shows another brush effect being applied to the image being edited. As shown the user is selecting a second region of the image e.g. by touching the region of the image and performing a rubbing gesture to apply the brush effect associated with the brush control to the second region of the image . When the image editing application receives the selection of the second region of the image the application applies the brush effect associated with the brush control to the second region of the image .

The fourth stage illustrates the GUI after the user has finished applying the brush effect to the image . As shown the second region of the image with the brush effect applied is indicated with diagonal lines.

The first stage of the GUI is similar to the fourth stage illustrated in . As shown a user has applied brush effects associated with the brush control to two regions of the image which are indicated by diagonal lines in the image . The first stage also shows the user selecting a different brush control. As illustrated in this stage the user is selecting the brush control e.g. by touching the brush control .

The second stage illustrates the GUI a brush effect being applied to the image being edited. As shown the user is selecting a third region of the image e.g. by touching the region of the image and performing a rubbing gesture to apply the brush effect to the third region of the image . When the image editing application receives the selection of the region of the image the application applies the brush effect associated with the brush control to the third region of the image . In addition upon receiving the selection of the region of the image the application displays an indicator above the brush control to indicate that a brush effect has been applied to the image with the brush control .

The third stage illustrates the GUI after the user has applied the brush effect to the image illustrated in the second stage . As shown the region of the image with the brush effect applied with the brush control is indicated with different diagonal lines.

The third stage also shows the user disabling the brush effects applied to the image with the brush control . In this stage the user has selected the brush control e.g. by touching the brush control twice in rapid succession to disable the brush effects applied to the image with the brush control .

The brush effect disabling feature of the brushes tool allows the user to disable and enable brush effects that have been applied to the image being edited with a particular brush control. This way the user may view brush effects applied to the image being edited using different brush controls separately. For instance the user might apply a first set of brush effects to a region of the image being edited using a first brush control and apply a second set of brush effects to the same region of the image using a second brush control. The brush effect disabling feature of the brushes tool allows the user to view only the first set of brush effects applied to the image only the second set of brush effects applied to the image or the both the first and second sets of brush effects applied to the image.

The fourth stage illustrates the GUI after the user has disabled the brush effects applied to the image with the brush control . As shown the diagonal lines on the car that represents the regions at which brush effects were applied to the image with the brush control are not displayed in the image in order to indicate that these brush effects have been disabled.

When the image editing application receives the selection of the brush control to disable the brush effects applied to the image with the brush control the application removes the brush effects from the regions of the image at which the brush effects have been applied. In addition upon receiving the selection of the brush control to disable the brush effects of the brush control the application displays a different indicator above the brush control . As shown a thin line displayed above the brush control is used to indicate that brush effects have been applied to the image with the brush control but the brush effects have been disabled.

As described above illustrate examples of applying brush effects to an image using a rubbing gesture e.g. to incrementally apply brush effects to a region of the image . In some embodiments brush controls that use rubbing gestures to apply brush effects are referred to as gradual brush controls incremental brush controls and or additive brush controls. Details of brush controls that use rubbing gestures to apply the brush effects are described in concurrently filed U.S. patent application Ser. No. 13 629 374 entitled User Interface Tools for Selectively Applying Effects to Image . In some embodiments the brushes tool includes other types of brush controls that do not utilize rubbing gestures to apply the brush controls brush effects. For instance for the repair brush control described above a user removes a blemish from an image by selecting region of an image e.g. by touching the region of the image that contains the blemish. In some embodiments the red eye brush control described above is used in a similar manner to remove red eye from an image. These types of brush controls are referred to as discrete brush controls in some embodiments.

At state the application is in an image editing viewing or organizing state. In some embodiments the application begins in the state when the application is first started. When the application is in the state the application is providing tools for editing viewing or organizing images. For example the application may be providing sharing tools for sharing images providing various editing tools e.g. a crop and rotate tool an exposure tool a color tool etc. providing tools for tagging images etc.

When the application activates the brushes tool while the application is in a landscape viewing mode the application transitions from state to state . When the application activates the brushes tool while the application is in a portrait viewing mode the application transitions from state to state . In some cases when the application activates the brushes tool the application returns to the last used state. In some such cases the application transitions from state to state if the application is in a landscape viewing mode and transitions from state to state if the application is in a portrait viewing mode not shown in . As shown in when the application is in any of the states and the application disables the brushes tool e.g. by activating another tool the application returns to state .

At state the application is in a landscape viewing mode and provides a GUI for displaying in the landscape viewing mode the brush controls of the brushes tool in a fanned open layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of when in state .

When the application changes to state e.g. from state or state the application displays a fanning open animation of the brush controls of the brushes tool . In some embodiments the application displays the fanning open animation similar to the animation described above by reference to .

If a brush control of the brushes tool is selected when the application transitions to state e.g. the application transitioned from state the application continues to highlight the selected brush control while in state . When the application is in state and the application receives a selection of a brush control of the brushes tool the application transitions to state . When the application is in state and the application changes from a landscape viewing mode to a portrait viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area decreasing the width of the display area increasing the height of the display area etc. the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state .

At state the application is in a landscape viewing mode and provides a GUI for displaying in the landscape viewing mode the brush controls of the brushes tool in a fanned closed layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of when in state .

When the application changes to state from state the application displays a fanning closed animation of the brush controls of the brushes tool . In some embodiments the application displays the fanning closed animation similar to the animation described above by reference to . When the application transitions to state the application highlights the selected brush control of the brushes tool .

When the application is in state and the application receives a selection of the selected brush control in order to change the selection of the brush control of the brushes tool the application transitions to state . When the application is in state and the application changes from a landscape viewing mode to a portrait viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area decreasing the width of the display area increasing the height of the display area etc. the application of some embodiments changes from a landscape viewing mode to a portrait viewing mode and then transitions to state .

In some embodiments the application receives a selection of a different brush control while in state . For instance the application of some embodiments that provides the GUI illustrated in the fourth stage of might receive a selection of a different brush to change the selection of the brush control of the brushes tool . When the application receives the selection of a different brush while in state the application removes the highlighting from the previously selected brush control and highlights the newly selected brush control as illustrated in .

When the application is in state and the application receives a selection of a region of an image being edited through the selected brush control of the brushes tool the application transitions to state . Referring to as an example when the application is in state the application receives a selection of a region of the image to apply a brush effect associated with the brushes control to the image .

At state the application is in a portrait viewing mode and provides a GUI for displaying in the portrait viewing mode the brush controls of the brushes tool in a fanned open layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of or the fourth stage of when in state .

When the application changes to state e.g. from state or state the application displays a fanning open animation of the brush controls of the brushes tool . In some embodiments the application displays the fanning open animation similar to the animation described above by reference to or .

If a brush control of the brushes tool is selected when the application transitions to state e.g. the application transitioned from state the application continues to highlight the selected brush control while in state . When the application is in state and the application receives a selection of a brush control of the brushes tool the application transitions to state . When the application is in state and the application changes the viewing mode from a portrait viewing mode to a landscape viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area increasing the width of the display area decreasing the height of the display area etc. the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state .

At state the application is in a portrait viewing mode and provides a GUI for displaying in the portrait viewing mode the brush controls of the brushes tool in a fanned open layout. For instance the application of some embodiments provides the GUI illustrated in the fourth stage of or the fourth stage of when in state

When the application changes to state from state the application displays a fanning closed animation of the brush controls of the brushes tool . In some embodiments the application displays the fanning closed animation similar to the animation described above by reference to or . When the application transitions to state the application highlights the selected brush control of the brushes tool .

When the application is in state and the application receives a selection of the selected brush control in order to change the selection of the brush control of the brushes tool the application transitions to state . When the application is in state and the application changes from a portrait viewing mode to a landscape viewing mode the application transitions to state . For example when the orientation of the display screen of a mobile computing device on which the application is running is changed the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state . As another example when a display area for displaying the GUI of the application is adjusted e.g. adjusting the size of the display area increasing the width of the display area decreasing the height of the display area etc. the application of some embodiments changes from a portrait viewing mode to a landscape viewing mode and then transitions to state .

When the application is in state and the application receives a selection of a region of an image being edited through the selected brush control of the brushes tool the application transitions to state . Referring to as an example when the application is in state the application receives a selection of a region of the image to apply a brush effect associated with the brushes control to the image .

At state the application applies a brush effect to the image being edited based on the selection of the image received through the selected brush control of the brushes tool . For instance referring to when the application while in state or state receives the selection of the region of the image shown in the second stage using the selected brush control the application in state applies the brush effect associated with brush control to the image being edited. After applying the brush effect based on the selection of the region of the image being edited the application transitions back to the state from which the application transitioned to state . In other words the application transitions back to state when the application transitions to state from state and the application transitions back to state when the application transitions to state from state .

The state diagram illustrated in shows several different states of the image editing application of some embodiments. One of ordinary skill in the art will recognize that the various actions represented by the states and transitions in are only a subset of the possible actions that can be performed in the application in some embodiments. Additionally other functions that are not shown may be performed while in a particular state. For instance in some embodiments when the image editing application is in fanned closed state e.g. state or state and the application receives input to apply a brush effect to the image being edited that does not yet have any brush effects applied to the image the application displays an indicator above the brushes tool UI item to indicate that a brush effect is applied to the image being edited. As another example when the image editing application is in a fanned closed state e.g. state the application might receive a selection of a brush control to disable or enable brush effects associated with the brush control as illustrated in .

As shown in the image editing application includes a user interface UI interaction and generation module a viewing mode module a UI control animator a UI control manager and a rendering engine . The image editing application also includes effects controls storage brush controls storage other controls storage and image data .

The effects controls storage stores information about effects controls such as different effects types of UI controls for controlling the effects etc. Similarly the brush controls storage stores information about brush controls such as different brush effects types of UI controls for controlling the brush effects etc. The other controls storage stores information about additional and or other controls e.g. color controls for adjusting colors of images exposure controls for adjusting the exposure of images etc. as well as types of UI controls for controlling the other controls etc. The image data storage stores image data e.g. RAW image files JPEG image files thumbnail versions of images edited versions of images display resolution versions of image other generated versions of images etc. that a user views edits and organizes with the image editing application . In some embodiments the storages are stored in one physical storage while in some embodiments the storages are stored on separate physical storages. Still in some embodiments some of the storages are stored in one physical storage while other storages are stored in separate physical storages.

The gyroscope device driver includes a set of drivers for translating signals from a gyroscope that is part of a computing device on which the application runs. The gyroscope in some embodiments is used to identify the orientation of the device. For instance the gyroscope is used to determine whether the device is being held in a landscape or portrait position. The gyroscope sends signals to the gyroscope device driver which provides the signals to the viewing mode module . The input device drivers may include drivers for translating signals from a keyboard mouse touchpad tablet touchscreen etc. A user interacts with one or more of these input devices which send signals to their corresponding device driver. The device driver then translates the signals into user input data that is provided to the UI interaction module .

The present application describes several graphical user interfaces that provide users with numerous ways to perform different sets of operations and functionalities. In some embodiments these operations and functionalities are performed based on different commands that are received from users through different input devices. For example the present application illustrates the use of touch control to control e.g. select move objects in the graphical user interface. In some embodiments touch control is implemented through an input device that can detect the presence and location of touch on a display of the device. An example of such a device is a touch screen device. In some embodiments with touch control a user can directly manipulate objects by interacting with the graphical user interface that is displayed on the display of the touch screen device. For instance a user can select a particular object in the graphical user interface by simply touching that particular object on the display of the touch screen device. As such when touch control is utilized a cursor may not even be provided for enabling selection of an object of a graphical user interface in some embodiments. However when a cursor is provided in a graphical user interface touch control can be used to control the cursor in some embodiments. Additionally in some embodiments objects in a graphical user interface can also be controlled or manipulated through other controls such as a cursor in a graphical user interface e.g. using a trackpad touchpad mouse etc. .

The display module translates the output of a user interface for a display device. That is the display module receives signals e.g. from the UI interaction and generation module describing what should be displayed and translates these signals into pixel information that is sent to the display device. The display device may be an LCD plasma screen CRT monitor touchscreen etc.

The UI interaction and generation module of the image editing application interprets the user input data received from the input device drivers and passes it to various modules including the viewing mode module the UI control manager and the rendering engine . The UI interaction module also manages the display of the UI e.g. fanning animations of UI controls highlights of UI elements indicators etc. and outputs this display information to the display module . This UI display information may be based on information from the UI control manager and the rending module etc. In addition the UI interaction module may generate portions of the UI based just on user input e.g. when a user moves an item in the UI that only affect the display not any of the other modules such as moving a window from one side of the UI to the other.

The viewing mode module determines a viewing mode for the application based on information the viewing mode module receives from the gyroscope device driver and sends the determination to the UI interaction and generation module so that the UI interaction and generation module provides the appropriate UI display information to the display module

Alternatively or in conjunction with the information from the gyroscope device driver the viewing mode module of some embodiments uses information from the UI interaction and generation module to determine the viewing mode. For instance when the user modifies the display area e.g. adjusting the size of the display area adjusting the width of the display area adjusting the height of the display area moving the display area etc. in which the application displays the GUI the application might determine that new viewing mode. As described above the application of some embodiments provides different GUI for different operations in different viewing modes e.g. landscape viewing mode portrait viewing mode .

The UI control animator generates animations for the UI control manager based on information from the viewing mode module and the UI control manager . When the UI control manager requests an animation of UI controls e.g. animations of fanning in out of effects controls animations of fanning in out of brush controls peeling on off animations etc. the UI control animator retrieves viewing mode information from the viewing mode in order to generate the appropriate animation for the UI control manager .

The UI control manager provides UI controls for the UI interaction and generation module to send to the display module to display. For instance when the user activates a UI tool such as a brushes tool or an effects tool the UI control manager receives from the UI interaction and generation module a request for the appropriate UI controls. The UI control manager then sends a request to the UI control animator for an animation of the UI controls.

The rendering engine is responsible for rending different versions of images based on the original image. For instance the rendering module uses the image data in the image data storage to render thumbnails of images and display resolution versions of the images for the UI interaction and generation module to send to the display module to display in a GUI. When edits are made to an image the rendering engine generates edited thumbnail and display resolution versions of the image based on the image data in the image data storage . In some embodiments the rendering engine receives requests from the UI control manager to generate images for UI controls e.g. thumbnail slider controls . The rendering engine also renders images when the application of some embodiments exports images to an external source. In some cases the rendering engine renders the full size version of original image.

While many of the features have been described as being performed by one module e.g. the UI interaction module the UI control animator etc. one of ordinary skill in the art will recognize that the functions described herein might be split up into multiple modules. Similarly functions described as being performed by multiple different modules might be performed by a single module in some embodiments e.g. the UI control animator and the UI control manager .

The image editing application of some embodiments provides various tools for editing an image. As described above the application of some such embodiments provides a crop tool an exposure tool a color tool a brush tool and an effects tool for editing an image. In some embodiments when different edits are made to the image using different tools the application applies the different edits in a particular order. The following section will describe several example operations for facilitating the application of different edits to an image that are made using different tools in a particular order.

The first stage of the GUI is similar to the first stage of the GUI illustrated in except a crop tool has been used to crop the lower left portion of the image as indicated by an indicate displayed above the crop tool UI item . Details of crop tools are described in concurrently filed U.S. patent application Ser. No. 13 629 370 entitled User Interface Tools for Cropping and Straightening Image . U.S. patent application Ser. No. 13 629 370 is herein incorporated by reference.

Also the first stage illustrates a selection of a selectable UI item of the effects control . As shown a user is selecting the UI item e.g. by touching the UI item to apply the effect associated with the thumbnail slider control to the cropped image .

The second stage shows the GUI after the effect selected in the first stage is applied to the cropped image . The application displays an indicator above the effects tool UI item to indicate that an effect has been applied to the image being edited. As shown the effect is indicated by diagonal lines on the cropped image . The second stage also illustrates the activation of color tool. As shown the user is selecting the color tool UI item e.g. by touching the UI item in order to activate the color tool.

The third stage illustrates the GUI after the color tool is activated. As shown the color tool includes a set of color adjustment slider controls for performing various color adjustment to the image being edited and a UI item for providing various white balance tools not shown in . Details of color tools that include color adjustment controls are described in concurrently filed U.S. patent application Ser. No. 13 629 428 entitled Context Aware User Interface for Image Editing . U.S. patent application Ser. No. 13 629 428 is herein incorporated by reference.

The third stage of the GUI also shows that the effects tool UI item is no longer highlighted and that the color tool UI item is highlighted to indicate that the color tool is activated. When the image editing application receives the selection of the color tool UI item the application removes the highlighting from the effects tool UI item and highlights the color tool UI item .

In this example the application applies color adjustment edits to the image before applying effects edits to the image. Thus in this example the application temporarily removes the effects edits applied to the cropped image when the color tool is activated. As shown the application indicates the removal of the effects edits from the cropped image by displaying an animation that is referred to as a peeling off animation. The peeling off animation shows a layer of the cropped image with the effects edits applied to the layer being removed from the cropped image . While displaying the peeling off animation the application displays a version of the image without the effects edits applied to the image underneath the layer being removed. In other words the application displays an animation that appears like the layer with the effects edits is being peeled away from the cropped image starting from the lower right corner of the cropped image towards the upper left corner of the cropped image .

The fourth stage shows the GUI near the end of the peeling off animation. Here the GUI displays the layer being peeled from the cropped image farther from the lower right corner of the image and farther towards the upper left corner of the image.

The fifth stage illustrates the GUI after the peeling off animation of the effects edits is completed. As shown the GUI displays the cropped image with the effects edits removed from the image as illustrated by the diagonal lines no longer displayed. The fifth stage also shows a different highlighting of the effects tool UI item and the indicator above the UI item . This different highlighting is to indicate that effects edits have been applied to the image being edited but the effects are currently removed. When the image editing application finishes displaying the peeling off animation the application displays the different highlighting of the effects tool UI item and the indicator above the UI item .

The sixth stage of the GUI shows color adjustment edits being applied to the image. As shown the user is adjusting the color adjustment slider control e.g. by touching the slider and dragging along the color adjustment slider control in order to adjust colors of the cropped image . The color adjustments in this example are represented by a different set of diagonal lines displayed on the cropped image . Additionally a different highlighting is displayed above the color tool UI item to indicate that color adjustments have been applied to the cropped image .

In the seventh stage the GUI is showing that the user is finished adjusting the color of the image being edited with the color tool. In this stage the user has increased the color adjustment of the cropped image from the color adjustment shown in the sixth stage as indicated by an increase in the different diagonal lines displayed over the cropped image .

The seventh stage also illustrates the activation of the effects tool . As shown the user is selecting the effects tool UI item e.g. by touching the UI item to activate the effects tool .

The eighth stage illustrates the GUI after the effects tool is activated. The eighth stage of the GUI also shows that the color tool UI item is no longer highlighted and that the effects tool UI item is highlighted to indicate that the effects tool is activated. When the image editing application receives the selection of the effects tool UI item the application removes the highlighting from the color tool UI item and highlights the effects tool UI item . The application continues to display the different highlighting above the effects tool UI item to indicate that the effects edits are still currently removed.

As mentioned above the application in this example applies color adjustment edits to the image before applying effects edits to the image. Since the user has finished making color edits to the image the application in this example applies the effects edits that were temporarily removed from to the cropped image when the color tool was activated in the second stage . As shown the application indicates the application of the effects edits to the cropped image by displaying an animation that is referred to as a peeling on animation. The peeling on animation shows a layer of the cropped image with the color edits and the effects edits applied to the layer being placed over the color adjusted cropped image . Thus the application displays an animation that appears like the layer with the color edits and the effects edits is being pasted on to the cropped image starting from the upper left corner of the cropped image towards the lower right corner of the cropped image .

The ninth stage shows the GUI near the end of the peeling on animation. In the ninth stage the GUI displays the layer being place over the cropped image farther from the upper left corner of the image and farther towards the lower right corner of the image. Also the application continues to display the different highlighting above the effects tool UI item to indicate that the effects edits are still currently removed.

The tenth stage illustrates the GUI after the peeling on animation is completed. As shown the effects edits that were temporarily removed have been applied to the cropped image . This is indicated by the display of the different types of diagonal lines on the cropped image . Here the application displays the original highlighting above the effects tool UI item to indicate that the effects edits have been applied to the image being edited.

The above described figures illustrate an example operation of applying different edits made with different tools to an image in a particular order. In some embodiments different edits made with the same tool to an image are applied in a particular order.

The first stage of the GUI is similar to the first stage of the GUI illustrated in except the brushes tool has been activated instead of the effects tool . As shown the brush control has been selected and a user is selecting a region of the cropped image e.g. by touching the region of the image and performing a rubbing gesture to apply the brush effect associated with the brush control to the region of the cropped image . When receiving the selection of the region of the cropped image the application displays an indicator above the brush control to indicate that a brush effect has been applied to the cropped image with the brush control and displays an indicator above the brushes tool UI item to indicate that edits have been applied to the cropped image with the brushes tool .

The second stage shows the GUI after the user has finished applying the brush effect to the cropped image . The region of the image with the brush effect applied is indicated with vertical lines. The second stage of the GUI also shows the user selecting a different brush control. As shown the user is selecting the brush control e.g. by touching the brush control .

The third stage illustrates the GUI after the brush control is selected. When application receives the selection of the brush control the application removes the highlighting of the brush control and highlights the selected brush control .

In this example the application applies the brush control s brush effect edits to the image before applying the brush control s brush effect edits to the image. Therefore in this example the application temporarily removes the brush control s brush effect edits that have been applied to the cropped image when the brush control is selected. As shown the application indicates the removal of the brush control s brush effect edits from the cropped image by displaying a peeling off animation. The peeling off animation shows a layer of the cropped image with the brush control s brush effect edits applied to the layer being removed from the cropped image . While displaying the peeling off animation the application displays a version of the image without the brush control s brush effect edits applied to the image underneath the layer being removed. In other words the application displays an animation that appears like the layer with the brush control s brush effect edits is being peeled away from the cropped image starting from the lower right corner of the cropped image towards the upper left corner of the cropped image . The fourth stage shows the GUI near the end of the peeling off animation. At this stage the GUI displays the layer being peeled from the cropped image farther from the lower right corner of the image and farther towards the upper left corner of the image.

The fifth stage illustrates the GUI after the peeling off animation of the brush control s brush effect edits is completed. As shown the GUI displays the cropped image with the brush control s brush effect edits removed from the image as illustrated by the vertical lines no longer displayed. The fifth stage also shows a different highlighting of the indicator above the brushes tool UI item . This different highlighting is to indicate that the brush control s brush effect edits have been applied to the image being edited but the brush effect edits are currently removed. When the image editing application finishes displaying the peeling off animation the application displays the different highlighting of the indicator above the brushes tool UI item .

The sixth stage of the GUI shows brush effect edits being applied to the image using the brush control . As shown the user is selecting a second region of the cropped image e.g. by touching the region of the image and performing a rubbing gesture to apply the brush effect associated with the brush control to the second region of the cropped image . When receiving the selection of the second region of the cropped image the application displays an indicator above the brush control to indicate that a brush effect has been applied to the cropped image with the brush control .

The seventh stage shows the GUI after the user has finished applying the brush effect with the brush control to the cropped image . As shown the second region of the image with the brush effect applied is indicated with horizontal lines. The seventh stage of the GUI also shows the user selecting a different brush control. As shown the user is selecting the brush control e.g. by touching the brush control .

The eighth stage illustrates the GUI after the brush control is selected. When the image editing application receives the selection of the brush control the application removes the highlighting from the brush control and highlights the brush control . The application continues to display the different highlighting above the brushes tool UI item to indicate that the brush control s brush effect edits are still currently removed.

As mentioned above the application in this example applies the brush control s brush effect edits to the image before applying the brush control s brush effect edits to the image. Since the user has finished making brush effect edits with the brush control to the image the application in this example applies the brush control s brush effect edits that were temporarily removed from to the cropped image when the brush control was selected in the second stage . As shown the application indicates the application of the brush control s brush effect edits to the cropped image by displaying a peeling on animation. The peeling on animation shows a layer of the cropped image with the brush control s brush effect edits and the brush control s brush effect edits applied to the layer being placed over the cropped image with just the brush control s brush effect edits. Thus the application displays an animation that appears like the layer with the brush control s brush effect edits and the brush control s brush effect edits is being pasted on to the cropped image with just the brush control s brush effect edits starting from the upper left corner of the cropped image towards the lower right corner of the cropped image .

The ninth stage shows the GUI near the end of the peeling on animation. In the ninth stage the GUI displays the layer being place over the cropped image farther from the upper left corner of the image and farther towards the lower right corner of the image. Also the application continues to display the different highlighting above the brush control to indicate that the effects edits are still currently removed.

The tenth stage illustrates the GUI after the peeling on animation is completed. As shown the brush control s brush effect edits that were temporarily removed have been applied to the cropped image . This is indicated by the display of the vertical lines and the horizontal lines on the cropped image . Here the application displays the original highlighting above the brush control to indicate that the brush control s brush effect edits have been applied to the image being edited

As described above and illustrate examples of displaying peeling off animations when edits are temporarily removed from an image and displaying peeling on animations when the edits are applied back on to the image in order to provide visual indications of removing edits from the image and applying edits to the image. Alternatively or in conjunction with displaying the animations the image editing application of some embodiments provides aural indications of removing edits from the image and applying edits to the image. For instance in some embodiments the image editing application plays a sound effect e.g. a sound of a piece of paper being lifted up while displaying a peeling off animation. Similarly the image editing application of some embodiments plays a sound effect e.g. a sound of a sheet of paper being placed down while displaying a peeling on animation. Other embodiments may provide additional and or different types of indications of edits being removed from an image and edits being applied to the image.

For each tool listed in the left most column the corresponding row in the table defines the type of edits that may continue to be applied to an image while the tool in the left column is in use i.e. is activated with checkmarks. For instance when the crop tool is in use crop edits exposure edits and color edits may continue to be applied to the image as indicated by the checkmarks in the corresponding row. Thus when the crop tool is activated the application of some embodiments removes any edits that have been applied to the image with the repair tool the red eye tool the paint tool or the effects tool.

As described above illustrate an example operation of applying different edits made with the same tool to an image in a particular order. The row corresponding to the repair tool and the red eye tool are examples of applying different edits made with the same tool to an image in a particular order. For example when the red eye tool is in use only crop edits may continue to be applied to the image. So when the red eye tool is activated e.g. by selecting the red eye brush control the application of some embodiments removes any edits that have been applied to the image with other brush tools the repair tool and the paint tool in this example as well as any edits that have been applied to the image with other tools the exposure tool the color tool and the effects tool in this example .

The table illustrated in is one example of the orders for applying edits to an image. One of ordinary skill in the art will realize that any number of different orders may be defined for any number of different tools.

As shown in the image editing application includes a user interface UI interaction and generation module an edit manager a peel animator edit module s and a rendering engine . The image editing application also includes image data storage . The effects controls storage

The image data storage stores image data e.g. RAW image files JPEG image files thumbnail versions of images edited versions of images display resolution versions of image other generated versions of images etc. that a user views edits and organizes with the image editing application . In some embodiments the image data storage is stored in one physical storage while in some embodiments the image data storage is stored on separate physical storages.

The input device drivers may include drivers for translating signals from a keyboard mouse touchpad tablet touchscreen etc. A user interacts with one or more of these input devices which send signals to their corresponding device driver. The device driver then translates the signals into user input data that is provided to the UI interaction module .

The output device drivers may include drivers for translating signals to speakers headphones printers etc. In some embodiments the output device drivers of some embodiments translate signals from the UI interaction module . For instance the output device drivers might receive audio signals e.g. sound effects from the UI interaction module to output to speakers and or headphones when a peel animation is being displayed.

The present application describes several graphical user interfaces that provide users with numerous ways to perform different sets of operations and functionalities. In some embodiments these operations and functionalities are performed based on different commands that are received from users through different input devices. For example the present application illustrates the use of touch control to control e.g. select move objects in the graphical user interface. In some embodiments touch control is implemented through an input device that can detect the presence and location of touch on a display of the device. An example of such a device is a touch screen device. In some embodiments with touch control a user can directly manipulate objects by interacting with the graphical user interface that is displayed on the display of the touch screen device. For instance a user can select a particular object in the graphical user interface by simply touching that particular object on the display of the touch screen device. As such when touch control is utilized a cursor may not even be provided for enabling selection of an object of a graphical user interface in some embodiments. However when a cursor is provided in a graphical user interface touch control can be used to control the cursor in some embodiments. Additionally in some embodiments objects in a graphical user interface can also be controlled or manipulated through other controls such as a cursor in a graphical user interface e.g. using a trackpad touchpad mouse etc. .

The display module translates the output of a user interface for a display device. That is the display module receives signals e.g. from the UI interaction and generation module describing what should be displayed and translates these signals into pixel information that is sent to the display device. The display device may be an LCD plasma screen CRT monitor touchscreen etc.

The UI interaction and generation module of the image editing application interprets the user input data received from the input device drivers and passes it to various modules including the edit manager the peel animator and the rendering engine . The UI interaction module also manages the display of the UI e.g. fanning animations of UI controls highlights of UI elements indicators etc. and outputs this display information to the display module . This UI display information may be based on information from the edit manager the peel animator and the rending module etc. In addition the UI interaction module may generate portions of the UI based just on user input e.g. when a user moves an item in the UI that only affect the display not any of the other modules such as moving a window from one side of the UI to the other. In some embodiments the UI interaction module manages the output of audio e.g. sound effects etc. based on user input and or interaction with the UI.

The edit manager manages the order of edit processing. For instance the edit manager identifies edits that a user has made to an image being edited and determines an order to process identified edits on the image. In some embodiments the edit manager determines the order to process edits based on a set of rules. When the edit manager determines the order the edit manager determines a set of edits to display in the UI and sends a request to the peel animator to generate an animation e.g. a peeling off animation a peeling on animation etc. and a request to edit modules to apply the set of edits to the image for the rendering engine to render.

The peel animator generates animations for the rendering engine based on information from the edit manager and the edit modules . When the edit manager requests a peeling animation e.g. a peeling off animation a peeling on animation etc. the peel animator 1 retrieves from the UI interaction and generation module a version of the image being edited that is currently displayed in the UI and 2 retrieves from the edit modules a version of the image being edited that is to be displayed in the UI after the peeling animation. With the information retrieved from the UI interaction module and the edit modules the peel animator generates the requested animation and sends the animation to the rendering engine .

The edit modules are for applying edits to an image e.g. an image being edited . When the edit modules receive from the edit manager a set of edits to apply to an image the edit modules identify the image data in the image data storage that corresponds to the image and apply the set of edits to the image. The edit modules send a version of the edited image to the rendering engine to render a version of the edited image to display. In some embodiments the edit modules send a version of the edited image to the peel animator in order for the peel animator to generate a peel animation.

The rendering engine is responsible for rending different versions of images based on the original image. For instance the rendering module uses the image data in the image data storage to render thumbnails of images and display resolution versions of the images for the UI interaction and generation module to send to the display module to display in a GUI. When edits are made to an image the rendering engine generates edited thumbnail and display resolution versions of the image based on the image data in the image data storage . The rendering engine also renders images when the application of some embodiments exports images to an external source. In some cases the rendering engine renders the full size version of original image.

While many of the features have been described as being performed by one module e.g. the UI interaction module the peel animator etc. one of ordinary skill in the art will recognize that the functions described herein might be split up into multiple modules. Similarly functions described as being performed by multiple different modules might be performed by a single module in some embodiments e.g. the peel animator and the edit manager .

The above sections describe various operations for editing images in the GUI of some embodiments. The application of some embodiments generates and stores a data structure to represent images. which conceptually illustrates a data structure for an image as stored by the application of some embodiments. As shown the data structure includes an image ID a reference to image data edit instructions Exchangeable image file format Exif data a caption shared image data cached versions of the image any tags on the image and any additional data for the image. The image ID is a unique identifier for the image.

The reference to image data is a pointe to the actual full size pixel data for displaying the image e.g. a series of color space channel values for each pixel in the image or an encoded version thereof . The image data of different embodiments are stored in different locations. For instance the image data may be stored in a local location e.g. stored as a file in a file system of a computing device on which the application runs . In such cases the reference points to the local location. In some embodiments the image data is stored in another application e.g. stored in a database of an image organizing application . The other application in some embodiments runs on the same computing device on which the application runs whereas the other application in other embodiments runs on a different computing device. The reference in some such embodiments stores a pointer to the image data stored in the other application. In some embodiments instead of storing a pointer to the image data stored in the other application the reference stores a unique identifier for retrieving the image data from the other application e.g. via an application programming interface API call . In some embodiments when the image is edited through the application the application generates retrieves the image that is stored in the other application and then stores the image in the data structure .

The edit instructions include information regarding any edits the user has applied to the image. In this manner the application stores the image in a non destructive format such that the application can easily revert from an edited version of the image to the original at any time. For instance if the user applies a saturation effect to the image leaves the application and then comes back and decides to remove the effect the user can easily do so.

As shown the edit instructions stores a set of instructions for each edit that the user has applied to the image and the tool identifier for identifier the tool that the user used to apply the edit. Examples of edits include crop edits rotate edits exposure edits color edits brush effect edits effects edits or any other type of edit that modifies the pixels of the image. This way the application can identify all the edits that the user has applied to the image using a particular tool. This allows the application to identify edits made with a particular tool so that the application can remove and re apply edits to the image in order to implement features such as the ones describes above by reference to and . Some embodiments store these editing instructions in a particular order so that users can view different versions of the image with only certain sets of edits applied or the application can easily remove and re apply certain types of edits. In some embodiments the editing instructions are stored in the order in which the user has applied the edits to the image.

The Exif data includes various information stored by the camera that captured the image when that information is available. While Exif is one particular file format that is commonly used by digital cameras one of ordinary skill in the art will recognize that comparable information may be available in other formats as well or may even be directly input by a user. The Exif data includes camera settings data GPS data and a timestamp. The camera settings data includes information about the camera settings for a image if that information is available from the camera that captured the image. This information for example might include the aperture focal length shutter speed exposure compensation and ISO. The GPS data indicates the location at which a image was captured while the timestamp indicates the time according to the camera s clock when the image was captured.

The caption is a user entered description of the image. In some embodiments this information is displayed with the photo in the image viewing area but may also be used to display over the photo in a created journal and may be used if the image is posted to a social media or photo sharing website. When the user posts the image to such a website the application generates shared image data for the image. This information stores the location e.g. Facebook Flickr etc. as well as an object ID for accessing the image in the website s database. The last access date is a date and time at which the application last used the object ID to access any user comments on the photo from the socialmedia or photo sharing website.

The cached image versions store versions of the image that are commonly accessed and displayed so that the application does not need to repeatedly generate these images from the full size image data . As shown the cached image versions include thumbnail image of the current image a display resolution version e.g. a version tailored for the image display area of the current image and a display resolution version of the original image. In some embodiments the application generates a new thumbnail image for the current thumbnail image and the new display resolution version for the current display resolution image when an edit is made to the image. For instance when edits are removed during an ordered edit operation the application generates new thumbnail and display versions of the image that includes only the edits that have not been removed for display in the GUI.

By storing cached versions of the image the application of some embodiments does not need to render full sized versions of the image. In some embodiments the application generates full sized versions of the image when the application exports the image. For instance the user might use a feature of the application of some embodiments that allows the user to save the image to another application e.g. an image organizing application . In such instances the application generates a full sized version of the image and exports it the other application.

As mentioned above the image data is stored in another application in some embodiments. In some embodiments the other application also stores a thumbnail version of the image. The application in some such embodiments stores a pointer to the thumbnail version that is stored in the other application while the image is not edited. In some embodiments when the image is edited through the application the application generates versions of the image that is stored in the other application and then stores them in the cached image versions field of the data structure .

The tags are information that the application enables the user to associate with an image. For instance in some embodiments users can mark the image as a favorite flag the image e.g. for further review and hide the image so that the image will not be displayed when the user cycles through a collection that includes the image. Other embodiments may include additional tags. For instance some embodiments store a tag for indicating that the image data is a raw image a tag that indicates whether an edit has been applied to the image etc. Finally the image data structure includes additional data that the application might store with an image e.g. locations and sizes of faces etc. .

One of ordinary skill in the art will recognize that the image data structure is only one possible data structure that the application might use to store the required information for an image. For example different embodiments might store additional or less information store the information in a different order etc.

In some embodiments the application provides a feature that allows the user to switch between the current edited version of the image and the original image. To facilitate the quick switching between the different versions of the image the application of some embodiments utilizes the non destructive method of storing images described above.

The first stage of the GUI shows an image after it has been edited through the effects tool. As shown a user has activated the effects tool e.g. by selecting the UI item as indicated by the highlighting of the effects item . In addition the user has selected a thumbnail slider control of the effects tool e.g. by touching the thumbnail slider control when the set of thumbnail slider controls of the effects tool were fanned out . The edits are represented in this image through the diagonal lines displayed on the image. The first stage also illustrates that the user has selected the toggle button .

The second stage illustrates the GUI after the user has selected the toggle button . The edited image in the image display area has been replaced by the original image. In this the original image is differentiated from the edited image by the absence of the diagonal lines that were displayed on the edited image in the first stage .

The third stage then illustrates the GUI after the user has selected the toggle button again the effect of which is to revert from the original image back to the edited image. This results in the illustration for the fourth stage which illustrates the edited image with the diagonal lines once again displayed on the image.

The first stage of the GUI shows an image after it has been edited through application of certain effects from the effects tool . As shown a user has made certain edits to image. The edits are represented in this image through the diagonal lines displayed on the image. The first stage also illustrates that the user has selected and continues to select the toggle button e.g. by touching the toggle button without releasing their finger from the screen the effect of which is illustrated in the second stage.

The second stage illustrates the GUI and the original image that appears within a certain threshold time period after the user selects and holds down the toggle button . The edited image in the image display area has been replaced by the original image. The original image is differentiated from the edited image by the absence of the diagonal lines that were displayed on the edited image in the first stage .

The third stage then illustrates the GUI after the user has released the toggle button which again reverts the image being displayed from the original image back to the edited image.

The first stage of the GUI shows an original image without any edits to the image. The first stage also illustrates that the user has selected and continues to select the toggle button e.g. by touching the toggle button without releasing their finger from the screen the effect of which is illustrated in the second stage .

The second stage illustrates the GUI and the edited image that appears within a certain threshold time period after the user selects and holds down the toggle button . The original image in the preview display area has been replaced by the edited image. The edited image is differentiated from the original image in the first stage by the diagonal lines that are displayed on the edited image.

The third stage then illustrates the GUI after the user has released the toggle button which again reverts the image being displayed from the edited image back to the original image.

The first stage of the GUI shows an image after it has been cropped using the crop tool . As shown a user has activated the crop tool e.g. by selecting the UI item as indicated by the highlighting of the crop tool . The cropped image displays only the cropped portion of the original image which in this image is the front portion of a car. The first stage also illustrates that the user has selected the toggle button .

The second stage illustrates the GUI after the user has selected the toggle button when the crop tool is activated. The cropped image in the image display area has been replaced by the original un cropped image. The original image displays the entire image which in this image is the entire car without any of the cropping edits.

The third stage then illustrates the GUI after the user has selected the toggle button again the effect of which is to revert from the original image back to the cropped image. This results in the illustration for the fourth stage which illustrates the cropped image with again only the front portion of the car being displayed in the image.

The described above provide examples of a feature for toggling between two images. In some embodiments the feature provides a visual indication when switching from one image to the other image. For instance some embodiments display an animation e.g. the peeling animations described above by reference to and that transitions from displaying one image to displaying the other image.

The application of some embodiments provides a feature that allows the user of the application to send images to users of other devices that are also running the application. The following section will describe several examples and embodiments of the feature.

As shown in each device within the network broadcasts a beaming service available message to indicate that the device is available to receive data from the image editing applications of the other devices through the beaming services of these applications. The structure of this message includes the hostname of the device service name of the device and the service type. The hostname is used to identify each device within the network with an identifier. This figure illustrates four devices each with a different hostname including devices 1 2 3 and 4 . The service name of the device indicates that the application using the beaming service is the image editing application. The service type indicates that each message is broadcast for the beaming services.

In the example illustrated in the two devices that are about to establish communication with each other are Device 1 and Device 2 as further described below by reference to . illustrates that the image editing application is concurrently running on both devices device 1 and device 2 in order to allow these two devices to exchange image data. In other words for any first device to be able to receive image data from a second device the first device in some embodiments has to have its image editing application active so that it is broadcasting its beaming service availability message to inform other nearby devices including the second device that it is ready to receive messages. However one of ordinary skill in the art will recognize that in other embodiments devices will broadcast this beaming service message even when the image editing application is not being executed by the device. In these embodiments the user will be prompted to open the image editing application to receive the image data when a second device beams an image to a first device that does not have its image editing application open.

In the example illustrated in and the examples described below the devices communicate through a wireless network e.g. Wi Fi network that is established by a wireless transceiver that is not part of one of the devices . Other embodiments however do not need such a wireless transceiver to establish a communication between the devices . For instance some embodiments use the Bluetooth transceiver of the device to establish a wireless link between the devices and then use this link to beam images between devices. In both the Bluetooth approach and the local wireless network approach have an advantage over prior IR based approaches in that they do not require the devices be in line of sight with each other in order to establish inferred communications between them. However some of the features described above and below could be implemented in more traditional IR based approaches.

The first stage shows an edited image . It also shows the first user s selection of the share button through the touching of the location of display of this icon on the display. The share button enables a user to share an image in a variety of ways. In some embodiments the user can send a selected image to another compatible device on the same network e.g. Wi Fi or Bluetooth . The second stage shows that in response to this selection a window has opened that provides the user with multiple choices for transmitting the edited image . This stage also shows that the user has selected Beam as a transmission option for transmitting the image .

The third stage shows that another window has opened in response to the selection of the beam option in the window in the second stage . This third stage also shows the user s selection of Device 2 .

The fourth stage illustrates that after the selection of Device 2 on the first device the image editing application on the second device informs the second user that device one would like to beam a photo to the user. The fourth stage also shows that the second user of the second device has accepted by touching the accept option and that this acceptance has been relayed back to the first device through another message transmission.

Finally the fifth stage shows that the first device provides a display prompt that notifies the first user that the user of the second device has accepted the image. It also shows that in response to this acceptance the first device has transmitted the image data along with the instructions for editing this image to the second device .

The first stage of the GUI illustrates an image displayed on the device that is stored in a library of images that have not been beamed to the device . The first stage also illustrates that the user has selected the back icon which enables the user to navigate back to a collection organization GUI. In order to access other image libraries stored on the device which is illustrated in the second stage . In some embodiments when the device receives a beamed image the device stores the image in a particular library consisting only of other images that have been beamed to a device.

The second stage illustrates the GUI which displays the image albums currently stored on the device. In this example the user has selected the albums icon to view the image albums currently stored on the device . The device only has a single image album labeled Beamed . In some embodiments this beamed image album stores only the images that have been beamed to the device. The second stage also illustrates the user has selected the beamed image album .

The third stage illustrates the GUI and the thumbnail images of the photos stored in the beamed image library . The library currently contains only one image which the user has selected for display.

The fourth stage of the GUI shows the display of the beamed image after the user has selected the thumbnail of the image. As shown the image has had certain edits made to the image. The edits are represented in this image through the diagonal lines displayed on the image . The fourth stage also illustrates that the user has selected and continues to select the toggle button e.g. by touching the toggle button without releasing their finger from the screen the effect of which is illustrated in the fifth stage .

The fifth stage illustrates the GUI and the original image that appears within a certain threshold time period after the user selects and holds down the toggle button . The edited beamed image in the image display area has been replaced by the original beamed image . As described above the application can easily perform this toggle operation because the application maintains the original image in a non destructive way. The original image is differentiated from the edited image by the absence of the diagonal lines that were displayed on the edited beamed image in the first stage .

The sixth stage then illustrates the GUI after the user has released the toggle button which again reverts the image being displayed from the original beamed image back to the edited beamed image .

The following description will be described in terms of a first device and a second device for purpose for explanation. The process is being performed on the first device and the second device is different device that in some embodiments is running the image editing application. One of ordinary skill in the art will realize that the service may be broadcasted to any number of different devices and thus receive image data from any device that detects the service and request to send image data to the first device.

The process starts by broadcasting at a service that specifies a hostname parameter a service name parameter and a service type parameter. The hostname parameter is the hostname of the device from which the process is broadcasting e.g. the device on which the image editing application is running . The service name parameter is a name used to identify the service being broadcasted. In some embodiments the service name parameter is the name of the image editing application. The service type parameter specifies the type of service that is broadcasted. In some instances an application on a device may provide several different services for the application. Thus using the hostname and service name is not sufficient to differentiate among the several services broadcasted for the application. As such the service type parameter is used to differentiate among different services that may be provided by a single application running on a device.

Next the process determines at whether a connection request from the second is received. In some embodiments the process receives a request to establish a set of connections with second device through which the first and second devices use to communicate. When the process determines that a connection request from the second device is received the process proceeds to . Otherwise the process returns to to continue broadcasting the service.

At the process establishes a set of connections e.g. by establishing a set of network sockets with the second device through which the first and second devices use to communicate. After establishing the set of connections the process receives at an image from the second device. In some embodiments the process receives the image in the form of a data structure of the image that is similar to the data structure described above by reference to .

The process begins by searching at a network for services of a service type. As noted above the image editing application of some embodiments broadcasts a service that specifies a service type along with a service name and the hostname of the device on which the application is running. In some embodiments the process searches for services broadcasted by the image editing application of such embodiments. The process in some embodiments uses a service discovery protocol to search the network for services of a service type. Examples of service discovery protocols include Apple Bonjour zero configuration networking zeroconf a service location protocol SLP simple service discovery protocol SSDP Bluetooth service discovery protocol SDP etc. In some embodiments the network that the process is searching is a single broadcast domain network.

Next the process determines at whether a device that provides the service type is identified. In some embodiments the process uses a service discovery protocol mentioned above to make the determination. When the process determines that a device that provides the service type is not identified the process returns to to continue searching the network.

When the process determines that a device that provides the service type is identified the process displays at the hostname of the host. As mentioned above some embodiments broadcast a service that specifies the hostname of the host. In some embodiments the process displays the hostname and or the service name specified by the service in a GUI e.g. the GUI described above by reference to .

The process then determines at whether a selection of a service is received. When the process determines that a selection of a service is received the process proceeds to . Otherwise the process returns to to continue searching for services of a service type and displaying the hostnames of devices that provide the services of the service type.

At the process resolves the hostname of the device that is providing the selected service to an Internet Protocol IP address. In some embodiments the process uses a service discovery protocol explained above to resolve the hostname of the device.

Next the process establishes at a set of connections to the device using the IP address. The process of some embodiments uses the IP address to establish a set of network sockets with the device.

Finally the process transmits at an image to the device. In some embodiments the process transmits the image in the form of a data structure of the image that is similar to the data structure described above by reference to .

To transmit the image or image data structure the process divides the image data into defined size portions e.g. 65536 byes and transmits the image data in packets. In some embodiments each packet includes a header and a portion of the image data e.g. the payload . The packet header of some embodiments includes various fields that include a signature field for versioning purposes a type field for specifying the type of packet e.g. payload packet cancel packet acknowledgement packet etc. a UUID for uniquely identifying the packet against other packets a packet index field a packet count field an item index field an item count field a filename length field etc.

The above described illustrate example techniques for receiving an image from a single device and transmitting an image to a single device. One of ordinary skill in the art will recognize that the similar techniques may be used to receive multiple images from multiple different devices. Similarly similar techniques may be used to transmit multiple images to multiple different devices.

The above described figures illustrated various examples of the GUI of an image viewing editing and organization application of some embodiments. illustrates a detailed view of a GUI of some embodiments for viewing editing and organizing images. The GUI will be described in part by reference to which conceptually illustrates a data structure for an image as stored by the application of some embodiments.

The data structure includes an image ID image data edit instructions Exchangeable image file format Exif data a caption shared image data cached versions of the image any tags on the image and any additional data for the image. The image ID is a unique identifier for the image which in some embodiments is used by the collection data structures to refer to the images stored in the collection.

The image data is the actual full size pixel data for displaying the image e.g. a series of color space channel values for each pixel in the image or an encoded version thereof . In some embodiments this data may be stored in a database of the image viewing editing and organization application or may be stored with the data of another application on the same device. In some embodiments this additional application is another image organization application that operates on the device on top of which the image viewing editing and organization operates.

Thus the data structure may store a pointer to the local file associated with the application or an ID that can be used to query the database of another application. In some embodiments once the application uses the image in a journal or makes an edit to the image the application automatically makes a local copy of the image file that contains the image data.

The edit instructions include information regarding any edits the user has applied to the image. In this manner the application stores the image in a non destructive format such that the application can easily revert from an edited version of the image to the original at any time. For instance the user can apply a saturation effect to the image leave the application and then reopen the application and remove the effect at another time. The edits stored in these instructions may be crops and rotations full image exposure and color adjustments localized adjustments and special effects as well as other edits that affect the pixels of the image. Some embodiments store these editing instructions in a particular order so that users can view different versions of the image with only certain sets of edits applied.

The Exif data includes various information stored by the camera that captured the image when that information is available. While Exif is one particular file format that is commonly used by digital cameras one of ordinary skill in the art will recognize that comparable information may be available in other formats as well or may even be directly input by a user. The Exif data includes camera settings data GPS data and a timestamp. The camera settings data includes information about the camera settings for a image if that information is available from the camera that captured the image. This information for example might include the aperture focal length shutter speed exposure compensation and ISO. The GPS data indicates the location at which a image was captured while the timestamp indicates the time according to the camera s clock at which the image was captured.

The caption is a user entered description of the image. In some embodiments this information is displayed with the photo in the image viewing area but may also be used to display over the photo in a created journal and may be used if the image is posted to a social media or photo sharing website. When the user posts the image to such a website the application generates shared image data for the image. This information stores the location e.g. Facebook Flickr etc. as well as an object ID for accessing the image in the website s database. The last access date is a date and time at which the application last used the object ID to access any user comments on the photo from the social media or photo sharing website.

The cached image versions store versions of the image that are commonly accessed and displayed so that the application does not need to repeatedly generate these images from the full size image data . For instance the application will often store a thumbnail for the image as well as a display resolution version e.g. a version tailored for the image display area . The application of some embodiments generates a new thumbnail for an image each time an edit is applied replacing the previous thumbnail. Some embodiments store multiple display resolution versions including the original image and one or more edited versions of the image.

The tags are information that the application enables the user to associate with an image. For instance in some embodiments users can mark the image as a favorite flag the image e.g. for further review and hide the image so that the image will not be displayed within the standard thumbnail grid for a collection and will not be displayed in the image display area when the user cycles through a collection that includes the image. Other embodiments may include additional tags. Finally the image data structure includes additional data that the application might store with an image e.g. locations and sizes of faces etc. .

One of ordinary skill in the art will recognize that the image data structure is only one possible data structure that the application might use to store the required information for an image. For example different embodiments might store additional or less information store the information in a different order etc.

Returning to the GUI includes a thumbnail display area an image display area a first toolbar a second toolbar and a third toolbar . The thumbnail display area displays thumbnails of the images in a selected collection. Thumbnails are small representations of a full size image and represent only a portion of an image in some embodiments. For example the thumbnails in thumbnail display area are all squares irrespective of the aspect ratio of the full size images. In order to determine the portion of a rectangular image to use for a thumbnail the application identifies the smaller dimension of the image and uses the center portion of the image in the longer direction. For instance with a 1600 1200 pixel image the application would use a 1200 1200 square. To further refine the selected portion for a thumbnail some embodiments identify a center of all the faces in the image using a face detection algorithm and then use this location to center the thumbnail portion in the clipped direction. Thus if the faces in the theoretical 1600 1200 image were all located on the left side of the image the application would use the leftmost 1200 columns of pixels rather than cut off 200 columns on either side.

After determining the portion of the image to use for the thumbnail the image viewing application generates a low resolution version e.g. using pixel blending and other techniques of the image. The application of some embodiments stores the thumbnail for an image as a cached version of the image. Thus when a user selects a collection the application identifies all of the images in the collection through the collection data structure and accesses the cached thumbnails in each image data structure for display in the thumbnail display area.

The user may select one or more images in the thumbnail display area e.g. through various touch interactions described above or through other user input . The selected thumbnails are displayed with a highlight or other indicator of selection. In thumbnail display area the thumbnail is selected. In addition as shown the thumbnail display area of some embodiments indicates a number of images in the collection that have been flagged i.e. that have a tag for the flag set to yes . In some embodiments this text is selectable in order to display only the thumbnails of the flagged images.

The application displays selected images in the image display area at a larger resolution than the corresponding thumbnails. The images are not typically displayed at the full size of the image as images often have a higher resolution than the display device. As such the application of some embodiments stores a cached version of the image designed to fit into the image display area. Images in the image display area are displayed in the aspect ratio of the full size image. When one image is selected the application displays the image as large as possible within the image display area without cutting off any part of the image. When multiple images are selected the application displays the images in such a way as to maintain their visual weighting by using approximately the same number of pixels for each image even when the images have different aspect ratios.

The first toolbar displays title information e.g. the name of the collection shown in the GUI a caption that a user has added to the currently selected image etc. . In addition the toolbar includes a first set of GUI items and a second set of GUI items .

The first set of GUI items includes a back button a grid button a help button and an undo button . The back button enables the user to navigate back to a collection organization GUI from which users can select between different collections of images e.g. albums events journals etc. . Selection of the grid button causes the application to move the thumbnail display area on or off of the GUI e.g. via a slide animation . In some embodiments users can also slide the thumbnail display area on or off of the GUI via a swipe gesture. The help button activates a context sensitive help feature that identifies a current set of tools active for the user and provides help indicators for those tools that succinctly describe the tools to the user. In some embodiments the help indicators are selectable to access additional information about the tools. Selection of the undo button causes the application to remove the most recent edit to the image whether this edit is a crop color adjustment etc. In order to perform this undo some embodiments remove the most recent instruction from the set of edit instructions stored with the image.

The second set of GUI items includes a sharing button an information button a show original button and an edit button . The sharing button enables a user to share an image in a variety of different ways. In some embodiments the user can send a selected image to another compatible device on the same network e.g. Wi Fi or Bluetooth network upload an image to an image hosting or social media website and create a journal i.e. a presentation of arranged images to which additional content can be added from a set of selected images among others.

The information button activates a display area that displays additional information about one or more selected images. The information displayed in the activated display area may include some or all of the Exif data stored for an image e.g. camera settings timestamp etc. . When multiple images are selected some embodiments only display Exif data that is common to all of the selected images. Some embodiments include additional tabs within the information display area for i displaying a map showing where the image or images were captured according to the GPS data if this information is available and ii displaying comment streams for the image on any photo sharing websites. To download this information from the websites the application uses the object ID stored for the image with the shared image data and sends this information to the website. The comment stream and in some cases additional information are received from the website and displayed to the user.

The show original button enables the user to toggle between the original version of an image and the current edited version of the image. When a user selects the button the application displays the original version of the image without any of the editing instructions applied. In some embodiments the appropriate size image is stored as one of the cached versions of the image making it quickly accessible. When the user selects the button again again the application displays the edited version of the image with the editing instructions applied.

The edit button allows the user to enter or exit edit mode. When a user has selected one of the sets of editing tools in the toolbar the edit button returns the user to the viewing and organization mode as shown in . When the user selects the edit button while in the viewing mode the application returns to the last used set of editing tools in the order shown in toolbar . That is the items in the toolbar are arranged in a particular order and the edit button activates the rightmost of those items for which edits have been made to the selected image.

The toolbar as mentioned includes five items arranged in a particular order from left to right. The crop item activates a cropping and rotation tool that allows the user to align crooked images and remove unwanted portions of an image. The exposure item activates a set of exposure tools that allow the user to modify the black point shadows contrast brightness highlights and white point of an image. In some embodiments the set of exposure tools is a set of sliders that work together in different combinations to modify the tonal attributes of an image. The color item activates a set of color tools that enable the user to modify the saturation and vibrancy as well as color specific saturations e.g. blue pixels or green pixels and white balance. In some embodiments some of these tools are presented as a set of sliders. The brushes item activates a set of enhancement tools that enable a user to localize modifications to the image. With the brushes the user can remove red eye and blemishes and apply or remove saturation and other features to localized portions of an image by performing a rubbing action over the image. Finally the effects item activates a set of special effects that the user can apply to the image. These effects include gradients tilt shifts non photorealistic desaturation effects grayscale effects various filters etc. In some embodiments the application presents these effects as a set of items that fan out from the toolbar .

As stated the UI items are arranged in a particular order. This order follows the order in which users most commonly apply the five different types of edits. Accordingly the editing instructions are stored in this same order in some embodiments. When a user selects one of the items some embodiments apply only the edits from the tools to the left of the selected tool to the displayed image though other edits remain stored within the instruction set .

The toolbar includes a set of GUI items as well as a settings item . The auto enhance item automatically performs enhancement edits to an image e.g. removing apparent red eye balancing color etc. . The rotation button rotates any selected images. In some embodiments each time the rotation button is pressed the image rotates 90 degrees in a particular direction. The auto enhancement in some embodiments comprises a predetermined set of edit instructions that are placed in the instruction set . Some embodiments perform an analysis of the image and then define a set of instructions based on the analysis. For instance the auto enhance tool will attempt to detect red eye in the image but if no red eye is detected then no instructions will be generated to correct it. Similarly automatic color balancing will be based on an analysis of the image. The rotations generated by the rotation button are also stored as edit instructions.

The flag button tags any selected image as flagged. In some embodiments the flagged images of a collection can be displayed without any of the unflagged images. The favorites button allows a user to mark any selected images as favorites. In some embodiments this tags the image as a favorite and also adds the image to a collection of favorite images. The hide button enables a user to tag an image as hidden. In some embodiments a hidden image will not be displayed in the thumbnail display area and or will not be displayed when a user cycles through the images of a collection in the image display area. As shown in many of these features are stored as tags in the image data structure.

Finally the settings button activates a context sensitive menu that provides different menu options depending on the currently active toolset. For instance in viewing mode the menu of some embodiments provides options for creating a new album setting a key photo for an album copying settings from one photo to another and other options. When different sets of editing tools are active the menu provides options related to the particular active toolset.

One of ordinary skill in the art will recognize that the image viewing and editing GUI is only one example of many possible graphical user interfaces for an image viewing editing and organizing application. For instance the various items could be located in different areas or in a different order and some embodiments might include items with additional or different functionalities. The thumbnail display area of some embodiments might display thumbnails that match the aspect ratio of their corresponding full size images etc.

Many of the above described features and applications are implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium also referred to as computer readable medium . When these instructions are executed by one or more computational or processing unit s e.g. one or more processors cores of processors or other processing units they cause the processing unit s to perform the actions indicated in the instructions. Examples of computer readable media include but are not limited to CD ROMs flash drives random access memory RAM chips hard drives erasable programmable read only memories EPROMs electrically erasable programmable read only memories EEPROMs etc. The computer readable media does not include carrier waves and electronic signals passing wirelessly or over wired connections.

In this specification the term software is meant to include firmware residing in read only memory or applications stored in magnetic storage which can be read into memory for processing by a processor. Also in some embodiments multiple software inventions can be implemented as sub parts of a larger program while remaining distinct software inventions. In some embodiments multiple software inventions can also be implemented as separate programs. Finally any combination of separate programs that together implement a software invention described here is within the scope of the invention. In some embodiments the software programs when installed to operate on one or more electronic systems define one or more specific machine implementations that execute and perform the operations of the software programs.

The image editing and viewing applications of some embodiments operate on mobile devices. is an example of an architecture of such a mobile computing device. Examples of mobile computing devices include smartphones tablets laptops etc. As shown the mobile computing device includes one or more processing units a memory interface and a peripherals interface .

The peripherals interface is coupled to various sensors and subsystems including a camera subsystem a wireless communication subsystem s an audio subsystem an I O subsystem etc. The peripherals interface enables communication between the processing units and various peripherals. For example an orientation sensor e.g. a gyroscope and an acceleration sensor e.g. an accelerometer is coupled to the peripherals interface to facilitate orientation and acceleration functions.

The camera subsystem is coupled to one or more optical sensors e.g. a charged coupled device CCD optical sensor a complementary metal oxide semiconductor CMOS optical sensor etc. . The camera subsystem coupled with the optical sensors facilitates camera functions such as image and or video data capturing. The wireless communication subsystem serves to facilitate communication functions. In some embodiments the wireless communication subsystem includes radio frequency receivers and transmitters and optical receivers and transmitters not shown in . These receivers and transmitters of some embodiments are implemented to operate over one or more communication networks such as a GSM network a Wi Fi network a Bluetooth network etc. The audio subsystem is coupled to a speaker to output audio e.g. to output different sound effects associated with different image operations . Additionally the audio subsystem is coupled to a microphone to facilitate voice enabled functions such as voice recognition digital recording etc.

The I O subsystem involves the transfer between input output peripheral devices such as a display a touch screen etc. and the data bus of the processing units through the peripherals interface . The I O subsystem includes a touch screen controller and other input controllers to facilitate the transfer between input output peripheral devices and the data bus of the processing units . As shown the touch screen controller is coupled to a touch screen . The touch screen controller detects contact and movement on the touch screen using any of multiple touch sensitivity technologies. The other input controllers are coupled to other input control devices such as one or more buttons. Some embodiments include a near touch sensitive screen and a corresponding controller that can detect near touch interactions instead of or in addition to touch interactions.

The memory interface is coupled to memory . In some embodiments the memory includes volatile memory e.g. high speed random access memory non volatile memory e.g. flash memory a combination of volatile and non volatile memory and or any other type of memory. As illustrated in the memory stores an operating system OS . The OS includes instructions for handling basic system services and for performing hardware dependent tasks.

The memory also includes communication instructions to facilitate communicating with one or more additional devices graphical user interface instructions to facilitate graphic user interface processing image processing instructions to facilitate image related processing and functions input processing instructions to facilitate input related e.g. touch input processes and functions audio processing instructions to facilitate audio related processes and functions and camera instructions to facilitate camera related processes and functions. The instructions described above are merely exemplary and the memory includes additional and or other instructions in some embodiments. For instance the memory for a smartphone may include phone instructions to facilitate phone related processes and functions. The above identified instructions need not be implemented as separate software programs or modules. Various functions of the mobile computing device can be implemented in hardware and or in software including in one or more signal processing and or application specific integrated circuits.

While the components illustrated in are shown as separate components one of ordinary skill in the art will recognize that two or more components may be integrated into one or more integrated circuits. In addition two or more components may be coupled together by one or more communication buses or signal lines. Also while many of the functions have been described as being performed by one component one of ordinary skill in the art will realize that the functions described with respect to may be split into two or more integrated circuits.

The bus collectively represents all system peripheral and chipset buses that communicatively connect the numerous internal devices of the electronic system . For instance the bus communicatively connects the processing unit s with the read only memory the GPU the system memory and the permanent storage device .

From these various memory units the processing unit s retrieves instructions to execute and data to process in order to execute the processes of the invention. The processing unit s may be a single processor or a multi core processor in different embodiments. Some instructions are passed to and executed by the GPU . The GPU can offload various computations or complement the image processing provided by the processing unit s . In some embodiments such functionality can be provided using CoreImage s kernel shading language.

The read only memory ROM stores static data and instructions that are needed by the processing unit s and other modules of the electronic system. The permanent storage device on the other hand is a read and write memory device. This device is a non volatile memory unit that stores instructions and data even when the electronic system is off. Some embodiments of the invention use a mass storage device such as a magnetic or optical disk and its corresponding disk drive as the permanent storage device .

Other embodiments use a removable storage device such as a floppy disk flash memory device etc. and its corresponding drive as the permanent storage device Like the permanent storage device the system memory is a read and write memory device. However unlike storage device the system memory is a volatile read and write memory such a random access memory. The system memory stores some of the instructions and data that the processor needs at runtime. In some embodiments the invention s processes are stored in the system memory the permanent storage device and or the read only memory . For example the various memory units include instructions for processing multimedia clips in accordance with some embodiments. From these various memory units the processing unit s retrieves instructions to execute and data to process in order to execute the processes of some embodiments.

The bus also connects to the input and output devices and . The input devices enable the user to communicate information and select commands to the electronic system. The input devices include alphanumeric keyboards and pointing devices also called cursor control devices cameras e.g. webcams microphones or similar devices for receiving voice commands etc. The output devices display images generated by the electronic system or otherwise output data. The output devices include printers and display devices such as cathode ray tubes CRT or liquid crystal displays LCD as well as speakers or similar audio output devices. Some embodiments include devices such as a touchscreen that function as both input and output devices.

Finally as shown in bus also couples electronic system to a network through a network adapter not shown . In this manner the computer can be a part of a network of computers such as a local area network LAN a wide area network WAN or an Intranet or a network of networks such as the Internet. Any or all components of electronic system may be used in conjunction with the invention.

Some embodiments include electronic components such as microprocessors storage and memory that store computer program instructions in a machine readable or computer readable medium alternatively referred to as computer readable storage media machine readable media or machine readable storage media . Some examples of such computer readable media include RAM ROM read only compact discs CD ROM recordable compact discs CD R rewritable compact discs CD RW read only digital versatile discs e.g. DVD ROM dual layer DVD ROM a variety of recordable rewritable DVDs e.g. DVD RAM DVD RW DVD RW etc. flash memory e.g. SD cards mini SD cards micro SD cards etc. magnetic and or solid state hard drives read only and recordable Blu Ray discs ultra density optical discs any other optical or magnetic media and floppy disks. The computer readable media may store a computer program that is executable by at least one processing unit and includes sets of instructions for performing various operations. Examples of computer programs or computer code include machine code such as is produced by a compiler and files including higher level code that are executed by a computer an electronic component or a microprocessor using an interpreter.

While the above discussion primarily refers to microprocessor or multi core processors that execute software some embodiments are performed by one or more integrated circuits such as application specific integrated circuits ASICs or field programmable gate arrays FPGAs . In some embodiments such integrated circuits execute instructions that are stored on the circuit itself. In addition some embodiments execute software stored in programmable logic devices PLDs ROM or RAM devices.

As used in this specification and any claims of this application the terms computer server processor and memory all refer to electronic or other technological devices. These terms exclude people or groups of people. For the purposes of the specification the terms display or displaying means displaying on an electronic device. As used in this specification and any claims of this application the terms computer readable medium computer readable media and machine readable medium are entirely restricted to tangible physical objects that store information in a form that is readable by a computer. These terms exclude any wireless signals wired download signals and any other ephemeral signals.

While the invention has been described with reference to numerous specific details one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. For instance many of the figures illustrate various touch gestures e.g. taps double taps swipe gestures press and hold gestures etc. . However many of the illustrated operations could be performed via different touch gestures e.g. a swipe instead of a tap etc. or by non touch input e.g. using a cursor controller a keyboard a touchpad trackpad a near touch sensitive screen etc. . In addition a number of the figures including and conceptually illustrate processes. The specific operations of these processes may not be performed in the exact order shown and described. The specific operations may not be performed in one continuous series of operations and different specific operations may be performed in different embodiments. Furthermore the process could be implemented using several sub processes or as part of a larger macro process. Thus one of ordinary skill in the art would understand that the invention is not to be limited by the foregoing illustrative details but rather is to be defined by the appended claims.

While the invention has been described with reference to numerous specific details one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. For example the various UI controls illustrated in and are either depicted as being set with a finger gesture e.g. placing pointing tapping one or more fingers on a touch sensitive screen or simply shown in a position without any indication of how they were moved into position. One of ordinary skill in the art will understand that the controls of and can also be activated and or set by a cursor control device e.g. a mouse or trackball a stylus keyboard a finger gesture e.g. placing pointing tapping one or more fingers near a near touch sensitive screen or any other control system in some embodiments. Thus one of ordinary skill in the art would understand that the invention is not to be limited by the foregoing illustrative details but rather is to be defined by the appended claims.

