---

title: Drop sensitive prefix (BGP path) attribute modification
abstract: In a system including a first autonomous system (AS) configured to have a first gateway router forward data associated with a set of IP address prefixes, to a second AS via a link to a first eBGP peer device of the second AS, the problem of data packets dropped at an output of the first gateway router while the link is still “up” and an eBGP session between the first gateway router and the first eBGP peer is still up, is solved by (1) receiving information about dropped data packets at an output of the first gateway router, (2) determining whether a data traffic offload condition exists using the received information, (3) changing path attribute(s) of at least some of the IP address prefixes of the set if a data traffic offload condition exists, such that the first gateway router will be less likely to forward data associated with those IP address prefixes, and (4) generating a BGP update message including the changed path attribute(s) for communication to at least one iBGP peer device in the first AS.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08948008&OS=08948008&RS=08948008
owner: Juniper Networks, Inc.
number: 08948008
owner_city: Sunnyvale
owner_country: US
publication_date: 20120803
---
The present invention concerns communications networks. More specifically the present invention concerns improving data transport services provided by a first autonomous system AS of a communications network to a second autonomous system of the communications network.

In traditional Internet service providers ISPs a peering relationship between a Service Provider and an Enterprise Customer e.g. between Verizon and WellsFargo Bank or between two Service Providers themselves e.g. between Verizon and AT T or more generally between a first autonomous system AS and a second autonomous system AS is predominantly via a point to point external border gateway protocol eBGP link. The current version of the border gateway protocol is described in IETF RFC 4271 which is incorporated herein by reference. Many times these point to point links e.g. a 1 Gbps link a 10 Gbps line or any other speed link become congested with too much data also referred to as running hot . This may occur for example because of a distributed denial of service DDoS attack the customer inadvertently DDoSing itself poor routing or a failure of certain paths in the networks.

When eBGP links become too congested there are often many packets dropped at the egress of the service provider on the given link e.g. at a gateway router of the service provider sharing a link with a customer device . In many router operating systems such as JUNOS provided in routers by Juniper Networks Inc. of Sunnyvale Calif. control packets of the BGP protocol are programmed such that BGP transmissions or retransmissions are transmitted over a higher priority queue Queue 3 Network Control queue for BGP TCP retransmissions than for normal data transmissions which typically use a best efforts queue . The reason for this implementation is to keep the BGP peering session up by protecting the control packets in cases where the link is getting congested. Consequently although route exchange sessions establishment and maintenance under the BGP protocol happen over a higher priority queue data packets as opposed to control packets by default get implemented in the best effort queue or get implemented on a queue that has lower priority than the higher priority queue of the control packets . Thus control packets e.g. BGP peering packets will be communicated with higher priority over data packets. Consequently even as data packets are dropped the BGP peering session might not be aware of this because its packets which are control packets not data packets are not dropped and the BGP session itself stays up

Dropped data packets lead to a poor experience for the ISP s enterprise customer or for a second AS having a peering relationship with a first AS .

BGP dampening as described in IETF RFC 2439 incorporated herein by reference prevents oscillations when a BGP session is flapping i.e. going down and coming back up often multiple times . However BGP dampening is invoked only when a BGP session itself is flapping in which case BGP damping penalizes the particular BGP session that is flapping. Unfortunately BGP flapping might not occur in scenarios where the link is running hot and data packets are being dropped. Again this is because the control packets of the BGP session are given priority over data packets and the BGP session is not going down. That is BGP damping won t even be invoked in scenarios where there are output drops due to link congestion but no BGP session flap.

Referring to consider an example environment in which an ISP has two of its Gateway GW routers having eBGP peering sessions with customer edge devices of the same Enterprise customer . The ISP advertises the network address prefixes of the customer internally to its other GW routers e.g. through internal BGP iBGP . In accordance with BGP the GW router is used as the primary gateway for the Enterprise Customer s network address prefixes while the GW router is available as the backup. This selection or configuration may be based on BGP path attributes such as local preference LP AS path origin etc. In this example assume that BGP selects the GW router with the highest local preference LP value for a given network address prefix as the primary gateway for that prefix. In since the GW router has a higher local preference value than that of GW router for all of the network address prefixes of the customer 120 100 assume that BGP uses GW router as the primary gateway for the network address prefixes of customer while GW router is available as the backup gateway.

Assume that the link between the primary GW router and the customer edge device e.g. customer router is experiencing congestion and many data packets are being dropped at the output e.g. the output queue of the GW router . Unfortunately the ISP will not see and be able to address this problem quickly unless it is monitoring the link . Typically the ISP will soon start getting complaints from its customer about applications failing call drops and all other problems that occur for the customer when data packets addressed to its prefixes are dropped. The ISP s customer is not going to be satisfied with such a situation. Typically the customer is going to report these problems to the ISP s network operations center NOC . It is only after the customer has become upset enough to contact the ISP does the ISP learn of the problem 

The ISP would only then realize that there might be a DDoS issue or that the customer is DDoSing itself. At the ISP if the problem cannot be handled by lower level personnel e.g. at Tier the problem ticket gets escalated to higher level personnel e.g. at Tier or higher until personnel with the appropriate skill set and authority can rectify the problem. Depending on their proficiency the NOC might mitigate the problem of dropped data packets on the congested link by changing one or more BGP path attributes such that the link between the primary GW router and the customer edge device becomes less preferred. Unfortunately however this solution wastes time and leads to decreased customer satisfaction with the ISP especially since this solution is slow and reactive to receiving a complaint from the customer . This is particularly unfortunate given that the backup GW router and link were available the whole time but were not utilized due to BGP selecting the congested primary path based on its BGP path attributes e.g. local preferences in this example .

Scheduling and load balancing techniques such as multipath are used to avoid congestion and are typically implemented at the ingress e.g. GW router of not at the egress. Although scheduling permits some data packets to get a higher priority than other data packets control packets almost always get the highest priority. Therefore at best some data packets if any in the same queue priority as that of the control packets get protected. Unfortunately however data packets in the other queues may be dropped leading to a poor customer experience. Multipath in essence tries to use both of the links simultaneously. However multipath is static and fixed in nature. It predetermines the traffic that will use one link versus the other and because of this unforeseen problems cannot be solved completely. A solution that is dynamic in nature and that tries to balance traffic responsive to the detection of a problem may be desirable.

As should be appreciated from the foregoing in a network environment in which a first AS configured to have a first GW router forward data associated with a set of one or more IP address prefixes to a second AS system via a first link to a first eBGP peer device of the second AS the first AS having a second GW router capable of forwarding data to the second AS system via a second link to a e.g. the same or another eBGP peer device of the second AS it would be useful to provide an improved solution to the problem of data packets dropped at an output e.g. egress of the first GW router while the first link between the first GW router and the first eBGP peer device of the second AS is still up and while an eBGP session between the first GW router and the first eBGP peer is still up. It would be useful if the solution avoided the need of a manually implemented reactive fix. It would be useful if the solution is invoked before the dropped data packets become very apparent to the customer. It would be useful if the solution notifies the service provider and prompts them to take proactive action or if the solution takes the proactive action itself. It would also be useful if the solution lets the enterprise customer use its redundant path more effectively to increase the return on investment value for the enterprise customer.

In a first AS configured to have a first GW router forward data associated with a set of one or more IP address prefixes to a second AS system via a first link to a first border device of the second AS the first AS having a second GW router capable of forwarding data to the second AS system via a second link to a e.g. the same or another border device of the second AS the problem of data e.g. packets cells etc. dropped at an output e.g. egress interface or port sometimes referred to as an egress or edge or GW peer point of the first GW router while the first link between the first GW router and the first border device of the second AS is still up is solved by 1 receiving information about dropped data at the output of the first GW router 2 determining whether a data traffic offload condition exists using the received information 3 changing one or more attributes of at least some of the one or more of the IP address prefixes of the set responsive to a determination that a data traffic offload condition exists such that the first GW router will be less likely to forward data associated with the at least some of the one or more IP address prefixes of the set and 4 outputting the changed one or more attributes for communication to at least one other router of the first AS.

In the context of an AS using iBGP and eBGP peering in a first AS configured to have a first GW router forward data associated with a set of one or more IP address prefixes to a second AS system via a first link to a first eBGP peer device of the second AS the first AS having a second GW router capable of forwarding data to the second AS system via a second link to a e.g. the same or another eBGP peer device of the second AS the problem of data packets dropped at an output of the first GW router while the first link between the first GW router and the first eBGP peer device of the second AS is still up and while an eBGP session between the first GW router and the first EBGP peer is still up is solved by 1 receiving information about dropped data packets at the output of the first GW router 2 determining whether a data traffic offload condition exists using the received information 3 changing one or more path attributes of at least some of the one or more of the IP address prefixes of the set responsive to a determination that a data traffic offload condition exists such that the first GW router will be less likely to forward data associated with the at least some of the one or more IP address prefixes of the set and 4 generating a BGP update message including the changed one or more path attributes for communication to at least one iBGP peer device in the first AS.

The present invention may involve novel methods apparatus message formats and or data structures for avoiding or reducing dropped data packets at an output of a first GW router while a first link between the first GW router and a first eBGP peer device of a second AS is still up and while an eBGP session between the first GW router and the first eBGP peer is still up. The following description is presented to enable one skilled in the art to make and use the invention and is provided in the context of particular applications and their requirements. Thus the following description of embodiments consistent with the present invention provides illustration and description but is not intended to be exhaustive or to limit the present invention to the precise form disclosed. Various modifications to the disclosed embodiments will be apparent to those skilled in the art and the general principles set forth below may be applied to other embodiments and applications. For example although a series of acts may be described with reference to a flow diagram the order of acts may differ in other implementations when the performance of one act is not dependent on the completion of another act. Further non dependent acts may be performed in parallel. No element act or instruction used in the description should be construed as critical or essential to the present invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Where only one item is intended the term one or similar language is used. Thus the present invention is not intended to be limited to the embodiments shown and the inventor regards his invention as any patentable subject matter described.

In some example implementations the first autonomous system is an Internet service provider and wherein the second autonomous system is a customer of the Internet service provider. In other example implementations the peers are both Internet service providers.

Referring back to block in some example embodiments the act of changing one or more path attributes of at least some of the one or more of the IP address prefixes of the set such that the first GW router will be less likely to forward data associated with the at least some of the one or more IP address prefixes of the set includes A changing a local preference BGP path attribute of at least some of the one or more of the IP address prefixes of the set B decreasing a local preference BGP path attribute of at least some of the one or more of the IP address prefixes of the set and or C changing at least one of i an AS path BGP path attribute ii an origin BGP path attribute and or iii a communities BGP path attribute of at least some of the one or more of the IP address prefixes of the set.

Some example methods may further include generating the received information about dropped data packets at an output of the first gateway router. Some example methods may generate the received information using an interface statistics counter. Other example methods may generate the received information using a management information base MIB of a simple network management protocol SNMP .

Referring back to block in some example methods the act of determining whether a data traffic offload condition exists using the received information includes determining whether A a measured dropped packet per time period value or B a measured dropped byte per time period value included in the received information exceeds a predetermined parameter. In some such example methods A the measured dropped packet per time period value or B the measured dropped byte per time period value may be taken from an output queue of the first GW router. In other such example methods A the measured dropped packet per time period value or B the measured dropped byte per time period value may be taken from an output interface of the first GW router.

In some example methods the at least some of the one or more of the IP address prefixes of the set consist of a predetermined number of the one or more IP address prefixes. In other example methods the at least some of the one or more of the IP address prefixes of the set consist of a predetermined percentage of the one or more IP address prefixes.

In some example methods the at least some of the one or more of the IP address prefixes of the set are selected randomly. In other example methods the at least some of the one or more of the IP address prefixes of the set are selected in accordance with a predefined heuristic. In such example methods the predefined heuristic may consider the amount of traffic destined or dropped for each of the IP address prefixes of the set.

The example method may be performed locally on the first GW router. In other example methods at least the act of changing one or more path attributes of at least some of the one or more of the IP address prefixes of the set responsive to a determination that a data traffic offload condition exists such that the first GW router will be less likely to forward data associated with the at least some of the one or more IP address prefixes of the set is performed by a centralized control unit external to the first GW router.

Finally the example method may further include sending by the first GW router a packet drop sensitive BGP attribute as a BGP capability to an iBGP peer.

As should be appreciated from the foregoing BGP may be used to monitor factors like congestion and drops on the link over which the eBGP session is established with the customer. When the BGP process finds that the link quality has degraded it may then feed this data to the prefixes learned over this eBGP session. BGP may then modify the attributes of some of the prefixes so as to make them less preferable. The method may be iterative in nature such that if after a first iteration a data traffic offload condition still exists the attribute modification process may be repeated. The goal is to make the GW router less preferable for certain routes shifting some of the data traffic to another e.g. redundant secondary link thereby alleviating the problem.

For example an example BGP process would first resolve the next hop of the eBGP peering IP address on which the method is configured. The result of this resolution would provide the BGP with an ifl index e.g. an interface index that maps virtual interfaces to physical interfaces . Using a data input mechanism e.g. interface statistics counters SNMP MIBS etc. BGP can monitor the output drops queues to ascertain the quality of the link to determine whether a data traffic offload condition exists. The data traffic offload condition can be a user configurable parameter in terms of packets or bytes per second drop e.g. 100 Mpps drops 500 Mpps drops etc . Based on this configured parameter once it is detected that the quality of the link has degraded to an unacceptable degree BGP can take different mitigating and or notification actions. These actions can be made user configurable to modify different BGP path attributes like changing the local preference LP origin AS path communities logging alarming etc. The BGP path attribute modification should be done on a subset of prefixes doing it on all the prefixes would likely just move the problem to a different node. The number of such prefixes can again be made user configurable like a set percentage of prefixes learned or a fixed value similar to the throughput queue setting knobs in Class of Service CoS in the JUNOS operating system provided on routers from Juniper Networks of Sunnyvale Calif. . The selection of such prefixes itself can also be made user configurable e.g. choose the first or last 10 of the prefixes choose prefixes only in a particular subnet choose all prefixes except in subnet choose the prefixes randomly etc. .

In some example implementations the first autonomous system is an Internet service provider and wherein the second autonomous system is a customer of the Internet service provider. In other example implementations the peers are both Internet service providers.

Some example methods may further include generating the received information about dropped data packets at an output of the first edge device. Some example methods may generate the received information using an interface statistics counter. Other example methods may generate the received information using a management information base MIB of a simple network management protocol SNMP .

Referring back to block in some example methods the act of determining whether a data traffic offload condition exists using the received information includes determining whether A a measured dropped packet per time period value or B a measured dropped byte per time period value included in the received information exceeds a predetermined parameter. In some such example methods A the measured dropped packet per time period value or B the measured dropped byte per time period value may be taken from an output queue of the first edge device. In other such example methods A the measured dropped packet per time period value or B the measured dropped byte per time period value may be taken from an output interface of the first edge device.

In some example methods the at least some of the one or more of the IP address prefixes of the set consist of a predetermined number of the one or more IP address prefixes. In other example methods the at least some of the one or more of the IP address prefixes of the set consist of a predetermined percentage of the one or more IP address prefixes.

In some example methods the at least some of the one or more of the IP address prefixes of the set are selected randomly. In other example methods the at least some of the one or more of the IP address prefixes of the set are selected in accordance with a predefined heuristic. In such example methods the predefined heuristic may consider the amount of traffic destined or dropped for each of the IP address prefixes of the set.

The example method may be performed locally on the first edge device. In other example methods at least the act of changing one or more path attributes of at least some of the one or more of the IP address prefixes of the set responsive to a determination that a data traffic offload condition exists such that the first edge device will be less likely to forward data associated with the at least some of the one or more IP address prefixes of the set is performed by a centralized control unit external to the first edge device.

As just discussed above and referring to some example routers include a control component e.g. routing engine and a packet forwarding component e.g. a packet forwarding engine .

The control component may include an operating system OS kernel routing protocol process es label based forwarding protocol process es interface process es user interface e.g. command line interface process es and chassis process es and may store routing table s label forwarding information and forwarding e.g. route based and or label based table s . As shown the routing protocol process es may support routing protocols such as the routing information protocol RIP the intermediate system to intermediate system protocol IS IS the open shortest path first protocol OSPF the enhanced interior gateway routing protocol EIGRP and the boarder gateway protocol BGP and the label based forwarding protocol process es may support protocols such as BGP the label distribution protocol LDP and the resource reservation protocol RSVP . One or more components not shown may permit a user to interact with the user interface process es . Similarly one or more components not shown may permit an external device to interact with one or more of the router protocol process es the label based forwarding protocol process es the interface process es and the chassis process es via SNMP and such processes may send information to an external device via SNMP .

The packet forwarding component may include a microkernel interface process es distributed ASICs chassis process es and forwarding e.g. route based and or label based table s .

In the example router of the control component handles tasks such as performing routing protocols performing label based forwarding protocols control packet processing etc. which frees the packet forwarding component to forward received packets quickly. That is received control packets e.g. routing protocol packets and or label based forwarding protocol packets are not fully processed on the packet forwarding component itself but are passed to the control component thereby reducing the amount of work that the packet forwarding component has to do and freeing it to process packets to be forwarded efficiently. Thus the control component is primarily responsible for running routing protocols and or label based forwarding protocols maintaining the routing tables and or label forwarding information sending forwarding table updates to the packet forwarding component and performing system management. The example control component may handle routing protocol packets provide a management interface provide configuration management perform accounting and provide alarms. The processes and may be modular and may interact with the OS kernel . That is nearly all of the processes communicate directly with the OS kernel . Using modular software that cleanly separates processes from each other isolates problems of a given process so that such problems do not impact other processes that may be running. Additionally using modular software facilitates easier scaling.

Still referring to the example OS kernel may incorporate an application programming interface API system for external program calls and scripting capabilities. The control component may be based on an Intel PCI platform running the OS from flash memory with an alternate copy stored on the router s hard disk. The OS kernel is layered on the Intel PCI platform and establishes communication between the Intel PCI platform and processes of the control component . The OS kernel also ensures that the forwarding tables in use by the packet forwarding component are in sync with those in the control component . Thus in addition to providing the underlying infrastructure to control component software processes the OS kernel also provides a link between the control component and the packet forwarding component .

Referring to the routing protocol process es of this process es provides routing and routing control functions within the platform. In this example the RIP ISIS OSPF and EIGRP and BGP protocols are provided. Naturally other routing protocols may be provided in addition or alternatively. Similarly the label based forwarding protocol process es provides label forwarding and label control functions. In this example the LDP and RSVP and BGP protocols are provided. Naturally other label based forwarding protocols e.g. MPLS may be provided in addition or alternatively. In the example router the routing table s is produced by the routing protocol process es while the label forwarding information is produced by the label based forwarding protocol process es .

Still referring to the interface process es performs configuration of the physical interfaces Recall e.g. and of . and encapsulation.

The example control component may provide several ways to manage the router. For example it may provide a user interface process es which allows a system operator to interact with the system through configuration modifications and monitoring. The SNMP allows SNMP capable systems to communicate with the router platform. This also allows the platform to provide necessary SNMP information to external agents. For example the SNMP may permit management of the system from a network management station running software such as Hewlett Packard s Network Node Manager HP NNM through a framework such as Hewlett Packard s OpenView. Accounting of packets generally referred to as traffic statistics may be performed by the control component thereby avoiding slowing traffic forwarding by the packet forwarding component .

Although not shown the example router may provide for out of band management RS 232 DB9 ports for serial console and remote management access and tertiary storage using a removable PC card. Further although not shown a craft interface positioned on the front of the chassis provides an external view into the internal workings of the router. It can be used as a troubleshooting tool a monitoring tool or both. The craft interface may include LED indicators alarm indicators control component ports and or a display screen. Finally the craft interface may provides interaction with a command line interface CLI via a console port an auxiliary port and or a management Ethernet port

The packet forwarding component is responsible for properly outputting received packets as quickly as possible. If there is no entry in the forwarding table for a given destination or a given label and the packet forwarding component cannot perform forwarding by itself it may send the packets bound for that unknown destination off to the control component for processing. The example packet forwarding component is designed to perform Layer 2 and Layer 3 switching route lookups and rapid packet forwarding.

As shown in the example packet forwarding component has an embedded microkernel interface process es distributed ASICs and chassis process es and stores a forwarding e.g. route based and or label based table s . The microkernel interacts with the interface process es and the chassis process es to monitor and control these functions. The interface process es has direct communication with the OS kernel of the control component . This communication includes forwarding exception packets and control packets to the control component receiving packets to be forwarded receiving forwarding table updates providing information about the health of the packet forwarding component to the control component and permitting configuration of the interfaces from the user interface e.g. CLI process es of the control component . The stored forwarding table s is static until a new one is received from the control component . The interface process es uses the forwarding table s to look up next hop information. The interface process es also has direct communication with the distributed ASICs . Finally the chassis process es may communicate directly with the microkernel and with the distributed ASICs .

Referring back to distributed ASICs of is an example of how the ASICS may be distributed in the packet forwarding component to divide the responsibility of packet forwarding. As shown in the ASICs of the packet forwarding component may be distributed on physical interface cards PICs flexible PIC concentrators FPCs a midplane or backplane and a system control board s for switching and or forwarding . Switching fabric is also shown as a system switch board SSB or a switching and forwarding module SFM . Each of the PICs includes one or more PIC I O managers . Each of the FPCs includes one or more I O managers each with an associated memory . The midplane backplane includes buffer managers . Finally the system control board includes an internet processor and an instance of the forwarding table Recall e.g. of .

Still referring to the PICs contain the interface ports. Each PIC may be plugged into an FPC . Each individual PIC may contain an ASIC that handles media specific functions such as framing or encapsulation. Some example PICs provide SDH SONET ATM Gigabit Ethernet Fast Ethernet and or DS3 E3 interface ports.

An FPC can contain from one or more PICs and may carry the signals from the PICs to the midplane backplane as shown in .

The midplane backplane holds the line cards. The line cards may connect into the midplane backplane when inserted into the example router s chassis from the front. The control component e.g. routing engine may plug into the rear of the midplane backplane from the rear of the chassis. The midplane backplane may carry electrical or optical signals and power to each line card and to the control component .

The system control board may perform forwarding lookup. It may also communicate errors to the routing engine. Further it may also monitor the condition of the router based on information it receives from sensors. If an abnormal condition is detected the system control board may immediately notify the control component .

Referring to A and B in some exemplary routers each of the PICs contains at least one I O manager ASIC responsible for media specific tasks such as encapsulation. The packets pass through these I O ASICs on their way into and out of the router. The I O manager ASIC on the PIC is responsible for managing the connection to the I O manager ASIC on the FPC managing link layer framing and creating the bit stream performing cyclical redundancy checks CRCs and detecting link layer errors and generating alarms when appropriate. The FPC includes another I O manager ASIC . This ASIC takes the packets from the PICs and breaks them into e.g. 64 byte memory blocks. This FPC I O manager ASIC sends the blocks to a first distributed buffer manager DBM decoding encapsulation and protocol specific information counting packets and bytes for each logical circuit verifying packet integrity and applying class of service CoS rules to packets. At this point the packet is first written to memory. More specifically the example DBM ASIC manages and writes packets to the shared memory across all FPCs . In parallel the first DBM ASIC also extracts information on the destination of the packet and passes this forwarding related information to the Internet processor . The Internet processor performs the route lookup using the forwarding table and sends the information over to a second DBM ASIC . The Internet processor ASIC also collects exception packets i.e. those without a forwarding table entry and sends them to the control component . The second DBM ASIC then takes this information and the 64 byte blocks and forwards them to the I O manager ASIC of the egress FPC or multiple egress FPCs in the case of multicast for reassembly. Thus the DBM ASICs and are responsible for managing the packet memory distributed across all FPCs extracting forwarding related information from packets and instructing the FPC where to forward packets. 

The I O manager ASIC on the egress FPC may perform some value added services. In addition to incrementing time to live TTL values and re encapsulating the packet for handling by the PIC it can also apply class of service CoS rules. To do this it may queue a pointer to the packet in one of the available queues each having a share of link bandwidth before applying the rules to the packet. Queuing can be based on various rules. Thus the I O manager ASIC on the egress FPC may be responsible for receiving the blocks from the second DBM ASIC incrementing TTL values queuing a pointer to the packet if necessary before applying CoS rules re encapsulating the blocks and sending the encapsulated packets to the PIC I O manager ASIC .

Referring back to block the packet may be queued. Actually as stated earlier with reference to a pointer to the packet may be queued. The packet itself may remain in the shared memory. Thus all queuing decisions and CoS rules may be applied in the absence of the actual packet. When the pointer for the packet reaches the front of the line the I O manager ASIC may send a request for the packet to the second DBM ASIC . The DBM ASIC reads the blocks from shared memory and sends them to the I O manager ASIC on the FPC which then serializes the bits and sends them to the media specific ASIC of the egress interface. The I O manager ASIC on the egress PIC may apply the physical layer framing perform the CRC and send the bit stream out over the link.

Referring back to block of as well as regarding the transfer of control and exception packets the system control board handles nearly all exception packets. For example the system control board may pass exception packets to the control component .

Although example embodiments consistent with the present invention may be implemented on the example routers of or See especially the BGP routing protocol of . embodiments consistent with the present invention may be implemented on communications network nodes e.g. routers switches etc. having different architectures. More generally embodiments consistent with the present invention may be implemented on an example system as illustrated on .

In some embodiments consistent with the present invention the processors may be one or more microprocessors and or ASICs. The bus may include a system bus. The storage devices may include system memory such as read only memory ROM and or random access memory RAM . The storage devices may also include a hard disk drive for reading from and writing to a hard disk a magnetic disk drive for reading from or writing to a e.g. removable magnetic disk an optical disk drive for reading from or writing to a removable magneto optical disk such as a compact disk or other magneto optical media or solid state non volatile storage.

Some example embodiments consistent with the present invention may also be provided as a machine readable medium for storing the machine executable instructions. The machine readable medium may be non transitory and may include but is not limited to flash memory optical disks CD ROMs DVD ROMs RAMs EPROMs EEPROMs magnetic or optical cards or any other type of machine readable media suitable for storing electronic instructions. For example example embodiments consistent with the present invention may be downloaded as a computer program which may be transferred from a remote computer e.g. a server to a requesting computer e.g. a client by way of a communication link e.g. a modem or network connection and stored on a non transitory storage medium. The machine readable medium may also be referred to as a processor readable medium.

Example embodiments consistent with the present invention might be implemented in hardware such as one or more field programmable gate arrays FPGA s one or more integrated circuits such as ASICs one or more network processors etc. Alternatively or in addition embodiments consistent with the present invention might be implemented as stored program instructions executed by a processor. Such hardware and or software might be provided in an addressed data e.g. packet cell etc. forwarding device e.g. a switch a router etc. a laptop computer desktop computer a tablet computer a mobile phone or any device that has computing and networking capabilities.

Still referring to assume that the link between the primary GW and the customer edge device e.g. customer router experienced congestion and a sufficient number and or rate of data packets were being dropped at the output e.g. the output queue of the GW router such that a traffic offload condition was met. Recall YES branch of Condition . Under this scenario the GW router changes the local preference attributes of the first five IP address prefixes for the customer from 120 to 50. Although the first five or the first 50 of the IP address prefixes were selected for attribute change in this example other ways of determining the number of IP address prefixes to have their attributes changed and selecting which of the IP address prefixes are to have their attributes changed are possible. In fact as described above such determinations and selections may be user configurable for example. Also the amount by which these values are dropped is user configurable. The changed local preference attributes of the first five IP address prefixes for the customer are communicated to the other routers or gateway routers of the AS via iBGP. In this instance GW router communicates the changed attributes to at least GW router . If GW router uses the route with the highest BGP local preference it will select GW router for the first five IP address prefixes of customer since LP 100 LP 50 but will continue to select GW router for the last five IP address prefixes of the customer since LP 120 LP 100 . Although not shown if the link remains congested and the traffic offload condition is still met due to dropped packets the attributes of more of the IP address may be changed in one or more additional iterations of the method.

As can be appreciated from the foregoing example example embodiments consistent with the present invention can offload traffic from an egress GW router by properly configuring the egress GW router and using BGP protocol.

The foregoing example methods and apparatus can be implemented and extended in different ways. For example the drop sensitive BGP path attributes can be exchanged between GW routers as new BGP capabilities. As another example analytics on the traffic e.g. jflow provided by the JUNOS operating system used on Juniper routers may be used to determine the particular prefix es that is driving the most amount of traffic. The traffic can be more intelligently separated e.g. programmatically using such information. The two foregoing extensions may be used by an external Orchestration Control unit such as the Juniper control system JCS for example to make more holistic traffic optimizing decisions.

In at least some example embodiments consistent with the present invention the service provider is notified of a problem through a community string for the problem prefix. Assume for example that when the prefix is identified it is marked by a community string of 666 666 and is then re advertised by the router . Under this example embodiment the service provider will have a policy which translates this string 666 666 to a data overload problem in the network somewhere. The service provider can then find the origin of 666 666 and try to fix the problem manually. Here the advantage is the faster recognition of the problem and more reactive.

As should be appreciated from the foregoing example embodiments consistent with the present invention provide an improved solution to the problem of data packets dropped at an output e.g. egress of the first GW router or more generally a first edge device while the first link between the first GW router and the first eBGP peer device or more generally a first customer edge device of the second AS is still up and while an eBGP session between the first GW router and the first eBGP peer is still up. Such example embodiments avoid the need of a manually implemented reactive fix that is invoked only after the dropped data packets become very apparent to the customer.

Example embodiments consistent with the present invention can be implemented locally even on a single router. That is unlike protocols such as RSVP these example embodiments don t require the entire network or entire AS to have the same capabilities for support. Rather mechanisms supported by the existing BGP protocol are exploited. Similarly the example methods can be implemented without requiring two different networks to exchange any new attributes. Consequently it is possible for a single vendor to implement it independent of other vendors.

