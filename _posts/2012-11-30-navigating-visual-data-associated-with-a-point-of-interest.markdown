---

title: Navigating visual data associated with a point of interest
abstract: Systems and methods for navigating an imagery graph are provided. In some aspects, a first image is provided for display, where the first image corresponds to a first image node within an imagery graph, where the imagery graph comprises image nodes corresponding to images from a plurality of different imagery types, and where each image node in the imagery graph is associated with geospatial data. An indication of a selection of a predetermined region within the first image is received, where the predetermined region is associated with a position in the first image that corresponds to geospatial data associated a second image node within the imagery graph. A second image corresponding to the second image node is provided for display in response to the indication of the selection of the predetermined region.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08928666&OS=08928666&RS=08928666
owner: Google Inc.
number: 08928666
owner_city: Mountain View
owner_country: US
publication_date: 20121130
---
The present application claims the benefit of priority under 35 U.S.C. 119 from U.S. Provisional Patent Application Ser. No. 61 712 729 entitled NAVIGATING VISUAL DATA ASSOCIATED WITH A POINT OF INTEREST filed on Oct. 11 2012 the disclosure of which is hereby incorporated by reference in its entirety for all purposes.

The subject technology generally relates to visual data processing and in particular relates to navigating visual data associated with a point of interest.

Images of points of interest e.g. landmarks buildings or natural wonders are available on the Internet or in various data stores. The images may include different types of imagery e.g. street view panoramas aerial images satellite images user images from photograph sharing services or images from videos as well as different sets of imagery having the same type. However the different types of imagery of these points of interest are oftentimes separate and disjoint from one another. As a result an end user of a client computing device may be able to see multiple views of the point of interest via the client computing device but may have difficulty navigating between different imagery sets and understanding the images of a specific point of interest within different imagery sets e.g. street view images of the Empire State Building and user images of the Empire State Building are interrelated with one another in three dimensional space. As the foregoing illustrates a new approach for combining and navigating between multiple imagery sets including visual data associated with a specific point of interest may be desirable.

The disclosed subject matter relates to a computer implemented method for navigating an imagery graph. The method includes providing a first image for display where the first image corresponds to a first image node within an imagery graph where the imagery graph comprises image nodes corresponding to images from a plurality of different imagery types and where each image node in the imagery graph is associated with geospatial data. The method includes receiving an indication of a selection of a predetermined region within the first image where the predetermined region is associated with a position in the first image that corresponds to geospatial data associated a second image node within the imagery graph. The method includes providing a second image corresponding to the second image node for display in response to the indication of the selection of the predetermined region.

The disclosed subject matter further relates to a computer readable medium. The computer readable medium includes instructions that when executed by one or more computers cause the one or more computers to implement a method for providing an image for display. The instructions include code for providing a first image for display where the first image corresponds to a first image node within an imagery graph where the imagery graph comprises plural image nodes and where each image node in the imagery graph is associated with geospatial data. The instructions include code for receiving an indication of a selection of one or more pixels within the first image where the one or more pixels are associated with a position in the first image that corresponds to geospatial data associated a second image node within the imagery graph. The instructions include code for providing a second image corresponding to the second image node for display in response to the indication of the selection of the one or more pixels.

The disclosed subject matter further relates to a system. The system includes one or more processors. The system also includes a memory. The memory includes one or more data structures representing a unified imagery graph. The unified imagery graph includes image nodes corresponding to images from a plurality of different imagery types where each image node in the unified imagery graph is associated with a geographic location a viewpoint orientation and a field of view. The memory includes instructions. The instructions include code for providing a first image for display where the first image corresponds to a first image node within the unified imagery graph and where the first image has a first imagery type. The instructions include code for receiving an indication of a selection of a predetermined region within the first image where the predetermined region is associated with a position in the first image that corresponds to a geographic location a viewpoint orientation or a field of view associated a second image node within the unified imagery graph. The instructions include code for providing a second image corresponding to the second image node for display in response to the indication of the selection of the predetermined region where the second image has a second imagery type different from the first imagery type.

It is understood that other configurations of the subject technology will become readily apparent to those skilled in the art from the following detailed description wherein various configurations of the subject technology are shown and described by way of illustration. As will be realized the subject technology is capable of other and different configurations and its several details are capable of modification in various other respects all without departing from the scope of the subject technology. Accordingly the drawings and detailed description are to be regarded as illustrative in nature and not as restrictive.

The detailed description set forth below is intended as a description of various configurations of the subject technology and is not intended to represent the only configurations in which the subject technology may be practiced. The appended drawings are incorporated herein and constitute a part of the detailed description. The detailed description includes specific details for the purpose of providing a thorough understanding of the subject technology. However it will be apparent that the subject technology is not limited to the specific details set forth herein and may be practiced without these specific details. In some instances structures and components are shown in block diagram form in order to avoid obscuring the concepts of the subject technology.

The subject technology is related to navigating visual data associated with a point of interest. In one example implementation a server provides a first image of the point of interest for display at a client computing device. The first image corresponds to an image node within an imagery graph. The first image includes one or more points of interest e.g. the Capitol Building or the Washington Monument in Washington D.C. . The first image may be a member of a first imagery set e.g. street view images . The server receives an indication of a selection of a point of interest within the first image. For example the end user of the client computing device may click on one or more pixels on a point of interest e.g. on a wall of the Capitol Building . Responsive to the indication of the selection of the point of interest the server selects from image nodes associated with the point of interest within the imagery graph a second image node. The second image node may correspond to an image of the point of interest for example an image taken from a viewpoint corresponding to the location on the first image where the end user selected the point of interest e.g. the wall of the Capitol Building . The server provides the image corresponding to the second image node for display on the client computing device. The image corresponding to the second image node may be a member of a second imagery set e.g. user images from photograph sharing services different from the first imagery set.

In some aspects the imagery graph includes different types of images e.g. street view panoramas aerial images satellite images user images from photograph sharing services or images from videos from multiple imagery sets e.g. imagery sets having sources including for example public images within social networking services images within mapping services public images within photograph sharing services images from web based encyclopedias etc. . Each image within the imagery graph is associated with an image node. The image nodes are connected in the imagery graph based on geographic location data of the associated the image as well as pose information e.g. position orientation or field of view associated with the image. However pose information may not be available for some of the images in the imagery graph.

Advantageously in some implementations of the subject technology a user is able to more easily navigate and interact with visual data of a point of interest from multiple imagery sets e.g. street view panoramas aerial images satellite images user images from photograph sharing services or images from videos . The user navigation is based on the three dimensional characteristics of the point of interest such that the user is able to familiarize him herself with the three dimensional characteristics of the point of interest and how the three dimensional characteristics relate to images within the imagery sets.

The data store may store one or more imagery graphs that include images of one or more points of interest. The images may be from multiple imagery sets e.g. street view panoramas aerial images satellite images user images from photograph sharing services or images from videos . The data store may include a single machine multiple machines a single processor system or a multi processor system. One example of the data store is described in more detail in conjunction with below.

The server may include a module to navigate visual data associated with a point of interest that is stored within the data store or other sources. The server may be implemented as a single machine with a single processor a multi processor machine or a server farm including multiple machines with multiple processors. One example of the server is described in more detail in conjunction with below.

The client computing device may be a laptop computer a desktop computer a mobile phone a personal digital assistant PDA a tablet computer a netbook a television with one or more processors embedded therein or coupled thereto a physical machine or a virtual machine. The client computing device may include one or more of a keyboard a mouse a display or a touch screen. The client computing device may also include a web browser configured to display a webpage configured to navigate visual data associated with a point of interest or include a special purpose application e.g. a mobile phone application or tablet computer application for navigating visual data associated with a point of interest. While only one client computing device is illustrated in the subject technology may be implemented in conjunction with multiple client computing devices .

As shown the data store includes a processor a network interface and a memory . The processor is configured to execute computer instructions that are stored in a computer readable medium for example the memory . The processor may be a central processing unit CPU . While only one processor is illustrated the data store may include multiple processors. The network interface is configured to allow the data store to transmit and receive data in a network e.g. network of . The network interface may include one or more network interface cards NICs . The memory may store data or instructions. The memory may include a cache memory unit a storage memory unit or any other memory unit. As illustrated the memory includes a data structure representing an imagery graph .

While the imagery graph is illustrated as being represented in a unified imagery graph a single data structure including multiple components e.g. image nodes the imagery graph may alternatively be represented using multiple data structures each of which includes at least a portion of the data in the imagery graph . The imagery graph includes image nodes from multiple imagery sets . The imagery graph also includes representation of geospatial relationships between the images corresponding to the image nodes . The geospatial relationships are defined based on geographic location data of the associated the image as well as pose information e.g. position orientation or field of view associated with the image. However pose information may not be available for some of the images in the imagery graph . Each imagery set may include one or more image nodes . Example imagery sets include street view panoramas aerial images satellite images user images from photograph sharing services or images from videos. While imagery set . is illustrated as including one image node . and imagery set . is illustrated as including two image nodes . the subject technology may be implemented with imagery sets that include multiple image nodes for example 50 image nodes 500 image nodes or 5000 image nodes. Furthermore while only two imagery sets . are illustrated the subject technology may be implemented with any number of imagery sets. The imagery sets may include different types of images. For example one imagery set may include aerial images and satellite images while another imagery set may include street view panoramas and yet another imagery set may include user images from a photograph or video sharing service.

As set forth above a unified imagery graph may include among other things a single data structure that includes multiple components e.g. image nodes for representing images from multiple different image sets e.g. public images in a social networking service or another source images in a mapping service images in a web based encyclopedia etc. . The unified imagery graph may include the images within the data structure or the unified imagery graph may include links e.g. uniform resource indicators URIs or references to locations in memory to the images in the unified imagery graph. In some aspects a unified imagery graph is associated with a specific geographic location e.g. the White House in Washington D.C. and includes multiple images of the geographic location from multiple different image sets. The unified imagery graph includes nodes representing the images and edges representing connections between the images e.g. expanding or narrowing a viewing angle moving a camera position from one point to another etc. .

As set forth above the imagery graph e.g. the unified imagery graph can include public images from multiple sources for example social networking service s or photograph sharing service s . Images are not included in the imagery graph without receiving appropriate permissions from a user who uploaded the image to the network server or data repository. Visibility of an image may be controlled by the user who uploaded the image e.g. the user may restrict visibility to his her social contacts in the social networking service . Furthermore unless appropriate permissions are received from a person depicted in the image the face of the person in the image is blurred to protect his her privacy.

As illustrated each image node includes an image . The image may be for example a photograph taken by a camera an image derived based on a three dimensional model or a shot from a video. In some aspects the image is associated with a geographic location a viewpoint orientation and a field of view . In some aspects one or more of the geographic location the viewpoint orientation or the field of view for the image is unavailable. Images are organized in the imagery graph based on their geographic location s viewpoint orientation s or field s of view. The geographic location may be based on a geographic tag within the image. The geographic location may be represented as a latitude and longitude or as a street address. The geographic location may be coupled with an accuracy radius e.g. 100 meters . The geographic location may correspond to the precise two dimensional or three dimensional position of the optical center of the image. The viewpoint orientation may include a direction in which a viewpoint is directed. For example if a photograph is taken while the lens of a camera is turned north the viewpoint orientation may be north. The viewpoint orientation may be expressed as a direction e.g. southeast or as an angle e.g. 135 degrees east of north clockwise from north . The viewpoint orientation may have three angles pan tilt and yaw or one or more of these three angles. The field of view may be expressed as an angle covered by a camera e.g. an angle between a left or top edge of a photograph a camera lens and a right or bottom edge of a photograph. The field of view may be expressed as an angle e.g. 45 degrees or as multiple angles e.g. 30 degrees left to right and 105 degrees top to bottom . In some aspects the geographic location viewpoint orientation or field of view are obtained via computer vision techniques.

As shown the server includes a processor a network interface and a memory . The processor is configured to execute computer instructions that are stored in a computer readable medium for example the memory . The processor may be a central processing unit CPU . While only one processor is illustrated the server may include multiple processors. Furthermore while the server is illustrated as a single machine the server may include multiple machines e.g. within a server farm. The network interface is configured to allow the server to transmit and receive data in a network e.g. network of . The network interface may include one or more network interface cards NICs . The memory may store data or instructions. The memory may include a cache memory unit a storage memory unit or any other memory unit. As illustrated the memory includes a server side imagery provider module .

The server side imagery provider module is configured to navigate visual data associated with a point of interest. The server side imagery provider module includes instructions to provide a first image e.g. image . for display. The first image corresponds to an image node e.g. image node . within an imagery graph e.g. imagery graph . The first image may include one or more points of interest e.g. the Capitol Building and the Washington Monument . The server side imagery provider module also includes instructions to receive an indication of a selection of a predetermined region within the first image e.g. a mouse click on the predetermined region . The predetermined region is associated with a position in the first image that corresponds to geospatial data e.g. a geographic location a viewpoint position or a viewpoint orientation associated with a second image node. The server side imagery provider module also includes instructions to provide a second image e.g. image . corresponding to the second image node for display in response to the indicated selection of the predetermined region. While the server side imagery provider module is illustrated in as a single module the server side imagery provider module may also be implemented as multiple modules with each of the multiple modules being configured to carry out or provide for carrying out of all or a portion of the instructions described above.

In some aspects the server side imagery provider module is configured to interact with a client side imagery viewer module executing on the client computing device . For example the indication of the selection of the predetermined region may come from the client side imagery viewer module executing on the client computing device . The first image or the second image may be displayed via the client side imagery viewer module executing on the client computing device . The server side imagery provider module provides to the client side imagery viewer module image s along with navigation controls which allow a user of the client computing device to select and receive additional imagery from the data store via the server using the navigation controls. Example navigation controls are discussed below in conjunction with and . The client side imagery viewer module may be either a standalone application e.g. a mobile phone application a tablet computer application or an application executing on a laptop or desktop computer or a component of an application e.g. a component of a browser a browser application or a browser plug in .

The process begins at step where the server e.g. server by operation of the server side imagery provider module provides a first image for display on a client computing device e.g. client computing device . The first image e.g. image . corresponds to an image node e.g. image node . within an imagery graph e.g. imagery graph . The imagery graph includes images from multiple different image types e.g. photographs depth enhanced images panoramic images aerial images satellite images or video images and images from multiple different image sets e.g. public images in a social networking service images in a mapping service images in a web based encyclopedia etc. . Each The first image may include one or more points of interest. The imagery graph may include image nodes. Each image node in the imagery graph is associated with an image and geospatial data e.g. geographic location viewpoint orientation or field of view for the image node.

The imagery graph includes multiple image nodes. In some aspects each image node in the imagery graph includes a corresponding image and corresponding geographic location. The corresponding image is associated with a viewpoint position relative to a depicted point of interest a viewpoint orientation and a field of view. If an image includes a point of interest having a known geographic location e.g. the White House has a known geographic location which may be represented as a street address or a latitude and longitude and the image is associated with a geographic location e.g. a geographic location tag the viewpoint orientation may be determined by comparing the geographic location associated with the image and the known geographic location of the point of interest. For example if a photograph of the White House is taken from a geographic location that is known to be west of the White House it may be determined that the viewpoint orientation is facing east toward the White House. Alternatively the viewpoint orientation may be stored in association with the image e.g. in a tag coupled of the image . In some aspects the geographic location viewpoint orientation or field of view of image s in the imagery graph are obtained via computer vision techniques.

In step the server receives an indication of a selection of a region e.g. one or more pixels within the first image. For example the end user of the client computing device may click the mouse on pixels corresponding to the region or touch pixels corresponding to the region on a touch screen. The region could correspond to all or a portion of a point of interest e.g. a depiction of the Statue of Liberty in a photograph . The region could correspond to geospatial data in the image e.g. a point on the north side of the Statue of Liberty could correspond to viewing the Statue of Liberty from the north . The selected region could correspond to a click target. For example a first image corresponding to a front view of the White House may include a click target i.e. a region indicating that it can be selected at the right corresponding to moving to a right side view of the White House and a click target at the door corresponding to moving to an interior view of the White House. The click target could be represented by a three dimensional arrow or by dotted lines indicating that the region pointed to by the three dimensional arrow or within the dotted lines can be selected e.g. clicked with a mouse or touched on a touch screen by the user.

In some examples a click target may not initially be indicated at all. When a user hovers a cursor over the click target an indication of the click target e.g. the three dimensional arrow or the dotted lines may appear or the cursor may change shape e.g. becoming larger or becoming the three dimensional arrow to provide a notification to the user that a click target is available.

In step the server determines whether the selected region is associated with a position in the first image that corresponds to geospatial data associated with a second image node in the imagery graph. Such a position in the first image that corresponds to geospatial data associated with a second image may correspond to a click target. If so the process continues to step . If not the process returns to step .

In step the server provides a second image corresponding to the second image node for display in response to the selection of the region. The second image node is associated with the position of the selected region on the first image. For example if the selected region includes a portion of a point of interest the second image could be an image of the point of interest. If the selected region is on the east side of the point of interest the second image could be a view from the east of the point of interest. The second image may be of a different imagery type than the first image. For example the first image may be an aerial image and the second image may be a street view panorama. Alternatively the first image and the second image may be of the same imagery type.

In some aspects the click target is a user interface element for selecting a predetermined position on an image. For example a click target may represent an image node in the imagery graph that is selectable from an image that is currently displayed. A cursor may transform into a shape different form its usual shape e.g. into a three dimensional arrow or an arrow larger than a typical cursor arrow when placed over one of the click targets to communication information to the user that the cursor is hovering over a click target and that additional image s associated with the click target are available. Alternatively the cursor is not transformed when hovering over the click target and click target s are represented via fixed three dimensional arrow s or dotted lines for example as shown in .

In one example the first image corresponding to the first image node e.g. image node . is from a first imagery set e.g. . within the multiple imagery sets and the second image corresponding to the second image node e.g. image node . is from a second imagery set e.g. imagery set . within the multiple imagery sets. For example the first image may correspond to satellite image from a satellite imaging service and the second image may correspond to a screen shot from a video in a video sharing service. After step the process ends.

In one example aspect instructions for implementing the steps in the process may be stored in a memory of a computer and may be implemented by one or more computers. The steps in the process may be carried out in series. Alternatively two or more of the steps in the process may be carried out in parallel.

In one example aspect image A of may be presented to a user of a client computing device for example in response to a search for images of the Capitol Building images of the Washington Monument or images of landmarks in Washington D.C. Image A corresponds to an image node in an imagery graph e.g. imagery graph . Image A may be an aerial photograph. Image A may include two points of interest the Capitol Building A and the Washington Monument A. A user may select one of the points of interest A or A for example by using the cursor A. As shown in the user is in the process of selecting the Capitol Building A on one side e.g. the front side of the Capitol Building A using the cursor A which may be associated with a mouse. In an alternative implementation the user may select a point of interest A or A by touching the point of interest A or A with his her finger on a touch screen.

In response to the user s selection of the Capitol Building A on the one side of the Capitol Building A image B of may be presented to the user of the client computing device. The server may associate the user s selection of the Capitol Building A with an image node in the imagery graph corresponding to image B as image B is an image of the Capitol Building from a position corresponding to the position of the cursor A in the image A of . Image B may be a user photograph or a street view panorama. As shown image B includes a view of the Capitol Building B which corresponds to the Capitol Building A from the one side of the Capitol Building which was selected by the cursor A in image A of .

As shown the imagery graph indicates a position of a point of interest indicated with a star and a position of a street . The imagery graph also includes street view panoramas taken on the street and user photographs and of the point of interest . The street runs from east to west and the point of interest is positioned north of the street .

In one example aspect a user of a client computing device may be viewing the point of interest from a north facing street view panorama . While looking at the north facing street view panorama the user may become interested in what the point of interest looks like from the right east side. Accordingly the user may select a point on the right east side of the point of interest in the street view panorama . In response the server may provide the user photograph of the point of interest taken from the east side of the point of interest for display.

In another example aspect while viewing the north facing street view panorama of the point of interest the user may want to see a more detailed or zoomed in view of the point of interest . Accordingly the user may select a point on the point of interest about which he she wants more detail e.g. a door or window of a building a head of a statue etc. . In response the server may provide the user photograph of the point of interest which includes a more detailed or zoomed in view of the point of interest for display.

As shown image A includes click targets A and A. The click targets A and A are indicated by three dimensional arrows A and A respectively. The three dimensional arrows A or A may indicate a viewpoint orientation for an image to be displayed in response to the user selecting the click targets A or A respectively. For example if click target A is selected a bottom left wall of the building in image A may be displayed in greater detail. If click target A is selected a bottom right wall of the building in image A may be displayed in greater detail. The images presented responsive to selections the click targets A and A may be from different imagery types from one another and or from a different imagery type than image A. The imagery types may include photographs depth enhanced images panoramic images aerial images satellite images or video images. For example image A may correspond to an aerial photograph while images corresponding to the click targets A or A may be panoramic images or photographs. Furthermore the image A may be from a different imagery set than the images associated with the click targets A or A. The images associated with the click targets A and A may be from different imagery sets. Imagery sets may include public images from a social networking service images from a mapping service web based encyclopedia images etc. As shown in click targets are indicated by three dimensional arrows. However other graphics can be used in place of or in addition to the three dimensional arrows to indicate click targets.

Image B includes click targets B B and B indicated by three dimensional arrows B B and B respectively. The three dimensional arrows B B and B may indicate directions of motion from the image B to the images resulting from selecting the click targets B or B respectively. For example click target B indicated by forward pointing arrow B may correspond to moving forward. Click target B indicated by arrow B may correspond to moving forward and slightly to the left in the direction indicated by arrow B. Click target B indicated by right pointing arrow B may correspond to moving to the right. Image B may be a street view panorama images corresponding to the click targets B and B may be photographs and an image corresponding to click target B may be an aerial image.

Image C includes click target C and three dimensional arrow C. Click target C may correspond to a zoomed in view of the arc point of interest as indicated by arrow and the region C. Image C may be a street view panorama while an image corresponding to click target C may be a depth enhanced image.

Image D includes click target D and three dimensional arrow D. The three dimensional arrow D points into the building point of interest indicating that click target D corresponds to viewing the interior of the building point of interest. In order for the server to provide images of the interior of the building point of interest the owner and the occupant of the building have provided proper permissions for the server and data store to store such images and to provide such images to users of client computing devices. The image D may be a depth enhanced image while an image corresponding to click target D may be a photograph.

Image E includes a click target E for viewing a scene to the right of the scene in image E as indicated by the three dimensional arrow E and a click target E for viewing an avenue scene behind the scene in image E as indicated by the backward pointing three dimensional arrow E. Image E may be from a set of depth enhanced images while the images associated with the click targets E and E may be public photographs stored within a social networking service or street view panoramas stored within a mapping service.

Image F includes a scene within a room. Click target F is for viewing a scene in an adjacent room to the left as indicated by three dimensional arrow F. Click target F is for viewing a scene in an adjacent room to the right as indicated by three dimensional arrow F. Click target F is for viewing the ceiling of the room in greater detail as indicated by three dimensional arrow F. The image F may be from a different image set or a different image type from the images associated with the click targets F F and F.

The bus collectively represents all system peripheral and chipset buses that communicatively connect the numerous internal devices of the electronic system . For instance the bus communicatively connects the processing unit s with the read only memory the system memory and the permanent storage device .

From these various memory units the processing unit s retrieves instructions to execute and data to process in order to execute the processes of the subject technology. The processing unit s can be a single processor or a multi core processor in different implementations.

The read only memory ROM stores static data and instructions that are needed by the processing unit s and other modules of the electronic system. The permanent storage device on the other hand is a read and write memory device. This device is a non volatile memory unit that stores instructions and data even when the electronic system is off. Some implementations of the subject technology use a mass storage device for example a magnetic or optical disk and its corresponding disk drive as the permanent storage device .

Other implementations use a removable storage device for example a floppy disk flash drive and its corresponding disk drive as the permanent storage device . Like the permanent storage device the system memory is a read and write memory device. However unlike storage device the system memory is a volatile read and write memory such a random access memory. The system memory stores some of the instructions and data that the processor needs at runtime. In some implementations the processes of the subject technology are stored in the system memory the permanent storage device or the read only memory . For example the various memory units include instructions for navigating visual data associated with a point of interest in accordance with some implementations. From these various memory units the processing unit s retrieves instructions to execute and data to process in order to execute the processes of some implementations.

The bus also connects to the input and output device interfaces and . The input device interface enables the user to communicate information and select commands to the electronic system. Input devices used with input device interface include for example alphanumeric keyboards and pointing devices also called cursor control devices . Output device interfaces enables for example the display of images generated by the electronic system . Output devices used with output device interface include for example printers and display devices for example cathode ray tubes CRT or liquid crystal displays LCD . Some implementations include devices for example a touchscreen that functions as both input and output devices.

Finally as shown in bus also couples electronic system to a network not shown through a network interface . In this manner the electronic system can be a part of a network of computers for example a local area network LAN a wide area network WAN or an Intranet or a network of networks for example the Internet. Any or all components of electronic system can be used in conjunction with the subject technology.

The above described features and applications can be implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium also referred to as computer readable medium . When these instructions are executed by one or more processing unit s e.g. one or more processors cores of processors or other processing units they cause the processing unit s to perform the actions indicated in the instructions. Examples of computer readable media include but are not limited to CD ROMs flash drives RAM chips hard drives EPROMs etc. The computer readable media does not include carrier waves and electronic signals passing wirelessly or over wired connections.

In this specification the term software is meant to include firmware residing in read only memory or applications stored in magnetic storage or flash storage for example a solid state drive which can be read into memory for processing by a processor. Also in some implementations multiple software technologies can be implemented as sub parts of a larger program while remaining distinct software technologies. In some implementations multiple software technologies can also be implemented as separate programs. Finally any combination of separate programs that together implement a software technology described here is within the scope of the subject technology. In some implementations the software programs when installed to operate on one or more electronic systems define one or more specific machine implementations that execute and perform the operations of the software programs.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages declarative or procedural languages and it can be deployed in any form including as a stand alone program or as a module component subroutine object or other unit suitable for use in a computing environment. A computer program may but need not correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

These functions described above can be implemented in digital electronic circuitry in computer software firmware or hardware. The techniques can be implemented using one or more computer program products. Programmable processors and computers can be included in or packaged as mobile devices. The processes and logic flows can be performed by one or more programmable processors and by one or more programmable logic circuitry. General and special purpose computing devices and storage devices can be interconnected through communication networks.

Some implementations include electronic components for example microprocessors storage and memory that store computer program instructions in a machine readable or computer readable medium alternatively referred to as computer readable storage media machine readable media or machine readable storage media . Some examples of such computer readable media include RAM ROM read only compact discs CD ROM recordable compact discs CD R rewritable compact discs CD RW read only digital versatile discs e.g. DVD ROM dual layer DVD ROM a variety of recordable rewritable DVDs e.g. DVD RAM DVD RW DVD RW etc. flash memory e.g. SD cards mini SD cards micro SD cards etc. magnetic or solid state hard drives read only and recordable Blu Ray discs ultra density optical discs any other optical or magnetic media and floppy disks. The computer readable media can store a computer program that is executable by at least one processing unit and includes sets of instructions for performing various operations. Examples of computer programs or computer code include machine code for example is produced by a compiler and files including higher level code that are executed by a computer an electronic component or a microprocessor using an interpreter.

While the above discussion primarily refers to microprocessor or multi core processors that execute software some implementations are performed by one or more integrated circuits for example application specific integrated circuits ASICs or field programmable gate arrays FPGAs . In some implementations such integrated circuits execute instructions that are stored on the circuit itself.

As used in this specification and any claims of this application the terms computer server processor and memory all refer to electronic or other technological devices. These terms exclude people or groups of people. For the purposes of the specification the terms display or displaying means displaying on an electronic device. As used in this specification and any claims of this application the terms computer readable medium and computer readable media are entirely restricted to tangible physical objects that store information in a form that is readable by a computer. These terms exclude any wireless signals wired download signals and any other ephemeral signals.

To provide for interaction with a user implementations of the subject matter described in this specification can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s client device in response to requests received from the web browser.

The subject matter described in this specification can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN an inter network e.g. the Internet and peer to peer networks e.g. ad hoc peer to peer networks .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some aspects of the disclosed subject matter a server transmits data e.g. an HTML page to a client device e.g. for purposes of displaying data to and receiving user input from a user interacting with the client device . Data generated at the client device e.g. a result of the user interaction can be received from the client device at the server.

It is understood that any specific order or hierarchy of steps in the processes disclosed is an illustration of example approaches. Based upon design preferences it is understood that the specific order or hierarchy of steps in the processes may be rearranged or that all illustrated steps be performed. Some of the steps may be performed simultaneously. For example in certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components illustrated above should not be understood as requiring such separation and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

Various modifications to these aspects will be readily apparent and the generic principles defined herein may be applied to other aspects. Thus the claims are not intended to be limited to the aspects shown herein but is to be accorded the full scope consistent with the language claims where reference to an element in the singular is not intended to mean one and only one unless specifically so stated but rather one or more. Unless specifically stated otherwise the term some refers to one or more. Pronouns in the masculine e.g. his include the feminine and neuter gender e.g. her and its and vice versa. Headings and subheadings if any are used for convenience only and do not limit the subject technology.

A phrase for example an aspect does not imply that the aspect is essential to the subject technology or that the aspect applies to all configurations of the subject technology. A disclosure relating to an aspect may apply to all configurations or one or more configurations. A phrase for example an aspect may refer to one or more aspects and vice versa. A phrase for example a configuration does not imply that such configuration is essential to the subject technology or that such configuration applies to all configurations of the subject technology. A disclosure relating to a configuration may apply to all configurations or one or more configurations. A phrase for example a configuration may refer to one or more configurations and vice versa.

