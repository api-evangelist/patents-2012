---

title: Prioritization of continuous deployment pipeline tests
abstract: A method to prioritize a plurality of tests in a continuous deployment pipeline. The method ranks the plurality of tests based on a test attribute and a test context to provide a test rank for each of the plurality of tests. The method sets a test set for the continuous deployment pipeline using the test ranks. The method executes the test set in the continuous deployment pipeline.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09652509&OS=09652509&RS=09652509
owner: Hewlett Packard Enterprise Development LP
number: 09652509
owner_city: Houston
owner_country: US
publication_date: 20120430
---
Software development life cycles use continuous integration CI and continuous deployment CD to reduce the time code changes spend in a production line. Continuous integration automates the process of receiving code changes from a specific source configuration management SCM tool constructing deliverable assemblies with the code changes and testing the assemblies.

In the following detailed description reference is made to the accompanying drawings which form a part hereof and in which is illustrated by way of specific examples in which the present disclosure may be practiced. It is to be understood that other examples may be utilized and structural or logical changes may be made without departing from the scope of the present disclosure.

Continuous integration CI and continuous deployment CD automate the construction testing and deployment of code assemblies with a code change. Continuous integration automates the process of retrieving code changes from the SCM tool constructing deliverable assemblies such as executing a build and unit testing the assemblies. The automation begins after a code change is committed to a source configuration management SCM tool. When the code change is committed to the SCM tool the code change is assigned to a particular continuous deployment pipeline CD pipeline or deployment pipeline . The code change moves through the continuous deployment pipeline as the code change is tested as part of a code assembly.

Continuous deployment extends continuous integration by automatically deploying the assemblies into a test environment and executing testing on the assemblies. The amount of testing is determined by the continuous deployment pipeline. The test sets used for the continuous deployment pipelines are typically static test sets assigned based on the classification of the continuous deployment pipeline such as low priority or high priority. Typical test sets include unit tests and application programming interface tests. User interface automation tests are rarely included in the test sets due to the execution time being longer than unit tests and application programming interface tests. As a result the test sets lack a quality guarantee since the test sets do not include user interface tests. Moreover the test set may be manually set up to include the user interface tests however manual changes to test sets does not guarantee consistency and requires manual operations.

In examples a method to prioritize a plurality of tests in a continuous deployment pipeline is provided. The method ranks the plurality of tests based on a test attribute and a test context to provide a test rank for each of the plurality of tests. The method sets a test set for the continuous deployment pipeline using the test ranks. The method executes the test set in the continuous deployment pipeline.

The phrase code change refers to a change in the source code for any software application. The phrase code change may also refer to a code change that is part of a code assembly constructed as part of a continuous integration process.

The phrase continuous deployment pipeline or deployment pipeline refers to a set of actions executed serially and or in parallel on a queue of code changes. For example the continuous deployment pipeline may include building the code executing unit tests deploying the code running automated tests staging the code running end to end tests and deploying the code to production. Each continuous deployment pipeline may be classified to receive code changes that match a defined set of criteria for example a specific continuous deployment pipeline may be used for low risk and high priority code changes. The test set used to test the pipeline may similarly be aligned with the defined set of criteria for the code changes.

The phrase test set refers to the tests run on a continuous deployment pipeline in a simulated environment. The test set tests functionality and or identifies deficiencies of the application under test AUT . The test set may include unit tests to test integration of the code changes and or functional tests with the code change such as application programming interface API or user interface UI tests.

The phrase test context comprises at least one of a code change a business priority and a test value. The test value may include the ability of the test to detect defects the importance of defects found in a test and the dependency of the test on other tests.

The phrase test rank or test ranking refers to a ranking or value assigned to a test based on one or more criteria. The criteria may be defined based on codes changes test characteristics business priorities and or continuous deployment pipelines associated with the test from prior executions of the test set.

The client device represents a computing device and or a combination of computing devices configured to interact with the test device and the deployment device via the link . The interaction may include sending and or transmitting data on behalf of a user such as the code change. The interaction may also include receiving data such as a software application with the code changes. The client device may be for example a personal computing device which includes software that enables the user to create and or edit code for a software application.

The test device represents a computing device and or a combination of computing devices configured to prioritize a plurality of tests in a continuous deployment pipeline. The test device is also configured to excute a set of tests or test sets on the continuous deployment pipeline in an application under test environment to integrate the plurality of code changes for use in a software application.

The test set and or the code changes may be stored in the data store . The data store represents generally any memory configured to store data that can be accessed by the test device and the deployment device in the performance of its function. The test device functionalities may be accomplished via the link that connects the test device to the deployment device the client device and the data store .

The link represents generally one or more of a cable wireless fiber optic or remote connections via a telecommunication link an infrared link a radio frequency link or any other connectors or systems that provide electronic communication. The link may include at least in part an intranet the Internet or a combination of both. The link may also include intermediate proxies routers switches load balancers and the like.

The data store may store data accessible by the test device and or the deployment device . The data store is for example a database that stores a code change a test or plurality of tests a test ranking or test rank a test set a test attribute a test context a weighted value and a test result .

The test device is illustrated as including a test engine and a decision engine . The test device is connected to the deployment device which receives the code change from the client device . The code change is tested in the test device using the tests that have test rankings . The test device determines a set of tests or test sets to use in the continuous deployment pipeline during the testing.

The test engine represents generally a combination of hardware and or programming to execute the test set in a continuous deployment pipeline. The test engine receives an instruction and or the test sets from the decision engine to execute the test set .

The decision engine represents generally a combination of hardware and or programming that ranks the plurality of tests and sets a test set for the continuous deployment pipeline. The decision engine ranks the plurality of tests based on a test attribute and a test context to provide a test ranking for each of the plurality of tests . The decision engine also assigns the test attribute and the test context a weighted value . The weighted value is determined based on the continuous deployment pipeline associated therewith. The test attribute and test context are collected as data inputs from multiple sources and are compounded with a weighted value for each continuous deployment pipeline as performance of the tests are requested.

The test attribute comprises data associated with the plurality of tests and previous executions of the plurality of tests . Examples of test attributes include the following a test type such as a system function or performance test. The impact that the test type will have on the rank varies depend on the continuous deployment pipeline. For example a comprehensive continuous deployment pipeline may select a single test for each test type while a quick continuous deployment pipeline may exclude one or more types of tests such as a performance test. Another type of test attribute is the coverage of the application under test AUT areas. The coverage of the AUT areas that have a positive impact on test ranking or results in a higher test ranking when the test yields more coverage. Test fixing frequency is another test attribute . Test fixing frequency can have a negative impact on the test ranking as the more frequent a test needs to be fixed the less stable and less valuable the test . Another test attribute is test cost such as costs in resources for example CPU memory network and storage. The more the test costs in resources and or actual price such as for cloud based deployments the lower the test ranking . The last execution time of the test is another type of test attribute . For example the older the last execution time is the higher the test ranking . A final example of the test attribute is average execution time which may result in a test having a lower test ranking because it takes more time to execute and uses more time in the pipeline which may reduce the total number of tests executed.

The test context comprises at least one of a code change a business priority and a test value. The test value may include for example a value corresponding to the ability of test to detect defects the importance of defects the test finds and the dependency of tests on other tests . Examples of application lifecycle management test contexts are provided as follows. A test context includes a recent code change linked to the test via requirements and defects. The test context receives a higher test ranking when the test verifies a large number of code changes recently committed. Another test context is the average or sum of the business priorities linked to the test via the requirements. The higher the business priority the higher test ranking . Moreover the test context in this case may be used to filter out no critical business requires in specific business critical continuous deployment pipelines. Another test context is an assessment of the ability of the test to find a defect or the average number of defects found by the test per test execution. The more defects the test finds the higher the test ranking . Similarly the average severity and or importance of the defect found by the test also results in a higher test ranking . A final example of the test context is a test s dependency on other tests . For example a comprehensive continuous deployment pipeline may select inter dependent tests as test groups while quick continuous deployment pipelines may avoid inter dependent test to minimize executions and application under test deployments.

The decision engine also sets a test set for the continuous deployment pipeline using the test ranks . The decision engine sets the test set using at least one of the following criteria associated with the plurality of tests an execution time a business value and a comprehensiveness value. Additional criteria that may be used to determine the test ranking and or the test set as defined by the deployment device such as costs and resources. For each continuous deployment pipeline the test rank is computed for all the tests and weights may be associated with the test ranks based on the characteristics of the continuous deployment pipeline. The tests may then be classified and stored with test rankings and weighted values that are easily accessible by the decision engine when the continuous deployment pipeline is executing and the test set is requested by the test device and or the deployment device .

After the continuous deployment pipeline is established the decision engine sets the test set to meet the criteria of the specific continuous deployment pipeline being executed and provides the test set to the test engine . The test set may meet the criteria such as time cost and or application coverage level criteria of the specific continuous deployment pipeline which includes obtaining an optimized or maximal aggregate rank of the tests . In meeting the criteria the test set may not include a high ranking test test ranking in order to include a lower ranking test test ranking that provides an aggregate rank desired.

Furthermore the decision engine collects a test result from the executed test set . The test result including data corresponding to at least one of the test attribute and the test context . For example the test result may include new found defects and execution times for a test . The decision engine updates the test attribute and the test context based on a test result from the execution of the test set . Moreover the decision dynamically collects and automatically updates the test attribute and the test context based on execution of the test set . The test engine may simultaneously collect the test result while executing the test set . Simultaneous executing the test set and collection of the test results including the test attributes and test context data to determine the test rankings and weighted values may be performed based on the capabilities of the processor and or computing resources. Moreover the test rankings and weighted values may also be updated simultaneously with the execution of the test set .

The deployment device includes a deployment engine . The deployment engine represents generally a combination of hardware and or programming that deploys the code change after testing in an application under test environment. The deployment device deploys the tested code change via a deployment engine . The deployment engine may work together with the test engine and the decision engine to execute the test sets . Moreover the deployment engine controls a continuous deployment pipeline after the code assembly with the code changes pass the test sets .

The memory is illustrated to include an operating system and applications . The operating system represents a collection of programs that when executed by the processor serve as a platform on which applications may run. Examples of operating systems include various versions of Microsoft s Windows and Linux . Applications represent program instructions that when executed by the processor function as an application that prioritizes a plurality of tests in a continuous deployment pipeline. For example illustrates a test module and a decision module as executable program instructions stored in memory of the test device .

Referring back to the test engine and the decision engine are described as combinations of hardware and or programming. As illustrated in the hardware portions may include the processor . The programming portions may include the operating system applications and or combinations thereof. For example the test module represents program instructions that when executed by a processor cause the implementation of the of the test engine of . The decision module represents program instructions that when executed by a processor cause the implementation of the of the decision engine of .

The programming of the test module and decision module may be processor executable instructions stored on a memory that includes a tangible memory media and the hardware may include a processor to execute the instructions. The memory may store program instructions that when executed by the processor cause the processor to perform the program instructions. The memory may be integrated in the same device as the processor or it may be separate but accessible to that device and processor .

In some examples the program instructions may be part of an installation package that can be executed by the processor to perform a method using the system . The memory may be a portable medium such as a CD DVD or flash drive or a memory maintained by a server from which the installation package can be downloaded and installed. In some examples the program instructions may be part of an application or applications already installed on the server. In further examples the memory may include integrated memory such as a hard drive.

The deployment device receives a code change from a source configuration management SCM tool and business criteria from an application lifecycle management ALM tool . The business criteria refers to business factors that are used to assign code changes to a continuous deployment pipeline using for example filtering rules. The business criteria may correspond to data associated with the application being modified and or the code changes such as author of a code change number of lines of code in the code change and or number of files changed The deployment device assigns the code change to a continuous deployment pipeline such as CD pipeline A A or CD pipeline B B. For example CD pipeline A may be a high priority pipeline A for code changes that are determined by the deployment device to be tested and deployed quickly. Similarly CD pipeline B may be a normal or low priority pipeline. The deployment device provides a deploy to test instruction to the test device to initiate performance of the tests .

The test device uses the decision engine to ranks the plurality of tests and sets a test set for the continuous deployment pipeline . The decision engine uses a test attribute and a test context to rank the plurality of tests . The decision engine may use a variety of test attribute and test context data to rank the tests and determine the test set . Additional data that may be considered to determine the test rankings include for example the code change the plurality of tests the weighted value and the test results . The ranking of the tests for each pipeline and even each code assembly with codes changes are automated and may vary as the rank specific to the pipeline the application and the types of code changes . Moreover the test set may be determined by the decision engine to optimize the tests performed based on the test rankings .

After the test set is determined the test set is provided to the test engine which executes the test set in the continuous deployment pipeline in a simulated or AUT environment. For example CD pipeline A A uses test set A and CD pipeline B B uses test set B . Depending on the continuous deployment pipeline the test sets may be the same or distinct. The test set execution is illustrated in the perform tests portion of the continuous deployment pipeline . The code changes remain in the respective continuous deployment pipeline until the assembly with the code change passes the test set determined by the test device . The test results are sent to the decision engine either when all the testing is complete and or simultaneously during the testing. The Lest results may include test attribute and test context data that is dynamically and automatically collected and complied by the decision engine . The test results are then automatically used to determine future test rankings and test sets .

After the code changes pass the performance tests including the execution of the test set the deployment device may deploy the assembly with the code changes to production and or releases a software application with the code change .

The test set for the continuous deployment pipeline is set in block using the test ranks. The test attribute and the test context may also be assigned a weighted value. The weighted value is determined based on the continuous deployment pipeline associated therewith. Moreover the test attribute and the test context are dynamically collected and automatically updated based on execution of the test set.

In block the test set is executed in the continuous deployment pipeline. Based on the execution of the test set a test result is collected. The test result includes data corresponding to at least one of the test attribute and the test context. The test result may be simultaneously collected during the execution of the test set. The test result is then used to update the test attribute and the test context based on the test result from the execution of the test set.

Examples can be realized in any computer readable media for use by or in connection with an instruction execution system such as a computer processor based system or an ASIC Application Specific Integrated Circuit or other system that can fetch or obtain the logic from computer readable media and execute the instructions contained therein. Computer readable media can be any media that can contain store or maintain programs and data for use by or in connection with the instruction execution system. Computer readable media can comprise any one of many physical media such as for example electronic magnetic optical electromagnetic or semiconductor media. More specific examples of suitable computer readable media include but are not limited to a portable magnetic computer diskette such as floppy diskettes or hard drives a random access memory RAM a read only memory ROM an erasable programmable read only memory or a portable compact disc.

Although the flow diagrams of illustrate specific orders of execution the order of execution may differ from that which is illustrated. For example the order of execution of the blocks may be scrambled relative to the order shown. Also the blocks shown in succession may be executed concurrently or with partial concurrence. All such variations are within the scope of the present invention.

The present disclosure has been described using non limiting detailed descriptions of examples thereof and is not intended to limit the scope of the present disclosure. It should be understood that features and or operations described with respect to one example may be used with other examples and that not all examples of the present disclosure have all of the features and or operations illustrated in a particular figure or described with respect to one of the examples. Variations of examples described will occur to persons of the art. Furthermore the terms comprise include have and their conjugates shall mean when used in the present disclosure and or claims including but not necessarily limited to. 

It is noted that some of the above described examples may include structure acts or details of structures and acts that may not be essential to the present disclosure and are intended to be exemplary. Structure and acts described herein are replaceable by equivalents which perform the same function even if the structure or acts are different as known in the art. Therefore the scope of the present disclosure is limited only by the elements and limitations as used in the claims.

