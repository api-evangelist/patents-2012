---

title: Processor to message-based network interface using speculative techniques
abstract: Methods and systems are provided for a message network interface unit (a message interface unit), coupled to a processor, that is used for allowing the processor to send messages to a hardware unit. Methods and systems are also provided for a message interface unit, coupled to a processor, that is used for allowing a processor to receive messages from a hardware unit. The message network interface unit described herein may allow for the implementation data-intensive, real time applications, which require a substantially low message response latency and a substantially high message throughput.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09176912&OS=09176912&RS=09176912
owner: ALTERA CORPORATION
number: 09176912
owner_city: San Jose
owner_country: US
publication_date: 20120209
---
This application claims the benefit and priority to commonly assigned U.S. Provisional Patent Application No. 61 531 950 filed Sep. 7 2011 which is hereby incorporated by reference herein in its entirety.

This invention relates to integrated circuit devices and particularly to a such devices having a message network interface unit for high speed message passing.

As data intensive electronic devices and applications proliferate data rates continue to increase. To facilitate the use of devices such as programmable logic devices in certain data intensive real time applications hierarchical specialized processing blocks including lower level specialized processing blocks and a message passing communication structure are increasingly being used. A specialized processing block such as an intellectual property IP block is a block circuitry that may be separate from the general purpose programmable logic of a device on which it is implemented that is at least partially hardwired to perform a specific function. A specialized processing block e.g. an IP block that is at a lower hierarchical level in terms of the device communications structure than other specialized processing blocks or circuitry may be referred to as a lower level specialized processing block e.g. a lower level IP block . Lower level specialized processing blocks are best coordinated using software operating on a processor which communicates to these specialized processing blocks using a message network. For example a processor may read and write messages using a memory mapped protocol and messages may be transmitted to or from the lower level specialized processing blocks using a streaming packet based protocol. A very efficient interface may be used between the processor and the message network for use in data intensive real time applications.

Message passing networks have come into common use. Many existing message passing networks allow processors or processing blocks e.g. IP cores to send and receive messages in order to communicate with each other. For example network on a chip NoC designs have been created and used for communication between IP cores in a system on a chip SoC . There are also multiple existing interface designs for use between a processor and the message passing network that are used by the processor to communicate with specialized processing blocks. As an example of such an interface design PicaRISC DPX makes use of a FIFO based message passing mechanism. As another example of an interface design a processor embedded in a programmable device can send messages by writing the messages directly into the network during a bus write cycle. However these interface designs have drawbacks. In particular PicaRISC DPX tends to be inflexible because of the FIFO requirement and a design involving writing messages directly into the network tends to be inflexible because the messages need to be contiguously grouped.

Due to the inflexibility of existing message passing networks there is a need for a fast and efficient interface between a processor and the message passing network.

To address the above and other shortcomings within the art the present disclosure presents methods and systems for providing a fast and efficient interface between a processor and a message passing network. This interface reduces the latency of sending messages from a processor i.e. increases message throughput and the latency of acting on messages received from hardware units i.e. reduces message response latency .

The message interface reduces these latencies by speculatively creating messages in a scratchpad memory within transmit registers speculatively queuing the created messages in one or more queues and later making a decision as to whether or not to send any of the messages and or queues of messages.

In particular the interface reduces the number of processor clock cycles required to send a message because messages can be created during periods when the processor would otherwise be idle and well ahead of when they are to be sent. The transmit registers and scratchpad memory may be used as a template to allow the processor to create boiler plate messages and to customize them. An application programming interface API is provided to allow close to optimal consumption of processor clock cycles for message creation i.e. creation of a message at a rate close to 1 message word per processor cycle . One or more queues are used to speculatively queue the created messages.

In addition the interface described herein reduces the latency of receiving messages and acting on messages received by having one or more individually addressed queues to queue incoming messages. The queues may be associated with a priority level. The priority level may be used to determine in which order to process the messages among the messages in different queues. For example a message from a queue with the highest priority level may be processed ahead of a message from a queue with a lower priority level. The message network interface described herein may allow for the implementation data intensive real time applications which requires a substantially low message response latency and a substantially high message throughput.

Methods and systems are provided for a message network interface unit i.e. a message interface unit coupled to a processor that is used for allowing the processor to send messages to a hardware unit. In an embodiment the message interface unit includes transmit registers. The transmit registers which include a scratchpad memory store arguments of at least one of the messages which are speculatively created by the processor. One or more queues are coupled to the transmit registers. The one or more queues may be used to queue the messages. An action may be taken on the one or more queues in response to receiving at the message interface unit a message indicating the action to be taken. The action that may be taken on one or more queues includes discarding all of the content in one of the queues in response to receiving a message that indicates that an exception occurred. The action that may be taken on one or more queues includes sending each of the messages stored in one of the queues. In some embodiments the message interface unit and the processor are located on the same device. Examples of devices include a programmable logic device an integrated circuit device or other device. In some embodiments the message interface unit is used by a video scalar.

Methods and systems are also provided for a message interface unit coupled to a processor and used for allowing the processor to receive messages from a hardware unit. In an embodiment the message interface unit includes one or more queues that may be used to queue the messages. Each of the one or more queues may be assigned a unique address that indicates a priority level for that queue. The unique address is used as a destination address in messages sent by the hardware unit to either the processor or the message interface unit. Receive registers are coupled to the one or more queues. The receive registers are used to store arguments of one or more of the messages. In some embodiments the receive registers are used to store the arguments of a message in a queue that currently has the highest priority level and this message is processed by the processor prior to messages in other queues for example in queues with a lower priority level. In some embodiments the message interface unit and the processor are located on the same device such as for example a programmable logic device.

To provide an overall understanding of the invention certain illustrative embodiments will now be described. However it will be understood by one of ordinary skill in the art that the systems and methods described herein may be adapted and modified as is appropriate for the application being addresses and that the systems and methods described herein may be employed in other suitable applications and that such other additions and modifications will not depart from the scope hereof.

Video upscaling may be performed using four of the hardware pipelines of system . Each of the hardware pipelines may include four hardware units in order a clipper a line buffer a scalar and another clipper and each of the pipelines may operate on one quarter of the incoming video. Software operating on processor may control each of hardware pipelines to process the incoming video by sending messages using message interface unit . In particular processor may instruct message interface unit to send messages to one of more of the hardware units in hardware pipelines . The software operating on processor may be able to dynamically adapt any of the hardware pipelines to any particular type of incoming video stream by changing the type of messages sent via message interface unit to the hardware units in hardware pipelines . This way of dynamically adapting hardware pipelines may allow the pipelines to support multiple configurations and types of input and output video formats without complex hardware control. For example hardware pipelines may be able to support the output of one 4K video stream four 1080p60 video streams or four 720p60 video streams.

In operation 1080p60 video may be input one line of a frame at a time to CVI unit which may process and send this information to VIB unit . VIB unit may packetize and output this information to packet switch which may output this information to message interface unit and to kernel creator . Message interface unit may notify processor of the incoming line of the frame of video by sending processor one or more messages. Processor may also be notified of the incoming line of the frame of video.

Processor may receive messages corresponding to the incoming lines and frames of video and may process each of these messages. In particular for 1080p60 video each of the 60 incoming frames per second may in effect cause processor to receive one message indicating the width and height of the frame. Each input active line of video of the incoming active lines may in effect cause processor to receive two messages one message indicating the start of the line and another message indicating the end of line. Each input active line of video may also in effect cause processor to receive two additional messages from kernel creator via packet switch that contain the required coefficients calculated by the kernel creator for upscaling the input active line of video in order to generate two lines of output video. Each of the preceding messages may be received by processor via message interface unit communicating to the processor.

Using message interface unit processor may also send messages based on the frames and lines of incoming video to be upscaled. Each input frame may cause processor to send six messages two messages to kernel creator and four messages to each of the line buffers in hardware pipelines . In addition each input active line of video may cause processor to send 52 messages for example to various components in each of the four hardware pipelines via packet switch . Message interface unit may send each of these messages on behalf of processor .

VIB unit may receive messages sent by message interface unit and or kernel creator via packet switch . VIB unit may duplicate video data in these messages and forward the messages to packet switch which may forward the messages to various components of hardware pipelines . Each of hardware pipelines which operates on the active lines and frames of incoming video contain a clipper that may clip a portion of each active line of video it receives a line buffer to buffer multiple incoming clipped active lines of video a scalar that scales the buffered and clipped active lines of video from the buffer and a clipper to clip the scaled buffered and clipped video. As discussed above each of these hardware units in hardware pipelines may be controlled using control messages that are sent forwarded by processor and or message interface unit . After being processed by hardware pipelines the resulting video may be sent to packet writers to be written to DDR3 memory block . The use of DDR3 memory block is exemplary and not intended to limit the scope of the present invention. Other types of memory for example any type of random access memory read only memory or flash memory may be used instead or in combination with DDR3 memory block . The resulting video can be read out of DDR3 memory block at some later time by frame readers which may each forward the video that it reads to one of the CVO units to be output from scalar . Frame readers may each be separately controlled using control messages that are sent forwarded by processor and or by message interface unit .

In order to upscale 1080p60 video to be 4K video a total of 60 1 1080 60 4 259260 messages may be received by the processor every second and a total of 60 6 1080 60 52 3369960 messages may be sent every second. Therefore in this exemplary embodiment a total of 259260 3369960 3.6 million messages may either be received or sent every second. Therefore in this example upscaling may require a throughput of 3.6 million messages per second.

Message response latency may be defined as the elapsed time between a processor receiving a message until the processor has completed taking appropriate action which could for example include sending out the appropriate message s in response. The upscaling 1080p60 video to 4K video may require low message response latency. For real time applications such as for example upscaling 1080p60 video to 4K video message response latency may be a substantial factor in the overall latency in the completion of tasks. Thus upscaling video may not only require a combined throughput of 3.6 million messages to be sent or received every second but it may also require a substantially low message response latency.

Processor may create messages and store these messages in shared memory . For example shows seven messages that were created and stored by processor in shared memory . Processor may create a DMA transfer description which refers to the messages in shared memory that processor wants to transmit. Processor may then instruct the DMA controller to send these messages by transferring the messages to one or more hardware units using memory mapped to message format bridge . Memory mapped to message format bridge may packetize the messages and transfer the messages to the appropriate hardware unit s . Although the message interface unit solution shown in is a fully functional message interface unit solution it may not be able to meet the substantially high throughput requirements of certain data intensive real time applications. In particular in the solution shown in processor may need to manage access to shared memory to avoid overwriting messages that are being sent transferred leading to inefficient use of the processor. In addition this solution may require processor to create a DMA transfer description for DMA controller for each message transfer leading to inefficient use of the processor. Moreover sending the same message multiple times or with minimal changes to the message using the solution shown in may be inefficient for processor because the solution requires processor synchronization with DMA controller . These inefficiencies for the processor may reduce message throughput when using the solution shown in .

The message interface unit solution in may also have too high of a message response latency for the proper operation of some data intensive real time applications when messages are received by the processor. In particular in this solution processor is required to instruct DMA controller to copy any incoming message to shared memory leading to the inefficient use of clock cycles for processor . In addition in this solution DMA controller interrupts processor when the controller has finished copying any incoming message to shared memory . Processor is then required to read the message and take appropriate action. The extra steps required for processor to take appropriate action for an incoming message lead to additional inefficiencies due to wasted clock cycles for processor . Thus receiving a message using message interface unit of the solution shown in leads to processor inefficiencies which may increase message response latency beyond the requirements for certain data intensive real time applications.

Message interface unit may allow processor to send and to receive messages. Message interface unit may allow processor to send and to receive messages at a sufficiently high throughput and sufficiently low message response latency to support data intensive real time applications such as for example upscaling 1080p60 video to 4K video described above. In some embodiments message interface unit may be included on the same device as processor . In some embodiments message interface unit is a separate device i.e. peripheral from processor . In some embodiments message interface unit is a memory mapped peripheral that can be attached to any processor. Message interface unit may be similar to message interface unit of and may be used with video scalar of .

Message interface unit may include transmit registers which include several reserved registers not shown space available register send queue register free queue register header register and argument registers . Argument registers may also be referred to as a scratchpad memory. Processor may read from or write to transmit registers by communicating with message interface unit . In some embodiments transmit registers may be coupled to one or more queues which may each be used to queue and send messages e.g. messages created by the processor . In some embodiments transmit registers may be used to send messages without first queuing the messages. In one embodiment the addresses of transmit registers and the description with regards to what occurs when processor either writes to or reads from each of these registers is shown in Table 1.

Processor may achieve a sufficiently high throughput for sending messages for data intensive real time applications using message interface unit . In particular argument registers i.e. the scratchpad memory may be accessed by processor to speculatively create messages that may later be sent. Processor may be able to create and send messages at a high rate by making use of the scratchpad memory. Message interface unit may control any access to the scratchpad memory and stall processor if it attempts to write to an argument register that is currently being sent e.g. as a part of a previous message . Otherwise message interface unit may allow processor to write to an argument register during each clock cycle in preparation to send a message. The processor may send identical or similar messages efficiently because only the argument registers corresponding to argument values that change need to be written prior to a message being sent. Once processor writes to header register a message that includes the arguments in the scratchpad memory may either be sent or queued in one of queues . In this way processor together with message interface unit may speculatively create and queue messages to be sent in the event that message interface unit and or processor receive particular messages. Speculative message creation and queuing will be discussed in greater detail below.

Examples of software code that could be used by a processor such as processor to send a message or to discard any of the contents of a queue are shown below. In the example code the macros that are used are described within Appendix A incorporated herein.

Processor may use argument registers i.e. the scratchpad memory in message interface unit to speculatively create messages. Processor may write to header register to send a message that the processor created either to a device or to one of queues . Processor may use a minimal number of clock cycles to send a message. In particular the number of clock cycles to send a message may be equal to N writes to write to the N argument registers where N is the number of arguments 1 write to write to header register . In addition a message may be sent without interrupting processor i.e. automatically sent by message interface unit without involvement from processor . In some embodiments argument registers may retain their values so that a subsequent identical message can be sent with only one write to header register . Processor may perform repeated writes to header register to send the same message repeatedly.

When sending a message arguments stored in argument registers may be read and sent forwarded sequentially to allow processor to update write to the arguments registers for arguments that have already been sent forwarded. In order to create a new message rapidly processor may write to any one of argument registers during the clock cycle immediately following the clock cycle during which the argument in that register had been sent forwarded. Thus at the start of the clock cycle following a write to header register message interface unit may allow processor to write to the arg0 argument register after previously stored argument arg0 has been sent forwarded . During the subsequent clock cycle message interface unit may allow processor to write to the arg1 argument register in the following clock cycle to the arg2 argument register and so on.

The transmission databus which is used to send forward messages from transmit registers to queues or to other devices may be a multiple of one argument s width. This may allow multiple arguments to be sent at once on the databus and it may also allow messages to be created and sent forwarded into the system or a queue without stalling processor . This may lead to improved efficiency for processor .

As discussed above a message may be placed in one of queues instead of being sent into the system or directly to a hardware unit. All the messages in any one of queues may be discarded with a single write by processor to free queue register . All the messages in any one of queues may be sent with a single write by processor to send queue register . In particular processor may speculatively create and queue a message into one of queues . Such speculative message creation and queuing may be performed by the processor in anticipation of expected events that may occur e.g. an expectation that an incoming message with a new line of video to be upscaled will arrive in the future . Messages may be created as described above and queued speculatively during clock cycles during which the processor is idle e.g. messages to be sent by the processor in response to receiving a new line of video may be speculatively created using transmit registers and queued using queues . This type of speculative message creation and queuing may allow message interface unit to achieve a high message throughput because several messages may be speculatively queued and sent rapidly in response to an expected message arriving. In addition this type of speculative message creation and queuing may allow message interface unit to achieve a low message response latency by avoiding the use of additional cycles to create messages in response to an expected message arriving. To reduce latency further message interface unit may be configured to automatically send or discard any or all of the messages in one of queues when triggered by a particular message also referred to as a triggering message thereby freeing additional clock cycles from processor to potentially perform other tasks.

As described above one or more queues may be used to queue message speculatively. Message interface unit acting on behalf of processor or independently may take action in response to a particular message being received by message interface unit or processor . The action taken by message interface unit allows for it to send or discard any message in one of the queues or all of the messages contained within one or more of queues in response to a particular message being received by message interface unit or processor . For example processor and or message interface unit may discard all of the messages in one of queues when it receives a message indicating that an exception occurred. Message interface unit may include configurable triggers not shown that allow any or all of the messages contained within any of queues to be sent or discarded automatically on receipt of a message i.e. a triggering message . These triggers may effectively allow message interface unit to act on the receipt of a message a triggering message without the involvement of processor thereby reducing the burden on processor . In some embodiments the configurable triggers may be hardwired or programmed in hardware units within message interface unit . In some embodiments the configurable triggers may be based in software operating on message interface unit .

Message interface unit may include receive registers which include several reserved registers not shown select queue register fill level register get message register header register and argument registers . Processor may read from or write to transmit registers via message interface unit . In one embodiment the addresses of receive registers and the description with regards to what occurs when processor either writes to or reads from each of these registers is shown in Table 2.

Examples of software code that could be used by a processor such as processor to receive a message is shown below. In the example code the macros that are used are described within Appendix B incorporated herein.

Messages may be loaded into argument registers from one or more of queues when processor performs a write operation to get message register . Processor may use a minimal number of clock cycles to load receive a message. In particular the number of clock cycles to load receive a message may be equal to 1 write to write to get message register 1 read to read from header register N reads to read from the N argument registers where N is the number of arguments . In addition in some embodiments a message may be loaded received without interrupting processor i.e. automatically loaded received by message interface unit .

When loading receiving a message argument registers may be written to and read from sequentially to allow processor to read arguments from the arguments registers that have already been written e.g. via one of queues and have recently become available. In order to load a new message rapidly processor may read from any one of argument registers during the clock cycle immediately following the clock cycle during which the argument in that register had been written to via for example one of queues . Thus at the start of the clock cycle following a write to get message register message interface unit may allow processor to read the arg0 argument register one clock cycle after argument arg0 has been written to via for example one of queues . During the subsequent clock cycle message interface unit may allow processor to read from the arg1 argument register in the following clock cycle from the arg2 argument register and so on.

The receive databus which is used to load receive messages from queues to receive registers may be a multiple of one argument s width. This may allow multiple arguments to be loaded received at once on the databus and it may also allow messages to be loaded received and read without stalling processor . This may lead to improved efficiency for processor .

Messages sent to processor or message interface unit may be placed in one of queues . Each of one or more queues may have a different unique destination address to allow each of the hardware units to be able to send its message to the appropriate queue. Because processor may be able to receive messages from any one of queues this use of dedicated queuing allows particular messages to jump ahead and be processed earlier than other messages. Moreover such use of dedicated queuing allows the system to queue messages according to different priorities. This may be accomplished by assigning a different priority level to each of queues . In such a scheme the address assigned to each queue may be indicative of and or associated with the particular priority level.

System could be used in a wide variety of applications such as computer networking data networking instrumentation video processing digital signal processing or any other application where the advantage of using programmable or reprogrammable logic is desirable. IC can be used to perform a variety of different logic functions. For example IC can be configured as a processor or controller that works in cooperation with processor . IC may also be used as an arbiter for arbitrating access to a shared resource in system . In yet another example IC can be configured as an interface between processor and one of the other components in system or another device or hardware unit outside of system . It should be noted that system is only exemplary and that the true scope and spirit of the invention should be indicated by the following claims.

It will be understood that the foregoing are only illustrative of the principles of the invention and that various modifications can be made by those skilled in the art without departing from the scope and spirit of the invention. For example message interface unit of may be similar to message interface unit of . In addition message interface unit may be used interchangeably with message interface unit . One skilled in the art will appreciate that the present invention can be practiced by other than the described embodiments which are presented for purposes of illustration and not of limitation and the present invention is limited only by the claims that follow.

