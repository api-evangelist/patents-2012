---

title: Deduplication architecture
abstract: A receiver-side deduplication architecture for data storage systems, for example remote data storage systems that use block-based data storage and that provide the data storage to client(s) via a network. The architecture may provide network deduplication by reducing bandwidth usage on communications channel(s) between the client(s) and the data storage systems. The architecture may leverage block storage technology of a data store provided to clients by a data store provider and caching technology to implement a deduplication data dictionary. The deduplication data dictionary includes deduplication data blocks stored in the data store and a mapping tier that leverages caching technology to store and maintain a store of key/value pairs that map data block fingerprints to deduplication data blocks in the data store.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09298723&OS=09298723&RS=09298723
owner: Amazon Technologies, Inc.
number: 09298723
owner_city: Reno
owner_country: US
publication_date: 20120919
---
In many data systems broadly viewed a sender a data source uploads data to a receiver a data processor via a communications channel. An example of such a system is a data storage system however these data systems may include any system in which a receiver somehow processes data uploaded from a sender. The uploaded and processed data may include but is not limited to any type of textual graphical or image data audio data e.g. music and voice data video data compressed and or encrypted data and so on. In many such systems large amounts of data may need to be uploaded from the sender to the receiver via the communications channel. However communications channels generally have bandwidth constraints while a goal of such data systems is to get as much usable data across the communications channel to the receiver as possible.

Data deduplication refers to techniques for reducing or eliminating redundant data in such systems for example to improve storage utilization in a data storage system referred to as data deduplication and or to reduce bandwidth usage on the communications channel referred to as network data deduplication or simply network deduplication . As an example in at least some data deduplication techniques applied to data storage systems the storage of duplicate data to a data store may be prevented. To achieve this units of data that already reside in the data store and or units of data that do not reside in the data store may be identified and only the units that do not reside in the data store are stored or updated in the data store. Data deduplication in this application may thus reduce required storage capacity since fewer or only one copy of a particular unit of data is retained.

While embodiments are described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that embodiments are not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the claims. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

Various embodiments of methods and apparatus for receiver side deduplication are described. Embodiments of a receiver side deduplication architecture and deduplication techniques are described that may be applied in data storage systems to provide network deduplication by reducing bandwidth usage on the communications channel s between data sender s and the receiver the data store provider . While primarily directed to network deduplication rather than data deduplication some embodiments may also improve storage utilization in the data storage system by reducing the amount of data that is actually stored. For example embodiments may be applied in remote data storage systems that use block based data storage and that provide the data storage to client s as primary or backend storage.

In receiver side deduplication rather than the sender maintaining a fingerprint dictionary and determining data units to be uploaded to the receiver the receiver maintains the fingerprint dictionary. When a sender has data to be uploaded the sender extracts fingerprints e.g. hashes for the data and sends only the fingerprints to the receiver. The receiver checks its fingerprint dictionary to determine the data units to be uploaded to the receiver and notifies the sender which then sends only the identified units of data to the receiver. Receiver side deduplication thus reduces the bandwidth used in uploading data from the sender to the receiver as only the units that are not present in the data store according to the fingerprint dictionary are uploaded. Receiver side deduplication removes or reduces the requirement for the sender to maintain a large fingerprint dictionary and centralizes deduplication at the receiver thus allowing deduplication to be applied across data stored for multiple data sources.

However conventional receiver side deduplication architectures typically employ dedicated temporary storage separate from the primary data store in which clients data is stored to maintain a backing store for deduplication data.

In embodiments of the receiver side deduplication architecture and technique describe herein instead of using separate dedicated storage to maintain a backing store for deduplication data the block storage technology of the data store provided by the data store provider and standard or commodity caching technology e.g. Memcached technology may be leveraged to implement a deduplication data dictionary.

The following describes embodiments of the receiver side deduplication architecture as well as receiver side data deduplication techniques including techniques that may be used to manage the components of the deduplication data dictionary. Embodiments of the receiver side deduplication architecture and techniques may for example be implemented in the context of a service provider that provides remote data storage to clients via a network. For example the service provider may provide access to the deduplication techniques to its clients that store data to the remote data storage via a deduplication Web service and Web service interface. An example implementation of the receiver side deduplication architecture and techniques in the context of a service provider that provides remote data storage to clients via a storage service and a gateway appliance is described.

While embodiments of the receiver side deduplication architecture and technique are generally described herein in reference to data storage system applications the architecture and technique may be applied in any system in which a receiver receives data uploaded from a sender. The uploaded and processed data may include but is not limited to any type of textual graphical or image data audio data e.g. music or voice data video data compressed and or encrypted data and so on. In addition while embodiments are generally described herein in terms of a sender and a receiver that are remotely located and communicate via a wired and or wireless network such as the Internet the data deduplication technique may also be applied in applications where the sender and receiver are local devices that communicate for example via a wired or wireless local network or direct link as well as applications where the sender and receiver are hardware and or software components within a single device or system that communicate via an internal communications channel such as a data bus direct data link shared memory transfer or wireless communications channel.

Data plane may comprise one or more network devices e.g. servers or host systems that implement data store process es that may provide an interface between the client s e.g. via sender data upload process es on the sender side and the data store and that may provide management logic e.g. volume based storage data I O garbage collection backup mirroring etc. for the data store . One or more receiver side deduplication processes of the deduplication architecture and technique may be implemented on the data plane . Note that data store processes and receiver side deduplication processes may be implemented on the same servers or host systems or on different servers or host systems. In at least some embodiments receiver may provide one or more interfaces for example Web services interfaces or APIs via which a sender may access functionality provided by the data plane including but not limited to the receiver side deduplication functionality described herein.

Rather than using separate dedicated storage to maintain a backing store for deduplication data units in the deduplication data dictionary embodiments of the deduplication architecture and technique may leverage block storage technology of the data store provided by the data store provider and caching technology to implement a deduplication data dictionary . The deduplication data dictionary includes the data store that stores data units data blocks stored in chunks and a mapping tier that leverages the caching technology to store and maintain key value pairs that map data block fingerprints e.g. hashes to deduplication data units data blocks in the data store . A chunk may be defined as a collection of data blocks. Each data block thus represents a fraction of a chunk in the data store . As a non limiting example chunk size may be 4 megabytes mB and data block size may be 4 kilobytes kB . In this example there are 1 k 1000 data blocks per chunk . However other chunk sizes and or data block sizes may be used. The fingerprints e.g. hashes may uniquely identify the data units in the data storage system. In at least some embodiments a fingerprint may be any type of cryptographically strong one way hash function for example a Secure Hash Algorithm SHA 256 hash function. The use of a cryptographically strong one way hash function may provide security and may help to avoid collisions as collisions using such a hash function are highly unlikely. A collision is when two units of data produce the same fingerprint. However in some embodiments fingerprints may be generated according to any hashing technique or other techniques than hashing may be used to generate fingerprints.

As noted the data units stored in the data store e.g. chunks are used as the backing data store for the deduplication functionality. Advantages to using the chunks in the data store directly as the deduplication data store over using a separate dedicated storage may include but are not limited to 

Note that the data store is not the deduplication data store instead the data units chunks of the data store are leveraged to implement the deduplication data store. In other words the deduplication data store is maintained within the data store by using locations in the chunks as storage locations for deduplication data blocks . Note that data that is not in the deduplication data store may also be stored in the chunks in data store .

In at least some embodiments the chunks in data store may be immutable. That is the chunks are guaranteed to be valid if they are present in data store . To achieve immutability when a portion e.g. a data block or all of a given chunk is changed by a client a new chunk is created and stored to the data store by the data plane rather than overwriting or updating the original chunk . A garbage collection process may periodically or aperiodically detect and delete or invalidate stale chunks from the data store .

In at least some embodiments the mapping tier may be implemented according to high performance caching technology and may be used to maintain a mapping between fingerprints e.g. hashes of data blocks that are part of the data dictionary and the locations in the data store at which the data blocks are stored. For example the location of a data dictionary data block in data store may be indicated by a chunk identifier that identifies the chunk in which the respective deduplication data block is stored an offset into the chunk at which the respective deduplication data block is stored and a size. Note that other information for and or methods of identifying the location of a deduplication data block may be used in some embodiments. For example in some implementations of a data store chunks may be versioned and a chunk version identifier may be included in the information for each data block . The fingerprints e.g. hashes and location information also referred to herein as indexes may be stored as key value pairs in mapping cache s . In at least some embodiments cache s may be implemented according to high speed caching technology for example an in memory cache.

In at least some embodiments a cache service provided by a service provider may be leveraged to implement the mapping tier of the deduplication data dictionary . A service provider that provides cloud storage to clients via the data store and a storage service may also provide a cache service for deploying operating and scaling an in memory cache in the cloud. The cache service may improve the performance of web applications by allowing the client to retrieve information from a fast managed in memory caching system instead of relying entirely on slower disk based databases. For example a cache service may be provided that is protocol compliant with Memcached caching technology. Memcached is an open source high performance distributed memory object caching system. Note however that the cache service may be implemented according to other caching technologies. Advantages of using the cache service provided by the service provider to implement the mapping tier may include but are not limited to 

However some embodiments of the deduplication architecture may use other caching technologies to implement the mapping tier . For example a mapping tier using other high performance caching technology may be implemented for example if such a cache service is not provided or if custom cache eviction logic or other custom cache management logic that may not be provided by a cache service is necessary or desired.

As indicated at after receiving the fingerprints the data plane may request the mapping tier to search for the fingerprints. For example the receiver side deduplication process may query a cache manager process of mapping tier with the fingerprints requesting a cache search and return of any cache hits in the cache .

As indicated at the mapping tier checks the mapping cache using the fingerprints as keys. The check of the mapping cache may result in no cache hits or may result in one or more cache hits. In some embodiments the mapping tier may update an entry in a data structure for each cache entry for which there is a hit. This information may be used by a cache maintenance process to evict stale cache entries. In at least some embodiments stale cache entries include cache entries that have not been accessed for a specified period and or cache entries for which there has not been at least a threshold amount of activity for a specified period. The section Mapping cache implementations and optimizations describes implementations of the mapping tier and mapping cache in more detail including methods for cache eviction. At if there are no cache hits on the fingerprints then the mapping tier may return an indication of no cache hits to the data plane . In this case there is no deduplication data in the deduplication data dictionary for the fingerprints sent from the sender data upload process to the data plane and the method may go to element .

At if there are cache hits on at least some of the fingerprints then as indicated at for each cache hit the mapping tier retrieves the corresponding index from the mapping cache . The mapping tier then returns the located index es to the data plane . In at least some embodiments the mapping tier may also return an indication of fingerprint s for which there was not a hit in the cache .

As indicated at the data plane validates the presence of the chunk s indicated by the indexes returned from the mapping tier in the data store . As previously mentioned in some implementations of data store the chunks may be immutable guaranteed to be valid if they are present in data store . However stale chunks may have been garbage collected. Thus the cache hits as indicated by the index es returned from the mapping cache need to be validated against the data store to determine if the chunks storing the deduplication data blocks indicated by the index es are still present in the data store . If a respective chunk is not present then the data block s that were in that chunk are no longer in the deduplication data store and thus these data blocks may need to be uploaded by the sender . In addition the mapping cache needs to be updated to avoid future false positive hits.

If a chunk indicated by an index is not present in the data store then the deduplication data block that was previously stored in the chunk is not present in the deduplication data dictionary and thus the corresponding cache entry need to be deleted to prevent further false positive hits. In addition the respective data block may need to be uploaded from the client. At if it is determined that a chunk indicated by an index returned from the mapping tier is not present in the data store then the corresponding entry may be deleted from the mapping cache as indicated at . For example a receiver side deduplication process may direct the mapping tier to delete the key value pair s corresponding to the chunk that was determined to be not present in data store . As indicated at an indication may be recorded that the respective data block is not in the deduplication data dictionary . At if it is determined that a chunk indicated by an index is present in the data store an indication may be recorded that the respective data block is in the deduplication data dictionary .

Thus the data plane now may have the following information for the fingerprints that it received from the sender 

Note that in some cases one but not both of the above two lists may be empty. That is it may be the case that none of the data blocks indicated by the fingerprints are in the deduplication data dictionary or that all of the data blocks indicated by the fingerprints are in the deduplication data dictionary .

Referring again to as indicated at the data plane e.g. a receiver side deduplication process may return information to the sender e.g. to sender data upload process identifying one or more data blocks that need to be uploaded. This information may for example include the fingerprints of data blocks for which there is deduplication data in the deduplication data dictionary . Alternatively this information may include the fingerprints of data blocks for which there is no deduplication data in deduplication data dictionary . As another alternative this information may include all of the fingerprints with an indication for each as to whether there is corresponding deduplication data in deduplication data dictionary . Note that only the blocks for which there is no deduplication data in deduplication data dictionary may need to be uploaded.

In some embodiments instead of returning some or all of the fingerprints other information may be returned to indicate which data blocks need to be uploaded. For example in some embodiments a binary string or byte string may be returned that indicates for all of the data blocks in a chunk which data blocks need to be uploaded and which do not need to be uploaded. As a non limiting example a 1 at position n of the string may indicate that the data block at position n of the chunk is not in the data deduplication dictionary and thus needs to be uploaded while a 0 at position n of the string may indicate that the data block at position n of the chunk is in the data deduplication dictionary and thus does not need to be uploaded.

As indicated at the sender uploads the data blocks that were identified as needing to be uploaded to the data plane . For example sender data upload process may send the data blocks in one or more packets to a block data store process . The data plane then constructs and uploads a new chunk to the data store . The new chunk may include the data blocks received from the sender and deduplication data blocks retrieved from the data store . In at least some embodiments a new data block may be stored in data store while leaving the previous data block in the data store . The previous data block may later be garbage collected. Alternatively in some embodiments the new data block may overwrite the previous data block that is being updated. An example technique for constructing and storing new data blocks to the data store is given in .

As indicated at the data plane extracts the deduplication data blocks indicated by the cache hit information from the chunk s retrieved from the data store . For example each index may include in addition to a chunk identifier at least an offset into the chunk at which the respective data block is stored. In some implementations the index may also include a size e.g. in bytes of the data block . The block data store process may use this information from the index to extract the data block from the chunk .

In some embodiments instead of downloading the entire chunk s from data store and extracting the deduplication data blocks only the deduplication data blocks may be downloaded from the data store .

As indicated at the data plane may retrieve data blocks from a chunk in the data store that is being updated by the sender . In some embodiments this may be performed by downloading a copy of the entire chunk from the data store and extracting the needed data blocks. Alternatively instead of downloading a copy of the entire chunk from data store and extracting the data blocks only the necessary data blocks may be downloaded from the data store .

Note that in most cases deduplication data blocks for a chunk being updated may be stored in one or more other chunks in the data store . However in some cases for example on a first update of a chunk that was previously uploaded by the sender all of the deduplication data blocks for a chunk may actually be in the chunk itself as indicated by the mapping cache which was updated with fingerprints and indexes for all of the data blocks in the chunk when the chunk was originally uploaded.

As indicated at the data plane e.g. the block data store process constructs a new chunk that may but does not necessarily include one or more deduplication data blocks extracted from the chunk s retrieved from the data store one or more data blocks retrieved from the chunk being updated and one or more data blocks received from the sender . As indicated at the data plane uploads the new chunk to the data store . Note that in uploading the new chunk a chunk identifier may be assigned to the chunk . In at least some embodiments a new data block may be stored in data store while leaving the previous data block in the data store . The previous data block may later be garbage collected. Alternatively in some embodiments the new data block may overwrite the previous data block that is being updated.

As indicated at the data plane updates the mapping cache via the mapping tier with fingerprints and indexes for all of the data blocks in the new chunk . For example a data plane process e.g. a block data store process may generate fingerprints for each data block in the new chunk construct an index e.g. chunk identifier offset size for each data block and send the fingerprints and corresponding indexes to the mapping tier . The mapping tier then writes the fingerprints and indexes as new key value pairs to the cache .

Sender data upload process may act as an interface between sender and data plane . Sender data upload process may be implemented in hardware software or a combination thereof. In some implementations sender data upload process may be a process of or executing on a storage gateway as shown in . The communications channel s between sender data upload process and data plane may be a relatively high bandwidth connection or communications channel as large amounts of data may need to be transferred across the network e.g. the Internet between sender data upload process and data plane .

Sender may locally cache store or obtain data receiver may serve as a primary store or backing store for the data. As a non limiting example to improve data access times for users rather than retrieving data from a data store maintained by receiver on demand large blocks or chunks of data even entire volumes of data may be locally cached or stored at sender as local data . As another example sender may maintain local data as a local primary data store and use data store as a backing or mirroring data store for the local primary data store. Sender may include physical data storage and or memory on which local data may be cached and or stored. The data store maintained by receiver may thus serve as a primary data store or as a backing or mirroring data store for the client sender . In either case sender data upload process may communicate with data plane to periodically aperiodically or continuously upload new or modified data in local data to the data store provided by the receiver .

Sender data upload process may in at least some embodiments maintain local data in relatively large blocks or chunks e.g. 4 megabyte chunks or 10 megabyte chunks although larger or smaller chunk sizes may be used. Note that the chunk size used in local data of sender may be but is not necessarily the same as the chunk size used in data store . When a chunk e.g. chunk A is accessed by a user or process at sender e.g. to create new data or modify existing data the chunk A may be marked as dirty. However the access may have changed only a small portion of the chunk A. Thus as shown in the sender data upload process may generate fingerprints for units data blocks of the dirty chunk A for example by applying a hash function to each data block or to only some of the data blocks in the dirty chunk A. In block based data systems for example block storage systems a unit of data may for example be a 128 k byte data block a 256 k byte data block a 1024 k byte data block or some other fixed or variable sized data block. In file based systems a data block may be a file or a portion of a file similar to the data blocks of a chunk in a block based data system . As shown in the sender data upload process may send the fingerprints that were generated for the dirty chunk A to the data plane of the receiver .

Referring to in response to receiving the fingerprints from the sender the data plane of the receiver may query the mapping tier with the fingerprints . Mapping cache stores previously received fingerprints and data indexes as key value pairs. In at least some embodiments standard or commodity caching technology e.g. Memcached technology may be leveraged to implement mapping tier and mapping cache . The mapping tier checks mapping cache for hits on the fingerprints . If a fingerprint in mapping cache matches a fingerprint received from sender the corresponding data index is returned to data plane as an index hit . Note that there may be hits on one or more or all of the fingerprints . However in some cases there may be no hits on the fingerprints .

Referring to the data plane validates the presence of the chunk s indicated by the index hits in the data store . As previously mentioned in some implementations of data store the chunks may be immutable guaranteed to be valid if they are present in data store . However stale chunks may have been garbage collected. Referring to if it is determined that a chunk or chunks indicated by the index hits are not present in the data store then the data plane may direct the mapping tier to delete the key value pair s in mapping cache corresponding to the chunk s that are not present in data store . Note that if a chunk indicated by an index is not present in the data store the corresponding cache entries need to be deleted to prevent further false positive hits. In addition the respective data blocks may need to be uploaded from the sender .

Referring to the data plane may determine from the index hits and according to the check for presence of chunks as shown in which of the data blocks need to be uploaded to the receiver by the sender . The data plane may then send indications of the data blocks to be uploaded to the sender data upload process . The sender data upload process may then extract the indicated data blocks shown as new data blocks from local data e.g. from data block A and send the new data blocks to data plane .

Referring to the data plane retrieves one or more chunks including chunk s that include the deduplication data blocks indicated by the index hits from the data store . The data plane may also retrieve the chunk being updated from the data store . For example if chunk C is the chunk being updated by the sender and chunks A and B include deduplication data blocks as indicated by the index hits then the data plane may retrieve chunks A B and C from the data store . Note that in retrieving a chunk a copy of the chunk may be downloaded from the data store the chunk remains in the data store . The data plane extracts the deduplication data blocks indicated by the index hits from the chunk s retrieved from the data store . For example each index hit may include in addition to a chunk identifier at least an offset into the chunk at which the respective data block is stored. In some implementations the index hit may also include a size e.g. in bytes of the data block. The data plane may use this information from the index hits to extract the data block s from the chunk s retrieved from data store . The data plane may also extract other data blocks from the chunk being updated. In some embodiments instead of retrieving the entire chunks and extracting the data blocks from the retrieved chunks only the data blocks and or the deduplication data blocks may be retrieved from chunks in the data store.

Referring to the data plane constructs a new chunk that includes the deduplication data blocks extracted from the chunk s retrieved from the data store the other data blocks extracted from the chunk being updated and the new data blocks received from the sender data upload manger . The data plane uploads the new chunk to the data store . Note that in uploading the new chunk a chunk identifier may be assigned to the chunk the new chunk is shown as chunk D in data store . As shown in the new chunk may be written as a new chunk D while leaving the chunk being updated e.g. chunk C in the data store. Alternatively the chunk being updated e.g. chunk C may be overwritten with the new chunk .

Referring to the data plane updates the mapping cache via the mapping tier with fingerprints and indexes for all of the data blocks in the new chunk D. For example a data plane process may generate fingerprints e.g. hashes for each data block in the new chunk D construct an index e.g. chunk identifier offset size for each data block and send the fingerprints and corresponding indexes to the mapping tier . The mapping tier then writes the fingerprints and indexes as new key value pairs to the cache .

In at least some embodiments of the receiver side deduplication architecture a cache service provided by a service provider may be leveraged to provide the mapping tier of the deduplication data dictionary. In at least some embodiments the mapping cache may be implemented according to high speed caching technology for example an in memory cache. In at least some embodiments standard or commodity caching technology e.g. caching Memcached technology may be leveraged to implement the mapping cache and mapping tier.

In at least some embodiments the deduplication technique may use information about the age or activity of a chunk to be replaced to mitigate cache updates. For example the deduplication data dictionary may prioritize data blocks that do not change constantly. In at least some embodiments an eviction mechanism used with the mapping cache may be driven by how recently fingerprints e.g. hash values were looked up or updated in the cache. In at least some embodiments of the cache eviction mechanism more recent fingerprints may be retained in the cache while fingerprints that have not been active for a specified period may be evicted from the cache. Note that other cache eviction techniques may be implemented in some embodiments.

To process a deduplication data upload request from a sender the data plane may download at least one large e.g. 4 mB chunk from the data store create a new chunk and upload the new chunk to the data store even if the deduplication data for the request is small e.g. just one or a few data blocks e.g. one or a few 4 kB data blocks . In at least some embodiments of the receiver side deduplication architecture and technique on every data upload request from a sender including deduplication requests and regular data write requests after the new chunk s are written to the data store the data plane computes the fingerprint e.g. hash for every data block on the new chunk s and updates the mapping tier with this information. See e.g. . There may be many data blocks in a chunk. For example with a chunk size of 4 mB and a data block size of 4 kB every chunk upload to the data store will result in 1 k 1000 cache put operations to the mapping cache. If there are many upload requests a bottleneck could occur in bandwidth between the data plane and the mapping tier and or at the mapping cache due to the large volume of cache update operations that would result. In at least some embodiments one or more of several techniques as described below may be implemented to help prevent or reduce these potential bottlenecks by reducing the overhead of updating all cache entries on every chunk write to the data store. These techniques may be in place all the time or alternatively may only be invoked at times of high activity when such a bottleneck has occurred or may potentially occur.

One technique that may be used in at least some embodiments is to reduce the ratio of the data block size to the chunk size for example by reducing the chunk size to thus reduce the number of data blocks per chunk which would reduce the number of cache updates per chunk write to the data store. For example reducing the number of data blocks per chunk from 1000 to 500 would cut the number of cache updates in half.

In at least some embodiments the deduplication data upload technique may only be used for chunks for which some threshold portion of the chunk may be deduplicated. Otherwise the sender just sends the data via a normal data upload operation that does not use the deduplication technique. For example with a chunk size of 4 mB and a block size of 4 kB the deduplication technique may only be used if there are 16 32 or some other threshold number of data blocks that may be deduplicated or alternatively if there is 64 kB 128 kB or some other threshold amount of data that may be deduplicated.

In at least some embodiments the deduplication technique may employ a best effort cache update process to update the mapping cache for new chunks uploaded to the data cache. The cache update process may attempt to update the mapping cache for all chunk uploads to the data store but at peak times the process may skip the cache update for at least some chunks. For example in some embodiments the cache update process may be implemented as a background process. When uploading new chunks the chunks may be uploaded to the data store and separately queued e.g. to a FIFO queue for handling by the cache update process on the data plane. If the queue gets full one or more of the chunks in the queue may be discarded the cache is not updated for the discarded chunks. Note that this does not cause a problem with or any corruption in the deduplication data dictionary.

In at least some embodiments the deduplication technique may limit cache updates to larger write requests. For example if only a relatively small portion e.g. only one or a few data blocks below some specified threshold of a chunk is dirty and needs to be uploaded the deduplication process may be skipped for this data upload and a normal non deduplication data upload may be used instead. Thus the mapping cache may not be checked or updated for relatively small writes.

In at least some embodiments the mapping cache may be implemented as a two tiered or two stage cache. In this implementation instead of each index in the key value pairs stored in the cache including a chunk identifier that identifies the chunk in which the respective deduplication data block is stored each index includes a pointer or reference e.g. a key to a location in the cache that stores the chunk identifier. Thus in at least some cache updates only the location that includes the chunk identifier for multiple key value pairs may need to be updated instead of the index in each of the key value pairs for the respective chunk.

Thus in the two stage cache there are two types of cache entries. The first type of cache entry are the key value pairs that each maps a fingerprint to a data block location within a chunk and also points to one of the second type of cache entry. Each of the second type of cache entry identifies a particular chunk within the data store in which deduplication data blocks are stored. The key value pairs may be referred to as first level cache entries and the cache entries identifying the chunks within the data store may be referred to as second level cache entries.

As an example of using the two stage cache described above a deduplication data upload request may be received for one data block of a chunk. The data plane retrieves the chunk from the data store builds the new chunk including the new data block and then uploads the new chunk to the data store. The data plane has knowledge of the original chunk and thus can determine which cache entries will be invalidated by the update. For example the data plane may calculate the fingerprint e.g. hash for the old data block the one being replaced by the new data block invalidate that particular cache entry via the mapping tier update the mapping cache with the fingerprint and index information of the new data block in the new chunk and upload the new chunk to the data store. For the new chunk the data plane knows that all data blocks except for the new data block are valid. The data plane then updates the second level entry in the cache to indicate the new chunk. All of the key value pairs for the chunk point to this updated second level entry except for the key value pair for the new data block.

In at least some embodiments when updating a chunk if only a small part of the chunk is being replaced e.g. fewer than a specified number of data blocks then the following method may be used to update the two stage cache 

In at least some embodiments when updating a chunk if a relatively large part of the chunk is being replaced e.g. more than a specified number of data blocks then the following method may be used to update the two stage cache 

In at least some embodiments the cache eviction algorithm may be tuned so that the second level entries are preferentially NOT evicted.

A service provider that provides a data store may allow clients to create snapshots of volumes on the data store. The snapshots may for example be used to create or recover local volumes on the client s network from the remotely stored snapshots. When a snapshot of a volume is taken a snapshot manifest file that describes the snapshot may be created. A snapshot may be viewed as an immutable point in time capture of a corresponding volume a snapshot includes the snapshot data and a snapshot manifest that indicates where the snapshot data chunks is located. In some implementations when a snapshot of a volume is taken the snapshot data is not copied to another location but is instead made immutable within the volume. Alternatively when or after a point in time snapshot of a volume is taken the snapshot data from the volume may be copied to new locations in the data store essentially creating a new and separate point in time snapshot of the volume. A snapshot manifest file for a snapshot may include entries that map the storage locations of all of the snapshot objects chunks stored in the data store to the blocks chunks of the volume.

As previously noted the chunks in the data store may be immutable guaranteed to be valid if they are present in the data store . Thus when updating a chunk via the deduplication process a chunk is created and uploaded to the data store as a new chunk and the respective old chunk is not overwritten or updated However stale chunks may be periodically or aperiodically garbage collected. A motivation for updating the mapping cache for each new chunk to be uploaded to the data store is that the respective old chunks in the data store may be discarded e.g. by a garbage collection process and thus the cache entries for the old chunk may be stale as well.

However if these old chunk s are part of a snapshot the old chunks are not considered stale and are not likely to be garbage collected soon. Thus in at least some embodiments the deduplication cache update process may check to see if old chunks are part of any snapshot e.g. by querying a snapshot maintenance process or by checking the snapshot manifests . If an old chunk is part of a snapshot then the mapping cache entries for data blocks in the chunk that are not affected by the respective deduplication data upload do not have to be updated.

In some block based data storage systems the data objects e.g. chunks may be versioned. For example there may be a version identifier as well as a chunk identifier for each chunk. When a new chunk is created a new value for a version identifier may be given to the new chunk. Thus there may be one or more older versions and a newest version of a chunk in the data store. Note that all of these chunks would have the same chunk identifier but each may have a different version identifier. In these implementations the indexes stored in the mapping cache may also include a version identifier. In deduplication operations such as validating the presence of chunks in the data store according to index hits retrieved from the mapping cache the version identifier may be used in addition to the chunk identifier.

As previously mentioned embodiments of the receiver side deduplication architecture and deduplication techniques may provide network deduplication by reducing bandwidth usage on the communications channel s between data sender s and the receiver the data store provider . However while primarily directed to network deduplication rather than data deduplication some embodiments may also improve storage utilization in the data storage system by reducing the amount of data that is actually stored.

In some embodiments to provide data deduplication in addition to network deduplication instead of retrieving copies of the chunks from the data store extracting the deduplication data blocks from the chunks and building new chunks that include the deduplication data blocks and the new data blocks uploaded from the sender as shown in references to the locations of the deduplication data blocks in the chunks in the data store may be stored in the new chunk. Note that the reference information is available in the index information obtained from the mapping tier.

In this case since references are stored to the new chunk and not the data blocks themselves then the chunk s that are referenced should not be garbage collected. In some embodiments to prevent the referenced chunks from being garbage collected a mechanism may be provided that increments or decrements a reference count for each referenced chunk. Chunks that have a reference count higher than zero may not be garbage collected.

Embodiments of the receiver side deduplication architecture and technique may for example be implemented in the context of a service provider that provides remote volume based block storage to one or more service client networks or data centers as a remote data store. The service provider may provide via a local storage gateway over an intermediate network such as the Internet a storage service to one or more customers of the service provider. The storage service interface may be implemented as a Web service interface. The storage gateway may be implemented as a virtual or physical appliance that is installed on premise at a client s data center and may act as a gateway between the client s data center and the storage service. The storage gateway may for example be configured as an interface to and local cache for a primary storage provided remotely via the storage service and or as an interface that shadows primary storage implemented on the client s network to remote storage provided by the storage service. The storage gateway may present standard data access interfaces to the client s applications at the front end of the appliance convert the data accesses into storage service requests at the back end of the appliance and transfer the data over the network to the storage service according to the storage service interface. The storage service may store the client s data in the remote data store according to block storage technology. The storage gateway may expose block storage protocols e.g. iSCSI GNBD Global Network Block Device etc. file storage protocols e.g. NFS Network File Storage CIFS Common Internet File System etc. and or object storage protocols e.g. REST Representational State Transfer at the front end to the client s applications. A block storage protocol such as iSCSI may be used to enable direct access to the underlying data blocks of the remote data store. Files written by an application to a remote data store via file storage protocols such as NFS or CIFS exposed by the storage gateway may be stored to the remote data store according to block storage technology. Through an exposed file storage protocol such as NFS and CIFS the storage gateway presents the client s data stored in the remote data store according to block storage technology to the client s applications as files before they are transmitted from the gateway over the client network to the client s applications. The exposed block storage protocol e.g. iSCSI transfers the blocks to the client s applications thus requiring the application to handle interpretation of the data blocks into whatever format the application expects.

Embodiments of the receiver side deduplication architecture and techniques may be implemented on the service provider network to provide deduplication for data uploaded from storage gateways at the client s data centers. In some embodiments receiver side deduplication may be provided to the clients as a deduplication service that provides access to the deduplication techniques described herein to clients that store data to the remote data storage provided by the service provider via storage gateways at the client data centers. Alternatively access to the deduplication techniques may be provided as part of the storage service. In at least some embodiments access to the deduplication service or to the deduplication techniques may instead or also be provided to other client data processes that upload data to the remote data store.

A customer of the service provider may be referred to as a service customer or simply customer and may be any entity that implements a computer network or networks coupled to an intermediate network such as the Internet to provide networked computing services to one or more users on a local network or network including one or more services remotely provided by service provider . A service customer may be a business enterprise an educational entity a government entity or in general any entity that implements a computer network or networks that provide networked computing services to users. While shows a single client network there may be multiple client networks . Each client network may correspond to a different service customer or two or more client networks may correspond to different data centers or localities of the same service customer for example different regional offices of a business enterprise or different campuses of a school system. In at least some embodiments each customer of the service provider may have an account with the service provider and may be provided with security credentials e.g. an account name and or identifier password etc. via which one or more customer representatives e.g. a client network administrator may log in to interfaces e.g. Web pages to the service provider to manage the customer s resources provided by one or more services including but not limited to a storage service offered by the service provider .

Embodiments of storage gateway may be implemented in hardware software or a combination thereof. In at least some embodiments storage gateway may be implemented as a virtual appliance that may for example execute within a virtual machine instantiated on a host system. In at least some embodiments storage gateway may be implemented as a virtual appliance that may be downloaded or otherwise installed activated and configured on one or more computing devices such as server systems coupled to a local network infrastructure at a service customer s data center e.g. client network . Alternatively storage gateway may be implemented as a dedicated device or appliance that may be coupled to a local network infrastructure at a service customer s data center e.g. client network the dedicated device or appliance may include software and or hardware that implements the functionality of the storage gateway . illustrates an example computer system on which embodiments of a storage gateway may be implemented. In at least some implementations storage gateway communicates with the service provider network via an intermediate network e.g. the Internet through firewall technology. Note that the service provider network may also include front end technology e.g. firewall technology border router technology load balancer technology etc. through which network traffic from and to intermediate network passes.

Embodiments of the storage gateway may be installed activated and configured for use with a storage service to provide one or more of several data store functionalities. For example a storage gateway may be installed activated configured and employed with a storage service to serve as 

Note that the file system gateway and the cloud volume gateway are similar in that both serve as gateways to a remote data store and both may locally cache data e.g. frequently and or recently used data. In both the file system gateway and the cloud volume gateway data reads from customer processes may be serviced from the local cache if possible or from the remote data store if not. In contrast in the shadowing gateway data reads are passed through the gateway to the customer s local data store. The file system gateway and cloud volume gateway may collectively be referred to as cached gateways to distinguish these implementations from the shadowing gateway.

As shown in service provider network may implement an embodiment of the receiver side deduplication architecture and techniques as described herein. One or more deduplication processes may be implemented on data plane e.g. on host systems or servers and a mapping tier that includes and manages a mapping cache may be implemented as part of the deduplication data dictionary that includes the data chunks stored in remote data store . Data uploads from the storage gateway may be handled according to the deduplication techniques for example as described in reference to . Referring to the sender data upload process may be a process of or executing on the storage gateway and may be implemented in software hardware or a combination thereof. Referring to local data may be data cached on storage gateway or data in local data store .

In at least some embodiments a server that implements a portion or all of one or more of the technologies including but not limited to the data storage system technologies and deduplication technologies as described herein may include a general purpose computer system that includes or is configured to access one or more computer accessible media such as computer system illustrated in . In the illustrated embodiment computer system includes one or more processors coupled to a system memory via an input output I O interface . Computer system further includes a network interface coupled to I O interface .

In various embodiments computer system may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store instructions and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above for data storage system technologies and deduplication technologies are shown stored within system memory as code and data .

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computer system and other devices attached to a network or networks such as other computer systems or devices as illustrated in for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet network for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer accessible medium configured to store program instructions and data as described above for for implementing embodiments of data storage system technologies and deduplication technologies. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer accessible media. Generally speaking a computer accessible medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computer system via I O interface . A non transitory computer accessible storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc that may be included in some embodiments of computer system as system memory or another type of memory. Further a computer accessible medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface .

Various embodiments may further include receiving sending or storing instructions and or data implemented in accordance with the foregoing description upon a computer accessible medium. Generally speaking a computer accessible medium may include storage media or memory media such as magnetic or optical media e.g. disk or DVD CD ROM volatile or non volatile media such as RAM e.g. SDRAM DDR RDRAM SRAM etc. ROM etc as well as transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as network and or a wireless link.

The various methods as illustrated in the Figures and described herein represent exemplary embodiments of methods. The methods may be implemented in software hardware or a combination thereof. The order of method may be changed and various elements may be added reordered combined omitted modified etc.

Various modifications and changes may be made as would be obvious to a person skilled in the art having the benefit of this disclosure. It is intended to embrace all such modifications and changes and accordingly the above description to be regarded in an illustrative rather than a restrictive sense.

