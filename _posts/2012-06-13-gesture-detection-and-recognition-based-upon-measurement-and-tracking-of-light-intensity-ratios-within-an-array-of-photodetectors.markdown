---

title: Gesture detection and recognition based upon measurement and tracking of light intensity ratios within an array of photodetectors
abstract: Techniques are described for tracking and recognizing gestures performed within a field-of-view of a sensor. In one or more implementations, the techniques may be implemented within an electronic device that is configured to receive a signal from a sensor in response to the sensor detecting a gesture occurring within a field of view of the sensor. A lens is positioned over the sensor to collimate light incident on the lens and to pass the collimated light to the sensor. The electronic device is configured to generate one or more light intensity ratios based upon the signal. The electronic device is then configured to determine a type of gesture performed based upon the one or more light intensity ratios.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09348462&OS=09348462&RS=09348462
owner: Maxim Integrated Products, Inc.
number: 09348462
owner_city: San Jose
owner_country: US
publication_date: 20120613
---
Gesture detection and recognition can be used to provide new and more intuitive human machine interfaces HMIs to electronic devices. The goal of gesture recognition is to interpret human gestures via mathematical algorithms. Generally speaking gestures can originate from any bodily motion or state but most often originate from the face or hand of a human user e.g. in the manner of hand gestures. Gesture recognition is often looked to as a way for electronic devices such as computers tablets smart phones and so forth to begin to understand human body language in order to provide a more convenient and or intuitive interface between machines and humans than text based interfaces and Graphical User Interfaces GUIs which typically limit the majority of electronic device input to a keyboard a mouse and possibly a touchpad or touchscreen. Thus gesture detection and recognition can enable humans to interact more naturally with machines without requiring the use of mechanical input devices.

Techniques are described for tracking and recognizing gestures performed within a field of view of a sensor. In one or more implementations the techniques may be implemented within an electronic device that is configured to process a signal from a sensor in response to the sensor detecting a gesture occurring within a field of view of the sensor. A lens is positioned over the sensor to collimate light incident on the lens and to pass the collimated light to the sensor. The electronic device is configured to generate one or more light intensity ratios based upon the signal. The electronic device is then configured to determine a type of gesture performed based upon the one or more light intensity ratios.

This Summary is provided solely to introduce subject matter that is fully described in the Detailed Description and Drawings. Accordingly the Summary should not be considered to describe essential features nor be used to determine scope of the claims.

Increasingly gesture detection is being employed by electronic devices to detect user input for various applications associated with the electronic device. Such electronic devices typically have sensor configurations employing a large number of photodetectors to improve range and operation e.g. noise reduction of gesture detection. These sensor configurations may also provide limited tracking and detection of complicated gestures e.g. circular gestures diagonal swipe gestures and so forth .

Accordingly techniques are described for tracking and recognizing gestures performed within a field of view of a sensor. In one or more implementations the techniques may be implemented within an electronic device that is configured to process a signal from a sensor in response to the sensor detecting a gesture occurring within a field of view of the sensor. A lens is positioned over the sensor to collimate light incident on the lens and to pass the collimated light to the sensor. The lens may improve the sensitivity of the sensor e.g. electronic device as compared to electronic devices not employing a lens. In embodiments the sensor may comprise an array of photodetectors and the lens may be integrated with the array of photodetectors. The electronic device is configured to generate one or more light intensity ratios based upon the signal. The electronic device is then configured to determine a type of gesture performed based upon the one or more light intensity ratios.

The photodetector array includes a lens that is at least partially positioned over the photodiode array to focus and transmit the light incident thereon e.g. light incident upon the lens from multiple angles . In an implementation the lens may be integrated with the photodetector array . For example the lens may be configured to at least substantially collimate the light incident on the lens to improve sensitivity of the photodetector array compared to like photodetector arrays that do not employ a lens. As shown the lens may be positioned directly over the photodetector array to allow the passage of the collimated light to the photodetectors . In implementations the lens may comprise a micro lens array structure that may be integrated with the photodetector array . In such implementations the lens may include a spherical convex surface to refract the light incident thereon see . However it is contemplated that the lens may be configured in a variety of other ways. For example the lens may be a glass lens a plastic lens and so forth and may be separate from the photodetector array . Similarly the lens may be an aspherical lens a Fresnel lens and so forth. In example implementations the lens may have a diameter of at least approximately twenty micrometers 20 m to at least approximately five hundred micrometers 500 m . In yet another implementation the lens may be at least approximately ninety five percent 95 to at least approximately fifty percent 50 of a surface area of the photodetector array . Moreover the curvature of the lens may vary. For example the lens may be concave. In another example the lens may be convex. However it is understood that other types of lenses may utilized. For instance the lens may be biconvex plano convex positive meniscus negative meniscus plano concave biconcave and so forth. The lens may have an index of refraction of at least approximately one and three tenths 1.3 to at least approximately two 2 . However it is understood that the lens specifications may vary depending on various design confirmations of the photodetector array .

As shown in the lens may be positioned over a passivation layer and within a shielding layer . The passivation layer at least partially encapsulates or encloses the photodetectors and . In an implementation the passivation layer may comprise a polymer material that at least substantially allows transmission of light from the lens to the photodetectors . For example the passivation layer may be fabricated of a Benzocyclobutene BCB polymer material. However it is contemplated that other buffer materials may also be used.

The shielding layer is positioned over the passivation layer and is configured to at least substantially prevent the transmission of light such as infrared light and or visible light from reaching the photodetectors . For example the shielding layer may be configured to at least substantially prevent the transmission of light within specific wavelength spectrums e.g. infrared wavelength spectrum blue wavelength spectrum and so forth . In an implementation the shielding layer may be comprised of a metal material such as Copper or the like.

It should be noted that photodetector array shown in is described by way of example only and is not meant to be restrictive of the present disclosure. Thus other sensor configurations may be employed. For example as shown in the photodetector array may be extended to comprise a four by four 4 4 array of photodiodes. Each quadrant of the array may be comprised of a two by two 2 2 array of photodiodes and may include a lens disposed over the two by two 2 2 array of photodiodes.

In implementations the photodetector array may include an optical baffle shown in that is configured to segment the photodetector array into one or more array sections . As shown each array section includes four 4 photodetectors . However it is contemplated that a greater or a lesser number of photodiodes may be utilized in each array section according to the requirements of the photodetector array . The optical baffle is configured to at least substantially prevent optical cross talk between the array sections . In an implementation as shown in the optical baffle extends beyond a plane defined by a surface of the photodetectors to interface with the shielding layer . The optical baffle may be configured in a variety of ways. For example as shown in the optical baffle may be positioned at least partially between each photodetector e.g. photodetectors within the photodetector array . The optical baffle may comprise a metal material a cast metallic ridge a molded plastic patrician a preformed rubber gasket or the like.

In implementations the photodetector array photodetector array and lens may be implemented for gesture detection and or recognition with an electronic device such as a tablet computer a mobile phone a smart phone a Personal Computer PC a laptop computer a netbook computer a hand held portable computer a Personal Digital Assistant PDA a multimedia device a game device an e book reader device eReader a Smart TV device a surface computing device e.g. a table top computer and so forth. In the following discussion an example electronic device is described. Example methods are then described that may be employed by the device.

In the electronic device is illustrated as including a processor and a memory . The processor provides processing functionality for the electronic device and may include any number of processors micro controllers or other processing systems and resident or external memory for storing data and other information accessed or generated by the electronic device . The processor may execute one or more software programs which implement the techniques and modules described herein. The processor is not limited by the materials from which it is formed or the processing mechanisms employed therein and as such may be implemented via semiconductor s and or transistors e.g. electronic Integrated Circuits ICs and so forth.

The memory is an example of non transitory device readable storage media that provides storage functionality to store various data associated with the operation of the electronic device such as the software program and code segments mentioned above or other data to instruct the processor and other elements of the electronic device to perform the techniques described herein. Although a single memory is shown a wide variety of types and combinations of memory may be employed. The memory may be integral with the processor stand alone memory or a combination of both. The memory may include for example removable and non removable memory elements such as Random Access Memory RAM Read Only Memory ROM Flash memory e.g. a Secure Digital SD card a mini SD card a micro SD card magnetic memory optical memory Universal Serial Bus USB memory devices and so forth. In embodiments of the electronic device the memory may include removable Integrated Circuit Card ICC memory such as memory provided by Subscriber Identity Module SIM cards Universal Subscriber Identity Module USIM cards Universal Integrated Circuit Cards UICC and so on.

As shown in the electronic device includes a sensor such as a sensor comprised of a photosensor photodetector array photodetector array shown in . The photodetector array may be configured in a variety of ways. For example the photodetector array may comprise an array of photosensor diodes e.g. photodiodes phototransistors and so forth e.g. photodetector array . In implementations the photodetector array is capable of detecting light and providing a signal in response thereto. Thus the photodetector array may provide a signal corresponding to the light intensity incident upon each photodetector within the array e.g. generates four signals for each photodetector as shown in by converting light into current and or voltage based upon the intensity of the detected light. For example when photodetector array is exposed to light multiple free electrons may be generated to create a signal comprised of electrical current. The signal may correspond to one or more characteristics of the detected light. For example the characteristics may correspond to but are not necessarily limited to the position of the detected light with respect to the photodetector array the intensity e.g. irradiance etc. of the light incident upon the photodetector array how long the light is incident on the photodetector array an orientation of the light incident upon the photodetector array and so forth.

The photodetector array can be configured to detect light in both the visible light spectrum and the near infrared light spectrum. As used herein the term light is used to refer to electromagnetic radiation occurring in the visible light spectrum and or the near infrared light spectrum. For instance as referenced herein the visible light spectrum visible light includes electromagnetic radiation occurring in the range of wavelengths from about three hundred ninety nanometers 390 nm to approximately seven hundred fifty nanometers 750 nm . Similarly as referenced herein the near infrared light spectrum infrared light includes electromagnetic radiation that ranges in wavelength from about seven hundred nanometers 700 nm to three microns 3 m . In implementations Complementary Metal Oxide Semiconductor CMOS fabrication techniques may be used to form the photodetector array .

In implementations the photodetector array is configured to detect gestures in multiple orientations with respect to the orientation of the photodetector array e.g. right to left left to right top to bottom bottom to top diagonally across the photodetector etc. . Thus the photodetector array may be a segmented photodetector that includes an array of individual photodetectors provided in a single package see . As described above with respect to the photodetector array the photodetector array includes a lens configured to focus and transmit the light incident thereon. For example as an object e.g. a hand passes through the field of view of the segmented photodetector array the object reflects light and the lens is configured to collimate the light incident upon the lens. The collimated light is then furnished to the photodetectors where each individual photodetector may provide a signal that is out of phase with the other photodetectors of the segmented photodetector array as the object passes over the respective individual photodetectors.

While photodetector array has been described with some specificity as including a number of photodiodes arranged in an array e.g. as shown in these configurations are provided by way of example only and are not meant to be restrictive of the present disclosure. Thus the photodetector array may include but is not necessarily limited to an active pixel sensor e.g. an image sensor including an array of pixel sensors where each pixel sensor is comprised of a light sensor and an active amplifier a Charge Coupled Device CCD a Light Emitting Diode LED reverse biased to act as a photodiode an optical detector that responds to the heating effect of incoming radiation such as a pyroelectric detector a Golay cell a thermocouple and or a thermistor a photoresistor Light Dependent Resistor LDR a photovoltaic cell a photodiode e.g. operating in photovoltaic mode or photoconductive mode a photomultiplier tube a phototube a phototransistor and so forth. Further photodetector array is provided by way of example only and other sensors can be used to detect gestural motions including a proximity sensor that emits a beam of electromagnetic radiation e.g. infrared light a touchpad a camera and so forth. For instance one or more cameras can be used to detect gestures such as depth aware cameras stereo cameras and so forth.

The electronic device may include an illumination source configured to generate light e.g. near infrared light and or visible light within a limited spectrum of wavelengths. The illumination source may be used to illuminate an object proximal to the electronic device such as the hand of an operator allowing the photodetector array to more easily and or accurately detect the object. In an implementation the photodetector array may be configured to detect light e.g. light reflected from an object proximate to the device generated and emitted from the illumination source . Thus the photodetector array may be configured to detect light within a limited spectrum of wavelengths. For example the illumination source may generate a light occurring in a first spectrum of wavelengths and the photodetector array may be configured to detect light only occurring within the first spectrum of wavelengths. In implementations the illumination source may comprise a light emitting diode a laser diode or another type of light source.

As shown in the electronic device may include a gesture recognition module which is storable in memory and executable by the processor . The gesture recognition module represents functionality to track and to recognize a gesture performed within the field of view of the photodetector array . The gesture recognition module is configured to track the gesture by the transitioning of the light intensity over the photodetector array . For example as shown in the generated array response illustrates signals representing the intensity of light incident upon each photodetector at each discrete position of the object. The gesture recognition module is configured to track the gesture based upon the various signals representing the light intensity at each photodetector as the gesture transitions over the photodetector array . In an implementation the gesture recognition module is configured to recognize the type of gesture performed based upon but not limited to an intensity of light detected by the photodetector array a ratio of light intensity between each photodetector photodetectors at a discrete time a change in slope of the light intensity ratios over time and so forth.

The gesture recognition module is also configured to recognize the type of gesture performed by light intensity ratio between each photodetector in the photodetector array. Exhibit 1 in conjunction with illustrates an example method of recognizing determining the type of gesture performed.

 SnA corresponds to a light intensity ratio value of the photodetector with respect to the other photodetectors ratio of the amount of light incident upon the photodetector with respect to the ratio of the amount of light incident upon the other photodetectors SnB corresponds to the light intensity ratio value of the photodetector with respect to the other photodetectors SnC corresponds to the light intensity ratio value of the photodetector with respect to the other photodetectors and SnD corresponds to the light intensity ratio value of the photodetector with respect to the other photo detectors. The light intensity ratio comprises ratio values of the light intensity between each photodetector photodetectors at a discrete time e.g. light intensity ratio values between each photodetector when the object is at position one 1 and so forth . For instance the light intensity ratio is based upon each signal furnished by the photodetector array e.g. signal representing the light intensity incident upon the photodetector A signal representing the light intensity incident upon the photodetector B and so forth . In this specific example the ratio 5 1 9 5 represents the light intensity ratio of each photodetector with respect to the other photodetectors when the object is at position one 1 and the ratio 1 5 5 9 represents the light intensity ratio of each photodetector with respect to the other photodetectors when the object is at position two 2 . In this example a higher number represents a lower intensity of light incident upon the respective photodetector and a higher number represents a lower intensity of light incident upon the respective photodetector. For example with respect to position one 1 in Exhibit 1 the greatest light intensity is incident upon the photodetector photodetector B and the least light intensity is incident upon the photodetector photodetector C . Exhibit 1 illustrates the ratios of discrete samplings between position one 1 and position two 2 as illustrated in . It is understood that the ratio values shown in Exhibit 1 are for example purposes and vary according to the positions as well as the distance of the object with respect to the photodetector array .

Based upon the intensity of the light incident upon the photodetector array the gesture recognition module is configured to determine the distance e.g. an approximate distance between the object and the photodetector array . In an implementation the gesture recognition module determines in approximate distance units the distance between the photodetector array and the object performing the gesture based upon the light intensity passed to each photodetector within the photodetector array e.g. photodetector . Once the distance between the object and the photodetector array is determined the gesture recognition module is configured to calculate light intensity ratios for each photodetector within the photodetector array . Thus as the object transitions e.g. performs a gesture within the field of view of the photodetector array the light intensity incident upon each photodetector that comprises the photodetector array changes and the gesture recognition module is configured to continually determine the light intensity ratio based upon the differing intensities of light. Upon completion of the gesture a series of light intensity ratios may have been determined that correspond to discrete points that represent the location of the object see Exhibit 1 . It is understood that the gesture recognition module is configured to determine the light intensity ratio at predetermined time intervals. For example the predetermined time intervals may correspond to the sampling rate of the photodetector array or the like.

Once the light intensity ratios for the completed gesture are determined the gesture detection module is configured to determine the type of gesture performed by calculating the change in distance over the change in time. In an implementation the gesture detection module is configured to determine the slope of each response within the generated array responses see . For example based upon the generated array responses signals representing light incident upon each photodetector the gesture detection module determines the performed gesture based upon the slopes of each response with respect to the other slopes. Thus the gesture detection module may be pre programmed with information that represents the type of gesture performed based upon the slopes of each generated array response and the corresponding locations positions of the light intensity ratios. The gesture detection module may then cross reference the determined slopes with the pre programmed information to determine the type of gesture performed. For instance referring to the gesture detection module is configured to determine that the object moved from position one 1 to position two 2 instead of from position two 2 to position one 1 by calculating that the slope of the response of the photodetector is negative from position one 1 to position two 2 the slope of the response of the photodetector is positive from position one 1 to position two 2 the slope of the response of the photodetector is negative from position one 1 to position two 2 and the slope of the response of the photodetector is negative from position one 1 to position two 2 . The gesture recognition module can then determine the direction of the gesture by determining the slopes associated with the later positions e.g. position two 2 to the original position one 1 as shown in . In this specific example the gesture recognition module can determine the gesture performed was a circular gesture.

It is understood that the gesture recognition module can detect other gestures as well. illustrate example generated array responses corresponding to swipe gestures e.g. finger swipes within the field of view of the photodetector array . illustrates a generated array response corresponding to a diagonal swipe beginning over the photodetector photodetector C and completing over the photodetector photodetector D . illustrates a generated array response corresponding to a diagonal swipe beginning over the photodetector photodetector B and completing over the photodetector photodetector C .

The generated array response shown in is based upon the light intensity ratios. As shown the greatest light intensity at position one 1 is over the photodetector photodetector B which corresponds to a generated array response value proximal to the time t axis as compared to the least light intensity over the photodetector photodetector C which corresponds to a generated array response value distal to the time t axis .

The device may be configured to distinguish between distinct gestures. For the purposes of the present disclosure a distinct gesture may be defined as occurring when some amount of measurable light incident upon the photodetector array transitions to at least substantially less measurable light incident upon the photodetector . In some instances e.g. where light reflected by an object is used to measure a gesture a transition from less detected light to substantially more detected light and again to less detected light may comprise a distinct gesture. In other instances e.g. where light blocked by an object is used to measure a gesture such as for a backlit object a transition from more detected light to substantially less detected light and again to more detected light may comprise a distinct gesture. For example the photodetector array may be configured to generate signals corresponding to characteristics of the light e.g. light emitted from the illumination source incident upon the photodetector array . Thus once the photodetector array is no longer providing signals for a predetermined amount of time e.g. a nanosecond a millisecond a second and so forth the gesture recognition module may determine that the associated gesture has been completed and generate the light intensity ratios corresponding to the signals representing the distinct gesture.

It should be noted that for the purposes of the present disclosure the term light when used with detect sense convert determine and so forth should not be construed as limited to the detection or conversion of the presence or absence of light e.g. above or below a particular threshold or to detecting or converting a spectrum of wavelengths to a single measurement representative of overall light intensity e.g. irradiance within the spectrum. Thus the detection and or conversion of the presence of light within the context of the present disclosure may be used to refer to detecting and or converting the presence or absence of light e.g. above or below a particular threshold detecting and or converting a spectrum of wavelengths to a single measurement representative of overall light intensity within the spectrum as well as to detecting and or converting multiple frequencies within a range of possible frequencies such as detecting and or converting intensities of radiation separately in two or more subsets of wavelengths within a spectrum as well as for individual frequencies such as colors of light and so forth.

Accordingly phrases such as more detected light and less detected light may refer to both representations of light within a broad range of wavelengths and representations of light within a limited range of wavelengths e.g. for a particular color within a color spectrum etc. . For example the phrase a transition from more detected light to substantially less detected light and again to more detected light may be used to refer to measurements of light within a spectrum of wavelengths e.g. for visible light as well as to measurements of light at one or more specific wavelengths and or within multiple wavelength ranges e.g. for a particular color . Thus techniques described with reference to an array of photodiodes may also be applied with an image capture device e.g. a camera where an object e.g. a hand may be detected by differentiating its color from a different color indicative of the surrounding environment.

The electronic device includes a display to display information to a user of the electronic device . In embodiments the display may comprise an LCD Liquid Crystal Diode display a TFT Thin Film Transistor LCD display an LEP Light Emitting Polymer or PLED Polymer Light Emitting Diode display an OLED Organic Light Emitting Diode display and so forth which may be configured to display text and or graphical information such as a graphical user interface and so forth. The electronic device may further include one or more Input Output I O devices e.g. a keypad buttons a wireless input device a thumbwheel input device a trackstick input device and so on . In an implementation the photodetector array may be configured as an I O device . For example the photodetector array may detect light representing gestures corresponding to a desired operation associated with the electronic device . Additionally the I O devices may comprise one or more audio I O devices such as a microphone speakers and so on.

The electronic device may include a communication module representative of communication functionality to permit electronic device to send receive data between different devices e.g. components peripherals and or over one or more networks . Communication module may be representative of a variety of communication components and functionality including but not necessarily limited to an antenna a browser a transmitter and or a receiver a wireless radio a data port a software interface and or a driver a networking interface a data processing component and so forth. The one or more networks are representative of a variety of different communication pathways and network connections which may be employed individually or in combination to communicate among the components of the electronic device . Thus the one or more networks may be representative of communication pathways achieved using a single network or multiple networks. Further the one or more networks are representative of a variety of different types of networks and connections that are contemplated including but not necessarily limited to the Internet an intranet a satellite network a cellular network a mobile data network wired and or wireless connections and so forth.

Examples of wireless networks include but are not necessarily limited to networks configured for communications according to one or more standard of the Institute of Electrical and Electronics Engineers IEEE such as 802.11 or 802.16 Wi Max standards Wi Fi standards promulgated by the Wi Fi Alliance Bluetooth standards promulgated by the Bluetooth Special Interest Group a 3G network a 4G network and so on. Wired communications are also contemplated such as through USB Ethernet serial connections and so forth. The electronic device through functionality represented by the communication module may be configured to communicate via one or more networks to receive various content from one or more content repositories e.g. an Internet provider a cellular data provider etc. . Content may represent a variety of different content examples of which include but are not necessarily limited to web pages services music photographs video email service instant messaging device drivers instruction updates and so forth.

The electronic device may include a user interface which is storable in memory and executable by the processor . The user interface is representative of functionality to control the display of information and data to the user of the electronic device via the display . In some implementations the display may not be included as a part of the electronic device and may instead be connected externally using USB Ethernet serial connections and so forth. The user interface may provide functionality to allow the user to interact with one or more applications of the electronic device by providing inputs via the I O devices . For example the user interface may cause an Application Programming Interface API to be generated to expose functionality to an application to configure the application for display by the display or in combination with another display. In embodiments the API may further expose functionality to configure the application to allow a user to interact with an application by providing inputs via the I O devices . For example a user may provide hand gestures proximate to the photodetector array corresponding to a desired operation associated with an application . For instance a user may perform a finger swipe proximate to the photodetector array to transition between various display pages showing various applications within the display .

The electronic device may include applications which may comprise software storable in memory and executable by the processor e.g. to perform a specific operation or group of operations to furnish functionality to the electronic device . Example applications include cellular telephone applications instant messaging applications email applications gaming applications address book applications and so forth. In implementations the user interface may include a browser . The browser enables the electronic device to display and interact with content such as a webpage within the World Wide Web a webpage provided by a web server in a private network and so forth. The browser may be configured in a variety of ways. For example the browser may be configured as an application accessed by the user interface . The browser may be a web browser suitable for use by a full resource device with substantial memory and processor resources e.g. a smart phone a PDA etc. . The browser may be a mobile browser suitable for use by a low resource device with limited memory and or processing resources e.g. a mobile telephone a portable music device a transportable entertainment device etc. .

Using this type of approach a user may navigate e.g. flick through menus controlling speed direction and or selection. For example a user may navigate through a cascading series of graphical representations of cover flow artwork with quick right to left swipes followed by slower right to left swipes as the user gets closer to a desired track. Then a stop pause select event may be used to complete a selection. A bottom to top swipe may constitute a cancel event. In another example implementation left to right swipes can be used to change channels on a smart TV while a top to bottom swipe can be used to lower the volume of the TV. This type of interface can be implemented using for example a photodetector array positioned in the bezel of a TV frame and may supplement or replace the buttons that would otherwise be provided for enabling control of the TV functions. In a further example horizontal and or vertical swipes can be used to advance the pages of a buttonless eReader.

Generally any of the functions described herein can be implemented using software firmware hardware e.g. fixed logic circuitry manual processing or a combination of these implementations. The terms module and functionality as used herein generally represent software firmware hardware or a combination thereof. The communication between modules in the electronic device of can be wired wireless or some combination thereof. In the case of a software implementation for instance the module represents executable instructions that perform specified tasks when executed on a processor such as the processor with the electronic device of . The program code can be stored in one or more device readable storage media an example of which is the memory associated with the electronic device of .

The following discussion describes methods that may be implemented in an electronic device for detecting gestures. Aspects of the methods may be implemented in hardware firmware or software or a combination thereof. The methods are shown as a set of blocks that specify operations performed by one or more devices and are not necessarily limited to the orders shown for performing the operations by the respective blocks. In portions of the following discussion reference may be made to the electronic device of . The features of techniques described below are platform independent meaning that the techniques may be implemented on a variety of commercial electronic device platforms having a variety of processors.

As shown in one or more light intensity ratios are generated based upon the signals generated by the sensor Block . With continuing reference to once signals are generated by the photodetector array the gestured detection module is configured to determine an approximate distance between the object and the photodetector array based upon the intensity of the light at the photodetector array . Once the distance between the object and the photodetector array is determined the gesture recognition module generates light intensity ratios at discrete positions of the object. As described above a series of light intensity ratios may be generated and each light intensity ratio value corresponds to a discrete position of the object within the field of view of the photodetector array .

The gesture detection module may determine whether a gesture has been detected Decision Block . If the gesture is not complete NO from Decision Block the gesture detection module continues to generate light intensity ratios based upon the signals. When a completed gesture is detected YES from Decision Block the gesture detection module can determine the type of gesture performed Block . In an implementation the gesture detection module is configured to determine the performed gesture based upon the slope of each generated array response occurring within the same positional movement e.g. determine whether the slope is positive or negative for each generated array response occurring from position one 1 to position two 2 .

Although the subject matter has been described in language specific to structural features and or process operations it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

