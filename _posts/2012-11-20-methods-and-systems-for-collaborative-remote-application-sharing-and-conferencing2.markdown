---

title: Methods and systems for collaborative remote application sharing and conferencing
abstract: Systems and method for providing a collaborative conferencing capability to an application remotely-accessed by client computing devices. A client media sharing application is provided in a client tier, and the client media sharing application allows at least one of the client computing devices to share media with the client computing devices. A conferencing manager application that receives the shared media is provided to the server tier. The conferencing manager application makes the shared media available to the client computing devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09648057&OS=09648057&RS=09648057
owner: Calgary Scientific Inc.
number: 09648057
owner_city: Calgary, AB
owner_country: CA
publication_date: 20121120
---
This application claims the benefit of U.S. Provisional Patent Application No. 61 563 256 filed on Nov. 23 2011 entitled Methods and Systems for Collaborative Remote Application Sharing and Conferencing and U.S. Provisional Patent Application No. 61 623 131 filed on Apr. 12 2012 entitled Methods and Systems for Collaborative Remote Application Sharing and Conferencing the disclosures of which are expressly incorporated herein by reference in their entireties.

Ubiquitous remote access to services application programs and data has become commonplace as a result of the growth and availability of broadband and wireless network access. As such users are accessing application programs and data using an ever growing variety of client devices e.g. mobile devices table computing devices laptop notebook desktop computers etc. . Data may be communicated to the devices from a remote server over a variety of networks including 3G and 4G mobile data networks wireless networks such as WiFi and WiMax wired networks etc. Clients may connect to a server offering the services applications programs and data across many disparate network bandwidths and latencies.

In such an environment applications may also be shared among remote participants in a collaborative session. However when collaborating participants may be limited solely to the functionalities provided by the shared application thus limiting the collaborative session. Specifically participants may be limited because they are unable to share media i.e. audio video desktop screen scrapes image libraries etc. with other participants in the collaborative session.

Disclosed herein are systems and methods for providing a collaborative conferencing capability to a remotely accessed application. A method of providing a collaborative conferencing capability to a remotely accessed application may include providing a tiered remote access framework comprising an application tier a server tier and a client tier the tiered remote access framework communicating first information regarding the remotely accessed application between client computing devices accessing the remotely accessed application within a state model that is used to display the remotely accessed application at the client computing devices providing a server remote access application in the server tier the server remote application being capable of modifying the state model providing a client remote access application in either the client tier or the application tier providing a client media sharing application in the client tier the client media sharing application allowing at least one of the client computing devices to share media with the client computing devices providing a conferencing manager application to the server tier the conferencing manager application receiving the shared media and modifying the state model to further include the shared media such that the shared media is provided in at least one of the client computing devices.

In another implementation a method of providing a collaborative conferencing capability may include providing a tiered remote access framework comprising a server tier and a client tier the tiered remote access framework communicating information regarding shared media between client computing devices accessing the shared media within a state model that is used to display the shared media at the client computing devices providing a server remote access application in the server tier the server remote application being capable of modifying the state model providing a client media sharing application in the client tier the client media sharing application allowing at least one of the client computing devices to share the shared media with the client computing devices providing a conferencing manager application to the server tier the conferencing manager application receiving the shared media and modifying the state model to further include the shared media such that the shared media is provided in at least one of the client computing devices.

Other systems methods features and or advantages will be or may become apparent to one with skill in the art upon examination of the following drawings and detailed description. It is intended that all such additional systems methods features and or advantages be included within this description and be protected by the accompanying claims.

Unless defined otherwise all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art. Methods and materials similar or equivalent to those described herein can be used in the practice or testing of the present disclosure. While implementations will be described for remotely accessing applications it will become evident to those skilled in the art that the implementations are not limited thereto but are applicable for remotely accessing any type of data or service via a remote device.

Referring to a system for providing remote access to an application data or other service via a computer network. The system comprises a client computer A or B such as a wireless handheld device such as for example an IPHONE A or a BLACKBERRY B connected via a computer network such as for example the Internet to a server B. Similarly the client computing devices may also include a desktop notebook personal computer C or a tablet device N that are connected by the communication network to the server B. It is noted that the connections to the communication network may be any type of connection for example Wi Fi IEEE 802.11x WiMax IEEE 802.16 Ethernet 3G 4G etc.

The server B is connected for example via the computer network to a Local Area Network LAN or may be directly connected to the computer network . For example the LAN is an internal computer network of an institution such as a hospital a bank a large business or a government department. Typically such institutions still use a mainframe computer A and a database connected to the LAN . Numerous application programs A may be stored in memory A of the mainframe computer A and executed on a processor A. Similarly numerous application programs B may be stored in memory B of the server B and executed on a processor B. The application programs A and B may be services offered for remote access. The mainframe computer A the server B and the client computers A B C or N may be implemented using hardware such as that shown in the general purpose computing device of .

A client remote access application A B C N may be designed for providing user interaction for displaying data and or imagery in a human comprehensible fashion and for determining user input data in dependence upon received user instructions for interacting with the application program using for example a graphical display with touch screen A or a graphical display B N and a keyboard B C of the client computers A B C N respectively. For example the client remote access application is performed by executing executable commands on processor A B C N with the commands being stored in memory A B C N of the client computer A B C N respectively.

Alternatively or additionally a user interface program is executed on the server B as one of application programs B which is then accessed via an URL by a generic client application such as for example a web browser executed on the client computer A B. The user interface is implemented using for example Hyper Text Markup Language HTML 5. In some implementations the server B may participate in a collaborative session with the client computing devices A B C . . . N. For example the aforementioned one of the application programs B may enable the server B to collaboratively interact with the application program A or another application program B and the client remote access applications A B C N. As such the server B and each of the participating client computing devices A B C . . . N may present a synchronized view of the display of the application program.

The operation of a server remote access application B with the client remote access application any of A B C N or one of application programs B is performed in cooperation with a state model as illustrated in . An example of the server remote access program is PUREWEB available from Calgary Scientific Alberta Canada. When executed the client remote access application updates the state model in accordance with user input data received from a user interface program. The remote access application may generate control data in accordance with the updated state model and provide the same to the server remote access application B running on the server B.

Upon receipt of application data from an application program A or B the server remote access application B updates the state model in accordance with the screen or application data generates presentation data in accordance with the updated state model and provides the same to the client remote access application A B C N on the client computing device. The state model comprises an association of logical elements of the application program with corresponding states of the application program with the logical elements being in a hierarchical order. For example the logical elements may be a screen a menu a submenu a button etc. that make up the application program user interface. This enables the client device for example to natively display the logical elements. As such a menu of the application program that is presented on a mobile phone will look like a native menu of the mobile phone. Similarly the menu of the application program that is presented on desktop computer will look like a native menu of the desktop computer operating system.

The state model is determined such that each of the logical elements is associated with a corresponding state of the application program A or B. The state model may be determined such that the logical elements are associated with user interactions. For example the logical elements of the application program are determined such that the logical elements comprise transition elements with each transition element relating a change of the state model to one of control data and application representation data associated therewith.

In some implementations two or more of the client computing devices A B C . . . N and or the server B may collaboratively interact with the application program A or B. As such by communicating state information between each of the client computing devices A B C . . . N and or the server B and or the mainframe computer A participating in a collaborative session each of the participating client computing devices A B C . . . N may present a synchronized view of the display of the application program A or B.

In accordance with some implementations the system may provide for decoupled application extensions. Such extensions are provided as part of the server remote access application B e.g. as a plug in the client remote access applications A B C N e.g. as part of a client software development kit SDK one of the applications B e.g. as part of a server SDK or combinations thereof to provide features and functionalities that are otherwise are not provided by the application programs A or B. These are described more fully with regard to below. These features and functionalities may be provided without a need to modify the application programs A or B as they are integral with the remote access applications. As such the decoupled application extensions are agnostic to the application itself i.e. the application extensions do not depend on the application being displayed within the server remote access application B and client remote access application A B C N. Further the application extensions may be made available within controls presented by the server remote access application B or client remote access application A B C N and may be always available.

For example an interactive digital surface layer may be provided as an application extension to enable participants in a collaborative session to make annotations on top of the application running in the session. The interactive digital surface layer functions like a scribble tool to enable a user to draw lines arrows symbols scribbles etc. on top of an application to provide collaboration of both the application and the interactive digital surface layer. As will be described below with reference to the interactive digital surface layer is available as a control within the environment of .

Under the collaboration node there are also one or more views defined. In the example of Glen and Jacquie may be collaborating within a medical imaging application. As such there may be two views defined an axial view and a coronal view. Sessions are associated with each of the views where the sessions include the users to the collaboration. For the axial view Glen s session has associated therewith a cursor position CP and certain markups e.g. a scribble arrow and circle. In the axial view Jacquie has an associated cursor position but since she has not made any markups to the interactive digital surface layer there is no additional information associated with Jacquie s axial session view. Under the coronal session each user only has a cursor position associated therewith.

The above information is displayed by the client remote access application which may be displayed on a client computing device associated with Glen and Jacquie respectively. For example Glen may be viewing the application on a client computing device such as a laptop which has a mid sized display. As such Glen is able to view both the axial view and the coronal view at the same time. In contrast Jacquie may be viewing the application on a smaller computing device such as a handheld wireless device. As such only the axial view may be presented due to the more limited display area of such a device.

Below is an example section of a state model in accordance with the tree of . The state model may be represented by e.g. an Extensible Markup Language XML document. Other representations of the state model may be used. Information regarding the application program and interactive digital surface layer is communicated in the state model . Because the interactive digital surface layer is decoupled from the application the information regarding the interactive digital surface layer is not part of the application state i.e. it is abstracted from the application . Rather the interactive digital surface layer information is separately maintained in the state model .

Information regarding the application A or B is maintained in the ApplicationState node in a first portion of the XML state model. Different states of the application program associated with the axial view and the coronal view are defined as well as related triggers. For example in the axial view a field is defined for receiving a name as user input data and displaying the same. The decoupled collaboration states and application extension states e.g. interactive digital surface layer are maintained in a second portion of the XML document.

The state model may thus contain session information about the application itself the application extension information e.g. interactive digital surface layer information about views and how to tie the annotations to specific views e.g. scribble arrow circle tied to axial view .

In yet another example in the application tier the application extension may be a separate executable program that includes new business logic to enhance the applications A B. The application extension may consume the state model and produce its own document i.e. a state model of the application extension that may include 1 information from the state model and information associated with the application extension 2 only information associated with the application extension or 3 a combination of some of the state model information and information associated with the application extension . The state model may be communicated to the server remote access application B where the server remote access application B may compose an updated state model to include the information in the state model . Alternatively or additionally the client remote access application A B C N may receive both the state model and the state model and the client remote access application may compose an updated state model to include the information in the state model .

The system of includes the client computing devices A B C and or N an application server machine i.e. the server B or the mainframe computer A and the server remote access application B which runs on the server B as discussed with regard to . As discussed above the server remote access application B provides access to one or more application programs A B which is displayed by the client remote access applications A B C or N. Operation of the server remote access application B with the client remote access application A B C or N or one of the application programs A B is performed in cooperation with the state model . According to the above implementations each of the client computing devices A B C or N participating in the collaborative session may present a synchronized view of the applications programs A B by communicating the state model between each of the client computing devices A B C or N and or the server B and or the mainframe computer A.

In order to provide conferencing capability i.e. share various media with the other participants in a collaborative session also includes a conferencing server machine having a conferencing stub application and a conferencing manager application . In some implementations the conferencing stub application and the conferencing manager application may run on the server B. A sharing component of the conferencing capability may be optional and may be initiated by a participant downloading but not installing a client media sharing application using the client computing device A B C or N. However if the client remote access application A B C or N is running in a restricted sandbox environment such as a web browser that does not have access to system resources to collect sharable media or is not sharing any media then the participant may not download the client media sharing application but will be unable to share various media with the other participants in the collaborative system. Instead the participant will be limited to solely viewing the remotely accessed application program A B and or various media shared by other participants in the collaborative session. In some implementations the client media sharing application may be incorporated into the client remote access application A B C or N.

The system of allows the participant that acquires conferencing capability to share media such as video audio desktop screen scrapes text messages libraries of images etc. with other participants in the collaborative session. The conferencing server machine may receive the shared media either directly from the client media sharing application or indirectly from the client remote access application A B C or via the conferencing stub application . Additionally a plurality of different participants can provide shared media which may be simultaneously displayed by the other client computing devices A B C or N.

In one implementation the conferencing stub application is a server application e.g. a plug in enabled to communicate with the server remote access application B. The conferencing stub application however may not included collaborative features such as for example the features that allow the client computing devices A B C or N to collaboratively interact with the application program A B. Thus the conferencing stub application may not be shared by the participants in the session via the state model . Accordingly in this implementation there is one conferencing stub application for each client computing device A B C or N connected to the conferencing server machine. In another implementation the conferencing manager application is a server application enabled to communicate with the server remote access application B and the functionality of the conferencing stub application exists entirely within the conferencing manager application . Further in yet another implementation the conferencing manager application is a server application enabled to communicate with the server remote access application B and the conferencing stub application becomes a hybrid client server where the conferencing stub application is a server with respect to the client computing devices A B C or N and a client with respect to the conferencing server machine.

During a collaborative session as discussed above the client remote access application A B C or N operates with the server remote access application B in cooperation with the state model to interface with the application program A B. Similarly during a conferencing session the client remote access application A B C or N operates with the server remote access application B in cooperation with the state model to interface with conferencing manager application via the conferencing stub application . For example the conferencing manager application acts as a multiplexer by making shared media received from one client computing device A B C or N either directly or indirectly as discussed above available to the conferencing stub application of each of the other client computing devices A B C or N. Specifically the conferencing stub application and the client remote access application A B C or N coordinate how various media streams may be reprocessed elided combined re sampled etc. before transmission from the conferencing stub application to the client remote access application A B C or N. For example the conferencing stub application may mix two or more available audio streams into a single audio stream in order to reduce the bandwidth requirements.

At in order to acquire conferencing capability the participant may download the client media sharing application using the client computing device A B C or N. The client media sharing application allows the participant to share various media with the other participants in a collaborative session.

At the participant provides the shared media to the conferencing server machine either directly using the client media sharing application or indirectly using the client remote access application A B C or N via the conferencing stub application . In one implementation a plurality of different participants can provide shared media which may be simultaneously displayed by the client computing devices A B C or N. At the client remote access application A B C or N operates with the server remote access application B in cooperation with the state model to interface with conferencing manager application via the conferencing stub application . For example upon receipt of the shared media from one client computing device A B C or N by the conferencing manager application the conferencing manager application makes the shared media available to each conferencing stub application of the other client computing devices A B C or N. Then the server remote access application B updates the state model .

At the server remote access application B generates presentation data in accordance with the updated state model and provides the same to the client remote access application A B C N on the client computing device. At the client remote access application A B C N updates the display of the client computing device A B C or N.

The user interfaces of the present disclosure may be presented on any type of computing device participating within the collaborative conferencing session. Thus to accommodate the various display areas of the devices that may participate in the collaborative conferencing session implementations of the present disclosure may provide for refactoring of the display. As such each type of device that is participating in the collaborative conferencing session presents the user interface having a device appropriate resolution based on information contained in the state model . For example with reference to the user interface of if a display is associated with a desktop computer the entire user interface may be displayed. However if a display is associated with a handheld mobile device then a subset of the user interface may be displayed e.g. the view of the application program . The other views may be made available on the handheld mobile via a control provided in the display. Other refactoring schemes are possible depending on the views in the user interface and the device on which the user interface is to be displayed.

During a collaborative session a user may wish to point to an area of the user interfaces without interacting with the underlying application program A B. For example a user may be making a presentation of a slide deck and may wish to point to an item on the slide being displayed in the user interface. The interactive digital surface layer may be used to provide such an indication to other users in the collaborative session.

To accommodate the above the sending of mouse cursor position data may be separated from the sending of mouse input events to the application A B so that the position and event data can be triggered independently of one another. As such a cursor position tool may be directed to send cursor information without input events that would otherwise cause an interaction when the user of the tablet device N does not desire such interaction with the application program A B. The above may be achieved by separating a single method that updates the interactive digital surface layer for cursor position into two methods one of which performs cursor position updates and one of which queues the input events. Optionally or additionally the mouse cursor may change characteristics when operating in such a mode. For example where the mouse cursor is being used for indication purposes the cursor may thicken change color change shape blink etc. to indicate to other users that the cursor is being used as an indicator.

While the above may be implemented for all types of client computers a particular use case is where users of mobile devices having a touch sensitive interface e.g. tablet device N wish to indicate to other users what he or she is currently viewing on the display. Typically a touch of a tablet device represents an interaction with the application program A B. In accordance with the above separating the mouse cursor position data i.e. the touch location from the sending of mouse input events i.e. the actual touch enables users of tablet devices N to make such an indication similar to client computers having a pointing device.

In another aspect that may be combined with the above or separately implemented annotations can be created in the interactive digital surface layer without interacting with the underlying application program A B and interactions with the underlying application program A B do not necessarily create annotations within the interactive digital surface layer. Therefore the interactive digital surface layer control may be provided with an option to disable interaction with the underlying application A B.

Thus as described above the present disclosure provides for conferencing capability around a remotely accessed collaborative application. More generally the present disclosure provides systems and methods for allowing participants in a collaborative session to share media with the other participants in the collaborative session.

Numerous other general purpose or special purpose computing system environments or configurations may be used. Examples of well known computing systems environments and or configurations that may be suitable for use include but are not limited to personal computers server computers handheld or laptop devices multiprocessor systems microprocessor based systems network personal computers PCs minicomputers mainframe computers embedded systems distributed computing environments that include any of the above systems or devices and the like.

Computer executable instructions such as program modules being executed by a computer may be used. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Distributed computing environments may be used where tasks are performed by remote processing devices that are linked through a communications network or other data transmission medium. In a distributed computing environment program modules and other data may be located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing aspects described herein includes a computing device such as computing device . In its most basic configuration computing device typically includes at least one processing unit and memory . Depending on the exact configuration and type of computing device memory may be volatile such as random access memory RAM non volatile such as read only memory ROM flash memory etc. or some combination of the two. This most basic configuration is illustrated in by dashed line .

Computing device may have additional features functionality. For example computing device may include additional storage removable and or non removable including but not limited to magnetic or optical disks or tape. Such additional storage is illustrated in by removable storage and non removable storage .

Computing device typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by device and includes both volatile and non volatile media removable and non removable media.

Computer storage media include volatile and non volatile and removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Memory removable storage and non removable storage are all examples of computer storage media. Computer storage media include but are not limited to RAM ROM electrically erasable program read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of computing device .

Computing device may contain communications connection s that allow the device to communicate with other devices. Computing device may also have input device s such as a keyboard mouse pen voice input device touch input device etc. Output device s such as a display speakers printer etc. may also be included. All these devices are well known in the art and need not be discussed at length here.

It should be understood that the various techniques described herein may be implemented in connection with hardware or software or where appropriate with a combination of both. Thus the methods and apparatus of the presently disclosed subject matter or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes CD ROMs hard drives or any other machine readable storage medium wherein when the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus for practicing the presently disclosed subject matter. In the case of program code execution on programmable computers the computing device generally includes a processor a storage medium readable by the processor including volatile and non volatile memory and or storage elements at least one input device and at least one output device. One or more programs may implement or utilize the processes described in connection with the presently disclosed subject matter e.g. through the use of an application programming interface API reusable controls or the like. Such programs may be implemented in a high level procedural or object oriented programming language to communicate with a computer system. However the program s can be implemented in assembly or machine language if desired. In any case the language may be a compiled or interpreted language and it may be combined with hardware implementations.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

