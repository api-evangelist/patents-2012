---

title: Interface and method for inter-thread communication
abstract: The interface for inter-thread communication between a plurality of threads including a number of producer threads for producing data objects and a number of consumer threads for consuming the produced data objects includes a specifier and a provider. The specifier is configured to specify a certain relationship between a certain producer thread of the number of producer threads which is adapted to produce a certain data object and a consumer thread of the number of consumer threads which is adapted to consume the produced certain data object. Further, the provider is configured to provide direct cache line injection of a cache line of the produced certain data object to a cache allocated to the certain consumer thread related to the certain producer thread by the specified certain relationship.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09330005&OS=09330005&RS=09330005
owner: International Business Machines Corporation
number: 09330005
owner_city: Armonk
owner_country: US
publication_date: 20121211
---
The invention relates to an interface and to a method for inter thread communication between a plurality of threads including a number of producer threads for producing data objects and a number of consumer threads for consuming the produced data objects.

In large core systems it is crucial for software developers to structure their programs to take advantage of the plurality of computational units in the core system. Software not optimized for multi cores may not improve its performance when running on such core systems.

Crucial for hardware platforms may be the support offer to software developers to rapidly write optimized code benefits from existing and upcoming hardware features.

In particular one important challenge for software developers is to deal with fine grained inter thread communications which may increase cache coherency overhead inter chip communication the impact of false sharing the number of thread migrations and which may saturate specific hardware constructs and limit scalability. This is particularly evident in modern managed languages e.g. JAVA that provide automatic memory management.

Moreover fine grained inter thread communication may reduce the performance of multi thread applications executed on modern multi core systems.

In case that two or more threads concurrently execute on different cores and communicate by means of a shared data structure references to the accessed data have to be moved between the caches of corresponding cores.

On modern architectures the last level cache e.g. L3 cache is conventionally shared between the cores that are part of the same CPU CPU Central Processing Unit .

However this may not be the case for caches at other levels e.g. L1 and L2 or for cores on different CPUs.

In case of fine grained communication the overhead introduced by cache coherency protocols may severely impact the program execution time.

In this regard shows an example for conventional inter thread communication between producer threads T T and consumer threads C C. Each thread T T C C has an allocated unshared cache M M.

The producer threads T T communicate with the consumer threads C C by means of a shared data structure embodied by a shared queue SQ in . References to this shared data structure SQ have to be frequently moved between the caches M M of the cores on which the corresponding threads T T C C are executing. This issue is even more evident in case of multiple producers T T and consumers C C accessing the same data structure SQ as exemplarily shown in .

Document US 2010 0332755 A1 describes a method and an apparatus for using a shared ring buffer to provide thread synchronization in a mulit core processor system. Therein synchronization between threads in a multi core processor system is provided. Such an apparatus includes a memory a first processor core and a second processor core. The memory includes a shared ring buffer for storing data units and stores a plurality of shared variables associated with accessing the shared ring buffer. The first processor core runs a first thread and has a first cache associated therewith. The first cache stores a first set of local variables associated with the first processor core. The first thread controls insertion of data items into the shared ring buffer using at least one of the shared variables and the first set of local variables. The second processor core runs a second thread and has a second cache associated therewith. The second cache stores a second set of local variables associated with the second processor core. The second thread controls extraction of data items from the shared ring buffer using at least one of the shared variables and the second set of local variables.

Document US 2010 0223431 A1 shows a memory access control system a memory access control method and a program thereof. In a multi core processor of a shared memory type deterioration in the data processing capability caused by competitions of memory accesses from a plurality of processors is suppressed effectively. In a memory access controlling system for controlling accesses to a cache memory in a data read ahead process when the multi core processor of a shared memory type performs a task including a data read ahead thread for executing data read ahead and a parallel execution thread for performing an execution process in parallel with the data read ahead the system includes a data read ahead controller which controls an interval between data read ahead processes in the data read ahead thread adaptive to a data flow which varies corresponding to an input value of the parallel process in the parallel execution thread. By controlling the interval between the data read ahead processes competitions of memory accesses in the multi core processor are suppressed.

Document US 2010 0169895 A1 describes the method and system for inter thread communication using processor messaging. In shared memory computer systems threads may communicate with one another using shared memory. A receiving thread may poll a message target location repeatedly to detect the delivery of a message. Such polling may cause excessive cache coherency traffic and or congestion on various system buses and or other interconnects. A method for inter processor communication may reduce such bus traffic by reducing the number of reads performed and or the number of cache coherency messages necessary to pass messages. The method may include a thread reading the value of a message target location once and determining that this value has been modified by detecting inter processor messages such as cache coherence messages indicative of such modification. In systems that support transactional memory a thread may use transactional memory primitives to detect the cache coherence messages. This may be done by starting a transaction reading the target memory location and spinning until the transaction is aborted.

Document US 2010 0131720 A1 shows the management of ownership control and data movement in shared memory systems. It is a method to exchange data in a shared memory system includes the use of a buffer in communication with a producer processor and a consumer processor. The cache data is temporarily stored in the buffer. The method includes for the consumer and the producer to indicate intent to acquire ownership of the buffer. In response to the indication of intent the producer consumer buffer are prepared for the access. If the consumer intends to acquire the buffer the producer places the cache data into the buffer. If the producer intends to acquire the buffer the consumer removes the cache data from the buffer. The access to the buffer however is delayed until the producer consumer and the buffer are prepared.

Document US 2009 0106495 describes a fast inter strand data communication for processors with write through L1 caches. Therein a non coherent store instruction is used to reduce inter thread communication latency between threads sharing a level one write through cache. When a thread executes the non coherent store instruction the level one cache is immediately updated with the data value. The data value is immediately available to another thread sharing the level one write through cache. A computer system having reduced inter thread communication latency is disclosed. The computer system includes a first plurality of processor cores each processor core including a second plurality of processing engines sharing a level one write through cache. The level one caches are connected to a level two cache via a crossbar switch. The computer system further implements a non coherent store instruction that updates a data value in the level one cache prior to updating the corresponding data value in the level two cache.

Further thread to thread communication is described in US 2005 0289555 A1. A method for programmer controlled cache line eviction policy is shown in US 2006 0143396 A1. Further background is described in references 1 and 2 .

According to a first aspect an interface for inter thread communication between a plurality of threads including a number of producer threads for producing data objects and a number of consumer threads for consuming the produced data objects is suggested. The interface includes a specifier and a provider. The specifier is configured to specify a certain relationship between a certain producer thread of the number of producer threads which is adapted to produce a certain data object and a consumer thread of the number of consumer threads which is adapted to consume the produced certain data object. Further the provider is configured to provide direct cache line injection of a cache line of the produced certain data object to a cache allocated to the certain consumer thread related to the certain producer thread by the specified certain relationship.

According to some implementations data from the cache allocated to a producer thread may be directly sent to the cache allocated to the consumer thread of this data.

Thus the present interface may allow software developers to better exploit modern multi core hardware i.e. by cache line injection and particularly also by cache line eviction. Thus the operating system and the CPU memory module may be adequately modified. Therefore according to some implementations cache coherency overhead may be reduced inter chip communication may be reduced the impact of false sharing may be reduced and the number of thread migrations may be reduced. Further saturation of specific hardware constructs may be avoided and the scalability may be improved. Therefore the performance level of software using the present interface may be improved. The implementation of the mechanism of the proposed interface may be built on top of existing hardware features.

In an embodiment the interface is a programming tool in particular an Application Programming Interface API .

In a further embodiment the certain data object is embodied by a number of consecutive cache lines. Then the provider may be configured to provide direct cache line injection of the number of consecutive cache lines from the cache allocated to the certain producer thread to the cache allocated to the certain consumer thread related to the certain producer thread by the specified certain relationship.

In a further embodiment the provider is configured to provide direct cache line injection of a cache line of the produced certain data object from a cache allocated to the certain producer thread to a reserved space of the cache allocated to the certain consumer thread. The reserved space may be the top of the cache.

In a further embodiment the cache allocated to the certain consumer thread is organized by a number of default policies. The default policies may include First In First Out FIFO and write back.

In a further embodiment the provider is configured to provide direct cache line injection of the cache line of the produced data object to a top line of the certain FIFO cache allocated to the certain consumer thread.

In a further embodiment the cache allocated to the certain consumer thread is a reserved portion of a cache shared by the plurality of threads or an additional dedicated cache provided for the inter thread communication.

In a further embodiment the plurality of threads are configured to be executed on different cores and further configured to communicate by means of a shared data structure where data objects are moved from caches allocated to producer threads to caches allocated to consumer threads. Data objects moved from a cache allocated to a producer thread to a cache allocated to a consumer thread may include references to data accessed by the threads and stored in the main memory of the processor.

In a further embodiment the provider is configured to provide direct cache line eviction of a cache line of a cache allocated to the certain consumer thread in dependence on the specified certain relationship. Here evicting a cache line includes selectively removing the cache line from the cache.

In a further embodiment the provider is configured to evict a cache line from the cache allocated to the certain producer thread to a reserved portion of a cache shared by the plurality of threads.

In a further embodiment the provider is configured to evict all cache lines from the cache allocated to the certain producer thread to a reserved portion of the cache shared by the plurality of threads.

In a further embodiment the provider is configured to evict a cache line from the cache allocated to the certain producer thread to a reserved portion of a cache shared by the plurality of threads and to inject the cache line from the reserved portion of the cache shared by the plurality of threads to the cache allocated to the certain consumer thread.

In a further embodiment the provider is configured to evict all cache lines from the cache allocated to the certain producer thread to a reserved portion of the cache shared by the plurality of threads and to inject all the cache lines from the reserved portion of the cache shared by the plurality of threads to the cache allocated to the certain consumer thread.

Any embodiment of the first aspect may be combined with any embodiment of the first aspect to obtain another embodiment of the second aspect.

According to a second aspect a method for inter thread communication between a plurality of threads including a number of producer threads for producing data objects and a number of consumer threads for consuming the produced data objects is suggested. The method includes a step of specifying a certain relationship between a certain producer thread of the number of producer threads which is adapted to produce a certain data object and a consumer thread of the number of consumer threads which is adapted to consume the produced certain data object. Moreover the method includes a step of providing direct cache line injection of a cache line of the produced certain data object to a cache allocated to the certain consumer thread related to the certain producer thread by the specified certain relationship.

According to a third aspect a computer program is suggested which comprises a program code for executing the method of the above second aspect for inter thread communication between a plurality of threads when run on at least one computer.

For example the present interface may be also called Thread Communication API and may be exposed to ease thread communication at operating system OS level 

For example the present interface may be realized at operating system OS level by exposing the interface as an API to access the following CPU cache management instructions dcbfl and dcbtst. In case of dcbfl the contents of a modified data cache block are copied to the main storage and the copy of the block is made invalid in the data cache.

In case of dcbtst a hint is provided that the program will probably soon access a specified data cache block.

At hardware level a specific area of the cache may be reserved to facilitate thread communication. This area may be implemented in two different ways. In a first way a portion of the shared L3 cache may be reserved. In a second way a specific additional cache may be designed and used for this scope.

Further software developers may use the proposed interface to optimize inter thread communication in the following ways. First it may be indicated that a reference to a specific data structure can be evicted from the cache using the evictAll function which triggers a call to the dcbfl instruction of the CPU cache management module. Second it may be indicated that the reference to a specific data structure can be injected to the cache of the core on which a thread is executing using the inject function which triggers the call to the dcbtst instruction of the CPU cache management module. Third it may be indicated that the reference to a specific data structure has to be sent from one thread to another thread using both the sendTo and the receive functions.

In the following exemplary embodiments of the present invention are described with reference to the enclosed figures.

Similar or functionally similar elements in the figures have been allocated the same reference signs if not otherwise indicated.

In a schematic block diagram of an embodiment of an interface for inter thread communication is depicted.

The interface is configured for inter thread communication between a plurality of threads T T see e.g. . The plurality of threads T T includes a number of producer threads T for producing data objects O and a number of consumer threads T for consuming the produced data objects O.

The interface includes a specifier and a provider . The specifier is configured to specify a certain relationship between a certain producer thread T of the number of producer threads which is adapted to produce a certain data object O and a consumer thread T of the number of consumer threads which is adapted to consume the produced certain data object O. In other words a certain relationship is specified or determined between the certain producer thread T and the certain consumer thread T if the producer thread T produces a certain data object O which is consumed by the certain consumer thread T in the following.

Moreover the provider is configured to provide direct cache line injection of a cache line of the produced certain data object O to a cache allocated to the certain consumer thread T related to the certain producer set T by the specified certain relationship see e.g. .

The interface is in particular a programming tool provided for a programmer. For example the interface is an Application Programming Interface API .

Functions of the interface of are described with reference to the first example for inter thread communication of and the second example for inter thread communication of the . In the following the first and second example for inter thread communication of and are described in detail. Without loss of generality the first and second example show only two threads T T including one producer thread T and one consumer thread T.

For the case that a certain data object O is embodied by a number of consecutive cache lines the provider may be configured to provide direct cache line injection of the number of consecutive cache lines from the cache allocated to the certain producer thread T to the cache allocated to the certain consumer thread T related to the certain producer thread T by the certain relationship specified by the specifier .

Moreover the provider may be configured to provide direct cache line injection of the cache line of the produced certain data object O from the cache allocated to the certain producer thread T to a reserved space of the cache allocated to the certain consumer thread T. The cache allocated to the certain consumer thread T may be organized by a number of default policies in particular including FIFO and write back.

In this case the provider may be configured to provide direct cache line injection of the cache line of the produced data object O to a top line of the certain FIFO cache allocated to the certain consumer thread T.

Moreover the plurality of threads T T may be configured to be executed on different cores see for example and may be further configured to communicate by means of a shared data structure. Therein data objects O are moved from caches allocated to producer threads T to caches allocated to consumer threads T.

Furthermore the provider may be configured to provide direct cache line eviction of a cache line of a cache allocated to the certain consumer thread T in dependence on the specified certain relationship. In this regard eviction may mean selectively removing the cache line from the cache allocated to the certain producer thread T to the reserved portion of a cache shared by the plurality of threads T T see for example .

Further with reference to the provider may be configured to evict a cache line from the cache allocated to the certain producer thread T to a reserved portion of a cache shared by the plurality of threads T T and to inject the cache line from the reserved portion of the cache shared by the plurality of threads T T to the cache allocated to the certain consumer thread T. In this regard the provider may be also configured to evict all cache lines from the cache to the reset portion and to inject all these cache lines from the reserved portion to the cache allocated to the certain consumer thread see for example .

In a producer thread T is depicted which is executed by a core X wherein a cache X is allocated to the core X . Further in a consumer thread T is depicted which is executed on the core Y which has an allocated cache Y . Further a reserved cache Y is shown. In a reference to a memory location embodied by a data object O is evicted from the cache X and inserted in the reserved cache Y by the command sendTo T function called by the thread T. According to the data object O contained in the reserved cache Y is moved to the cache Y by a certain function called by the consumer thread T.

The second example for inter thread communication is depicted in . show a computer system having a number of cores core A core X and core Y .

With reference to core X is executing a thread T and the core Y is executing a thread T. Each of the cores has an allocated unshared cache A cache X and cache Y . Further the computer system has a shared cache which includes a reserved cache for inter thread communication.

The following example comprised of steps to illustrated in shows the functionality of the present inter thread communication of . In step thread T executed on core X produces some data O in its unshared cache X .

In step thread T knows it doesn t need the produced data O anymore. Therefore thread T uses the present interface which is shown in by the evict command and the receive command to evict the data object O from the unshared cache X to the reserved cache . In this regard the operating system may be modified such that the command evict is exposed to the users. Further the hardware of the computer system may be modified such that the data object O is copied to the reserved cache as shown in .

In step thread T executed on core Y needs the data object O produced by thread T and receives it from the reserved cache by the receive command. Therefore thread T uses the interface to provide a hint to the reserved cache that the data object O is to be accessed. Also here the operating system may be modified such that the receive command is exposed to the users and the hardware is modified such that it may search in the reserved cache . If data object O is there as shown in the data object O is injected into the unshared cache Y of the core Y .

In an embodiment of a sequence of method steps for inter thread communication between a plurality of threads including a number of producer threads for producing data objects and a number of consumer threads for consuming the produced data objects is depicted.

In step a certain relationship between a certain producer thread of the number of producer threads which is adapted to produce a certain data object and a consumer thread of the number of consumer threads which is adapted to consume the produced certain data object is specified.

In step a cache line of the produced certain data object is directly injected to a cache allocated to the certain consumer thread related to the certain producer thread by the specified certain relationship.

Computerized devices can be suitably designed for implementing embodiments of the present invention as described herein. In that respect it can be appreciated that the methods described herein are largely non interactive and automated. In exemplary embodiments the methods described herein can be implemented either in an interactive partly interactive or non interactive system. The methods described herein can be implemented in software e.g. firmware hardware or a combination thereof. In exemplary embodiments the methods described herein are implemented in software as an executable program the latter executed by suitable digital processing devices. In further exemplary embodiments at least one step or all steps of above method of may be implemented in software as an executable program the latter executed by suitable digital processing devices. More generally embodiments of the present invention can be implemented wherein general purpose digital computers such as personal computers workstations etc. are used.

For instance the system depicted in schematically represents a computerized unit e.g. a general purpose computer. In exemplary embodiments in terms of hardware architecture as shown in the unit includes a processor memory coupled to a memory controller and one or more input and or output I O devices or peripherals that are communicatively coupled via a local input output controller . The input output controller can be but is not limited to one or more buses or other wired or wireless connections as is known in the art. The input output controller may have additional elements which are omitted for simplicity such as controllers buffers caches drivers repeaters and receivers to enable communications. Further the local interface may include address control and or data connections to enable appropriate communications among the aforementioned components.

The processor is a hardware device for executing software particularly that stored in memory . The processor can be any custom made or commercially available processor a central processing unit CPU an auxiliary processor among several processors associated with the computer a semiconductor based microprocessor in the form of a microchip or chip set or generally any device for executing software instructions.

The memory can include any one or combination of volatile memory elements e.g. random access memory and nonvolatile memory elements. Moreover the memory may incorporate electronic magnetic optical and or other types of storage media. Note that the memory can have a distributed architecture where various components are situated remote from one another but can be accessed by the processor .

The software in memory may include one or more separate programs each of which comprises an ordered listing of executable instructions for implementing logical functions. In the example of the software in the memory includes methods described herein in accordance with exemplary embodiments and a suitable operating system OS . The OS essentially controls the execution of other computer programs such as the methods as described herein e.g. and provides scheduling input output control file and data management memory management and communication control and related services. For example the interface may be embodied in the OS .

The methods described herein may be in the form of a source program executable program object code script or any other entity comprising a set of instructions to be performed. When in a source program form then the program needs to be translated via a compiler assembler interpreter or the like as known per se which may or may not be included within the memory so as to operate properly in connection with the OS . Furthermore the methods can be written as an object oriented programming language which has classes of data and methods or a procedure programming language which has routines subroutines and or functions.

Possibly a conventional keyboard and mouse can be coupled to the input output controller . Other I O devices may include sensors especially in the case of network elements i.e. hardware devices that produce a measurable response to a change in a physical condition like temperature or pressure physical data to be monitored . Typically the analog signal produced by the sensors is digitized by an analog to digital converter and sent to controllers for further processing. Sensor nodes are ideally small consume low energy are autonomous and operate unattended.

In addition the I O devices may further include devices that communicate both inputs and outputs. The system can further include a display controller coupled to a display . In exemplary embodiments the system can further include a network interface or transceiver for coupling to a network .

The network transmits and receives data between the unit and external systems. The network is possibly implemented in a wireless fashion e.g. using wireless protocols and technologies such as WiFi WiMax etc. The network may be a fixed wireless network a wireless local area network LAN a wireless wide area network WAN a personal area network PAN a virtual private network VPN intranet or other suitable network system and includes equipment for receiving and transmitting signals.

The network can also be an IP based network for communication between the unit and any external server client and the like via a broadband connection. In exemplary embodiments network can be a managed IP network administered by a service provider. Besides the network can be a packet switched network such as a LAN WAN Internet network etc.

If the unit is a PC workstation intelligent device or the like the software in the memory may further include a basic input output system BIOS . The BIOS is stored in ROM so that the BIOS can be executed when the computer is activated.

When the unit is in operation the processor is configured to execute software stored within the memory to communicate data to and from the memory and to generally control operations of the computer pursuant to the software. The methods described herein and the OS in whole or in part are read by the processor typically buffered within the processor and then executed. When the methods described herein e.g. with reference to are implemented in software the methods can be stored on any computer readable medium such as storage for use by or in connection with any computer related system or method.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon. Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device. Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the unit partly thereon partly on a unit and another unit similar or not.

Aspects of the present invention are described above with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams can be implemented by one or more computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the blocks may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved and algorithm optimization. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

More generally while the present invention has been described with reference to certain embodiments it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted without departing from the scope of the present invention. In addition many modifications may be made to adapt a particular situation to the teachings of the present invention without departing from its scope. Therefore it is intended that the present invention not be limited to the particular embodiments disclosed but that the present invention will include all embodiments falling within the scope of the appended claims.

