---

title: Collaborative modeling environment
abstract: determine whether to provide the model in a list of models created for the search query, based on the one or more sequences of characters and the group of tags.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09323851&OS=09323851&RS=09323851
owner: The MathWorks, Inc.
number: 09323851
owner_city: Natick
owner_country: US
publication_date: 20121106
---
This application is a Continuation of application Ser. No. 13 185 243 filed Jul. 18 2011 for a Collaborative Modeling Environment by Pieter J. Mosterman et al. which is a continuation of application Ser. No. 11 687 510 filed Mar. 16 2007 for a Collaborative Modeling Environment by Pieter J. Mosterman et al. which applications are hereby incorporated by reference in their entireties.

Models may be designed for numerical simulations or for other purposes. In some instances a model designer may need to design a portion of a model e.g. a pump of a waste water treatment plant with which the model designer does not have a high level of familiarity. The model designer may make assumptions regarding the unfamiliar portion that are different than the way the portion actually works. Thus the model may not be completely accurate.

In one embodiment a computer readable medium may store instructions executable by at least one processor for searching for models. The computer readable medium may include instructions for receiving a search query from a model creation environment instructions for performing a search to identify a list of models from a model repository based on the search query instructions for providing the identified list of models instructions for receiving a request for one model in the identified list of models and instructions for providing the one model to the model creation environment based on receiving the request.

In another embodiment a computer readable medium may store instructions executable by at least one processor. The computer readable medium may include instructions for receiving a model from a user device instructions for obtaining information for the received model by executing the received model and instructions for creating first tags using the obtained information the created tags being at least one or a combination of displayed to a user or used as part of a model search.

In another embodiment a computer readable medium may store instructions executable by at least one processor. The computer readable medium may include instructions for receiving a model from a user device instructions for obtaining information for the received model the obtained information including at least one or a combination of a number of input ports for the model one or more characteristics of the input ports a number of output ports for the model one or more characteristics of the output ports whether the model uses continuous time integration or discrete time integration whether the model is self contained information identifying a number of subsystems within the model a number of charts in the model a number of discrete states in the model whether the model adheres to one or more modeling standards annotations added to the model or review information about an author of the model and instructions for at least one or a combination of displaying the obtained information to a user or using the obtained information to determine whether the received model relates to a search query.

In another embodiment a computer readable medium may store instructions executable by at least one processor. The computer readable medium may include instructions for detecting a single selection of an element in a model creation environment that includes a model and instructions for transmitting a portion of the model to a modeling infrastructure in response to detecting the single selection. The transmitting may cause the portion of the model to be published by the modeling infrastructure.

In still another embodiment a computer readable medium may store instructions executable by at least one processor. The computer readable medium may include instructions for detecting selection of an element in a model creation environment instructions for providing a search dialog box in response to detecting the selection where the search dialog box allows for a model search to be performed instructions for receiving a search query and instructions for transmitting information relating to the search query to a remote location.

In still yet another embodiment a computer readable medium may store instructions executable by at least one processor. The computer readable medium may include instructions for receiving a search query instructions for identifying a list of models in response to receiving the search query the identifying including relating the search query to information extracted from the identified models and instructions for providing the list of models to a user.

In another embodiment a computer readable medium may store instructions executable by at least one processor. The computer readable medium may include instructions for receiving a model instructions for extracting information from the model instructions for forming a group of tags using the extracted information instructions for associating the group of tags with the model instructions for receiving a search query including one or more sequences of characters and instructions for determining whether to provide the model in a list of models created for the search query based on the one or more sequences of characters and the group of tags.

In yet another embodiment a computer readable medium may store stores instructions executable by at least one processor. The computer readable medium may include instructions for automatically searching for models instructions for retrieving a model in response to the searching and instructions for executing the model using a program to determine whether an issue exists with the model or with the program.

In still yet another embodiment a computer readable medium may store instructions executable by at least one processor. The computer readable medium may include instructions for providing access to a model to a remote model creation environment and instructions for transmitting a rating for the model to the remote model creation environment for display in the remote model creation environment.

In another embodiment a computing device implemented method may include receiving a model at a modeling infrastructure making the model available for peer review and publishing via the modeling infrastructure based on the peer review.

The following detailed description of exemplary embodiments refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements. Also the following detailed description does not limit the invention.

Systems and methods described herein may provide a modeling infrastructure that allows users to make models available to other users and to obtain models of interest. is an exemplary diagram illustrating a concept consistent with exemplary embodiments. As illustrated in a modeling infrastructure may receive a model such as a Simulink modeling environment model from a user and process the model to allow the model to be shared with other users. In one embodiment the modeling infrastructure may allow a user to share a model with other users e.g. publish the model via a 1 click or simplified process. In this embodiment the modeling infrastructure may extract information from the received model and associate the extracted information with the model e.g. as tags . The modeling infrastructure may also allow users to search and obtain models that have been shared e.g. uploaded to the modeling infrastructure and or indicated to the modeling infrastructure as available for sharing . In essence the modeling infrastructure may provide a model sharing ecosystem where users can easily share models with other users and obtain models of interest. In some embodiments users may share comments regarding models that are available via the modeling infrastructure and may rate these models. In this way users can use other users opinions to distinguish between two possible models of interest.

A document as the term is used herein is to be broadly interpreted to include any machine readable and or machine storable work product. A document may include for example an e mail a file a dialog a combination of files one or more files with embedded links to other files a graphical user interface etc. In the context of the Internet a common document is a web page. Documents often include textual information and may include embedded information such as meta information images hyperlinks etc. and or embedded instructions such as Javascript etc. . A tag as used herein may broadly include any type of data that may be used to relate information to an object. An example of a tag may include a meta tag or another type of tag. A model may be broadly defined as a representation of something e.g. an object a system etc. . A computational model may be broadly defined as a model that contains an element that represents computation. A computational model may be associated with static and or dynamic semantics. The computational model may include entities. Relations between the entities may be explicitly represented. In graphical models these relations may be represented as lines. In textual models these relations may represented based on the order of syntactic entities in a sentence. A computational model with dynamic semantics can be interpreted by an execution engine to generate a behavior where a behavior refers to a change of value of a variable. Dynamic models may include one or more data structures to represent elements that capture aspects of the dynamics e.g. the behavior . Examples of such aspects may include the identity of the values that represent how a new value of a variable is computed e.g. the value of a derivative of a variable with respect to time or a time delayed value of a variable how the sequence of values is constructed whether it is as a relation with an independent variable e.g. time whether the values should be computed with a given period etc. As such in a dynamic model a variable can assume multiple values when evaluated. These aspects for different model elements are often related for example to ensure integrity and consistency and can be automatically derived and reconciled by model processing.

User devices may include user entities. An entity may be defined as a device such as a personal computer a laptop a personal digital assistant PDA a smartphone or another type of computation or communication device a thread or process running on one of these devices and or an object executable by one of these devices. Modeling infrastructure may include one or more hardware and or software components that receive models and information relating to models from user devices and provide user devices with the ability to access the models.

Network may include a local area network LAN a wide area network WAN a metropolitan area network MAN a telephone network such as the Public Switched Telephone Network PSTN or a cellular network an intranet the Internet or a combination of networks. User devices and modeling infrastructure may connect to network via wired and or wireless connections.

It will be appreciated that a user device may perform one or more acts described below as being performed by modeling infrastructure and that modeling infrastructure may perform one or more acts described below as being performed by a user device .

Processor may include a processor microprocessor or processing logic that may interpret and execute instructions. Main memory may include a random access memory RAM or another type of dynamic storage device that may store information and instructions for execution by processor . ROM may include a ROM device or another type of static storage device that may store static information and instructions for use by processor . Storage device may include a magnetic and or optical recording medium and its corresponding drive.

Input device may include a mechanism that permits an operator to input information to user device such as a keyboard a mouse a pen voice recognition and or biometric mechanisms an accelerometer or gyroscope based motion input device a camera etc. Output device may include a mechanism that outputs information to the operator including a display a printer a speaker etc. Communication interface may include any transceiver like mechanism that enables user device to communicate with other devices and or systems. For example communication interface may include mechanisms for communicating with modeling infrastructure via a network such as network .

As will be described in detail below user device consistent with exemplary embodiments may perform certain processing related operations. User device may perform these operations in response to processor executing software instructions contained in a computer readable medium such as memory . A computer readable medium may be defined as a physical or logical memory device and or carrier wave.

The software instructions may be read into memory from another computer readable medium such as data storage device or from another device via communication interface . The software instructions contained in memory may cause processor to perform processes that will be described later. Alternatively hardwired circuitry may be used in place of or in combination with software instructions to implement processes described herein. Thus embodiments described herein are not limited to any specific combination of hardware circuitry and software.

User interface module may include one or more software and or hardware components that provide documents to user devices. For example in one embodiment user interface module may provide documents that allow users to search for and obtain models of interest.

Model ratings module may include one or more software and or hardware components that allow users to rate models that are associated with model infrastructure . In one embodiment model ratings module may receive rating information from a user and may determine a rating for a model based on the received rating information. In some embodiments model ratings module may determine more than one rating for a model. Each rating may be associated with a different rating characteristic such as operating speed memory usage sensitivity to disturbances number of zero crossings performance on Japanese platform etc. Thus as an example the ratings associated with a model may indicate that the model runs slowly takes a lot of memory is very sensitive to disturbances includes a lot of zero crossings cannot run well on Japanese platform etc.

Model execution module may include one or more software and or hardware components that determine whether models function properly. In one embodiment model execution module may receive or access a model and may execute the model to verify the model s functional status. If the model does not function properly e.g. an error is produced when the model is executed model execution module may for example notify the user that the model cannot be shared.

Tag extraction module may include one or more software and or hardware components that create tags or other forms of data that allow for searching of models for a given model. In one embodiment tag execution module may receive a model analyze the model to identify characteristics of the model and associate the extracted information as tags with the model. The information may include any information that would be of interest to a user searching for a model. For example the information may include information indicating the complexity e.g. cyclomatic complexity of the model the number of warnings that an editing style is violated the number of input ports for the model and characteristics of the input ports the number of output ports for the model and characteristics of the output ports whether the model uses continuous time integration or discrete time integration whether the model is self contained information identifying the number of subsystems within the model information identifying a product or products on which the model relies e.g. a user will need to have or obtain a license for a particular product annotations added to the model the software that was used to create the model the version of the software that was used to create the model whether the model adheres to certain modeling standards e.g. whether the model results in Motor Industry Software Reliability Association MISRA compliant code whether the model can be used in DO B certification etc. the coverage of model functionality when executed e.g. the percent decision coverage condition coverage condition decision coverage modified condition decision coverage etc. etc.

Search module may include one or more software and or hardware components that allow users to search for models. For example search module may include a model search engine in which a user may enter search terms and or other search criteria. Search module may use the search terms and or search criteria to identify a list of candidate models.

Model database may include one or more databases that may store models which includes storing actual models a portion of the models links to models e.g. in the form of uniform resource locators URLs etc. and information relating to models such as tags user reviews or comments ratings cost etc. In some instances model database may be considered a repository of models and information relating to models. In one embodiment model database may store a model including all of the model s dependent files e.g. parameter files in a single file or virtual group. The single file may include for example a single project a single zipped file a single archive etc. In this way a user can download a single file that includes all of the information for executing a model. Database may include one or more physical databases which may be located at modeling infrastructure or one or more remote locations in network or may represent a conceptual database repository of models.

Although shows exemplary components of modeling infrastructure in other embodiments modeling infrastructure may include fewer different or additional components than depicted in . Moreover one or more components of modeling infrastructure may perform one or more functions of one or more other components of modeling infrastructure .

Processing may begin with modeling infrastructure detecting an indication to share a model block . Modeling infrastructure may receive a request to share a model from user device and in response may establish a connection with user device . In other embodiments a connection between modeling infrastructure and user device may be established before receiving the request. As part of establishing the connection with user device modeling infrastructure may authenticate the user of user device . For example modeling infrastructure may request that the user of user device provide a user identifier and possibly a password.

As an alternative to or in addition to providing the ability to share a model via a menu element a user may share a model in other ways. For example as illustrated in a user who has created a model may right click on the model to cause a pop up menu to appear in a document . Similar to SHARE menu element pop up menu may be associated with a SHARE REMOTELY menu item and a SHARE LOCALLY menu item that may allow the user to perform the operations described above. As yet another alternative and as illustrated in dedicated buttons and may be provided in a document to allow the user to share the model remotely and locally respectively. In one embodiment the model that is to be shared may be represented by an element in another model. For example right clicking on that element may cause a pop up menu to be displayed that allows only that element to be shared. If the element is a referenced model the interface information may be available. If the element is a subsystem some model processing may occur to infer the interface information.

Returning to the processing of modeling infrastructure may receive the created model from user device block . In one embodiment user device may transfer the created model to modeling infrastructure regardless of whether the user indicates that the model is to be shared remotely or locally.

Modeling infrastructure may execute the received model block . Modeling infrastructure may execute the model to determine whether the model is actually functional. If the model executes without an error occurring modeling infrastructure may determine that the model is functional. If on the other hand execution of the model produces an error modeling infrastructure may determine that the model is not functional. In other embodiments additional criteria or other criteria may be used to determine if a received model is functional. Execution of the model may alternatively or additionally include processing the received model in other ways. For example modeling infrastructure may perform a consistency check on the connections included in the model to determine for example whether data types match whether interface timing information matches etc. In some embodiments some information may be obtained by compiling the model without executing the model. Compiling a model performs model processing to obtain all model attributes to be used for execution e.g. the sample rate of all blocks in a block diagram and the data types of all model variables . Compiling a model may also perform optimizations by removing superfluous model elements by combining computations such as replacing two consecutive multiplications with constant factors by one multiplication with the aggregate factor by reducing computations that provide the same result for each evaluation during a behavior to a constant value etc.

If modeling infrastructure determines the model is not functional block NO modeling infrastructure may notify the user that the attempt to share the model failed block . illustrates an exemplary notification message that may be provided to the user if an attempt to share the model failed. In some embodiments notification message may include buttons such as buttons and that allow the user to continue to share the non operational model in the manner described below or not share the non operational model respectively. Other ways of notifying the user are also possible. For example modeling infrastructure may transmit a notification via e mail instant message or in another manner.

If modeling infrastructure determines the model is functional block YES modeling infrastructure may analyze the model to extract information regarding the model block . This analysis may include interpreting the model compiling the model and or executing the model. As indicated above the extracted information may include any information that a user may find important when searching for a model. For example the extracted information may include information indicating the complexity e.g. cyclomatic complexity of the model the number of input ports for the model and characteristics of the input ports e.g. data type sample rate etc. the number of output ports for the model and characteristics of the output ports whether the model uses continuous time integration or discrete time integration whether the model is self contained information identifying the number of subsystems within the model whether the model adheres to certain modeling standards e.g. whether the model results in MISRA compliant code whether the model can be used in DO B certification etc. information identifying a product or products on which the model relies e.g. a user will need to have or obtain a license for a particular product annotations added to the model the software used to create the model the version of the software that was used to create the model information about an author of the model and or other information. For example other information that may be extracted may include information identifying the number of state transition diagrams charts that are present in a model information relating to state machine elements e.g. how many AND states are in the model how many OR states are in the model how may substrates are in the model how many graphical functions are in the model how many history junctions are in the model how many junctions are in the model how many events are registered in the model how many input events are in the model how many output events are in the model characteristics of a state machine embedded in a block diagram such as a sample rate etc. whether the state transition diagram follows a style such as Moore or Mealy information relating to class diagrams that may be in the model e.g. how many classes how deep the hierarchy is whether there is multiple inheritance whether interface classes are used how many private protected and public elements are present etc. etc. For scenario diagrams in the model modeling infrastructure may extract information relating to how many messages are passed between timelines how many timelines there are whether preemption is present etc. Modeling infrastructure may create tags using the extracted information block . These tags may be considered as machine provided tags.

Modeling infrastructure may receive information regarding the model from the user block . The information may include for example the user s description of the model e.g. the operating range in which the model should be executed information about the user e.g. contact information for the user such as an e mail address an instant messenger identifier a telephone number Internet Protocol IP address voice over internet protocol VoIP address etc. the user s education the number of models that the user has shared etc. and or other information. In addition the information may include any or all of the information that may be extracted from the model. Some or all of this user provided information may be used to create tags block . Moreover the user may provide tags to be associated with the model. The foregoing tags may be considered as user provided tags.

Modeling infrastructure may also receive information about the user from other users. For example other users may provide information indicating how prompt the user was in providing help regarding his her model whether the user produced good models in the past whether the user explains his her models well etc. Some or all of this information may also be used to create tags. These tags may also be considered as user provided tags.

Modeling infrastructure may associate the machine provided tags and the user provided tags with the model block . Modeling infrastructure may further store the model. For example in those situations where the user had indicated that the model is to be shared remotely modeling infrastructure may store the model or a link to the model on a remote device and the tags in database . In those situations where the user had indicated that the model is to be shared locally modeling infrastructure may discard the model and store a link to the model e.g. on user device and the tags in database . Once the model has been processed by modeling infrastructure the model can be considered as published e.g. available for sharing .

In one embodiment a model may undergo a review process such as by peers prior to becoming published. For example after some or all of the above processing a received model may be submitted to one or more model evaluators to determine whether the model is acceptable for publishing. In some situations a model evaluator s may send a received model back to the author for revisions. The model may be revised until the model is accepted by the model evaluator s . Once accepted by the model evaluator s the model may be published. Moreover additional documents can be included with the model submission such as descriptions of how model parameters were derived what laws of physics were employed to design the model explanations on potential and actual model use what assumptions were made about the model etc.

Once the model has been made available for sharing modeling infrastructure may in one embodiment use a version control system to manage revisions of the model. For example changes to the model may be identified by incrementing an associated revision number or letter code.

In one embodiment modeling infrastructure may re execute the model when the model creation environment has been updated. Modeling infrastructure may send notifications based on a result of the re execution.

Processing may begin with modeling infrastructure receiving a review for a model block . Modeling infrastructure may for example provide a document such as document to a user of a user device . Document may include an area that allows the user to comment on or review the model being displayed in document . Once the user has entered a comment or review in area the user may elect to post the comment by selecting button or discard the comment by selecting button . In some embodiments modeling infrastructure may request that the user log in to modeling infrastructure by for example providing a user identifier and possibly a password before the user is allowed to post a comment.

Modeling infrastructure may associate the review with the model block . For example modeling infrastructure may store the review in database . Modeling infrastructure may also associate the review with information identifying the user who provided the review. Thereafter if the model is later viewed user s review may be displayed as illustrated in .

Processing may begin with modeling infrastructure receiving rating information for a model block . Modeling infrastructure may for example provide a document such as document to a user of a user device . Document may include an area that allows the user to rate the model being displayed in document . The user may for example click on one of the stars to rate the model. Other techniques for rating a model may alternatively be used. Assume as illustrated in that the user clicks on the right most star giving the model a rating of five stars . In some embodiments modeling infrastructure may request that the user log in to modeling infrastructure by for example providing a user identifier and possibly a password before the user is allowed to rate a model.

Returning to the process of modeling infrastructure may determine a rating for the model using the received rating information block . For example modeling infrastructure may take the average of all of the ratings received for the model. Other techniques for determining a rating may alternatively be used. For example modeling infrastructure may take the mean and its variance of all of the ratings received for the model the maximum and minimum of all of the ratings received for the model etc.

Modeling infrastructure may associate the determined rating with the model block . For example modeling infrastructure may store the determined rating in database . Thereafter if a document is provided that includes the model a new rating may be displayed as illustrated in .

Processing may begin with modeling infrastructure receiving a search query from a user of a user device block . Assume as illustrated in that a user is in the process of creating a model using a model creation environment document . The user may insert an element into the model where the user wants to insert another model into the model being created. By selecting element a search dialog box may be presented to the user. The user may enter a search query into search dialog box to cause user device to transmit the search query to modeling infrastructure . Search dialog box may be associated with an advanced search feature and a preferences feature as will be described in further detail below. The user may cause search dialog box to appear in other ways. For example model creation environment may provide a menu item that if selected causes search dialog box to appear.

As an alternative to accessing a search dialog box via a model creation environment the user may connect to modeling infrastructure or another device to access a search dialog box. For example assume as illustrated in a user connects to modeling infrastructure and requests a document that allows the user to search for a model of interest. As illustrated in document may include a search dialog box an advanced search feature and a preferences feature . Search dialog box may allow the user to enter a search query for a model and transmit the search query to modeling infrastructure for processing. If advanced search feature is selected e.g. by clicking on it modeling infrastructure may provide a document as illustrated in . Document may allow the user to specify criteria for performing a current search for a model. For example document may allow the user to specify one or more sequences of characters that may appear in a title associated with a model one or more sequences of characters that may appear in a user description of a model a level of complexity for a model the number of input ports contained in the model and or a range for the number of input ports in the model e.g. less than 10 between 5 and 10 more than 5 etc. the number of output ports contained in the model and or a range for the number of output ports in the model e.g. less than 10 between 5 and 10 more than 5 etc. characteristics of the input ports and or output ports such as data type sample rate etc. a date or date range when the model was added to modeling infrastructure an author of a model associated with modeling infrastructure a location or group of locations e.g. one or more web sites where the model search is to be performed rating information such as only provide models that have been rated as four stars or above whether the model uses continuous time integration or discrete time integration whether the model is self contained the number of subsystems within the model the identify of the software and or the version of the software that was used to create the model and or other information.

If preferences feature is selected e.g. by clicking on it modeling infrastructure may provide a document as illustrated in . Document may allow the user to specify criteria for performing searches for a model. For example document may allow the user to specify a language in which document and other documents are to be presented to the user the language in which the user is going to provide the search query the number of results to display on a single page and or other information.

Returning to the process of modeling infrastructure may identify a list of models based on the received search query block . Modeling infrastructure may use any well known searching technique to identify the list of models. The searching technique may involve acts that are different than merely filtering a list of models based for example on a name. For example modeling infrastructure may match the one or more sequences of characters in the search query to the data associated with the models e.g. tags or other information . Modeling infrastructure may also rank the models in the list based for example on how closely the models match the one or more sequences of characters in the search query or on other criteria .

Modeling infrastructure may provide the list of models to the user block . For example modeling infrastructure may cause a document such as document illustrated in which contains the list of models to be provided to the user. As illustrated in document may include an image section a title section a description section a tags section an author section a downloads section a cost section a rating section and a reviews section .

Image section may include a snapshot of the model e.g. a high level block diagram or other image of the model . Alternatively image section may include another image related or unrelated to the model e.g. an image of the author of the model an image selected by the author or another source etc. . In one embodiment document may allow the user to execute a portion of the model by for example clicking on the snapshot in image section . Title section may include a title associated with the model. Description section may include a description or a portion of the description that was provided by the author of the model. In other instances description section may include a description or a portion of the description provided by another source e.g. an administrator associated with modeling infrastructure . Tags section may include a list of one or more of the tags associated with the model. Author section may include a name or identifier of the author of the model. In one embodiment selection of the author s name may cause further information about the user to be provided such as background information and or contact information for the author. In another embodiment selection of the author s name may cause an instant messenger or e mail program to be launched to allow the user to transmit a question or comment to the author. In yet another embodiment the authors may be notified by modeling infrastructure upon occurrence of some events such as for example that one of the models of their creation has been downloaded. Downloads section may provide information regarding the number of times that users have downloaded or obtained the model. Cost section may including information indicating how much it costs to download or obtain the model. The models may cost a certain amount of money or may be free. In some embodiments the models may be auctioned off to the highest bidder or immediately sold to a bidder who offers a minimum amount. Rating section may indicate a rating associated with the model. Reviews section may provide an indication of how many users have reviewed the model. In one embodiment selection of the number of reviews may cause a document to be provided to the user that includes all or a portion of the reviews for the model. In one embodiment some or all of the reviews may be selectively accessible to the user e.g. based on user privileges a date stamp etc. .

It will be appreciated that document may include additional information or other information than illustrated in . For example document may provide an indication of quality for a model in document in a number of categories. The categories may include cyclomatic complexity of the model the number of semantic and or syntax errors in the model the number of potential problems with the model the amount of help files associated with the model the number of issues that exist with respect to file naming the amount of duplicate functionality or code included in the model and or other categories. Moreover document may also provide an indication as to how the model compares to other models in the above categories and or other categories.

Returning to the process of modeling infrastructure may detect selection of one of the models provided in the list of models block . For example the user may select a model by for example clicking on the image in image section the title in title section or another portion of document . In response to detecting selection of a model modeling infrastructure may provide additional details regarding the model block . For example modeling infrastructure may provide a document such as document illustrated in . In addition to the model information provided in document document may provide a full description of the model provided by the user or another user reviews of the model a larger number of tags associated with the model etc. Document may also include a button or other element that allows the user to obtain the model.

Returning to the process of modeling infrastructure may receive a request for the model block . For example assume that the user selects GET IT button in document . In response the user s user device may transmit a request for the model to modeling infrastructure .

In those situations where the requested model is associated with a fee the user may be requested to pay the fee prior to obtaining the model. The payment of the fee could be handled between the two parties directly i.e. between the author of the model and the user purchasing the model or may involve a third party mediator.

Modeling infrastructure may provide the model to the user in response to the request block . In some embodiments modeling infrastructure may request that the user log in to modeling infrastructure e.g. by providing a user identifier and possibly a password to modeling infrastructure prior to providing a model. In those situations where the model is shared remotely e.g. stored in modeling infrastructure modeling infrastructure may allow the user to download the model or connect to the model via for example a Transmission Control Protocol TCP Internet Protocol IP connection or other type of connection. In those situations where the model is shared locally by the author modeling infrastructure may provide instructions or a link for downloading the model from the author s user device or connecting to the model via for example a TCP IP connection or other type of connection. In either situation the obtained model may be manually or automatically inserted into the element e.g. element in in the model that the user is creating. In this way a user may easily search for and obtain models of interest.

Transferring the requested model to the user e.g. for inclusion in another model being created by the user may allow the model or part of the model to undergo some initial processing. For example if the actual content of the model is available rather than only an interface that allows communication of numerical data such as in co simulation inherited characteristics of the model can be supported. For example the model or part of the model can inherit the sample rate from where the model is used. Since access to the model s internals is available the sample rate of the context where the model is used can be used to establish the sample rates of elements in the received model. This may be accomplished by propagating the sample rate into the model or part of the model . Also optimizations may be applied to the model or model part. Moreover since access to the model s internals is available the internals can be for example reduced in complexity while maintaining functionality. This reduction in complexity can be performed locally i.e. within the model or model part but also based on the context in which the model or model part is used. For example if the context in which the model or model part is used is known some of the functionality of the model or model part may be removed or the model or model part may be executed differently to obtain an overall more efficient execution. In some embodiments the model or model part may be processed to obtain a more complex or simplified version. For example nonlinear blocks within the model or model part may be replaced by their linear approximation within a given tolerance that may be user provided.

In some embodiments once the obtained model is inserted into the element e.g. element in or the reference to the model is obtained information available through modeling infrastructure regarding the obtained model may be displayed in the model creation environment. For example in one embodiment a rating of the model as determined by modeling infrastructure may be displayed on element . The rating may be represented by stars numbers or in another manner. The displayed rating may be dynamically updated as modeling infrastructure changes the rating for the obtained model. As an example a user may obtain a model that at the time of obtaining the model is rated as 4 stars. Assume that over time the rating of the model decreases to 1 star. This decreased rating may be reflected in the modeling creation environment to the user who obtained the model. Thus the user may decide in this situation to obtain another model due to the low rating that the model has achieved. In an alternative embodiment the rating will continue to reflect the rating at the time when the user has initially obtained the model. In yet another embodiment the rating may reflect both the initial rating and or the updated rating and the user s own rating. The proportional significance of each of those parameters may be different in different embodiments.

The following example set forth in illustrates how models in a model repository e.g. models associated with modeling infrastructure or models stored on a network such as the Internet may be accessed from a model creation environment. In example the model creation environment may be used to design textual models. As illustrated in user interface may include two main interface windows a main window and a command window .

Main window provides a user with the ability to access models associated with modeling infrastructure . In example the model repository is marked Home and alternate repositories may be accessible. Each repository may be associated for example with a separate tab in main window . Models may be grouped into categories in each repository. The models illustrated in main window are in a Mathematic category and may include for example minimum radius and minimum area based computations Latex figure output recursive sphere computations and integration methods. Additional models may be displayed by selecting arrow on the right hand side of main window . Other categories that may be selected may include for example a graphics category a visualization category a programming category and an other categories category. The models can be presented in main window based on their time of creation when the models were made available e.g. most recent first or their ratings e.g. based on how high the ratings are how often they have been rated etc. and or on other information.

Command window may allow users to enter commands e.g. at the prompt . The history of commands can be accessed by activating a Command History tab .

An additional details window that provides information regarding a model in command window may be provided to the user as illustrated in in response to a user selecting the model e.g. in response to a mouse over mouse click tab event or shortcut keyboard event . As illustrated additional details window may include the title of the model an abstract to summarize an intent or content of the model one or more graphics e.g. to display characteristic output of the model the type of the model the category to which the model belongs when the model was made available or published information identifying an author or authors of the model and a rating for the model e.g. based on a history of ratings . Furthermore additional details window may also include reviews in their complete or partial form and or a link to more reviews or more details of reviews. In example additional details window includes a link to open a document with the 5 reviews that the model has received. Additional details window may include additional information such as the number of inputs associated with the model the number of outputs associated with the model the data types of inputs and outputs the complexity sample rates dimensions cyclomatic complexity the number of model elements of a certain type such as e.g. lines of code etc.

Systems and methods described herein may provide a modeling infrastructure that allows users to make models available to other users and to search for and obtain models of interest.

The foregoing description of exemplary embodiments provides illustration and description but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example in some embodiments modeling infrastructure may provide one or more application programming interfaces APIs that allow different model creation providers to integrate the use of modeling infrastructure into their own model creation programs.

While the above description focused on modeling infrastructure providing a modeling sharing environment modeling infrastructure may perform other functions. For example modeling infrastructure may automatically search for models in a network such as the Internet and may automatically attempt to execute any models that are found. If a model does not function properly e.g. execution of the model fails execution requires a large amount of resources etc. the model may be evaluated to determine if there is an issue with the model or with the software that is executing the model. For example if the model is valid there may be an issue with the software executing the model. In case of a valid model modeling infrastructure may execute the model using a previous version of the potentially problematic software. If the model functions properly using the previous version of software the model may be flagged for later analysis as to why the previous version of software works but the newer version of software does not work. For example a comparison between the execution of the model using two different versions of the software may reveal an increase in memory usage an increase in execution time loading different shared libraries etc. In this way modeling infrastructure may aid in software evaluation.

While series of acts have been described with regard to the order of the acts may be modified in other embodiments. Further non dependent acts may be performed in parallel.

It will be apparent that aspects as described above may be implemented in many different forms of software firmware and hardware in the embodiments illustrated in the figures. The actual software code or specialized control hardware used to implement aspects described herein is not limiting of the invention. Thus the operation and behavior of the aspects were described without reference to the specific software code it being understood that one would be able to design software and control hardware to implement the aspects based on the description herein.

Further certain portions of the invention may be implemented as logic that performs one or more functions. This logic may include hardware such as an application specific integrated circuit or a field programmable gate array software or a combination of hardware and software.

No element act or instruction used in the present application should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Where only one item is intended the term one or similar language is used. Further the phrase based on is intended to mean based at least in part on unless explicitly stated otherwise.

