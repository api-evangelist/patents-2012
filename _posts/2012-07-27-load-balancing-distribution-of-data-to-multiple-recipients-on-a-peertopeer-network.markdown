---

title: Load balancing distribution of data to multiple recipients on a peer-to-peer network
abstract: Each peer node in a plurality has a different corresponding key value. Each of the nodes can broadcast one or more items to a plurality of recipient nodes. The recipient nodes are arranged into a list according to a key value order. The list is divided into two or more parts of approximately equal size, and each part of the list and the one or more items is forwarded to a recipient peer node corresponding to a first key value in that part of the list. It is emphasized that this abstract is provided to comply with the rules requiring an abstract that will allow a searcher or other reader to quickly ascertain the subject matter of the technical disclosure. This abstract is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08913492&OS=08913492&RS=08913492
owner: Sony Computer Entertainment Inc.
number: 08913492
owner_city: Tokyo
owner_country: JP
publication_date: 20120727
---
This application is a continuation of and claims the priority benefit of co pending U.S. patent application Ser. No. 11 764 680 filed Jun. 18 2007 the entire contents of which are incorporated herein by reference.

The present invention relates to peer to peer networks and more specifically to load balancing the distribution of content over the peer to peer network.

A decentralized computing environment may be defined by a number of computing systems interconnected to communicate with one another wherein each computing system can perform both client and server functions. A peer to peer P2P network represents a decentralized computing environment in which each computing system within the P2P network is defined as a peer of every other computing system within the network. For discussion purposes each peer computing system within the P2P network is referred to as a node. Additionally each node within the P2P network may be configured to execute software having substantially equivalent functionality. Therefore each node may act as both a provider and a user of data and services across the P2P network. Peer to peer networks are distributed data networks without any centralized hierarchy or organization. Peer to peer data networks provide a robust and flexible means of communicating information between large numbers of computers or other information devices referred to in general as nodes.

A P2P network relies primarily on the computing power and bandwidth of the participants in the network rather than concentrating it in a relatively low number of servers. P2P networks are typically used for connecting nodes via largely ad hoc connections. Such networks are useful for many purposes. P2P networks may be used e.g. for sharing content files containing audio video data or anything in digital format is very common and real time data such as telephony traffic may also be transmitted using P2P technology.

An overlay network is a logical or virtual network organization that is imposed on nodes connected by one or more types of underlying physical network connections. In an overlay network nodes are connected by virtual or logical links each of which can correspond with one or more paths in an underlying physical network. Overlay network are typically implemented in hardware and or software operating in the application layer or other top level layer of an OSI network stack or other type of networking protocol.

One class of peer to peer overlay networks are referred to as distributed hash table networks. Distributed hash table overlay networks use a hash function to generate and assign one or more key values to a unique node. The set of all possible key values is referred to as a hash space. Nodes are organized in the hash space according to their assigned key values. The hash function is selected so that nodes are approximately evenly distributed throughout the hash space. Distributed hash table overlay networks are typically highly scalable often supporting millions of nodes robust allowing nodes to join or leave frequently and efficient routing a message to a single destination node quickly.

There are numerous different types of distributed hash table overlay networks. One type of peer to peer overlay network is known as a Chord network. The Chord overlay network protocol is described in detail in Chord A Scalable Peer to peer Lookup Protocol for Internet Applications Ion Stoica Robert Morris David Liben Nowell David R. Karger M. Frans Kaashoek Frank Dabek Hari Balakrishnan Vol. 11 No. 1 pp. 17 32 February 2003 which is incorporated herein by reference. Another type of distributed hash table overlay network is Pastry which is described in Pastry Scalable distributed object location and routing for large scale peer to peer systems A. Rowstron and P. Druschel. Heidelberg Germany pages 329 350 November 2001 which is incorporated herein by reference.

A Chord overlay network may exhibit logarithmic properties arising from asymptotic complexity of messaging. For example if there are N nodes in a Chord ring and a first node wants to send a message to a second node the first node typically has to communication with some subset of the N nodes in order to locate node B. In a Chord overlay network the first node generally has to communicate with a very small subset of all N nodes specifically logN. This property allows a Chord overlay network to have relatively fast messaging even for a very large number N of nodes. However a Chord overlay network can only guarantee this logN messaging property if the IDs of the nodes are completely randomly distributed around the Chord ring.

Current state of the art Chord overlay networks often rely on an even random distribution of the node IDs in distributed hash tables to provide load balanced routing of queries and messages in a peer to peer network. However even if node IDs are evenly and randomly distributed clustering of recipients of a message or query within the global address space of the P2P network may lead to bottlenecks. For example when a peer tries to route the same message to multiple peer nodes some intermediate nodes may become overloaded as they route messages if those nodes are responsible for the address space of the recipients.

Although the following detailed description contains many specific details for the purposes of illustration anyone of ordinary skill in the art will appreciate that many variations and alterations to the following details are within the scope of the invention. Accordingly the exemplary embodiments of the invention described below are set forth without any loss of generality to and without imposing limitations upon the claimed invention.

Embodiments of the invention address problems with load balancing search for or distribution of a file or block of data to multiple recipients on a peer to peer network particularly where the recipients are not uniformly distributed within the global address space.

To appreciate the advantages embodiments of the present invention it is useful to understand a conventional Chord search. In a typical P2P implementation a large number of peers connected to the Internet are organized into a ring to form a peer to peer network as shown in . In this example the network includes peer nodes and . Not all nodes connected to the network are shown for the sake of simplicity. Each peer node is assigned a unique identifier referred to as a key. These identifiers may be evenly and randomly distributed. However this is not a strict requirement for all embodiments of the present invention. For the purposes of example the assignment of keys to peer nodes in network is as shown in Table I below 

In addition each shared file represented by diagonal lines on the network is also assigned a unique key. When a new peer or file is added to the circle or new information about a peer is generated that information is published to a hash table as a hash number generated according to some hash function. Thus the hash table may be regarded as a database in which each database entry has a hash number. The hash numbers are chosen from an identifier ID space that covers a sufficiently large range of numbers that two entries are extremely unlikely to be hashed to the same identifier number. For example the well known SHA 1 hash function has 160 bits which may represent 2 different numbers. Peers randomly choose an identifier from the ID space and organize themselves into the circle. Each published object in the hash table is a pointer back to a particular peer that has that object. The hash table is said to be distributed in the sense that each of the peer nodes in the network is responsible for keeping track of a different range of keys that make up the hash table.

When a peer joins the hash table it is assigned responsibility for a particular range of keys in the ID space of the hash table. Each peer maintains a finger table stored in memory that provides a fast lookup into the ring. The topology of the nodes in the overlay network may be dynamic. Nodes can join or leave the overlay network at any time. When a node departs the overlay network the links between the departing node and any related nodes should be updated. In general the update should change links to the departing node in other nodes finger tables or other node references to valid nodes. Additionally new links should be established to nodes previously linked to by the departing node s finger table or other node references. Joining nodes should be added to other nodes finger tables. Additionally finger tables or other links should be established for the joining nodes. Example protocols for handling nodes joining or leaving the overlay network are discussed in detail in the above cited references.

Generally each peer node in the network needs to be able to communicate directly with every node in its finger table. This may be implemented by a persistent connection but it is not required. Persistent connections are an optimization that most Chord implementations choose to use but are not fundamentally necessary for operation of a Chord network. Nodes in the network may have direct communication available with any other nodes. Typically connectivity to non finger table nodes may be implemented with some sort of fixed size cache. For example a node might keep connections open to K non finger table nodes. Again this is merely an optimization that can be used to avoid performing a Chord lookup using the finger table.

A particular node may locate files or other information stored at other nodes by using a peer to peer search technique referred to as a Chord lookup protocol. Chord allows a distributed set of participants to agree on a single node as a rendezvous point for a given key without any central coordination. In particular it provides a distributed evaluation of the successor ID function given the identifier of a key ID the successor function returns the address of the node whose identifier most closely follows ID in a circular identifier space. The identifier space is typically a 160 bit number. The Chord algorithm handles adjusting this mapping as the population of nodes changes over time. To find any key using a Chord search in a peer to peer network of N nodes a peer typically has to communicate with logN nodes. If N 300 million nodes a peer typically has to communicate with about 28 nodes to find any key or peer on the network.

In P2P networks it is desirable to distribute the communication load for looking up each peer or file identifier. In a Chord search a node requesting a file looks up in its own finger table to determine which key corresponding to a node is closest to the key corresponding to a file. For example referring again to suppose node is searching for the file corresponding to key and node s finger table contains information about nodes with keys and . Specifically node may have information in its finger table about which data keys each of the nodes corresponding to keys and is responsible for. In a conventional Chord search node would look up in its finger table and determine that node with key is closest to key . Node would send a request for key to node . If node is responsible for key it would send the corresponding file back to node . If node is not responsible for key it would look up in its finger table to determine which node is likely to be responsible for key . This process repeats until the node responsible for key is found. At that point the node responsible for key may send the corresponding file to node .

If node is looking for a group of files the Chord search described above may be repeated for each file. For example suppose node wants find files and corresponding to keys and . From the previous example node s finger table contains information about the nodes that are assigned keys and . Using an unmodified Chord search node would end up querying node about keys and and querying node corresponding to key about keys and . Suppose node determines from its finger table that the node corresponding to key node is responsible for keys and . Node would send a request for these files to node . In the meantime node would look up in its finger table to determine which node was responsible for keys and . For example suppose node is responsible for key while node is responsible for key and node is responsible for keys and . In this case the searches for keys and take the same path for almost all of these files. Specifically all four requests would pass through node and the requests for keys and would pass through nodes and and . This would tend to overload the nodes on these paths particularly nodes and . Note particularly the multiple requests indicated by arrows from node to nodes and .

According to embodiments of the present invention to balance the load for the above described search node may order a list of requested files according to key split the list into two or more parts and send requests for the files in each part to a node corresponding to the first key in the corresponding part of the list. This embodiment may be understood by referring to the flow chart in and the diagram shown in . illustrates a method for an improved chord search according to an embodiment of the present invention. As indicated at a node in a chord overlay network may receive or initiate a request for files. As in the above example node may initiate or receive a request for files and corresponding to keys and . The list may be arranged in order according to key value as indicated at and divided into two or more parts as indicated at . By way of example the request may be divided such that keys and are in a first part and files and are in a second part . Lookups may then be performed in a finger table to determine which node keys are closest to the first key in each part. The nodes corresponding to these keys are referred to herein as the finger nodes for each part of the list. For example at node may perform a lookup in finger table for the node key closest to key and at node may perform a lookup for the node key closest to key . In this example node key corresponding to node is closest to key and node key corresponding to node is closest to key . Thus node is the finger node for the first part and node is the finger node for the second part of the list.

Once the finger nodes have been determined for each part of the list requests for the files in the parts of the list are sent at to the corresponding finger nodes. Specifically at node may forward a request to node to perform a lookup for keys and . Similarly at node may forward a request to node to perform a lookup for keys and .

Each node in the network may be configured e.g. by appropriate programming to implement the method . As a result the process described above with respect to may be repeated at each finger node. For example node may have a finger table organized such that it has information regarding the assignment of keys to nodes with keys and . Node may determine from this finger table which other node s is are closest to files and . In this example the closest node to both and is key which corresponds to node . If node has sent node a request for a relatively large number of keys node may a split the request it received from node into two or more parts and repeat the procedure described above with respect to . Alternatively if the number of requested keys is relatively small node may b figure out which node is responsible for the remaining keys in the request. By way of example node may be configured to always perform action a. Action b could be considered an optimization. As such many factors may be taken into account when deciding to perform action b. Possible factors are the number of nodes left in the list pre existing communication channel to a node or if the node is known to have high bandwidth to some or all of the listed nodes. For example if there is a small number of remaining nodes e.g. 4 or less it may be more efficient for node to message them directly. Alternatively if a recipient is in node s finger table it may choose to send a direct message to that recipient while using action a for the rest of the list . Furthermore information regarding bandwidth to particular nodes could be gathered and remembered from previous interactions with other nodes using some sort of cache.

As used herein the term bandwidth refers to a rate of data transmission over a network e.g. in bits per second or message packets per second as determined by among other things network throughput and network latency. Network throughput refers to a rate of data transfer while data transmission is ongoing and network latency refers to a period of delay occurring before or data transmission commences. In general terms increasing network throughput tends to increase bandwidth and increasing network latency tends to decrease bandwidth.

In this example node may determine that node is responsible for keys and and send node a request for the files corresponding to keys and . Node may then send the results files and either directly to node or back to node which may relay the results back to node . In certain embodiments a requesting node s address may be embedded in its queries and in all queries sent on its behalf by other nodes so that the answers to these queries are sent directly back to the node initiating the request.

For the second part of the request node may have a finger table containing information about assignment of keys to nodes having node keys and . Node may determine from this finger table that node key corresponding to node is closest to key . Node may then contact node with a request for keys and . By way of example node may be responsible for key but not key . Node may look up in its own finger table and determine that the node with key node in this example is responsible for key corresponding to file . Node may then return the file to node node or node and forward a request for key to node . In the meantime node may send a request to the node having which is assigned key for keys and . Node may then and forward the request for keys and to node which may return files and . Note that in contrast to the conventional chord search described with respect to the Chord search depicted in distributes the search load more evenly. In particular as may be seen in there is considerably less traffic between node and node and between node and node .

Further optimizations can be made to the Chord search described above. For example at a node may split a request into more than two parts. Although the preceding example describes splitting the request into two parts there may be conditions where splitting the request into more than two parts may be advantageous. For example an application implementing a chord search may be configured to cluster recipients in a way that takes advantage of specific high bandwidth connections. It should be understood therefore that splitting the request into two groups is not the only possible implementation within the scope of embodiments of the present invention.

Furthermore a node may be configured to monitor network bandwidth available to the members of its finger table so that the parts of a request may be preferentially forwarded to nodes having more available resources. By way of example bandwidth could be measured when a node is first added to the finger table. Although it is generally difficult to determine instantaneous available bandwidth general link capabilities may be determined fairly readily. For example the difference between a 28.8 baud modem and a T1 connection is very easy to determine. Another important network performance metric is latency which could also be measured when adding a node to the finger table. For the purposes of embodiments of the present invention coarse grain knowledge is sufficient to perform these types of decisions. For example a node may choose to act differently if it knows a destination node has a broadband connection. By claiming more responsibility for message delivery nodes with fewer resources can continue to perform in a responsive manner.

It is noted that a modified Chord search as described above is particularly advantageous compared to a conventional Chord search if there are more than two items in the request. The two techniques are more or less identical if there are one or two items in the request. However if there are three or more items this new technique is advantageous. The node wishing to send the message only has to contact 2 nodes using the technique described above where a single split was performed instead of all 3 as would be the case in a conventional Chord search.

According to embodiments of the present invention the Chord search described above with respect to and may be adapted to implement broadcasting data from a peer node to a plurality of other peer nodes. To reduce overloading intermediate nodes an original sender of broadcast data may divide a list of recipients for the data into two or more parts as shown in . The sender may be a peer in a peer to peer network of the type described above. The list may be arranged in order of key values corresponding to the recipients. Each part of the list may be sent along with the data to a peer node corresponding to a first key in that part of the list. By way of example the list may be divided into a first part and a second part . The data may be sent along with the first part of the recipient list to a first finger node A chosen from the sender s finger table . If for example it is determined that the list is to be split into two parts the first finger node A may be the member of the sender s finger table that is responsible for the address space containing most of the recipients on the list . The second part of the list may be sent with the data to a second finger node D chosen from the sender s finger table e.g. using a procedure similar to that described above for the chord search method . By way of example the second finger node D may be a predecessor of the first finger node A. Because of the logN distribution of the distributed hash table the predecessor can be expected to know the location of many of the recipients as well and will be highly likely to be able to deliver the message without further routing. Recipient nodes D and A may then deliver the message to any node with which they have a direct peer to peer connection and the process may be repeated for any remaining entries in the list . Specifically first finger node A may send the data to nodes B C while second finger node D forwards the data to nodes E F. In some embodiments the recipient nodes may be selected such that those with more available resources take on a greater portion of the load of broadcasting the files.

The method may be repeated at nodes and . Specifically node may split the first part in two and forward the data to nodes and . Similarly node may forward the data to nodes and . Node may also send the remaining part of the list key to node . Node may then forward the data to node . Note that in this example no node has to send the data to more than two other nodes. In a more general case where the list is split into K parts where K 2 no node has to send the data to more than K nodes.

As may be seen from the foregoing in certain embodiments of the present invention a node sending a broadcast message need not be overly burdened with sending a message to many peers. In a traditional Chord implementation by contrast the sender would individually send the message to each recipient. Using the broadcast technique described herein the sender only transmits a limited number K of messages regardless of the number of intended recipients. If the list is divided into K 2 parts the sender only needs to transmit the message to two different recipients in the overlay network. The entire overlay network cooperates to deliver the message to the entire list of recipients. This levels the playing field allowing nodes that do not have high amounts of network resources to perform more equally with the other peers participating in the overlay network.

In a further embodiment some devices of the overlay network may have restricted capabilities. For example only a limited subset of nodes of the overlay network may be allowed to initiate broadcast messages. The remaining nodes may only be permitted to forward and or process broadcast message. In still a further embodiment all or a subset of the nodes of the overlay network are capable of authenticating broadcast messages. Such a configuration may be implemented to prevent the spread of unauthorized broadcast messages. Upon receiving a broadcast message a node first determines whether the broadcast message is authentic for example by checking a cryptographic signature. If the broadcast message is authentic it is processed and potentially forwarded to other nodes as described above. Otherwise the broadcast message may be ignored.

The overlay network typically includes a plurality of processors and . In further embodiments overlay network may include thousands or millions of processors. Each processor may be a microprocessor microcontroller system on a chip processor digital signal processor application specific integrated circuit ASIC programmable logic device and or any other type of information processing device. Each processor may further include one or more processing units capable of independently executing sequences of information processing instructions or processing information according to a fixed algorithm. Each processor may include local data storage as well as access to common or shared data storage.

A memory is coupled to the CPU . The memory may store applications and data for use by the CPU . The memory may be in the form of an integrated circuit e.g. RAM DRAM ROM and the like . A computer program may be stored in the memory in the form of instructions that can be executed on the processor . The instructions of the program may be configured to implement amongst other things a Chord search method e.g. as described above with respect to and or a broadcast method e.g. as described above with respect to . The computing system may also include well known support functions such as input output I O elements power supplies P S a clock CLK and cache . The system may further include a storage device that provides non volatile storage for applications and data. By way of example the storage device may be a fixed disk drive removable disk drive flash memory device tape drive CD ROM DVD ROM Blu ray HD DVD UMD or other optical storage devices.

The memory may also contain a finger table . The finger table contains information regarding the keys for which the node is responsible. These keys include data keys associated with data e.g. shared files that may be stored in the storage . In addition the finger table may include node keys associated with other peer nodes. Such nodes may include a subset of the nodes in the network that the peer node may be able to contact directly via peer to peen connection. The data keys may be arranged into key groups with each key group being associated with a different node key.

One or more user input devices may be used to communicate user inputs from one or more users to the computer system . By way of example one or more of the user input devices may be coupled to the system via the I O elements . Examples of suitable input device include keyboards mice joysticks touch pads touch screens light pens still or video cameras and or microphones. A network interface allows the computer system to communicate with other computer systems via an electronic communications network . The network interface may include wired or wireless communication over local area networks and wide area networks such as the Internet. The system may send and receive data and or requests for files via one or more message packets over the network .

The computer system may further comprise a graphics subsystem which may include a graphics processing unit GPU and graphics memory . The graphics memory may include a display memory e.g. a frame buffer used for storing pixel data for each pixel of an output image. The graphics memory may be integrated in the same device as the GPU connected as a separate device with GPU and or implemented within the memory . Pixel data may be provided to the graphics memory directly from the CPU . Alternatively the CPU may provide the GPU with data and or instructions defining the desired output images from which the GPU may generate the pixel data of one or more output images. The data and or instructions defining the desired output images may be stored in memory and or graphics memory . In an embodiment the GPU may be configured e.g. by suitable programming or hardware configuration with 3D rendering capabilities for generating pixel data for output images from instructions and data defining the geometry lighting shading texturing motion and or camera parameters for a scene. The GPU may further include one or more programmable execution units capable of executing shader programs.

The graphics subsystem may periodically output pixel data for an image from graphics memory to be displayed on a display device . The display device may be any device capable of displaying visual information in response to a signal from the computer system including CRT LCD plasma and OLED displays. The computer system may provide the display device with an analog or digital signal. By way of example the display may include a cathode ray tube CRT or flat panel screen that displays text numerals graphical symbols or images. In addition the display may include one or more audio speakers that produce audible or otherwise detectable sounds. To facilitate generation of such sounds the system may further include an audio processor adapted to generate analog or digital audio output from instructions and or data provided by the CPU memory and or storage .

The components of the computer system including the CPU memory support functions data storage user input devices network interface and audio processor may be operably connected to each other via one or more data buses . These components may be implemented in hardware software or firmware or some combination of two or more of these.

While the above is a complete description of the preferred embodiment of the present invention it is possible to use various alternatives modifications and equivalents. Therefore the scope of the present invention should be determined not with reference to the above description but should instead be determined with reference to the appended claims along with their full scope of equivalents. Any feature described herein whether preferred or not may be combined with any other feature described herein whether preferred or not. In the claims that follow the indefinite article A or An refers to a quantity of one or more of the item following the article except where expressly stated otherwise. In the claims that follow the expressions first and second are used to distinguish between different elements and do not imply any particular order or sequence. The appended claims are not to be interpreted as including means plus function limitations unless such a limitation is explicitly recited in a given claim using the phrase means for. 

