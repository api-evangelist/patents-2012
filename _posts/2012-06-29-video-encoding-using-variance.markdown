---

title: Video encoding using variance
abstract: Disclosed herein are implementations of systems, methods, and apparatuses for video encoding using variance. One aspect of the disclosed implementations includes a method for encoding a video stream that includes generating a first input variance based on pixel values of a first block of a first frame of the video stream, generating a first reconstruction variance based on pixel values of a reconstructed first block that is reconstructed from an encoding of the first block, comparing the first input variance and the first reconstruction variance to detect a visual artifact in the reconstructed first block, and encoding a second block of a second frame of the video stream using an encoding mode that is selected based on the detection of the visual artifact in the reconstructed first block by the comparison.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09185414&OS=09185414&RS=09185414
owner: GOOGLE INC.
number: 09185414
owner_city: Mountain View
owner_country: US
publication_date: 20120629
---
Digital video streams can represent video using a sequence of frames e.g. still images . Digital video can be used for various purposes including for example remote business meetings via video conferencing high definition video entertainment video advertisements and sharing of user generated videos. Digital video can be encoded using a computer or using hardware specifically designed for video encoding.

Disclosed herein are implementations of systems methods and apparatuses for video encoding using variance.

An aspect of the disclosed implementations is a method for encoding a video stream. The method includes generating a first input variance based on pixel values of a first block of a first frame of the video stream generating a first reconstruction variance based on pixel values of a reconstructed first block that is reconstructed from an encoding of the first block comparing the first input variance and the first reconstruction variance to detect a visual artifact in the reconstructed first block and encoding a second block of a second frame of the video stream using an encoding mode that is selected based on the detection of the visual artifact in the reconstructed first block by the comparison.

An aspect of the disclosed implementations is a computing device. The computing device includes a processing core configured to encode a video stream and a memory connected to the processing core by a bus wherein the processing core is configured to encode blocks of the video stream using encoding modes including at least one of an intra prediction mode or an inter prediction mode and an encoding mode of a current block of the video stream is selected based on a comparison between an input variance and a reconstruction variance of a previous block of the video stream.

An aspect of the disclosed implementations is a non transitory computer readable medium having stored thereon a register transfer level model of an encoder that when incorporated into an application specific integrated circuit causes the application specific integrated circuit to perform steps including generating a first input variance based on pixel values of a first block of a first frame of a video stream encoding the first block reconstructing the encoded first block generating a first reconstruction variance based on pixel values of the reconstructed first block comparing the first input variance and the first reconstruction variance and encoding a second block of a second frame of the video stream using an encoding mode that is selected based on a result of the comparison.

To permit transmission of digital video streams while limiting bandwidth consumption video encoding and decoding implementations can incorporate various compression schemes. These compression schemes generally break the image up into blocks and use one or more techniques to limit the amount of information included in a resulting compressed video bitstream for transmission. The bitstream once received is then decoded to re create the blocks and the source images from the limited information. Digital video can be encoded into video bitstreams using formats such as VPx H.264 MPEG MJPEG and or others.

Encoding a video stream or a portion thereof such as a frame or a block can include using temporal and spatial similarities in the video stream to improve coding efficiency. For example a current block of a video stream may be encoded based on a previously encoded block in the video stream by predicting motion and color information for the current block based on the previously encoded block and identifying a difference residual between the predicted values and the current block. Inter prediction can include using a previously encoded block from a previously encoded frame reference frame . Intra prediction can include using a previously encoded block from the current frame. Intra prediction can be used for encoding for example a frame of video or individual images.

The type of prediction utilized for a block or frame can be identified by an encoding mode which can be encoded into the compressed video bitstream to enable decoding. For example intra prediction can include predicting values for a current block based on values of spatially proximate previously encoded blocks in the current frame which can be identified using one or more intra prediction modes such as horizontal prediction H PRED vertical prediction V PRED DC prediction DC PRED or TrueMotion prediction TM PRED .

Encoding a video stream can include selection of an encoding mode to be utilized to encode a block of the video stream. The encoding mode can be selected by determining a score for various available encoding modes. For example the score can be an estimation of the resulting quality and or compressed size of an encoded block using a particular encoding mode. The scores can be compared to select the encoding mode for the block. In some implementations the estimation of the scores can be suboptimal for example due to implementation constraints such as limited processor speed and or also due to a low encoding bitrate e.g. high quantization selected for encoding. When the estimation is suboptimal visual artifacts can be included in the encoded block due to suboptimal selection of an inter prediction mode e.g. using a reference block near a boundary of a moving object in a frame . For example a reference block can be selected that includes a portion of a moving object that is not included in the block to be encoded and the residual values representative of the differences associated with the moving object with respect to the block to be encoded can be omitted from the encoded bitstream due to a high quantization value.

Video encoding using variance can include generating a first input variance for a first block of a first frame generating a first reconstruction variance for a reconstruction of an encoding of the first block of the first frame generating a second input variance for a second block of a second frame following the first frame where the first block and second block are at spatially corresponding locations in the frames and using one or more comparisons of the generated variances in the selection of the encoding mode for the second block. In an implementation comparison of the variances can be utilized to detect visual artifacts in the reconstructed first block. If visual artifacts are detected selection of the encoding mode can be biased towards selection of an intra prediction encoding mode for the second block in order to reduce the likelihood of the visual artifacts being propagated to the second block by the selection of an inter prediction encoding mode.

Encoder can be implemented using an application specific integrated circuit ASIC or a field programmable gate array FPGA . Encoder can be configured to encode a video stream using encoding techniques such as those described with respect to . External memory can be connected to encoder using bus . External memory can include configuration settings and parameters to be used by encoder . Encoder can further utilize external memory for storage of input data for encoding e.g. a video stream for storage of values utilized during encoding and or for storage of output data from encoding e.g. a compressed bitstream .

One or more functions incorporated into encoder can be implemented using a register transfer level RTL design. The RTL design can be in the form of a hardware description language HDL such as Verilog HDL. The RTL design can be incorporated into an ASIC. Incorporation of the RTL design can include using techniques such as logic synthesis to produce a gate level netlist which can then be used to fabricate the ASIC.

CPU can be a general purpose processor capable of executing instructions stored in external memory accessed via bus . CPU can be configured to control the operation of encoder . In an implementation external memory can include a hardware driver that enables CPU to control the operation of encoder . In an implementation the operation of encoder can be further controlled by a software program stored in external memory using an application programming interface API of the hardware driver.

Network device can enable the computing device to send and or receive data from a network not shown . In an implementation network device can be utilized to receive a video stream for encoding to transmit a compressed bitstream encoded by encoder or a combination thereof. The network can for example be the Internet. The network can also be a local area network LAN wide area network WAN virtual private network VPN or any other means of transferring data to or from computing device .

Computing device can also include or be in communication with an image sensing device for example a camera or any other image sensing device now existing or hereafter developed that can sense images such as an image of a device user operating computing device . The image sensing device can be positioned such that it is directed toward a device user that is operating the computing device . The image sensing device can be configured to receive images for example of the face of a device user while the device user is operating the computing device .

Although depicts components such as CPU and external memory of the computing device as being integrated into a single unit other configurations can be utilized. The operations of the CPU can be distributed across multiple devices or machines. External memory can be distributed across multiple devices or machines such as network based memory or memory in multiple machines performing the operations of the computing device . Although depicted here as a single bus the bus of the computing device can be composed of multiple buses. Further the external memory can be directly coupled to the other components of the computing device or can be accessed via a network and can comprise a single integrated unit such as a memory card or multiple units such as multiple memory cards. In an implementation multiple components or portions of components of computing device can be incorporated into a system on a chip SoC . For example bus can include a standard bus interface such as an Advanced Microcontroller Bus Architecture AMBA Advanced eXtensible Interface AXI which can be used as an on chip bus in SoC designs. The computing device can thus be implemented in a wide variety of configurations.

Encoding technique encodes an input video stream e.g. video stream . Encoding technique has the following stages to perform the various functions in a forward path shown by the solid connection lines to produce an encoded or a compressed bitstream an intra inter prediction stage a transform stage a quantization stage and an entropy encoding stage . Encoding technique also includes a reconstruction path shown by the dotted connection lines to reconstruct a frame for encoding of further blocks. Encoding technique can include the following stages to perform the various functions in the reconstruction path a dequantization stage an inverse transform stage a reconstruction stage and a loop filtering stage . Other variations of encoding technique can be used to encode the input video stream .

When the input video stream is presented for encoding a frame e.g. frame within the input video stream is processed in units of blocks. At the intra inter prediction stage blocks can be encoded using intra frame prediction within a single frame or inter frame prediction from frame to frame . In either case a prediction block can be formed. In the case of intra prediction a prediction block can be formed from prediction samples in the current frame that have been previously encoded and reconstructed. In the case of inter prediction a prediction block can be formed from prediction samples in one or more previously constructed reference frames.

Next still referring to the prediction block can be subtracted from the current block at the intra inter prediction stage to produce a residual block residual . The transform stage transforms the residual into transform coefficients in for example the frequency domain. Examples of block based transforms include the Karhunen Lo ve Transform KLT the Discrete Cosine Transform DCT and the Singular Value Decomposition Transform SVD . In one example the DCT transforms the block into the frequency domain. In the case of DCT the transform coefficient values are based on spatial frequency with the lowest frequency DC coefficient at the top left of the matrix and the highest frequency coefficient at the bottom right of the matrix.

The quantization stage converts the transform coefficients into discrete quantum values which are referred to as quantized transform coefficients or quantization levels. The quantized transform coefficients are then entropy encoded by the entropy encoding stage . Entropy encoding can include the use of various techniques such as formatting compressed bitstream using run length encoding RLE and zero run coding. The entropy encoded coefficients together with the information used to decode the block such as the type of prediction used motion vectors and quantizer value are then output to the compressed bitstream .

The reconstruction path in shown by the dotted connection lines can be used to ensure that both the encoding technique and decoding technique described below use the same reference frames to decode the compressed bitstream . The reconstruction path performs functions that are similar to functions that take place during the decoding process that are discussed in more detail below including dequantizing the quantized transform coefficients at the dequantization stage and inverse transforming the dequantized transform coefficients at the inverse transform stage to produce a derivative residual block derivative residual . At the reconstruction stage the prediction block that was predicted at the intra inter prediction stage can be added to the derivative residual to create a reconstructed block. The loop filtering stage can be applied to the reconstructed block to reduce distortion such as blocking artifacts.

Other variations of encoding technique can be used to encode the compressed bitstream . For example a non transform based encoder can quantize the residual signal directly without the transform stage . In another implementation an encoder can have the quantization stage and the dequantization stage combined into a single stage.

Decoding technique similar to the reconstruction path of encoding technique discussed above includes in one example the following stages to perform various functions to produce an output video stream from a compressed bitstream e.g. compressed bitstream an entropy decoding stage a dequantization stage an inverse transform stage an intra inter prediction stage a reconstruction stage a loop filtering stage and a deblocking filtering stage . Other variations of decoding technique can be used to decode the compressed bitstream .

When the compressed bitstream is presented for decoding the data elements within the compressed bitstream can be decoded by the entropy decoding stage using for example Context Adaptive Binary Arithmetic Decoding to produce a set of quantized transform coefficients. The dequantization stage dequantizes the quantized transform coefficients and the inverse transform stage inverse transforms the dequantized transform coefficients to produce a derivative residual. Using header information decoded from the compressed bitstream decoding technique can use the intra inter prediction stage to create a prediction block. At the reconstruction stage the prediction block can be added to the derivative residual to create a reconstructed block. The loop filtering stage can be applied to the reconstructed block to reduce blocking artifacts. The deblocking filtering stage can be applied to the reconstructed block to reduce blocking distortion and the result is output as the output video stream .

Other variations of decoding technique can be used to decode the compressed bitstream . For example decoding technique can produce the output video stream without the deblocking filtering stage .

The first input variance can be stored for example in external memory . At stage the first block can be encoded and reconstructed to generate a reconstructed first block by using for example the forward path and reconstruction path of encoding technique . At stage a first reconstruction variance V of a first block of a first frame of a video stream is generated based on pixel values of the reconstructed first block. At stage a second input variance V of a second block of a second frame of a video stream is generated based on pixel values of the second block.

At stage a comparison is made to determine if Vis less than limit a pre determined factor. The value of limit can be stored in external storage . If Vis less than limit control passes to stage where a comparison is made to determine if Vis less than Vmultiplied by scale a pre determined factor. If Vis less than Vmultiplied by scale control passes to wherein a comparison is made to determine if Vplus limit a pre determined factor is less than Vmultiplied by scale. If Vplus limit a pre determined factor is less than Vmultiplied by scale control passes to stage where a penalty value is determined. For example the penalty value can be set to a pre determined value or can be set based on some or all of the values available to technique such as Vand V.

At stage an encoding mode for the second block is determined based on an intra score inter score and the penalty value. For example an intra score can be determined for an intra prediction mode and an inter score can be determined for an inter prediction mode. The scores can estimate the resulting quality and or compressed size of an encoded block using either the intra prediction mode or the inter prediction mode. For example a sum of absolute differences SAD can be calculated for prediction samples to be used in each mode to determine the score for each mode. Other techniques can also be utilized to determine the scores.

The penalty value can be added to either of the scores and the resulting scores can be compared to select the encoding mode. For example the penalty value can bias the selection towards the intra prediction mode based on the detection of a visual artifact by the comparisons of stages and .

If any of the comparisons of stages do not meet the specified criteria control instead passes to stage where an encoding mode for the second block is selected based on an intra score and an inter score. Operation of stage can be the same as stage with the exception that a penalty value is not utilized. For example the comparisons can indicate that a visual artifact has not been detected and that no bias is to be applied in the selection of the encoding mode.

Once the encoding mode is determined for the second block the second block can be encoded using the selected encoding mode not shown . The stages of technique as described are exemplary and other implementations are available. For example stages of technique can be added omitted combined split or otherwise modified. For example stages and can be omitted from technique . As another example the comparison used in technique can be altered such as by removing or changing the use of the scale factor. In implementations technique can further include determining whether the first block was encoded using an intra prediction mode and not biasing the selection of the encoding mode if the first block was encoded using an intra prediction mode.

Technique can further be incorporated into a process for encoding blocks in a video stream where the blocks include multiple components such as luma and chroma values. The following pseudo code illustrates an implementation of using technique for encoding a block of a video stream having multiple components 

The above pseudo code includes a memory structure boost used to store arrays of variance values in memory for V V and Vassociated with each component. Comparisons can be made for each component of the block using the values stored in memory e.g. external memory . If comparisons of the variance values associated with any component of the block indicates that a visual artifact is present in the previous block e.g. first block then the visual artifact is attributed to the entire block. If the previous block is encoded using an intra mode prediction the comparisons can be overridden such that no visual artifact is deemed detected.

The current block being processed in the above pseudo code is identified by mbNum. As such the above pseudo code can process multiple blocks of the frame by changing mbNum to refer to other blocks in the frame. The boost variable can be an array that includes values associated with each block in a frame.

The use of the adjectives first second third etcetera herein is not intended to infer any particular meaning regarding the ordering or positioning of elements unless specifically indicated. For example a first frame and a second frame of a video stream can refer to any two frames of the video stream and does not necessarily indicate that the first frame and the second frame are the first two frames of the video stream or that the first frame is located before the second frame.

The words example or exemplary are used herein to mean serving as an example instance or illustration. Any aspect or design described herein as example or exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather use of the words example or exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X includes A or B is intended to mean any of the natural inclusive permutations. That is if X includes A X includes B or X includes both A and B then X includes A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Moreover use of the term an embodiment or one embodiment or an implementation or one implementation throughout is not intended to mean the same embodiment or implementation unless described as such.

The processors described herein can be any type of device or multiple devices capable of manipulating or processing information now existing or hereafter developed including for example optical processors quantum and or molecular processors general purpose processors special purpose processors intellectual property IP cores ASICS programmable logic arrays programmable logic controllers microcode firmware microcontrollers microprocessors digital signal processors memory or any combination of the foregoing. In the claims the terms processor core and controller should be understood as including any of the foregoing either singly or in combination. Although a processor of those described herein may be illustrated for simplicity as a single unit it can include multiple processors or cores.

In accordance with an implementation of the invention a computer program application stored in non volatile memory or computer readable medium e.g. register memory processor cache RAM ROM hard drive flash memory CD ROM magnetic media etc. may include code or executable instructions that when executed may instruct or cause a controller or processor to perform methods discussed herein such as a method for performing a coding operation on video data using a computing device containing a plurality of processors in accordance with an implementation of the invention.

A computer readable medium may be a non transitory computer readable media including all forms and types of memory and all computer readable media except for a transitory propagating signal. In an implementation the non volatile memory or computer readable medium may be external memory.

Although specific hardware and data configurations have been described herein note that any number of other configurations may be provided in accordance with implementations of the invention. Thus while there have been shown described and pointed out fundamental novel features of the invention as applied to several implementations it will be understood that various omissions substitutions and changes in the form and details of the illustrated implementations and in their operation may be made by those skilled in the art without departing from the spirit and scope of the invention. Substitutions of elements from one implementation to another are also fully intended and contemplated. The invention is defined solely with regard to the claims appended hereto and equivalents of the recitations therein.

