---

title: System and method for management of network-based services
abstract: In one embodiment, a system includes an interface configured to receive a first request sent from a first customer for a first service provided by a first service provider, the first request being of a first type. The system also includes at least one processor configured to determine a first set of configuration parameters from a first policy associated with the first service provider in response to receiving the first request. The at least one processor also causes a node associated with the first service provider to provide the first service in response to receiving the first request using the first set of configuration parameters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09450836&OS=09450836&RS=09450836
owner: Cisco Technology, Inc.
number: 09450836
owner_city: San Jose
owner_country: US
publication_date: 20121221
---
This application claims priority to U.S. Provisional Patent Application Ser. No. 61 580 564 entitled Improved Networking which was filed on Dec. 27 2011 and is hereby incorporated by reference.

This disclosure relates generally to computer networks and more particularly to a system and method for management of network based services.

In network based service provision certain providers follow an approach where low level application programming interfaces APIs are exposed and allow developers to build customized services. This approach pushes the complexity of service creation from the provider into the customer of the service. A customer invests in building custom solutions and is responsible for the design of service. If the service provider decides to incorporate such custom solutions as part of their offerings complexity grows rapidly. The complexity grows linearly with the number of unique combinations and exponentially with the number of services within a combination. The rapid increase in complexity makes services brittle and hard to modify.

Most cloud services use HTTP web services SOAP and REST to distribute service information and access and manage services. This model has shortcomings. First HTTP was not designed for service discovery and publishing but only to connect to hosts after they have been discovered through other means. Second HTTP does not interact with policy in packet treatment. Service packets need to be policy routed and may be modified based on policies. Third to authenticate authorize and account AAA all HTTP packets must be intercepted or terminated at some proxy.

In one embodiment a system includes an interface configured to receive a first request sent from a first customer for a first service provided by a first service provider the first request being of a first type. The system also includes at least one processor configured to determine a first set of configuration parameters from a first policy associated with the first service provider in response to receiving the first request. The at least one processor also causes a node associated with the first service provider to provide the first service in response to receiving the first request using the first set of configuration parameters.

In some embodiments the first request may include a dotted decimal name associated with the first service. The at least one processor may further be configured to verify that the first request complies with a set of rules associated with the first type and validate the first request by comparing the first request to information about the first service. The first request may include a first portion the first portion comprising information independent of how the first service is implemented. The first request may also include a second portion the second portion comprising information dependent on how the first service is implemented.

In one embodiment a method executed by at least one processor includes receiving a first request sent from a first customer for a first service provided by a first service provider the first request being of a first type. The method also includes determining a first set of configuration parameters from a first policy associated with the first service provider in response to receiving the first request. In addition the method includes causing a node associated with the first service provider to provide the first service in response to receiving the first request using the first set of configuration parameters.

Depending on the specific features implemented particular embodiments may exhibit some none or all of the following technical advantages. Service deployments may cross customer and service provider boundaries. Each customer or service provider may be able to enforce policy rules for service usage at ingress and egress points. As another example separate service dependent and service independent functions may be defined in a network. Other technical advantages will be readily apparent to one skilled in the art from the following figures description and claims.

System depicts various nodes coupled via one or more electronic networks. Such networks may be implemented using an ad hoc network a personal area network PAN a local area network LAN a wide area network WAN a metropolitan area network MAN and or one or more portions of the Internet. One or more portions of one or more of these networks may be wired or wireless. As examples a network may be implemented using one or more of a wireless PAN WPAN e.g. a BLUETOOTH WPAN a WI FI network a WI MAX network a Long Term Evolution LTE network a cellular telephone network e.g. a Global System for Mobile Communications GSM network or other suitable wireless network.

In some embodiments data centers and may represent a collection of hardware devices that serve to host multiple applications used by customer nodes and using one or more networks as discussed above. Data centers and may include one or more networks that allow for communication sessions. Multiple service providers may use aspects of the infrastructure of data centers and to provide services. For example a service provider may have an agreement with an entity associated with data center wherein the service provider may utilize one or more of service nodes and to provide one or more services. As a result in some embodiments multiple service providers may utilize the same hardware resources of data center or may reside on the same network or sub network. Virtualization techniques may be used to provide multiple service providers access to physical hardware resources of data centers and . For example services by service providers may be implemented using virtual machines.

In some embodiments customer nodes and may be nodes used by entities e.g. users or service providers that use services provided by service nodes and . As examples customer nodes may represent an end user a service provider who sources services from other service providers and combines them with their own services or a third party service provider that aggregates services from multiple providers. For example a business entity that enters into an agreement with a service provider to source cloud services for their users may be represented by customer nodes and . As another example a customer may be an enterprise that buys cloud services. In some embodiments a customer may define policies for service and may authenticate its users. Customer nodes may be implemented using a computer workstation telephone Internet browser electronic notebook Personal Digital Assistant PDA computer tablet or any other suitable device wireless wireline or otherwise component or element capable of receiving processing storing or communicating information with other components of system . As examples may be a smartphone a desktop computer a laptop computer or an IP enabled telephone. System may include any suitable number of customer nodes that may be operated by any suitable number of users. Information stored in storage of customer nodes may each be implemented using any suitable structure for storing and retrieving information. Databases file systems tables lists or suitable combinations of these structures are examples of how such information may be stored. Computer readable non transitory storage media may be used such as a semiconductor based or other integrated circuit IC e.g. a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive another suitable medium or a suitable combination of these where appropriate. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

In some embodiments each of service nodes and may be a hardware or software entity e.g. a virtual machine that provides a service. The service can be hardware resources e.g. compute network security storage or other suitable services platform and middleware resources e.g. HTTP servers application server frameworks databases messaging middleware or other suitable resources and applications e.g. supply chain communication collaboration e governance or other suitable applications . A service provider may be a supplier of cloud services to cloud customers and users e.g. customer nodes and per some business agreement. As an example the service may be a virtual instance of a hardware or software product that can be owned by a customer or user for their personal use. Software running on one or more of such computing systems may perform one or more steps of one or more methods described or illustrated herein or provides functionality described or illustrated herein. Such computing systems may be in any suitable physical form. As examples and not by way of limitation a computing system may be a virtual machine VM an embedded computer system a system on chip SOC a single board computer system SBC e.g. a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a server an application server a router a switch or a combination of two or more of these. Where appropriate computing systems may be unitary or distributed span multiple locations span multiple machines or reside in a computing cloud e.g. a networked set of computing systems which may include one or more cloud components in one or more networks. Where appropriate one or more computing systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computing systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computing systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

Information stored in storage of service nodes may be implemented using any suitable structure for storing and retrieving information. Databases file systems tables lists or suitable combinations of these structures are examples of how such information may be stored. Computer readable non transitory storage media may be used such as a semiconductor based or other integrated circuit IC e.g. a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive another suitable medium or a suitable combination of these where appropriate. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

In some embodiments system may use a classification scheme to name services. Classification may allow the combining of attributes across similar types of services. An object oriented approach may be used to define service domains. As examples network can be a root domain switching routing and services can be child domains of the root network domain and security and packet inspection can be child domains of the services domain. Labeling of such relationships for example may be accomplished by a dotted decimal name. illustrates an example of a hierarchical naming scheme. Examples of names taken from may be iaas.network.switching and iaas.network.security as well as others. Child domains may inherit parameters defined in the parent domain. A child domain may override the parent domain s attributes by redefining them in the child domain. Using domain naming proxies such as proxies and may advertise domains and users e.g. associated with customer nodes and who access the services will access them based on which domain of service they prefer. This may serve to in some embodiments abstract the service implementation from the service user. XML schemas can be used to implement the classification scheme. Inheritance of attributes in the classification scheme may also be provided. For example routing and switching domains may inherit the network domain and a virtual firewall domain will inherit both the firewall and virtual machine domains. Through inheritance large portions of a domain s attributes can be automatically re used in some embodiments.

In some embodiments each service domain can have its own service specific parameters. They can reuse existing parameters by inheriting an existing domain. Each domain may be associated with its own schema and that may allow a proxy validate a request before forwarding it even without details of a domain and its associated parameters. The parameters of a domain can be defined in a service dependent way but it may still be generalized to apply to a wide variety of services in that domain. These parameters may be represented through XML text binary or other kinds of formats.

In some embodiments vendor specific attributes VSAs may be used in conjunction with service domains. These attributes may not be understood by all clients or users. These may however be understood between select endpoints that choose to use such attributes. Using VSAs experimental domains or vendor specific domains may be defined.

In some embodiments proxies and may receive requests e.g. from other proxies and or from customer nodes and and execute them on behalf of services provided by service nodes and . In some embodiments the use of proxies and is directed to functions related to service management that are not dependent on the details of a particular service such as service creation and service deletion . Proxies may be implemented using one or more computing systems. Software running on one or more of such computing systems may perform one or more steps of one or more methods described or illustrated herein or provides functionality described or illustrated herein. Such computing systems may be in any suitable physical form. As examples and not by way of limitation a computing system may be a virtual machine VM an embedded computer system a system on chip SOC a single board computer system SBC e.g. a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a server an application server a router a switch or a combination of two or more of these. Where appropriate computing systems may be unitary or distributed span multiple locations span multiple machines or reside in a computing cloud e.g. a networked set of computing systems which may include one or more cloud components in one or more networks. Where appropriate one or more computing systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computing systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computing systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

Information stored in storage of proxies may be implemented using any suitable structure for storing and retrieving information. Databases file systems tables lists or suitable combinations of these structures are examples of how such information may be stored. Computer readable non transitory storage media may be used such as a semiconductor based or other integrated circuit IC e.g. a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive another suitable medium or a suitable combination of these where appropriate. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

Service management may include creating modifying moving or deleting services. Service management may involve one or more actions performed in sequence or in parallel. These actions could be invoked on hardware and software services or on other cloud providers. Such functions may be abstracted from the rest of the network. For example proxies may be unaware of service user or policy nuances. A proxy in various embodiments may perform the following functions 

Regardless of the kind of service that is being offered common actions may be performed such as service discovery creation modification deletion and migration among others. Further reliable confirmation and cancellation of requests or indicating successes and failures upstream may be provided. Cloud computing may involve many such actions which are service independent. As examples if a virtual machine a virtual private network or a storage service a create action can be used to indicate the operation of service creation. This common create action can be used for a variety of create tasks by proxies and and its meaning can depend on the receiver.

Requests for service may be forwarded by a proxy to a service node e.g. service nodes and other proxies e.g. proxy may forward a service request received from customer node to locating proxy or workflow nodes e.g. workflow nodes and . A network of interoperable networks e.g. datacenters and may use multiple proxies. A proxy may inspect or modify packets in transit. In some embodiments locating proxy may perform loadbalancing locating and security functions while forwarding requests received from proxies e.g. proxies and to a proxy associated with the requested service e.g. proxies and . As an example operation customer node may request a service and proxy may route the request to the right location. Proxies discover and monitor services. Proxies may also authenticate service providers and customer nodes so that unwanted users or services cannot get into the service routing data and procedures. A proxy may forward responses back to other proxies and customer nodes. A proxy may statefully inspect packets and insert or remove headers.

In some embodiments a proxy may operate in one of two modes transparent and aggregated. A proxy operating in transparent mode does not aggregate services it forwards messages transparently. A proxy operating in aggregate mode aggregates services and publishes them as aggregates. In the aggregated mode a single proxy may publish a wide variety of services to their users although these services are in turn managed by other proxies.

A proxy is typically located at the premises of an associated node e.g. an associated service node or customer node . A proxy handling a request of an associated node may be located at the edge of a network that includes the associated node and perform functions of egress control. In some embodiments a proxy may be located inside a service provider s network even though it is associated with a node requesting a service. For example a proxy associated with a software as a service SaaS node may send a query for an infrastructure as a service IaaS service and both the SaaS and IaaS may be implemented in a network of a particular service provider. In this case the proxy associated with the SaaS node would be located inside a provider s network.

One or more of proxies and may be defined to cater to specific customers service types e.g. a compute service or a storage service or locations. For example proxy may be set to service requests from customer nodes and because they have been guaranteed a certain level of service. One or more of proxies and may orchestrate services in a given geography.

One or more of proxies and may control service management across multiple resources or resource domains. For example proxy may manage services such as compute storage network and security services. One or more of proxies and may instantiate multiple service instances based on a single request and may be used to setup a complete virtual datacenter on a single request. Error or failure scenarios may be handled by one or more of proxies and for example rollback actions may be triggered. A proxy associated with a service node may discover services allow service registrations and publish aggregates of services to upstream locating proxies e.g. locating proxy . Such a proxy is also responsible for accounting for service usage. Proxies may use timers and detect timeouts on requests. These timers may be used to expect a response to a request within the specified timeframe. When the timer expires recovery actions should be possible. This may also be useful in case of network failures and on going transactions can be automatically reversed. Through use of timers and automated reversal failures may not result in leaked resources incorrect accounting or other problems.

One or more of proxies and may become the anchor for complex services that are outside the domain of its own control. For example proxy may create a pool of virtual machines and may run out of resources and direct a request to locating proxy to find additional resources in another location e.g. service node associated with proxy . A proxy may be configured to sequence and parallelize messages within a single context. Sequences or parallelization would depend on the specific needs of a particular kind of service. For example compute and network services may be provisioned in parallel while workload movement across geographical regions must take place sequentially. Accordingly the responses to such requests may also be received in sequential or parallel fashion. When managing requests in a parallel or sequential fashion it should be possible to commit these operations as a whole. If errors are encountered in any one of the transactions it should be possible to cancel the entire service context as a whole.

In some embodiments workflow nodes are service dependent network elements i.e. functions performed by workflow nodes depend upon the details of a particular service . This includes service authorization service level agreements SLAs for those services location preferences charging policies processes for fulfilling requests and other suitable functions. These policies may be available as syntax and semantics validation procedures that can be applied by a workflow node to received requests. If the validation fails the requests may be rejected. To apply customer specific rules a workflow node may know about users e.g. at customer nodes and and their location. To apply service specific rules a workflow node may know about service availability and location. A workflow node may be implemented using one or more computing systems. Software running on one or more of such computing systems may perform one or more steps of one or more methods described or illustrated herein or provides functionality described or illustrated herein. Such computing systems may be in any suitable physical form. As examples and not by way of limitation a computing system may be a virtual machine VM an embedded computer system a system on chip SOC a single board computer system SBC e.g. a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a server an application server a router a switch or a combination of two or more of these. Where appropriate computing systems may be unitary or distributed span multiple locations span multiple machines or reside in a computing cloud e.g. a networked set of computing systems which may include one or more cloud components in one or more networks. Where appropriate one or more computing systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computing systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computing systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

Information stored in storage of workflow nodes may be implemented using any suitable structure for storing and retrieving information. Databases file systems tables lists or suitable combinations of these structures are examples of how such information may be stored. Computer readable non transitory storage media may be used such as a semiconductor based or other integrated circuit IC e.g. a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive another suitable medium or a suitable combination of these where appropriate. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

A workflow node may receive this information from an associated proxy on a periodic basis or whenever the information changes. For example a workflow node may subscribe for updates with an associated proxy e.g. workflow node may be subscribed to updates from proxy . In some embodiments a workflow node can include device and service specific configurations. These configurations can be mapped to device or service capabilities identified by meta attributes. While the meta attributes describe the capability at a high level the configurations stored in a workflow node will involve detailed configurations. These could include command line interface commands text or XML configurations or even binary formatted application specific configurations. A workflow node can use the meta attributes to construct a configuration for a particular resource or device . A workflow node may also store this configuration against a unique identifier to be used later for querying the configuration out of the workflow node.

Workflow nodes include workflow definitions along with policies to validate or modify workflows in service requests. As an example service user and policy information can be encoded in an abstract language like the extensible markup language XML . In such an example a workflow may be an XML document. Workflows may include tasks and may represent the order in which tasks must be executed. A task in a workflow may include a definition of actions that need to be taken for that task. Tasks may be operations that a proxy can perform. To execute a task a proxy may send or receive an appropriate message. A workflow may be referenced by a workflow name. A customer node e.g. customer node may request a service bundle by invoking a workflow name. Workflows may be stored in workflow nodes e.g. workflow nodes and . Workflow nodes may be situated at various points in the network s as illustrated in . A workflow node may be configured to associate a workflow name with a workflow e.g. an XML document that include tasks . A workflow node can perform service specific validations by validating the workflow request against the service specific syntax and semantic validation procedures stored in that workflow node. In an example where the language to describe syntax and semantics is standardized a workflow node e.g. workflow node can support multiple new service combinations through configuration alone without needing proxies e.g. proxy to be upgraded to support new services.

When using an XML definition of workflows and tasks validation rules can be defined by for example using an XML Schema Definition XSD to validate syntax and using an Object Constraint Language OCL to validate semantics of a workflow request. When a workflow request arrives the requested workflow can be validated against the associated schemes already defined in XML or other abstract languages. If a request fails validation according to syntax and semantic rules already defined in a workflow node the request may be rejected. The rules may also specify how to modify all or selected requests before forwarding them downstream e.g. from workflow node to service node . The collection of all the syntax and semantic rules constitute a policy framework. A policy framework may be centralized at the provider at the customer or distributed between the provider and customers. Accordingly the requests may be modified and or validated multiple times.

A policy may be associated with a user e.g. of customer node such that the user can modify personalized policies about services. A policy may be associated with a service e.g. provided by service node and the service vendor may provide a configurable system for policy controlling each service which the service provider can customize to suit the needs of their deployment. A policy may be associated with a proxy e.g. proxy which may be defined either by a service provider a customer or jointly by a service provider and a customer. When policies are associated with proxies clients and servers may be unaware of the policy. The complexity in managing policy rules can be reduced by centralizing the intelligence to define and apply policies in proxies. To apply these policies client requests are intercepted transformed and routed according to the policies before they reach the service node. The nodes such as customer node and service node may be unaware of this behavior. The rules for controlling services requests can be defined through configuration. A proxy e.g. proxy or can download policy rules for a service and execute those rules on demand.

In some embodiments the separation of the control and policy planes allows the same control plane to be re used for a variety of policies. Policies can now be defined through configuration instead of being programmed in a proxy. A common control plane can be used to manage all these services. Through this separation a proxy e.g. proxies and can be programmable and it may not include hardcoded service logic. Rather proxies can be programmed through policies defined by users or service providers in a suitable manner e.g. using a user friendly language . This can ease service creation and customization of existing services while reducing overall management complexity.

One example of policies that may be applied in system are routing policies. A service may be provided from multiple sources e.g. service nodes and and to route a request to the correct destination various types of routing policies may be applied. For example a service request may be routed to the geographically nearest provider. Or it might be routed to a location that offers the cheapest service rate or to a different location based on time of day. There can be routing rules based on SLAs. Each user s request may be routed differently based on their roles. There could be rules specific to a type of service or routing may be determined by the locations that have the necessary capacity. Routing may be determined by legal or governmental regulations. These rules may be dynamically changed and different rules may apply to different types of services users locations roles or other suitable targets. A service provider and a customer may independently or jointly define these policies and enforce them at the customer edge at the service provider edge or both.

Another example of policies that may be applied in system are security policies. Security in the context of services provided in system can encompass a broad spectrum of issues spanning authentication authorization and accounting AAA . For example a customer e.g. at customer node may authenticate its users based on internal user databases while a service provider e.g. at service node may be responsible for the authorization and accounting of the service request. As another example a customer may be responsible for user specific authorization and authentication while the service provider may be response for the accounting. As users join or leave a customer the service provider may not own user specific authentication and policies. The AAA functions are best performed at the service provider or customer edges. Each service may not be required to do AAA it is inefficient and complex. Service nodes may be protected from denial of service attacks by preventing unauthorized requests from entering the network. Services may only be accounted as a bundle e.g. network compute and storage services may form a single service bundle and not individually. Request logging for business analytics is can be done at the network level and not in individual services. A service provider may also wish to hide network topology of services and may abstract all services from user visibility. For example a service provider may publish one interface to access services although these services are managed by service specific proxies. These proxies may be situated in different locations.

Another example of policies that may be applied in system are service policies. Complex services can use coordination of multiple resources. A virtual machine for example may need network attached storage network based security and network quality of service. The virtual machine service may be regarded incomplete without the combination of all services. Some virtual machines may use network attached storage while others may not. Some virtual machines may need to offload denial of service attacks while others may use encryption of data. Some services may use a specific amount of network bandwidth to be available. Policies associated with services can be abstracted from clients and service providers. Accordingly when a client requests for a virtual machine the request may be modified to include storage security and quality of service requests before it reaches the service provider. Likewise for example if a user is not authorized to request high end services their requests might be automatically downgraded to the appropriate grade of service. This is a function of policies that a service provider and or a customer can define. This means that a request for a virtual machine may do different things for different classes of users. Users may be upgraded or downgraded in the level of services while using the same request. This means that the syntax and semantics of a request is not fixed in advance. Rather it is determined based on context and different factors may be used to modify these requests in transit. Syntax and semantics of a request may be restricted from an end user perspective as well as a service provider perspective. Thus a service node can support a superset of request parameters to allow any user to access the service in different ways. A client can request a subset of those parameters based on a prior customer or a service provider defined policies or SLAs. The validation and tweaking of request parameters in a user specific manner should be controlled by a policy in transit. In effect the requests that a client makes and the requests that a service node receives can be very different based upon the policies that modify the request in the middle.

A workflow node associated with a proxy that received a request for service from a customer node may be used to validate the request before allowing it to be forwarded. For example workflow node may validate a request from customer node against the policies provisioned for a given user before forwarding the request. A workflow node may be used by a service provider to validate provider to provider requests before sending them to another service provider. The validations may be defined unilaterally or based upon agreements or defined SLAs.

In some embodiments a workflow node may automatically trim or expand a requested workflow prior to execution. For example to a virtual machine creation workflow a workflow node may add tasks for storage access control quality of service provisions and load balancing even though such tasks were not in the original request. Policies used to govern the trimming or expanding of workflows may be defined by a user a service provider or mutually agreed upon as an SLA. Once a workflow has been defined an associated proxy or service node can download the workflow and task definitions from a workflow node. In case of failures or service termination a workflow node will determine action reversal by flipping the individual tasks in the correct order.

In some embodiments to add a new service a new API combination may not be needed. Rather a new XML document may be created to validate syntax and semantics of the service request. New services can thus be added through configuration alone. With the ability to define and validate workflows a user e.g. at customer node or a service provider e.g. at service node can create service bundles on demand. Workflow nodes store all user or service provider defined workflows which are referenced by a workflow name.

Proxies and workflow nodes may be designated for specific customers service providers and service types. One or both of proxies and workflow nodes may be deployed at multiple points in one or more networks including but not limited to a a customer or service provider egress b a customer or service provider ingress and c a customer or service provider intranet. Interaction between proxies and workflow nodes may be any to any e.g. one proxy may interact with multiple workflow nodes for multiple service types and a workflow node may serve one type of service dependent rules to multiple proxies that support the same service . illustrates multiple examples of the any to any relationships between proxies and workflow nodes. A proxy may connect to multiple workflow nodes e.g. proxy is coupled to workflow nodes and . A workflow node may be connected to multiple proxies e.g. workflow node is coupled to proxies and . A distribution of proxies and workflow nodes as illustrated in facilitates load balancing. Workflow nodes advertise the workflows they support to proxies. Workflow nodes may also advertise class of users and service domains they can support. A proxy may use this information to forward appropriate service requests to appropriate workflow nodes. A proxy may advertise workflows it receives from associated workflow nodes to other proxies. This way a proxy can know how to reach the particular proxy that can execute a requested workflow and be able to route requests to it.

In some embodiments locating proxy aggregates service information and publishes aggregated information. Locating proxy may be used to hide the service topology inside a service provider. For example a service provider who supports multiple services e.g. services provided by service nodes and in datacenter may only publish its locating proxy address and internally route the requests to a dynamically or policy selected proxy. Locating proxy can also be used to implement high availability of services by routing service requests to where the requests are best fulfilled. Locating proxy may statefully inspect received requests and authenticate the senders before forwarding the requests further. It may rate limit requests from a particular source and may be capable of intrusion detection and prevention for protecting an internal network from denial of service DoS and DDoS attacks. Nodes behind locating proxy e.g. proxies and may then assume that packets entering them are secure. This in some embodiments may obviate the need for service authenticating the user requests and building security defenses.

In some embodiments locating workflow node may have rules to forward requests based on policies. For example locating workflow node may determine that service requests from customer node must be always directed to a definite location e.g. datacenter . Locating workflow node may choose the nearest service creation location or route to a location that has resources available.

In some embodiments locating proxy may provide one or more functions as being a node at the border of a network. For example locating proxy may be considered to be at the border of datacenter with respect to one or more of customer nodes and . As another example locating proxy may be considered to be at the border of datacenter with respect to nodes in datacenter . A function that may be performed by locating proxy is inspection of headers of request packets e.g. a request packet sent form customer node to service node . The inspection may include determining whether the request packet was sent or routed inadvertently or determining whether the request is malicious. Proxy may also be configured to reject the request packet or sanitize the header of the request packet.

As another example locating proxy may insert headers into messages based on policies at the edge of a network. For example datacenter may have policies that apply to all incoming packets and locating proxy may modify headers of packets sent to nodes in datacenter according to one or more policies associated with datacenter . This may allow for a convenient method to apply policies at one point without users or nodes of a network e.g. those in datacenter or customer nodes and to be familiar with such policies. A node can receive a packet modified by locating proxy e.g. service node . The modified messages can look like user requested transactions.

As another example locating proxy may modify addresses. In some embodiments locating proxy may perform network address translation of messages regarding management of network based services such as the functions of proxies and discussed above . This may serve to hide the network topology related to proxies and as well as workflow servers and .

As another example locating proxy may detect and address concurrent requests from the same source e.g. customer node sending parallel request for services from service node . This can be problematic because resources may be allocated and released in parallel and can cause confusion in the system thereby leading to one or more security threats. Locating proxy may be configured to forbid parallel requests and thereby protect the system.

As another example locating proxy may rate limit requests from a single source e.g. customer node sending requests for service to service node . This may allow users e.g. those associated with customer nodes and to have a fair share of services e.g. those provided service nodes and . A single user can potentially overload the system by sending e.g. periodic analytic requests using automated mechanisms. Rate limiting can reduce or prevent overuse.

As another example locating proxy may be involved with virtual private networking VPN or Internet Protocol Security IPSec sessions. Locating proxy may perform public key authentication using key chains in order to validate that a user e.g. associated with customer node should have access to services e.g. provided by service node . Locating proxy can determine whether a user is authorized to receive a requested service.

As another example locating proxy can translate between different service request formats. For instance a locating proxy can translate between an externally exposed API e.g. by service node and an internal protocol for managing network based services.

In some embodiments system depicts a user e.g. at customer node using cloud services from different cloud providers e.g. provided by service nodes and using a common protocol e.g. through communication between proxies and . This may allow the user to move across service providers or source the same service in a different geography from a different provider.

In some embodiments system depicts a user e.g. at customer node interoperating in house or private clouds e.g. of which customer node is a part with those in the service provider domain e.g. a domain associated with service node . As an example workloads may be moved between the private cloud associated with customer node and a public cloud associated with service node using communication between proxies and . As another example virtual services may be created using a common protocol in the public cloud associated with service node as in the private cloud associated with customer node via proxies and .

In some embodiments system depicts a service provider e.g. associated with service node interoperating its service with another service provider e.g. associated with service node using proxies e.g. proxies and . As an example the service providers may source each other for services when demand grows. As another example one service provider may use the other service provider s service as backup or for disaster recovery under an outage. Service providers may agree to host services in each other clouds where a workload moves between service providers located in different geographies. As another example a service provider could source services across different service providers by using interoperability provided by proxies such as proxies and .

In some embodiments system depicts how a cloud provider may deliver many kinds of services layered on top of one another. For instance a SaaS service may use a platform as a service PaaS service. A PaaS service e.g. represented by service nodes and may use a IaaS service e.g. represented by service nodes and network and security services or other suitable services. A cloud provider may build services incrementally and interoperate services across tiers. This may avoid for example having to build a new IaaS system for every new PaaS service or a new PaaS service for every SaaS service. The interoperability may be provided using proxies such as proxies and communicating with each other using a common protocol related to management of services.

In some embodiments system depicts how a cloud provider may source a service from more than one vendor. Examples of such services include compute virtualization storage network and security. For example customer node may seek a service from service node such as a SaaS service. In this example service node may source services associated with the offered SaaS service from service nodes e.g. offering a storage service and e.g. offering a security service . Proxies and may be used in such an example to allow for sourcing services from the multiple locations without requiring that customer node being made aware of how services are being sourced. Such interoperability may be provided by the proxies communicating with each other using a common protocol related to management of services.

In some embodiments system may allow for customers to define service requests at various levels of granularity. For example a customer may desire a single request to provision compute storage network and another customer may request these three services one by one. Such differing requests may take place at one or more points in system . For example a service provider e.g. associated with service node might publish customer specific workflows e.g. using proxy and translate them at the edge of a cloud. As another example a service provider may publish workflows that are translated into detailed tasks to be executed by another service provider. As another example a customer e.g. associated with customer node may define workflows that are translated as a request leaves the customer premise e.g. at proxy .

In some embodiments headers include fields with names and values. The order of fields is not specified in a SOP message but it may be helpful if fields relevant to service routing To From Exchange Via are present at the top of the message to facilitate rapid processing. Example message name headers 

The number following the Message Type indicates if the message is being re transmitted as the same message in the same transaction. This number can be incremented by a sender whenever a message is re transmitted. A receiver may give higher priority to re transmitted messages.

A proxy can advertise its presence along with the ability to proxy for certain services. A service node can discover service specific proxies by listening to proxy advertisements. A service node should also be able to trigger service discovery e.g. because the service node may have been out of service when the proxy advertised its presence. Two messages may be used in SOP ADVERTISE and DISCOVER messages to support proxy discovery. The proxy sends an ADVERTISE message to announce its presence and ability to handle some services. The service node may use a DISCOVER message to trigger the ADVERTISE message if an ADVERTISE message has not been transmitted or if it was transmitted but the service node was not operational to receive it. In some embodiments these two messages may be independent requests and not related as request response. A proxy may periodically send an ADVERTISE message to announce its presence. A service node may send a DISCOVER message whenever it starts up and if an ADVERTISE has not already been received. A proxy may send an ADVERTISE message in response to receiving a DISCOVER message if the service types in the DISCOVER message match with the service types supported by the proxy. The DISCOVER message may be broadcasted. The ADVERTISE message may be sent as a unicast. An ADVERTISE message sent in response to a DISCOVER message may be sent as a unicast message the unicast address is derived from the received DISCOVER message .

After receiving an ADVERTISE message from a proxy and if the service interests match a service node a workflow server a user or a proxy may register with the proxy. If a service node supports multiple services it may register with those proxies that support those services. If a client is interested in services supported by multiple proxies it may register with all of them. If a proxy is interested in exchanging service information with multiple proxies it should register with them. Registration identifies the service node workflow server user or proxy to the registering proxy. A proxy receiving registration may initiate authentication during the registration. A proxy may interact with an AAA server to authenticate and or challenge the registration identity. Registrations may be carried out periodically and they may serve as a keep alive mechanism with a proxy. A registration may be used to determine the location of a user proxy workflow server or service node and location based policies can be applied in service management.

In some embodiments the ADVERTISE message may be sent by a proxy to advertise its presence and willingness to proxy for certain types of services. The SDF payload e.g. included in attributes and service descriptors of packet in the message indicates which service domains it can support. In the example message below the proxy supports the iaas.compute domain of services. The message may carry a Registration Timeout header. The message may also carry other Timer values and Retry counts as a way to globally configure all service nodes in the network uniformly. Example 

In some embodiments the DISCOVER message is sent by a service node to discover proxies that might be willing or capable to act as proxy for its services. The SDF content in the message indicates service capabilities in the service node. In the example below the service node is capable of iaas.compute domain of services 

In some embodiments the PUBLISH message is sent by a service node whenever its service capabilities change when the Publish Timeout timer expires or after a service restart after a registration whichever comes earlier. This message indicates the current service availability of the service node to a proxy. The proxy will use the information given in the SDF payload to update its service database. The capabilities indicated here would be used by the proxy to route service requests towards the service node. The capability and availability inside the SDF indicate the total capacity and the capacity that is available currently. Example PUBLISH message 

In some embodiments the REGISTER may be used by a service node a proxy a workflow server or a user to register with a proxy after a new proxy is discovered or when the Registration Timeout expires whichever comes earlier. The Node Type header informs the proxy about the type of registering entity. If the Node Type header indicates a service node then the message may have the Transfer Node header that indicates the type of mobility the service node supports. For other node types the Transfer Node header may be absent. The REGISTER message is used by a proxy to establish the identity of the service node e.g. its domain name and IP Address . The Proxy may initiate authentication procedures with the registering entity after the REGISTER message is received. If the registration fails the proxy may not register the entity. The REGISTER message may be used by the proxy as a heartbeat or keep alive mechanism. The proxy can be configured to de register an entity if three successive Registration Timeouts have expired and remove all information related to that service. The proxy may initiate service recreation procedures for all services under that service node at another service node when that service node has been de registered due to the expiration of the Registration Timer. Example REGISTER message 

In some embodiments the SUBSCRIBE message allows a SOP network element to request updates on a particular type of service capability. The SDF payload indicates the capabilities for which the requestor is subscribing. A workflow server can subscribe with the proxy for all updates to services and all updates to user registrations. A user may subscribe with the proxy to receive workflow and service related updates. Example SUBSCRIBE message 

In some embodiments the TRANSFER message is sent by a proxy to initiate a service transfer. The From and To headers indicate the source and destination proxies. The Source and Destination headers indicate the source and destination service nodes. The Requestor header identifies the initiator of the transfer e.g. a proxy . The TRANSFER message sets up a session that initiates a service transfer. It may not be responsible for actually transferring service state from one service node to another. For example each service may choose its own methods to transfer state such as FTP to transfer a file . The SDF payload in the TRANSFER message indicates to the destination service node the capabilities expected in the transfer. For example these capabilities may indicate the total amount of memory or storage required to accept a moving virtual machine. The content of that memory is outside scope for SOP and to be handled separately. Example TRANSFER message 

In some embodiments the UPDATE message can be used by a proxy to request a service update to a service node. The UPDATE message refers to the task to be executed through the Task ID header. The receiver of the request may obtain a description of the task by querying the workflow server with the Task ID provided in the message. Example UPDATE message 

In some embodiments the WORKFLOW message is used by a client or a proxy to initiate workflow execution. It contains the Workflow Name that needs to be executed. It contains a reference to the prior Workflow ID when the request involves deletion or transfer of a prior executed workflow. Example WORKFLOW message 

In some embodiments SOP may include two kinds of service publishing. First a service node publishes its capabilities to a proxy. Second the proxy publishes the capabilities of the service node to other proxies and users. These publications build up the service routing tables in a network and users and proxies can know how to route a request to a service. Service publishing may use a PUBLISH message. This message is used in a request response configuration so a response is sent by the receiver. A service node may send a PUBLISH message in part due to service virtualization. Service nodes may be capable of hosting multiple virtualized service instances. As those instances are allocated the total virtualized capacity in the service node reduces. The service node may inform an associated proxy about its current capacity to host services. A proxy may aggregate these capacities and use them to determine the placement of services. A service node may send a PUBLISH message to an associated proxy in the following three cases whichever comes first 

a. Periodically based on a time indicated by the proxy in e.g. an ADVERTISE message sent by the proxy . A proxy may set a service node s capabilities to null if three successive PUBLISH messages have not been received.

c. Whenever the service capabilities of a service node changes this may be typically after a new service allocation or partial failure outage.

A proxy may also send PUBLISH messages to other proxies and users to propagate service capabilities in the network. As new services are made available or existing ones are removed users may know the available list of services. A proxy can dynamically publish its catalogue of discovered services to a user. These publications can carry two kinds of information. They can have an aggregated view of service capabilities available via a proxy. This information is useful to a receiver to determine which services can be accessed via a publisher. The PUBLISH message can indicate which workflows can be requested through a proxy. Workflows may be tagged by service types. In some situations publishing an aggregated view of services may be undesirable as it may expose a provider s internal details to other providers or users. The PUBLISH message may however carry aggregated services to a limited set of trusted proxies. It may carry workflows to users or proxies that may use the workflows. To avoid flooding a user or proxy can indicate its service interests by sending a SUBSCRIBE message to a proxy. The SUBSCRIBE message can indicate the sender s service interests which act as a filter for a proxy to forward those service specific details. A proxy may use information gleaned during registration to determine which users and proxies should be forwarded which information. For example it might forward aggregated service information to proxies within a trust zone but send workflows to external users.

Separating DISCOVER ADVERTISE messages from PUBLISH SUBSCRIBE messages is that the ADVERTISE DISCOVER messages may be broadcasted without responses to them whereas the PUBLISH SUBSCRIBE messages are always unicast and every message has a response. Both REGISTER and PUBLISH messages indicate a service node s information to a proxy. In some embodiments the difference between them is that a REGISTER message informs a proxy about the service node s identity domain name and IP address whereas a PUBLISH message informs a proxy about its Service Domain Name SDN and capabilities. Similarly a REGISTER message informs a proxy about the user s identity domain name and IP address whereas a SUBSCRIBE message informs the proxy about the user s service interests. Hence in some embodiments distinctions exist between capability and interest as described in service domain name information and identity which is in terms of DNS and IP. A reason to keep REGISTER messages separate from PUBLISH SUBSCRIBE messages is to separate identity e.g. DNS and IP from service information. Identity is associated with authentication and if a user or service node have been authenticated this identity may be usable across all service requests. Authentication may not be required in every service transaction. Having identity validation associated with REGISTER messages allows for other requests to use that identity and obviates the need to authenticate the user or service node separately. REGISTER messages may be used as a single sign on feature for services.

In some embodiments service management performed by proxies involve at least five functions CREATE DELETE UPDATE GET and TRANSFER. CREATE DELETE and UPDATE functions address the creation deletion and updating of services. The GET message requests a description of the service or workflow or tasks depending on the context. For example a GET message can fetch the total allocated size of a storage disk but is usually not used to determine the content of that disk. The TRANSFER message addresses service virtualization and movement of services. The TRANSFER message sets up the context in which service information may be transferred from one point to another such as the source and destination addresses and the type of information to be transferred. Actual transfers may be determined by the service itself such as use of SFTP to transfer memory snapshots when moving a virtual machine .

In some embodiments the CREATE message is used by a proxy to request a service creation to a service node. The CREATE message refers to the task to be executed through the Task ID header. The receiver of the request can obtain a task description by querying the workflow server with the Task ID provided in the message. Example CREATE message 

In some embodiments the DELETE message is used by a proxy to request a service deletion to a service node. The DELETE message refers to the task to be executed through the Task ID header. The receiver of the request can obtain a task description by querying the workflow server with the Task ID provided in message. Example DELETE message 

In some embodiments the GET message is used by a service node to obtain a task description from a workflow server. It can be used by a proxy to request a service node description prior to a service transfer. It can be used by a proxy to obtain a workflow or task description from a workflow server. The context of the transaction determines which of these functions need to be achieved. Depending on the context various headers must be present. To request a service node description a proxy can include the Service ID header to refer to the specific service whose description is required. To get a workflow or task description the appropriate Workflow Name Workflow ID or Task ID headers are present. The Query Type header can be present to describe the type of query. Example GET message 

In some embodiments SOP addresses reliability concerns that span multiple service nodes. An example service may require management across compute network storage security and other domains. Failure in a service node providing one of these services may trigger a rollback of actions in service nodes providing the other related services. This may be performed by sending a CANCEL message to the service nodes that are impacted by a failure. If for example all service nodes have been successfully invoked then a COMMIT message is sent to the service nodes. Service transactions in SOP may be committed within a certain time period. For example if the time for a commit to occur has elapsed the service will be automatically canceled by the service node. This mechanism is helpful in scenarios where the user the proxy some service node or a combination of these fail. If the proxy has failed and does not send the COMMIT message to a service node the service node can rollback the transaction. If the service node has failed and does not respond to the proxy the proxy may send a CANCEL message to other proxies and or service nodes. If a proxy has failed and does not respond to the user the user for example can be assured that they are not billed for the service. As another example the provider can be assured that unless a COMMIT message has been sent service resources will not be leaking due to failures.

In some embodiments the CANCEL message can be used to cancel a transaction that has not been committed in case of errors detected or in case of a timeout. The cancellation is a new transaction and it requires a response. The CANCEL message refers to a task to be cancelled through the Task ID header. The receiver of the request may obtain a description of the task again by querying the workflow server with the Task ID provided in the message. Example 

In some embodiments the COMMIT message is used to commit CREATE DELETE UPDATE or TRANSFER transactions. This message is sent by a proxy to each service node involved in a workflow after all tasks have been successfully completed. In some embodiments the workflow specification may override this through a specification of when the COMMIT message should be sent. The COMMIT message refers to the task to be committed through the Task ID header. The receiver of the request may obtain a description of the task again by querying the workflow server with the Task ID provided in the message. The proxy can send a COMMIT message to the workflow server to commit the workflow. This is an indication to the workflow server that the workflow execution was successful. The workflow server upon receipt of a COMMIT message will store the workflow instance for reference later and return a Workflow ID. This Workflow ID can be used to recreate services in case of disaster recovery or reverse them in case of service deletion . Example COMMIT message 

In some embodiments the 100 TRYING message can be sent by a proxy on receiving a workflow request. It can indicate that the proxy has received the request and is attempting to execute it. This message is sent by a receiving service node upon a CREATE UPDATE DELETE or TRANSFER request. This message informs the proxy that the request has been received and it being processed. Example of the 100 TRYING message 

In some embodiments a proxy may send a 183 WORKFLOW PROGRESS message periodically to a client keeping it informed about the update. This message may have a workflow description that describe the progress in execution. Example of the 183 WORKFLOW PROGRESS message 

In some embodiments a 200 OK message can be sent by multiple entities including a workflow server a proxy and a service node to indicate successful completion of the requests. Depending on the context message contents and headers will vary. Below is an example message sent by a proxy on completion of a CREATE task 

In some embodiments the 305 USE PROXY message is sent by a proxy if it wants to redirect the requestor to another proxy and will not service the request itself. The message includes the Alternate Proxy header. Example 305 USE PROXY message 

In some embodiments the 400 BAD REQUEST message is sent by a proxy or a workflow server or a service node if they find a request malformed. Below is an example message 

In some embodiments the 403 FORBIDDEN message is sent by a proxy or a workflow server if they find the user is not authorized to perform an operation. This may be used by a proxy to indicate that a need to authenticate. The message may be used if a proxy or workflow server finds that a user is not authorized to execute a workflow. Example 403 FORBIDDEN message 

In some embodiments the 500 SERVER INTERNAL ERROR message is sent by a proxy or a workflow server or a service node if they tried to process a request but failed due to some internal error. A service node may send this request if it fails to perform a requested operation e.g. service creation deletion or update . Example 500 SERVER INTERNAL ERROR message 

In some embodiments the 504 SERVER TIMEOUT message is sent by a proxy if one of the service nodes fails to respond to a request and the proxy times out on retransmits. Example 504 SERVER TIMEOUT message 

In some embodiments the 603 DECLINE message is sent by a proxy workflow server or service node if it is not able to support the request because there is no capacity available. This response can be sent if the proxy knows that no other proxy will be able to support this request otherwise a 305 USE PROXY may be sent . The scope of the DECLINE message is the set of proxies that the proxy sending the message is aware of. Example 603 DECLINE message 

In some embodiments SOP can use UDP or TCP transports. Service management creates deletes configures and moves services. It is beneficial to have these transactions be highly reliable and scalable. SOP has built in timers to COMMIT CANCEL procedures to deal with network reliability issues e.g. in case the proxy fails or the connection to the proxy fails. As such SOP can work with the use of either TCP or UDP. The choice of transport therefore may depend on the desired scale and reliability of deployment. Limitations of transport may also be overcome through additional means. For example it is possible to deploy a set of TCP proxies that offloads TCP scale outside the SOP proxy. As another example UDP transport can be used in combination with shorter retransmit timers and increased retransmit counters. SOP can dynamically distribute timer and counter values across the network.

In some embodiments headers have source and destination names. A request may traverse through proxies and which may keep track of the request paths and correlate them with response paths using the source and destination names. Headers may also include transaction identifiers that may be used to correlate requests with responses. Headers may include sequence numbers that may be used to identify the order of message transmission. Fields to define content type and content length may also be included in headers .

In some embodiments entities in SOP can be addressed by a user domain name. The user default can be used in the following circumstances 

Headers included in packet in various embodiments may be defined to suit various goals. The following is a list of example headers 

 a active workflows all workflow ids against a workflow name. The Workflow Name can be present in the request.

 b active tasks all task ids for a Workflow Name or Workflow ID. The Workflow Name and or Workflow ID can be present in request.

 c workflow name description of a Workflow in Tasks specified by a Workflow Name. The Workflow Name can be present in the request.

 d workflow id description of tasks that were performed in a particular instance of a Workflow denoted by the Workflow ID. The Workflow ID can be present in the request.

 e task id description of the attributes that make up a specific task referenced by the Task ID. The Task ID can be present in the request. Workflow Name and Workflow ID can be present.

In some embodiments service nodes may be addressed by a name such as service sn.provider.com where sn is a service node and service is a virtual service instance at the service node. If there is one service node for many virtualized service instances the service node can receive all messages for virtualized service instances even though they are addressed to a particular service . The service node may take actions on a request on behalf of the service or pass on information to the service. When messages are being broadcast an address of the type default default.provider.com may be used and the packet will use a broadcast IP address.

In some embodiments one or more of the following timers and or counters can be used by proxies e.g. proxies and in implementing a common protocol for managing services 

In some embodiments attributes and service descriptors may include information regarding names of services service classes syntax for properties of service classes semantics in a service class bundles of multiple service classes into a single workflow and description of tasks and workflows.

Service descriptors may include XML schemas. For example an XML scheme may be included for a hub in a domain named iaas.network would be 

As another example an XML scheme may be included for a router in a domain named iaas.network and adds ip address and subnet mask elements would be 

The XML element is used to encapsulate the domain specific service description that the receiver can interpret. This element has the following attributes 

The example domain scheme described here can be used in conjunction with existing standard or non standard service definitions. For example the domain scheme may be used in conjunction with an existing specification such as Open Virtualization Format OVF described at http xml.coverpages.org DMTF OVF v10 DSP0243.pdf. The OVF scheme will need to be identified by a domain name such as iaas.compute.virtual. This is shown below.

In some embodiments there may be a need for vendors to deliver service customizations that are non standard. Such services may be defined in the same or similar manner as standard service definitions. To indicate that it is a vendor specific domain and may not be understood by every network element a domain may be a given a name that does not overlap with standard domain names and b identified by the def vsd attribute in the element. For example a vendor may define their private domain vendor.router and this domain would be referred to as follows.

In some embodiments vendor defined domains may begin with the vendor s name. Vendor specific domains VSDs may be treated differently in how they are used across boundaries. For example a vendor might advertise a VSD to selected customers.

In some embodiments XML schemas associated with service domains define elements their attributes and the syntax for describing elements and attributes. Domain semantics may be used to describe the relation between attributes within and across service domains. The described relations may indicate how resources logical virtual or physical are allocated to populate elements and attributes in XML documents. For example the MAC address assigned to a virtual machine may be unique amongst hosts that the virtual machine is going to interact with. This uniqueness is a relation between the various MAC addresses. Continuing the example the MAC address of the virtual machine may also be in access lists on the network. This is a relation between the compute and network domains. As another example network based storage may be mapped to file systems on a host requiring a mapping of logical and virtual resources across compute and storage domains. To restrict access to the storage to certain hosts there may be a relation between host network and storage domains. Relations between attributes within and across domains constrain resource allocation. When resources are allocated according to these constraints services created across different domains work together with little to no conflict. Domain semantics is the relation between attributes within a domain and across domains.

One manner to express the relations between attributes is using a high level language such as XML. For example XML technologies such as Object Constraint Language and SCHEMATRON can be used to describe semantic relations. An example constraint is shown below where a virtual local area network VLAN configured on a virtual machine interface is equal to the VLAN access allowed on the network switch.

In some embodiments semantic rules that specify relations between domain attributes may be defined in separate Domain Semantics Rules DSR files. Each DSR file may be associated with a workflow. Similar to hierarchical domain specifications it is also possible to define parent and child DSR files. Specification of semantics through DSR files may provide for a service to be rapidly customized and for new services to be created. A reusable hierarchy of DSR files may be defined to facilitate service relations across domains.

An example XML schema that includes information included in attributes and service descriptor follows 

In some embodiments packet may illustrate a manner in which attributes and descriptors separate a set of domain specific meta attributes and vendor specific service descriptions. The meta attributes include things like service type e.g. compute network storage firewall load balancer application and other suitable services vendor software and hardware versions domain specific attribute parameters or attributes such as attributes specific to Communication as a Service Network as a Service Storage as a Service Software as a Service or other suitable services . The meta attributes can also identify the type of format used for the vendor specific service description. These meta attributes can be understood by one or more proxies e.g. proxies or because there is need for a minimal connection between the service description and the management provided by proxies. The meta attributes may help a proxy aggregate service types logically which is essential to select the appropriate kind of resource for service creation. Once the meta attributes have been standardized the service description data can be non standard vendor specific or otherwise suitably configured. Using this separation any kind of service description may be transparently communicated through a proxy. Some of these descriptions could be standardized and others proprietary. Service descriptions can carry command line interface commands XML packets text based or binary formatted documents. The proxy may not need to know what is inside a service description other than the meta attributes. The domain specific meta attributes can be borrowed or developed by different standards organizations that are standardizing different kinds of network based services e.g. cloud services .

In some embodiments a proxy can obtain the combination of proprietary and standard descriptions from a policy server and pass them to a hardware or software entity transparently. This may enable the possibility that such an entity can be upgraded and enable a transparent use of new features with the same proxy. The attributes to such an entity can change the vendor specific attributes while preserving the domain specific attributes. Domain specific proxies can be developed which specialize in a particular kind of cloud orchestration using the proposed separation between meta data and data. The mechanism can also be used to create multi vendor and multi product service management that span across several different service domains.

Information stored in storage of nodes in system may be implemented using any suitable structure for storing and retrieving information. Databases file systems tables lists or suitable combinations of these structures are examples of how such information may be stored. Computer readable non transitory storage media may be used such as a semiconductor based or other integrated circuit IC e.g. a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive another suitable medium or a suitable combination of these where appropriate. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

When a workflow spans across multiple service nodes e.g. compute storage network security and or software there may be a location e.g. proxy and workflow node where the workflow is broken into individual tasks for execution. Branching a workflow involves allocating tasks to different service nodes. In some embodiments the location e.g. proxy and workflow node in the network where the workflow is decomposed into tasks may be referred to as the workflow anchor. The component tasks in a workflow are determined by the workflow node at the workflow anchor e.g. workflow node . These tasks may be initiated by a proxy e.g. proxy at the workflow anchor.

In some embodiments a flowchart may be created using tasks task groups and workflows by labeling individual items in the workflow and ordering the items using for example prev and next tags. Each workflow may have an associated workflow anchor. The following XML is an example implementation of a workflow 

The type of each task may map to one of the messages used by a proxy of system . The server attribute defines the service entity that will process the task or workflow. The server could be a service node e.g. service node a proxy e.g. proxy or a workflow server e.g. workflow server . The instance attribute in the workflow may be an exchange value that represents one instance of an executing workflow.

In some embodiments a WORKFLOW message is used by proxies implementing SOP to perform the functionality discussed above regarding workflows. The WORKFLOW message may contain the workflow name being requested. The request may also contain a complete or partial workflow description. All network elements prior to a workflow anchor may forward the WORKFLOW message request without branching it into tasks. When receiving the WORKFLOW message the workflow anchor extracts the workflow and sends it to the relevant workflow servers along with the workflow name using the GET message. This requests that the workflow server validate and complete the workflow specification. The workflow in the GET request serves as input to the workflow server to construct a complete workflow specification. The workflow server may override the workflow description or may reject the GET request using for example configured policies. If the workflow has been accepted the complete workflow specification can specify individual tasks such as CREATE DELETE TRANSFER COMMIT or other suitable tasks that the workflow anchor can execute. On receiving a completed workflow specification the workflow anchor can proceed to executing the workflow. If the workflow has been rejected the workflow anchor can forward a rejection indication to the upstream network element.

In some embodiments the WORKFLOW message allows service bundles to be treated as atomic services for upstream network elements. A customer or provider can create a workflow description and use a PUBLISH message to send it through the service network using a unique service name. Users or service providers can request this service through the WORKFLOW message. By anchoring the workflow in a particular location the correct execution of the workflow can be guaranteed. The workflow anchor ensures that the workflow is validated and authorized prior to execution and accounted after completion.

In some embodiments a workflow anchor is helpful because once a workflow has been branched into tasks other downstream entities receiving such tasks e.g. proxies and do not have the entire workflow and so they cannot manage the workflow as a whole. The workflow anchor e.g. proxy and workflow node manages the workflow. It is responsible for a executing the right tasks b executing these tasks in the correct order c correctly accounting for tasks after execution and d handling failures in the right way when they arise among other responsibilities.

In some embodiments network elements that are upstream from the anchor location may not be able to branch the workflow into tasks. These elements may validate the workflow but they are not responsible for doing so. The nodes including in the anchor location may be responsible for validating the workflow and correct execution. There may be an interface through which proxies and clients can request complete workflows.

In some embodiments a workflow request received at a proxy e.g. proxy at the anchor location may be incomplete. The request may specify parameters about a virtual machine and may leave the details of network storage and security to the anchor location for example. Such a request may be forwarded to an associated workflow node e.g. workflow node to obtain a complete and accurate description of the workflow prior to executing it.

The workflow anchor can be located at multiple points in the network such as at a customer location or a service provider location. For example the workflow anchor may be at a client of services and the client will have to manage the workflow execution service accounting and failure handling. In such an example customer proxies and service provider proxies e.g. proxies and may inspect or authenticate the messages in transit but they may not have knowledge of the complete sequence of tasks and will not be able to validate if the workflow anchor is executing the right sequence of tasks.

In some embodiments the workflow may be anchored using a customer s proxy or a service provider s proxy. A client would then request workflow execution from one of these proxies. The client may refer to the workflow through some workflow name in order for the receiving proxy to validate if the request is correctly formed. Execution of the workflow would be managed by the proxy of the customer or service provider while the client may still know the workflow composition and can frame the workflow request. The proxy serving as a workflow anchor will validate the workflow before branching tasks. The proxy may ensure accounting and failure handling.

Depending on the deployment scenario the workflow anchor may be situated at various points in the network. For personal clouds as an example a client may be a valid anchor location. For private enterprise clouds as another example a customer s proxy may be a valid anchor location. For public clouds a service provider s proxy may be a valid anchor location. For community clouds a service node may be a valid anchor location.

An example application of system involves a situation where a customer creates a complex service by combining workflows in a private cloud and a public cloud through a single request. Another example involves a service provider creating services in its network and another service provider s network through the same request. As another example a single request may be managed by multiple domain specific proxies e.g. proxies and within a provider s network. To distribute workflows across service domains and provider customer boundaries a large workflow may be decomposed into individual workflows owned by individual proxies.

As an example operation proxy may receive a two stage workflow called MN M and N are two stages and may forward the two stages to proxies and . Proxy may execute workflow M using service node . Proxy may divide workflow N into workflows X Y and Z. Proxy may execute workflow X using service node . Proxy may delegate workflows Y and Z to proxies and respectively. Proxy may execute workflow Y using service node and proxy may execute workflow Z using service node .

In some embodiments the implementation of a workflow may be changed while keeping the interface to it unchanged. The mapping between workflows and their branching patterns may also be changed. This may give operators flexibility in deploying services.

In this example message the service node supports the iaas.compute domain. It sends the DISCOVER message to find proxies that may manage service for this domain.

At step in some embodiments the proxy sends an ADVERTISE message indicating its presence and readiness to proxy for certain service domains. This may be sent on initialization on the receipt of a DISCOVER message or on the expiration of the Advertise Timeout whichever comes earlier. The ADVERTISE message will be sent as a unicast if sent to a specific service node after receiving a DISCOVER message from it. Otherwise the proxy will broadcast the DISCOVER message to all service nodes in the network. The ADVERTISE message indicates service domain names so that service nodes with those capabilities need recognize it. An example of the message sent at this step follows 

The ADVERTISE message also has the function of globally configuring corresponding service nodes by sending out Timer and Counter information in the message itself. Each transaction can subsequently override these values for that transaction alone. Unless overridden in those requests these values apply for all transactions.

At step in some embodiments on receiving the ADVERTISE message sent at step a service node may respond with a REGISTER message if the domains match. The REGISTER message would be sent after receipt of the ADVERTISE message if the service node has not already registered or upon the expiration of the Registration Timeout whichever comes first. The REGISTER message identifies a service node to the proxy and acts as a heartbeat between the proxy and the service nodes. An example REGISTER message follows 

In the example above the REGISTER message is being sent for the first time to the proxy. The service node does not yet have an identity. The From header therefore has a default address. For subsequent REGISTER messages the identity assigned to the service node in a prior REGISTER message can be used.

At step in some embodiments after receiving a REGISTER message and after validating that the service node belongs to the service domain that the proxy is configured for the proxy responds with a 200 OK response indicating a successful registration. If the REGISTER message had not indicated a unique name in the From field the proxy response contains a Service ID header assigning a name to the service node. The service node uses the assigned Service ID henceforth and the proxy may reject all requests that do not match the assigned Service ID name the default name is always admitted . The proxy matches the name of the requestor against its IP Address that was used during for the REGISTER message for subsequent requests. Example message sent at this step 

At step in some embodiments upon a successful registration the service node sends a PUBLISH message to the proxy providing details about available services. While the REGISTER message is sent periodically the PUBLISH message is sent when service availability changes after the first registration or when the Publish Timeout expires whichever comes first. A service node can send the PUBLISH message after service creation or deletion to update the proxy about its new capabilities which may be increased or decreased . An example of a message sent at this step follows 

At step in some embodiments upon receipt of the PUBLISH message the proxy forwards it to an appropriate workflow server. This can allow the workflow server to know of the service node s capabilities which can then be utilized in service allocations. After successfully updating its service repository the workflow server responds with a 200 OK response step . The proxy forwards the 200 OK response back to the service node step . An example of this response follows 

In some embodiments at step a SUBSCRIBE message is sent by a user. It may be done after a new registration when the interest list of services of the user changes or upon the expiration of the Subscribe Timeout whichever comes first. The SUBSCRIBE message is a request response sequence and the proxy sends a 200 OK response if the SUBSCRIBE message matches the service capabilities of the proxy. If a proxy s service capabilities change the proxy sends out a new ADVERTISE message listing new domain capabilities. If those capabilities are of interest to a user a new SUBSCRIBE message may be sent expressing interest in receiving information about those services. If a SUBSCRIBE message is sent without any specific domain the proxy interprets it as an interest in all service domains. The user includes the Node Type as a service client . An example message sent at step follows 

At step in some embodiments the proxy forwards the SUBSCRIBE message to a workflow server. This may happen when a SUBSCRIBE message identifies service domains that the proxy can support. The workflow server validates whether the user is authorized to receive those services. If the user is authorized the workflow server responds with a 200 OK response step to the proxy. At step the proxy forwards the 200 OK response to the user step . An example of this response follows 

At step in some embodiments the workflow server sends updates on services through the PUBLISH message. These updates are sent after the first SUBSCRIBE message is received whenever services availability changes e.g. new services are available or old ones are removed or upon expiration of a Publish Timer whichever comes first. The PUBLISH message is forwarded to the proxy which will send it to the user step . The proxy changes the From header to its own address in some embodiments. This may serve to hide the workflow server from the user. The workflow server can identify categories of information to the user through a PUBLISH message. Examples follow 

Accordingly the PUBLISH message can have different types of content. The receiving proxy uses the Node Type header to apply a node specific policy of publishing in conjunction with other policies . The example below shows a PUBLISH message that publishes a workflow.

The workflow contains a list of tasks domains and attributes that the user needs to populate. The workflow server can mask one or more of the tasks service domains and attributes of a workflow that are visible to a user. In effect the user specifies certain portions of the workflow and leave the rest to the workflow server. The workflow can be viewed as an API exposed to the user where the user is allowed to identify certain parameters before communicating with the proxy.

At step in some embodiments after receiving the PUBLISH message the user responds with a 200 OK response confirming receipt of the message. If the user accepts the workflow it sends a 200 OK response which is forwarded from the proxy to the workflow server step . An example of such a response follows 

At step in some embodiments a SUBSCRIBE message is sent from proxy to proxy along with the service domains that it is interested in. This is done in a similar manner as step of . The Node Type header is set to service proxy . The subscribing proxy receives service information. Proxy forwards the SUBSCRIBE message to a workflow server at step in a manner similar to step of .

At step in some embodiments workflow server sends a 200 OK response to proxy . At step this response is forwarded to proxy . These steps are performed in a similar manner as steps and of .

At step in some embodiments workflow server sends a PUBLISH message to proxy . This message includes information about the workflows including management information and details or summaries of current capacities depending on configured policies . Proxy at step forwards the PUBLISH message to proxy . A 200 OK response is sent from proxy to proxy at step . Proxy forwards the 200 OK response to the workflow server at step . Steps are performed in a similar manner to steps of .

At step in some embodiments a user initiates a workflow by sending a WORKFLOW message. An example of this message follows 

The user indicates a Workflow Name that already exists. This message may contain a detailed specification of the workflow tasks and parameters. As the WORKFLOW request traverses the network towards a workflow anchor the request may be modified in transit by intermediate proxies. Each proxy looks up the source of the Workflow Name and forwards it to another proxy until it gets to the proxy that will serve as the workflow anchor which is illustrated in .

In some embodiments at step the proxy serving as the workflow anchor sends a 100 Trying response to indicate to the user that it has received the request and is processing it. An example of this response follows 

At step in some embodiments the proxy sends a GET request to a corresponding workflow server seeking detailing of the workflow. If the original request sent at step was received with a detailed workflow description the proxy sends the description to the workflow server. The workflow server uses the received workflow to determine a completed and finalized workflow using one or more policies. An example of the GET message follows 

The GET message includes the requestor name into the Requestor header. This may allow the workflow server to validate whether the indicated workflow is available for the Requestor and apply user specific policies if any.

At step in some embodiments the workflow server will then return a workflow description comprising of individual tasks using a 200 OK response. An example of this follows 

At this point the workflow server has created an instance of a workflow based on the request sent at step using one or more policies. This instance is referenced by the Workflow ID 68743693 . In this example it carries a detailed configuration of a virtual machine which is referenced by a Task ID 67439375 . The workflow server has allocated a server 4357254.provider.com for the CREATE task.

At step in some embodiments the proxy sends a CREATE request to the selected server service node . An example of this message follows 

The above CREATE request is sent by the proxy p.provider.com to a server 4357254.provider.com . The CREATE message informs the receiver that there is a Task ID 67439375 pending at ws.provider.com . The receiver should obtain that task and execute it. The Requestor field describes the user on whose behalf the request is proxied.

At step in some embodiments the proxy may request a second task to be performed by service node from the workflow server using a GET message. At step workflow server may be configured to send the requested information using a 200 OK response message. At step proxy may use a CREATE message to service node informing service node of the task. Steps and may be implemented in a manner similar to and .

At step in some embodiments service node downloads the task description from the workflow server identified by the Task ID using a GET request. An example follows 

The workflow server at step forwards a task description to the requestor as shown below. The task describes a workflow to be executed by the receiver pertaining to a domain iaas.compute 

If service node does not understand the task schema it can discard the description and send a 400 BAD REQUEST response. After completing the processing service node sends a 200 OK response at step . An example of this follows 

Similarly service node sends a 200 OK response at step after completing the processing associated with the CREATE message sent at step .

At steps and in some embodiments the proxy commits the service by sending COMMIT messages to service nodes and . The COMMIT message is useful when a the workflow may involve many transactions in parallel and the proxy may not commit requests if one of the transactions fails b the proxy may have failed after making request and the service node will then cancel the earlier transaction and delete services. The Commit Timeout timer received via the ADVERTISE message determines when transactions must be cancelled. An example COMMIT message follows 

On receiving the COMMIT message the service nodes activate the services if the services were dormant and send a 200 OK response illustrated as steps and . An example of this message follows 

The service nodes also send PUBLISH messages indicating their new capabilities and service availability. The capabilities may have been reduced. This is illustrated at steps and . Responses to these PUBLISH messages using 200 OK responses are sent to the service nodes by the proxies at steps and .

At step in some embodiments the proxy sends a COMMIT message using the Workflow ID to the workflow server. This is a reference to be used at the time of service deletion and they will define how create actions have to be reverted. Upon receiving a COMMIT message the workflow server creates a workflow description that the proxy can send to the user. In some embodiments only certain tasks need to be made visible to the user. For example if the use was allocating a virtual machine the address of the switch to which the virtual machine is attached should not be known although the address of the virtual machine itself should be known. The workflow server returns a workflow description that can be passed to the user. The workflow server returns this reduced task list to the proxy as part of a 200 OK response at step an example follows 

The proxy forwards at step the reduced task list information to the user as part of the response to the original WORKFLOW request. This information helps the user understand certain information about the service as well as what it needs to know to modify delete or transfer this service in future. The user may obtain this information again using a GET query specifying a specific Workflow ID Task ID and or other suitable information. The user may also send a GET query on a Workflow Name with Query Type set to active workflows and obtain all active Workflow IDs using a given workflow name. The Workflow IDs can then be used to query Task IDs and details of those task and Workflow IDs. The workflow server that responds to these queries can in some embodiments ensure that it is only sharing user relevant information and not information that the provider considers private.

In some embodiments service deletion works similar to flow regarding provisioning a service. In service deletion the initiating workflow is defined to be deleting a service instead of creating one. The deletion workflow request includes the prior Workflow ID and or Task ID. An example of this request follows 

The proxy sends a GET message to the workflow server asking for a workflow description. The workflow server returns a workflow that is nearly opposite from the workflow used in flow due to the actions of provisioning are reversed in deletion. The order of tasks may be determined by the deletion workflow. An example of the deletion workflow follows 

The workflow server allocates a new Workflow ID and provides tasks that reverse earlier service creation. The new Workflow ID has a reference to the earlier Workflow ID. In this example the task type is set to DELETE. The rest of the process remains unchanged from the process depicted in . COMMIT on the workflow server deletes the original Workflow ID and Task ID along with the new workflow and Task IDs that were created as part of the delete operation.

In some embodiments the service update message flow is similar to that depicted in . One difference is that the WORKFLOW request references prior Workflows and or Tasks that are modified by the UPDATE message. The service update workflow request includes the prior Workflow ID and or Task ID. The WORKFLOW request may also have a set of attributes being modified. Alternately the request may invoke a workflow while the attribute changes are determined by the workflow server. An example WORKFLOW requests follows 

The proxy sends a GET message to the workflow server asking for a workflow description. The workflow server returns a modified workflow in the sense that its tasks include service updates and references prior tasks. The order of tasks in the workflow is determined by the update workflow. An example of the workflow server s response follows 

The workflow server allocates a new Workflow ID and provides tasks that update the earlier service creation. The new Workflow ID has a reference to the earlier Workflow ID. The task type in the example is set to DELETE . When this update is completed the proxy commits the tasks and workflow using the COMMIT message. In response to the COMMIT message the workflow server may delete the Workflow ID and Task ID associated with the service update workflow and update the original Workflow ID.

At step in some embodiments a client e.g. customer node of initiates service mobility by sending a WORKFLOW message. The message includes references to past workflows and or Task IDs that need to be moved. The source proxy receives the WORKFLOW message and forwards the content of the WORKFLOW message to the workflow server using a GET message at step to obtain a description of the workflow. An example of the GET message follows 

At step in some embodiments if the workflow is authorized for the client and the workflow server can find the appropriate resources to move the service it sends a 200 OK response. An example of this follows 

At step in some embodiments the source proxy begins executing the service transfer by sending a TRANSFER message to the target proxy. The target proxy may be selected by the workflow server and populated as the server in the element of the task. An example of the TRANSFER message follows 

In some embodiments the target proxy selects the target service node for the service based on the received service description. After that it will forward the TRANSFER request at step to the selected service node to prepare it for receiving the service. If the allocation fails the target proxy may reject the request. An example of the TRANSFER message follows 

In this example the Requestor and Source headers are preserved to let the target source node know the identity of the proxy and service being moved. If the target service node approves of the move e.g. it has the necessary service domain capabilities and resources it sends a 200 OK response at step . The target service node may approve a modified service description from the one it received. The target service node must also add a Destination header as the name of the target service. An example of the response sent at step follows 

The target proxy sends the response to the source proxy at step . On receiving the 200 OK response the source proxy uses the received service description and sends it in a TRANSFER message to the source service node at step . If the source service node approves it the source service node initiates service creation at step using the Source and Destination headers as the From and To headers. If the service transfer is successful indicated by the 200 OK response sent at step the source proxy sends COMMIT messages to the source service node at step and to the target service node via the target proxy at steps and . Responses to these messages 200 OK responses are sent at step from the source service node and from the target node via the target proxy to the source proxy. Examples of the COMMIT messages follow 

The source proxy commits the workflow in the workflow server as well so that the new location of the service is known at the workflow server. This location may be used to determine subsequent mobility actions or service deletion. This is performed by sending a COMMIT message from the source proxy to the workflow server at step . The workflow server responds with a 200 OK message at step .

At steps and in some embodiments the source and target service nodes send PUBLISH messages to the source and target proxies respectively. This may be used to inform these proxies of the capabilities and resources of the service nodes after the service has been transferred. 200 OK responses are sent by the proxies to the service nodes indicating receipt of the PUBLISH messages at steps and .

At step in some embodiments the source proxy sends a 200 OK response to the client indicating the successful completion of the movement of the service.

At step in some embodiments a client e.g. customer node of initiates service mobility by sending a WORKFLOW message to the source proxy. This step may be performed similarly to step of . In response the source proxy may send a GET message at step to the workflow server for information regarding the workflow identifed in the message sent at step . The workflow server may send the information in a 200 OK response at step . Steps and may be performed in a manner similar to steps and of .

At step in some embodiments a CREATE message is sent from the source proxy to the target proxy. This is different than flow in that the TRANSFER message is not used. Instead the workflow delivers two independent but coordinated tasks one that creates a new service instance and the other that deletes the old service instance. Details from the information provided at step are used to implement the CREATE message at step intended to instruct the target service node to create the service instance being transferred in flow . The target proxy sends the CREATE message at step to the target service node and receives a 200 OK response from the target service node at step . This response is sent from the target proxy to the source proxy at step .

At step in some embodiments the source proxy sends a DELETE message to the source service node. This is so that source service node will stop providing the service that is being transferred from it to the target service node. At step a 200 OK response is sent from the source node to the source proxy in response to the DELETE message.

In some embodiments COMMIT messages are sent from the source proxy to the source service node at step to the target service node via the target proxy at steps and and to the workflow server at step . This may be performed in a manner similar to steps and of . Responses e.g. 200 OK responses to these COMMIT messages are sent to the source proxy at steps and . These responses may be implemented in a manner similar to steps and .

At steps and in some embodiments the source and target service nodes send PUBLISH messages to the source and target proxies respectively. This may be used to inform these proxies of the capabilities and resources of the service nodes after the service has been transferred. 200 OK responses are sent by the proxies to the service nodes indicating receipt of the PUBLISH messages at steps .

At step in some embodiments the source proxy sends a 200 OK response to the client indicating the successful completion of the movement of the service. Flow may be useful when the state of the service resides outside the service node e.g. an external database . Flow may be used for disaster recovery geographical redundancy or moving capacity dynamically from one site to another.

Advantages may be realized in one or more of the examples discussed above with respect to . For example service deployments may cross customer and service provider boundaries. Each customer or service provider may be able to enforce policy rules for service usage at ingress and egress points. As another example separate service dependent and service independent functions may be defined in a network. A service consumer or provider may not have to upgrade their infrastructure in order to deploy or use a new service. Separation allows new service deployment without disrupting the network of existing services. As another example scaling of service across many consumers service types and locations may be facilitated by distribution of service functionality. Service dependent information for a set of customers might be stored in one network element or information related to one class of services may be centralized in one network element. All customers in one particular geography or location may access services from one particular network element. As another example bundling and tiering of services may be facilitated. Bundling may include two or more services that work independently but have improved functionality by being combined. Services may be deployed in bundles that may include a virtual machine storage resources quality of service parameters and controls access control and intrusion prevention. Tiering may involve one service using another service for its functioning e.g. a software as a service SaaS might use a platform as a service PaaS a PaaS might use an infrastructure as a service IaaS . As another example the ability for users to receive continued service even in case of network failures may be facilitated. As another example a single service may be customized for different users e.g. a security device may be improved with intrusion detection . As another example the creation of new services may be simplified while giving the flexibility to both customers and providers to control service specific parameters and configurations.

Another example of an advantage is extensions are provided for that allow for service variety. Given the variety of cloud applications and to allow flexibility within a standard way of communicating service information a separation of service independent and service dependent items is maintained.

Another example of an advantage is facilitating service deployments that may require complex service combinations. If a virtual machine is being provisioned network attached storage security rules that limit access to that storage firewalls and access controls that restricts access to the virtual machine bandwidth to the virtual machine user provisioning for who can access the virtual machine loadbalancers wide area network WAN optimization techniques and intrusion detection and prevention or techniques to log and report accesses to a service may also be provisioned.

In some embodiments various disadvantages may be reduced or avoided. For example HTTP does not have the PUBLISH and SUBSCRIBE methods through which service information can be selectively distributed in a network. HTTP also does not have procedures by which a network of clients and servers can DISCOVER others and ADVERTISE their presence and capabilities before someone does a PUBLISH or SUBSCRIBE. This means that HTTP as an Open Systems Interconnection OSI Layer 5 protocol is not suitable for discovering agents and services in a network because methods for advertising discovering publishing and subscribing do not exist in HTTP. Embodiments discussed above provide solutions to these problems by allowing for interoperability including PUBLISH SUBSCRIBE DISCOVER and ADVERTISE features.

As another example of a disadvantage that may be reduced or avoided in the client server model a client may need to wait for a response from the server. However there is generally no mechanism to time out on a request or cancel the request midway. This may make error handling across a request that has been forked a one or more times difficult. For example if one of the forked legs has failed the system must wait for the other legs to finish before issuing a request to cancel the other legs. If one of the legs is taking too long then the other legs are unable to be completed. An HTTP client connection may not be closed immediately and have correct resolution. This problem can also arise network connection loss occurs due to network software or other failures.

In some embodiments separation between end user API control of network based services and the use of proxies as discussed above may have one or more of the following advantages. It may allow a service provider to support multiple end user access and control mechanisms without altering their management network. Applications and tools that have been developed using APIs can be migrated to a service provider whose internal network uses management techniques discussed above. API development can create more and more functionalities and features using the same basic capabilities that the management techniques discussed above provide. Rapid innovation and service creation through APIs can thus be de coupled with certain service management technology in the network. Separation could allow for end users that do not need to understand the details of how a service is implemented which can be proprietary to a particular provider. A service provider can keep APIs but continuously evolve the internal service implementation logic through policies.

In some embodiments node includes messaging bus service registry and controller . Messaging bus may be configured to communicate with middleware agents and . Controller may be configured to manage services and infrastructure related to nodes and . Service registry may include information regarding applications and .

In some embodiments nodes and may each be configured to provide one or more services using applications and . Nodes and may include hypervisors and respectively as well as virtual machines and respectively. These virtual machines and hypervisors may be used to support applications and . Nodes and also include middleware agents and that may be configured to communicate using the same types of messages or protocol e.g. the messages and protocols discussed above with respect to .

In some embodiments SaaS and PaaS implementations may use agents such as middleware agents and . These agents can interact with applications e.g. applications and in nodes and . For example these agents can serve as Middleware and be used to instantiate collaboration educational or gaming applications. Cloud controller can interact with such agents on nodes and instruct them to create new services. The newly created applications can in turn use the middleware to communicate with controller e.g. to request resources . As another example application may have a certain number of records in a table and application may request the creation of a new virtual machine with the same application type. SaaS PaaS middleware agent can send the request to controller which then transmits it to IaaS middleware agent to create a new virtual machine. Once the new virtual machine has been installed controller can now instruct the SaaS PaaS agent to install a new application. Once the application is ready messages in a protocol discussed above with respect to can now be used for sending application specific commands to one or more application instances. This middleware technique can enable across the board communications between applications and and controller .

In some embodiments standard libraries and APIs can be published for interacting with infrastructure controllers and other applications. Applications e.g. applications and can use service registry to locate applications and forward them messages. Service registry can enable a logical addressing of services e.g. provided by applications and including addressing beyond domain names. In some embodiments the domain names may not be known or the messaging may be based upon service types rather than names of hosts that carry them. Multicast and broadcast messages without knowing their MAC or IP can be sent in an authenticated manner using middleware agents and .

Computer system may have one or more input devices which may include a keypad keyboard mouse stylus etc. one or more output devices which may include one or more displays one or more speakers one or more printers etc. one or more storage devices and one or more storage medium . An input device may be external or internal to computer system . An output device may be external or internal to computer system . A storage device may be external or internal to computer system . A storage medium may be external or internal to computer system .

System bus couples subsystems of computer system to each other. Herein reference to a bus encompasses one or more digital signal lines serving a common function. The present disclosure contemplates any suitable system bus including any suitable bus structures such as one or more memory buses one or more peripheral buses one or more a local buses or a combination of the foregoing having any suitable bus architectures. Example bus architectures include but are not limited to Industry Standard Architecture ISA bus Enhanced ISA EISA bus Micro Channel Architecture MCA bus Video Electronics Standards Association local VLB bus Peripheral Component Interconnect PCI bus PCI Express bus PCI X and Accelerated Graphics Port AGP bus.

Computer system includes one or more processors or central processing units CPUs . A processor may contain a cache for temporary local storage of instructions data or computer addresses. Processors are coupled to one or more storage devices including memory . Memory may include random access memory RAM and read only memory ROM . Data and instructions may transfer bidirectionally between processors and RAM . Data and instructions may transfer unidirectionally to processors from ROM . RAM and ROM may include any suitable computer readable storage media. For example aspects of this paragraph may be used to implement stored information discussed in e.g. in packet .

Computer system includes fixed storage coupled bi directionally to processors . Fixed storage may be coupled to processors via storage control unit . Fixed storage may provide additional data storage capacity and may include any suitable computer readable storage media. Fixed storage may store an operating system OS one or more executables EXECs one or more applications or programs data and the like. Fixed storage is typically a secondary storage medium such as a hard disk that is slower than primary storage. In appropriate cases the information stored by fixed storage may be incorporated as virtual memory into memory . For example aspects of this paragraph may be used to implement stored information discussed in e.g. in packet .

Processors may be coupled to a variety of interfaces such as for example graphics control video interface input interface output interface and storage interface which in turn may be respectively coupled to appropriate devices. Example input or output devices include but are not limited to video displays track balls mice keyboards microphones touch sensitive displays transducer card readers magnetic or paper tape readers tablets styli voice or handwriting recognizers biometrics readers or computer systems. Network interface may couple processors to another computer system or to network . Network interface may include wired wireless or any combination of wired and wireless components. Such components may include wired network cards wireless network cards radios antennas cables or any other appropriate components. With network interface processors may receive or send information from or to network in the course of performing steps of particular embodiments. Particular embodiments may execute solely on processors . Particular embodiments may execute on processors and on one or more remote processors operating together.

In a network environment where computer system is connected to network computer system may communicate with other devices connected to network . Computer system may communicate with network via network interface . For example computer system may receive information such as a request or a response from another device from network in the form of one or more incoming packets at network interface and memory may store the incoming packets for subsequent processing. Computer system may send information such as a request or a response to another device to network in the form of one or more outgoing packets from network interface which memory may store prior to being sent. Processors may access an incoming or outgoing packet in memory to process it according to particular needs.

Particular embodiments involve one or more computer storage products that include one or more computer readable storage media that embody software for performing one or more steps of one or more processes described or illustrated herein. In particular embodiments one or more portions of the media the software or both may be designed and manufactured specifically to perform one or more steps of one or more processes described or illustrated herein. In addition or as an alternative in particular embodiments one or more portions of the media the software or both may be generally available without design or manufacture specific to processes described or illustrated herein. Example computer readable storage media include but are not limited to CDs such as CD ROMs FPGAs floppy disks optical disks hard disks holographic storage devices ICs such as ASICs magnetic tape caches PLDs RAM devices ROM devices semiconductor memory devices and other suitable computer readable storage media. In particular embodiments software may be machine code which a compiler may generate or one or more files containing higher level code which a computer may execute using an interpreter.

As an example and not by way of limitation memory may include one or more computer readable storage media embodying software and computer system may provide particular functionality described or illustrated herein as a result of processors executing the software. Memory may store and processors may execute the software. Memory may read the software from the computer readable storage media in mass storage device embodying the software or from one or more other sources via network interface . When executing the software processors may perform one or more steps of one or more processes described or illustrated herein which may include defining one or more data structures for storage in memory and modifying one or more of the data structures as directed by one or more portions the software according to particular needs. In addition or as an alternative computer system may provide particular functionality described or illustrated herein as a result of logic hardwired or otherwise embodied in a circuit which may operate in place of or together with software to perform one or more steps of one or more processes described or illustrated herein. The present disclosure encompasses any suitable combination of hardware and software according to particular needs.

Herein reference to a computer readable non transitory storage medium may include a semiconductor based or other integrated circuit IC such as for example a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive another suitable medium or a suitable combination of these where appropriate. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

Herein or is inclusive and not exclusive unless expressly indicated otherwise or indicated otherwise by context. Therefore herein A or B means A B or both unless expressly indicated otherwise or indicated otherwise by context. Moreover and is both joint and several unless expressly indicated otherwise or indicated otherwise by context. Therefore herein A and B means A and B jointly or severally unless expressly indicated otherwise or indicated otherwise by context.

This disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Moreover reference in the appended claims to an apparatus or system or a component of an apparatus or system being adapted to arranged to capable of configured to enabled to operable to or operative to perform a particular function encompasses that apparatus system component whether or not it or that particular function is activated turned on or unlocked as long as that apparatus system or component is so adapted arranged capable configured enabled operable or operative.

