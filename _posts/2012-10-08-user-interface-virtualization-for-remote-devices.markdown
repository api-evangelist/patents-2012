---

title: User interface virtualization for remote devices
abstract: User interface virtualization describes a technique for providing a user with access to one computing device from another computing device, while translating the ergonomics of one computer's user interface style into the ergonomics of the other's. An agent running on a remote desktop collaborates with a corresponding client running on a client machine that accepts a “touch and swipe” style input. The agent and client exchange user interface metadata and user interface input events and translate the exchanged information to provide native graphical user interface elements (at the client machine) and simulated user actions (at the remote desktop). The agent running on the remote desktop may use an interface interaction API or library to programmatically manipulate the user interface of the remote desktop responsive and act as a proxy for the corresponding client.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09250854&OS=09250854&RS=09250854
owner: VMware, Inc.
number: 09250854
owner_city: Palo Alto
owner_country: US
publication_date: 20121008
---
This application claims the benefit of U.S. Provisional Patent Application No. 61 638 469 filed Apr. 25 2012 and entitled User Interface Virtualization the entire contents of which are incorporated by reference herein.

This invention is related to U.S. patent application Ser. No. 13 217 484 filed Aug. 25 2011 and entitled Native Viewer Use for Service Results from a Remote Desktop the entire contents of which are incorporated by reference herein. This invention is also related to U.S. patent application Ser. No. 13 362 854 filed Jan. 31 2012 and entitled Multi Touch Interface Gestures for Keyboard and or Mouse Inputs the entire contents of which are incorporated by reference herein.

Server based computing allows a networked client device remotely situated with respect to a server computing system to access computing resources on the server. For example the client device may run desktop remoting client software and hardware that uses a remote desktop protocol such as Remote Desktop Protocol RDP Virtual Network Computing VNC or Personal Computer over Internet Protocol PCoIP to access a desktop remotely. The desktop remoting client software displays an image of a graphical user interface generated by the operating system and applications running at the server computing system e.g. in a virtual machine. The term desktop can refer to a virtual machine or physical system accessed by an end user as a local to the user desktop or workstation computer. The term desktop may also refer to the human interface environment through which users can launch interact with and manage applications settings and data. The remote desktop is accessible by the user using the remote desktop protocol and a desktop remoting client. The client device typically has a local set of input and output devices e.g. display keyboard mouse and transmits user input such as keyboard or mouse input to the remote system to be processed there and receives display and other data sound for presentation to the user using the local set of I O devices.

However users of client devices with touch screens face several challenges when interfacing with traditional desktop based applications e.g. Microsoft Windows applications and desktops through a remote display protocol. One challenge relates to latency of the network connection between the touch screen device and the remote desktop which often creates a halting or jittery user experience. Another challenge relates to attempts to remotely control a conventional point and click driven interface e.g. Windows interface from a touch screen device which is designed not for traditional point and click interactions but rather for touch screen gestures and finger swipe style of interactions.

To address these challenges it is known in the art to modify a remote desktop controlled by touch screen devices for example by automatically adjusting a font size of the remote desktop. However these largely cosmetic changes only modify the displayed contents received from the remote server do not fail to reduce latency in menu navigation and user feedback and still require users to navigate desktop applications through a point and click style interface.

It is also known in the art as described in Remote Desktop Protocol Graphics Device Interface Acceleration Extensions made available by Microsoft Inc. for a remote server to use its own video driver to render display output and encoding drawing operations that produce an image instead of encoding the actual image. For example instead of sending a bitmap image of a filled rectangle from server to client an order to render a rectangle at coordinate X Y with given width height and fill color may be sent to the client. The client then executes the drawing order to produce the intended graphics result. However this approach only produces a same corresponding graphical interface on the client as on the server which are difficult to use on a client device having a touch screen or non pointer based style of interface.

Alternatively it is also known in the art as described in United States Patent Publication No. 2011 0314093 A1 to translate user gestures on a client device into a digital representation of a remote computer s native input format such as a control common to a two button mouse e.g. click window scroll right click thereby allowing the client device to control the computer. However this approach forces a user to learn a new user interface and memorize which touch screen gestures is equivalent to a mouse input which can be cumbersome hard to use. Further this approach still requires capturing and displaying basic screen data from the remote desktop and does not improve latency in interactions between the user and the user interface.

Consequently there is a need for improved systems and methods for providing access to a remote desktop having one style of user interface to a client device having a different style of user interface.

One or more embodiments of the present invention provide a method of generating a local graphical user interface GUI on a touch screen of a client device that is connected to a server device having a remote GUI. The method includes receiving from the server device a base image of the remote GUI and user interface UI metadata describing a GUI element in the remote GUI. The method further includes generating at the client device a native GUI element to be displayed on the touch screen according to the received UI metadata. The native GUI element corresponds to the GUI element in the remote GUI. The method includes generating the local GUI to be displayed on the touch screen of the client device where the local GUI includes the base image received from the server device and the native GUI element.

Embodiments of the present application provide a method of providing access to a graphical user interface GUI of a server device having a guest operating system executing therein. The method includes generating user interface UI metadata specifying a GUI element in the GUI of the server device using an application programming interface of the guest operating system configured to programmatically manipulate the GUI of the server device. The method further includes transmitting abuse image of the GUI and the generated UI metadata to a touch input client device connected to the server device and receiving from the touch input client device information indicating user input linked to the GUI element in the GUI of the server device. The method includes invoking the application programming interface to programmatically manipulate the GUI of the server device according to the received information.

Embodiments of the present application further provide a method of generating a local graphical user interface GUI on a client device that is connected to a server device having a remote GUI. The method includes receiving at the client device a voice input through an input device of the client device and processing the voice input to determine a command input to manipulate the remote GUI of the server device. The method includes transmitting to the server device information indicating that the command input configured to manipulate the remote GUI.

Embodiments of the invention provide a technique and system for user interactions on a client system with one user interface scheme e.g. touch screen to remotely operate a server system with another user interface scheme e.g. point and click desktop . In one embodiment a virtual desktop infrastructure VIM uses an application programming interface API configured to programmatically manipulate and activate graphical user interface GUI elements of the server side desktop to bridge the difference in user interface schemes between the touch screen client system e.g. tablet computer smart phone and server side desktop.

For example application frameworks and Application Programming Interfaces APIs such as Microsoft Active Accessibility API and Microsoft UI Automation API may derive contents of UI elements such as menu navigation at the server side desktop which are then passed to the remote client system e.g. tablet computer over a network connection e.g. via desktop remoting protocols . The menu contents are rendered as a native GUI element and engaged on the remote client directly. A user of the remote client can select menu options launch applications and documents and perform other common point and click activities directly on the tablet using a local touch friendly rendition of these menus.

In another example APIs configured to manage file and filesystems at the server side desktop e.g. File Explorer APIs may be used to facilitate export of document folders for direct document launches and other file functions on the client device. In yet another example APIs configured to manage process and threads at the server side desktop e.g. Application Process API s allow remote launch and termination of applications using icons on the client device. By shifting key user interface activities such as menu operation document operations and application launches from the remote desktop running at the server to the client embodiments of the invention dramatically improve user experience of traditional point and click applications used on touch screen devices and augment the traditional remote display protocol driven user experience.

In the following description numerous specific details are set forth in order to provide a thorough understanding of exemplary embodiments of the present invention. However it will be apparent to one skilled in the art that the present invention may be practiced without some of these specific details. In other instances well known process operations and implementation details have not been described in detail in order to avoid unnecessarily obscuring novel aspects of the invention.

VDI system may include a domain controller such as Microsoft Active Directory that manages user accounts including user log in information and a connection broker that manages connections between VDI clients and desktops running in virtual machines or other platforms. Domain controller and connection broker may run on separate servers or in separate virtual machines running on the same server or different servers. In the embodiments of the present invention illustrated herein desktops are running in virtual machines are instantiated on a plurality of physical computers each of which includes virtualization software and hardware . Physical computes may be controlled by a virtual machine management server and be coupled to a shared persistent storage system .

All of the components of VDI system communicate via network . For simplicity a single network is shown but it should be recognized that in actual implementations the components of VDI system may be connected over the same network or different networks. Furthermore a particular configuration of the virtualized desktop infrastructure is described above and illustrated in but it should be recognized that one or more embodiments of the present invention may be practiced with other configurations of the virtualized desktop infrastructure.

As shown in a call out in desktop may include an application having a traditional point and click style user interface that relies on input from a pointer e.g. mouse cursor to manipulate or interact with UI elements of application . The difference in styles of user interface between client machine and desktop may worsen user experience and turn routine user tasks into frustrating exercises. This problem is especially clear from . Here the graphical user interface of remote desktop may have widgets and elements that expect manipulation and interaction with a smaller more precise pointer e.g. mouse cursor and as such may have a small size that is difficult to target with a touch input illustrated as circle .

According to an embodiment VDI client includes a user interface virtualization UIV client configured to communicate with a corresponding UIV agent running on VM to translate between the point and click style user interface of the user desktop on VM and the touch and gesture user interface of client machine . In one embodiment UIV client and UIV agent exchange messaging in the form of UI input events and UI metadata which are translated into remote desktop input and native GUI elements respectively at the appropriate endpoints.

In one embodiment UIV agent executing on VM is configured to invoke an interface interaction API to obtain metadata related to user interface UI widgets and elements seen on the desktop of VM . In one embodiment interface interaction API may be an API exposed by guest OS to obtain metadata related to user interface UI widgets and elements seen on the desktop of VM . For example interface interaction API may be an API traditionally used by assistive technologies e.g. screen readers to make an application running on a guest OS or the guest OS itself more accessible to persons with vision hearing or motion impairments for example such as Microsoft Accessibility API or automate software testing such as Microsoft UI Automation API. Interface interaction API is further configured to expose functionality of UI elements by enabling programmatic access e.g. for UIV agent to identify manipulate and interact with UI elements of guest OS and applications running on guest OS .

In an alternative embodiment interface interaction API may be a software framework configured to build an application model over time including performing GPS style recalculation to determine efficient ways to activate any application function from any other point in an application s interface. Such recalculation functionality may be useful to insure injection of user input even when something goes wrong and an application s state is not what VDI client expects at the point where a proxied action is sent to desktop side UIV agent . In one embodiment interface interaction API is configured to intercept UI elements determine state of an application and its application objects and perform simulated user actions on the UI elements.

VDI host agent is configured to transmit VDI data to VDI client having display and input data according to conventional remote desktop techniques. VDI data may include a base GUI image that is used to display the GUI of remote desktop at client machine . In some embodiments base GUI image may be a graphical bitmap or framebuffer illustrating a portion of or an entirety of the display at desktop similar to a screenshot of the remote desktop. In other embodiments base GUI image may be graphical information for drawings lines polygons and other shapes fonts and graphical primitives to render an image that displays the GUI of desktop at client machine .

In addition to VIM data transmitted between VDI client and VDI host agent UIV agent executing on VM is configured to transmit UI metadata to UIV client on client device . UI metadata includes information provided by interface interaction API that are descriptive of one or more UI elements of the user desktop on VM . Examples of UI elements that may be specified by UI metadata include windows buttons menus dialog or message boxes lists menu bars scroll bars title bars status bars size grips toolbars tree view controls list view controls dropdown lists and input carets. In contrast to previous approaches which used graphical primitives or drawing operations for rendering at a VDI client UI metadata includes semantic information related to contents and application state of one or more UI elements of the user desktop. For example rather than merely providing graphical primitives for drawing a rectangle menu metadata provides semantic information representing the contents of the menu such as the selectable options in the menu. Based on UI metadata VDI client may independently render GUI elements that display behave and are interacted with differently than corresponding UI elements on the user desktop on VM . As such UI metadata enables VDI client to generate render and display native GUI elements that are most appropriate for the interface style and form factor of client machine e.g. touch screen . In one embodiment information in the UI metadata may be organized into a hierarchical or tree like data structure having root elements and child elements corresponding to UI elements of a user desktop as shown in greater detail in .

In one embodiment interface interaction API allows application to expose a tree structure of UI metadata that represents the structure of graphical user interface . Elements in the tree expose properties and methods that facilitate programmatic manipulation of the GUI on desktop . In one embodiment UI metadata may include for each UI element specified a label for a UI element that is predetermined e.g. assigned in code by a developer of application and guest OS role information describing the type of UI element e.g. ROLE SYSTEM PUSHBUTTON properties that describe a UI element s state at a given moment in time e.g. invisible unavailable focused focusable pressed etc and other values contained in a UI element e.g. percentages integers non integers textual visual that may indicate information represented by the UI element. For example UI metadata may include information for window that includes an identifier e.g. id 982 a state property indicating a window is in focus within the remote desktop and information for UI elements contained within window e.g. title bar and menu bar . In another example metadata for menu includes information for a plurality of menu items within menu such as items for New Open Save etc. In some embodiments UI metadata may include graphical data such as thumbnails or icons associated with UI elements on desktop .

Referring back to UIV client is configured to construct and display a native UI element or widget having the same functionality and information as a corresponding UI element or widget on the remote desktop based on UI metadata received from UIV agent . In one embodiment UIV client may generate a native touch and gesture style GUI element that corresponds to point and click style UI element based on UI metadata provided by interface interaction API . In some embodiments native GUI elements generated by UIV client may be different than corresponding UI elements of desktop such as having differences in size shape color style manner of interaction animation and interactive behavior. For example UIV client may use UI metadata derived from a conventional drop down list on remote desktop to generate a native GUI element that appears like a large wheel that spins in response to swipe gestures. In another example UIV client may present a reformatted version of a navigation menu optimized for the form factor and touch screen ergonomics of client machine . As shown a native GUI element may be overlaid on top of base GUI image represented in VDI data to form a client GUI . In one embodiment UIV client is configured to use native graphical frameworks or user interface frameworks that are local to client machine to render one or more native GUI elements based on the received UI metadata .

UIV client is further configured to capture user input on the constructed native GUI element and transmit UI input events to UIV agent running in VM . In one embodiment UIV client is configured to generate UI input events based on touch input that represents interactions with the native GUI element . In one embodiment UI input events include information indicating that the corresponding GUI elements at the remote desktop on VM have been manipulated at the client machine . In some embodiments UI input events may indicate a selection of activation of change of state in or interaction with a corresponding UI element or option at remote desktop . In other embodiments UI input events may indicate execution or invocation of an operation or option corresponding to a UI element at remote desktop . According to UI input events received from UIV client UIV agent is configured to query and invoke the corresponding UI elements of application or guest OS using interface interaction API to simulate input and facilitate programmatic manipulation of the user interface of the remote desktop on VM .

At step VDI client detects a UIV trigger performed by a user operating client machine . In one embodiment the UIV trigger may be a pre determined gesture e.g. a unique swipe gesture performed by the user or a UI button activated by the user that indicates VDI client should render one or more UI elements of an active application running on the remote desktop e.g. application using native GUI elements. At step responsive to detecting a UIV trigger VDI client requests UI metadata from VDI host agent which receives the request at step .

At step in response to receiving a request for UI metadata VDI host agent makes an API call to interface interaction API of guest OS to obtain UI metadata e.g. UI metadata for application . For example VDI host agent may obtain a hierarchical menu structure having a list of menus sub menus and menu items of an in focus application. In one embodiment rather than return metadata for every UI element on the remote desktop UIV agent may identify a subset of UI elements of the user desktop and generate UI metadata only for the subset of UI elements. For example UIV agent may only generate UI metadata for the application that currently has focus in another embodiment TAN agent may generate UI metadata for one or more UI elements on the remote desktop based on the received request for UI metadata. For example UV agent may generate UI metadata for the hierarchical menu bar based on a request from VDI client that indicates only menu metadata are requested. In some embodiments VDI host agent may proactively request UI metadata from guest OS in response to detected changes in the active application or the underlying guest OS e.g. via events received via a Windows Event callback function .

At step VDI host agent generates a base image for the GUI e.g. according to a VDI protocol established between VDI client and VDI host agent and transmits the base image for the GUI along with the contents of the hierarchical menu structure to VDI client at step . As described above the base image e.g. base GUI image provides graphical information for displaying an image of the remote desktop at the client machine. In one example the base image may be raw pixel data similar to a screenshot of the entire desktop to be displayed at the client machine. In another example the base image may be an updated set of pixel data to changing at least a portion of earlier transmitted raw pixel data. In some embodiments the base image may be drawing operations and graphical primitives for drawing the display of the remote desktop within a client GUI of the client machine.

In one embodiment the UIV client and UIV agent may use a messaging bus or message passing service to transmit and receive UI input events and UI metadata across network . In another embodiment VDI host agent may incorporate UI metadata. within VDI data passed through a remote display channel e.g. PCoIP HTML5 to VDI client . Similarly VDI client may incorporate UI input events within VDI data transmitted to VDI host agent .

At step VDI client receives the base image for the GUI along with the contents of the hierarchical menu structure. At step VDI client renders the GUI based on the received base image and contents of the hierarchical menu structure and at step displays the GUI. The displayed GUI includes the base image received from VDI host agent and native GUI elements i.e. native to client machine in which VDI client is executed that VDI client generated based on the contents of the menu structure. In some embodiments the native GUI elements are included in the displayed GUI as UI elements overlaid on top of the base image received from VDI host agent . In some embodiments the native GUI elements are included in the displayed GUI as a semi transparent layer incorporated into the base image received from VDI host agent . In one embodiment VDI client generates native GUI elements configured to be touch friendly. For example VDI client generates native GUI elements having a size and shape that more readily facilities activation by a touch object e.g. human finger or stylus as compared to a GUI element configured for activation by a pointer or mouse cursor. In another example VDI client generates native GUI elements responsive to touch based input and gestures including taps swipes multi point gestures etc. As such the user experiences an improved user interface because VDI client enables the user to interact with native GUI elements that are rendered in a touch friendly manner yet correspond to UI elements from the remote desktop. Furthermore embodiments of the present invention may use native graphical frameworks or user interface frameworks that are local to client machine thereby offloading work and relying on the graphical capabilities of client machine .

At step VDI client detects an input e.g. a touch screen input made by the user through the GUI onto the native GUI elements in response to detecting an input VDI client processes the input at step . In the example of the hierarchical menu structure the input may of a type that causes menu items of a lower level to be displayed or may be a final selection. If it is the former the flow returns to step where the GUI is generated for display again. If the input is a final selection from the menu information e.g. UI input events indicating that a certain menu item has been selected is transmitted to the VDI host agent at step .

At step the VDI host agent receives the information indicating that the certain menu item has been selected. At step the VDI host agent makes an API call e.g. to interface interaction API to the guest OS to communicate that the certain menu item has been selected. The flow then returns to step where the base image for GUI may be regenerated.

In some embodiments the VIM host agent programmatically manipulates the user interface of the guest OS using an identifier that specifies an object within an object model of guest OS . In contrast to previous approach which simply invoked the server s keyboard and mouse driver to simulate keyboard and mouse events UV agent uses interface interaction API to directly manipulate UI elements of desktop according to the UI input events received from the VDI client. In some embodiments UIV agent passes the received UI input events directly to interface interaction API in cases where UV client transmits UI input events that are already configured for use by interface interaction API . In other embodiments UIV agent translates received UI input events into events or parameters for interface interaction API to indicate application state or property values of one or more UI elements have been changed. By way of example LTV agent may use interface interaction API to indicate for a given UI element element activation element selection spatial navigation logical navigation alerts focus changes and other property value changes.

According to one embodiment VDI client improves latency and responsiveness for UI elements that require multiple user interactions such as scrolling through items in a drop down list or navigating menus and sub menus. In one example use case menu navigation on a desktop may involve pointing and clicking on a Edit menu button causing a drop down menu to appear pointing and clicking on a menu item which may cause additional menus to appear e.g. Paste Special . . . etc. . To perform this use case under previous approaches to remote desktops a VDI client might have to receive an image of a GUI for the window and menu bar over the remote network and render the appearance of the window menu bar which might include frames of GUI animation transmit click input receive an image of a GUI for the window menu bar and now Edit menu over the remote network and render the appearance of the window menu bar and now Edit menu transmit click input possibly for one of the menu items and so forth. In contrast embodiments of the invention enable VDI client to construct and modify native GUI elements using UI metadata without having to make repeated network requests which increase latency and create a laggy user experience. In fact embodiments of the invention provide a means of accessing menu navigation metadata within an application even before a user selects a menu option. Interface related operations that use graphical feedback like drag and drop box resizing and key animations are performed locally on the client device for example as a remote session overlay and then executed within the remote session.

While embodiments of the present invention describe a remote desktop system that generates native GUI elements of a touch based gesture driven interface configured for a touch screen on a client device various embodiments of the client device described herein may include alternative non touch based input devices such as a microphone accelerometer gyroscopic sensor near field communications sensor etc. that may be configured to control a remote desktop according to techniques described herein. One example alternative embodiment of the VIM system in having a client device with alternative input devices for controlling a remote desktop is shown in .

According to one embodiment a val client running on client device is configured to transform a conventional point and click driven interface on a remote desktop to an interface operable using input device . For example VDI client may be configured to generate a client GUI that incorporates a base GUI image from VDI data and one or more native GUI elements operable by voice rather than touch based gestures . In the embodiment shown in one embodiment VDI client is configured to generate a native GUI element depicted in as a microphone icon providing graphical feedback from voice input received from the user.

In one embodiment VDI client is configured to receive an audio input signal from an input device e.g. microphone of client device that represents a voice command spoken by a user. UIV client decodes the audio input signal using a speech to text engine and transmits a UI input event to UV agent based on the decoded audio signal. For example UIV client may process a voice command of Open Excel from a user to launch an application e.g. application on desktop . UIV client processes the audio input signal to generate command text e.g. open excel and determine a UI input event based on the generated command text. In some embodiments the speech to text engine may generate a text value representing a best match for a given input audio signal. In some embodiments the speech to text engine may utilize a third party voice recognition component that may be internal or external e.g. via a cloud service for processing the audio signal.

In one embodiment UIV client is configured to process the command text generated from audio input signal using a rule based engine that associates command text matching pre determined commands with one or more UI input events . Examples of pre determined commands may include Open Application Show Documents Search for File . The UIV agent at VM is configured to directly execute one or more commands at the VM based on the UI input events received from UIV client . The UIV agent may execute the one or more commands using one or more APIs of guest OS as described above.

In one embodiment UIV client may process input from input device using a context awareness provided by UI metadata . For example UIV client may process a voice command of File New from a user to navigate a menu of an application e.g. application running on desktop . UIV client processes the audio input signal to generate command text e.g. File New and determine a UI input event based on the generated command text. In one embodiment UIV client may process the command text to generate a UI input event using a rule based engine that includes rules for current context and application state of desktop . In some embodiments UV client may determine a UI input event based on intermediate GUI elements similar to native GUI elements on client GUI . For example UIV client may determine that the command text File New corresponds to intermediate GUI elements shown as a File menu and a New menu item currently rendered in client GUI .

In one embodiment UIV client is configured to modify its processing of audio input signal from input device based on UI metadata received from UIV agent . UIV client may seed its speech to text engine with information from UI metadata to bias values returned by the speech to text engine towards particular components on desktop . For example UIV client may use information from UI metadata that indicates which application is active and which UI element has focus to increase or decrease weight of possible matches to candidate texts from a speech to text conversion. In the example shown UIV client may use UI metadata to indicate that a voice command having the word Open is more likely intended to refer to the Open menu item in GUI element than a pre determined global command Open .

In one alternative embodiment UIV client is configured to generate one or more native GUI elements operable by sensor input for example from an accelerometer. For example UIV client may generate a scrollable UI element that is responsive to input from the accelerometer. UV client is configured to receive motion input or other positional input from the accelerometer and transmit a corresponding UI input event to UIV agent . In one example the transmitted UI input event may cause the corresponding GUI on desktop to scroll in a specified direction and speech e.g. scroll up fast . In some embodiments UIV client may be configured to associate sensor input from input device with one or more UI input events according to a predetermined input mapping. For example UIV client may receive a rotational input from input device indicating that client device has been manipulated by the user from a landscape to portrait orientation. Based on a pre determined input mapping UIV client may translate this rotational input to a UI input event corresponding to a Maximize Window interface command which would be carried out by UIV agent .

The various embodiments described herein may employ various computer implemented operations involving data stored in computer systems. For example these operations may require physical manipulation of physical quantities usually though not necessarily these quantities may take the form of electrical or magnetic signals where they or representations of them are capable of being stored transferred combined compared or otherwise manipulated. Further such manipulations are often referred to in terms such as producing identifying determining or comparing. Any operations described herein that form part of one or more embodiments of the invention may be useful machine operations in addition one or more embodiments of the invention also relate to a device or an apparatus for performing these operations. The apparatus may be specially constructed for specific required purposes or it may be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines may be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The various embodiments described herein may be practiced with other computer system configurations including hand held devices microprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like.

One or more embodiments of the present invention may be implemented as one or more computer programs or as one or more computer program modules embodied in one or more computer readable media. The term computer readable medium refers to any data storage device that can store data which can thereafter be input to a computer system computer readable media may be based on any existing or subsequently developed technology for embodying computer programs in a manner that enables them to be read by a computer. Examples of a computer readable medium include a hard drive network attached storage NAS read only memory random access memory e.g. a flash memory device a CD Compact Discs CD ROM a CD R or a CD RW a DVD Digital Versatile Disc a magnetic tape and other optical and non optical data storage devices. The computer readable medium can also be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.

Although one or more embodiments of the present invention have been described in some detail for clarity of understanding it will be apparent that certain changes and modifications may be made within the scope of the claims. Accordingly the described embodiments are to be considered as illustrative and not restrictive and the scope of the claims is not to be limited to details given herein but may be modified within the scope and equivalents of the claims. In the claims elements and or steps do not imply any particular order of operation unless explicitly stated in the claims.

Plural instances may be provided for components operations or structures described herein as a single instance. Finally boundaries between various components operations and data stores are somewhat arbitrary and particular operations are illustrated in the context of specific illustrative configurations. Other allocations of functionality are envisioned and may fall within the scope of the invention s . In general structures and functionality presented as separate components in exemplary configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements may fail within the scope of the appended claims s .

