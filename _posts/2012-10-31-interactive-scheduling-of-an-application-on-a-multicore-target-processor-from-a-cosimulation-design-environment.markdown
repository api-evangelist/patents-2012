---

title: Interactive scheduling of an application on a multi-core target processor from a co-simulation design environment
abstract: In an embodiment, a method for interactively varying scheduling of a multi-threaded application executing on a symmetric multi-core processor provides an interface in a co-simulation design environment. The interface is associated with a multi-threaded application executing on a target processor that includes symmetric processor cores. The method also sets a scheduling attribute of the multi-threaded application using the interface. The setting occurs when the multi-threaded application is executing. The method further receives data associated with the executing of the multi-threaded application in the co-simulation design environment when the multi-threaded application is executing subsequent to the setting of the scheduling attribute.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09317331&OS=09317331&RS=09317331
owner: The MathWorks, Inc.
number: 09317331
owner_city: Natick
owner_country: US
publication_date: 20121031
---
Co simulation is a technique used by developers to design test and optimize an application that is to be implemented on particular target hardware. With co simulation one or more components of an application in development executes on the target hardware. The target hardware may be a symmetric multi core processor SMP where the resources associated with the cores are identical. That is the execution characteristics of an application component running on one core of an SMP are identical to the execution characteristics of the same component running on any other core of the SMP.

During co simulation execution of the application under development may include one or more application components that are simulated in the host simulation environment and one or more application components that are executing on SMP. The one or more application components executing on the SMP may have been generated from the host environment via automatic code generation.

According to various embodiments an application is designed in a co simulation design environment. The application may be designed by a user. A user may be a person an algorithm a program that is part of an application running in simulation or any combination thereof. Accordingly the term interaction may refer to an interaction with a person an algorithm a program or any combination thereof.

Exemplary co simulation design environments may include graphical programming environments e.g. block diagram environments BDEs and or textual programming environments TPEs . An application designed in a BDE may be a BDE model and an application designed in a TPE may be a TPE model. According to various embodiments a TPE model can include one or more of a textual program a script a function another TPE model etc. A BDE model can include one or more of a block a subsystem another BDE model etc.

The application designed in the co simulation design environment may include one or more application components. As discussed in further detail below in connection with an application component may be formed by grouping together one or more elements of the application. An application component may be a subset of the application that is able to run independently from the rest of the application and that has defined boundaries along with a defined input and output.

In a TPE the application components may be formed by grouping elements of the application by function object method model textual program other demarcated boundary e.g. a conditional statement etc.

In a BDE the components may be formed by grouping elements of the application by block subsystem rate sub model e.g. Referenced Model other demarcated boundary etc. An application component may be composed of one or more execution threads that may be mapped to processing cores of a symmetric multi core processor SMP . An application component may be designated to execute on a SMP.

A scheduler may distribute or map execution threads of one or more application components to available processing cores at compile time. Conventionally the schedulers are implemented in the target processing device such as a SMP. Conventional schedulers may include conventional static schedulers and conventional dynamic schedulers.

For example conventional static scheduler illustrated in has the following fixed mapping execution threads of application components and are mapped to processing core of the SMP execution threads of application component are mapped to processing core of the SMP execution threads of application component are mapped to processing core of the SMP and execution threads of application components and are mapped to processing core of the SMP. The mapping between the execution threads of application components and processing cores implemented by conventional static scheduler remains unchanged during the execution of the application components on the SMP with processing cores .

Conventional static scheduler illustrated in implements a different fixed mapping. As shown in conventional static scheduler maps execution threads of application components and to processing core of the SMP execution threads of application components and to processing core of the SMP execution threads of application component to processing core of the SMP and execution threads of application component to processing core of the SMP. The mapping between the execution threads of application components and processing cores implemented by conventional static scheduler remains unchanged during the execution of the application components on the SMP with processing cores .

Conventional static scheduler illustrated in implements a different fixed mapping. As shown in conventional static scheduler maps execution threads of application components and to processing core of the SMP execution threads of application component to processing core of the SMP execution threads of application components and to processing core of the SMP and execution threads of application component to processing core of the SMP. The mapping between the execution threads of application components and processing cores implemented by conventional static scheduler remains unchanged during the execution of the application components on the SMP with processing cores .

Other exemplary conventional dynamic scheduling rule sets may include for example a shortest execution time scheme where the application component with the shortest predicted execution time is assigned to the least busy core and the application component with the second predicted execution time is assigned to the second least busy core etc. One of ordinary skill in the art will appreciate that load balancing and shortest execution time allocation execution rules are used for illustrative purposes only and that the execution criteria may include other execution rules and or rule sets.

For example conventional dynamic scheduler illustrated in may change the mapping of execution threads of application components to processing cores when application components are executing on the SMP. At time t 0 conventional dynamic scheduler implements a first mapping where conventional dynamic scheduler maps execution threads of the application components and to processing core of the SMP execution threads of the application component to processing core of the SMP execution threads of the application component to processing core of the SMP and execution threads of the application components and to processing core of the SMP.

At time t 1 conventional dynamic scheduler may change the mapping and implement a second mapping where execution threads of the application components and are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP and execution threads of the application component are mapped to processing core of the SMP. While the execution of threads of the application components continues on the cores of the SMP conventional dynamic scheduler implements a third mapping at time t 3. As illustrated in at time t 2 execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP and execution threads of the application component are mapped to processing core of the SMP.

At time t 1 conventional dynamic scheduler may change the mapping and implements a second mapping execution threads of the application components and are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP no execution thread is mapped to processing core of the SMP and execution threads of the application components and are mapped to processing core of the SMP. Thus conventional dynamic scheduler does not have to assign execution thread of the application components to each processing core of the SMP.

Conventional dynamic scheduler may choose to assign no execution thread or all execution threads to a given processing core of the SMP. While the execution of the components continues on the processing cores of the SMP conventional dynamic scheduler may implement a third mapping at time t 2. As illustrated in at time t 3 execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP and execution threads of the application component are mapped to processing core of the SMP. As shown in a conventional dynamic scheduler may change the mapping of an execution thread of an application component to a specific processing core multiple times during the execution of the application.

According to various embodiments conventional schedulers may be implemented in the co simulation design environment. Such schedulers are referred as co simulation schedulers. For example if a conventional static scheduler is implemented in the co simulation design environment such scheduler is referred as a co simulation static scheduler. Accordingly the co simulation static scheduler is a scheduler implemented in the co simulation environment with a fixed mapping of execution threads to processing cores. The mapping implemented by a co simulation static scheduler is similar to the mapping illustrated in . However contrary to a conventional static scheduler which is implemented on the target processor such as the SMP the co simulation static scheduler is implemented in the co simulation design environment.

If a conventional dynamic scheduler is implemented in the co simulation design environment such scheduler is referred as a co simulation dynamic scheduler. Accordingly the co simulation dynamic scheduler is a scheduler implemented in the co simulation environment with a dynamic mapping of execution threads to processing cores. The mapping implemented by a co simulation dynamic scheduler is similar to the mapping illustrated in . However contrary to a conventional dynamic scheduler which is implemented on the target processor such as the SMP the co simulation dynamic scheduler is implemented in the co simulation design environment.

According to various embodiments interactive schedulers may be constructed from co simulation schedulers. For example an interactive static scheduler may be constructed from a co simulation static scheduler. The interactive static scheduler is a scheduler implemented in the co simulation environment that may interactively change from one co simulation static scheduler to another co simulation static scheduler during co simulation without re generating re compiling or re running code for the one or more application components.

The interactive static scheduler remaps execution threads of application components to processing cores during co simulation i.e. at runtime from the co simulation environment. This form of operation by an interactive static scheduler is referred to as changing of co simulation static schedulers. The varying of one co simulation static scheduler to another co simulation static scheduler is prompted by the user. As provided above the user may be a person an algorithm a program that is part of an application running in simulation or any combination thereof. Varying one co simulation static scheduler to another co simulation static scheduler has the effect of changing the mapping of execution threads of application components to processing cores without re generating re compiling or re running code for the one or more application components.

At time t 0 interactive static scheduler implements a first co simulation static scheduler where execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP and execution threads of the application components and are mapped to processing core of the SMP.

At time t 1 interactive static scheduler may change to co simulation static scheduler without re generating re compiling or re running code for the one or more application components. As illustrated in at time t 1 execution threads of the application components and are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP and execution threads of the application component are mapped to processing core of the SMP.

At time t 2 interactive static scheduler may change to co simulation static scheduler without re generating re compiling or re running code for the one or more application components. As illustrated in at time t 2 execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP and execution threads of the application component are mapped to processing core of the SMP.

The technique of changing the mapping of execution threads to processing cores at runtime such as changing from co simulation static scheduler to co simulation static scheduler may be thought of as changing of co simulation static schedulers during co simulation i.e. run time without re generating re compiling or re running code for the one or more application components. In certain embodiments a desired co simulation static scheduler may be chosen during co simulation. Based on the selected co simulation static scheduler a desired conventional static scheduler that will implement a static mapping of threads to cores at compile time of the application may be automatically generated. This generated conventional static scheduler may be reused for subsequent executions of the application on target SMP.

According to various embodiments interactive dynamic schedulers may be constructed from co simulation schedulers. For example an interactive dynamic scheduler may be constructed from a co simulation dynamic scheduler. The interactive dynamic scheduler is a scheduler implemented in the co simulation environment that may interactively change from one co simulation dynamic scheduler to another co simulation dynamic scheduler during co simulation without re generating re compiling or re running code for the one or more application components.

The interactive dynamic scheduler remaps execution threads of application components to processing cores during co simulation i.e. at runtime from the co simulation environment. Accordingly the interactive dynamic scheduler is a scheduler implemented in the co simulation environment that may vary from one co simulation dynamic scheduler to another co simulation dynamic scheduler at runtime during co simulation without re generating re compiling or re running code for the one or more application components. This form of operation by an interactive dynamic scheduler is referred to as changing of co simulation dynamic schedulers. The varying of one co simulation dynamic scheduler to another co simulation dynamic scheduler may be prompted by the user. As provided above the user may be a person an algorithm a program that is part of an application running in simulation or any combination thereof.

A co simulation dynamic scheduler remaps execution threads of application components to processing cores based on for example conditions and or rule sets of the runtime environment during co simulation without re generating re compiling or re running code for the one or more application components. For example an interactive dynamic scheduler may change a co simulation dynamic scheduler based on load balancing where the execution thread of an application component is mapped to a least busy processing core at that instance of time to another co simulation dynamic scheduler where the execution threads of the application component are mapped to the processing core that has been running the longest. One of ordinary skill in the art will appreciate that other conditions and or rule sets such as dependency among threads e.g. requiring two or more execution threads to run on the same processing core etc. can be used to determining how co simulation dynamic schedulers may map execution threads to processing cores. In certain embodiments a desired co simulation dynamic scheduler may be chosen during co simulation. Based on the chosen co simulation dynamic scheduler a desired conventional dynamic scheduler may be automatically generated using an embodiment of the invention. The generated conventional dynamic scheduler may be reused for subsequent executions of the application on target SMP.

At time t 0 interactive dynamic scheduler implements the first mapping of co simulation dynamic scheduler where execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP and execution threads of the application components and are mapped to processing core of the SMP.

At time t 1 interactive dynamic scheduler may change to co simulation dynamic scheduler without re generating re compiling or re running code for the one or more application components. Interactive dynamic scheduler may implement the second mapping of co simulation dynamic scheduler where execution threads of the application components and are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP.

At time t 2 interactive dynamic scheduler may change back to co simulation dynamic scheduler without re generating re compiling or re running code for the one or more application components. Interactive dynamic scheduler may implement the third mapping of co simulation dynamic scheduler where execution threads of the application components and are mapped to processing core of the SMP execution threads of the application component are mapped to processing core of the SMP execution threads of the application components and are mapped to processing core of the SMP and execution threads of the application component are mapped to processing core of the SMP.

Changes to a mapping of execution threads to processing cores at runtime such as changing from co simulation dynamic scheduler to co simulation dynamic scheduler is a technique of changing co simulation dynamic schedulers during co simulation i.e. run time without re generating re compiling or re running code for the one or more application components. In certain embodiments a desired co simulation dynamic scheduler may be chosen during co simulation. Based on the selected co simulation dynamic scheduler a desired conventional dynamic scheduler that will implement a dynamic mapping of threads to cores at compile time of the application may be automatically generated. This generated conventional dynamic scheduler may be reused for subsequent executions of the application on target SMP.

A co simulation dynamic scheduler remaps execution threads of application components to processing cores during co simulation i.e. at runtime from the co simulation environment. The varying of one mapping of execution threads of application components to processing cores to another mapping of execution threads of application components to processing cores is performed by the co simulation dynamic scheduler. A co simulation dynamic scheduler changes the mapping of execution threads of application components to processing cores without re generating re compiling or re running code for the one or more application components

A co simulation dynamic scheduler may operate in a similar manner as an interactive static scheduler. As example the co simulation dynamic scheduler of may operate in a similar manner as the interactive static scheduler of . According to various embodiments an interactive static scheduler may help to generate an optimal conventional static scheduler. For example the interactive static scheduler of may be used to generate an optimal conventional static scheduler such as the conventional static scheduler or illustrated in respectively. In some embodiments a co simulation dynamic scheduler may help to generate a conventional dynamic scheduler. For example the co simulation dynamic scheduler or of may be used to generate a conventional dynamic scheduler such as the conventional dynamic scheduler or illustrated in respectively. In some embodiments a co simulation dynamic scheduler may be used to construct an interactive dynamic scheduler which may be used to generate an optimal conventional dynamic scheduler. For example the co simulation dynamic scheduler and or of may be used to construct an interactive dynamic scheduler such as the interactive dynamic scheduler illustrated in . The interactive dynamic scheduler may be used to generate an optimal conventional dynamic scheduler such as the conventional dynamic scheduler or illustrated in respectively.

The interactive static and dynamic schedulers discussed above may allow interactive re scheduling of execution threads of the application components to different processing cores of the target SMP during execution of the one or more application components i.e. without stopping execution of the one or more application components . The re scheduling during co simulation does not alter the design of the one or more application components and does not require re generating re compiling or re running code for the one or more application components. Accordingly the re scheduling discussed herein represents improved efficiency and time savings compared to conventional approaches that require re generating re compiling and re running of code for the components in order to find a suitable conventional static and or dynamic scheduler.

The ability to assess various scheduling schemes by interactively altering co simulation static or dynamic schedulers may help to determine an optimal co simulation scheduling scheme without re generating re compiling or re running code for the application. Conventional scheduling schemes assess a single candidate conventional scheduler. If a different scheduling scheme is to be employed the conventional schemes need to stop the target SMP re generate re compile and re run code for the application using the different scheduling scheme. According to various embodiments discussed herein a desired co simulation static or dynamic scheduler may be identified during co simulation using interactive scheduling. The desired conventional static or dynamic scheduler that corresponds to the identified co simulation static or dynamic scheduler may then be generated for standalone deployment of the application on the target SMP. Contrary to the conventional scheduling schemes embodiments allow interactively altering co simulation static or dynamic schedulers to generate the desired conventional static or dynamic scheduler without re generating re compiling or re running code for the application.

Embodiments allow profiling results i.e. runtime statistics of various static and dynamic scheduling schemes that map the execution threads of application components to specific processing cores on the target SMP to be considered and acted upon. For example relevant runtime statistics such as CPU load and memory usage may be streamed back to the co simulation design environment from the target SMP in real time i.e. while the code for the application components is being executed on the target SMP. According to various embodiments the target SMP may send continuous runtime statistics updates to the co simulation design environment. A portion of the runtime statistics may be provided to the user in various graphical and or textual formats if desired. Based on the profiling results the user may change the co simulation static or dynamic scheduling scheme to improve execution efficiency of the code including but not limited to increasing execution speed minimizing memory usage improving load distribution across cores minimizing power consumption minimizing communication among the cores etc. For example the user may change the mapping for faster execution or to better meet application design constraints.

According to exemplary embodiments runtime scheduling experiments may be conducted in the co simulation design environment to determine and subsequently generate schedulers that satisfy e.g. meet or exceed a design requirement for an application. A generated scheduler may identify a scheduling scheme for executing the application being designed in the co simulation design environment on the SMP. The generated scheduler may be reused in subsequent executions of the application on the SMP.

Optionally computing device may include multiple CPUs for executing software loaded in memory and other programs for controlling system hardware. Each of the CPUs can be a single or a multiple core processor. The code loaded in memory may run in a virtualized environment such as in a Virtual Machine VM . Multiple VMs may be resident on a single processor. Also part of the code may be run in hardware for example by configuring a field programmable gate array FPGA using an application specific instruction set processor ASIP or creating an application specific integrated circuit ASIC . Further part of the applications may be run on analog electronic devices or other resources may be used to run part of the application such as graphics processing units GPUs or may be dedicated hardware such as Fast Fourier Transform FFT processing blocks.

Storage may contain software tools for applications. Storage can include code for the operating system OS of the computing device code for at least one application executed by the OS including the applications for the co simulation design environment . Storage may also hold data generated from the co simulation design environment . Those of ordinary skill in the art will appreciate that parts of applications can be stored in the CPU cache or memory as well or they can be stored on a network.

Input device coupled to computing device may include a keyboard mouse microphone camera such as a web camera or other input device such as a 3D mouse space mouse multipoint touchpad accelerometer based device gyroscope based device etc. Computing device may receive through input device input data such as the input data for developing a model. Computing device may display on output device one or more interfaces for displaying the data generated from co simulation design environment .

As discussed above computing device may host co simulation design environment . For example computing device may host a BDE or TPE. The co simulation design environment may be used to create and test application . Application may include one or more of a block diagram a state based diagram a textual program a technical computing program that performs technical calculations when executed etc.

For example co simulation design environment may be used to develop a block diagram application or a textual application. Application may have one or more application components such as application components and . Furthermore co simulation design environment may include code generator . Code generator may be used to generate code that executes on an SMP . For example code generator may generate code for application components and where the generated code is capable of executing on SMP . Code generator may be implemented in hardware or a combination of hardware and software.

A scheduler for application may be developed in co simulation design environment . Scheduler may be an interactive static scheduler or an interactive dynamic scheduler. Scheduler may implement a mapping of application components and to individual processing cores on SMP . SMP may include identical processing cores core core core and core . The term identical is used herein to indicate that resources associated with the cores are identical. That is when the input to cores is the same execution results of a given core of SMP are identical to the execution results of any other core of SMP . It will be appreciated that the number of cores depicted in SMP is exemplary and the actual number of identical cores in SMPs utilized by embodiments may be less or greater. In one embodiment SMP may be the processor for computing device .

Based on the mapping code for application components and may be executed on the assigned cores and during a co simulation of application . For example application component may be mapped to execute on core . Application component may be mapped to execute on core . Application component may be mapped to execute on core . The mapping may maintain data synchronization within application and across application components and . That is if application includes multiple copies of a dataset application may be mapped to execute such that the multiple copies are kept in coherence with one and other and therefore data integrity is maintained. Thread synchronization primitives may be implemented to maintain data synchronization.

It will be appreciated that application can contain at least one application component that is simulated in co simulation design environment while other application components from application are executed on SMP .

During a co simulation of application profiling results may be generated during execution of application and provided to co simulation design environment from the SMP in real time i.e. while application is executing. Profiling results may include performance statistics associated with the cores of the target SMP. For example profiling results may include but are not limited to metrics and or runtime statistics associated with the execution of application on SMP . Exemplary profiling results may include processor load a metric associated with the execution utilization of a core memory usage stack usage cache utilization e.g. hit miss statistics etc. Profiling results may also include metrics relating to a buffer allocation algorithm data synchronization an inter thread wait time resource utilization by other applications and the execution priorities of those applications. Profiling results are discussed below in greater detail in connection with .

A user of co simulation design environment e.g. a person another software program or an algorithm that is part of the application running in simulation etc. may view profiling results via interface . According to various embodiments interface may include a graphical user interface GUI or an application programming interface API . In an embodiment interface may be provided via output device in communication with computing device . The user may review the information from profiling results. Based on the review the user may interactively vary the scheduling scheme of scheduler during the execution of application via interface . According to various embodiments the user may use input device to interact with interface . The scheduling scheme may be interactively varied without halting execution of application . In addition the scheduling scheme can be modified without re generating re compiling or re running code for application .

According to various embodiments the application components may be formed by grouping i.e. factoring together various components of application . depict an exemplary technique for factoring an application into application components within a BDE.

Output signal is fed into if block . If output signal satisfies the condition specified in the if block output signal is added with output signal at adder block . The output of adder block is fed into block which may contain a Boolean expression such as AND . Output signal is also fed into block . The output of block may be generated as the final output of the block diagram model illustrated in . Block diagram model may be an executable block diagram model that represents a dynamic system that can be simulated on target hardware. Additionally block diagram may be factored according to an instruction received from a user or programmatically e.g. from a remote application. The factorization of block diagram is illustrated in .

As illustrated in blocks and may be grouped together to form a first factored region e.g. demarcation boundary of diagram according to an instruction received from a user or programmatically e.g. from a remote application. Demarcation boundary indicates that blocks and represent a group. Blocks and of block diagram remain outside demarcation boundary and thus are not part of the group. Grouping of the elements illustrated in is for illustrative purposes and should not be construed as limiting.

In the blocks within demarcation boundary are designated as application component in block diagram . Use of application component to represent blocks and does not alter the design of block diagram . As illustrated in three outputs and leave the demarcated boundary of application component . These three outputs are illustrated as output signals of application component in . further illustrates an additional grouping of blocks and using demarcation boundary . Similarly block is encompassed by demarcation boundary .

According to various embodiments factorization may attempt to break components of an application into groups according to a criteria. For example an application may be factored into groups using as few groups as possible. illustrates an exemplary factorization result for block diagram . Blocks and are designated as application component . Block is designated as application component . As shown in exemplary factorization illustrated in resulted in grouping blocks of diagram into three application components and .

Application components and of application may be executed on an SMP using an interactive static scheduler or an interactive dynamic scheduler.

During co simulation a user or a program can modify the mapping between the application components and cores of the SMP by re allocating application components to different cores for execution. For example via input device a user may activate interface displayed on output device . Interface may be associated with application components and . According to various embodiments interface may be a graphical user interface GUI or an application programming interface API . illustrates an exemplary GUI as interface . Interface allows a user to switch the execution of application component from the currently selected core to another core via graphical affordance . Graphical affordance may include for example a button a dropdown menu a list etc. The switch can be made from co simulation design environment . For example selecting a core on graphical affordance of interface may transfer execution of application component from core to core when application component is next invoked i.e. the next time application component runs . It should be noted that co simulation may not need to be stopped during the core selection and execution transfer processes. That is the execution of application component is transferred from core to another core without re generating re compiling or re running code for application component or application components and .

As provided above an interactive static scheduler or a co simulation dynamic scheduler may be used to modify the scheme assigning the execution threads associated with application components to processing cores on the SMP. That is an interactive static scheduler or a co simulation dynamic scheduler may be used to remap the execution threads associated with application components to different processing cores on the SMP during co simulation. According to various embodiments the scheduling scheme i.e. the mapping between the execution threads and processing cores may be modified by a user such an algorithm or an application. The main.c code illustrated below represents the main execution entry point of the application components to be executed on the target SMP. The main.c code also refers to the main thread of the application components running on the SMP that receives instructions from the co simulation environment and allocates the other application threads to processing cores. In this example there is one thread representing one application component. The thread representing the application component is illustrated using a variable called baseRateThread in the code. Additionally the desired processor core number to which the application component is to be mapped is received from the host simulation environment and stored in a variable called cpuset during co simulation. With the statement s pthread setaffinity np baseRateThread sizeof cpu set t cpuset the thread baseRateThread is set to be executed on the processor core pointed to by cpuset Since the processor core identification is parameterized the core processors to execute the application components may be set and changed during co simulation. Therefore modifying the scheduling scheme does not require re generating re compiling and re running the code for the application comprising the application components. Provided below is an exemplary C code program that executes on the SMP for modifying the scheduling scheme without re generating re compiling and re running code for the application components.

The ability to modify the scheduling scheme of application components as illustrated in gives a user the ability to determine an allocation of application components to cores to provide things such as but not limited to improved load balancing on the SMP faster execution of the application improved processing efficiency and optimal memory usage. In an embodiment a user can determine a best or optimum allocation of application components to cores. The user may use real time information such as statistics about the cores processing the application components to better determine which modifications may improve processing efficiency among the cores. For example relevant runtime statistics such as CPU load and memory usage may be streamed back to the co simulation design environment from the target SMP in real time i.e. while the code for the application components is being executed on the target SMP. Accordingly it may be beneficial to provide relevant runtime statistics to the co simulation design environment where the user can access the runtime statistics.

According to various embodiments the target SMP may send continuous runtime statistics updates to the co simulation design environment. As illustrated in profiling results may be generated during execution of application including application components and and provided to co simulation design environment from SMP in real time i.e. while application is executing. Profiling results may include performance statistics associated with cores of SMP . For example profiling results may include but are not limited to metrics and or runtime statistics associated with the execution of application on SMP . Exemplary profiling results may include processor load a metric associated with the execution utilization of a core memory usage stack usage cache utilization e.g. hit miss statistics etc. Profiling results may also include metrics relating to a buffer allocation algorithm data synchronization an inter thread wait time resource utilization by other applications and the execution priorities of those applications.

A portion of the profiling results may be provided to the user in various graphical and or textual formats if desired. For example profiling results may be provided on output device . Based on the profiling results the user may change the interactive static or dynamic scheduling scheme to improve execution efficiency of the code including but not limited to increasing execution speed minimizing memory usage improving load distribution across cores minimizing power consumption minimizing communication among the cores etc. For example the user may change the mapping of application components to cores using interface via input device for faster execution or to better meet application design constraints.

According to various embodiments relevant runtime statistics may be provided in the co simulation design environment and back annotated to corresponding application components. For example runtime statistics associated with each application component may be displayed in the co simulation design environment along with the corresponding application component.

As provided above one or more application components of the application provided in the co simulation design environment may execute on the SMP while other application component s may execute on the co simulation design environment. illustrates an exemplary flowchart where an application component of the application is running on the co simulation design environment during co simulation. The execution of algorithm component is started on the co simulation design environment block . As the application executes in co simulation one or more application components of the application execute on the SMP. The profiler results for those application components running on the SMP may be sent from SMP to the co simulation design environment using a TCP IP server. TCP IP server is started for sending the profiling results to the co simulation design environment block . The co simulation design environment connects to the TCP IP server for receiving the profiling results for those application components running on the SMP from the target SMP block . The receiver i.e. the co simulation design environment may request the profiling results of the application components running on the SMP from the SMP block . The system then determines if the profiling results for current time step has been received block . If the profiling results for current time step has been received the profiling results is displayed for the current time step block .

According to various embodiments flowchart illustrated in and flowchart illustrated in may be active simultaneously during co simulation to illustrate that the profiler results may be received on the co simulation design environment during co simulation. Flowchart illustrated in describes the application running on the SMP and flowchart illustrated in describes the application running on the co simulation design environment. Accordingly there may be communication and or synchronization between flowchart and flowchart .

Back annotated runtime statistics for application component indicate that application component is executed on core with execution priority of 4 and uses up 78 of the processing resources of core when executing. The utilization percentage illustrated in back annotated runtime statistics and refers to the percentage of execution capacity of the specified processing core that the associated component uses. The runtime statistics for application components and illustrated in indicate that all components have been mapped to execute on core on the target SMP. A user may wish to modify the mapping so that more than one core are used to execute application components and .

During co simulation a user presented with profiling results may interactively modify the scheduling scheme for an application by re allocating components to different cores for execution. depicts model during co simulation in which the profiling statistics for the components have been updated following an interactive static or dynamic varying of the scheduling scheme to reassign application component and application component to execute on cores and core respectively. Following the static or dynamic re scheduling of the application components to execute on different cores the back annotation of profiling results for application component indicate that application component still executes on core now with execution priority set to 12 and using up 23 of the processing resources of core when executing.

Back annotation of profiling results for application component indicates that application component now executes on core with execution priority set to 7 and using up 57 of the processing resources of core when executing. Back annotation of profiling results for application component indicates that application component now executes on core with execution priority set to 4 and using up 80 of the processing resources of core when executing.

Comparing the execution profiling results of the modified scheduling scheme illustrated in with the profiling results of the scheduling scheme illustrated in it can be determined that the utilization of each component has increased. The increased utilization may be for example due to additional communications overhead associated with transferring data between different cores. In the modified scheduling scheme only application component executes on core thereby reducing the load on core . Accordingly the overall load has been more effectively balanced across the multiple cores.

Profiling results of the modified scheduling scheme illustrated in can be visually provided on an output device. For example CPU load for each core can be processed and may be graphically represented e.g. using a scope block and a plot. depicts exemplary plots of profiling results for each target processor core respectively during co simulation of application components as depicted in . In plots the utilization percentage over time for core core and core respectively is displayed and tracks the profiling results displayed in .

Based on utilization graph of core illustrated in the user may determine that resources of core are being used close to the maximum level. Accordingly the user may choose to avoid mapping another application component to core in order to prevent core from overloading or generating errors. On the other hand utilization graph of core illustrated in indicates that resources of core are being used at a minimum level. Accordingly the user may choose to map other application components to core in order to better distribute the load between cores and .

According to various embodiments the design of an application may be re factored during co simulation. As provided above illustrate exemplary BDE model being factored into three application components and . Embodiments allow re factorization of model .

For example application components and of model can be combined into a single component. illustrates exemplary re factored BDE model where application component of BDE model remains intact. However in re factored BDE model application components and of BDE model are combined together and represented by a new application component . Following re factorization the profiling results of application components and may be annotated back to BDE model . As illustrated in profiling results of application component application component may be assigned to core for processing. Application component uses up to 76 of resources of core . The utilization rate for new application component is equal to the sum of the utilization rates for two application components and together. Profiling results associated with application component illustrate that application component is assigned to core for processing where application component uses up to 78 of resources of core .

The CPU load i.e. utilization percentage of a specific core is the sum of all application component utilizations for that core. illustrates that application component and application component are both executed on core for example core of SMP illustrated in . The utilization rate for application component is 29 and the utilization rate for application component is 15 . Accordingly the utilization rate of core is the sum of the utilization rates for application component and application component which is equal to 44 . The utilization percentage of the cores may be displayed in a graphical plot such as plots and shown in . Plots and graphically depict core utilization on the target SMP e.g. SMP over time for model that is being co simulated according to the scheduling scheme illustrated in .

Based on the profiling results illustrated in no application component was assigned to core for example core of SMP illustrated in . Accordingly graph for core indicates an utilization rate of about 0 . As provided above the utilization rate of core is the sum of the utilization rates for application component and application component which is equal to 44 . Graph for core indicates a utilization rate of about 44 . The runtime statistics provided on show that the utilization rate of core for example core of SMP illustrated in is 17 and the utilization rate for core for example core of SMP illustrated in is 65 . Accordingly graph for core indicates a utilization rate of about 17 and graph for core indicates an utilization rate of about 65 . The graph provides visual representation to the user illustrating the utilization rates of all cores on SMP . Accordingly the user can determine if the application components should be re mapped among the cores using a different scheduling scheme.

Accordingly in an interactive dynamic scheduler may be better suited for BDE model as compared to an interactive static scheduler. Profiling results can be back annotated to model and shown on BDE representations of components and . The profiling results may be displayed in streaming fashion. Interactive dynamic scheduler may switch between a plurality of co simulation dynamic schedulers during execution of BDE model . Interactive dynamic scheduler may generate one conventional dynamic scheduler using the plurality of co simulation dynamic schedulers based on execution i.e. simulation results of BDE . According to various embodiments a conventional dynamic scheduler may be generated using a single co simulation dynamic scheduler. An interactive dynamic scheduler adds the ability to consider multiple co simulation dynamic schedulers and generate an optimal i.e. desired conventional dynamic scheduler. Interactive dynamic scheduler is illustrated in greater detail in .

For example interactive dynamic scheduler may switch between a first co simulation dynamic scheduler or a second co simulation dynamic scheduler . According to various embodiments co simulation dynamic scheduler may implement a dynamic scheduling algorithm where application components and of BDE model are assigned to SMP cores based on shortest predicted execution time mapped to least busy core. Co simulation dynamic scheduler may implement a dynamic scheduling algorithm based on executing the longest waiting component first on the least busy core. Co simulation dynamic schedulers and execute during simulation and control the mapping of the components in model to the cores of the target SMP. After co simulation a conventional dynamic scheduler may be generated using one of the co simulation dynamic schedulers and . For example the optimal conventional dynamic scheduler may be generated that corresponds to the co simulation dynamic scheduler that had the best runtime statistics during execution of BDE model .

In addition to improving the execution efficiency it may be necessary to re map the components to different cores to satisfy system requirements and or design constraints. An embodiment may be used to identify schedulers that satisfy certain system requirements and or design constraints. For example with regard to the model depicted in an adequate or possibly optimal interactive dynamic scheduler might have to take the following into account to satisfy design constraints 

According to various embodiments a co simulation dynamic scheduler may be represented using a state chart BDE such as that depicted as chart in . shows a co simulation dynamic implemented as a state chart. Blocks and in state chart represent states. The directed arrows connecting one state to another are state transitions. Some state transitions such as directed arrows have conditions attached to them signifying that state transitions occur when the specified conditions are satisfied. The co simulation dynamic starts by transitioning to state that contains the initial conditions of the scheduling algorithm.

As illustrated in connection with state application components through start running on core . The co simulation dynamic starts simulating in the co simulation environment and continuously monitors the CPU load of core . Based on the condition associated with state transition if the CPU load of core exceeds 80 a state transition occurs. State chart tests a series of conditions to determine the next state of the algorithm. For example the condition associated with transition tests if application component is running i.e. active. If it is determined that Component is active state transition to state occurs. As a result of state transition the co simulation dynamic starts executing application component on core of the SMP as indicated by state . There is an unconditional state transition associated with state which brings the state back to .

While the co simulation dynamic is running the co simulation dynamic continuously receives runtime statistics from the SMP e.g. CPU load. The co simulation dynamic determines the mapping of application components to SMP cores based on the runtime statistics. The user may interactively vary the scheduling scheme by for example selecting one co simulation dynamic scheduler among a plurality of co simulation dynamic schedulers during co simulation i.e. only one co simulation dynamic scheduler is executing at any given time.

According to embodiments the user or a program may also interactively vary the scheduling scheme by for example interactively varying a parameter or a condition of a state transition of a given co simulation dynamic scheduler. Interactively varying the parameter or the condition of the state transition in turn may alter the decision making process of the co simulation dynamic scheduler resulting in changing the behavior of the co simulation dynamic scheduler. For example the user may decide to change the threshold for state transition to 70 from the initial 80 . Such interactive actions do not require re generating re compiling or re running code for the application running on the SMP. Accordingly co simulation dynamic schedulers may be interactively modified without re generating re compiling or re running code for the application running on the SMP.

Once a satisfactory co simulation dynamic scheduler is identified by interactive dynamic scheduling code controlling the scheduling of the application may be generated in the co simulation design environment for standalone execution on the SMP. That is a conventional dynamic scheduler is generated as a result of the by interactive static scheduling illustrated in .

In processing may begin by factoring the design of an application such as a model in either a BDE or TPE into two or more application components block . As provided above the factored application components can be defined in a BDE by block by subsystem by rate by model or by demarcated boundary. Similarly application components in a TPE may be defined by function by object method by pragma instrumentation by model or by demarcated boundary. For example in an exemplary TPE e.g. MATLAB code may be factored as follows 

The MATLAB code above provides an example depicting how MATLAB functions can be used to factor the design into application components. The MATLAB code shows the results of factoring an application component from the original function comm dmt resulting in a new function comm. dmt1 with a factored application component i.e. the function component.

Processing may initially map application components to one or more cores of the target SMP block . Code for the application may be generated based on the initial mapping block . For example in one embodiment default settings may initially map all application components to one core and then generate code to be executed on that one core. Mapping all application components to execute on a single core may predict the processing time CPU load of each application component. However such mapping does not predict the potential I O wait times if dependent data were to come from a different core i.e. wait times caused by inter thread communications and synchronization . Also the profiling results of the single core execution may not account for cache effects associated with multi core parallel execution. That is runtime statistics such as CPU load may not be an exact predictor for CPU load when the application components are distributed across multiple cores in parallel. As a result in other embodiments an initial mapping of application components may be distributed across multiple cores rather than all of the components being assigned to execute on the same core.

Once mapped the application may be co simulated by executing some application components in the co simulation design environment and executing other application components for which code has been generated on the SMP using the assigned core s block .

Profiling may be performed on different components running on the SMP cores during co simulation. Runtime statistics for the application components can be captured and stored or displayed block . The runtime statistics may be displayed in the co simulation design environment in various graphical and textual formats during co simulation. For example runtime statistics may be displayed by back annotation to the corresponding application components in the co simulation design environment. For example a textual display of runtime statistics may include CPU load memory usage cache utilization cache hit miss statistics system throughput input wait times buffer use re use thread dependencies graph timelines etc.

Processing allows for interactively varying the scheduling scheme by reallocating one or more application components to available cores during co simulation block . Reallocation of the application components to available cores results in a modified mapping i.e. modified scheduling scheme. The interactive varying of scheduling scheme occurs without a user or program first having to re generate re write re compile re link re download and or re run the application code. Embodiments allow implementing application components deployed as threads of execution in a multi threaded process to allow for varying the scheduling scheme.

A thread may be mapped to any core of an SMP based on for example inter thread communication primitives. The inter thread communication primitives may include an OS supplied interface and synchronization abstractions like pipes messages queues etc. to carry signal buffers back and forth across the components. Instrumenting and parameterizing the generated code using application programming interfaces APIs may allow the co simulation design environment to tune the processor core affinity while the application components are running on the SMP. Notwithstanding the above it should be appreciated that threading is one way to dynamically map application components to cores at runtime and embodiments are not limited to deploying application components as separate threads of execution in a multi threaded process.

Runtime statistics may be updated for the new modified scheduling scheme. The updated runtime statistics may be analyzed programmatically and or by a user block . For example the runtime statistics may be sent back to the co simulation design environment and back annotated to the corresponding application components. A user may determine whether the modified scheduling scheme meets requirements. Alternatively a program may determine whether the modified scheduling scheme meets requirements based on comparing the runtime statistics to pre determined criteria. If the updated runtime statistics indicate that the modified scheduling scheme meets design requirements yes for block a conventional static or dynamic scheduler implementing the modified scheduling scheme is generated for the application block . The process ends with generating the conventional static or dynamic scheduler.

If the scheduling scheme does not meet requirements no for block a further decision is made as to whether or not there are additional scheduling schemes to attempt block .

If there are more scheduling schemes to try in the search for a scheduling scheme that best meets design requirements yes for block the sequence repeats and allows the interactive scheduler to reallocate application components to different cores block .

If there are no more scheduling schemes to try no for block a further determination may be reached as to whether or not there are any more application component combinations to try in which the various elements in the model may be factored into different combinations block . The decision as to whether or not there are more application component combinations to try may be made by a user or may be programmatically determined based on pre determined criteria. If there are more application component combinations to try yes for block the process iterates and the application design is factored into two or more different application components block . If there are no more application component combinations to try no for block then processing may optionally generate the next best conventional static or dynamic scheduler block . According to various embodiments the processing may end without generating a conventional static or dynamic scheduler.

The processing described above in reference to illustrates an exemplary sequence in which a scheduler that is good enough to meet a design requirement is produced. Processing depicted in stops once any conventional static or dynamic scheduler that meets design requirements is found. In another exemplary embodiment the processing of can be adjusted so as to attempt to generate an optimal conventional static or dynamic scheduler. The processing can include determining whether the current conventional static or dynamic scheduler is the best so far in the co simulation. The determination may be by a user or programmatically determined without user input based on pre determined criteria. For example design requirements for the application may be automatically compared to the profiling results of the modified scheduling scheme to see if the profiling result passes a pre determined threshold. One or more modified scheduling schemes may be compared and the best scheme may be determined for example as the best so far scheduling scheme. The resulting scheduler may be the best so far conventional static or dynamic scheduler implementing the best so far scheduling scheme.

The potential re factoring of the application design by assembling new application component combinations provides greater flexibility in identifying an optimal conventional static or dynamic scheduler that meets application design requirements than does the varying of mappings alone. Thus using the exemplary techniques described above a generated conventional static or dynamic scheduler that meets design requirements can continually be refined and improved in an attempt to identify an optimal conventional static or dynamic scheduler for an application under development in the co simulation design environment.

If the co simulation techniques described above are unable to identify a satisfactory conventional static or dynamic scheduler a user may need to change some of the variables affecting the co simulation of the application design. For example the user or program may choose a different SMP platform with different characteristics reduce complexity of the application design lower scheduling requirements or make other changes and then perform the above described techniques again to attempt to identify a satisfactory conventional static or dynamic scheduler.

In the network environment computing devices and may provide clients with software components or products under a particular condition such as a license agreement. The software components or products may include those for providing co simulation design environment and or implementations of code for select elements. In one example computing device may perform program development in the co simulation design environment while computing device hosts a target hardware used in the co simulation.

In an embodiment a non transitory computer readable media is provided. The media comprises one or more instructions that when executed cause at least one computing device to interact with a co simulation design environment using an interface to communicate with a multi threaded application executing on a target processor. The target processor includes a plurality of symmetric processor cores. The media further comprises one or more instructions that when executed cause at least one computing device to allocate execution of the multi threaded application to one or more symmetric processor cores of the target processor using the interface. The media also comprises one or more instructions that when executed cause at least one computing device to receive an interactive instruction via the co simulation design environment the interactive instruction to alter allocation of at least a portion of the execution of the multi threaded application. The media further comprises one or more instructions that when executed cause at least one computing device to alter via the interface allocation of the at least a portion of the execution of the multi threaded application.

In another embodiment a method for interactively varying scheduling of a multi threaded application executing on a symmetric multi core processor is provided. The method interacts with a co simulation design environment using an interface to communicate with a multi threaded application executing on a target processor. The target processor includes a plurality of symmetric processor cores. The method further allocates execution of the multi threaded application to one or more symmetric processor cores of the target processor using the interface. The method receives an interactive instruction via the co simulation design environment. The interactive instruction is to alter allocation of at least a portion of the execution of the multi threaded application. The method alters via the interface allocation of the at least a portion of the execution of the multi threaded application.

In an embodiment a system for interactively varying scheduling of a multi threaded application executing on a symmetric multi core processor is provided. The system includes a memory and a processor. The memory stores allocation information. The processor interacts with the memory and uses the allocation information to interact with an interface in a co simulation design environment to communicate with a multi threaded application executing on a target processor. The target processor includes a plurality of symmetric processor cores. The processor further uses the allocation information to allocate execution of the multi threaded application to one or more symmetric processor cores of the target processor using the interface. The allocating occurs when the multi threaded application is executing without re generating re compiling or re running code for the multi threaded application. The processor further uses the allocation information to receive an interactive instruction via the co simulation design environment. The interactive instruction is to alter allocation of at least a portion of the execution of the multi threaded application while the multi threaded application is executing. The processor further uses the allocation information to receive execution data from the multi threaded application executing on the one or more symmetric processor cores of the target processor. The receiving occurs in the co simulation design environment via the interface and when the multi threaded application is executing. The processor further uses the allocation information to alter via the interface allocation of the at least a portion of the execution of the multi threaded application based on the received data while the multi threaded application is executing on the symmetric processor cores of the target processor without re generating re compiling or re running code for the multi threaded application.

Although the embodiments described above take place within a co simulation design environment other embodiments are also possible within the scope of the present invention. For example in another embodiment the search to identify static and dynamic schedulers as described above may take place completely within a simulation environment. In such an embodiment instead of generating code for a target hardware that will be executed on an actual SMP during co simulation the performance of the SMP cores in executing the application being designed may be completely simulated within a simulation design environment. During the simulation a user or program may be presented with simulated performance data representing the performance of the virtual cores of the SMP and may adjust scheduling attributes based on the data. While such an embodiment may suffer some accuracy loss due to not running the application code on the actual target hardware it may provide a lower cost alternative and be more readily available than the co simulation techniques described above as the target hardware does not need to be available during application design.

One type of application that can be co simulated may include a block diagram model representing a real world system. It should be noted that the term block diagram may also refer to and can include other graphical modeling formalisms. For instance flow charts are block diagrams of entities that are connected by relations. Flow charts may be used to capture process flow and may not generally be suitable for describing dynamic system behavior. Data flow block diagrams are diagrams of entities with relations between them that describe a graphical programming paradigm where the availability of data is used to initiate execution of blocks in the diagram. In data flow diagrams a block may represent an operation and a line may represent execution dependency describing the direction of data flowing between blocks. It will be appreciated that a block diagram model provided in one modeling formalism may include entities from other modeling formalisms.

Embodiments described herein may be provided as one or more computer readable programs embodied on or in one or more physical and non transitory computer readable storage media. The media may be a floppy disk a hard disk a compact disc a digital versatile disc a flash memory card a PROM an MRAM a RAM a ROM a magnetic tape etc. In general the computer readable programs may be implemented in any programming language. Some examples of languages that can be used include MATLAB programming language FORTRAN C C C Python FLASH JavaScript or JAVA . A programming language may be an array based language. An array based language is a language where an array is a basic unit of data storage. An array may have zero or more dimensions. An example of an array based language may be a language at least a subset of which is executable in the MATLAB programming environment. The software programs may be stored on or in one or more mediums as object code. Hardware acceleration may be used and all or a portion of the code may run on a FPGA an Application Specific Integrated Processor ASIP or an Application Specific Integrated Circuit ASIC . The code may run in a virtualized environment such as in a virtual machine. Multiple virtual machines running the code may be resident on a single processor.

Since certain changes may be made without departing from the scope of the present invention it is intended that all matter contained in the above description or shown in the accompanying drawings be interpreted as illustrative and not in a literal sense. Practitioners of the art will realize that the sequence of steps and architectures depicted in the figures may be altered without departing from the scope of the present invention and that the illustrations contained herein are singular examples of a multitude of possible depictions of the present invention.

The foregoing description of example embodiments of the invention provides illustration and description but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example while a series of acts has been described herein the order of the acts may be modified in other implementations consistent with the principles of the invention. Further non dependent acts may be performed in parallel.

In addition implementations consistent with principles of the invention can be implemented using devices and configurations other than those illustrated in the figures and described in the specification without departing from the spirit of the invention. Devices and or components may be added and or removed from the implementations described herein depending on specific deployments and or applications. Further disclosed implementations may not be limited to any specific combination of hardware.

Further certain portions of the invention may be implemented as logic that performs one or more functions. This logic may include hardware such as hardwired logic an application specific integrated circuit a field programmable gate array a microprocessor software wetware or a combination of hardware and software.

No element act or instruction used in the description of the invention should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Where only one item is intended the term one or similar language is used. Further the phrase based on as used herein is intended to mean based at least in part on unless explicitly stated otherwise.

