---

title: Concurrency control in database transactions
abstract: To achieve long running batch updates, a transaction aggregator layer and one or more data aggregation queues, such as a command queue, are placed between one or more clients and a database. Writes go to the database aggregator layer and are enqueued in the appropriate data aggregation queue, which may be allocated by transaction. Committing the transaction drains the queue and writes the contents of the queue in one transaction-like update to the database. By using the transaction logic in the transaction aggregator layer, transaction-like behavior may be achieved that allows both updates and transactions to scale with less impact on database servers.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08965861&OS=08965861&RS=08965861
owner: Amazon Technologies, Inc.
number: 08965861
owner_city: Reno
owner_country: US
publication_date: 20120628
---
Databases can be difficult to scale as demands on a database increase. Many conventional horizontal and vertical scaling techniques may attempt to solve some of the problems of scaling. Still when placing large amounts of data into a database whether horizontally or vertically scaled the database may exceed the input output capacity of its host system. For example the database may be input output bound to the number of connections available to the database. In other cases the database may be input output bound to the amount of memory available for transactions. As a result clients may experience periods of database unavailability when the database is busy.

For example long running transactions of seconds or minutes may require significant input output overhead while locking clients from the database for large amounts of time. The input output bounding can prevent the scaling of databases to receive and contain large amounts of data. To ease the scaling problem some database managers may use larger database hardware with more capabilities such as memory and input output throughput.

In the following description various embodiments will be described. For purposes of explanation specific configurations and details are set forth in order to provide a thorough understanding of the embodiments. However it will also be apparent to one skilled in the art that the embodiments may be practiced without the specific details. Furthermore well known features may be omitted or simplified in order not to obscure the embodiment being described.

Techniques described and suggested herein include placing a transaction aggregation layer between a client and a database to reduce a load from a large number of transactions on the database. The transaction aggregator layer may receive a request to open a queue for aggregation. The transaction aggregator layer may then enqueue data manipulation requests such as transactional writes in a data aggregation queue. After receiving a request to close the queue the transaction aggregation layer may commit the data manipulation requests in the data aggregation queue to the database in a single transaction. This method allows transaction like behavior from long running batch updates.

For example to achieve long running batch updates a transaction aggregator layer and one or more data aggregation queues such as a command queue are placed between one or more clients and a database. Writes go to the database aggregator layer and are enqueued in the appropriate data aggregation queue which may be allocated by transaction. Committing the transaction drains the queue and writes the contents of the queue in one transaction like update to the database. By using the transaction logic in the transaction aggregator layer transaction like behavior may be achieved that allows both updates and transactions to scale with less impact on database servers.

By aggregating data manipulation requests into the transaction aggregator layer in accordance with the various embodiments described and suggested herein several technological benefits may be obtained. For example databases performing many transactions and or large transactions may become input output bounded such as running out of available connections running out of memory and or increased disk input output I O because of maintaining database state. In some cases large single database transactions may take seconds or minutes as opposed to small transactions that may be measured in milliseconds or less. By using a transaction aggregator layer the number of database connections may be reduced and the input output I O demand decreased and or distributed over time. As the input output demand is decreased the database hardware demand may be lower. In some embodiments this may allow large databases to run on commodity hardware as the input output demand is no longer as strenuous. In other embodiments the aggregation of data manipulation requests enable load balancing and scheduling of transactions. For example data manipulation can be selectively performed at times when a database is relatively idle. When not serving customer traffic the aggregated data manipulations may be performed as a transaction. By performing aggregated data manipulation transactions when customer traffic is low a better customer experience may be provided because the database may be more responsive during high customer traffic times without the additional load of the aggregated data manipulations. In some embodiments as the demand on the database is decreased a database may be scaled to larger volumes of data than were possible without the transaction aggregation layer. Another advantage is that the database retains a consistent view during the operation of the transaction aggregator layer. Yet another advantage is that the transaction may be performed atomically. Another advantage includes concurrency controls such as locking and locking scope.

It should be recognized that a data aggregation queue may take the forms of multiple storage technologies. Queue is used in the sense of a place of temporary holding. In fact the data aggregation queue may be formed of technologies that may include SQL Databases NoSQL Databases Files XML JSON Caches FIFO Queues LIFO Queues Stacks Collections Arrays or other technologies applicable to data storage. In one embodiment the data aggregation queue is placed on a semi persistent data store which includes data that is acceptably lost during a failure but used during normal operation.

It should also be noted that computing resources discussed herein may include virtual resources as well. A server for example may be running directly on the hardware or provided services through a virtual machine. Storage databases and other computing resources may also be managed resources whether on hardware directly or on a virtual machine.

The transaction aggregator layer may use different types of locking which may include optimistic locking and pessimistic locking Optimistic locking allows the transaction that commits first to succeed. For example timestamps in the database may be used to determine which commit first succeeded. Pessimistic locking allows the transaction that starts first to succeed. For example timestamps in the data aggregation queues may be examined for priority. In some embodiments optimistic locking may include delaying the locking of the database toward the time of committing a transaction to the database. In one embodiment using optimistic locking the transaction is attempted without an external request to lock the database and instead relying on the database to process the transaction. In some embodiments pessimistic locking may include decreasing the delay between receiving transaction information and locking the database. In one embodiment using optimistic locking the transaction aggregator layer will receive data manipulation requests and place them in the queue without locking the database. After all of the data manipulation requests for a transaction are received and the data aggregation queue is closed the transaction aggregator layer may determine if the data manipulation requests may be performed on the database. This determination may include having the transaction aggregator layer determine if data dependencies of the data manipulation requests to the database are still valid such as by checking timestamps. The determination may also include failing if dependencies are included between data manipulation requests in the transaction. In some embodiments this may include determining if data in the database affected by the data manipulation requests has changed since the data manipulation request was created and or stored in the data aggregation queue. If the data dependencies are invalid the transaction aggregator may fail without proposing a transaction with the database. However if the data dependencies are valid the transaction aggregator may lock the database such that the data dependencies may no longer be changed by external requests. The transaction aggregator layer may then commit the data manipulation requests stored in the data aggregation queue to the database.

In one embodiment using pessimistic locking the transaction aggregator may receive information about the data manipulation requests that are to be sent to the data aggregation queue such as data manipulation requests related to billing information for a client. The transaction aggregator layer may lock the database or relevant parts of a database such as tables and or rows such that billing information for the client may not be modified. The transaction aggregator layer may then store received data manipulation requests in the data aggregation queue. Once all the data manipulation requests have been received and or the data aggregation queue has been closed the transaction aggregator layer may commit the data manipulation requests in the data aggregation queue to the database in a single transaction.

In some embodiments the filling of a data aggregation queue may occur over time. In one embodiment after opening a data aggregation queue a client may perform multiple application interface calls over time with the transaction aggregation layer. Each application interface call may provide a subset of the total data manipulation requests to store in the data aggregation queue to form a transaction. In another embodiment multiple clients may perform application interface calls to store data manipulation requests in the data aggregation queue. In one embodiment the data manipulation requests may be received with further information. For example a client may receive instructions that include the data manipulation and metadata identifying the ordering of the data manipulation in the transaction.

Turning now to an illustrative example of an environment using a transaction aggregator layer is shown. In this example the environment includes a client a transaction aggregator layer and a database . The client may be a computing resource including a server virtual machine computer that may be configured to communicate with a database and or make application interface calls. The transaction aggregator layer for example may be a layer of one or more servers between the database and the client. The database may be for example a collection of servers that work together to provide database functionality that may include atomicity consistency isolation and durability through transactional behavior. The client transaction aggregator layer and database may communicate using protocols over a network. The client may provide data manipulation requests to the transaction aggregator layer to apply as a single transaction to the database . A transaction is a unit of work applied to a database in which the contents of the transaction are applied or fail but leave the database in a consistent state.

In the embodiment shown a client such as a server has data manipulation requests to store in a database . The client may communicate with the transaction aggregator layer requesting the transaction aggregator layer to store the data manipulation requests to form a transaction to be applied to the database . The transaction aggregator layer may open a data aggregation queue to hold the incoming data manipulation requests. The client may then electronically transmit data manipulation requests to the transaction aggregator layer which stores the data manipulation requests in the data aggregation queue . Once the client has completed electronically transmitting the data manipulation requests the data aggregation queue may be closed. Using a version of optimistic locking the transaction aggregator layer may determine if the transaction can be performed based at least in part on the data manipulation requests in the data aggregation queue remaining unaffected by any changes to the database during the filling of the data aggregation queue . If determined that the transaction cannot be performed the transaction aggregation layer may report the failure to the client . If determined that the transaction can be performed the transaction aggregator layer may choose a scope of locking that covers the data dependencies of the data manipulation requests and lock the database . During locking scope selection options exist to lock individual rows which may be more costly through locking rows to locking entire columns. The more that is locked the less costly and more likely a collision occurs that would cause the transaction to fail. The transaction aggregator layer may then retrieve the data manipulation requests from the data aggregation queue and commit them to the database . After committing the data manipulation requests from the data aggregation queue the transaction aggregator layer may unlock the database and report the results to the client .

In one example a usage server as a client may report usage of a service to a transaction aggregator layer comprising a set of servers. The usage server may send an application programming interface API call to one of the set of servers of the transaction aggregator layer to request aggregation of transactional writes as data manipulation requests destined for a billing database supported by a SQL database optimized for storage of a large amount of information. The transaction aggregator layer makes available a data aggregation queue supported by a document based database optimized for a large volume of small transactions. Through one or more API calls the usage server may provide transactional writes such as conditional writes that are stored in the data aggregation queue . After providing all of the transactional writes to be used in the transaction the client may request to close the data aggregation queue . Upon closing the data aggregation queue the transaction aggregator layer may verify that the stored transactional writes in the data aggregation queue were not invalidated by other transactions that may have occurred on the billing database . If the transactional writes are still valid the transactional aggregator layer may lock the database using a scope preventing changes to data in the billing database writable by the usage server. The transaction aggregator layer may then commit the transactional writes in the data aggregation queue to the billing database using one transaction. After the transaction is complete the transaction aggregator layer may then unlock the billing database .

Turning now to an illustrative example of a more complex environment using a transaction aggregator layer is shown. In the embodiment shown a plurality of clients with different numbers of requests communicates with the transaction aggregator layer in order to store data manipulation requests with the database . In the embodiment shown a plurality of servers may request to open a data aggregation queue . In some embodiments a subset of the plurality of clients request to share a transaction and may work together to provide the data manipulation requests to use in a single transaction. Upon receiving a request for a data aggregation queue a data aggregation queue may be selected for use. The data aggregation queue may be selected based on data dependencies in the database and or scope of the transaction. In some embodiments if the data aggregation queue is in use the requestor may have to wait for the data aggregation queue to become available. As the data aggregation queue may be selected based at least in part on the scope of the transaction a shared scope may cause any requestors to wait until the prior requestor has finished its transaction. This prevention of causing a requestor to wait may help prevent transactions from failing.

Once selected and available the data aggregation queue may store data manipulation requests received by the transaction aggregator from the plurality of clients sharing the data aggregation queue . A failure detection module may detect if any changes have affected the data dependencies between the data manipulation requests in the data aggregation queue and the database . If not the plurality of clients may request to close the data aggregation queue . In some embodiments this may occur based on the first client to request the data aggregation queue be closed. In other embodiments all clients associated with the data aggregation queue must close the data aggregation queue . As the failure detection module has been monitoring changes the transaction aggregator layer may lock the database with a scope related to the data manipulation requests and commit the transaction using the data manipulation requests stored in the data aggregation queue . After which the database may be unlocked and the transaction status may be reported to one or more of the plurality of clients .

While the data aggregation queue is receiving data manipulation requests it can be desirable to fail fast or fail the transaction before all of the data manipulation requests are aggregated in the data aggregation queue. In some embodiments a failure detection module may discover if the transaction may fail due to a change in the underlying data within the database forming a data dependency. The failure detection module may monitor the database for changes to data forming a data dependency with the data manipulation requests stored within the data aggregation queue . If a change to data having a data dependency in the data aggregation queue is detected the failure detection module may cause the aggregation to fail. For example a refund has been requested of a billing system and the refund is stored in the data aggregation queue . If the refund is processed through another process such as through a phone call to an agent while the data aggregation queue also contains the refund the failure detection module detects that a refunded amount to a client has changed while a refund amount also exists in the data aggregation queue . The failure detection module may then communicate to the transaction aggregator layer which may then communicate to the plurality of clients that the billing transaction has failed. After which the plurality of clients may determine whether to resubmit the data manipulation requests in whole not at all or only a subset of the data manipulation requests. In some embodiments the failure detection module may be internal or external to the database. For example the failure detection module may compare a timestamp or version of data within the database with a timestamp or version of data manipulation requests within the data aggregation queue. If there is a mismatch the failure detection module may determine the transaction is failed.

For example a catalog domain may include several servers that are responsible for different portions of the catalog such as description images and ratings. The servers may request to submit transactional writes to the catalog database through an API call to the transaction aggregator layer . The transactional aggregator layer may select a data aggregation queue related to the scope of the transactional writes such as video games. The transactional aggregator layer may receive API calls from the servers with instructions on performing one or more of the transactional writes relating to descriptions images and or ratings. A failure detection module verifies that no changes occur to the data in the databases which are related to the transactional writes such as product page information. If a change is detected the failure detection module causes the transaction to fail. In some embodiments the failure detection module also determines the scope of the transactional writes to use for the database locking. If no changes are detected the scope of the transactional writes may be used to lock the database to changes. The database aggregation queue may supply the transactional writes to commit to the database by the transaction aggregator layer in a single transaction.

Turning now to an illustrative diagram of control flow using optimistic locking and a transaction aggregator layer is shown. This may be accomplished by a system such as seen in including a client transaction aggregator layer database and data aggregation queue . A client may request that the transaction aggregator layer create a new transaction. The transaction aggregator layer may open a new data aggregation queue to receive data manipulation requests into the transaction. The system may return from the data aggregation queue through the transaction aggregator layer to wait for further instructions from the client . In some embodiments these returns are a success confirmation of the operations such as a return from an API call . The client may then request one or more data manipulation requests be inserted into the transaction . The transaction aggregator layer may then write the one or more data manipulation requests to the data aggregation queue . The control may be returned from the data aggregation queue through the transaction aggregator layer to the client . In some embodiments this may also include a success message. If needed the client may repeat to as many times as needed to include all of the desired data manipulation requests in the transaction. After including all of the desired data manipulation requests in the transaction the client may request to close the transaction. The transaction aggregator layer may then determine if the data dependencies of the data manipulation requests are still valid. If so the transaction aggregator layer may read the data aggregation queue lock the database and place the read data manipulation requests into a transactional write into the database . After the transactional write the database may be unlocked and the result of the transactional write is reported to the transaction aggregator layer .

Turning now to an illustrative example of a process that may be used to aggregate data manipulation requests in a transaction is shown. The process may be accomplished by a system as seen in including a client transaction aggregator layer database and data aggregation queue . The client may receive a request to aggregate data manipulation requests in a single transaction. In response the transaction aggregator layer may open a data aggregation queue . The transaction aggregator layer may receive data manipulation requests to include in the single transaction and store the data manipulation requests in the data aggregation queue . After all of the data manipulation requests have been received the data aggregation queue may be closed . The transaction aggregator layer may determine that the database can successfully receive the single transaction. In some embodiments this may involve comparing a timestamp of the data manipulation request against a timestamp of the dependencies of the data manipulation request in the database. If a dependency timestamp is later than the data manipulation request the single transaction will fail. Otherwise the transaction aggregator layer locks the database relative to the scope of the transaction. The transaction aggregation layer may then commit and or execute the data manipulation requests in the data aggregation queue during a single transaction. After the transaction is complete the database may be unlocked .

In an alternative embodiment the transaction aggregator layer may not request the lock and simply attempt the transaction and rely on the database to determine whether the transaction succeeds or fails. If the transaction is successful other data aggregation queues may be scanned for conflicting data manipulation requests. If a data aggregation queue contains a conflicting data manipulation request that would fail a client providing the data manipulation request may be notified that the transaction would fail before attempting the transaction. This notification would provide a fail fast advantage in which a client need not attempt a transaction before being notified that the transaction would fail.

In the event that a client stops providing data manipulations to be stored in the data aggregation queue without closing the data aggregation queue and or requesting the corresponding transaction be performed the transaction aggregation layer may perform cleanup operations. In one embodiment the transaction aggregation layer may purge the stored data manipulations from a data aggregation queue after waiting for a period of time that exceeds a timeout value. Even though the data manipulations are purged the data within the database remains consistent. Other reasons for purging a data aggregation queue may include a fail fast notification conflicting data manipulations that would fail incorrect API calls too many failed API calls total idle time recent idle time or time between API calls.

Some or all of the process or any other processes described herein or variations and or combinations thereof may be performed under the control of one or more computer systems configured with executable instructions and may be implemented as code e.g. executable instructions one or more computer programs or one or more applications executing collectively on one or more processors by hardware or combinations thereof. The code may be stored on a computer readable storage medium for example in the form of a computer program comprising a plurality of instructions executable by one or more processors. The computer readable storage medium may be non transitory.

Turning now to an illustrative example of a process that may be used to aggregate data manipulation requests in a transaction through multiple requests is shown. The process may be accomplished by a system as seen in including a client transaction aggregator layer database and data aggregation queue . A transaction aggregator layer may receive a request to start aggregation such as a request to construct a single transaction. Based on the request the transaction aggregator layer may open a data aggregation queue . The transaction aggregator layer may receive an instruction. If the instruction is not a close instruction the instruction may include data manipulation requests which are received and stored in the data aggregation queue . The transaction aggregator layer may then await further instructions which may repeat operations to . Once all of the data manipulation requests for the transaction are stored the client may send a close instruction which is received by the transaction aggregator layer . As the message is a close instruction the transaction aggregator layer closes the data aggregation queue . The transaction aggregator layer determines whether the transaction can succeed by examining whether the data manipulation requests in the data aggregation queue have a conflict with other data manipulation requests in the queue or the database. If the conflicts are found the transaction cannot succeed and the transaction will be failed . If the transaction can succeed the transaction aggregation layer locks the database commits the data manipulation requests in the transaction to the database and then unlocks the database .

Turning now to an illustrative example of a process that may be used to aggregate data manipulation requests in a transaction with a fail fast configuration is shown. The process may be accomplished by a system as seen in including one or more clients a transaction aggregator layer a database data aggregation queues and a failure detection module . The transaction aggregator layer may receive a request to start aggregation such as an API call to open a new transaction. A queue matching the scope of request may be selected to prevent use of the queue by other clients that would also request a transaction on data within the scope represented by the data aggregation queue . If the queue is not ready the clients may wait for the queue. After the queue is ready the clients may send instructions . If a received instruction is not a close instruction data manipulation requests may be received stored and determined if the stored data manipulation requests have a conflict with other data manipulation requests or with changes to the database such as data dependencies. If the transaction cannot succeed the failure detection module may cause the transaction to fail based on the determined conflict in a fail fast way before the transaction is closed. If the transaction can still succeed the next instruction may be processed. If the instruction is a close instruction the data aggregation queue may be closed . As the transaction has been continually vetted by the failure detection module the transaction aggregation layer may lock the database commit the transaction containing the data manipulation requests and then unlock the database.

The client may also be billed for the services in use. For example a customer may be billed for the number of data manipulation requests contained in a transaction. The customer may also be billed for a granularity and or number of services provided. For example a customer may be billed more for a larger number of data aggregation queues providing a smaller scope than a larger number of queues that have a larger scope.

The illustrative environment includes at least one application server and a data store . It should be understood that there can be several application servers layers or other elements processes or components which may be chained or otherwise configured which can interact to perform tasks such as obtaining data from an appropriate data store. As used herein the term data store refers to any device or combination of devices capable of storing accessing and retrieving data which may include any combination and number of data servers databases data storage devices and data storage media in any standard distributed or clustered environment. The application server can include any appropriate hardware and software for integrating with the data store as needed to execute aspects of one or more applications for the client device handling a majority of the data access and business logic for an application. The application server provides access control services in cooperation with the data store and is able to generate content such as text graphics audio and or video to be transferred to the user which may be served to the user by the Web server in the form of HTML XML or another appropriate structured language in this example. The handling of all requests and responses as well as the delivery of content between the client device and the application server can be handled by the Web server. It should be understood that the Web and application servers are not required and are merely example components as structured code discussed herein can be executed on any appropriate device or host machine as discussed elsewhere herein.

The data store can include several separate data tables databases or other data storage mechanisms and media for storing data relating to a particular aspect. For example the data store illustrated includes mechanisms for storing production data and user information which can be used to serve content for the production side. The data store also is shown to include a mechanism for storing log data which can be used for reporting analysis or other such purposes. It should be understood that there can be many other aspects that may need to be stored in the data store such as for page image information and to access right information which can be stored in any of the above listed mechanisms as appropriate or in additional mechanisms in the data store . The data store is operable through logic associated therewith to receive instructions from the application server and obtain update or otherwise process data in response thereto. In one example a user might submit a search request for a certain type of item. In this case the data store might access the user information to verify the identity of the user and can access the catalog detail information to obtain information about items of that type. The information then can be returned to the user such as in a results listing on a Web page that the user is able to view via a browser on the user device . Information for a particular item of interest can be viewed in a dedicated page or window of the browser.

Each server typically will include an operating system that provides executable program instructions for the general administration and operation of that server and typically will include a computer readable storage medium e.g. a hard disk random access memory read only memory etc. storing instructions that when executed by a processor of the server allow the server to perform its intended functions. Suitable implementations for the operating system and general functionality of the servers are known or commercially available and are readily implemented by persons having ordinary skill in the art particularly in light of the disclosure herein.

The environment in one embodiment is a distributed computing environment utilizing several computer systems and components that are interconnected via communication links using one or more computer networks or direct connections. However it will be appreciated by those of ordinary skill in the art that such a system could operate equally well in a system having fewer or a greater number of components than are illustrated in . Thus the depiction of the system in should be taken as being illustrative in nature and not limiting to the scope of the disclosure.

The various embodiments further can be implemented in a wide variety of operating environments which in some cases can include one or more user computers computing devices or processing devices which can be used to operate any of a number of applications. User or client devices can include any of a number of general purpose personal computers such as desktop or laptop computers running a standard operating system as well as cellular wireless and handheld devices running mobile software and capable of supporting a number of networking and messaging protocols. Such a system also can include a number of workstations running any of a variety of commercially available operating systems and other known applications for purposes such as development and database management. These devices also can include other electronic devices such as dummy terminals thin clients gaming systems and other devices capable of communicating via a network.

Most embodiments utilize at least one network that would be familiar to those skilled in the art for supporting communications using any of a variety of commercially available protocols such as TCP IP OSI FTP UPnP NFS CIFS and AppleTalk. The network can be for example a local area network a wide area network a virtual private network the Internet an intranet an extranet a public switched telephone network an infrared network a wireless network and any combination thereof.

In embodiments utilizing a Web server the Web server can run any of a variety of server or mid tier applications including HTTP servers FTP servers CGI servers data servers Java servers and business application servers. The server s also may be capable of executing programs or scripts in response requests from user devices such as by executing one or more Web applications that may be implemented as one or more scripts or programs written in any programming language such as Java C C or C or any scripting language such as Perl Python or TCL as well as combinations thereof. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase and IBM .

The environment can include a variety of data stores and other memory and storage media as discussed above. These can reside in a variety of locations such as on a storage medium local to and or resident in one or more of the computers or remote from any or all of the computers across the network. In a particular set of embodiments the information may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers servers or other network devices may be stored locally and or remotely as appropriate. Where a system includes computerized devices each such device can include hardware elements that may be electrically coupled via a bus the elements including for example at least one central processing unit CPU at least one input device e.g. a mouse keyboard controller touch screen or keypad and at least one output device e.g. a display device printer or speaker . Such a system may also include one or more storage devices such as disk drives optical storage devices and solid state storage devices such as random access memory RAM or read only memory ROM as well as removable media devices memory cards flash cards etc.

Such devices also can include a computer readable storage media reader a communications device e.g. a modem a network card wireless or wired an infrared communication device etc. and working memory as described above. The computer readable storage media reader can be connected with or configured to receive a computer readable storage medium representing remote local fixed and or removable storage devices as well as storage media for temporarily and or more permanently containing storing transmitting and retrieving computer readable information. The system and various devices also typically will include a number of software applications modules services or other elements located within at least one working memory device including an operating system and application programs such as a client application or Web browser. It should be appreciated that alternate embodiments may have numerous variations from that described above. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code can include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the a system device. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. It will however be evident that various modifications and changes may be made thereunto without departing from the broader spirit and scope of the embodiments as set forth in the claims.

Other variations are within the spirit of the present disclosure. Thus while the disclosed techniques are susceptible to various modifications and alternative constructions certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood however that there is no intention to limit the scope of the claimed subject matter to the specific form or forms disclosed but on the contrary the intention is to cover all modifications alternative constructions and equivalents falling within the spirit and scope of the invention as defined in the appended claims.

The use of the terms a and an and the and similar referents in the context of describing the disclosed embodiments especially in the context of the following claims are to be construed to cover both the singular and the plural unless otherwise indicated herein or clearly contradicted by context. The terms comprising having including and containing are to be construed as open ended terms i.e. meaning including but not limited to unless otherwise noted. The term connected is to be construed as partly or wholly contained within attached to or joined together even if there is something intervening. Recitation of ranges of values herein are merely intended to serve as a shorthand method of referring individually to each separate value falling within the range unless otherwise indicated herein and each separate value is incorporated into the specification as if it were individually recited herein. All methods described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. The use of any and all examples or exemplary language e.g. such as provided herein is intended merely to better illuminate embodiments of the invention and does not pose a limitation on the scope of the invention unless otherwise claimed. No language in the specification should be construed as indicating any non claimed element as essential to the practice of the invention.

Preferred embodiments of this disclosure are described herein including the best mode known to the inventors for carrying out the invention. Variations of those preferred embodiments may become apparent to those of ordinary skill in the art upon reading the foregoing description. The inventors expect skilled artisans to employ such variations as appropriate and the inventors intend for the invention to be practiced otherwise than as specifically described herein. Accordingly this invention includes all modifications and equivalents of the subject matter recited in the claims appended hereto as permitted by applicable law. Moreover any combination of the above described elements in all possible variations thereof is encompassed by the invention unless otherwise indicated herein or otherwise clearly contradicted by context.

All references including publications patent applications and patents cited herein are hereby incorporated by reference to the same extent as if each reference were individually and specifically indicated to be incorporated by reference and were set forth in its entirety herein.

