---

title: Buffering mechanism for camera-based gesturing
abstract: A method can include buffering video data to a buffer that includes a buffer capacity that corresponds to a video time interval; sampling video data at a sampling rate of at least once per video time interval; processing the sampled video data for gesture evidence; and, responsive to gesture evidence in the sampled video data, processing the buffered video data for additional gesture evidence. Various other apparatuses, systems, methods, etc., are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09024958&OS=09024958&RS=09024958
owner: Lenovo (Singapore) Pte. Ltd.
number: 09024958
owner_city: Singapore
owner_country: SG
publication_date: 20120130
---
Gestures are used in many fields from bartering to transportation to music to computing. In bartering transportation and music gestures usually convey information directly from one human to another. In the field of computing a gesture may be part of a human machine command interface protocol etc. While gestures are often associated with bodily signs or movements regardless of the field a person may possibly make a gesture using a tool an instrument etc. As examples consider a conductor with a baton an air marshaller with lighted wands or a stock trader with a colored card.

In the field of computing gestures have also become associated with so called touch or multi touch sensors that require physical contact or close contact e.g. close EM field sensors with a generally flat sensing surface. As to non touch or non contact gestures a camera may be implemented along with associated circuitry to acquire stream and analyze video data for purposes of gesture detection. When compared to contact based systems non contact systems can provide some additional freedom for example by allowing a person to be some distance from a camera a computing system etc.

Where video data are relied upon for gesture detection such data may be streamed according to a particular format such as the Common Intermediate Format CIF H.261 standard which specifies a video resolution of 352 240 pixels width height with a frame rate of 30000 1001 about 30 fps and color encoding as YCbCr 4 2 0 a Video Graphics Array VGA format which specifies a resolution of 640 480 pixels width height and a frame rate of about 15 fps or other format. Whether video is streamed according to CIF VGA or other format such streaming and analysis of video data can place substantial demands on a computing system. Where such a computing system has only on off control for non contact gesturing performance may differ substantially between on and off states. Further in an off state it is not possible to turn the gesturing feature on by using a non contact gesture. Given such constraints a user may simply leave the gesturing feature in an on state and accept degraded performance or simply leave the gesturing feature in an off state and not use it.

As described herein various technologies techniques etc. can optionally provide for gesture detection with reduced resource demands which in turn may for example improve computing performance user experience etc.

A method can include buffering video data to a buffer that includes a buffer capacity that corresponds to a video time interval sampling video data at a sampling rate of at least once per video time interval processing the sampled video data for gesture evidence and responsive to gesture evidence in the sampled video data processing the buffered video data for additional gesture evidence. Various other apparatuses systems methods etc. are also disclosed.

The following description includes the best mode presently contemplated for practicing the described implementations. This description is not to be taken in a limiting sense but rather is made merely for the purpose of describing the general principles of the implementations. The scope of the described implementations should be ascertained with reference to the issued claims.

A buffering mechanism for camera based gesturing can include intermittent analysis of video data e.g. intermittent processing of video data . For example given a camera that can stream video data some amount of the video data may be buffered while also sampling and analyzing the video data one frame or a few frames at a time to determine if a user is performing a gesture. Based on the sampling and analyzing if it is determined that the user is performing a gesture then the buffered video data is analyzed e.g. processed using one or more processors . In such an example a video stream may be buffered in dedicated hardware at the camera or in main memory at the operating system level. As to an analysis of one or more intermittent frames e.g. at a rate of once per second or other suitable rate if such an analysis shows that the user is moving e.g. evidence of a gesture a trigger may be issued that calls for an analysis of the buffered video data for purposes of recognizing a gesture e.g. the gesture seen in the one or more intermittent frames . To implement such an approach a buffer size e.g. buffer capacity may be set to be long enough to hold all of possible gestures of a set of gestures and the intermittent sampling period should be short enough that the shortest allowable gesture will cause issuance of a trigger that calls for looking at the video data in the buffer. As described in various examples a buffer capacity may be determined based at least in part on a maximum gesture time or duration for a user which may be preset adjustable or learned by a user performing the gesture. As a user becomes more accustomed to gesturing gesture times may become shorter and for example approach a limit. A mechanism may be provided that allows for tracking gesture times of a user and optionally adjusting buffer capacity or one or more other parameters for gesture detection.

As to analysis of buffered video data as described herein the buffer may optionally be processed backwards from newest in time to oldest in time e.g. according to one or more setting options . In such an example processing circuitry may be provided that can recognize events performed in reverse . Reverse analysis can allow for shorter gestures to be recognized more quickly without having to play through an entire buffer which as mentioned may be set as being long enough to capture the longest gesture e.g. of a set of gestures . As to sampling a sampling mechanism may be configured to initiate mid gesture an increased frame rate e.g. full frame rate recognition engine. Such a sampling mechanism and recognition engine may be features of processing circuitry configured to receive video data via one or more interfaces. Where mid gesture triggering occurs e.g. at some time during a gesture such processing circuitry may be provided with one or more features to look back in time through the gesture e.g. as evidenced by buffered video data as well as staying current with new frames as they are provided by the camera e.g. real time video data .

Depending on video data format transfer technology processing technology etc. a system with a buffer and a sampling mechanism may be sufficient to detect all gestures in a set of gestures. For example where buffer data transfer and processing of transferred data are on the order of several hundred milliseconds or less given a sufficient sampling rate the buffered data may by itself be sufficient to keep pace with a person gesturing. A buffer data transfer time and a processing time for transferred data may be considered depending on device configuration blanking times or blackout times for processing e.g. where sampling does not occur noting that buffering may continue during such blanking times. For some perspective as to timings an input device such as mouse may have a double click time window of about 300 milliseconds which can be achieved by most people upon moving a finger a millimeter or so on a mouse button. As to hand gestures time windows for single hand or double hand gestures may be on the order of 500 milliseconds to a second or longer. Thus a blanking period of several hundred milliseconds as to sampling may have little impact on user experience.

As described herein a method can include buffering video data to a buffer that includes a buffer capacity that corresponds to a video time interval e.g. based at least in part on a number of video frames sampling video data at a sampling rate of at least once per video time interval processing the sampled video data for gesture evidence and responsive to gesture evidence in the sampled video data processing the buffered video data for additional gesture evidence. As mentioned such processing may occur directionally from newest video data to oldest video data.

As described herein a buffer may be a data structure configured as a circular buffer e.g. cyclic buffer ring buffer etc. defined at least in part by a parameter to provide a fixed size buffer as if it were connected end to end. In such an example the fixed size may be set or adjusted based on for example one or more factors such as a camera setting available memory gesture type gesture distance data transfer technique e.g. wired or wireless etc. A circular buffer may operate as a FIFO buffer noting that reading of data in the buffer may occur based on one or more pointers each of which may be incremented according to a forward reverse or other algorithm. As an example a circular buffer may operate according to three pointers one to the actual buffer in memory one to point to the start of valid data and one to point to the end of valid data. As an alternative example a circular buffer may be a fixed length buffer that includes two parameters e.g. integers to track indices e.g. for use with programming languages that do not include pointers .

A circular buffer may be implemented using a scheme that includes mapping the underlying buffer to two contiguous regions of virtual memory. In such a scheme reading from and writing to the circular buffer may then be carried out with greater efficiency by means of direct memory access e.g. those accesses which fall beyond the end of the first virtual memory region may automatically wrap around to the beginning of the underlying buffer . For example given such an implementation when the read offset is advanced into the second virtual memory region both offsets read and write are decremented by the length of the underlying buffer.

As described herein a system can include circuitry to buffer video data circuitry to sample video data circuitry to process sampled video data for gesture evidence circuitry to process buffered video data for gesture evidence and circuitry to assign gesture evidence in sampled video data and gesture evidence in buffered video data to a single gesture. Such a system may include a circular buffer that receives video data from the circuitry to buffer video data. A system may include a video camera or one or more interfaces e.g. wired wireless or wired and wireless for receipt of video data. As described herein circuitry to process buffered video data for gesture evidence can include circuitry that acts in response to gesture evidence in sampled video data. As described herein circuitry to sample video data can include a sampling resolution and circuitry to buffer video data can include a buffering resolution where for example the buffering resolution exceeds the sampling resolution. As described herein circuitry to sample video data can include a frame sampling rate and circuitry to buffer video data can include a frame buffering rate where for example the frame buffering rate exceeds the frame sampling rate.

As described herein one or more computer readable media e.g. non transitory media can include processor executable instructions to instruct a processor to buffer video data to a circular buffer sample video data at a sampling rate process sampled video data for evidence of a gesture process buffered video data for additional evidence of a gesture responsive to evidence of a gesture in the sampled video data and issue a command based at least in part on evidence of a gesture in the sampled video data and additional evidence of a gesture in the buffered video data. Such instructions may include instructions to instruct a processor to define a circular buffer based at least in part on a maximum gesture time instructions to instruct a processor to define a sampling rate based at least in part on a minimum gesture time instructions to instruct a processor to process buffered video data directionally toward older buffered video data etc.

The example of shows various processes that occur with respect to the blocks and . As the sample block can trigger the buffer block processes associated with the sample block are discussed prior to processes associated with the buffer block .

As indicated a process block processes one or more samples of the sample block . A decision block operates to decide if evidence of a gesture is present in one or more samples of video data. If the decision block decides that evidence is not present another sample may be taken upon return to the sample block . However if the decision block decides that evidence is present another decision block acts to decide if the evidence is sufficient as to warrant transferring of at least buffered video data e.g. which may act to help eliminate noise false positives etc. . If the decision block decides that the evidence is insufficient another sample may be taken upon return to the sample block . However if the decision block decides that the evidence is sufficient e.g. from one or more samples then a trigger block acts to trigger transfer of at least buffered video data. As actions stemming from such a trigger may increase demand on resources an optional blanking blackout or wait may be instituted per the wait block . For example a wait of several hundred milliseconds may be instituted during which sampling is halted processing of samples is halted etc. Such an approach may act to expedite processes such as triggering transferring and processing of buffered data which in turn can increase responsiveness to gesturing.

Referring to the buffer block a loop or interrupt may be provided in the form of a decision block that acts in response to a trigger signal per the trigger block . If no trigger signal is present or received the decision block continues with buffering per the buffer block . However if the decision block decides that transfer should occur per presence or receipt of a trigger signal then a transfer block follows that acts to transfer buffered video data for processing. The transfer block may operate according to one or more settings that provide for transferring the buffered video data for example in an order from newest in time to oldest in time see e.g. block . Upon transfer a process block processes the transferred buffered video data optionally in an order from newest in time to oldest in time see e.g. block . Order of processing may be determined by the transfer block the process block or a combination of both the transfer block and the process block e.g. transfer logic process logic or combined logic .

In the example of the process block may extract hand data using one or more video algorithms such as masking sharpening edge detection etc. For example a combination of algorithms may provide for extracting hand data from background data and tracking from frame to frame one or more edges or boundaries of the hand e.g. optionally using control points vectors etc. . Given such processing an assignment block may assign a gesture or gestures for example using information in a gesture database . In turn an issuance block may issue a command for example using a command database that relates gestures and commands.

In the example of the gesture database and the command database may be associated with a user an application a distance from a camera etc. For example consider a user using a slide presentation application where the gesture database provides long distance gestures and where the command database relates long distance gestures to appropriate commands to command the slide presentation application. As another example consider a user using a drawing application while seated before a camera. In such an example the gesture database provides short distance gestures and the command database relates short distance gestures to appropriate commands to command the drawing application. A method may provide for automatic switching between gesture sets and related commands e.g. based on user application distance etc. . For example where a user brings an application to the fore on a display projection screen etc. or otherwise activates an application an operating system signal may instruct gesturing circuitry to be configured for that application e.g. dynamic switching based on OS or other information .

The example of also shows an optional transfer of real time data on trigger from the acquisition block to the transfer block . Depending on various parameters resources timings etc. the method may benefit from transfer of real time data e.g. acquired camera data with delay less than about 100 ms . In such a scheme processing per the process block may occur for both buffered video data and real time video data. Further buffered video data may be processed in a backward in time direction while real time video data are processed in a forward in time direction. As to backward in time processing the process block can identify and chain evidence according to a reverse gesture. For example given the closed to open hand example in and reverse processing may identify an open hand and look backward in time through the buffered video data for a closed hand. In contrast forward processing may identify a closed hand and expect or look forward in time for an open hand e.g. in the transferred real time data . A method may include processing that appends or concatenate information e.g. gesture evidence from a reverse analysis of buffered video data and a forward analysis of real time video data to construct a gesture or string of gestures.

In the example of filled frames represent sampled frames that exhibit evidence of a gesture. However as shown it takes eight sampled frames before the evidence is sufficient to trigger transfer of buffered video data see e.g. crossed frame . Transferring and processing e.g. per blocks and of may cause a processing circuitry to be busy and unavailable for sampling and such constraints may influence selection or determination of buffer capacity. As mentioned a busy or wait period may be implemented for example to not interfere with transferring or processing and to thereby help expedite such processes. Where real time video data is also transferred such transferring may occur responsive to a trigger and optionally after a busy or wait period. In such an example sampling may be placed on hold e.g. temporarily disabled and then resumed responsive to insufficient evidence of gesturing in real time video data e.g. no evidence for a period of about 10 seconds .

In each of the sampled frames is shown as including some gesture evidence. The hand gesture examples are shown for purposes of explanation as the view of a camera may differ depending on its position with respect to a user s hand or hands. For example where a user is wearing a body camera e.g. head or chest the examples may be appropriate e.g. back of hand however where a camera is in front of the user the perspective would differ e.g. the video data would show the palm side of the user s hand . Instances may exist where multiple cameras are configured to acquire data a trigger may trigger transfer and analysis of a video data from a single buffer video data from multiple buffers real time transfer of video data from a single camera real time transfer of video data from multiple cameras etc.

In the example of evidence is labeled to which is processed per process blocks labeled to each of which may optionally control a respective adjustment block labeled to . Per the example of as evidence is gathered via sampling and processed a probability threshold may be reached to issue a trigger that initiates transfer of video data from a buffer to processing circuitry to piece together more complete evidence as to the nature of the gesture. In other words the processing of the process blocks to may be rudimentary compared to a process block for processing buffered video data. The process blocks to may simply look for evidence of a gesture without trying to assign the evidence to a specific gesture. In such an approach processing associated with sampling may occur rapidly without placing any significant demands on resources of a device. As described herein a standalone device optionally a device that includes a camera may include such sampling capabilities as well as buffering capability where for example upon issuance of a trigger transfer of buffered video data occurs via a serial interface or other interface to another device for processing. In such an approach resources of the other device are demanded on an as needed basis e.g. other than for example periodic bus monitoring that provides for appropriate responsiveness .

As an example consider a Frame Rate FR of 30 fps a Longest Gesture Time GT of 2 s a Recognition Time RT less than GT a Transfer Time TT of 200 ms a Processing Time PT of 100 ms such that the Buffer Capacity BC is a video time interval of 4.3 s e.g. 2 s 2 s 0.2 s 0.1 s 4.3 s or in terms of frames 129 frames e.g. 30 4.3 .

The sensor circuitry may include features such as a photodiode array with associated analog to digital control circuitry memory circuitry format circuitry exposure circuitry interface circuitry etc. The sensory circuitry may optionally include audio or other circuitry.

The sensor interface circuitry may include features such as a video processor an encode engine FIFO or other logic memory and a memory controller core one or more clocks and serial interface circuitry such as a USB core. In the example of memory of the sensor interface circuitry may be optionally configured as a circular buffer to buffer video data for purposes of gesturing. Further a video processor of the sensor interface circuitry may be optionally configured for sampling video data and processing sampled video data for evidence of a gesture or gestures and optionally configured for triggering transfer of buffered video data to another device via an interface e.g. a USB interface .

As shown in various devices e.g. a camera a smart phone a tablet a notebook etc. may include a lens and sensor circuitry and optionally sensor interface circuitry and optionally processing circuitry . As shown a stand alone camera may include sensor circuitry and sensor interface circuitry . Such a device may include a USB wired interface which may provide power to power its circuitry. Such a device may be optionally configured to buffer video data as well as sample and process sampled video data and to trigger transfer of buffered video data to another device for further processing e.g. for gesturing and issuing of one or more gesture based commands .

The processing circuitry may be configured to operate according to the Microsoft Windows Image Acquisition WIA application programming interface API and device driver interface DDI Microsoft Corporation Redmond Wash. . The WIA API allows applications to run in a process that is separate from the driver enumerate available image acquisition devices create simultaneous connections to multiple devices query properties of devices in a standard and extensible manner acquire device data by using standard and high performance transfer mechanisms and monitor a wide variety of device events.

The WIA technology provides for transfer of data from a device to another device e.g. from a camera and its associated circuitry to motherboard circuitry of a computer . As an example consider the following interface code associated with a data download from a device to the caller and cancelation of an operation 

In the WIA technology a IWiaTransfer Upload takes an IStream interface directly whereas IWiaTransfer Download takes a IWiaTransferCallback because IWiaTransfer Upload uploads a single item whereas IWiaTransfen Download can transfer multiple items.

The WIA technology includes various other features. For example the IWiaVideo interface provides methods that allow an application that uses Windows Image Acquisition WIA services to acquire still images from a streaming video device.

As another example of technology for handling video data consider the Microsoft DirectShow application programming interface API which is a media streaming architecture for the Microsoft Windows platform. Using DirectShow applications can perform high quality video and audio playback or capture. The DirectShow features provide a Stream Buffer Engine that enables an application to seek pause and record a live video stream without interrupting the stream. Transitions between live and recorded content can be achieved in a relatively seamless manner. The Stream Buffer Engine supports for example MPEG 2 video and digital video DV sources e.g. at capture rates up to 20 megabits per second Mbps .

As shown in any of a variety of devices can include processing circuitry . For example a smart phone a tablet a notebook a desktop or server a television or monitor etc. may include processing circuitry . Such devices may optionally include sensor circuitry sensor interface circuitry or both.

As to a television or monitor gesturing may allow for navigation of channels or other content e.g. via one or more gesture based navigation commands . For example for broadcast channels a channel menu may be invoked via a gesture and the menu navigated to select a channel whether for viewing purchase recording etc. As another example consider a movie or a show being displayed where a gesture may act to pause content rendering to fast forward content rendering to reverse content rendering etc. A device for camera based gesturing may optionally be provided in the form of a camera and associated circuitry that samples buffers processes and outputs commands to a set top box cable box computer etc. to control content e.g. scheduling purchase rendering recording etc. . Such a camera may be mountable to a television or monitor to acquire video data for a user for example seated a distance as far as several meters from the television or monitor.

The processing circuitry may provide features to perform the method . For example the processing circuitry may provide one or more interfaces for transferring data data processing capabilities data extraction capabilities learning algorithm capabilities and pattern matching capabilities for processing video data gesture information optionally application specific for assigning a gesture and commands related to gestures for issuing a command.

As to issuance of a command a table or other data structure may be provided with information that relates commands and gestures. In the example of the table includes commands and related close gestures and far gestures. In such an example the close gestures may be for a hand or hands in a distance of about 0.15 meter to about 3 meters from a camera lens and the far gestures may be for a hand or hands in a distance of about 3 meters to about 8 meters from a camera lens. As indicated a gesture may be the same or may differ depending on distance of a user s hand or hand from a camera lens. The processing circuitry may include memory to store information of the table an interface to access such information etc. for purposes of performing the processing assigning or issuing of the method .

The term circuit or circuitry is used in the summary description and or claims. As is well known in the art the term circuitry includes all levels of available integration e.g. from discrete logic circuits to the highest level of circuit integration such as VLSI and includes programmable logic components programmed to perform the functions of an embodiment as well as general purpose or special purpose processors programmed with instructions to perform those functions.

While various examples of circuits or circuitry have been discussed depicts a block diagram of an illustrative example of a computer system . The system may be a desktop computer system for example such as one of the ThinkCentre or ThinkPad series or IdeaPad series of personal computers sold by Lenovo US Inc. of Morrisville N.C. or a workstation computer such as the ThinkStation which are sold by Lenovo US Inc. of Morrisville N.C. however as apparent from the description herein a device may include other features or only some of the features of the system .

As shown in the system includes a so called chipset . A chipset refers to a group of integrated circuits or chips that are designed to work together. Chipsets are usually marketed as a single product e.g. consider chipsets marketed under the brands INTEL AMD etc. .

In the example of the chipset has a particular architecture which may vary to some extent depending on brand or manufacturer. The architecture of the chipset includes a core and memory control group and an I O controller hub that exchange information e.g. data signals commands etc. via for example a direct management interface or direct media interface DMI or a link controller . In the example of the DMI is a chip to chip interface sometimes referred to as being a link between a northbridge and a southbridge .

The core and memory control group include one or more processors e.g. single core or multi core and a memory controller hub that exchange information via a front side bus FSB . As described herein various components of the core and memory control group may be integrated onto a single processor die for example to make a chip that supplants the conventional northbridge style architecture.

The memory controller hub interfaces with memory . For example the memory controller hub may provide support for DDR SDRAM memory e.g. DDR DDR2 DDR3 etc. . In general the memory is a type of random access memory RAM . It is often referred to as system memory or main memory or primary memory .

The memory controller hub further includes a low voltage differential signaling interface LVDS . The LVDS may be a so called LVDS Display Interface LDI for support of a display device e.g. a CRT a flat panel a projector etc. . A block includes some examples of technologies that may be supported via the LVDS interface e.g. serial digital video HDMI DVI display port . The memory controller hub also includes one or more PCI express interfaces PCI E for example for support of discrete graphics . Discrete graphics using a PCI E interface has become an alternative approach to an accelerated graphics port AGP . For example the memory controller hub may include a 16 lane 16 PCI E port for an external PCI E based graphics card. A system may include AGP or PCI E for support of graphics. The system may include circuitry for wireless delivery of video e.g. WiFi circuitry .

The I O hub controller includes a variety of interfaces. The example of includes a SATA interface one or more PCI E interfaces optionally one or more legacy PCI interfaces one or more USB interfaces a LAN interface more generally a network interface a general purpose I O interface GPIO a low pin count LPC interface a power management interface a clock generator interface an audio interface e.g. for speakers a total cost of operation TCO interface a system management bus interface e.g. a multi master serial computer bus interface and a serial peripheral flash memory controller interface SPI Flash which in the example of includes BIOS and boot code . With respect to network connections the I O hub controller may include integrated gigabit Ethernet controller lines multiplexed with a PCI E interface port. Other network features may operate independent of a PCI E interface. One or more interfaces of the system may be suitable for receiving transmitting or receiving and transmitting information with a sensor such as an accelerometer e.g. to effectuate orientation or other control .

The interfaces of the I O hub controller provide for communication with various devices networks etc. For example the SATA interface provides for erasing reading and writing information on one or more drives such as HDDs SDDs or a combination thereof. The I O hub controller may also include an advanced host controller interface AHCI to support one or more drives . The PCI E interface allows for wireless connections to devices networks etc. The USB interface provides for input devices such as keyboards KB mice and various other devices e.g. circuitry camera devices phones storage media players etc. . As to cellular communication the system can include cellular circuitry . Such circuitry may be circuitry suitable for a cell phone or other device that communicates via one or more frequencies e.g. TDMA CDMA GSM etc. . The system may optionally include GPS circuitry for GPS communications and GPS functionality.

In the example of the LPC interface provides for use of one or more ASICs a trusted platform module TPM a super I O a firmware hub BIOS support as well as various types of memory such as ROM Flash and non volatile RAM NVRAM . With respect to the TPM this module may be in the form of a chip that can be used to authenticate software and hardware devices. For example a TPM may be capable of performing platform authentication and may be used to verify that a system seeking access is the expected system.

The system upon power on may be configured to execute boot code for the BIOS as stored within the SPI Flash and thereafter processes data under the control of one or more operating systems and application software e.g. stored in system memory . An operating system may be stored in any of a variety of locations and accessed for example according to instructions of the BIOS . Again as described herein a device or other machine may include fewer or more features than shown in the system of . For example the device of or other device see e.g. may include some or all of the features shown in the system .

Although various examples of methods devices systems etc. have been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as examples of forms of implementing the claimed methods devices systems etc.

