---

title: Selective prediction signal filtering
abstract: Disclosed herein are methods and apparatuses for selective prediction signal filtering. One aspect of the disclosed implementations is a method for encoding a frame of a video stream including determining a first performance measurement for a first set of prediction samples identified for a group of pixels using a first prediction mode, generating a filtered set of prediction samples by applying a filter to a second set of prediction samples, wherein at least one of the filtered set of prediction samples or the second set of prediction samples are identified using a second prediction mode, determining a second performance measurement for the filtered set of prediction samples, generating, using a processor, a residual based on the filtered set of prediction samples and the group of pixels if the second performance measurement exceeds the first performance measurement, and encoding the frame using the residual.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09344729&OS=09344729&RS=09344729
owner: GOOGLE INC.
number: 09344729
owner_city: Mountain View
owner_country: US
publication_date: 20120711
---
An increasing number of applications today make use of digital video for various purposes including for example remote business meetings via video conferencing high definition video entertainment video advertisements and sharing of user generated videos. As technology is evolving users have higher expectations for video quality and expect high resolution video even when transmitted over communications channels having limited bandwidth.

Disclosed herein are implementations of systems methods and apparatuses for selective prediction signal filtering.

An aspect of the disclosed implementations is a method for encoding a video signal having a frame. The method includes determining a first performance measurement for a first set of prediction samples identified for a group of pixels of the frame using a first prediction mode generating a filtered set of prediction samples for the group of pixels by applying a filter to a second set of prediction samples wherein at least one of the filtered set of prediction samples or the second set of prediction samples are identified using a second prediction mode determining a second performance measurement for the filtered set of prediction samples generating using a processor a residual based on the filtered set of prediction samples and the group of pixels if the second performance measurement exceeds the first performance measurement and encoding the frame using the residual.

An aspect of the disclosed implementations is an apparatus for encoding a video signal having a frame. The apparatus includes a memory and a processor configured to execute instructions stored in the at least one memory to determine a first performance measurement for a first set of prediction samples identified for a group of pixels of the frame using a first prediction mode generate a filtered set of prediction samples for the group of pixels by applying a filter to a second set of prediction samples wherein at least one of the filtered set of prediction samples or the second set of prediction samples are identified using a second prediction mode determine a second performance measurement for the filtered set of prediction samples generate a residual based on the filtered set of prediction samples and the group of pixels if the second performance measurement exceeds the first performance measurement and encode the frame using the residual.

An aspect of the disclosed implementations is a method for decoding an encoded video signal. The method includes decoding a prediction mode a filter indicator and a residual associated with a group of pixels of a frame of the encoded video signal identifying a set of prediction samples for decoding the group of pixels based on the prediction mode applying a filter to the identified set of prediction samples based on the filter indicator to generate a filtered set of prediction samples and generating a reconstructed group of pixels using the filtered set of prediction samples and the residual.

To permit transmission of digital video streams while limiting bandwidth consumption video encoding and decoding implementations can incorporate various compression schemes. These compression schemes generally break the image up into blocks and use one or more techniques to limit the amount of information included in a resulting compressed video bitstream for transmission. The bitstream once received is then decoded to re create the blocks and the source images from the limited information. Digital video can be encoded into video bitstreams using formats such as VPx H.264 MPEG MJPEG and or others.

Encoding a video stream or a portion thereof such as a frame or a block can include using temporal and spatial similarities in the video stream to improve coding efficiency. For example a current block of a video stream may be encoded based on a previously encoded block in the video stream by predicting motion and color information for the current block based on the previously encoded block and identifying a difference residual between the predicted values and the current block. Inter prediction can include using a previously encoded block from a previously encoded frame reference frame . Intra prediction can include using a previously encoded block from the current frame. Using the previously encoded block can include using less than all of the pixels of the previously encoded block to generate a prediction block. Intra prediction can be used for encoding for example a frame of video or individual images.

The type of prediction utilized for a block or frame can be identified by a prediction mode which can be encoded into the compressed video bitstream to enable decoding. For example intra prediction can include predicting values for a current block based on values of spatially proximate previously encoded blocks in the current frame which can be identified using one or more intra prediction modes such as horizontal prediction H PRED vertical prediction V PRED DC prediction DC PRED or TrueMotion prediction TM PRED . For example inter prediction can include predicting values of a current block based on values of a reference block from a previously decoded frame or a reference frame that can be identified by a motion vector using one or more inter prediction modes such as the use of neighboring motion vectors MV NEAR or MV NEAREST differentially encoded motion vectors NEWMV sub block motion vectors SPLITMV and reference frame identifier e.g. last frame golden frame alternate reference frame .

Many prediction techniques use block based prediction and quantized block transforms. The use of block based prediction and quantized block transforms can give rise to picture quality degradation visual artifacts and discontinuities along block boundaries during encoding. These degradations artifacts and discontinuities can be visually disturbing and can reduce the quality of the decoded video and the effectiveness of the reference frame used as a predictor for subsequent frames. These degradations artifacts and discontinuities can be reduced by the application of selective prediction signal filtering performance measurement for loop filtering or both.

Selective prediction signal filtering can include generating a performance measurement for an encoding of a group of pixels using various prediction mode and filter combinations. The group of pixels can be for example a segment macroblock subblock block or individual pixel of a frame. Performance measurements can include for example a rate distortion measurement sum of squared differences measurement or any available error metric rate metric or combination thereof. Performance measurements can be made for a prediction mode with filtering and without filtering. In an implementation a prediction mode can be defined to include filtering or not include filtering. Filtering can include applying a Finite Impulse Response FIR filter in the horizontal and vertical directions to pixels in the group of pixels. In an implementation filtering can include the use of other filters or filters applied in other directions. In an implementation some pixels of the group of pixels may not be filtered based on pixel values to be used for filtering and threshold values defined for use with the filter being used. Performance measurements can be made for a single filter per prediction mode or multiple potential filters e.g. filter type and or filter strength per prediction mode.

A prediction mode and filter can be selected for encoding the group of pixels based on the performance measurement by for example selecting a prediction mode and filter having a smallest rate distortion selecting a filter can include not applying a filter . The selected prediction mode and filter can be used to identify prediction samples used to generate a residual of the group of pixels for encoding. The encoding can include data indicative of the selected prediction mode and filter. A decoder can decode the encoding by for example identifying prediction samples for decoding using the selected prediction mode and by using the selected filter or absence thereof .

Performance measurement for loop filtering can include generating performance measurements for a reconstruction of a group of pixels using various filter type and strength combinations. For example available filter type and strengths can be applied to the group of pixels and a rate distortion measurement can be generated for each application. The resulting rate distortion measurements can be compared and a filter type and strength having a lowest rate distortion measurement can be selected. The selected filter type and strength can be used to filter pixels in the reconstruction of the group of pixels. The selected filter type and strength can be included in the encoding of the group of pixels so that a decoder when decoding the encoding can apply the selected filter type and strength to the reconstruction of the group of pixels generated by the decoder.

A network connects the transmitting station and a receiving station . Specifically a video stream can be encoded in the transmitting station and the encoded video stream can be decoded in the receiving station . The network can for example be the Internet. The network can also be a local area network LAN wide area network WAN virtual private network VPN or any other means of transferring the video stream from the transmitting station .

The receiving station in one example can be a computer having an internal configuration of hardware such as that described in . Other suitable implementations of the receiving station are possible. For example the processing of the receiving station can be distributed among multiple devices.

Other implementations of the encoder and decoder system are possible. In an implementation additional components can be added to the encoder and decoder system . For example a second receiving station can be added. In an implementation components can be removed from the encoder and decoder system . For example the receiving station and or network can be omitted and the techniques and processes described herein or a subset thereof can be implemented using station .

The CPU in stations can be a conventional central processing unit. Alternatively the CPU can be any other type of device or multiple devices capable of manipulating or processing information now existing or hereafter developed. Although the disclosed embodiments can be practiced with a single processor as shown e.g. CPU advantages in speed and efficiency can be achieved using more than one processor.

The memory in stations can be a random access memory device RAM . Any other suitable type of storage device can be used as the memory . The memory can include code and data that is accessed by the CPU using a bus . The memory can further include an operating system and application programs the application programs including programs that permit the CPU to perform the methods described here. For example the application programs can include applications through N which further include a video communication application that can perform the methods described here. Stations can also include a secondary storage which can for example be a memory card used with a mobile computing device. Because video communication can contain a significant amount of information they can be stored in whole or in part in the secondary storage and loaded into the memory as needed for processing.

Stations can also include one or more output devices such as display which can be a touch sensitive display that combines a display with a touch sensitive element that is operable to sense touch inputs. The display can be coupled to the CPU via the bus . Other output devices that permit a user to program or otherwise use stations can be provided in addition to or as an alternative to the display . When the output device is or includes a display the display can be implemented in various ways including by a liquid crystal display LCD or a cathode ray tube CRT or light emitting diode LED display such as an OLED display.

Stations can also include or be in communication with an image sensing device for example a camera or any other image sensing device now existing or hereafter developed. The image sensing device can be configured to receive images for example of the face of a device user while the device user is operating one of stations .

Although depicts the CPU and the memory of stations as being integrated into a single unit other configurations can be utilized. The operations of the CPU can be distributed across multiple machines each machine having one or more of processors which can be coupled directly or across a local area or other network. The memory can be distributed across multiple machines such as network based memory or memory in multiple machines performing the operations of stations . Although depicted here as a single bus the bus of stations can be composed of multiple buses. Further the secondary storage can be directly coupled to the other components of stations or can be accessed via a network and can comprise a single integrated unit such as a memory card or multiple units such as multiple memory cards. Stations can thus be implemented in a wide variety of configurations.

Encoder encodes an input video stream e.g. video stream . Encoder has the following stages to perform the various functions in a forward path shown by the solid connection lines to produce an encoded or a compressed bitstream an intra inter prediction stage a transform stage a quantization stage and an entropy encoding stage . Encoder also includes a reconstruction path shown by the dotted connection lines to reconstruct a frame for encoding of further blocks. Encoder can include the following stages to perform the various functions in the reconstruction path a dequantization stage an inverse transform stage a reconstruction stage and a loop filtering stage . Other variations of encoder can be used to encode the input video stream .

When the input video stream is presented for encoding a frame e.g. frame within the input video stream can be processed full frame by units of macroblocks or by any other segment of pixels in the frame. At the intra inter prediction stage blocks can be encoded using intra frame prediction within a single frame or inter frame prediction from frame to frame . In either case a prediction block can be formed. In the case of intra prediction a prediction block can be formed from prediction samples in the current frame that have been previously encoded and reconstructed. In the case of inter prediction a prediction block can be formed from prediction samples in one or more previously constructed reference frames.

Intra inter prediction stage can include a selective prediction signal filtering stage . For example in an implementation a prediction block can be formed from prediction samples that are filtered using a filter. Exemplary implementations of prediction signal filtering that can be incorporated into stage such as technique are described later with respect to .

Next still referring to the prediction block can be subtracted from the current block at the intra inter prediction stage to produce a residual block residual . The transform stage transforms the residual into transform coefficients in for example the frequency domain. Examples of block based transforms include the Karhunen Lo ve Transform KLT the Discrete Cosine Transform DCT and the Singular Value Decomposition Transform SVD . In one example the DCT transforms the block into the frequency domain. In the case of DCT the transform coefficient values are based on spatial frequency with the lowest frequency DC coefficient at the top left of the matrix and the highest frequency coefficient at the bottom right of the matrix.

The quantization stage converts the transform coefficients into discrete quantum values which are referred to as quantized transform coefficients or quantization levels. The quantized transform coefficients are then entropy encoded by the entropy encoding stage . Entropy encoding can include the use of various techniques such as formatting compressed bitstream using run length encoding RLE and zero run coding. The entropy encoded coefficients together with the information used to decode the block such as the type of prediction used motion vectors and quantizer value are then output to the compressed bitstream .

The reconstruction path in shown by the dotted connection lines can be used to ensure that both the encoder and decoder described below use the same reference frames to decode the compressed bitstream . The reconstruction path performs functions that are similar to functions that take place during the decoding process that are discussed in more detail below including dequantizing the quantized transform coefficients at the dequantization stage and inverse transforming the dequantized transform coefficients at the inverse transform stage to produce a derivative residual block derivative residual . At the reconstruction stage the prediction block that was predicted at the intra inter prediction stage can be added to the derivative residual to create a reconstructed block. The loop filtering stage can be applied to the reconstructed block to reduce distortion such as blocking artifacts.

An implementation of encoder can include a group of filters F Fn. In an implementation compression can be optimized by filtering a set of pixels such as a block of pixels in a given frame in the reconstruction path with filters F Fn or filters F Fn and default filter Fs which may be a sharpening filter or other suitable default filter. In an implementation the group of filters can be utilized in intra inter prediction stage using selective prediction signal filtering stage . In various implementations filtering can be used in the reconstruction loop intra inter prediction stage or both. In an implementation selective prediction signal filtering stage can be included in intra inter prediction stage and application of the group of filters can be omitted from the reconstruction path e.g. performance measurement stage and or loop filtering stage can be omitted from encoder so that the unfiltered data can be retained as an alternative predictor for current or future blocks.

Compressed bitstream may include frames that contain residual blocks. Because prediction blocks are subtracted from current blocks at intra inter prediction stage to form residual blocks residual blocks can improve compression by reducing the number of bits used to represent frames in compressed bitstream . One way to reduce an amount of bits needed to represent the residual blocks is to improve the accuracy of prediction at the intra inter prediction stage .

For example in an implementation the accuracy of prediction at stage can be improved by a performance measurement stage that can select between multiple filter settings for a given set of pixels at loop filter depending on the characteristics of the set of pixels. In addition to improving accuracy selecting between multiple filter settings can also improve compression. For example performance measurement stage can compare a performance measurement of a given macroblock after provisional application of a filter with a performance measurement of that same macroblock prior to any filtration. The performance measurement may indicate quality error compression characteristics or a metric that takes into account quality error and compression characteristics. Based on the results of such a comparison encoder may select zero one or multiple filters from the group of filters F Fn to be used for loop filtering at stage . Encoder can select only the filters from F Fn that result in an improved performance measurement that exceeds the initial performance measurement for a particular block.

An improved performance measurement exceeds an initial performance measurement if its value is closer to a desired result. A desired result is typically a result in which a video signal is transmitted with higher quality or lower bandwidth or with greater reliability. Depending on the performance measurement a measurement that exceeds another measurement could be numerically higher or lower than the other measurement. A performance measurement can be any metric used to indicate characteristics for a set of pixels. Rate distortion for example is a metric that is a function of both error rate and coding efficiency. Customizing filtration on a macroblock by macroblock basis based on a performance measurement can result in a more robust and accurate prediction at intra inter prediction stage . These and other implementations are described herein with respect to .

Other variations of encoder can be used to encode the compressed bitstream . For example a non transform based encoder can quantize the residual signal directly without the transform stage . Various forms of error testing error correction and filtering can be implemented in the reconstruction loop. In an implementation performance measurement stage can be omitted and or can be incorporated into loop filtering stage . In an implementation an encoder can have the quantization stage and the dequantization stage combined into a single stage.

The encoding process shown in can include two iterations or passes of processing the video data. The first pass can be carried out by encoder using an encoding process that is less computationally intensive which gathers and stores information about input video stream for use in the second pass. In the second pass encoder can use this information to optimize final encoding of compressed bitstream . For example encoder may use this information to select parameters for encoding locating key frames selecting coding modes used to encode macroblocks such as blocks and allocating the number of bits to each frame. The output of the second pass can be final compressed bitstream .

Decoder similar to the reconstruction path of encoder discussed above includes in one example the following stages to perform various functions to produce an output video stream from a compressed bitstream e.g. compressed bitstream an entropy decoding stage a dequantization stage an inverse transform stage an intra inter prediction stage a reconstruction stage a loop filtering stage and a deblocking filtering stage . Other variations of decoder can be used to decode the compressed bitstream .

When the compressed bitstream is presented for decoding the data elements within the compressed bitstream can be decoded by the entropy decoding stage using for example Context Adaptive Binary Arithmetic Decoding to produce a set of quantized transform coefficients. The dequantization stage dequantizes the quantized transform coefficients and the inverse transform stage inverse transforms the dequantized transform coefficients to produce a derivative residual. Using header information decoded from the compressed bitstream decoder can use the intra inter prediction stage to create a prediction block. At the reconstruction stage the prediction block can be added to the derivative residual to create a reconstructed block. The loop filtering stage can be applied to the reconstructed block to reduce blocking artifacts. The deblocking filtering stage can be applied to the reconstructed block to reduce blocking distortion and the result is output as the output video stream .

Other variations of decoder can be used to decode the compressed bitstream . For example decoder can produce the output video stream without the deblocking filtering stage . Furthermore for a decoder that decodes a bitstream sent from encoder as shown in the decoder can include thresholding error testing and selectable loop filtering in the feedback loop to intra inter prediction stage to create the same reconstructed macroblock that was created at encoder . Decoder can also include filtering in inter intra prediction stage .

In an implementation selecting a subset of pixels taking a performance measurement of that subset and selecting filters for loop filtration can occur according to the flowchart of a technique for performance measurement shown in . Technique can be carried out for example by CPU executing instructions stored in memory of transmitting station or receiving station . Technique or aspects thereof can be incorporated for example into performance measurement stage or intra inter prediction stage of encoder .

At step a set of pixels are selected. The set of selected pixels and can be an entire frame of pixels a macroblock of pixels or any other segment or number of pixels derived from a reconstructed frame assembled at reconstruction stage . One example of an image segment or set of pixels is a macroblock of pixels depicted in . At step the reconstructed image segment or set of pixels is measured for an initial performance measurement. The initial performance measurement measures some indicator of quality or error such as differences between an original set of pixels as constituted prior to encoding and the reconstructed version of the original set of pixels at reconstruction stage . During encoding transform stage and quantization stage can create errors between a frame in input video stream and the reconstructed version of that same frame at reconstruction stage . An initial performance measurement may measure these errors or other errors related to a reconstructed frame. The performance measurement itself can be a sum of squares error a mean squared error or various other suitable measurements of error. The initial performance measurement can also be a calculation such as rate distortion which takes into account an error measurement as well as coding efficiency.

Once an initial performance measurement has been determined for a particular set of pixels at step the performance measurement for that set of pixels is stored. For example at step a variable here called base best rd is initialized to the initial performance measurement for the set of pixels selected at step . Once the variable base best rd has been initialized the first filter denoted by variable n is selected at step . As depicted in each time a filter n is selected process shown by a dashed line box is engaged. When process is complete step determines if all of the n filters have been selected. If all of the n filters have not been selected step increments n and selects the next filter. If all of the n filters have been selected step determines if there are any additional macroblocks that must undergo the process depicted in . If any of the k macroblocks remain step increments k and selects the next macroblock. If no macroblocks remain at step the results of process are implemented at loop filter .

Within process the filter selected at step is applied to the particular set of pixels selected at step . At step the filter n is applied to macroblock k where filter n engages each pixel in macroblock k according to for example technique as shown in . During technique each pixel in the set of pixels in macroblock k is analyzed in a predetermined order such as for example raster scan order or any other suitable order. When a pixel is engaged at step that pixel can be considered a target pixel. Data is retrieved from pixels in the region of the target pixel to make a determination or calculation with respect to a given target pixel. Specifically data from a filter dependent region of pixels surrounding a target pixel is collected. For example each pixel in the filter dependent region of pixels contains data related to how each pixel will appear when displayed such as luma or chroma data represented by a number as depicted in . Based on this data technique determines if the target pixel should be filtered or bypassed without filtration at step . Process is only an exemplary embodiment.

Referring to how threshold determinations are made the determination at step is made by comparing data from the filter dependent region of pixels surrounding a target pixel and comparing that data with a threshold or strength setting. The terms threshold and strength setting may be used interchangeably. Each filter F Fn may use a different type of threshold criteria. For example step may average all pixels in the filter dependent region of pixels to determine if they differ in value from the target pixel by less than a threshold value. Step may select filters that fall above or below a particular threshold criteria. In another exemplary embodiment step may indicate filter F should be applied to a given pixel if the statistical variance of the pixels in the filter dependent region is below a threshold value. The statistical variance threshold criteria may be less computationally intensive than the target pixel differential approach as fewer computations per pixel are required. Accordingly the statistical variance approach may be used for filters with a large amount of taps such as long blur filters.

Once a threshold determination is made at step process will either filter the target pixel at step or pass through the target pixel without filtration at step . In either case the next step is to move to the next pixel at step . In some embodiments this process will continue until all pixels in the set of pixels selected at step have received a threshold determination for the filter selected at step .

By way of example filter F may be a one dimensional filter such as a one dimensional finite impulse response FIR filter with 3 taps and weights of 1 3 1 designed to be applied in the horizontal and vertical directions about a target pixel for example as shown in . Because of the properties of exemplary filter F the filter dependent region of pixels forms a cross section of pixels including a row of 3 pixels centered at target pixel and a column of 3 pixels centered at target pixel . When an n tap filter is one dimensional and is designed to be applied in the horizontal and vertical directions the filter dependent region will contain 2 n pixels and will form a cross section centered at the target pixel as shown in .

Additionally filter F may be a one dimensional FIR filter with 5 taps and weights of 1 1 4 1 1 designed to be applied in horizontal and vertical directions to a target pixel for example as shown in . Filters F Fn can also be two dimensional square filters that form a block of pixels about a target pixel or any other type of filter. Each filter selection can have design advantages and disadvantages. For example a threshold determination for a two dimensional filter will require more calculations than a one dimensional filter applied in the horizontal and vertical directions because the filter dependent region of pixels is larger. Filters F Fn may contain various other types of filters such as one or two dimensional filters sharpening filters blurring filters linear filters edge detecting filters Gaussian filters Laplacian filters embossing filters edge sharpening filters or any other image processing filters with any number of taps or weights. In one exemplary embodiment filters F Fn include one dimensional FIR filters with taps and weights of 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 4 1 1 and 1 3 1 . In one exemplary embodiment the 1 3 1 filter is a default sharpening filter that is applied to all pixels in a set of pixels such as a macroblock of pixels at step without determining whether each pixel in the set of pixels should be filtered or passed through without filtration at step .

In addition to the fact that each filter in F Fn may have a different threshold criteria process in can also alter the threshold value for each filter selected at step so that a given filter is provisionally applied to a given set of pixels at multiple threshold values. For example filter F may use statistical variance as its threshold criteria. Filter F may also have several different statistical variance values or strength settings each of which is applied to the given set of pixels at step . Specifically once a first threshold value or strength setting is used at step and the set of pixels undergo a second performance measurement at step a new threshold value or strength setting is received at step . Each filter may have any number of strength settings. The process of determining and applying new strength settings may repeat until all strength settings have been measured for performance. Alternatively process may discontinue the process of receiving new strength settings if for example rate distortion measurements at step indicate worsening rate distortion measurements for a predetermined number of measurements.

In origin 3 corresponds to target pixel i in step . In one embodiment for example if it is determined that any of the values 42 46 55 or 56 differ from the center pixel by less than a predetermined threshold at step the target pixel with a value of 60 will be filtered. If the values are more than a predetermined threshold the pixel will pass through the filter without filtration. Accordingly depending on the strength setting determined at step the number of pixels actually filtered in a given set of pixels for a given filter will change. Strength setting alteration step may increase or decrease the strength setting or threshold value by a predetermined amount. To filter a target pixel a convolution or correlation can be performed between the kernel and the filter dependent region of pixels surrounding the target pixel . Convolutions and correlations calculate a weighted average of all the pixels in the filter dependent region . The resulting weighted average is used to replace the original target pixel value. As a result the target pixel value is altered or filtered based on the pixels in the filter dependent region surrounding it.

Once a threshold determination has been made for all pixels in the set of pixels such that each pixel has either been filtered at step or passed through at step a second performance measurement can be taken such as rate distortion for the set of pixels at step . At step it is determined whether the second performance measurement from step is less than the initial performance measurement determined at step . If the second performance measurement after filtration at is less than the initial performance measurement variable best rd is updated with the new second performance measurement information. Furthermore for each filter entering process the filters can be measured for performance for each of any number of strength settings determined at step as discussed previously. Although process depicts an implementation where a performance rate distortion measurement is used other performance measurements can be used.

In an implementation each time a strength setting results in a performance measurement that exceeds previous measurements the best rd variable is updated at step and the current filter n and filter strength i is saved at step . Once the filters for all pixels in the set of pixels has gone through process as indicated by step information associated with the filter n and strength i having the best performance measurement can be forwarded to loop filter stage at step . At loop filter stage pixels can be filtered using the filter and filter strength forwarded by performance measuring stage at a strength setting indicated by performance measuring stage .

The current filter n and filter strength i can be stored for transmission to be used at decoder to recreate the same reconstructed and filtered image segment that was created at encoder . It should also be noted that in order to properly decode frames created at encoder decoder should implement a similar decoding path as the reconstruction path implemented by encoder .

The above description of technique describes some exemplary implementations of performance measurement and loop filtration and other implementations of technique are available including those that include additional stages remove certain stages modify certain stages split certain stages and or combine certain stages. In an implementation stage can be moved to be between stages and so that filter n and strength i is applied on a per macroblock k basis.

In an implementation technique can be adjusted to identify more than one filter and filter strength. For example a filter n evaluated by process can incorporate the use of two or more filters in sequence. In another example process can be altered to select a filter and then select one or more additional filters based on performance measurements of the additional filters based on an application of that filter to pixel values filtered by the selected filter. Accordingly depending on results from stage each set of pixels or macroblock in frame can have between zero and n filters implemented at loop filter stage .

At stage a current mode X can be selected from available prediction modes. Available prediction modes for technique can include all prediction modes included in encoder or a subset thereof. For example in various implementations available prediction modes can include one of all inter prediction modes all intra prediction modes or both.

At stage a performance measurement e.g. rate distortion for the current mode X without filtering RD is determined. To determine the performance metric the current mode X can be used to identify prediction samples for predicting the current block comparing the prediction samples to the current block and determining the metric using the comparison. The identified prediction samples are not filtered at stage . In an implementation determining the performance metric can include considering a number of bits needed to encode indications of mode X and the filter selection e.g. FILTER 0 into the encoded bitstream. The performance measurement RDis compared to the best rate distortion value RDat stage . If RDis less than RD control passes to stage .

At stage the best identified mode MODE is set to the current mode X the best rate distortion value RD is set to RD and the filter state FILTER is set to 0. After stage control passes to stage . Alternatively if RDis greater or equal than RD control passes to stage from stage .

At stage a performance measurement e.g. rate distortion for the current mode X with filtering RD is determined. To determine the performance metric the current mode X can be used to identify prediction samples for predicting the current block. The identified prediction samples can then be filtered for example by using a pre determined filter. The filtering of the prediction samples can in addition or alternatively use techniques such as adaptations of those described with respect to D and or . The filtered prediction samples can be compared to the current block and the performance metric can be determined using the comparison. In an implementation determining the performance metric can include considering a number of bits needed to encode indications of mode X and the filter selection e.g. FILTER 1 into the encoded bitstream.

The performance measurement RDis compared to the best rate distortion value RDat stage . If RDis less than RD control passes to stage . At stage the best identified mode MODE is set to the current mode X the best rate distortion value RD is set to RD and the filter state FILTER is set to 1. After stage control passes to stage . Alternatively if RDis greater or equal than RD control passes to stage from stage .

At stage a determination is made as to whether all available prediction modes have been tested e.g. whether each available prediction mode has been processed through stages to . If not all available prediction modes have been tested control passes to stage where a new current mode X is selected from remaining available prediction modes. Otherwise control passes to stage where a residual is determined using the MODEand FILTER settings determined by technique . In other words a residual is generated using the combination of mode and filter that produces a smallest e.g. best performance measurement e.g. rate distortion .

Following stage not shown MODEand FILTER can be encoded into the compressed bitstream along with the generated residual for example by use of probability encoding techniques by entropy encoding stage . For example FILTER can be entropy encoded using a binary flag or a tri state flag. In an implementation using a binary flag a flag e.g. FILTER can be encoded for each block e.g. using a BoolCoder based on a encoding probability pred filter prob that is generated for example based on a count of number of blocks where the filter is disabled pred filter off count and a number of blocks where the filter is enabled pred filter on count such as shown with respect to equation 1 

The value of pred filter prob can be encoded into the compressed bitstream at the frame level and can be used to probabilistically encode the binary flag FILTER for each block within the frame. In an implementation pred filter prob can be encoded as an 8 bit literal value using less than 8 bits based on a modeling algorithm using a differential with a pred filter prob value encoded for a previous frame or a combination thereof.

In an implementation using a tri state flag a mode can be encoded at the frame level e.g. by entropy encoding stage using probability encoding techniques such as BoolCoder and can indicate for example whether filtering should be enabled for the entire frame 0 disabled for the entire frame 1 or signaled at a per macroblock level 2 . If the per macroblock level 2 mode is utilized the binary flag technique described above can be used to encode a binary flag for each macroblock. In a one pass encoder the pred filter prob for a previous frame can be utilized instead of the pred filter prob for the current frame since the value for the current frame can be determined once the entire frame is processed.

The above description of technique describes some exemplary implementations of selective prediction signal processing and other implementations of technique are available including those that include additional stages remove certain stages modify certain stages split certain stages and or combine certain stages. A number of alternative implementations are possible including but not limited to the use of one or more of the additional and or alternative techniques described below.

In an implementation the available prediction modes for encoding can include one or more intra prediction modes. Prediction samples can be identified using an intra prediction mode and can optionally be filtered once identified. Alternatively or additionally the intra prediction mode can identify prediction samples based on pixels that are filtered before the prediction samples are identified. In an example blocks of pixels above and to the left of a current block being encoded can be filtered before prediction samples are identified.

In an implementation more than one filter e.g. filter type and or filter strength can be considered in conjunction with available prediction modes. For example an optimized filter can be identified for each prediction mode multiple filters can be identified for at least some prediction modes multiple filters can be identified without respect to prediction mode or a combination thereof. Some prediction modes can have one or more associated filter based on for example the suitability of the associated filters for use with their respective prediction modes. Available filters can include high pass low pass thresholded separable or non separable filters. For example a thresholded filter can be configured to filter a pixel only if the pixel to be filtered has adjoining pixels that have similar characteristics in an effort to preserve edges within the frame.

In the event that multiple filters are considered an indication of the type and or strength of filter used can be encoded into the compressed bitstream to enable a decoder to apply the same filter and strength during decoding e.g. in addition to or instead of the FILTER flag . Thus a filter indicator can include a binary flag e.g. FILTER a tri state flag an indication of filter type and or strength or a combination thereof.

In an implementation available prediction modes can be defined to include a determination of whether filtering is to be performed. In other words the filter indicator can be included within the prediction mode e.g. defined based on the prediction mode .

In an implementation the available prediction modes for encoding can include one or more inter prediction modes. Inter prediction can include performing a candidate search for a reference block e.g. prediction samples and the identification of the reference block can include considering unfiltered candidate search locations filtered candidate search locations or a combination thereof. The resulting reference block can therefore be identified based on pre filtered candidate search locations candidate search locations without pre filtering or a combination thereof. The use of pre filtered candidate search locations can be used in addition to or instead of filtering identified prediction samples.

In an implementation the use of selective prediction signal processing can be used in lieu of sub pixel motion compensation. Sub pixel motion compensation can include filtering candidate reference blocks to estimate virtual pixel values at locations between pixels. Selective prediction signal processing can provide a similar benefit as sub pixel motion compensation and thus can be used instead of sub pixel motion compensation to improve efficiency of encoding.

In an implementation the use of selective prediction signal processing can be used in lieu of Average Reference frame Noise Reduction ARNR filtering or in combination with a reduced level of ARNR filtering. ARNR filtering can include calculating an average of pixel values over a number of frames e.g. 20 successive frames . ARNR filtering can provide an alternative reference frame with reduced noise to be used for inter prediction. Selective prediction signal processing can provide similar benefits as ARNR filtering. Reduced ARNR filtering can include reducing a number of frames used to generate ARNR filtering.

In an implementation a filter strength and or type selected for an inter prediction mode can be determined based on a motion vector selected for the inter prediction mode. The filter strength and or type can be based on a magnitude of the motion vector. For example a stronger filter strength can be used for larger motion vector magnitudes and a weaker filter strength can be used for smaller motion vector magnitudes. As another example a motion blur filter can be selected for larger motion vector magnitudes to compensate for blurring and a weak filter can be selected for smaller motion vector magnitudes to preserve detail. The filter strength and or type can also be based on a direction of the motion vector. For example a blur filter can be applied in the direction of the motion vector to compensate for blurring occurring in the direction of movement.

In an implementation a filter indicator can be entropy encoded into the compressed bitstream using contextual techniques. For example a filter indicator for a block can be encoded based on the filter indicator for adjoining blocks such as the blocks above and to the left of the block. These and other implementations of technique are possible including variations and combinations of the various implementations described herein.

At stage prediction samples are identified using the decoded prediction mode. For example the prediction mode can be an inter prediction mode and the decoded prediction mode can include a motion vector identifying a reference block having the prediction samples to be used for decoding. At stage a determination is made whether FILTER 1. If FILTER 1 the identified prediction samples are filtered at stage . Next and also if FILTER 0 control passes to stage where the block is reconstructed using the prediction samples or filtered prediction samples and the decoded residual.

The above description of technique describes some exemplary implementations of decoding a compressed bitstream encoded using selective prediction signal processing. Other implementations of technique are available including those that include additional stages remove certain stages modify certain stages split certain stages and or combine certain stages. A number of alternative implementations are possible including but not limited to the use of techniques capable of decoding a bitstream encoded using alternative implementations of technique such as those described above. For example the decoded filter indicator can include an indication of filter type and or strength instead of a boolean indicator that filtering is to be performed and the indicated filter type and or strength can be used to filter the prediction samples at stage . As another example the filter indication can be incorporated into the prediction mode and stage can be omitted and stage and can be incorporated into stage .

Accordingly as can be understood from the description above aspects of this disclosure add a processing stage within an intra inter prediction stage e.g. . During this stage a most appropriate coding mode can be selected for each group of pixels individual sub blocks macro blocks or segments within a frame. The coding mode can be selected from a set of coding modes based on minimizing one or more error metrics between an original value or original data and a predicted value or predicted data . Intra modes such as DC PRED create the prediction value from data already encoded within the same frame while inter modes use data from one of a number of previously encoded reference frames e.g. the last golden or alternative reference frames.

In one implementation the prediction data that is outputted as a result of applying a coding mode to reference frame data is filtered to create an alternative prediction block. The encoder can consider both the filtered and unfiltered prediction variants for each coding mode and can use a rate distortion function for example to decide which mode and filter state off on to use for a particular set of pixels balancing the additional cost of signaling the filter state off on against anticipated ensuing savings in encoding a reduced residual signal.

As an example in one implementation a motion compensation stage may result in a fractional pixel motion vector. Once the vector has been selected a prediction is created from a designated reference frame using the selected motion vector. This prediction can be evaluated by computing the cost of encoding the residual error and adding the cost of signaling the state of the filter off in this example providing a first coding option. The filter can then be applied to the prediction signal and the evaluation process repeated this time factoring in the cost of signaling that the filter should be enabled to give a second coding option. The different filters can be understood as giving rise to new prediction modes e.g. a 0 0 motion vector mode and a new 0 0 motion vector plus filtering mode . Accordingly unfiltered data can be retained as an alternative for a current block or future blocks. Once various mode filter combinations have been evaluated the combination providing a best rate distortion trade off can be selected for the final encoding.

Further as can be understood from the description above the mode can be encoded and the state of the prediction filter for each group of pixels e.g. each macroblock segment etc. can be signaled. In one implementation the signaling is accomplished by using a binary flag which may be called for example prediction filter state . The binary flag can be encoded for each group of pixels e.g. macroblock segment etc. specifying whether the prediction filter is disabled e.g. with a value of 0 or enabled e.g. with a value of 1 for that group of pixels e.g. macroblock segment etc. for example. Other values may also be used. The binary flag can be encoded using the BoolCoder into the final output bitstream during an entropy encoding stage e.g. . During mode selection counts of the number of group of pixels e.g. macroblocks segments etc. where the filter is disabled e.g. pred filter off count and enabled e.g. pred filter on count can be maintained and used to compute the encoding probability e.g. using Equation 1. The value of pred filter prob can be encoded into a bitstream at the frame level e.g. as an 8 bit literal value. In alternative implementations the value of pred filter prob is encoded differentially from the value in the previous frame or in less than 8 bits e.g. using a relevant modeling algorithm.

In one implementation the signaling is accomplished using a tri state flag which may be called for example prediction filter mode . The tri state flag can be encoded at the frame level signaling that the prediction filter should be turned off e.g. with a value of 0 or on e.g. with a value of 1 for all group of pixels in the current frame e.g. all macroblocks in the current frame or indicating that the decision will be signaled independently at the group of pixel level such as at the macroblock level e.g. with a value of 2 . In the latter case individual prediction filter state flags can be encoded for each group of pixels e.g. each macroblock as per the signaling method described above in relation to the binary flag. During mode selection the pred filter prob computed for a previous frame can be used to compute the cost of signaling the prediction filter state flags for each group of pixels e.g. each macroblock since the value for the current frame may only be known at the end of mode selection in certain implementations. Alternatively a first pass could determine an estimation of this probability that could subsequently be used during a second pass encode. The prediction filter mode flag can be encoded at the frame level using the BoolCoder.

The operation of encoding can be performed in many different ways and can produce a variety of encoded data formats. The above described embodiments of encoding or decoding may illustrate some exemplary encoding techniques. However in general encoding and decoding are understood to include any transformation or any other change of data whatsoever.

The use of the adjectives first second third etcetera herein is not intended to infer any particular meaning regarding a relationship between elements e.g. ordering positioning etc. unless specifically indicated. For example a first frame and a second frame of a video stream can refer to any two frames of the video stream and does not necessarily indicate that the first frame and the second frame are the first two frames of the video stream or that the first frame is located before the second frame.

The use of the adjectives better best etcetera with respect to elements herein is not intended to infer that a particular element is the best possible element or is better than all other possible elements. Instead the adjectives better and best are intended to indicate the relative strength or ranking of an element as compared to one or more other known elements based on particular criteria that may or may not be the most advantageous possible criteria to determine said ranking or strength.

The words example or exemplary are used herein to mean serving as an example instance or illustration. Any aspect or design described herein as example or exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather use of the words example or exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X includes A or B is intended to mean any of the natural inclusive permutations. That is if X includes A X includes B or X includes both A and B then X includes A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Moreover use of the term an embodiment or one embodiment or an implementation or one implementation throughout is not intended to mean the same embodiment or implementation unless described as such.

The processors described herein can be any type of device or multiple devices capable of manipulating or processing information now existing or hereafter developed including for example optical processors quantum and or molecular processors general purpose processors special purpose processors intellectual property IP cores ASICS programmable logic arrays programmable logic controllers microcode firmware microcontrollers microprocessors digital signal processors memory or any combination of the foregoing. In the claims the terms processor core and controller should be understood as including any of the foregoing either singly or in combination. Although a processor of those described herein may be illustrated for simplicity as a single unit it can include multiple processors or cores.

In accordance with an implementation of the invention a computer program application stored in non volatile memory or computer readable medium e.g. register memory processor cache RAM ROM hard drive flash memory CD ROM magnetic media etc. may include code or executable instructions that when executed may instruct or cause a controller or processor to perform methods discussed herein such as a method for performing a coding operation on video data using a computing device containing a plurality of processors in accordance with an implementation of the invention.

A computer readable medium may be a non transitory computer readable media including all forms and types of memory and all computer readable media except for a transitory propagating signal. In an implementation the non volatile memory or computer readable medium may be external memory.

Although specific hardware and data configurations have been described herein note that any number of other configurations may be provided in accordance with implementations of the invention. Thus while there have been shown described and pointed out fundamental novel features of the invention as applied to several implementations it will be understood that various omissions substitutions and changes in the form and details of the illustrated implementations and in their operation may be made by those skilled in the art without departing from the spirit and scope of the invention. Substitutions of elements from one implementation to another are also fully intended and contemplated. The invention is defined solely with regard to the claims appended hereto and equivalents of the recitations therein.

