---

title: Method for improving repeatability in edge location results of a machine vision inspection system
abstract: A method for improving repeatability in edge location measurement results of a machine vision inspection system comprises: placing a workpiece in a field of view of the machine vision inspection system; providing an edge measurement video tool comprising an edge-referenced alignment compensation defining portion; operating the edge measurement video tool to define a region of interest of the video tool which includes an edge feature of the workpiece; operating the edge measurement video tool to automatically perform scan line direction alignment operations such that the scan line direction of the edge measurement video tool is aligned along a first direction relative to the edge feature, wherein the first direction is defined by predetermined alignment operations of the edge-referenced alignment compensation defining portion; and performing edge location measurement operations with the region of interest in that position.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08885945&OS=08885945&RS=08885945
owner: Mitutoyo Corporation
number: 08885945
owner_city: Kawasaki-shi
owner_country: unknown
publication_date: 20121227
---
The present application relates generally to machine vision inspection systems and more particularly to compensating for the effects of a misalignment of a machine vision inspection system edge measurement video tool relative to an edge feature of a workpiece.

Precision machine vision inspection systems or vision systems for short can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer a camera and optical system and a precision stage that is movable in multiple directions to allow workpiece inspection. One exemplary prior art system that can be characterized as a general purpose off line precision vision system is the commercially available QUICK VISION series of PC based vision systems and QVPAK software available from Mitutoyo America Corporation MAC located in Aurora Ill. The features and operation of the QUICK VISION series of vision systems and the QVPAK software are generally described for example in the QVPAK 3D CNC Vision Measuring Machine User s Guide published January 2003 and the QVPAK 3D CNC Vision Measuring Machine Operation Guide published September 1996 each of which is hereby incorporated by reference in their entirety. This type of system is able to use a microscope type optical system and move the stage so as to provide inspection images of either small or relatively large workpieces at various magnifications.

General purpose precision machine vision inspection systems such as the QUICK VISION system are also generally programmable to provide automated video inspection. U.S. Pat. No. 6 542 180 the 180 patent teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the 180 patent automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text based programming for example or through a recording mode which progressively learns the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user with the aid of a graphical user interface or through a combination of both methods. Such a recording mode is often referred to as learn mode or training mode or record mode. Once the inspection event sequence is defined in learn mode such a sequence can then be used to automatically acquire and additionally analyze or inspect images of a workpiece during run mode. 

The machine control instructions including the specific inspection event sequence i.e. how to acquire each image and how to analyze inspect each acquired image are generally stored as a part program or workpiece program that is specific to the particular workpiece configuration. For example a part program defines how to acquire each image such as how to position the camera relative to the workpiece at what lighting level at what magnification level etc. Further the part program defines how to analyze inspect an acquired image for example by using one or more video tools such as edge boundary detection video tools.

Video tools or tools for short include GUI features and predefined image analysis operations such that operation and programming can be performed by non expert operators. Video tools may be operated by a user to accomplish manual inspection and or machine control operations in manual mode . Their set up parameters and operation can also be recorded during learn mode in order to create automatic inspection programs. Exemplary video tools include edge location measurement tools which may include a tool configuration referred to as a box tool used to locate an edge feature of a workpiece. For example commonly assigned U.S. Pat. No. 7 627 162 which is incorporated herein by reference in its entirety teaches various applications of box tools. Another exemplary edge location measurement video tool is referred to as an arc tool. For example commonly assigned U.S. Pat. No. 7 769 222 which is incorporated herein by reference in its entirety teaches various applications of arc tools.

Various methods are known for locating edge features in workpiece images. For example various algorithms are known which apply brightness gradient operators to images which include an edge feature to determine its location e.g. a Canny Edge detector or a differential edge detector. Such edge detection algorithms may be included in the machine vision inspection systems e.g. in video tools which also use carefully configured illumination and or special image processing techniques to enhance brightness gradients or otherwise improve edge location measurement accuracy and repeatability. However it remains difficult to measure the location of certain edges with the desired level of repeatability for example noisy edges such as the edges of irregular surfaces or irregular edges produced by sawing or laser cutting and or closely spaced edges. Video tools and or automatic operations that allow non expert users to measure such edges with improved reliability and or repeatability would be desirable.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Misalignment of a machine vision inspection system edge measurement video tool relative to an edge feature of a workpiece may limit the utility reliability and or accuracy of that video tool. Conversely compensating for that misalignment e.g. either mathematically or by actually correcting the misalignment may increase the utility reliability and or accuracy of that video tool as described in greater detail below. However it may be difficult for relatively unskilled users to understand how to compensate for or correct misalignment to the degree that may be desirable in order to obtain the most reliable and accurate measurements of an edge e.g. at the micron or sub micron level which may require sub pixel interpolation to determine the edge location . This is particularly true when measuring noisy edges or closely spaced edges. Therefore it may be useful to include an automatic edge referenced alignment compensation feature as disclosed herein in a machine vision inspection system for a number of reasons particularly in relation to noisy edges.

As a first example in order to preserve the edge location as well as possible when performing directional averaging and or directional filtering e.g. to combine intensity data from parallel scan lines so that the noise along any particular scan line tends to be averaged out by the combination of the scan lines the offset if any of one scan line relative to the next must be determined such that corresponding pixels of the scan lines are properly combined by the averaging or filtering operation. In this case much of the benefit may be gained by using intensity data determined along an original scan line direction and mathematically compensating for an offset between the scan lines e.g. an offset expressed as the difference in location of the same workpiece feature along adjacent scan lines expressed as a number of pixels with subpixel resolution such that comparable features along the respective scan lines are properly combined. In this case the offset of an edge feature along various scan lines may be characterized by analyzing a plurality of the scan lines and the characterized offset s may be considered as the edge referenced alignment compensation.

As a second example in order to determine an edge location most accurately it may be advantageous to arrange the intensity scan line perpendicular to the edge such that the edge width is minimized and the gradient across the edge is maximized. In this case the benefit is obtained by computing an intensity scan line actually arranged perpendicular to the edge e.g. based on previously obtained image data . Computing an intensity scan line along a desired direction based on previously obtained image data is taught for example in U.S. Pat. No. 7 567 713 to Ding which is hereby incorporated herein by reference in its entirety. In this case the adjustment of the intensity scan line direction such that it is actually perpendicular to the edge may be considered as the edge referenced alignment compensation.

As a third example in order to distinguish between closely spaced edges and particularly between closely spaced noisy edges within a region of interest an offset such as that outlined above between adjacent scan lines may be used as a basis for various combinations of a scanline data such that data related to the various closely spaced edges can be more reliably grouped for analysis e.g. statistical analysis to eliminate detected edge point outliers along a first edge a second edge and the like with less risk of mistaking second edge points for first edge points and vice versa. In this case the offset of an edge feature along various scan lines may be characterized by analyzing a plurality of the scan lines and the characterized offset s may be considered as the edge referenced alignment compensation. However to distinguish between closely spaced edges even more reliably it may be even more advantageous to determine intensity scan lines that are perpendicular to the edge as outlined above in the second example. This will tend to define each edge e.g. its detected edge points most accurately which should benefit any additional analysis performed based on the detected edge points whether that analysis is intended to discriminate one edge from another or locate a particular edge most accurately or the like. In this case the adjustment of the intensity scan line direction such that it is actually perpendicular to the edge may be considered as the edge referenced alignment compensation.

As a fourth example it should be appreciated that when a part program is created the parameters characterizing a particular workpiece edge that is to be located by an edge detection video tool also referred to as the learned edge parameters will be based on video tool scan lines as they are oriented relative to the edge during learn mode. In contrast when that part program is run to automatically detect the corresponding edge on a different workpiece during a run mode the workpiece edge may be rotated to a slightly different angle relative to the programmed video tool leading to a slightly different edge width and gradient along the runtime scan line which makes it more likely that the learned edge parameters will fail to match the characteristics of the run mode scan lines.

It will be appreciated that for noisy edges in particular reliable edge detection is inherently difficult and the margin for such errors may be minimal. Therefore to increase edge detection reliability in such cases it may be desirable to ensure that the run mode scan line orientation relative to an edge feature is as similar as possible to the learn mode scan line orientation which will increase the likelihood of a match between the learned edge parameters included in a part program and the observed edge characteristics during run mode. In this case in one embodiment the adjustment of the intensity scan line direction such that it is actually perpendicular to the edge during learn mode and or run mode may be considered as the edge referenced alignment compensation. In another embodiment the actual orientation of the intensity scan line direction relative to the edge or another characterization of the intensity scan line direction e.g. a composite scan line intensity profile formed by assuming no offset between the scan lines inherently characterizes the intensity scan line direction relative to the edge may be determined and recorded during learn mode and then the run mode scan line orientation relative to the edge may be adjusted to best match the actual scan line orientation or other characterization recorded during learn mode e.g. a scan line or composite scan line intensity or gradient profile . In this case the adjustment of the run mode scan line orientation relative to the edge such that it matches the actual scan line orientation relative to the edge or other scan line characterization recorded during learn mode may be considered as the edge referenced alignment compensation.

As outlined above arranging an intensity scan line such that it is actually perpendicular to an edge may be performed computationally based on previously obtained image data. It will be appreciated that alternatively a workpiece and camera may be rotated relative to one another such that pixel rows or columns of the camera define the scan line direction and are oriented along a desired direction e.g. perpendicular relative to the edge on the workpiece although this may be a time consuming or impossible alternative in many machine vision systems and therefore may not be preferred in such systems. Various methods of determining when a scanline is oriented along a desired direction e.g. perpendicular relative to an edge are described further below.

Disclosed herein is a method for improving repeatability and or robustness in edge location measurement results in a video tool of a machine vision inspection system. The machine vision inspection system may comprise an edge measurement video tool comprising a region of interest portion wherein the edge measurement video tool is configured to detect edge points along a plurality of scan lines in the region of interest such that an edge location measurement may be determined based on the detected edge points. The method comprises placing a workpiece in a field of view of the machine vision inspection system operating the edge measurement video tool to define a region of interest including an edge feature in an acquired image of the workpiece and operating the edge measurement video tool to automatically determine scan line data comprising an intensity profile along a plurality of scan lines across the edge feature in the region of interest. The plurality of scan lines are analyzed in order to provide an edge referenced alignment compensation related to a respective offset amount of the edge feature along respective scan lines of the analyzed plurality of scan lines wherein the edge referenced alignment compensation is usable to adjust the scan line data of the edge measurement video tool such that the respective offset amount of the edge feature along respective scan lines is at least one of a substantially removed b substantially compensated and c substantially matched to a previously determined respective offset amount of a corresponding edge feature along respective scan lines.

In some embodiments the edge measurement video tool may comprise a user interface including at least a region of interest indicator superimposed on an image of the workpiece and the method may further comprise providing an indication that the edge referenced alignment compensation has been provided by adjusting a user interface element that is superimposed on the image of the workpiece in the user interface. In some such embodiments adjusting the user interface element may comprise changing a property of one or more elements that are superimposed on the image of the workpiece e.g. their color or line type or the like or adding an edge referenced alignment compensation indicator e.g. and icon or a widget superimposed on the image.

In some such embodiments e.g. embodiments wherein the scan lines are adjusted to be perpendicular to the edge feature which may remove the offset adjusting the user interface element may comprise adjusting at least one of the region of interest indicator an edge direction indicator and a scan line indicator to indicate that a scan line direction of the video tool is perpendicular to the edge feature. When the video tool is a box tool adjusting the user interface element may comprise rotating the region of interest indicator such that one of its axes is perpendicular to the edge feature or rotating the edge direction indicator such that it is parallel to the edge feature or rotating the scan line indicator such that it is perpendicular to the edge feature. It will be understood that adjusting the user interface element may also comprise translation in some embodiments or applications. When the video tool is one of a circle tool and an arc tool adjusting the user interface element may comprise positioning the region of interest indicator such that its boundaries are approximately concentric with the edge feature or positioning the edge direction indicator such that it is approximately concentric with the edge feature or positioning the scan line indicator such that it is perpendicular to the edge feature.

In some such embodiments the edge referenced alignment compensation determines the respective offset amount s and it is used to adjust the scan line data such that the respective offset amount of the edge feature along respective scan lines is substantially compensated. In such embodiments adjusting the user interface element may comprise adjusting at least one of the region of interest indicator an edge direction indicator and a display representing detected edge points to symbolically represent the respective offset amount s . When the video tool is a box tool adjusting the user interface element may comprise shaping the region of interest indicator to include a side approximately parallel to the edge feature or rotating the edge direction indicator such that it is parallel to the edge feature or displaying the representation of detected edge points or a line fit to the detected edge points approximately along the edge feature. When the video tool is one of a circle tool and an arc tool adjusting the user interface element may comprise shaping the region of interest indicator such that its curved boundaries are approximately concentric with the edge feature or positioning the edge direction indicator such that its curve is approximately concentric with the edge feature or displaying the representation of detected edge points or an arc fit to the detected edge points approximately along the edge feature.

In various embodiments the implementation of the method may comprise one of a selecting the edge measurement video tool such that it is a type that includes edge referenced alignment compensation operations b selecting an edge referenced alignment compensation mode or option of the edge measurement video tool which includes edge referenced alignment compensation operations c selecting a directional filtering mode or option of the edge measurement video tool which includes edge referenced alignment compensation operations and d selecting an edge referenced alignment compensation tool that provides edge referenced alignment compensation operations that operate in conjunction with the edge measurement video tool. In such embodiments the step of analyzing the plurality of scan lines in order to provide the edge referenced alignment compensation may comprise executing the edge referenced alignment compensation operations in conjunction with operations of the edge measurement video tool.

In some cases the method is performed during a learn mode of the machine vision system and corresponding operations are recorded in a part program. In other cases at least some steps of the method are performed during a run mode of the machine vision system by executing corresponding operations recorded in a part program.

In some embodiments the method may further comprise applying the edge referenced alignment compensation to adjust the scan line data of the edge measurement video tool such that the respective offset amount of the edge feature along respective scan lines as reflected in the detected edge points of the edge measurement video tool is at least one of a substantially zero b substantially compensated and c substantially matched to a previously determined respective offset amount of a corresponding edge feature along respective scan lines.

In some embodiments providing the edge referenced alignment compensation comprises characterizing the respective offset amount of the edge feature along respective scan lines. In some such embodiments the edge measurement video tool is one of a box tool a circle tool and an arc tool and characterizing the respective offset amount of the edge feature along respective scan lines comprises detecting edge points fitting a line shape associated with the video tool to the edge points and characterizing the respective offset amount of the fitted line along respective scan lines. When the video tool is a box tool the respective scan lines may be parallel to one another the line shape associated with the video tool is a straight line and characterizing the respective offset amount of the fitted line along respective scan lines may comprise determining an angle between the fitted line and the respective scan lines. When the edge measurement video tool is a circle tool the respective scan lines may all be along radii extending from a center of the circle tool the line shape associated with the video tool is a circle and characterizing the respective offset amount of the fitted line along respective scan lines may comprise determining where the fitted circle intersects the respective scan lines.

In some embodiments providing the edge referenced alignment compensation comprises adjusting the scan lines of the edge measurement video tool such that the scan lines are substantially perpendicular to the edge feature.

In some embodiments providing the edge referenced alignment compensation comprises determining a learn mode composite scan line based on a plurality of contributing learn mode scan lines that include the respective offset amount of a representative learn mode edge feature along the respective contributing learn mode scan lines during a learn mode of the machine vision system and operations corresponding to the method are stored in a part program including a stored representation of the learn mode composite scan line. In some such embodiments the method may further comprise executing the part program during a run mode of the machine vision system comprising adjusting the scan lines of an edge measurement video tool during the run mode based on determining a run mode composite scan line based on a plurality of run mode contributing scan lines that include the respective offset amount of a run mode edge feature corresponding to the representative learn mode edge feature along the respective run mode contributing scan lines wherein the run mode scan lines are adjusted based on approximately maximizing a match of the run mode composite scan line to the learn mode composite scan line. In some such embodiments the learn mode scan lines may be adjusted during learn mode such that a gradient corresponding to the representative edge feature in the learn mode composite scan line is approximately maximized.

In some embodiments scan lines may be defined relative to the video tool e.g. the video tool region of interest and adjustment of the scan lines may comprise adjustment of a feature of the region of interest. Thus it will be appreciated that scan lines may be adjusted directly or indirectly in various embodiments.

The vision measuring machine includes a moveable workpiece stage and an optical imaging system which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system is generally comparable to the QUICK VISION series of vision systems and the QVPAK software discussed above and similar state of the art commercially available precision machine vision inspection systems. The machine vision inspection system is also described in commonly assigned U.S. Pat. Nos. 7 454 053 7 324 682 8 111 905 and 8 111 938 which are each incorporated herein by reference in their entireties.

The optical assembly portion is controllably movable along a Z axis that is generally orthogonal to the X and Y axes by using a controllable motor that drives an actuator to move the optical assembly portion along the Z axis to change the focus of the image of the workpiece . The controllable motor is connected to the input output interface via a signal line .

A workpiece or a tray or fixture holding a plurality of workpieces which is to be imaged using the machine vision inspection system is placed on the workpiece stage . The workpiece stage may be controlled to move relative to the optical assembly portion such that the interchangeable objective lens moves between locations on a workpiece and or among a plurality of workpieces . One or more of a stage light a coaxial light and a surface light e.g. a ring light may emit source light and or respectively to illuminate the workpiece or workpieces .

The light source may emit light along a path including a beam splitter mirror . The source light is reflected or transmitted as workpiece light and the workpiece light used for imaging passes through the interchangeable objective lens and the turret lens assembly and is gathered by the camera . The images of the workpiece s from the camera are output on a signal line to the control system portion . The light sources and may be connected to the control system portion through signal lines or busses and respectively. To alter the image magnification the control system portion may rotate the turret lens assembly along axis to select a turret lens through a signal line or bus .

As shown in in various exemplary embodiments the control system portion includes a controller the input output interface a memory a workpiece program generator and executor and a power supply portion . Each of these components as well as the additional components described below may be interconnected by one or more data control buses and or application programming interfaces or by direct connections between the various elements.

The input output interface includes an imaging control interface a motion control interface a lighting control interface and a lens control interface . The motion control interface may include a position control element and a speed acceleration control element although such elements may be merged and or indistinguishable. The lighting control interface includes lighting control elements and which control for example the selection power on off switch and strobe pulse timing if applicable for the various corresponding light sources of the machine vision inspection system .

The memory may include an image file memory portion a workpiece program memory portion that may include one or more part programs or the like and a video tool portion . As illustrated the video tool portion includes representative video tool portions and which determine the GUI image processing operation etc. for each of the corresponding video tools. Also the video tool portion may include in particular an edge tool with edge referenced alignment compensation as described in greater detail below which may include edge location measurement operations described with respect to a box tool and an arc tool in the QVPAK 3D CNC Vision Measuring Machine Operation Guide for example and which may incorporate signal processing to implement the methods disclosed herein. The video tool portion also includes a region of interest ROI generator that supports automatic semi automatic and or manual operations that define various ROIs that are operable in various video tools included in the video tool portion . In some embodiments the edge tool with edge referenced alignment compensation may operate in conjunction with or to supplement the operation of the region of interest ROI generator in order to adjust an initial orientation or position of the region of interest and associated scan line directions to align a video tool region of interest with an edge feature to improve repeatability of edge location measurements as described in greater detail below.

In the context of this disclosure and as known by one of ordinary skill in the art the term video tool generally refers to a relatively complex set of automatic or programmed operations that a machine vision user can implement through a relatively simple user interface e.g. a graphical user interface editable parameter windows menus and the like without creating the step by step sequence of operations included in the video tool or resorting to a generalized text based programming language or the like. For example a video tool may include a complex pre programmed set of image processing operations and computations which are applied and customized in a particular instance by adjusting a few variables or parameters that govern the operations and computations.

In addition to the underlying operations and computations the video tool comprises the user interface that allows the user to adjust those parameters for a particular instance of the video tool. For example many machine vision video tools allow a user to configure a graphical region of interest ROI indicator through simple handle dragging operations using a mouse in order to define the location parameters of a subset of an image that is to be analyzed by the image procession operations of a particular instance of a video tool. It should be noted that the visible user interface features are sometimes referred to as the video tool with the underlying operations being included implicitly.

In common with many video tools and or video tool features and operations the edge referenced alignment compensation subject matter of this disclosure includes both user interface features and underlying image processing operations and the like and the related features may be characterized as features of an edge measurement video tool with or including edge referenced alignment compensation that is included in the video tool portion . The edge tool with edge referenced alignment compensation provides operations which may be used to automatically provide edge referenced alignment compensation for detecting or locating an edge feature to improve the repeatability of related edge location measurements.

The edge tool with edge referenced alignment compensation may include an edge referenced alignment compensation defining portion that automatically or semi automatically determines the desired compensation. In one embodiment the alignment compensation defining portion may adjust the scan line direction used by the edge tool and the adjustment of the intensity scan line direction e.g. such that it is perpendicular to the edge feature that is to be located may be considered as the edge referenced alignment compensation.

In another embodiment the alignment compensation defining portion may characterize the offset of the edge feature along various scan lines by analyzing a plurality of the scan lines and the characterized offset s may be considered as the edge referenced alignment compensation. The characterized offset s may be used to mathematically compensate for the offset s when performing various additional operations that compare or combine the scan lines for example as described further below.

Various tool parameters and or offset characterizations determined during learn mode operations of the edge tool may be determined and stored in a part program during learn mode as described in greater detail below. The video tool portion may also or instead include a conventional edge measurement video tool which operates according to known edge detection or location methods.

In one embodiment the edge referenced alignment compensation defining portion may be linked or otherwise act in conjunction with such a tool. For example in one embodiment the edge referenced alignment compensation operations disclosed herein may be included as an edge referenced alignment compensation mode in a multi mode edge detector or location tool that includes modes comparable to the known edge detection tools e.g. a known box tool arc tool circle tool etc. .

In some embodiments the edge tool with edge referenced alignment compensation and the known or conventional edge tool s may be separate tools but in some embodiments they may be two modes of a single edge tool. In some embodiments where they are two modes of a single edge tool the particular mode may be chosen by the edge tool based on manual and or automatic learn mode operations e.g. based on how irregular or noisy the edge is and or whether its nominal shape is known as described further below.

The signal lines or busses and of the stage light the coaxial lights and and the surface light respectively are all connected to the input output interface . The signal line from the camera and the signal line from the controllable motor are connected to the input output interface . In addition to carrying image data the signal line may carry a signal from the controller that initiates image acquisition.

One or more display devices e.g. the display of and one or more input devices e.g. the joystick keyboard and mouse of can also be connected to the input output interface . The display devices and input devices can be used to display a user interface which may include various graphical user interface GUI features that are usable to perform inspection operations and or to create and or modify part programs to view the images captured by the camera and or to directly control the vision system components portion .

In various exemplary embodiments when a user utilizes the machine vision inspection system to create a part program for the workpiece the user generates part program instructions by operating the machine vision inspection system in a learn mode to provide a desired image acquisition training sequence. For example a training sequence may comprise positioning a particular workpiece feature of a representative workpiece in the field of view FOV setting light levels focusing or autofocusing acquiring an image and providing an inspection training sequence applied to the image e.g. using an instance of one of the video tools on that workpiece feature . The learn mode operates such that the sequence s are captured or recorded and converted to corresponding part program instructions. These instructions when the part program is executed will cause the machine vision inspection system to reproduce the trained image acquisition and inspection operations to automatically inspect that particular workpiece feature that is the corresponding feature in the corresponding location on a run mode workpiece or workpieces which matches the representative workpiece used when creating the part program.

The lower part of is a chart which shows an intensity profile IPa and a corresponding intensity gradient profile GPa the rate of change of intensity at pixel locations e.g. pixel numbers along the scan line SLa. As is known in the art it is conventional to identify an edge point along a scan line as the location where the maximum gradient occurs e.g. at the extremum in the box . shows an example where the region of interest is aligned with the edge and the scan lines are arranged perpendicular to the edge . Due to this alignment assuming the edge is approximately straight and uniform the intensity profile and gradient profile of the scan line SLb will be approximately the same as for the scan line SLa and the edge will occur at approximately the same location along the scan lines SLa and SLb. This means that the edge is not offset along one of the scan lines relative to the other that is the offset Oab of the edge along one scan line relative to the other will be approximately zero.

Because of these properties of scan lines that are aligned relative to the edge a normalized composite gradient profile e.g. an average or a normalized sum of the gradient profiles GPa and GPb will be approximately as narrow as its constituent profiles and will indicate the average or representative location of the edge with good fidelity. For example forming a composite gradient profile may be particularly advantageous if the gradient profiles GPa and GPb each contain noise due to a noisy or randomly irregular edge but the edge is known or assumed to be straight. In such a case the composite gradient profile will most likely provide a better estimate of the location of the edge than the individual gradient profiles.

In contrast to shows a field of view window including an image of the workpiece wherein the edge is rotated or misaligned relative to the region of interest ROI and or the scan lines SLa and SLb . A dashed line illustrates an edge orientation EO of the edge in the image for purposes of explanation. For purposes of explanation also shows two parallel scan lines SLa and SLb similar to those shown in . With the edge assumed to be a straight edge a misalignment angle MA is associated with an offset Oab of the edge along one scan line relative to the other. In particular sin MA distance between scan lines offset of edge between scan lines as discussed further below.

The lower part of is a chart which shows intensity gradient profiles GPa and GPb at pixel locations e.g. pixel numbers along the scan lines SLa and SLb respectively. shows an example where the region of interest is misaligned with the edge and the scan lines are not perpendicular to the edge . Due to this misalignment assuming the edge is approximately straight and uniform the gradient profile along the scan line SLb will be offset from that along the scan line SLa and the edge will occur at a location along the scan lines SLa and SLb . This means that the edge is offset along one of the scan lines relative to the other that is the offset Oab of the edge along one scan line relative to the other will not be zero.

Because of these properties of scan lines that are misaligned relative to the edge a normalized composite gradient profile e.g. an average or a normalized sum of the gradient profiles GPa and GPb will include errors or artifacts due to the offset s of the edge location along the scan lines and will not indicate the average or representative location of the edge with good fidelity. For example the composite gradient peak region will not be as narrow as its constituent peaks and may exhibit spurious composite gradient peaks as exhibited in the box .

From it may be seen that a gradient due to a closely spaced edge e.g. the edge may even be improperly combined with the desired edge for some misalignments e.g. misalignments slightly greater than those illustrated . Such errors and artifacts impede the determination of an accurate representative edge location of the edge particularly if it is a noisy edge. The offset s also impede the use of certain directional filtering and or other processing operations than may be desirable for enhancing and or distinguishing noisy edges and or closely spaced edges and the like. Thus it may be desirable to provide an edge referenced alignment compensation for various edge detection video tools as disclosed herein.

In particular it is desirable for an edge referenced alignment compensation to either remove or compensate for the offset Oab or the like so that scan lines can be averaged or combined or directional filtering or other techniques may be used to improve the detected or estimated location of noisy edges that have an approximately known shape and or the reliability of distinguishing among closely spaced edges or both.

As previously outlined in order to compensate the offset if any of one scan line relative to the next such that corresponding pixels of the scan lines are properly combined by a comparison or averaging or filtering operation much of the benefit may be gained by using intensity data determined along an original scan line direction and mathematically compensating for an offset between the scan lines e.g. an offset expressed as the difference in location of the same workpiece feature along adjacent scan lines expressed as a number of pixels with subpixel resolution such that comparable features along the respective scan lines may be properly combined. In this case the offset of an edge feature along various scan lines may be characterized by analyzing a plurality of the scan lines and the characterized offset s may be considered as the edge referenced alignment compensation.

In some such embodiments the edge measurement video tool is one of a box tool a circle tool and an arc tool and characterizing the respective offset amount of the edge feature along respective scan lines comprises detecting edge points fitting a line shape associated with the video tool to the edge points and characterizing the respective offset amount of the fitted line along respective scan lines. When the video tool is a box tool the respective scan lines may be parallel to one another the line shape associated with the video tool is a straight line and characterizing the respective offset amount of the fitted line along respective scan lines may comprise determining an angle between the fitted line and the respective scan lines. When the edge measurement video tool is a circle tool the respective scan lines may all be along radii extending from a center of the circle tool the line shape associated with the video tool is circle and characterizing the respective offset amount of the fitted line along respective scan lines may comprise determining where the fitted circle intersects the respective scan lines.

In another embodiment in order to determine an edge location most accurately is advantageous to arrange the intensity scan line perpendicular to the edge e.g. such that the edge width is minimized and or the gradient across the edge is maximized . As outlined above arranging an intensity scan line such that it is actually perpendicular to an edge may be performed computationally based on previously obtained image data. It will be appreciated that alternatively a workpiece and camera may be rotated relative to one another such that pixel rows or columns of the camera are define the scan line direction and are oriented along a desired direction e.g. perpendicular relative to the edge on the workpiece although this may be a time consuming or impossible alternative in many machine vision systems and therefore may not be preferred in such systems. In either case the adjustment of the intensity scan line direction such that it is actually perpendicular to the edge may be considered as the edge referenced alignment compensation.

An intensity scan line that is actually arranged perpendicular to an edge may be computed based on previously obtained image data. Computing an intensity scan line along a desired direction based on previously obtained image data is taught for example in U.S. Pat. No. 7 567 713 to Ding which is hereby incorporated herein by reference in its entirety. One alternative way of determining the proper direction of the scan line may include fitting a line to the edge and adjusting the orientation and or position of the set of scan lines of the video tool such that the fit edge has the same offset along all scan lines or the scan lines are perpendicular to the fitted line or both. Known mathematics may be used to perform such operations.

In at least one embodiment when the video tool is a box tool the respective scan lines may be parallel to one another the line shape associated with the video tool may be a straight line and the angle between the fitted line and the respective scan lines may be determined and the scan lines adjusted to be perpendicular to the fitted line. In at least one embodiment when the edge measurement video tool is a circle tool or an arc tool the respective scan lines may all be along radii extending from a center of the circle or arc tool or a scan line center the line shape associated with the video tool may be a circle or portion of a circle and the center of the fitted circle may be determined relative to the center of the circle or arc tool or the scan line center. Then the scan line center may be adjusted to coincide with the center of the fitted circle and the adjusted scan line profile s computed.

Another alternative way of determining the proper direction of the scan lines may include performing a search that varies the orientation and or position of a set of scan lines associated with a video tool and for each orientation and or position forming a composite scan line by combining the data from scan lines along a direction parallel to an edge shape associated with a video tool for example summing or averaging scan line data along a direction perpendicular to the scan lines e.g. along a straight or circular direction or by summing or averaging corresponding pixel numbers along the scan lines . The resulting composite scan lines are evaluated. The orientation and or position that provides the narrowest edge and or the narrowest and or highest edge gradient in the composite scan line is the orientation and or position that is used to determine scan lines that are approximately perpendicular to the edge that is to be detected.

This embodiment for determining proper scan line direction may be the most advantageous method when the objective is to distinguish between closely spaced edges and particularly between closely spaced noisy edges within a region of interest. It may be used as a basis for various combinations of a scanline data such that data related to the various closely spaced edges can be more reliably grouped for analysis e.g. statistical analysis to eliminate detected edge point outliers along a first edge a second edge and the like with less risk of mistaking second edge points for first edge points and vice versa. This will tend to define each edge e.g. its detected edge points most accurately which should benefit any additional analysis performed based on the detected edge points whether that analysis is intended to discriminate one edge from another or locate a particular edge most accurately or the like.

It should be appreciated that when a part program is created the parameters characterizing a particular workpiece edge that is to be located by an edge detection video tool also referred to as the learned edge parameters will be based on video tool scan lines as they are oriented relative to the edge during learn mode. In contrast when that part program is run to automatically detect the corresponding edge on a different workpiece during a run mode the workpiece edge may be rotated to a slightly different angle relative to the programmed video tool leading to a slightly different edge width and gradient along the runtime scan line which makes it more likely that the learned edge parameters will fail to match the characteristics of the run mode scan lines.

It will be appreciated that for noisy edges in particular reliable edge detection is inherently difficult and the margin for such errors may be minimal. Therefore to increase edge detection reliability in such cases it may be desirable to ensure that the run mode scan line orientation relative to an edge feature is as similar as possible to the learn mode scan line orientation which will increase the likelihood of a match between the learned edge parameters included in a part program and the observed edge characteristics during run mode. In this case in one embodiment the adjustment of the intensity scan line direction such that it is actually perpendicular to the edge during learn mode and or run mode may be considered as the edge referenced alignment compensation. In another embodiment the actual orientation of the intensity scan line direction relative to the edge or another characterization of the intensity scan line direction e.g. a composite scan line intensity profile formed by assuming no offset between the scan lines inherently characterizes the intensity scan line direction relative to the edge may be determined and recorded during learn mode and then the run mode scan line orientation relative to the edge may be adjusted to best match the actual scan line orientation or other characterization recorded during learn mode e.g. a scan line or composite scan line intensity or gradient profile . In this case the adjustment of the run mode scan line orientation relative to the edge such that it matches the actual scan line orientation relative to the edge or other scan line characterization recorded during learn mode may be considered as the edge referenced alignment compensation.

In some embodiments providing the edge referenced alignment compensation comprises determining a learn mode composite scan line based on a plurality of contributing learn mode scan lines that include the respective offset amount of a representative learn mode edge feature along the respective contributing learn mode scan lines during a learn mode of the machine vision system and operations corresponding to the method are stored in a part program including a stored representation of the learn mode composite scan line. In some such embodiments the method may further comprise executing the part program during a run mode of the machine vision system comprising adjusting the scan lines of an edge measurement video tool during the run mode based on determining a run mode composite scan line based on a plurality of run mode contributing scan lines that include the respective offset amount of a run mode edge feature corresponding to the representative learn mode edge feature along the respective run mode contributing scan lines wherein the run mode scan lines are adjusted based on approximately maximizing a match of the run mode composite scan line to the learn mode composite scan line. In some such embodiments the learn mode scan lines may be adjusted during learn mode such that a gradient corresponding to the representative edge feature in the learn mode composite scan line is approximately maximized.

In some embodiments the learn mode and or run mode scan line adjustments may be determined in a manner similar or identical to the search methods and composite scan line evaluation principles outlined above. During run mode the composite scan line evaluation may include finding the composite scan line that best matches the corresponding recorded learn mode composite scan line e.g. based on a correlation analysis or other known data profile comparison techniques . Such a procedure is one way to provide a run mode offset amount for various scan lines that is substantially matched to a previously determined respective offset amount of a corresponding edge feature along respective scan lines e.g. as determined during learn mode . In any case such a procedure may increase the reliability of edge detection parameters determined for a learn mode workpiece and recorded in a part program when the part program is applied to similar workpieces during run mode.

As previously outlined it will be appreciated that in some embodiments scan lines may be defined relative to the video tool e.g. the video tool region of interest and adjustment of the scan lines may comprise adjustment of an element or feature of the region of interest. Thus it will be appreciated that scan lines may be adjusted directly or indirectly in various embodiments.

As shown in the edge referenced alignment compensation has not yet been provided e.g. the tool has not yet been run or trained in learn mode or manual mode . As a result the video tool GUI appears in an initial state e.g. an untrained state . In some embodiments the optional Edge Referenced indicator ERin may be displayed in a state that indicates that the edge referenced alignment compensation has not yet been provided. In other embodiments the video tool GUI simply appears in its initial state.

As shown in the edge referenced alignment compensation has been provided e.g. the tool has been run or trained in learn mode or manual mode . In this particular embodiment internal operations of the video tool have eliminated the offset between scan lines e.g. perpendicular scan lines have been computed perpendicular to the edge . As a result in some embodiments the optional Edge Referenced indicator ERin may be displayed in a state that indicates that the edge referenced alignment compensation has been provided. In other embodiments the video tool GUI adjusts one of its elements relative to its initial state in a manner that suggests that the edge referenced alignment compensation has been provided.

For example in the video tool which is a box tool adjusts the user interface by rotating the region of interest indicator such that one of its axes is perpendicular to the edge feature in it provides and or rotates one or more edge direction indicator s EDin such that it is parallel to the edge feature and in it provides and or rotates one or more scan line direction indicator s SLin such that it is perpendicular to the edge feature .

The arc tool comprises a user interface including a region of interest indicator ROIin superimposed on an image of the workpiece. As shown in the edge referenced alignment compensation has not yet been provided. As a result the video tool GUI appears in an initial state e.g. an untrained state . In some embodiments the optional Edge Referenced indicator ERin may be displayed in a state that indicates that the edge referenced alignment compensation has not yet been provided. In other embodiments the video tool GUI simply appears in its initial state. As shown in the edge referenced alignment compensation has been provided e.g. the tool has been run or trained in learn mode or manual mode .

In this particular embodiment internal operations of the video tool have eliminated the offset between scan lines e.g. perpendicular scan lines have been computed perpendicular to the edge . As a result in some embodiments the optional Edge Referenced indicator ERin may be displayed in a state that indicates that the edge referenced alignment compensation has been provided. In other embodiments the video tool GUI adjusts one of its elements relative to its initial state in a manner that suggests that the edge referenced alignment compensation has been provided. For example in the video tool adjusts the user interface by positioning the region of interest indicator ROIin such that its boundaries are approximately concentric with the edge feature in it provides and or positions the edge direction indicator s EDin such that it is approximately concentric with the edge feature and in it provides and or positions the scan line indicator s SLin such that it is perpendicular to the edge feature. It will be appreciated that various embodiments of a circle tool may have analogous features to the arc tool embodiments shown in .

As outlined previously in some embodiments the edge referenced alignment compensation determines the respective offset amount s along various scan lines and it is used to adjust the scan line data such that the respective offset amount of the edge feature along respective scan lines is substantially compensated as outlined previously. In such embodiments adjusting the user interface element may comprise adjusting at least one of the region of interest indicator an edge direction indicator and a display representing detected edge points to symbolically represent the respective offset amount s . and show user interface features which may be used in such embodiments.

As shown in the edge referenced alignment compensation has been provided e.g. the tool has been run or trained in learn mode or manual mode . In this particular embodiment internal operations of the video tool have determined the offset between scan lines e.g. such that it may be computationally compensated as outlined previously . As a result in some embodiments the optional Edge Referenced indicator ERin may be displayed in a state that indicates that the edge referenced alignment compensation has been provided. In other embodiments the video tool GUI adjusts one of its elements relative to its initial state in a manner that suggests that the edge referenced alignment compensation has been provided. For example in the video tool adjusts the user interface by shaping the region of interest indicator ROIin to include a side approximately parallel to the edge feature in it provides and or positions the edge direction indicator EDin such that it is parallel to the edge feature and or indicates an angle between the edge feature and a line indicative of the scan line orientation and in it provides and or positions a detected edge point representation s DEP or a line fit to the detected edge points approximately along the edge feature.

As shown in the edge referenced alignment compensation has been provided e.g. the tool has been run or trained in learn mode or manual mode . In this particular embodiment internal operations of the video tool have determined the offset between scan lines e.g. such that it may be computationally compensated as outlined previously . As a result in some embodiments the optional Edge Referenced indicator ERin may be displayed in a state that indicates that the edge referenced alignment compensation has been provided.

In other embodiments the video tool GUI adjusts one of its elements relative to its initial state in a manner that suggests that the edge referenced alignment compensation has been provided. For example in the video tool adjusts the user interface by shaping the region of interest indicator ROIin such that its curved boundaries are approximately concentric with the edge feature in it provides and or positions the edge direction indicator EDin such that its curve is approximately concentric or coincident with the edge feature and or indicates an angle between the edge feature and a line indicative of the scan line orientation and in it provides and or positions a detected edge point representation s DEP or a line fit to the detected edge points approximately along the edge feature.

In various embodiments implementation of the edge references alignment compensation methods disclosed herein may comprise one of a selecting the edge measurement video tool such that it is a type that includes edge referenced alignment compensation operations b selecting an edge referenced alignment compensation mode or option of the edge measurement video tool which includes edge referenced alignment compensation operations c selecting a directional filtering mode or option of the edge measurement video tool which includes edge referenced alignment compensation operations and d selecting an edge referenced alignment compensation tool that provides edge referenced alignment compensation operations that operate in conjunction with the edge measurement video tool. In such embodiments the step of analyzing the plurality of scan lines in order to provide the edge referenced alignment compensation may comprise executing the edge referenced alignment compensation operations in conjunction with operations of the edge measurement video tool.

In some cases the method is performed during a learn mode of the machine vision system and corresponding operations are recorded in a part program. In other cases at least some steps of the method are performed during a run mode of the machine vision system by executing corresponding operations recorded in a part program.

In some embodiments the method may further comprise applying the edge referenced alignment compensation to adjust the scan line data of the edge measurement video tool such that the respective offset amount of the edge feature along respective scan lines as reflected in the detected edge points of the edge measurement video tool is at least one of a substantially zero b substantially compensated and c substantially matched to a previously determined respective offset amount of a corresponding edge feature along respective scan lines.

It will be appreciated that the edge referenced alignment compensation status indicators shown in are exemplary only and not limiting.

While various embodiments have been illustrated and described numerous variations in the illustrated and described arrangements of features and sequences of operations will be apparent to one skilled in the art based on this disclosure. Thus it will be appreciated that various changes can be made therein without departing from the spirit and scope of the invention.

