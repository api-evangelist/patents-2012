---

title: Inferring switching conditions for switching between modalities in a speech application environment extended for interactive text exchanges
abstract: The disclosed solution includes a method for dynamically switching modalities based upon inferred conditions in a dialog session involving a speech application. The method establishes a dialog session between a user and the speech application. During the dialog session, the user interacts using an original modality and a second modality. The speech application interacts using a speech modality only. A set of conditions indicative of interaction problems using the original modality can be inferred. Responsive to the inferring step, the original modality can be changed to the second modality. A modality transition to the second modality can be transparent the speech application and can occur without interrupting the dialog session. The original modality and the second modality can be different modalities; one including a text exchange modality and another including a speech modality.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08874447&OS=08874447&RS=08874447
owner: Nuance Communications, Inc.
number: 08874447
owner_city: Burlington
owner_country: US
publication_date: 20120706
---
This is a continuation of U.S. application Ser. No. 13 179 098 entitled INFERRING SWITCHING CONDITIONS FOR SWITCHING BETWEEN MODALITIES IN A SPEECH APPLICATION ENVIRONMENT EXTENDED FOR INTERACTIVE TEXT EXCHANGES filed on Jul. 8 2011 and now pending which is a continuation of U.S. application Ser. No. 11 613 176 entitled INFERRING SWITCHING CONDITIONS FOR SWITCHING BETWEEN MODALITIES IN A SPEECH APPLICATION ENVIRONMENT EXTENDED FOR INTERACTIVE TEXT EXCHANGES filed on Dec. 19 2006 now U.S. Pat. No. 8 000 969. Each of the foregoing documents is incorporated herein by reference in its entirety.

The present invention relates to the field of automated speech systems and more particularly to inferring switching conditions for switching between modalities in a speech application environment extended for text based interactive services.

Interactive Voice Response IVR systems are often used to provide automated customer service via a voice channel of a communication network. IVR systems permit routine customer requests to be quickly efficiently and automatically handled. When a request is non routine or when a caller has difficulty with the IVR system a transfer can be made from the IVR system to a customer service representative. Even when human interactions are needed the IVR system can obtain necessary preliminary information such as an account number and a reason for a call which can ensure callers are routed to an appropriate human agent and to ensure human to human interactive time is minimized. Successful use of IVR systems allows call centers to be minimally manned while customers are provided a high level of service with relatively low periods spent in waiting queues.

IVR systems especially robust ones having natural language understanding NLU capabilities and or large context free grammars represent a huge financial and technological investment. This investment includes costs for purchasing and maintaining IVR infrastructure hardware IVR infrastructure software and voice applications executing upon this infrastructure. An additional and significant reoccurring cost can relate to maintaining a sufficient number of voice quality channels to handle anticipated call volume. Further each of these channels consumes an available port of a voice server which has a limited number of costly ports. Each channel also consumes a quantity of bandwidth needed for establishing a voice quality channel between a caller and the IVR system.

One innovative solution for extending an IVR infrastructure to permit text based interactive services is detailed in co pending patent application Ser. No. 11 612 996 entitled Using an Automated Speech Application Environment to Automatically Provide Text Based Interactive Services. More specifically the co pending application teaches that a chat robot object referred to as a Chatbot can dynamically convert text received from a text messaging client to input consumable by a voice server and can dynamically convert output from the voice server to text appropriately formatted for the client. From a perspective of the voice server the text based interactions with the text messaging client are handled in the same manner and with the same hardware software that is used to handle voice based interactions. The enhanced speech application environment allows for a possibility of switching between modalities without interrupting a pre existing communication session which is elaborated upon in co pending patent application Ser. No. 11 613 040 entitled Switching Between Modalities in a Speech Application Environment Extended for Text Based Interactive Services. 

Different advantages exist for a text messaging modality and for a voice modality. In a text modality for example a user may have difficulty entering lengthy responses. This is particularly true when a user has poor typing skills or is using a cumbersome keypad of a resource constrained device e.g. a Smartphone to enter text. In a voice modality a speech recognition engine may have difficulty understanding a speaker with a heavy accent or who speaks with an obscure dialect. A speech recognition engine can also have difficulty understanding speech transmitted over a low quality voice channel. Further speech recognition engines can have low accuracy when speech recognizing proper nouns such as names and street addresses. In all of these situations difficulties may be easily overcome by switching from a voice modality to a text messaging modality. No known system has an ability to switch between voice and text modalities during a communication session. Teachings regarding inferential modality switching are non existent.

The present invention teaches a solution applicable to a communication system having multiple interactive modalities that permits users to dynamically switch modalities during a communication session. For example a user can dynamically switch between a text messaging modality and a voice modality while engaged in a communication session with an automated response system such as an IVR. The invention can infer a need to switch modalities based upon conditions of a communication session. When this need is inferred a programmatic action associated with modality shifting can occur.

For instance a user can be prompted to switch modalities a modality switch can automatically occur or a new modality can be automatically added to the communication session which results in a multi mode communication session or a dual mode communication session. In a multi mode communication session more than one input output modality e.g. speech and text can be permitted for a single device client application communicating over a single communication channel. In a dual mode communication session different devices e.g. a phone and a computer each associated with a different modality and or communication channel can be used during an interactive communication session. That is a user can respond to a session prompt by speaking a response into a phone or by typing a response into a text messaging client either of which produces an equivalent result.

It should be appreciated that conventional solutions for providing voice and text messaging services implement each service in a separate and distinct server. Each of these servers would include server specific applications tailored for a particular modality. For example a VoiceXML based application controlling voice based interactions can execute on a speech server and a different XML based application controlling text based interactions can execute on a text messaging server.

Any attempt to shift from a text session to a voice session or vice versa would require two distinct servers applications and communication sessions to be synchronized with each other. For example if a voice session were to be switched to a text session a new text session would have to be initiated between a user and a text messaging server. The text messaging server would have to initiate an instance of a text messaging application for the session. Then state information concerning the voice session would have to be relayed to the text messaging server and or the text messaging application. Finally the speech application executing in the speech server would need to be exited and the original voice session between the speech server and a user terminated.

These difficulties in switching modalities during a communication session are overcome by using a novel speech application environment that is extended for text based interactive services. This speech application environment can include a Chatbot server which manages chat robot objects or Chatbots. Chatbots can dynamically convert text received from a text messaging client to input consumable by a voice server and to generate appropriately formatted for the client. For example the Chatbot server can direct text messaging output to a text input API of the voice server which permits the text to be processed. Additionally voice markup output can be converted into a corresponding text message by the Chatbot server. The extended environment can use unmodified off the shelf text messaging software and can utilize an unmodified speech applications. Further the present solution does not require special devices protocols or other types of communication artifacts to be utilized.

The voice server like most voice servers can include a text mode interface which is typically used by developers system maintainers and or trainers of a speech recognition engine. For example a set of proprietary restricted or standardized e.g. MRCPv2 INTERPRET Application Program Interfaces APIs can be used for the interface . This set of APIs which are typically not available or accessible within a production environment can be enabled to create a text input channel that consumes considerably fewer computing resources that a voice channel which is typically established with the voice server operating in a production environment. In most cases the text mode interface is present but dormant within production voice servers . Interface can be enabled for text based interactions with Chatbot server.

Use of interface occurs in a manner transparent to the application server and therefore has no affect on application . That is application and application server remain unaware that the voice server is processing text input via interface as opposed to voice input. The output produced by voice server and sent to Chatbot server can be the same in either case. Further the output produced by the application server and sent to the Chatbot server can be the same. Thus multiple communication sessions one or more being text based sessions that use interface and others being voice based sessions can be concurrently handled by application server . System can be implemented without infrastructure changes to application server and without changes to voice server assuming interface is present and without changing code of speech enabled applications . This is true even though the application may lack explicitly coded support for text exchange interactions and would be unable to support such interactions without the disclosed invention. Further the text exchange interface can be any off the shelf text exchange software which needs not be modified to operate as shown in system .

In system the Chatbot server can fetch voice markup associated with a speech enabled application which it executes. The Chatbot server can also relay textual input from interface to send text consumable by voice server via interface . The voice server can match the input against a recognition grammar and generate text output for the Chatbot server . The Chatbot server can use this output when it executes the application. The application processes this output which can produce a responsive output typically in a form of a Voice markup segment such as VoiceXML which can further employ the use of the W3C Speech Synthesis Markup Language or SSML . When performing text exchange operations normal speech synthesis operations performed by the voice server can be bypassed. The Chatbot server can dynamically convert the responsive output from the markup into textual output which interface handles. For example textual content contained between markup tags can be extracted from the application markup i.e. the markup tags can be omitted and included within a text message.

During the communication session switching engine can perform a switching operation from text exchange interface to voice interface . The switching operation can occur in a fashion transparent to application and can occur without interrupting the communication session. After the switch voice input can be received from interface which is conveyed to server as voice input . Voice output can be generated in response which is conveyed to voice interface as voice output .

From within interface a user can switch from one modality to another which results in Chatbot server performing a switching operation. This switching can occur in a manner transparent to application and a dialogue state of an existing communication session can be seamlessly maintained.

To illustrate Chatbot server can switch from the text exchange interface to voice interface . The voice interface can be provided through a separate device such as a phone. After the switch voice input can be routed as input to Chatbot server . The Chatbot server can send the voice input to the voice server which produces text result . The Chatbot server can generate new markup after processing result which is sent not shown to voice server which returns not shown voice output. The voice output can be conveyed to voice interface by Chatbot server as voice output .

One feature of the switching engine is an inference module that automatically detects occurrences of conditions of interaction problems. These conditions can be established in step of the illustrated flow chart. In step a value indicative of an interaction problem can be calculated during a communication session. In step the calculated value can be compared against one or more modality switching thresholds. In step when a threshold is exceeded a modality switching action can be triggered that is associated with the exceeded threshold. In step connection information for the new modality can be determined. A user or a user machine can be queried as necessary. For example when modality change requires a new telephony connection be established with a phone associated with voice interface than a telephone number can be required so that Chatbot server can call the phone. This number can be received through user input or can be automatically looked up from a previously established profile. In step modalities can be switched and previous communication channels can be closed as necessary.

A set of illustrative inferential switching conditions which are not intended to be exhaustive is shown in table . Different conditions can be indicative of a problem with a text exchange modality and with a speech modality. In table a text exchange modality problem that could be corrected by a switch to a voice modality is indicated by symbol T V included in the value column. Symbol V T is used to indicate a voice modality problem that could be corrected by a switch to a text exchange modality. Different conditions can optionally have a set of severity levels associated with them where a modality problem is greater for a higher severity level.

In table conditions associated with text exchange problems include inappropriate text entry excessively long text input long delays between input and out of context input. Inappropriate text can be text indicative of angst or user frustration. Textual swearing or other frustration indicative input such as or are examples of inappropriate text. A detection of excessively long text input can indicate that a voice modality may be better served for input capture. This is especially true when long delays between input is combined with the long text which can indicate a user is entering text through a cumbersome interface such as through a mobile phone keypad or can simply indicate that a user is an inexpert typist. Long delays between input can indicate user confusion regarding a correct manner to respond to a prompt and or can indicate that a user is having difficulty typing a response. Out of context input can indicate an interaction problem with an automated system which may be aggravated by the free form nature of a text exchange modality. A user repetitively providing out of context input may benefit from switching to a more directed interface such as dialogue driven and contextually restrained voice interface.

Conditions associated with a speech modality that are shown in table include recognition accuracy problems and problems with a low quality voice channel. Recognition accuracy problems can result from a speaker who speaks in an unclear fashion or has a strong dialect not easily understood by voice server . Additionally many name street addresses and other often unique words or phrases are difficult for a voice server to recognize. Additionally a low quality voice channel between interface and server can be problematic for a voice modality but less so for a text exchange modality.

In one embodiment detection of a problem condition can result in a modality switching action being immediately triggered. In another embodiment a set of weights or problem points and thresholds can be established where modality switching actions only occur after a sufficient quantity of problem points are accrued to reach or exceed one or more action thresholds. Table provides an example of a table that associates different thresholds with different switching actions.

As shown a switching action can prompt a user to switch modalities or can occur automatically. A switching action can also switch from automated interactions with the voice server to live interactions with agent . Additionally a switching action can either disable an existing communication modality or not depending on circumstances. For example when a voice server is having difficulty understanding speech input received form interface an additional and simultaneous text exchange channel can be opened so that input output can be sent received by either interface and or . When simultaneously operational interface and can operate upon the same or different devices and within a same e.g. multi mode interface or different interface.

The voice server can include a text input API which is typically used by developers system maintainers and or trainers of a speech recognition engine. This set of APIs which are typically not available or accessible within a production environment can be enabled to permit the voice server to directly consume text which requires considerably fewer computing resources than those needed to process voice input which server typically receives.

As shown client can send a request to Chatbot server to initialize a text modality channel. Chatbot server can send a channel initialization message to voice server to establish a session. Server can positively respond causing a channel to be established between servers and . Chatbot server can then establish the requested text channel with client . After step the Chatbot server can send a request to application server which causes a speech enabled application to be instantiated. That is application markup can be conveyed to Chatbot server for execution.

Application initiated prompt can occur when the ChatBot Server executes the speech enabled application . Server can convert markup provided by application into pure text represented by text prompt which is sent to client . For example prompt can be written in markup and can include 

The voice server can include a text input API which is typically used by developers system maintainers and or trainers of a speech recognition engine. This set of APIs which are typically not available or accessible within a production environment can be enabled to permit the voice server to directly consume text which requires considerably fewer computing resources than those needed to process voice input which server typically receives.

As shown client can send a request to Chatbot server to initialize a text modality channel. Chatbot server can send a channel initialization message to server which uses the text input API. Server can positively respond causing a channel to be established between servers and . Chatbot server can then establish the requested text channel with client .

A prompt can be sent from server to server over the voice channel. Server can convert markup provided by server into pure text represented by text prompt which is sent to client . For example prompt can be written in markup and can include 

Chatbot server can then infer a potential interaction problem that can be alleviated by shifting modalities. For example long delays between user input and long text input strings can indicate that it would be easier for a user to interact using a voice modality. A modality switching prompt can be conveyed to client which permits a user to either continue using the text exchange modality or to switch to a voice modality. Appreciably different actions can be taken when a modality problem is detected by the Chatbot server . For example a user can be prompted to switch modalities a modality switch can automatically be performed and a switch between the voice server and a human agent can occur along with any related modality switch. Additionally different problems can cause an actual switch to occur or can cause an additional channel of communication to be opened without closing an existing channel.

Assuming the user opts to switch modalities a switch code to that effect can be conveyed to the Chatbot server . A telephone number for a voice device can be optionally provided to server by the user. The telephone number can also be automatically looked up from a previously stored profile or dialogue session store. Once the Chatbot server finds the number it can call the voice client thereby establishing a voice channel. The original channel with client can then be optionally closed . That is concurrent text and voice input output from each client is permitted for a common communication session.

Voice input can be conveyed from voice client to Chatbot server which relays the voice input to voice server . Voice server can speech recognize the input and provide recognition results to the Chatbot server . The executing speech enabled application can apply application logic to the results which generates markup which is conveyed to voice server . Voice output can be generated from the markup which is conveyed through Chatbot server to voice client as voice output .

Eventually client can send an end session request to Chatbot server which closes the channel to the voice server as well as the channel to the voice client .

The communication device can be any communication device linking a customer to network . Devices can include for example mobile telephones line based phones computers notebooks computing tablets personal data assistants PDAs wearable computing devices entertainment systems interactive media devices and the like. Specific categories of devices include a text exchange device a voice communication device and a multi mode device .

A text exchange device is a computing device capable of real time interactive text exchanges. These text exchanges include online chatting instant messaging and text messaging. A communication device can be any device capable of real time voice communication over network . This includes VoIP based communication traditional circuit switched communications two way radio communications and the like. A multi mode device is a device capable of engaging in text exchanges and in voice communications. Some multi mode devices are restricted to one mode of communication at a time while others are able to communicate across multiple modes concurrently.

Chatbot server can be a VoiceXML server or equivalent device that dynamically converts text exchange messages from device to messages consumable by voice server . Use of a text input API which lets voice server accept text may permit text from device to be directly consumed by voice server . Chatbot server can also dynamically convert output from voice server to output consumable by the speech application and then making it presentable within interface .

For each managed communication session the Chatbot server can instantiate a Chatbot object . The Chatbot object can include a SIP servlet and one or more interpreters such as a Call Control Extensible Markup Language CCXML interpreter a Voice Extensible Markup Language VoiceXML interpreter an Extensible Hypertext Markup Language XML plus voice profiles X V interpreter a Speech Application Language Tags SALT interpreter a Media Resource Control Protocol MCRP interpreter a customized markup interpreter and the like. The SIP servlet can map incoming SIP requests to appropriate interpreters.

A switching engine of server can allow a customer to switch modalities in a manner transparent to an executing speech application. For example the customer can switch from a text exchange interface to a voice interface during a communication session. This switching can cause a text exchange channel to close and a voice channel to be established. The Chatbot server can trigger text input API to be utilized or not depending on a type of input that is conveyed over channel . In one embodiment a data store can include information that facilitates switching such as storing telephone numbers associated with voice device associated with voice interface .

The conversion engine of server can perform any necessary conversions to adapt output from text exchange device to input consumable by voice server . Typically no significant conversions are necessary for text consumed by the voice server which provides access to text mode interaction functions via API . Appreciably text mode interaction functions are typically used by developers during a testing and development stage but are being used here at runtime to permit the voice server to directly handle text. For example the Internet Engineering Task Force IETF standard Media Resource Control Protocol version 2 MRCPv2 contains a text mode interpretation function called INTERPRET for the Speech Recognizer Resource which would permit the voice server to directly handle text.

The application server will typically generate voice markup output such as VoiceXML output which a voice server converts to audio output. The conversion engine can extract text content from the voice markup and can convey the extracted text to communication device over channel .

Application server can be an application server that utilizes modular components of a standardized runtime platform. The application server can represent a middleware server of a multi tier environment. The runtime platform can provide functionality for developing distributed multi tier Web based applications. The runtime platform can also include a standard set of services application programming interfaces and protocols. That is the runtime platform can permit a developer to create an enterprise application that is extensible and portable between multiple platforms. The runtime platform can include a collection of related technology specifications that describe required application program interfaces APIs and policies for compliance.

In one embodiment the runtime platform can be a JAVA 2 PLATFORM ENTERPRISE EDITION J2EE software platform. Accordingly the application server can be a J2EE compliant application server such as a WEBSPHERE application server from International Business Machines Corporation of Armonk N.Y. a BEA WEBLOGIC application server from BEA Systems Inc. of San Jose Calif. a JBOSS application server from JBoss Inc. of Atlanta Ga. a JOnAS application server from the ObjectWeb Consortium and the like. The runtime platform is not to be construed as limited in this regard and other software platforms such as the .NET software platform are contemplated herein.

The IVR application can be an application that permits callers to interact and receive information from a database of an enterprise server . Access to the voiceXML server which has been extended for Chatbot can accept user input using touch tone signals voice input and text input. The IVR application can provide information to the user in the form of a single VoiceXML application that can be used by any modality including DTMF voice and chat. The voice markup can also be directly conveyed to conversion engine where it is converted to text presentable in interface .

The IVR application can present a series of prompts to a user and can receive and process prompt responses in accordance with previously established dialogue menus. Speech processing operations such as text to speech operations speech to text operations caller identification operations and voice authorization operations can be provided by a remotely located voice server . Without the intervention of Chatbot server IVR application would be unable to interact with a text exchange device since it lacks native coding for handling text exchange input output.

The present invention may be realized in hardware software or a combination of hardware and software. The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also may be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

The present invention may be realized in hardware software or a combination of hardware and software. The present invention may be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also may be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

