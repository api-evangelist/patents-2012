---

title: Systems and methods for mask adjustment in 3D display
abstract: Certain embodiments relate to systems and methods for presenting a stereoscopic, 3-dimensional image to a user. The system may comprise a mobile device having a camera and a pixel-selective mask overlaying a display. The system may perform facial and object recognition techniques to determine the location of the user's eyes. Subsequently, the system may adjust the mask so as to maintain an optimal stereoscopic effect for the user, regardless of the user's position.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09648310&OS=09648310&RS=09648310
owner: QUALCOMM Incorporated
number: 09648310
owner_city: San Diego
owner_country: US
publication_date: 20120224
---
This application claims the benefit under 35 U.S.C. Section 119 e of commonly assigned U.S. Provisional Patent Application Ser. No. 61 557 800 filed on Nov. 9 2011 entitled SYSTEMS AND METHODS FOR MASK ADJUSTMENT IN 3D DISPLAY TECHNOLOGY which application is incorporated by reference herein in its entirety.

The systems and methods disclosed herein relate generally to the display of three dimensional images to a user possibly from a mobile device.

Current 3D displays such as may be found on handheld devices may use a mask to obscure odd pixels from the right eye and to obscure even pixels from the left eye or vice versa . By obscuring pixels the system may selectively display each image of a stereoscopic image pair to the user s eyes. Unfortunately separation of stereoscopic image pairs in this manner may impose undesired constraints upon the user. Particularly the location at which the 3D image may be visible to the user may be very limited. This location referred to herein as a sweet spot or stereoscopic focus position may comprise a very narrow range of positions. The stereoscopic focus position may generally be located at a point along a vector normal to the display and may depend upon the spacing between the viewer s eyes. There exists a need for a more versatile means for comfortably presenting a user with a 3D stereoscopic effect.

Using a device with a very limited stereoscopic focus position may impose considerable strain upon the viewer s eyes arms back and neck. Accordingly there is a need for an economic and efficient system to adjust the stereoscopic focus position based upon the user s position relative to the device.

Certain embodiments contemplate a computer implemented method for rendering a stereoscopic effect for a user. The method may comprise receiving an image the image containing a portion of the user s face determining a location corresponding to the user s eyes determining a width between the user s eyes based on the image and moving a stereoscopic focus position from a first position to a second position by adjusting a mask on a 3D display based on the first location and the width.

In some embodiments the second position corresponds to the location of the user s eyes. In some embodiments the first position is further from the 3D display than the second position and adjusting the mask comprises moving the mask closer to the 3D display. In some embodiments adjusting the mask comprises modifying a distance between separations within the mask. In some embodiments the step of determining the location corresponding to the user s eyes is based on the image. In some embodiments the step of determining the location of the user s eyes comprises retrieving location information from memory.

Certain embodiments contemplate a device for rendering a stereoscopic effect for a user the device comprising a camera a display configured to display a stereoscopic image pair and a mask over the display. The device may also comprise a module configured to receive an image from the camera the image containing a portion of the user s face a module configured to determine a location corresponding to the user s eyes a module configured to determine a width between the user s eyes based on the image and a module configured to move a stereoscopic focus position from a first position to a second position by adjusting the mask based on the first location and the width.

In some embodiments the second position corresponds to the location of the user s eyes. In some embodiments the first position is further from the 3D display than the second position and adjusting the mask comprises moving the mask closer to the 3D display. In some embodiments adjusting the mask comprises modifying a distance between separations within the mask. In some embodiments the step of determining the location corresponding to the user s eyes is based on the image. In some embodiments the step of determining the location of the user s eyes comprises retrieving location information from memory.

Certain embodiments contemplate a non transitory computer readable medium comprising instructions configured to cause one or more computer systems to perform a method. The method may comprise receiving an image the image containing a portion of the user s face determining a location corresponding to the user s eyes determining a width between the user s eyes based on the image and moving a stereoscopic focus position from a first position to a second position by adjusting a mask on a 3D display based on the first location and the width.

In some embodiments the second position corresponds to the location of the user s eyes. In some embodiments the first position is further from the 3D display than the second position and adjusting the mask comprises moving the mask closer to the 3D display. In some embodiments adjusting the mask comprises modifying a distance between separations within the mask. In some embodiments the step of determining the location corresponding to the user s eyes is based on the image. In some embodiments the step of determining the location of the user s eyes comprises retrieving location information from memory.

Certain embodiments contemplate a device for rendering a stereoscopic effect for a user. The device may comprise a camera means for displaying a stereoscopic image pair means for masking the display and means for receiving an image from the camera. The image may contain a portion of the user s face. The device may also comprise means for determining a location corresponding to the user s eyes means for determining width between the user s eyes based on the image and means for moving a stereoscopic focus position from a first position to a second position by adjusting the masking means based on the first location and the width.

In some embodiments the displaying means comprises a display the masking means comprises a mask the receiving means comprises a software module the determining a location means comprises a software module the determining a width means comprises a software module and the moving means comprises a software module configured to operate an actuator.

In some embodiments the second position corresponds to the location of the user s eyes. In some embodiments the first position is further from the 3D display than the second position and adjusting the mask comprises moving the mask closer to the 3D display. In some embodiments adjusting the mask comprises modifying a distance between separations within the mask. In some embodiments the step of determining the location corresponding to the user s eyes is based on the image. In some embodiments the step of determining the location of the user s eyes comprises retrieving location information from memory.

Implementations disclosed herein provide systems methods and apparatus for generating a stereoscopic image with an electronic device having one or more imaging sensors. The present embodiments further contemplate monitoring the position of a user s eyes and adjusting a mask over a display of the electronic device in response. One skilled in the art will recognize that these embodiments may be implemented in hardware software firmware or any combination thereof.

In the following description specific details are given to provide a thorough understanding of the examples. However it will be understood by one of ordinary skill in the art that the examples may be practiced without these specific details. For example electrical components devices may be shown in block diagrams in order not to obscure the examples in unnecessary detail. In other instances such components other structures and techniques may be shown in detail to further explain the examples.

It is also noted that the examples may be described as a process which is depicted as a flowchart a flow diagram a finite state diagram a structure diagram or a block diagram. Although a flowchart may describe the operations as a sequential process many of the operations can be performed in parallel or concurrently and the process can be repeated. In addition the order of the operations may be re arranged. A process is terminated when its operations are completed. A process may correspond to a method a function a procedure a subroutine a subprogram etc. When a process corresponds to a software function its termination may correspond to a return of the function to the calling function or the main function or a similar completion of a subroutine or like functionality.

Those of skill in the art will understand that information and signals may be represented using any of a variety of different technologies and techniques. For example data instructions commands information signals bits symbols and chips that may be referenced throughout the above description may be represented by voltages currents electromagnetic waves magnetic fields or particles optical fields or particles or any combination thereof.

In configuration mobile device is rotated 180 degrees from the position in configuration . As illustrated in the configuration of the mobile device may comprise a viewscreen and a camera . The viewscreen may comprise a mask to selectively obscure various pixels as described in greater detail below. This masking may facilitate generation of the stereoscopic effect from the user s perspective. The mask may comprise any suitable material for preventing the user from viewing the image pixels. Camera may be used for video conferencing image capture etc. and may be placed relative to viewscreen for these purposes.

Certain of the present embodiments contemplate using a camera such as camera to determine the location of and the spacing between the viewer s eyes. These embodiments further contemplate adjusting a mask located on or near screen such that the stereoscopic focus position tracks the movement of the user s eyes. The location of the user s eyes may be determined using facial and or object recognition techniques applied to video or images captured using camera . The system may use a face tracking algorithm to determine the spacing between the viewer s eyes and the location of the viewer s eyes relative to the 3D display . In addition to the face tracking algorithm the system may use an eye detection algorithm such as may be found in blink detection best shot algorithms. Some mobile devices such as mobile phones may include blink detection best shot algorithms as part of an application programming interface API or other common repository of software tools. Once the system determines the position of the user s eyes the system may then dynamically adjust the mask over screen such that the stereoscopic focus position follows the location of the user s eyes. For example if the stereoscopic focus position were originally located at the position the system may subsequently move the stereoscopic focus position to the position so as to include the user s eyes. The stereoscopic focus position may be moved both along the vector and along an offset orthogonal to the vector by adjusting the mask using techniques such as those described in greater detail below.

As the viewer moves to the left or right of the display center the location of the mask with respect to the even and odd pixels may be moved left or right to keep only the even or odd pixels exposed to the left or to the right eye. As the viewer moves closer further from the display or to account for different eye spacing between different viewer s eyes the mask may be moved closer or further from the display to correctly mask the pixels. Alternatively the width of the mask can be changed to prevent the viewer s eyes from seeing the unintended pixels. Finally a combination of mask width and distance adjustments can also be used to place the sweet spot at a more optimal position.

By dynamically tracking the location and eye spacing of the viewer to adjust the location of the mask it is possible to significantly increase the size of the 3D viewing area. This may reduce strain on the viewer. Furthermore the system improves the performance of applications which anticipate the user moving their head relative to the display . For example applications which present objects in a 3D environment from a different view depending on the relative position of the user will present a more effective image using the present embodiments.

Certain of the present embodiments contemplate a mask adjustment system which includes a facial identification system. The facial identification system may determine the position of the user s eyes and the relative spacing of the eyes relative to one another. The system may then adjust the mask to reorient the stereoscopic focus position to a position more favorable for creating the 3D effect for the user. As the user moves the system may update the stereoscopic focus position in real time to track the user s movement. In this manner the system may provide a continuous 3D effect for the user even as the user moves relative to the 3D display. Although face and eye identification may be determined using dedicated hardware certain embodiments contemplate repurposing existing functionality on a mobile device for use with the mask adjustment system. For example if a cell phone already includes firmware or software for performing face and eye identification as part of a red eye removal process the system may reuse these components as part of the mask displacement operations. Similarly rather than including a new dedicated camera for the mask adjustment the system may reuse a general purpose camera already present on the mobile device such as a camera on a mobile phone which may already face the user when the user views the screen.

Some embodiments may consider the relative motion between the user and the mobile device when recalibrating the location of the mask. That is natural hand motion may continuously vary the relationship between the user and the display. Accordingly the system may also review a sequence of image captures to determine the variations in the relative position as a consequence of hand motion as well as gyroscopic and acceleration information.

At step the system may determine the distance between the user s eyes. In some embodiments this step may be unnecessary if the distance between the user s eyes was previously recorded in which case the system may refer to the previously recorded value . In some embodiments the system may maintain profiles of different users which include information regarding the particular user s distance between their eyes. The width between the user s eyes may be absolute or relative . An absolute determination of width would determine the physical width between the user s eyes which does not change with the user s position. Such an absolute determination may be assumed or inferred such as from an average over many user faces. Alternatively the user may calibrate the system by taking a picture of their face when the camera is a known distance from their face. The absolute determination of width could then be inferred from this image capture by comparing the observed width with the known distance to the user s face . A relative determination in contrast would determine the distance between the user s eyes as the user s eyes appear from the position of the camera. That is the user s eyes will appear further apart when the user s face is closer to the camera. Conversely the user s eyes appear closer together when the user s face is further from the camera. Comparison of the relative and absolute width determinations may be used to infer the distance from the user s face to the camera. The relative position of the camera and screen may then be used to infer the distance from the user s face to the screen. Use of these image processing techniques or other location and width determining means may be readily determined by one skilled in the art.

At step the system may determine the distance from the display to the user s eyes. As mentioned the process may use facial tracking techniques in conjunction with knowledge of the relative position of the camera on the display device . The system may thereby determine the position of the user s eyes relative to the display for example by comparing the absolute and relative widths of the user s eyes as discussed above.

At step the system may determine widths separating portions of the mask and or a mask translation vector necessary to reorient the stereoscopic focus position to the user s eyes. In some embodiments the process may instead end without performing this step if the user s eyes have not moved a sufficient distance since a previous adjustment of the mask. The system may consider the relative position of the camera and display on the device when determining the translation and separation values for the mask. As discussed above the translation of the mask may be substantially less than the translation of the user s face. In some embodiments the relationship between translation of the user s face and translation of the mask may be encoded as a proportional function. For example movement of the mask may be a scaled percentage of the movement of the user s face. Accordingly step may simply comprise referencing a lookup table of values which indicate translation vectors and separation widths which correspond to a particular distance from the user s face to the screen.

At step the system may then implement the determined mask adjustments by directing one or more actuators to translate the mask and to adjust the width of the mask s separations as determined at step . The actuators may comprise motors piezoelectric voice coil micro mechanical conventional electric etc. servos levers liquid crystal electrodes or any other means for adjusting the position of the mask. provide a plurality of means for masking a display such as physical barriers liquid crystal components polarized barriers etc. also provide a plurality of means for moving a stereoscopic focus position such as piezoelectric motors voice coil motors MEMs micro mechanical system motors conventional electric motors or the like.

Those having skill in the art will further appreciate that the various illustrative logical blocks modules circuits and process steps described in connection with the implementations disclosed herein may be implemented as electronic hardware computer software or combinations of both. To clearly illustrate this interchangeability of hardware and software various illustrative components blocks modules circuits and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application but such implementation decisions should not be interpreted as causing a departure from the scope of the present invention. One skilled in the art will recognize that a portion or a part may comprise something less than or equal to a whole. For example a portion of a collection of pixels may refer to a sub collection of those pixels.

The various illustrative logical blocks modules and circuits described in connection with the implementations disclosed herein may be implemented or performed with a general purpose processor a digital signal processor DSP an application specific integrated circuit ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor but in the alternative the processor may be any conventional processor controller microcontroller or state machine. A processor may also be implemented as a combination of computing devices e.g. a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration.

The steps of a method or process described in connection with the implementations disclosed herein may be embodied directly in hardware in a software module executed by a processor or in a combination of the two. A software module may reside in RAM memory flash memory ROM memory EPROM memory EEPROM memory registers hard disk a removable disk a CD ROM or any other form of non transitory storage medium known in the art. An exemplary computer readable storage medium is coupled to the processor such the processor can read information from and write information to the computer readable storage medium. In the alternative the storage medium may be integral to the processor. The processor and the storage medium may reside in an ASIC. The ASIC may reside in a user terminal camera or other device. In the alternative the processor and the storage medium may reside as discrete components in a user terminal camera or other device.

Headings are included herein for reference and to aid in locating various sections. These headings are not intended to limit the scope of the concepts described with respect thereto. Such concepts may have applicability throughout the entire specification.

The previous description of the disclosed implementations is provided to enable any person skilled in the art to make or use the present invention. Various modifications to these implementations will be readily apparent to those skilled in the art and the generic principles defined herein may be applied to other implementations without departing from the spirit or scope of the invention. Thus the present invention is not intended to be limited to the implementations shown herein but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.

