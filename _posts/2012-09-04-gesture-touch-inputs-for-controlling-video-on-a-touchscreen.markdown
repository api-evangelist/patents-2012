---

title: Gesture touch inputs for controlling video on a touchscreen
abstract: In general, this disclosure describes novel techniques for controlling video content on a computing device, such as a mobile computing device. For example, a computing device may execute a media application that provides a video output to a presence-sensitive screen of the computing device. During execution of the media application, the presence-sensitive screen may receive a gesture touch input that has motion with respect to the presence-sensitive screen. The computing device may then rewind or fast forward the video output based at least in part on the gesture touch input. The computing device may display, during the rewinding or fast forwarding of the video output, a plurality of frames of the video output concurrently on the presence-sensitive screen in lateral motion corresponding to the rewinding or fast forwarding.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09454303&OS=09454303&RS=09454303
owner: Google Inc.
number: 09454303
owner_city: Mountain View
owner_country: US
publication_date: 20120904
---
This application claims the benefit of priority to U.S. Provisional Application No. 61 647 942 filed May 16 2012 the entire content of which is hereby incorporated by reference.

Mobile computing devices with touchscreens such as smartphones tablet computers and portable media players have grown in popularity as platforms on which to watch video. A mobile computing device may have a media applications or a video application loaded on it that plays videos. The mobile computing device may be used to download videos.

In general this disclosure includes potentially more easy and intuitive new user interface features for video on a mobile computing device or any device with a touch sensitive screen or interface e.g. a touchscreen . For example through implementation of one or more techniques of the present disclosure a user can rewind or fast forward a video simply by making a rightward or leftward swiping gesture across the touchscreen of a mobile computing device.

In one example a method includes executing by a computing device a media application that provides a video output to a presence sensitive screen of the computing device. The method further includes receiving by the presence sensitive screen during execution of the media application a gesture touch input that has motion with respect to the presence sensitive screen. The method further includes rewinding or fast forwarding the video output based at least in part on the gesture touch input. The method further includes displaying during the rewinding or fast forwarding of the video output a plurality of frames of the video output concurrently on the presence sensitive screen in lateral motion corresponding to the rewinding or fast forwarding.

In another example a method includes detecting by a presence sensitive screen during execution of a media application a gesture touch input that has motion with respect to the presence sensitive screen on which a video output is being displayed. The method further includes displaying on the presence sensitive screen a plurality of frames from the video output the frames being located in advance of a current frame of the video output at the time the gesture touch input is detected each of the frames being separated by a frame interval and the interval being a function of a speed of motion of the gesture touch input wherein the presence sensitive screen depicts at least two of the frames concurrently and depicts the frames moving across the presence sensitive screen in lateral motion to provide the user with a perception of advancing video footage. The method further includes advancing a counter position indicating a currently depicted frame of the video output based on the gesture touch input and in coordination with the displaying of the plurality of frames from the video output. The method further includes resuming the video output based on the advanced counter position.

In another example a computing device includes at least one processor at least one data storage device a presence sensitive screen configured for detecting touch inputs and machine readable code stored on the at least one data storage device comprising executable instructions that are executable by the at least one processor. The executable instructions include executable instructions for providing a video output to the presence sensitive screen executable instructions for receiving a gesture touch input on the presence sensitive screen and executable instructions for determining a speed of the motion of the gesture touch input across the presence sensitive screen. The executable instructions also include executable instructions to rewind or fast forward the video output if the gesture input has either a rightward motion or a leftward motion with respect to the presence sensitive screen wherein the rewinding or fast forwarding of the video output is performed at a speed based at least in part on the speed of the motion of the gesture input. The executable instructions also include executable instructions to display during rewinding or fast forwarding the video output a frame carousel comprising a plurality of frames of the video output on the presence sensitive screen with two or more of the frames displayed concurrently in different portions of the presence sensitive screen and in lateral motion across the presence sensitive screen corresponding to the rewinding or fast forwarding of the video output.

In another example a computer readable storage medium includes executable instructions for causing at least one processor of a computing device to perform operations. These include providing a video output to the presence sensitive screen receiving a gesture touch input on the presence sensitive screen and determining a speed of the motion of the gesture touch input across the presence sensitive screen. These also include rewinding or fast forwarding the video output if the gesture touch input has either a rightward motion or a leftward motion with respect to the presence sensitive screen. These also include displaying during rewinding or fast forwarding the video output a frame carousel comprising a plurality of frames of the video output displayed concurrently on the presence sensitive screen in lateral motion across the presence sensitive screen corresponding to the rewinding or fast forwarding of the video output wherein a speed of the frame carousel is based at least in part on the speed of the motion of the gesture touch input.

The details of one or more embodiments are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

In accordance with common practice the various described features are not drawn to scale and are drawn to emphasize one or more features relevant to the present application. Like reference characters denote like elements throughout the figures and text.

While depicts example computing device in the form of a smartphone other touchscreen enabled computing devices may be used equivalently such as tablet computers netbook computers laptop computers desktop computers processor enabled televisions personal digital assistants PDAs touchscreen devices connected to a video game console or set top box or any other computing device that has a touchscreen and is enabled to play or execute a media application or other video application or to display a video output or video content. The terms video content and a video output may be used interchangeably throughout this disclosure.

Display window A is a player stage or a graphical user interface element generated by the media application on an area of touchscreen in which the media application displays the video content or video output. The video content being shown in display window A is depicted in a simplified view that includes a character A that may be part of a personally produced video a movie a television show an advertisement a music video or other type of video content. The video content may be provided by a media application which may also provide an audio output synchronized with the video output. The video content as depicted is merely an example and any video content may be displayed by the media application. The media application may for example be the mobile YouTube application or app provided by Google Inc. of Mountain View Calif. and its subsidiary YouTube LLC of San Bruno Calif. and which may be any of a number of versions for running on different mobile operating systems. The media application may source the video content from any of a variety of sources including streaming or downloading from a server or data center over a network or playing a video file stored locally on computing device .

Touchscreen may be a presence sensitive screen in that it is enabled to detect touch inputs from a user including gesture touch inputs that include motion with respect to the presence sensitive screen and translate those gesture touch inputs into corresponding inputs made available to the operating system and or one or more applications running on the device. Various embodiments may include a touch sensitive screen configured to detect touch gesture inputs or other types of presence sensitive screen such as a screen device that reads gesture inputs by visual acoustic remote capacitance or other type of signals and which may also use pattern recognition software in combination with user input signals to derive program inputs from user input signals. Display window A is depicted in a simplified form in including a triangle icon which may be displayed as a graphical user interface icon equivalent of a play button that may be displayed by the media application on top of or in place of a frame of ordinary video content while the video content is paused or is just in the process of being opened or is otherwise buffering for example.

In this example during playback of the video content on display window A computing device may accept a touch input in the form of a tap input with a simple touch on touchscreen without any motion along the surface of or relative to touchscreen . This simple tapping touch input without motion along the surface of touchscreen may be contrasted with a gesture touch input that includes motion with respect to the presence sensitive screen or motion along the surface of the touchscreen . The media application may detect and distinguish between simple tapping touch inputs and gesture touch inputs on the surface of touchscreen as communicated to it by the input detecting aspects of touchscreen and interpret tapping touch inputs and gesture touch inputs in different ways. Inputs and actions may be attributed to computing device throughout this disclosure with the understanding that various aspects of those inputs and actions may be received or performed by touchscreen the media application the operating system or any other software or hardware elements of or running on computing device . 

In the example of the media application also displays a timeline and a scrubber that occupies a position along timeline that indicates a corresponding proportional position of the currently displayed video frame relative to the entire duration of the video content. The media application s user interface elements may configure the timeline and scrubber to fade away during normal playback of the video content and to reappear when any of a variety of touch inputs are detected on touchscreen . In other examples the media application may have a timeline and or scrubber and or play button icon that have different positions than those depicted here or that function differently from what is described here.

Scrubber may be selected by a touch input on scrubber on touchscreen and manually moved along the timeline to jump to a different position within the video content. Finding and successfully manipulating the scrubber on the timeline can be challenging on a mobile device particularly a smartphone where the touchscreen has a constrained size.

Scrubber is in the same position on timeline as depicted in . The user may initially contact the touchscreen in one position as shown with the position of finger A as depicted in but then move the finger A laterally along the surface of touchscreen so that the finger A retains contact with touchscreen while in motion with respect to touchscreen thereby forming a gesture touch input on touchscreen . This gesture touch input may be referred to as a swipe or a swiping gesture.

The user may make a swiping gesture toward the left side of the touchscreen as depicted at arrow or toward the right side of the touchscreen as depicted at arrow . Arrows and are therefore intended as abstract representations of the motion of the user s finger A relative to touchscreen thereby forming a gesture touch input. As depicted in the user may swipe her finger A over the portion of touchscreen in which character A appears within the video content currently being displayed in display window B in the case of a rightward swiping gesture depicted at . Computing device responds to these swiping gesture inputs by fast forwarding or rewinding the video content in this example.

The media application running on computing device therefore uses these swiping gesture touch inputs as represented by the motion of the user s finger A in the directions of arrows or as inputs to initiate a rewinding or a fast forwarding of the video content. Specifically a swiping gesture touch input in the direction of arrow may initiate a fast forwarding of the video content while a swiping gesture touch input in the direction of arrow may initiate a rewinding of the video content in this example although in other examples the reverse may be used or any other direction or type of gesture touch inputs may be used to initiate rewinding or fast forwarding of the video output or video content. The media application may also synchronize an audio output with the video output during the rewinding or fast forwarding of the video output.

While the description above refers to swiping gestures toward the left side and the right side of touchscreen it will be well understood that the left and right sides of touchscreen may be relative to the orientation of computing device or of the video output from the media application. Computing device may incorporate sensors that detect its orientation and it may present the video output in a corresponding orientation to be right side up for the user. This context dependent orientation may also be incorporated for the gesture touch inputs so that the gesture touch inputs remain intuitive for the user and a leftward swiping gesture i.e. a touch input with a leftward motion across touchscreen always initiates a fast forwarding of the video output and a rightward swiping gesture i.e. a touch input with a rightward motion across touchscreen always initiates a rewinding of the video output or whatever other relation between gesture touch inputs and motion control of the video output is in use regardless of the orientation of computing device . Or in other examples as indicated above the opposite input relation may be implemented so that a gesture touch input with a leftward motion across touchscreen initiates a rewinding of the video output and a gesture touch input with a rightward motion across touchscreen initiates a fast forwarding of the video output.

Therefore touchscreen may have a current left right orientation at a particular time when touchscreen receives the gesture touch input and rewinding or fast forwarding the video output based at least in part on the gesture touch input includes rewinding the video output in response to the gesture touch input having a motion toward a right side of touchscreen in the current left right orientation and fast forwarding the video output in response to the gesture touch input having a motion toward a left side of touchscreen in the current left right orientation. Gesture touch inputs that are not very directly leftward or rightward or otherwise relatively ambiguous may still be interpreted by measuring and accepting the overall component of motion along the left right axis of touchscreen . A threshold of sufficient ambiguity of direction or of motion in general such as if the detected motion has a relatively very minor total displacement across the real estate of touchscreen may also be imposed so that sufficiently short or ambiguous touch inputs are not translated into controls to initiate a rewind or fast forward in various examples.

Any of various aspects of interpreting the swiping gesture touch inputs translating those inputs into rewind or fast forward inputs for the media application re orienting the video output and the orientations for the gesture touch inputs in response to a re orienting of the computing device may be handled by the media application itself by software specific to reading touch inputs on the touchscreen by the operating system of the computing device or by any combination of the operating system and or other software running on computing device or on computing resources accessible to computing device .

Computing device may therefore execute the media application that provides the video output to touchscreen such that touchscreen is enabled to receive a gesture touch input that has motion with respect to touchscreen and rewind or fast forward the video output based at least in part on the gesture touch input. Computing device may perform these functions or a portion of them by a method implemented in the media application for example. This media application may be bundled with or optimized for the operating system in an initial configuration of the computing device . The media application may be made be available for downloading onto computing device either from a vendor of the operating system or from a third party. Computing device may also perform these functions or a portion of them by a feature implemented in the operating system configured to execute on computing device in various examples. In this example this feature of the operating system may be configured to detect and interpret gesture touch inputs and other touch inputs on touchscreen and to communicate data about the gesture touch inputs and other touch inputs to a separate media application.

The media application also currently renders display window C such that the 104th frame depicted at and the 107th frame depicted at appear in sequence with the 100th frame in a carousel or film reel type view. While these are described as the 100th 104th and 107th frames these are merely representative numbers with the understanding that any number of frames including high numbers of frames are likely to be common in video outputs. In this example the media application may also render the original frame with highlighting a darker outline a different color or some other visual indication depicted here as a bold outlining for the user s reference to give the user context relative to the other frames being depicted. The position of the scrubber or playhead corresponding to the position of the original frame may also be marked with a highlighted line or other positional indication in or around timeline also to give the user reference or context as the frame reel moves away from the position at which the fast forward or rewind was initiated.

The view of display window C as depicted in is intended as a momentary snapshot during the fast forwarding of the video output with the carousel or reel of frames moving leftward in the direction of arrow . also depicts a representative set of frame intervals between the frames. The frame intervals may be different in different examples and may be based on the speed of the gesture touch input in various examples. In one example the frame interval may decrease over time until it dwindles to no interval absent a subsequent user input at which point the device may resume normal playback for example. In other examples the frame interval may remain constant or may increase over time. The frame carousel itself may move at a constant rate or at a decreasing rate and in either case may be combined with a frame interval that is constant over time or that decreases over time. The speed of the frame carousel may also be proportional to the speed of the gesture input or otherwise a function of the speed of the gesture input. The speed of the gesture input may therefore be used to influence the frame interval the speed of motion of the frame carousel neither or both in different examples.

Arrows and as with arrows and in are intended as abstract indications of the motion of the sequence of frames and not as part of the video output being rendered in display window C or otherwise on touchscreen . Arrow shows the direction of motion of the sequence of frames in the alternative case in which a leftward swiping gesture touch input had been made initiating a rewinding of the video output rather than a fast forwarding. During the rewinding or the fast forwarding of the video output therefore computing device concurrently displays a plurality of frames of the video output on the touchscreen in lateral motion corresponding to the rewinding or fast forwarding.

The swipe gesture touch input therefore respects a finger motion physics user experience for scrolling the frame carousel with an eventual slowdown of the scrolling action. This user interface feature may be implemented by the mobile operating system running on computing device by the media application or in part by aspects of both or any other combination of the operating system and other software running on computing device . In other examples the intermittency rate may alter over time with some other pattern and the frame carousel may come to rest before the intermittency rate or frame interval drops to the point of omitting a certain minimum number of frames. Computing device may also enable a user to enter a simple input to undo the fast forwarding or rewinding in case the user changes her mind or initiated the fast forwarding or rewinding by accident. For example computing device may enable the user to tap a region of the display window C outside of the video frames and computing device may accept this outside tap as an input for undoing the fast forwarding or rewinding and returning to normal play resuming from the frame at which play was interrupted.

In the example as depicted in the frame speed i.e. the speed of the motion of the sequence of frames and additional frames rendered in the carousel view may therefore slow down over time and may eventually stop unless it is reset by a subsequent gesture touch input. In other examples the friction emulating user interface feature may be omitted and the fast forwarding or rewinding may progress indefinitely until interrupted by a subsequent input or by reaching the end or beginning for a rewind of the video content in the style of rewinding or fast forwarding of a video on a traditional VCR DVD player or Blu Ray player. In these examples the concurrently displayed frames may be displayed with a frame interval that is held constant until interrupted by a subsequent user input or until the video content runs out of frames to display.

The frame speed may also be determined based at least in part on the speed of the swiping gesture touch input. The computing device may determine the speed of the motion of the gesture touch input when the user swipes her finger A across the touchscreen as shown in . The computing device may then rewind or fast forward the video output at a frame speed based on the determined speed of the motion of the gesture touch input. The frame speed based on the determined speed of the motion of the gesture touch input in the sense that it is based at least in part on the determined speed of the motion of the gesture touch input as well as being based at least in part on other factors such as a constant of proportionality between the two a relation of proportionality between the two a range of speeds bound by a minimum and or a maximum frame speed or other factors. The resulting variation in frame speed is illustrated between .

This much higher intermittency rate can be used with a frame carousel that is moving at the same rate as with a lower intermittency rate and still have a faster frame speed since it is sampling its way through the frames of the video content at a much faster rate. This allows faster fast forward or rewind speeds while still keeping the apparent motion of the frame carousel at a speed low enough to allow a user to glimpse the content of individual frames so the user can still evaluate individual frames to decide whether she has fast forwarded or rewound the video content to a desired segment. Keeping the apparent carousel speed relatively moderate may also pose a relatively easier burden on the graphics rendering capabilities of the computing device particularly if the device is relatively underpowered in its graphics rendering capability. In other examples the media application may render the frame carousel with the same intermittency rate but with faster apparent motion to achieve a faster frame speed or may use some combination of higher intermittency rate and faster apparent motion to achieve faster frame speed in response to faster swiping gesture touch inputs.

In various examples the media application may also use initial intermittency rates with any number of skipped frames between rendered frames from only one or two skipped frames to between three and eleven i.e. between the initial intermittency rates depicted in or any number above eleven. In various examples the media application may also reduce the number of skipped frames between rendered frames at any rate. While depicts the number of skipped frames dropping from three to two within the span of just three frames and depicts the number of skipped frames dropping from eleven to ten i.e. between the 100th frame and 112th frame then between the 112th frame and the 123rd frame also within the span of just three frames the media application may render two frames or ten or a hundred or any other number in a row before altering the number of skipped frames between rendered frames during the motion of the frame carousel corresponding to the rewinding or fast forwarding of the video content.

Computing device may also base the frame speed or at least the initial the frame speed of the rewinding or fast forwarding on the speed measured for the gesture touch input in a variety of different ways. In one implementation computing device may cause the frame speed to be directly proportional to the speed measured for the gesture touch input so that the frame speed rises proportionally to the speed of the gesture touch input across the surface of touchscreen in a directly linear way. In another implementation computing device may cause the frame speed to be exponentially proportional to the speed measured for the gesture touch input. In this case a moderately slow gesture touch input across the surface of touchscreen may result in only a very slow frame speed while only a moderately fast gesture touch input across the surface of touchscreen results in a fast frame speed and a fast gesture touch input causes an extremely fast frame speed. This implementation may make it easier for the user to learn to select anywhere from very slow to extremely fast frame speeds across a relatively narrow range of gesture touch input speeds. In still another implementation the frame speed may be directly proportional to the speed measured for the gesture touch input in a first part of a range of possible speeds for the gesture touch input while the frame speed is exponentially proportional to the gesture touch input speed in a second part of the range of possible speeds for the gesture touch input. Any of these implementations may be exclusive or a default setting or may be freely selectable by the user.

In various examples computing device or B which may be collectively referred to hereafter as computing device may therefore display a sequence of frames from a video application concurrently with different frames rendered on different portions of a display at the same time and in which the sequence of frames may be rendered with an apparent motion across the display. Each frame in the sequence may appear at one end of the frame carousel on one side of the display propagate in apparent motion within the frame sequence across the display and apparently disappear off the opposite side of the display. At each point in time during the rendering of the frame carousel the computing device renders different frames from the video sequence concurrently in different portions of the display. Over time computing device adjusts the position in which each of the frames is rendered thereby creating the impression of each of the frames moving across the display from one side to the other. This illustrates one way in which computing device may display during the rewinding or fast forwarding of the video output a plurality of frames of the video output concurrently on the presence sensitive screen in lateral motion corresponding to the rewinding or fast forwarding. The lateral motion of the frames across the display intuitively suggests to the user the fast forwarding or rewinding of the video output as one example of how the lateral motion of the frames corresponds to the fast forwarding or rewinding of the video output.

As shown in the user has once again placed her finger B in contact with touchscreen to enter a touch input. This time the user makes a simple tap or tapping touch input on a portion of touchscreen in which one of the frames in the frame carousel is currently rendered in particular frame i.e. the 150th frame of the video output . Computing device detects this tapping touch input and responds by stopping the fast forwarding of the video content and stopping the corresponding apparent motion of the frame carousel as rendered in display window E and returning to normal playback of the video content as further depicted in .

The video output may then resume its normal playback from this point. The video output may either automatically resume normal play or be in a paused state at this point and require another tap input on the paused content to resume normal play in different implementations. Computing device may therefore receive a new touch input in the form of a stationary tapping touch input that lacks motion with respect to the touchscreen and respond to this new touch input by interrupting or stopping the rewinding or fast forwarding of the video output and either pausing the video output or resuming normal playback of the video output. In the case of coming out of the carousel view in a paused state computing device may therefore also receive another tapping touch input that lacks motion with respect to touchscreen and respond to this touch input by resuming normal playback of the video output.

As also shown in scrubber is in the same more advanced position along timeline as in indicating the video content having advanced to a point further along in its running time. Computing device may also respond to various touch inputs in various ways from the carousel view. For example computing device may allow a user to enter additional gesture touch inputs on touchscreen during fast forwarding or rewinding to continue the fast forwarding or rewinding to accelerate or decelerate the fast forward or rewinding or to alternate between fast forwarding or rewinding or back and forth between them. Touchscreen may therefore receive at any time during rewinding or fast forwarding the video output a subsequent gesture touch input that has motion with respect to touchscreen and computing device may then rewind or fast forward the video output based on that subsequent gesture touch input.

A user may rewind or fast forward a video output while the video output is being streamed or downloaded by computing device over a network connection. If the fast forwarding surpasses the last cached frame the frame carousel may stop at the last available frame and show an icon indicating that the video content is still loading. Computing device may also actively arrange for a loading or caching order to facilitate fast forwarding while it is still in the process of streaming downloading caching or buffering the video content in various examples.

Computing device may generate and provide predictions of one or more frames that are imminently pending to render for an interspersed display of frames in the frame carousel during the rewinding or fast forwarding of the video output. Computing device may predict that a frame is imminently pending to render for the interspersed display of frames in the frame carousel if that frame is in order to be displayed within a relatively short period of time within a planned or predicted order in which computing device plans on displaying the frames within the frame carousel. This may be in an intermittent order that corresponds to a frictional slowing down of the user interface physics emulation or may be in an inertial rate that may have a constant intermittency rate. Specific measures of time considered imminent for this purpose may vary in different implementations and may be measured in anything from less than one millisecond to several seconds or more or may include anything from below the shortest period of time in which a human user is physically capable of noticing any change in her field of vision to the total predicted period of time required to rewind or fast forward the entirety of the video content.

Computing device may then modify the frame buffering process such as by rearranging the order in which it buffers or caches frames of the video content based on the predictions of the frames that are imminently pending to render to populate the frame carousel for the fast forwarding or rewinding of the video content. Computing device may then cache or buffer the frames intermediate to those it caches for the frame carousel out of order after the frames it caches to populate the frame carousel in a way that optimizes between frames with which to populate the frame carousel during fast forwarding and rewinding and the remaining frames to populate the full video content from a point in the middle of the frame content at which the user may resume normal playback of the video content.

Computing device may include operating system . Each of components and may be interconnected physically communicatively and or operatively for inter component communications. Operating system in various examples may control the operation of components of computing device . Computing device in this example further includes media application that is also executable by computing device . Operating system in one example facilitates the interaction of media application with processors memory network interface data storage device touchscreen and power source . As shown in media application may include video module . Media application and video module may each include program instructions and or data that are executable by computing device or by a processor thereof. For example media application and or video module may include computer executable software instructions that cause computing device to perform one or more of the operations and actions described in the present disclosure. For example operating system and media application may include code and or data that are stored on one or more data storage devices and that are read and executed or processed by one or more processors and may in the process be stored at least temporarily in memory .

In this illustrative implementation of computing device operating system may include an operating system kernel which may include various drivers including display driver . Display driver may process or handle certain fundamental or underlying functions for controlling what is displayed on touchscreen including for displaying video output in a display window for media application as well as for displaying user interface elements including timeline scrubber and the frame carousel as depicted in . Operating system may also interact with a set of libraries which may include various more or less standard specialized and or proprietary libraries such as a media framework which may also contribute to certain functions for controlling what is displayed on touchscreen .

In this illustrative implementation of computing device operating system may also interact with a runtime which includes various core libraries of its own as well as a virtual machine which may be the Dalvik virtual machine in one example implementation. Virtual machine may abstract certain lower level aspects and properties of operating system and allow higher level applications to be run on top of virtual machine so that software code in the higher level applications is compiled into bytecode to be executed by the virtual machine .

For example software for applications such as media application may be written in C which may be executable as native code by computing device or may also be written in Java then compiled to virtual machine executable bytecode to be executed by virtual machine . As one illustrative example libraries may include the Standard C Library libc which provides native support for C functions. In different implementations the operating system and or the virtual machine may be able to execute code written in various other languages such as Objective C C JavaScript Python Ruby Clojure or Go for example either natively or compiled into a virtual machine executable bytecode or compiled into an assembly language or machine code native to the CPU of computing device . Various examples may not use a virtual machine and use applications that run natively on the computing device or that use some other technique compiler interpreter or abstraction layer for interpreting a higher level language into code that runs natively on computing device .

In various examples computing device may also have various application programming interfaces APIs that are native to operating system and that run on top of operating system and which are intended to provide resources that automate or facilitate higher level applications that access the one or more APIs. These one or more APIs may include object libraries or other libraries toolsets or frameworks and may be associated with a native programming environment for writing applications. These may include a native API for detecting and interpreting gesture touch inputs and other touch inputs on touchscreen . In this example media application may be programmed in the native programming environment of an API or set of APIs that detect and interpret gesture touch inputs to touchscreen and are configured to interpret gesture touch inputs for initiating a rewind or fast forward of the video output.

Higher level applications such as media application may therefore make use of any of various abstractions properties libraries or lower level functions that are provided by any of operating system OS kernel display driver libraries media framework runtime core libraries virtual machine or other compilers interpreters frameworks APIs or other types of resources with which computing device is configured to enable functions such as rewinding or fast forwarding a video output based on a gesture touch input or rendering a rewinding or fast forwarding video frame carousel in response to such a gesture touch input.

Processors in various examples may be configured to implement functionality and or process instructions for execution within computing device . For example processors may be capable of processing instructions stored in memory or instructions stored on data storage devices . Computing device may include multiple processors and may divide certain tasks among different processors. For example processors may include a central processing unit which may have one or more processing cores and may also include one or more graphics processing units GPUs . Processors may be configured for multi threaded processing. Processors and or operating system may divide tasks among different processors or processor cores according to certain criteria such as to optimize graphics rendering or to optimize the user experience. For example processors and or operating system may reserve a particular processing thread or processor or processing core or a portion thereof for certain tasks such as rendering translational motion of graphical elements or for rendering still images or video frames within a video output.

As a more particular example while computing device is displaying a video frame carousel being rewound or fast forwarded such as described with reference to computing device may have a certain processing thread processor or processing core or a portion thereof reserved for the task of rendering the translational motion of the frame carousel across the touchscreen and a different processing thread processor or processing core or a portion thereof reserved for the task of rendering the details of the images within each of the video frames etc. as depicted in . Such a system for reserving certain high priority processing resources for certain tasks may ensure that processing tasks where fast performance is important for effective user experience are not competing for processing time with less time critical background tasks especially during tasks that may impose a relatively high processing burden which may include displaying a rewinding or fast forwarding video frame carousel.

Various tasks or portions of tasks may also be divided among different layers of software and hardware. For example a processing thread may oversee higher level management of video display while being configured to push much of the processing burden of rendering the graphics through GPU hardware that is optimized for the task.

Memory in various examples may be configured to store information within computing device during operation. Memory in various examples may be a computer readable storage medium. In various examples memory is a temporary memory and computing device relies more on one or more data storage devices than memory for long term storage. Memory in various examples may be a volatile memory meaning that memory does not maintain stored contents for a long duration of time once it is powered down such as when computing device is turned off. Examples of volatile memories that may characterize memory include random access memories RAM dynamic random access memories DRAM static random access memories SRAM and other forms of volatile memories. In various examples memory may be used to store program instructions for execution by processors . Memory in various examples may be used by software or applications running on computing device to temporarily store information during program execution.

One or more data storage devices in various examples may include a computer readable storage medium or multiple computer readable storage media. Data storage devices may be configured to store larger amounts of information than memory . Data storage devices may further be configured for long term storage of information. In various examples data storage devices include non volatile storage elements. Examples of such non volatile storage elements include magnetic hard discs optical discs floppy discs flash memories or forms of electrically programmable memories EPROM or electrically erasable and programmable EEPROM memories. In other examples memory may also be configured for long term data storage and any of a variety of technologies may blur the lines between memory and data storage and between volatile and non volatile. Memory and data storage devices may also include any of various caches buffers and other temporary memories that may be incorporated at any of various levels of a processing architecture and with various latency and capacity profiles including a dedicated cache exclusive to a processing core or processing chip.

Computing device in various examples may also include a network interface . Computing device in one example utilizes network interface to communicate with external devices via one or more networks which may include one or more wireless networks. Network interface may be or include a network interface card such as an Ethernet card an optical transceiver a radio frequency transceiver or any other type of component that is configured to send and receive information. Other examples of such network interfaces may include Bluetooth 3G and WiFi radios configured for mobile computing devices as well as USB. In various examples computing device may use network interface to communicate wirelessly with an external device such as server device of as described below a mobile phone or other networked computing device. In various embodiments computing device may also execute a gesture touch input controlled rewind and fast forward function for a video output solely from data stored internally to computing device or input to computing device from a local input device such as a USB player Blu Ray player or DVD player for example without necessarily using a network connection and without streaming or downloading the video content from a server or remote data source.

Computing device in various examples may also include one or more input and or output devices such as touchscreen which is a presence sensitive screen. Touchscreen in various examples may be configured to detect and receive input from a user through touch inputs on the surface of touchscreen as well as to provide video output and other graphical output. Touchscreen may incorporate any of various components to carry out these functions which may include a liquid crystal display LCD display screen or display screen that uses another type of graphical output technology as well as an electrically capacitive layer sensitive to the presence of touch and configured to translate the positions of touch inputs and the motions of touch inputs as they change position over time into signals to provide to a driver for the touchscreen or other feature for receiving the information on the touch inputs.

Computing device may also include any of a variety of other input and or output devices such as a speaker a microphone physical buttons as opposed to virtual buttons rendered on touchscreen a physical keyboard as opposed to a virtual keyboard rendered on touchscreen a mouse a touchpad a trackball a voice user interface system a camera an accelerometer a vibration component a sound card a video graphics adapter card or any other type of device for detecting and or interpreting inputs from a user or for converting a signal into a form of graphical audio tactile or other form of user output that can be sensed by a user. Computing device may also include one or more of any of these components.

Computing device in various examples may include one or more power sources which may be rechargeable and provide power to computing device . Power source in various examples may be a lithium ion battery a nickel cadmium battery a nickel metal hydride battery or other suitable power source.

In various examples all of or portions of media application and or video module may be a part of or native to operating system libraries and or runtime . In various examples media application may receive input from one or more data storage devices and or through network interface of computing device . Computing device may for example receive video content through network interface from a network connected server device such as is shown in .

As shown in server device includes web server which may include video session module and video session . As illustrated in computing device may communicate with server device via network which may be or include the Internet a local area network LAN or other network and which may incorporate any of a wide variety of servers gateways routers other network nodes and wired or wireless communication channels capable of sending and receiving data. Computing device may thereby be operatively and or communicatively coupled via network to server device . Communication between computing device and server device over network may incorporate a network connection using a Transmission Control Protocol and Internet Protocol TCP IP protocol stack or a User Datagram Protocol UDP network connection over IP or other Internet Layer and Transport Layer protocols. Communication between computing device and server device over network may also make use of any of a variety of Application Layer protocols on top of TCP or UDP for communicating the video and audio data as well as requests responses controls and negotiating the connection such as Real Time Streaming Protocol RTSP Real time Transport Protocol RTP Real time Control Protocol RTCP Hypertext Transfer Protocol HTTP and or Hypertext Transfer Protocol Secure HTTPS for example.

Web server as shown in may perform one or more operations that enable media application to access video session to stream or download a video output onto computing device . Web server may generate manage and terminate video sessions such as video session . In various examples web server may include one or more modules such as video session module executing on server device . Video session module may be involved in creating managing and terminating video sessions such as video session .

Web server may use any of a variety of tools or technologies for implementing the functions described herein. For example web server may use server side JavaScript and may use the V8 JavaScript engine developed by Google Inc. in conjunction with libraries for server side JavaScript. Any action performed by any element or feature comprised in or running on server device may in general be attributed to server device . Any of the functions of server device described herein may also equivalently be abstracted among multiple servers a data center or a collection of servers and data centers.

In various examples media application on computing device may include functionality to send an initiation request to server device to create or initiate one or more video sessions such as video session . Server device may automatically communicatively couple computing device to video session in response to receiving the initiation request. Computing device may also send updated requests to server device for changes in the order in which frames or other portions of a video output are to be sent or downloaded based on the predictions of the one or more frames that are imminently pending to render for the interspersed display of frames such as if a user enters a fast forward input early in the process of streaming and buffering the data for the video output.

In this case computing device may send an updated request for the server device to send intermittently spaced frames from a large sample of the video output first so that computing device may render intermittently spaced frames from a large sample of the video output in a video frame carousel such as is depicted in and to de pioritize sending the remaining intermediate frames of video output or sending the audio output until after the video frame carousel is populated for fast forwarding or rewinding. Computing device may continue sending updated requests to server device with updated specifics of frames of video content to prioritize for downloading based on ongoing user inputs and or predictions made by computing device for likely imminent user inputs based on prior user inputs. The term downloading in this context may refer to any form of communicating data from server device to computing device for streaming or downloading the video content and or any other audio content or media content such as when the media application provides the video output to touchscreen while still downloading the video output from server device .

Server device may then send signals including data for a streaming or downloading video output and a corresponding audio output from video session to computing device . Server device and or computing device may configure the streaming or downloading of data for the video output to optimize the delivery of the video output based at least in part on the hardware and or software specifications and capabilities of computing device . For example if computing device is a mobile computing device with relatively higher or lower bandwidth and computing resource capabilities communication server may optimize the quality of the streaming video output sent to computing device based on its particular bandwidth and computing resource capabilities.

In process a computing device may execute a media application that provides a video output to a presence sensitive screen i.e. touchscreen of the computing device . During execution of the media application the presence sensitive screen receives a gesture touch input that has motion with respect to the presence sensitive screen . Computing device may optionally determine a speed of the motion of the gesture touch input . Computing device rewinds or fast forwards the video output based on the gesture touch input and may optionally do so at a frame speed based at least in part on the determined speed of the motion of the gesture touch input . During the rewinding or fast forwarding the video output computing device may also optionally display a plurality of frames of the video output concurrently on the presence sensitive screen in the frame carousel mode in lateral motion corresponding to the rewinding or fast forwarding .

Various techniques described herein may be implemented in software that may be written in any of a variety of languages making use of any of a variety of toolsets frameworks APIs programming environments virtual machines libraries and other computing resources as indicated above. For example software code may be written in Java C Objective C C Go Python Ruby Scala Clojure assembly language machine code or any other language. As one specific illustrative example aspects of the disclosure discussed above may be implemented in a software module written in Java that is executable on virtual machine of which may be the Dalvik virtual machine.

This software module may listen for touch input events from a module application driver combination of one or more of these or other software that manages the detecting and interpreting of touch inputs to touchscreen . This software module may execute a boolean method that performs evaluations of the touch inputs on touchscreen and detects whether a touch input qualifies as a gesture touch input that has motion with respect to touchscreen . For example the software may include an asynchronous event notification API that triggers an input event when a gesture touch input is detected. Different aspects of this detecting and interpreting may be divided among different layers of the software between the software that primarily manages touch inputs and software that listens for touch input events and communicates them to the controls of media application.

In this example if the boolean method detects a gesture touch input that has motion with respect to touchscreen a scroller class that extends a video class is triggered to evaluate properties of the gesture touch input and to generate a rewind effect or a fast forward effect in the video class based on the properties of the gesture touch input. The rewind effect or fast forward effect in the video class may cause a rewinding or fast forwarding of the video output. The scroller class may also extend the video class to manipulate the frames of the video content to render the video frame carousel as depicted in .

The properties of the gesture touch input evaluated by the scroller class may include a direction of the gesture touch input such as leftward or rightward. The properties evaluated by the scroller class may also include a speed and or a duration of the gesture touch input. The video class may then generate either the rewind effect or the fast forward effect based on the direction of the gesture touch input. The video class may also generate the rewind effect or the fast forward effect with a scrolling speed based on one or more of the speed and the duration of the gesture touch input in this illustrative example.

In this or other specific examples aspects of the disclosure described above may be tailored to operate on the Android operating system developed by the Open Handset Alliance consortium and may make use of and add new capabilities to Android media APIs such as android.media.MediaRecorder.VideoSource and android.media.MediaRecorder.VideoEncoder. Aspects of the disclosure may be equally applicable and implemented on any other operating system and using any other APIs frameworks or toolsets. Aspects described herein for transmission decoding and rendering of data for video output or video content which may be considered interchangeably herein with media output or media content that also includes audio output or audio content may make use of any protocol standard format codec compression format HTML element or other technique or scheme for processing decoding rendering or displaying a video output.

Various techniques described herein may be implemented in hardware software firmware or any combination thereof. Various features described as modules units or components may be implemented together in an integrated logic device or separately as discrete but interoperable logic devices or other hardware devices. In some cases various features of electronic circuitry may be implemented as one or more integrated circuit devices such as an integrated circuit chip or chipset.

If implemented in hardware this disclosure may be directed to an apparatus such as a processor or an integrated circuit device such as an integrated circuit chip or chipset. Alternatively or additionally if implemented in software or firmware the techniques may be realized at least in part by a computer readable data storage medium comprising instructions that when executed cause a processor to perform one or more of the methods described above. For example the computer readable data storage medium may store such instructions for execution by a processor.

A computer readable medium may form part of a computer program product which may include packaging materials. A computer readable medium may comprise a computer data storage medium such as random access memory RAM read only memory ROM non volatile random access memory NVRAM electrically erasable programmable read only memory EEPROM flash memory magnetic or optical data storage media and the like. In various examples an article of manufacture may comprise one or more computer readable storage media.

In various examples the data storage devices and or memory may comprise computer readable storage media that may comprise non transitory media. The term non transitory may indicate that the storage medium is not embodied in a carrier wave or a propagated signal. In certain examples a non transitory storage medium may store data that can over time change e.g. in RAM or cache . Machine readable code may be stored on the data storage devices and or memory and may include executable instructions that are executable by at least one processor. Machine readable code and executable instructions may refer to any form of software code including machine code assembly instructions or assembly language bytecode software code in C or software code written in any higher level programming language that may be compiled or interpreted into executable instructions that may be executable by at least one processor including software code written in languages that treat code as data to be processed or that enable code to manipulate or generate code.

The code or instructions may be software and or firmware executed by processing circuitry including one or more processors such as one or more digital signal processors DSPs general purpose microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs or other equivalent integrated or discrete logic circuitry. Accordingly the term processor as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition in some aspects functionality described in this disclosure may be provided within software modules or hardware modules.

The various embodiments described above and depicted in as well as additional embodiments are within the scope of the following claims.

