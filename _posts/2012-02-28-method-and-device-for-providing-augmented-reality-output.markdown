---

title: Method and device for providing augmented reality output
abstract: Methods and devices for generating an augmented reality output are described. In one aspect, the method includes: obtaining camera data from a camera associated with an electronic device, the camera data defining an image representing a card having a graphic disposed thereon; obtaining sensor data from a sensor associated with the electronic device; and generating an augmented reality output on an output interface based on the sensor data and the graphic.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09277367&OS=09277367&RS=09277367
owner: BlackBerry Limited
number: 09277367
owner_city: Waterloo, Ontario
owner_country: CA
publication_date: 20120228
---
The present disclosure relates to augmented reality systems and more particularly to methods and electronic devices for providing an augmented reality output based on a real world card.

Electronic devices such as smartphones and tablet computers are sometimes equipped with cameras. Cameras may for example be used to allow a user to capture a video or a still photograph. Some electronic devices may store images which are captured with a camera to a memory of the electronic device. Some electronic devices may transmit data via a communication subsystem to another electronic device in order to provide a video based chat.

Electronic devices may use camera data to provide an augmented reality. Augmented reality is a process wherein a live view of a physical real world environment which may be obtained via the camera may be augmented by computer generated input.

In one aspect the present disclosure describes a method implemented by a processor of an electronic device. The method includes obtaining camera data from a camera associated with the electronic device the camera data defining an image representing a card having a graphic disposed thereon obtaining sensor data from a sensor associated with the electronic device and generating an augmented reality output on an output interface in dependence on the sensor data and the graphic.

In another aspect the present disclosure describes an electronic device. The electronic device includes a camera and an output interface. The electronic device also includes a sensor and a processor connected to the camera the sensor and the output interface. The processor is configured to obtain camera data from the camera the camera data defining an image representing a card having a graphic disposed thereon obtain sensor data from the sensor and generate an augmented reality output on the output interface in dependence on the sensor data and the graphic.

In yet another aspect the present disclosure describes a computer readable storage medium comprising computer readable instructions for obtaining camera data from a camera associated with an electronic device the camera data defining an image representing a card having a graphic disposed thereon obtaining sensor data from a sensor associated with the electronic device and generating an augmented reality output on an output interface in dependence on the sensor data and the graphic.

Other example embodiments of the present disclosure will be apparent to those of ordinary skill in the art from a review of the following detailed descriptions in conjunction with the drawings.

Referring first to a top view of an example card is illustrated. The card may be associated with an augmented reality application . The card may in at least some embodiments be used to provide an augmented reality experience on an electronic device . The card may for example be constructed of heavy paper thin cardboard plastic coated paper plastic cotton blend paper or another material. In at least some embodiments the card is a playing card. That is the card may be of the type which is commonly used in card games.

The card includes a graphic . The graphic is a visual presentation on the card . The graphic may for example include photographic features text features line features shape based features symbols graphs geometric designs or other features not specifically listed herein. The graphic may in some embodiments be a black and white graphic. However in other embodiments the graphic may be a color graphic which includes one or more color features. In the embodiment illustrated the graphic is a depiction of a person. However in other embodiments the graphic could take another form.

Referring now to a top view of an example electronic device is illustrated. In the example illustrated the electronic device is a smartphone. A smartphone is a mobile phone which offers more advance computing capability than a basic non smart cellular phone. For example a smartphone may have the ability to run third party applications which are stored on the smartphone.

In other example embodiments the electronic device may be of another type. For example in some embodiments the electronic device may be a tablet computer. A tablet computer which may also be referred to as a tablet is an electronic device which is generally larger than a mobile phone such as a smartphone or personal digital assistant. Many mobile phones or personal digital assistants are designed to be pocket sized. That is mobile phones or personal digital assistants are generally small enough to be carried by a person easily often in a shirt or pant pocket while tablet computers are larger and may not fit within pant pockets. For example many tablet computers have a height which is seven inches or more. In some example embodiments the tablet computer may be a slate computer. A slate computer is a tablet computer which does not include a dedicated keyboard. A slate computer may allow for text input through the use of a virtual keyboard or an external keyboard which connects to the slate computer via a wired or wireless connection.

The electronic device may in other embodiments be of another type. For example in some embodiments the electronic device may be a remote control such as a television remote control a navigation system such as a Global Positioning System a wearable computer such as a watch a personal digital assistant PDA a desktop netbook notebook or laptop style computer system or a television. The electronic device may in other embodiments be of a type not specifically listed herein.

The electronic device includes one or more output interfaces. For example in the embodiment illustrated in the electronic device includes a display . The display may for example be a liquid crystal display LCD . In at least some embodiments the display is a touchscreen display which may be used to provide input to the electronic device . The touchscreen display may for example be a capacitive touchscreen display which senses changes in capacitance.

The electronic device includes one or more cameras . The camera is configured to generate camera data such as images in the form of still photographs and or motion video. The camera data may be captured in the form of an electronic signal which is produced by an image sensor associated with the camera . More particularly the image sensor not shown is configured to produce an electronic signal in dependence on received light. That is the image sensor converts an optical image into an electronic signal which may be output from the image sensor by way of one or more electrical connectors associated with the image sensor. The electronic signal represents electronic image data which may also be referred to as camera data .

In some embodiments the electronic device may include a front facing camera. A front facing camera is illustrated in . A front facing camera is a camera which is generally located on a front face of the electronic device . The front face is typically the face on which a display is mounted. That is the display is configured to display content which may be viewed from a side of the electronic device where the front facing camera is directed. The front facing camera may be located anywhere on the front surface of the electronic device for example the front facing camera may be located above or below the display . In at least some example embodiments the front facing camera may be provided in a central location relative to the display to facilitate image acquisition of a face. In at least some embodiments the front facing camera may be used for example to allow a user of the electronic device to engage in a video based chat with a user of another electronic device . An example camera which is a front facing camera is illustrated in .

The electronic device may in at least some embodiments include a rear facing camera. A rear facing camera is a camera which is located to obtain images of a subject near a rear face of the electronic device . The rear face is typically a face which does not include the main display of the electronic device . The rear face is in at least some embodiments located at a side of the electronic device which is opposite the side which includes the display . The rear facing camera may obtain images which are not within the field of view of the front facing camera. The field of view of the front facing and rear facing cameras may generally be in opposing directions. Since illustrates a top view of the electronic device the rear facing camera is not illustrated.

In at least some embodiments a user may manipulate the electronic device so that a camera on the electronic device is directed at a card associated with an augmented reality application of the electronic device . For example the electronic device may be oriented so that a camera of the electronic device faces the card and is able to capture an image which includes the card . In at least some embodiments the rear facing camera not shown of the electronic device may be directed at the card . That is a user may move the electronic device so that the electronic device is in a position in which the card is within a field of view of a rear facing camera.

As will be described in greater detail below an augmented reality application associated with the electronic device may be configured such that an augmented reality output of the card is displayed on the display when the electronic device is in a position in which a camera is directed at the card .

The augmented reality output includes a device generated portion which is generated by the electronic device . In the example embodiment illustrated the device generated portion is a comment box which includes text. In at least some embodiments the device generated portion may be a graphic and or an animation. In at least some embodiments the device generated portion may animate or alter the graphic on the card . For example in the embodiment of where the graphic is a person the person could be animated. For example the person could appear to walk run jump or move in another manner.

The augmented reality output also includes a real world portion . The real world portion is a portion of the output which is defined by camera data obtained by a camera such as the rear facing camera . The real world portion may reflect real world changes in the camera data. That is changes in the camera data may result in corresponding changes to the rear world portion. Such changes may be reflected in real time or in near real time. By way of example if an object such as a user s finger is moved into the field of view of the camera then the real world portion may be immediately updated to reflect the change. Thus the real world portion acts as a viewfinder and displays images defined by camera data in real time or near real time.

The device generated portion may be superimposed on an image defined by the camera data obtained by the camera . The portion of the image which is not covered by the superimposing forms the real world portion of the augmented reality output .

In the embodiment illustrated in the real world portion includes the card or a portion thereof . In the illustrated embodiment the real world portion also includes the graphic on the card and a portion of the surface on which the card is supported.

As will be described in greater detail below the electronic device may be configured to generate the augmented reality output based on the camera data and also based on sensor data obtained from a sensor associated with the electronic device .

Referring now to a block diagram of an example electronic device is illustrated. In the illustrated example embodiment the electronic device is a mobile communication device such as the smartphone of . In at least some example embodiments the mobile communication device is a two way communication device having data and possibly voice communication capabilities and the capability to communicate with other computer systems for example via the internet. As noted above the electronic device may take other forms in other embodiments.

The electronic device of includes a housing which houses components of the electronic device . Internal components of the electronic device may be constructed on a printed circuit board PCB . The electronic device includes a controller including at least one processor such as a microprocessor which controls the overall operation of the electronic device . The processor interacts with device subsystems such as a wireless communication subsystem for exchanging radio frequency signals with a wireless network to perform communication functions. The processor interacts with additional device subsystems including one or more input interfaces such as a keyboard one or more control buttons one or more microphones one or more cameras one or more sensors and or a touch sensitive overlay associated with a touchscreen display flash memory random access memory RAM read only memory ROM auxiliary input output I O subsystems a data port which may be a serial data port such as a Universal Serial Bus USB data port one or more output interfaces such as a display which may be a liquid crystal display LCD one or more speakers or other output interfaces a short range communication subsystem and other device subsystems generally designated as . Some of the subsystems shown in perform communication related functions whereas other subsystems may provide resident or on device functions.

The electronic device may include a touchscreen display in some example embodiments. The touchscreen display may be constructed using a touch sensitive input surface connected to an electronic controller. The touch sensitive input surface overlays the display and may be referred to as a touch sensitive overlay. The touch sensitive overlay and the electronic controller provide a touch sensitive input interface and the processor interacts with the touch sensitive overlay via the electronic controller. That is the touchscreen display acts as both an input interface and an output interface .

The communication subsystem includes a receiver a transmitter and associated components such as one or more antenna elements and local oscillators LOs and a processing module such as a digital signal processor DSP . The antenna elements and may be embedded or internal to the electronic device and a single antenna may be shared by both receiver and transmitter as is known in the art. The particular design of the wireless communication subsystem depends on the wireless network in which the electronic device is intended to operate.

The electronic device may communicate with any one of a plurality of fixed transceiver base stations of the wireless network within its geographic coverage area. The electronic device may send and receive communication signals over the wireless network after the required network registration or activation procedures have been completed. Signals received by the antenna through the wireless network are input to the receiver which may perform such common receiver functions as signal amplification frequency down conversion filtering channel selection etc. as well as analog to digital A D conversion. A D conversion of a received signal allows more complex communication functions such as demodulation and decoding to be performed in the DSP . In a similar manner signals to be transmitted are processed including modulation and encoding for example by the DSP . These DSP processed signals are input to the transmitter for digital to analog D A conversion frequency up conversion filtering amplification and transmission to the wireless network via the antenna . The DSP not only processes communication signals but may also provide for receiver and transmitter control. For example the gains applied to communication signals in the receiver and the transmitter may be adaptively controlled through automatic gain control algorithms implemented in the DSP .

In some example embodiments the auxiliary input output I O subsystems may include an external communication link or interface for example an Ethernet connection. The electronic device may include other wireless communication interfaces for communicating with other types of wireless networks for example a wireless network such as an orthogonal frequency division multiplexed OFDM network.

In some example embodiments the electronic device also includes a removable memory module typically including flash memory and a memory module interface . Network access may be associated with a subscriber or user of the electronic device via the memory module which may be a Subscriber Identity Module SIM card for use in a GSM network or other type of memory module for use in the relevant wireless network type. The memory module may be inserted in or connected to the memory module interface of the electronic device .

The electronic device may store data in an erasable persistent memory which in one example embodiment is the flash memory . In various example embodiments the data may include service data having information required by the electronic device to establish and maintain communication with the wireless network . The data may also include user application data such as email messages address book and contact information calendar and schedule information notepad documents image files and other commonly stored user information stored on the electronic device by its user and other data.

The data stored in the persistent memory e.g. flash memory of the electronic device may be organized at least partially into a number of databases or data stores each containing data items of the same data type or associated with the same application. For example email messages contact records and task items may be stored in individual databases within the electronic device memory.

The data port may be used for synchronization with a user s host computer system. The data port enables a user to set preferences through an external device or software application and extends the capabilities of the electronic device by providing for information or software downloads to the electronic device other than through the wireless network . The alternate download path may for example be used to load an encryption key onto the electronic device through a direct reliable and trusted connection to thereby provide secure device communication.

The electronic device includes one or more sensors . The sensors are configured to generate sensor data. In at least some embodiments one or more of the sensors may specify a physical property associated with the electronic device or its operating environment. The physical property is a property that is measurable and whose values depend on a physical system s state. By way of example the physical property may include a location pressure velocity orientation direction temperature etc.

The one or more sensors may in at least some embodiments include a location sensor. The location sensor is a geospatial location sensor which is configured to produce sensor data based on the location of the electronic device . That is the location sensor may provide sensor data which specifies a location of the electronic device . In at least some embodiments the location sensor is a global positioning system GPS sensor. However in other embodiments the location sensor may be of another type. For example in some embodiments the location sensor may be configured to determine a location of the electronic device based on cellular and or Wi Fi triangulation. The location sensor may be of a type not specifically listed herein.

In at least some embodiments the one or more sensors of the electronic device include an electronic compass which generates sensor data which specifies direction information. The direction information may for example specify the direction of magnetic north. In at least some embodiments the electronic compass is a magnetometer. A magnetometer is an instrument which is used to measure the strength or direction of a magnetic field.

In at least some embodiments the one or more sensors of the electronic device include an altimeter. The altimeter generates sensor data which specifies an altitude associated with the electronic device. The altimeter may for example be provided by the location sensor. For example the altimeter may determine altitude by four way trilateration. For example where the location sensor is a GPS sensor altitude of the electronic device may be determined by trilateration with four or more satellites.

In at least some embodiments the one or more sensors may include a thermometer. The thermometer is configured to generate sensor data which specifies a temperature associated with the electronic device. In at least some embodiments the thermometer is configured to generate sensor data which corresponds to the temperature of an operating environment in which the electronic device is located. For example the thermometer may generate sensor data based on the air temperature near the electronic device .

In at least some embodiments the one or more sensors of the electronic device may include an orientation sensor. The orientation sensor is a sensor which is configured to generate sensor data based on the orientation of the electronic device . For example the orientation sensor may generate sensor data based on the device s orientation relative to the earth s gravitational field. In at least some embodiments the orientation sensor is an accelerometer. In at least some embodiments the orientation sensor is a gyroscope. The orientation sensor may take other forms in other embodiments.

The sensor data generated by the sensor is an electrical signal and is in at least some embodiments a digital signal. The sensor data may be provided to a processor associated with the electronic device for processing and or analysis. The sensor s may be communicably coupled to the processor .

In some example embodiments the electronic device is provided with a service routing application programming interface API which provides an application with the ability to route traffic through a serial data i.e. USB or Bluetooth Bluetooth is a registered trademark of Bluetooth SIG Inc. connection to the host computer system using standard connectivity protocols. When a user connects their electronic device to the host computer system via a USB cable or Bluetooth connection traffic that was destined for the wireless network is automatically routed to the electronic device using the USB cable or Bluetooth connection. Similarly any traffic destined for the wireless network is automatically sent over the USB cable Bluetooth connection to the host computer for processing.

The electronic device also includes a battery as a power source which is typically one or more rechargeable batteries that may be charged for example through charging circuitry coupled to a battery interface such as the serial data port . The battery provides electrical power to at least some of the electrical circuitry in the electronic device and the battery interface provides a mechanical and electrical connection for the battery . The battery interface is coupled to a regulator not shown which provides power V to the circuitry of the electronic device .

The short range communication subsystem is an additional optional component which provides for communication between the electronic device and different systems or devices which need not necessarily be similar devices. For example the short range communication subsystem may include an infrared device and associated circuits and components or a wireless bus protocol compliant communication mechanism such as a Bluetooth communication module to provide for communication with similarly enabled systems and devices.

A predetermined set of applications that control basic device operations including data and possibly voice communication applications may be installed on the electronic device during or after manufacture. Additional applications and or upgrades to an operating system or software applications may also be loaded onto the electronic device through the wireless network the auxiliary I O subsystem the data port the short range communication subsystem or other suitable device subsystems . The downloaded programs or code modules may be permanently installed for example written into the program memory e.g. the flash memory or written into and executed from the RAM for execution by the processor at runtime.

In some example embodiments the electronic device may provide two principal modes of communication a data communication mode and a voice communication mode. In the data communication mode a received data signal such as a text message an email message or webpage download will be processed by the communication subsystem and input to the processor for further processing. For example a downloaded webpage may be further processed by a web browser or an email message may be processed by the email messaging application and output to the display . A user of the electronic device may also compose data items such as email messages for example using an input interface in conjunction with the display . These composed items may be transmitted through the communication subsystem over the wireless network .

In the voice communication mode the electronic device provides telephony functions and may operate as a typical cellular phone. The overall operation is similar to the data communication mode except that the received signals would be output to the speaker and signals for transmission would be generated by a transducer such as the microphone . The telephony functions are provided by a combination of software firmware i.e. a voice communication module and hardware i.e. the microphone the speaker and input devices . Alternative voice or audio I O subsystems such as a voice message recording subsystem may also be implemented on the electronic device . Although voice or audio signal output may be accomplished primarily through the speaker the display may also be used to provide an indication of the identity of a calling party duration of a voice call or other voice call related information.

The processor operates under stored program control and executes software modules stored in memory such as persistent memory for example in the flash memory . As illustrated in the software modules may include operating system software and one or more additional applications or modules such as for example an augmented reality application . In the example embodiment of the augmented reality application is illustrated as being implemented as a stand alone application but in other example embodiments the augmented reality application could be provided by another application or module such as for example the operating system software . Furthermore while the augmented reality application is illustrated with a single block the functions or features provided by the augmented reality application could in at least some embodiments be divided up and implemented by a plurality of applications and or modules.

The augmented reality application is configured to generate an augmented reality output on an output interface associated with the electronic device . In at least some embodiments the augmented reality application is configured to generate an augmented reality output on the display associated with the electronic device . More particularly the augmented reality application is configured to obtain camera data from the camera and sensor data from the sensor . The camera data may in at least some embodiments define an image representing a card having a graphic disposed thereon. In at least some embodiments the augmented reality application may generate an augmented reality output in dependence on the sensor data and the card . For example the augmented reality application may generate an augmented reality output based on both the sensor data from a sensor and the graphic which is on a card captured in the camera data. The augmented reality output may be of the type described above with reference to .

Accordingly the camera data may define a card associated with the augmented reality application . In at least some embodiments a card associated with the augmented reality application is a card which has a graphic which the augmented reality application is able to identify. In at least some embodiments the augmented reality application may only provide the augmented reality output if the augmented reality application identifies the card. More particularly in at least some embodiments the augmented reality application may only provide the augmented reality output if it determines that the graphic on the card represented in the image defined by the camera data is a known graphic.

In at least some embodiments the memory of the electronic device may include a graphic database which may be used to allow the electronic device to determine whether the graphic is a known graphic. The graphic database may define graphics associated with the augmented reality application . That is the graphic database includes information which the augmented reality application may use to identify whether a graphic included in the camera data is a known graphic.

In at least some embodiments the graphic database may specify information which may be used to generate a device generated portion of the augmented reality output when the augmented reality application identifies a graphic. That is the graphic database may associate a graphic with specific information which may be used to generate device generated portions . Accordingly the device generated portion which is generated may depend at least in part on the graphic which is identified. Different graphics may yield different device generated portions for the augmented reality output .

Similarly the device generated portion which is generated may depend at least in part on the sensor data. Different sensor data may yield different device generated portions for the augmented reality output . In at least some embodiments the graphic database may associate a single graphic with information which may be used to generate two or more device generated portions . Each of the two or more device generated portions for a graphic may be associated with different sensor conditions. For example the sensor conditions may define thresholds for sensor data which are associated with a device generated portion . In at least some such embodiments when a graphic is identified one of the device generated portions for that graphic may be selected based on the sensor data. For example when a graphic is identified one of the device generated portions for that graphic is selected by comparing the sensor data with the sensor conditions for the device generated portions for that graphic.

Functions and features of the augmented reality application will be described in greater detail below with reference to .

The electronic device may include a range of additional software applications including for example a notepad application voice communication i.e. telephony application mapping application a media player application or any combination thereof. Each of the software applications may include layout information defining the placement of particular fields and graphic elements e.g. text fields input fields icons etc. in the user interface i.e. the display according to the application.

The software modules or parts thereof may be temporarily loaded into volatile memory such as the RAM . The RAM is used for storing runtime data variables and other types of data or information. Although specific functions are described for various types of memory this is merely one example and a different assignment of functions to types of memory could also be used.

Referring now to an example method for providing an augmented reality output is illustrated in flowchart form. The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of . For example the method may be implemented by a processor of an electronic device .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

In at least some embodiments the method may be initiated when the augmented reality application is launched. For example a user may input a command to the electronic device which causes the augmented reality application to be run on the electronic device and which consequently initiates the method .

At the electronic device obtains camera data from a camera associated with the electronic device . In at least some embodiments the electronic device obtains camera data from a rear facing camera. However in other embodiments the electronic device may obtain camera data from a front facing camera.

The camera data may in at least some embodiments define an image representing a card having a graphic disposed thereon. This may occur when the camera is directed at the card having the graphic . The card may be a card which is associated with the augmented reality application . That is the card may be a card which has a known graphic i.e. a graphic which the electronic device is able to identify as being associated with the augmented reality application .

At the electronic device obtains sensor data from a sensor associated with the electronic device . The sensor may be of a type described above with reference to . For example the sensor may be any one or more of a location sensor such as a GPS sensor an electronic compass an altimeter a thermometer an orientation sensor such as an accelerometer or gyroscope or a sensor of another type not specifically listed herein. In at least some embodiments the sensor may generate sensor data which specifies a physical property associated with the electronic device or its operating environment. For example the sensor data may specify a location pressure velocity orientation direction temperature acceleration and or altitude associated with the electronic device .

At the electronic device may generate an augmented reality output on an output interface such as a display based on the sensor data obtained from the sensor at and also based on the graphic included in the camera data at .

The augmented reality output may include a device generated portion which may be superimposed on the image defined by the camera data obtained at . The augmented reality output may also include a real world portion which is a portion of the augmented reality output which is defined by camera data obtained from the camera. That is the real world portion may represent the portion of the image obtained by the camera which is not covered when the device generated portion is superimposed on the image defined by the camera data. In at least some embodiments the device generated portion is generated based on the graphic included in the camera data and also based on the sensor data.

The augmented reality output may in at least some embodiments include an animation. That is based on the particular graphic which was included in the camera data and based also on the sensor data the electronic device may generate an animation. The animation which is generated may depend on both the graphic and also on the sensor data. That is a different graphic may produce a different animation and different sensor data may also produce a different animation. The animation may in at least some embodiments form the device generated portion of the augmented reality output . That is the animation may be superimposed on the image defined by the camera data to produce the augmented reality output .

In at least some embodiments the augmented reality output may include text. For example in the embodiment illustrated in and discussed above the augmented reality output includes a comment box which includes text. The text may in at least some embodiments provide an instruction to a user of the electronic device .

For example in at least some embodiments the text may provide an instruction to a user to manipulate the card . The instruction may specify a message which will be provided to a next user as a result of the manipulation of the card. For example in the embodiment of the text which is included in the augmented reality output states Way to go Turning me 90 degrees will tell the next user that he is a slowpoke. Leaving me in my current position will tell him way to go Accordingly the instruction may permit the user to communicate with a next user i.e. to communicate with the next electronic device which captures an image of the card after it is manipulated . The instruction may provide the user with instructions regarding how the card may be manipulated e.g. Turning me 90 degrees and may in some embodiments provide the user with information about how the manipulation of the card may be used to communicate with the next user e.g. will tell the next user that he is a slowpoke . The instruction may for example specify that the user may manipulate the card in any one or more of the following manners rotating the card moving the card which may for example include moving the card horizontally to cause a change in location or moving the card vertically to cause a change in altitude and or flipping the card over. The manipulation may be a manipulation which affects camera data and or sensor data. That is camera data and or sensor data for an electronic device having a camera directed at the card would change following the manipulation.

In at least some embodiments the instruction to manipulate the card may provide a plurality of options for manipulating the card. In at least some embodiments each option may be associated with a different message for a next user. For example in the embodiment of a first option e.g. Turning me 90 degrees may be associated with a first message e.g. will tell the next user that he is a slowpoke and a second option e.g. Leaving me in my current position is associated with a second message e.g. will tell him way to go which is different from the first message.

The text which is included in the augmented reality output may depend on both the graphic and also on the sensor data. That is a different graphic may produce different text and different sensor data may also produce different text. The text may in at least some embodiments form the device generated portion of the augmented reality output . That is the text may be superimposed on the image defined by the camera data to produce the augmented reality output .

In at least some embodiments the augmented reality output may cause one or more features of the card to appear to be modified. For example in at least some embodiments the graphic associated with the card may be modified. The manner in which the graphic is modified may depend on the graphic itself and also on the sensor data. For example where the sensor data indicates that the altitude is greater than a predetermined threshold then a high altitude effect may be applied to the graphic. For example the graphic may appear to be on a mountain or in an airplane. By way of example the person graphic of may be shown to climb a mountain or board an airplane. By way of further example if the sensor data suggests that the temperature is greater than a predetermined threshold then a high temperature effect may be applied to the graphic. By way of example a sun or palm trees may be added to the graphic when it is output on the display .

In at least some embodiments the output interface through which the augmented reality output is generated at is a display . That is at the augmented reality output is displayed on the display associated with the electronic device .

As noted above in the discussion of in at least some embodiments the electronic device may include a graphic database which defines known graphics e.g. graphics associated with an augmented reality application . The graphics database may specify information which may be used to generate a device generated portion of the augmented reality output when the augmented reality application identifies a graphic. That is the graphic database may associate a graphic with specific information which may be used to generate device generated portions .

The device generated portion which is generated may depend at least in part on the sensor data. Different sensor data may yield different device generated portions for the augmented reality output . In at least some embodiments the graphic database may associate a single graphic with information which may be used to generate two or more device generated portions . Each of the two or more device generated portions for a graphic may be associated with different sensor conditions. For example the sensor conditions may define thresholds for sensor data which are associated with a device generated portion .

In at least some such embodiments when a graphic is identified by the electronic device one of the device generated portions for that graphic may be selected based on the sensor data. For example when a graphic is identified one of the device generated portions for that graphic is selected by comparing the sensor data with the sensor conditions for the device generated portions for that graphic. Accordingly in at least some embodiments at when generating the augmented reality output based on the camera data and the sensor data the electronic device may consult the graphic database . For example the electronic device may use the graphic database to select an appropriate device generated portion based on the graphic and the sensor data.

In at least some embodiments the augmented reality output will only be generated based on the graphic and the sensor data if the electronic device determines that the graphic is known to the electronic device .

Referring now to one such example method is illustrated. In an example method for providing an augmented reality output is illustrated in flowchart form. The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of . For example the method may be implemented by a processor of an electronic device .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

In at least some embodiments the method may be initiated when the augmented reality application is launched. For example a user may input a command to the electronic device which causes the augmented reality application to be run on the electronic device and which consequently initiates the method .

The method includes a number of features which are described in greater detail above with reference to the method of . For example at the electronic device obtains camera data in the manner described above with reference to and at the electronic device obtains sensor data in the manner described above with reference to .

At the electronic device determines whether the camera data defines a card having a known graphic thereon. That is the electronic device determines whether the camera data defines an image which represents a card having a known graphic disposed thereon. In at least some embodiments a graphic may be a known graphic if the graphic is associated with an augmented reality application of the electronic device . For example in at least some embodiments the graphic will be considered a known graphic if it is included in a graphic database associated with the electronic device . Accordingly in at least some embodiments at the electronic device may consult the graphic database and may determine whether the camera data includes a known graphic.

If the camera data does not include a known graphic then in some embodiments no further action will be performed. In some embodiments if the camera data does not include a known graphic then no augmented reality output will be provided. For example in some embodiments if the camera data does not define an image containing a known graphic then the display may act as a view finder by displaying camera data.

If however the electronic device determines that the camera data defines a card having a known graphic then at an augmented reality output may be generated based on the sensor data and the camera data. is discussed in greater detail above with reference to .

As noted previously an augmented reality output may depend on both the camera data and also on sensor data. That is a different graphic may result in a different augmented reality output . Similarly different sensor data may result in different augmented reality output.

Reference will now be made to which illustrates a method for generating an output based on sensor data and camera data. The method illustrates the effect of different graphics and or different sensor data may have on the augmented reality output .

The method may in at least some embodiments be performed at of or . The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

At the electronic device may attempt to identify a graphic represented in the camera data. That is the electronic device may attempt to determine whether the camera data includes a graphic which is known to the electronic device . The identification of a graphic in the camera data may be performed for example by comparing the camera data to a graphic database . The graphic database may be of the type described above with reference to . For example the graphic database may define one or more graphics which are known to the electronic device .

In at least some embodiments in order to identify the graphic the electronic device may determine at whether a graphic contained in the camera data corresponds to a first known graphic. For example in at least some embodiments at the electronic device determines whether the camera data includes a graphic which contains features associated with a first known graphic. The first known graphic is a specific one of the graphics in the graphic database . That is at the electronic device determines whether a captured graphic corresponds to one of the graphics in the camera database.

If the electronic device determines at that the camera data does not include a graphic corresponding to the first known graphic then at it may determine whether the camera data includes a graphic corresponding to a second known graphic. The second known graphic is another one of the graphics represented in the graphics database . That is the second known graphic is not the same graphic as the first known graphic.

In at least some embodiments at the electronic device may compare the camera data to all graphics in the graphic database to determine whether the camera data includes a graphic corresponding to any of the graphics in the graphic database. Accordingly while the embodiment of illustrates a method in which the camera data is compared to only the first known graphic and the second known graphic in other embodiments the identification process at may compare the camera data to a greater number of known graphics.

As noted above in at least some embodiments an augmented reality output may be generated based on both camera data e.g. based on the graphic identified at and also based on the sensor data from a sensor . Accordingly in at least some embodiments a graphic in the graphic database may have one or more predetermined criteria associated with that graphic. The predetermined criteria may specify one or more sensor conditions and may associate such sensor conditions with a specific device generated portion for an augmented reality output . If such conditions are found to exist i.e. if the sensor data satisfies the predetermined criteria then the device generated portion associated with that sensor condition and that graphic may be selected and used to generate the augmented reality output .

For example in the embodiment of each of the two known graphics are associated with separate first predetermined criteria and second predetermined criteria. These criteria are separate in the sense that the first predetermined criteria associated with the first known graphic need not be the same as the first predetermined criteria associated with the second known graphic.

In the illustrated embodiment if at the electronic device determines that a graphic contained in the camera data corresponds to a first known graphic then at the electronic device may determine whether sensor data obtained from the sensor satisfies first predetermined criteria related to the first known graphic. In at least some embodiments the predetermined criteria may include a threshold. For example in at least some embodiments the predetermined criteria may require that the sensor data represent a number which is greater than a threshold. In other embodiments the predetermined criteria may require that the sensor data represent a number which is less than the threshold. For example in one embodiment the predetermined criteria may require that the altitude of the electronic device be greater than a predetermined threshold. In other embodiments the predetermined criteria may require that a location of the electronic device be within a certain distance from a fixed location. Other predetermined criteria may be used in other embodiments.

If at the electronic device determines that the sensor data from the sensor satisfies the first predetermined criteria associated with the first known graphic then at the electronic device may generate an output on the electronic device based on the specific device generated portion associated with that predetermined criteria and that known graphic. For example in the illustrated embodiment the electronic device may generate a first animation. The first animation is an animation which is associated with the sensor condition and with the graphic identified at . The first animation may form the device generated portion of the augmented reality output .

If however at the electronic device determines that the sensor data from the sensor does not satisfy the first predetermined criteria associated with the first known graphic then at the electronic device may determine whether second predetermined criteria associated with the first known graphic is satisfied. If so then at the electronic device may generate an output on the electronic device based on the specific device generated portion associated with that predetermined criteria and that known graphic. For example in the illustrated embodiment the electronic device may generate a second animation. The second animation is an animation which is associated with the sensor condition which was found to exist at and with the graphic identified at . The second animation may form the device generated portion of the augmented reality output . The second animation is different than the first animation.

If at the electronic device determines that the graphic included in the camera data corresponds to the second known graphic which may be determined at then the electronic device may evaluate the sensor data against one or more predetermined conditions associated with that known graphic. For example in the embodiment of at the electronic device determines whether the sensor data satisfies first predetermined criteria related to the second known graphic. That is the electronic device determines whether a sensor condition associated with the second known graphic exists. If so then at the electronic device may generate an output on the electronic device based on the specific device generated portion associated with that predetermined criteria and that known graphic. For example in the illustrated embodiment the electronic device may generate a third animation. The third animation is an animation which is associated with the sensor condition found to exist at and with the graphic identified at . The third animation may form the device generated portion of the augmented reality output . In at least some embodiments the third animation may be different than the first animation of and the second animation of .

If at the electronic device determines that the sensor data does not satisfy the first predetermined criteria associated with the second known graphic then at the electronic device may determine at whether second predetermined criteria associated with the second known graphic is satisfied. If so then at the electronic device may generate an output on the electronic device based on the specific device generated portion associated with that predetermined criteria and that known graphic. For example in the illustrated embodiment the electronic device may generate a fourth animation. The fourth animation is an animation which is associated with the sensor condition which was found to exist at and with the graphic identified at . The fourth animation may form the device generated portion of the augmented reality output . The second animation is different than the third animation and may be different from the first animation of and the second animation of .

While the example embodiment of illustrated an embodiment in which each known graphic was associated with two sensor conditions i.e. two predetermined criteria in other embodiments one or more of the known graphics may be associated with a greater or lesser number of sensor conditions.

In at least some embodiments an augmented reality output may depend on both the camera data and also on the location of the electronic device and or the card . That is the location of the electronic device and or the card may affect the augmented reality output .

Referring now to an example of one such method is illustrated. The method may in at least some embodiments be performed at of or . The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

In at least some embodiments the method may be performed by a geocaching application. That is a geocaching application which may reside in memory of the electronic device may include processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . Geocaching is a sporting activity in which a participant attempts to find containers also called geocaches or caches which are hidden in the real world. In at least some embodiments such containers may include a card of the type described above with reference to . In such embodiments the graphic on the card and the location of the card could affect the augmented reality output of the electronic device .

First at the electronic device may attempt to identify a graphic in the camera data. This may be done in the manner described above with reference to .

Next at the electronic device identifies the location of the electronic device from the sensor data obtained from the sensor . For example in at least some embodiments the sensor is a location sensor which generates sensor data based on the location of the electronic device .

Next at the electronic device generates the augmented reality output on the output interface of the electronic device based on the location of the electronic device and also based on the graphic identified at . The output may be generated in the manner described above with reference to of . For example the output may be generated on the display of the electronic device .

In at least some embodiments an augmented reality output may depend on both the camera data and also on the direction of the electronic device e.g. relative to magnetic north and or the card . That is the direction of the electronic device and or the card may affect the augmented reality output .

Referring now to an example of one such method is illustrated. The method may in at least some embodiments be performed at of or . The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

First at the electronic device may attempt to identify a graphic in the camera data. This may be done in the manner described above with reference to .

Next at the electronic device identifies the direction of the electronic device and or the card based on the sensor data. In at least some such embodiments the sensor may be an electronic compass which generates sensor data which specifies direction information. The direction information may for example specify the direction of magnetic north relative to the electronic device . In at least some embodiments the electronic compass is a magnetometer.

In at least some embodiments at the electronic device uses the direction information from the sensor and the orientation of the graphic in the camera data to determine the orientation of the card. That is the orientation of the card relative to the electronic device which may be determined by analyzing the camera data and the orientation of the camera relative to magnetic north which may be determined from the sensor data may be used to determine the orientation of the card relative to magnetic north. That is an absolute orientation of the card may be determined.

Next at the electronic device generates the augmented reality output on the output interface of the electronic device based on the direction of the electronic device and or the card and also based on the graphic identified at . The output may be generated in the manner described above with reference to of . For example the output may be generated on the display of the electronic device .

Thus the augmented reality output may be affected by the direction of the card and or the electronic device .

In at least some embodiments an augmented reality output may depend on both the camera data and also on the velocity of movement of the electronic device . That is the velocity at which the electronic device is moving may affect the augmented reality output . For example in at least some embodiments a different augmented reality output will be generated when the electronic device is moving than will be generated when the electronic device is stationary.

Referring now to an example of one such method is illustrated. The method may in at least some embodiments be performed at of or . The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

First at the electronic device may attempt to identify a graphic in the camera data. This may be done in the manner described above with reference to .

Next at the electronic device identifies a velocity associated with the electronic device based on the sensor data. That is the electronic device determines a rate of movement of the electronic device. In at least some embodiments the sensor is a location sensor which generates sensor data based on the location of the electronic device . In some such embodiments the electronic device may determine its velocity based on the rate at which the location of the electronic device changes. That is the electronic device may evaluate its change of distance and the time associated with that change of distance in order to determine its velocity. Other methods of determining velocity based on the sensor data may be used in other embodiments.

Next at the electronic device generates the augmented reality output on the output interface of the electronic device based on the velocity of the electronic device and also based on the graphic identified at . The output may be generated in the manner described above with reference to of . For example the output may be generated on the display of the electronic device .

In at least some embodiments an augmented reality output may depend on both the camera data and also on the orientation of the electronic device . For example in at least some embodiments a different augmented reality output will be generated when the electronic device is oriented such that its camera is directed upward than will be generated when the electronic device is oriented such that the camera points downward.

Referring now to an example of one such method is illustrated. The method may in at least some embodiments be performed at of or . The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

First at the electronic device may attempt to identify a graphic in the camera data. This may be done in the manner described above with reference to .

Next at the electronic device determines an orientation of the electronic device based on sensor data received from a sensor which may be an orientation sensor such as an accelerometer . For example the electronic device may determine whether the electronic device is oriented so that a camera associated with that electronic device is directed upwardly and or whether the electronic device is oriented so that a camera associated with that electronic device is directed downwardly. That is the electronic device effectively determines whether the card is above or below the electronic device .

Next at the electronic device generates the augmented reality output on the output interface of the electronic device based on the orientation of the electronic device and also based on the graphic identified at . The output may be generated in the manner described above with reference to of . For example the output may be generated on the display of the electronic device . In at least some embodiments if the electronic device determines at that the electronic device is oriented so that the camera is pointed upwardly i.e. if the electronic device determines that the card is above the electronic device then the augmented reality output may have a first effect. For example in at least some embodiments the device generated portion of the augmented reality output may appear to be hanging from the real world portion .

In at least some embodiments if the electronic device determines at that the electronic device is orientated so that the camera is pointed downwardly i.e. if the electronic device determines that the card is below the electronic device then the augmented reality output may have a second effect which may be different than the first effect . For example in at least some embodiments the device generated portion of the augmented reality output may appear to be standing on the real world portion .

In at least some embodiments an augmented reality output may depend on both the camera data and also on the altitude of the electronic device . That is altitude of the electronic device may affect the augmented reality output . For example in at least some embodiments a different augmented reality output will be generated when the electronic device is above a certain threshold than will be generated when the electronic device is below a certain threshold.

Referring now to an example of one such method is illustrated. The method may in at least some embodiments be performed at of or . The method includes features which may be provided by an electronic device such as the electronic device of and or . More particularly one or more application or module associated with the electronic device such as the augmented reality application may contain processor readable instructions for causing a processor associated with the electronic device to perform one or more steps of the method of . That is in at least some example embodiments the electronic device may be configured to perform the method of .

In at least some embodiments one or more of the functions or features of the method of may be performed in whole or in part by another system software application module component or device apart from those specifically listed above.

First at the electronic device may attempt to identify a graphic in the camera data. This may be done in the manner described above with reference to .

Next at the electronic device identifies an altitude associated with the electronic device from sensor data received from a sensor of the electronic device. In some embodiments the sensor is an altimeter. The altimeter generates sensor data which specifies an altitude associated with the electronic device. The altimeter may for example be provided by the location sensor. For example the altimeter may determine altitude by four way trilateration. For example where the location sensor is a GPS sensor altitude of the electronic device may be determined by trilateration with four or more satellites.

Next at the electronic device generates the augmented reality output on the output interface of the electronic device based on the altitude of the electronic device and also based on the graphic identified at . The output may be generated in the manner described above with reference to of . For example the output may be generated on the display of the electronic device . In at least some embodiments the augmented reality output may be generated by comparing the altitude of the electronic device to a predetermined threshold. A different augmented reality output may be generated if the altitude of the electronic device exceeds the threshold than will be generated if the altitude of the electronic device does not exceed the threshold. For example in some embodiments when the sensor data indicates that the altitude is greater than a predetermined threshold a high altitude effect may be applied to the augmented reality output. For example a graphic in the augmented reality output may appear to be on a mountain or in an airplane. By way of example the person graphic of may be shown to climb a mountain or board an airplane. In some embodiment when the sensor data indicates that the altitude is less than the threshold a low altitude effect may be applied to the augmented reality output. For example a graphic in the augmented reality output may appear to be at ground level.

While the embodiments described herein discussed the use of a card to provide an augmented reality experience on an electronic device in other embodiments the methods and devices described below may be used with an object of another type. For example in some embodiments a game piece may be used to provide an augmented reality experience on an electronic device . The game piece may be an object of the type commonly used with board games. The game piece may in some embodiments be constructed of plastic metal and or wood.

While the present application is primarily described in terms of methods a person of ordinary skill in the art will understand that the present application is also directed to various apparatus such as a handheld electronic device and a server. The handheld electronic device and the server includes components for performing at least some of the example aspects and features of the described methods be it by way of hardware components such as the memory and or the processor software or any combination of the two or in any other manner. Moreover an article of manufacture for use with the apparatus such as a pre recorded storage device or other similar computer readable medium including program instructions recorded thereon or a computer data signal carrying computer readable program instructions may direct an apparatus to facilitate the practice of the described methods. It is understood that such apparatus articles of manufacture and computer data signals also come within the scope of the present application.

The term computer readable medium as used herein means any medium which can store instructions for use by or execution by a computer or other computing device including but not limited to a portable computer diskette a hard disk drive HDD a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or flash memory an optical disc such as a Compact Disc CD Digital Versatile Disc DVD or Blu Ray Disc and a solid state storage device e.g. NAND flash or synchronous dynamic RAM SDRAM .

Example embodiments of the present application are not limited to any particular operating system system architecture mobile device architecture server architecture or computer programming language.

The various embodiments presented above are merely examples and are in no way meant to limit the scope of this application. Variations of the innovations described herein will be apparent to persons of ordinary skill in the art such variations being within the intended scope of the present application. In particular features from one or more of the above described example embodiments may be selected to create alternative example embodiments including a sub combination of features which may not be explicitly described above. In addition features from one or more of the above described example embodiments may be selected and combined to create alternative example embodiments including a combination of features which may not be explicitly described above. Features suitable for such combinations and sub combinations would be readily apparent to persons skilled in the art upon review of the present application as a whole. The subject matter described herein and in the recited claims intends to cover and embrace all suitable changes in technology.

