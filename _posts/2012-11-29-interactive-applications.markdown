---

title: Interactive applications
abstract: Disclosed are various embodiments to facilitate interactive experiences. Interactive content includes video content that is streamed to a client device, such as a set-top box. Complementary content is transmitted to a controller device, such as a tablet computing system and/or smartphone. Input obtained from the controller device can affect an update to the video content and/or complementary content.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09398342&OS=09398342&RS=09398342
owner: Amazon Technologies, Inc.
number: 09398342
owner_city: Seattle
owner_country: US
publication_date: 20121129
---
Interactive content is often consumed via personal computing devices such as tablet devices personal computers and or smartphones. Non interactive streaming video content is often consumed via televisions set top boxes and or personal computing devices. Interactive games are often consumed via personal computing devices and or gaming consoles where user feedback and or inputs are obtained via the computing device and or gaming console on which the content is consumed.

Embodiments of the present disclosure are directed to facilitating interactive applications that are at least in part remotely executed over a network. Applications such as games educational applications and or other interactive content can employ multiple client devices that are in communication via a network with a computing environment in which interactive content is executed. To this end video audio and or other data generated by the interactive application may be sent over the network to a remotely located client device. Input commands for the interactive application may be obtained over the network from the remotely located client devices and provided to the interactive application.

In one scenario one client device can be configured to render video content on a display device such as a television while another client device can be configured as a controller and or second screen device to provide complementary content in tandem with the video content shown on the display device. For example a controller can comprise a tablet device that is equipped with a touchscreen input device and or other form of input device.

As one example illustrated in shown is an environment illustrating an interactive experience facilitated by embodiments of the present disclosure. depicts an environment in which a client device is coupled to a display device . The client device is in communication via a network with a computing environment from which interactive content is retrieved and which the client device renders on the display device . In the depicted example the client device facilitates rendering of video content on the display device . In one embodiment a client device can comprise a set top box a personal computer or any other device that can communicate via a network as well as render video on a display device .

The environment also illustrates a controller device that is independently in communication via a network with a computing environment from which interactive content is retrieved. In the depicted example the controller device can render complementary content that is associated with the interactive content which in the case of is a high twitch action video game where content associated with the game is rendered on both devices and user inputs can be obtained from the controller device . As will be described herein interactive content can take many forms and may also involve a multi user experience where multiple users are providing inputs to the computing environment via a controller device as well as viewing complementary content on multiple controller devices that may or may not be disparately located.

With reference to shown is a networked environment according to various embodiments. The networked environment includes a computing environment and at least one client device which are in data communication with each other via a network . The network may include for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks.

The computing environment may comprise for example a server computer or any other system providing computing capability. Alternatively the computing environment may employ a plurality of computing devices that are arranged for example in one or more server banks or computer banks or other arrangements. Such computing devices may be located in a single installation or may be distributed among many different geographical locations. For example the computing environment may include a plurality of computing devices that together may comprise a cloud computing resource a grid computing resource and or any other distributed computing arrangement. In some cases the computing environment may correspond to an elastic computing resource where the allotted capacity of processing network storage or other computing related resources may vary over time.

Various applications and or other functionality may be executed in the computing environment according to various embodiments. Also various data is stored in a data store that is accessible to the computing environment . The data store may be representative of a plurality of data stores as can be appreciated. The data stored in the data store for example is associated with the operation of the various applications and or functional entities described below.

The components executed on the computing environment for example include an interactivity application a plurality of interactive content . . . N and other applications services processes systems engines or functionality not discussed in detail herein. The interactivity application may correspond to a type of application session server. The interactivity application is executed to launch interactive content sessions in response to requests from users. In this sense the interactivity application establishes an interactive content session corresponding to an interactive application that is requested by a user via a controller and or client . The interactivity application is also executed to capture input data from the clients and or controllers and provide the input data to the interactive content session.

The interactivity application is also executed to send video content and or complementary content that is captured from the interactive content to the clients and or controllers . The interactivity application may communicate with a client and or controller over various protocols such as for example hypertext transfer protocol HTTP simple object access protocol SOAP representational state transfer REST real time transport protocol RTP real time streaming protocol RTSP real time messaging protocol RTMP user datagram protocol UDP transmission control protocol TCP and or other protocols for communicating data over the network . The interactivity application may be configured to maintain state information associated with the executing interactive content .

In various embodiments the interactivity application may be configured to transmit video content as well as complementary content associated with particular interactive content. For example video content can be streamed to a client which can be rendered by the client on a display device in communication with the client . Additionally complementary content which can include video and other types of content can be streamed to the controller and rendered by the controller on a display. A given interactive content session can also incorporate multiple controllers that are in communication with the interactivity application via the network . In this sense the interactivity application can support a multi user interactive experience in which multiple users can participate in an interactive experience via multiple controllers that render complementary content.

The interactive application may correspond for example to a game an interactive story educational content or other types of applications. As non limiting examples the interactive application may correspond to a high twitch action game a first person shooter game an action game an adventure game a party game trivia game educational games a role playing game a simulation game a strategy game a vehicle simulation game and or other types of games. The interactive applications may also correspond to mobile phone applications computer aided design CAD applications computer aided manufacturing CAM applications photo manipulation applications video editing applications office productivity applications operating systems and associated applications emulators for operating systems architectures and capabilities not present on a consumer device and other applications and combinations of applications. The interactive applications may further correspond to interactive movies stories and or other forms of content in which progression of a storyline or progress through an interactive world depends upon user input and or selections via a controller .

The state information that is maintained by the interactivity application includes various data relating to application sessions that are currently active. For example the state information may track the users that are currently participating in an application session status information associated with the users security permissions associated with the application session e.g. who can or cannot join and so on. In some embodiments some or all of the state information may be discarded when an application session ends. The data stored in the data store includes for example interactive applications saved state data user data and potentially other data. The interactive applications correspond to a library of different applications that provide interactive content and that are available to be launched as interactive applications . The interactive applications may correspond to executable code within the computing environment .

The saved state data corresponds to session states that have been saved by the interactivity application and that correspond to an interactive content session. Because the interactive applications may be executed in a virtualized environment the interactivity application may write state information to a virtual location which is then mapped for storage in the data store as the saved state data . The saved state data may correspond to data saved normally by the interactive application or may correspond to a memory image of the interactive application that may be resumed at any time. The user data includes various data related to the users of the interactive applications such as for example types of computing devices associated with a user security credentials application preferences billing information a listing of other users that are permitted to join application sessions started by the user and so on. The user data may also identify media streaming devices set top boxes tablet devices smartphones or other devices that are associated with a user s account. To this end the user data may include one or more hardware or software identifiers that identify a device. In one embodiment a user may install a client application on a device and register the device with the interactivity application by providing user authentication credentials which can cause the device to be associated with the user s account.

The client and or controller are representative of one or more devices that may be coupled to the network and that can be independently in communication with the computing environment . The clients and or controllers may be geographically diverse. The clients and or controllers may comprise for example a processor based system such as a computer system. Such a computer system may be embodied in the form of a desktop computer a laptop computer personal digital assistants cellular telephones smartphones set top boxes music players web pads tablet computer systems game consoles electronic book readers or other devices with like capability.

The client may include a display interface that is coupled to a display device. A display device may comprise for example one or more devices such as cathode ray tubes CRTs liquid crystal display LCD screens gas plasma based flat panel displays LCD projectors or other types of display devices etc. The client may therefore render video content provided by the interactivity application on a display device via the display interface . In some cases such a display device may be a display that is integrated within the client . For example a client may comprise a tablet device a laptop computer a television or any other type of device having an integrated display.

In some embodiments the client and or controller may include one or more input devices and or input devices respectively. The input devices and or input devices may comprise for example devices such as touchscreen input devices keyboards mice joysticks accelerometers light guns game controllers touch pads touch sticks push buttons optical sensors microphones webcams and or any other devices that can provide user input. Additionally various input devices and or input devices may incorporate haptic technologies in order to provide feedback to the user.

The client may be configured to execute various applications such as a client application and or other applications. The client application is executed to allow a user to launch join play or otherwise interact with interactive content executed by the computing environment . Additionally the client application facilitates rendering of video content that is streamed via the network by the interactivity application and that is associated with interactive content . The client application is also configured to obtain video content over the network from the computing environment and render a screen on the display . To this end the client application may include one or more video and audio players to play out a media stream generated by an interactive application . In one embodiment the client application comprises a plug in or other client side code executed within a browser application.

The client may be configured to execute applications beyond the client application such as for example browser applications email applications instant message applications and or other applications. In some embodiments multiple clients may be employed for one or more users to interact with the interactive application .

The controller may be configured to execute a controller application and or other applications. The controller application is executed to allow a user to view complementary content that is related to interactive content requested by the user and or video content that is rendered on a display device by the client application . For example the complementary content may comprise text video and or imagery that is related to the video content rendered by the client application . Additionally the controller application can also capture user inputs from a user and transmit the user inputs via the network to the interactivity application which can update the video content provided to the client and or the complementary content provided to the controller in response.

Accordingly as briefly described above the interactivity application can facilitate interactive experiences that involve client device that renders video content provided by the interactivity application via the network as well as a controller device that is independently in communication with the interactivity application via the network . In many embodiments the controller can comprise a tablet device a smartphone or any other device with an integrated display . As noted above the controller can also comprise one or more input device that can be captured by a controller application executed by the controller and transmitted via the network to the interactivity application .

The depicted framework can facilitate various types of interactive experiences that can be provided to a user. For example an interactive application can be requested by a user via a controller to be consumed in tandem with a client such as a set top box and or media streamer. In response the interactivity application can establish a session associated with the requested interactive application on behalf of the user account and or a client that is paired with the user account. Accordingly the interactivity application can execute an instance of interactive content and provide video content to the client as well as complementary content to the controller .

Interactive content can comprise for example interactive movies television programming or other types of content in which the user can navigate through a storyline and or virtual world where the video content provided to the client varies depending upon actions taken by the user in a user interface rendered by the controller . In some examples the complementary content rendered on the controller can represent an alternate view replay view and or alternative camera angle associated with live and or recorded programming. As another example the complementary content can represent content that supplements the video content rendered by the client . For example programming rendered by the client may involve a storyline surrounding a criminal investigation. Accordingly the complementary content can comprise items that are evidence related to the criminal investigation as the objects are discovered and or collected within the storyline as it is viewed by a user as it is streamed by the client . Because the interactivity application is providing the video content as well as complementary content the interactivity application can determine when to update the complementary content in such a scenario.

Interactive content can also comprise interactive games and or educational content in which user inputs can be captured by the controller application and provided to the interactivity application as input data by the controller via the network . The interactivity application can then update the video content and or complementary content to reflect the user input. For example an interactive game can comprise a trivia game where users answer questions and accumulate points for correctly answered questions. The trivia game can also comprise a competitive endeavor where users are pitted against other users who might be disparately located and or competing by acting on video data rendered by the same client device e.g. located within the vicinity of the same client device .

Interactive content can also comprise for example high twitch action video game where a view of game action is presented in the form of video content rendered by the client device and an alternative view associated with the game action is presented in the form of complementary content that is rendered by the controller . For example the video content rendered by the client and complementary content rendered by the controller can represent differing angles of the game action. As another example the controller can render an alternative view of game action in combination with a controller user interface such as in the example shown in . As another example the controller can render a controller user interface through which the user can interact with the interactive content and these interactions can be captured by the controller application and provided to the interactivity application in the form of input data .

Therefore in the above examples as well as in other examples of interactive experiences that can be facilitated by the interactivity application the interactivity application can stream video content and or complementary content to a client and generate one or more interactive events that cause the video content and or complementary content to be updated. An interactive event can correspond to user input captured by the controller application and transmitted to the interactivity application via the network . An interactive event can also correspond to a timecode being reached within interactive content that is being consumed by the client device and controller . In other words the interactivity application can generate an interactive event in response to reaching a certain point within video content and or complementary content that is being streamed via the network to the client device and or controller respectively.

An interactive event can also be triggered upon an occurrence in an interactive game educational content or other type of interactive content . For example upon reaching a certain milestone within interactive content the interactivity application can generate an interactive event that causes the video content and or complementary content to be updated.

Accordingly in order to facilitate an interactive experience the interactivity application can also facilitate registration of a controller with an interactive content session. Registration of a controller allows the interactivity application to provide complementary content associated with the video content that is provided to a corresponding client . In one embodiment the interactivity application can request authentication of a user via a controller as well as obtain a request for interactive content via a user interface generated by the controller application which is in communication with the interactivity application . The user may select an appropriate client device via the user interface that is paired with an account of the user to receive video content associated with an interactive content session. Upon receiving such a request from the controller application the interactivity application can initiate the session including interactive content that involves appropriate video content being transmitted to the selected client as well as complementary content being served to the controller .

In another embodiment the interactivity application can obtain a request for interactive content from a client device where the request includes a user and or device identifier with which the interactivity application can determine whether the user is authorized the requested interactive content . In response the interactivity application can establish an interactive content session and stream video content associated with the requested interactive content to the client device . Additionally the user may join the interactive content session with a controller such as with a tablet device and or smartphone. In response the interactivity application can stream complementary content to the controller application executed on the controller .

A user may join an interactive content session with a controller in various ways. In one embodiment the interactivity application can include within the video content rendered by the client a session identifier that a user can enter in the controller application . The controller application can provide the session identifier entered by the user to the interactivity application which can validate the session identifier to identify which interactive content session with which to join the controller . Accordingly such a session identifier can be unique among the various interactive content sessions being executed by the interactivity application . In some embodiments such a session identifier can comprise a barcode such as a quick response code QR code that is embedded within video content rendered by the client device . In this scenario the user may scan the QR code using a barcode scanner and or camera integrated within the controller . The session identifier can also be obtained by the controller from the client device via a local area network connection between the client device and controller .

Reference is now made to which illustrate an example of an interactive experience facilitated by the interactivity application according to various embodiments of the disclosure. In the depicted example the client device comprises a set top box or a media streamer that is coupled to a display device . The client device is in communication with the interactivity application via a network connection such as the internet. The controller is also independently in communication with the interactivity application via a network connection. Accordingly the interactivity application can provide video content that is rendered by the client device on a display as well as complementary content that is rendered by the controller . As shown in the video content can be related to an interactive experience such as an interactive game educational content or other types of content.

In the depicted example the interactivity application has transmitted video content and complementary content to the client device and controller respectively. The complementary content includes content that is related to the video content . The complementary content in the depicted example also includes a user interface with which a user may interact to further the interactive experience. In the example of when the user selects an answer related to a question that can be presented as textual content on the controller and or rendered by the client the response can be transmitted from the controller to the interactivity application via the network .

In response the interactivity application can generate an interactive event which causes the interactivity application to generate an update to the video content streamed to the client and or the complementary content streamed to the controller . Referring to shown is an example of how the interactivity application can update the video content and or complementary content in response to input data obtained from the controller . In the example of the user has provided user input via the controller application executed by the controller which generates and communicates input data corresponding to the user s selection to the interactivity application via the network .

The input data corresponding to the particular interactive content session causes an interactive event which in turn causes the interactivity application to update the video content and or complementary content to reflect the user s input and or selection. As shown in the example of such an update can take the form of advancing to a different level and or stage in an interactive game. In other examples described above such an update can take the form of advancing a storyline in an interactive storytelling experience and generating a corresponding update to the video content and or complementary content .

Moving on to shown is a flowchart that provides one example of the operation of a portion of the interactivity application according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the interactivity application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing environment according to one or more embodiments.

First in box the interactivity application can obtain a request for interactive content on behalf of a client controller and or a user. Such a request can take the form of a request to execute an interactive application that includes streaming video content and or complementary content from the interactivity application . The interactivity application can also establish a session corresponding to the request in box . The session can identify a user account associated with the session the requested interactive content as well as an identifier corresponding to a client device and or controller associated with the session.

In box the interactivity application can then transmit video content corresponding to the requested interactive content to the client device associated with the session. In box the interactivity application can also transmit complementary content corresponding to the requested interactive content to the client device associated with the session. In the context of this disclosure video content and or complementary content can be streamed to the client device and or controller respectively. Alternatively video content and or complementary content can also be downloaded to the client device and or controller and saved in a mass storage device that is accessible to either device.

In box the interactivity application can determine whether an interactive event related to the interactive content associated with the session should be generated. As noted above an interactive event can comprise user input from the controller reaching a certain portion in a video stream or any other event or occurrence. In response to the interactive event the interactivity application can then determine in box whether the video content rendered by the client should be updated or changed in any way. If so then in box the interactivity application updates the video content correspondingly. In response to the interactive event the interactivity application can also determine in box whether the complementary content rendered by the controller should be updated or changed in any way. If so then in box the interactivity application updates the complementary content correspondingly.

Moving on to shown is a flowchart that provides one example of the operation of a portion of the interactivity application according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the interactivity application that facilitates registering of a controller device with an interactive content session. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing environment according to one or more embodiments.

First in box the interactivity application establishes an interactive content session associated with content requested on behalf of a client . The session can also be associated with a session identifier that uniquely identifies the session with respect to other interactive content sessions executed by the interactivity application . In box the interactivity application can communicate the session identifier to one or more controllers .

In some embodiments the session identifier can comprise a barcode such as a quick response code QR code that is embedded within video content rendered by the client device . In this scenario the user may scan the QR code using a barcode scanner and or camera integrated within the controller . The session identifier can also be obtained by the controller from the client device via a local area network connection between the client device and controller . In other embodiments the session identifier can be manually inputted into an application executed by the controller .

The controller can transmit the session identifier along with an identifier that identifies the controller to the interactivity application . Accordingly in box the interactivity application can obtain the controller identifier corresponding to the controller as well as potentially the session identifier corresponding to the interactive content session. In box the interactivity application can register the controller with the interactive content session.

With reference to shown is a schematic block diagram of the computing environment according to an embodiment of the present disclosure. The computing environment includes one or more appropriate computing device . The appropriate computing device includes at least one processor circuit for example having a processor and a memory both of which are coupled to a local interface . To this end the appropriate computing device may comprise for example at least one server computer or like device. The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated.

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor is the interactivity application and potentially other applications. Also stored in the memory may be a data store and other data. In addition an operating system may be stored in the memory and executable by the processor .

It is understood that there may be other applications that are stored in the memory and are executable by the processor as can be appreciated. Where any component discussed herein is implemented in the form of software any one of a number of programming languages may be employed such as for example C C C Objective C Java JavaScript Perl PHP Visual Basic Python Ruby Delphi Flash or other programming languages.

A number of software components are stored in the memory and are executable by the processor . In this respect the term executable means a program file that is in a form that can ultimately be run by the processor . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory and run by the processor source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory and executed by the processor or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memory to be executed by the processor etc. An executable program may be stored in any portion or component of the memory including for example random access memory RAM read only memory ROM hard drive solid state drive USB flash drive memory card optical disc such as compact disc CD or digital versatile disc DVD floppy disk magnetic tape or other memory components.

The memory is defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memory may comprise for example random access memory RAM read only memory ROM hard disk drives solid state drives USB flash drives memory cards accessed via a memory card reader floppy disks accessed via an associated floppy disk drive optical discs accessed via an optical disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

Also the processor may represent multiple processors and the memory may represent multiple memories that operate in parallel processing circuits respectively. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any processor and any of the memories or between any two of the memories etc. The local interface may comprise additional systems designed to coordinate this communication including for example performing load balancing. The processor may be of electrical or of some other available construction.

Although the interactivity application and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits having appropriate logic gates or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowcharts of show the functionality and operation of an implementation of portions of the interactivity application . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor in a computer system or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowcharts of show a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in may be executed concurrently or with partial concurrence. Further in some embodiments one or more of the blocks shown in may be skipped or omitted. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also any logic or application described herein including the interactivity application that comprises software or code can be embodied in any non transitory computer readable medium for use by or in connection with an instruction execution system such as for example a processor in a computer system or other system. In this sense the logic may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the logic or application described herein for use by or in connection with the instruction execution system.

The computer readable medium can comprise any one of many physical media such as for example magnetic optical or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives memory cards solid state drives USB flash drives or optical discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

