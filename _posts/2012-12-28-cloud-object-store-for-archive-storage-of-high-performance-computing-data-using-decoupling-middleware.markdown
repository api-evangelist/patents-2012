---

title: Cloud object store for archive storage of high performance computing data using decoupling middleware
abstract: Cloud object storage is enabled for archived data, such as checkpoints and results, of high performance computing applications using a middleware process. A plurality of archived files, such as checkpoint files and results, generated by a plurality of processes in a parallel computing system are stored by obtaining the plurality of archived files from the parallel computing system; converting the plurality of archived files to objects using a log structured file system middleware process; and providing the objects for storage in a cloud object storage system. The plurality of processes may run, for example, on a plurality of compute nodes. The log structured file system middleware process may be embodied, for example, as a Parallel Log-Structured File System (PLFS). The log structured file system middleware process optionally executes on a burst buffer node.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09069778&OS=09069778&RS=09069778
owner: Los Alamos National Security, LLC
number: 09069778
owner_city: Los Alamos
owner_country: US
publication_date: 20121228
---
This invention was made under a Cooperative Research and Development Agreement between EMC Corporation and Los Alamos National Security LLC. The United States government has rights in this invention pursuant to Contract No. DE AC52 06NA25396 between the United States Department of Energy and Los Alamos National Security LLC for the operation of Los Alamos National Laboratory.

The present application is related to U.S. patent application Ser. No. 13 730 058 filed Dec. 28 2012 entitled Cloud Object Store for Checkpoint of High Performance Computing Applications Using Decoupling Middleware. 

The field relates generally to data storage and more particularly to cloud storage for high performance computing applications.

High performance computing HPC techniques are used in many industries and applications for implementing computationally intensive models or simulations. For example the Department of Energy uses a large number of distributed compute nodes tightly coupled into a supercomputer to model physics experiments. In the oil and gas industry parallel computing techniques are often used for computing geological models that help predict the location of natural resources.

High performance computing applications typically require that simulation checkpoints and results are archived for long periods of time such as several years . A small number of highly complex parallel file systems are typically employed to store the archived checkpoints and results. Such file systems are not economical in the sense that they need to solve challenging problems for a relatively small market.

An increasing number of companies and other enterprises are reducing their costs by migrating portions of their information technology infrastructure to cloud service providers. For example virtual data centers and other types of systems comprising distributed virtual infrastructure are coming into widespread use.

Cloud object storage amortizes the software development and hardware infrastructure costs across a much larger number of parties thereby reducing the cost significantly. In cloud based information processing systems enterprises in effect become tenants of the cloud service providers. However by relinquishing control over their information technology resources these cloud tenants expose themselves to additional potential security threats. For example a given tenant may be inadvertently sharing physical hardware resources of a cloud computing environment with other tenants that could be competitors or attackers. Cloud storage systems have addressed such security concerns with multi tenancy mechanisms.

A need exists for improved storage of archived checkpoints and results for high performance computing applications.

Illustrative embodiments of the present invention provide cloud object storage for archived data such as checkpoints and results of high performance computing applications using a middleware process. According to one aspect of the invention a method is provided for storing a plurality of archived files generated by a plurality of processes in a parallel computing system by obtaining the plurality of archived files from the parallel computing system converting the plurality of archived files to objects using a log structured file system middleware process and providing the objects for storage in a cloud object storage system.

The plurality of processes may run for example on a plurality of compute nodes. The plurality of files may comprise for example checkpoint files generated by the plurality of compute nodes. The log structured file system middleware process may be embodied for example as a Parallel Log Structured File System PLFS . The log structured file system middleware process optionally executes on a burst buffer node.

Advantageously illustrative embodiments of the invention provide techniques for storing checkpoint files in a parallel computing system using a middleware process. These and other features and advantages of the present invention will become more readily apparent from the accompanying drawings and the following detailed description.

Illustrative embodiments of the present invention will be described herein with reference to exemplary cloud storage systems and associated computers servers storage devices and other processing devices. It is to be appreciated however that the invention is not restricted to use with the particular illustrative system and device configurations shown. Accordingly the term cloud storage system as used herein is intended to be broadly construed so as to encompass for example private or public cloud systems distributed over multiple geographically dispersed locations as well as other types of storage systems comprising multiple physical sites.

According to one aspect of the invention cloud object storage is employed for storing archived data such as checkpoints and results of high performance computing applications using decoupling middleware. Aspects of the present invention recognize that existing cloud object storage application programming interfaces APIs are not sufficient for the highly complex parallel IO workloads in HPC. Therefore a cloud object storage API is coupled with software middleware that transparently converts complex parallel Input Output I O file workloads into object based workloads for storage in a cloud storage system.

As indicated above high performance computing applications typically require that simulation checkpoints results and other data are archived for example in a corresponding tape archive system through N for long periods of time such as several years . The archived complex parallel I O through N comprised of the data to be archived is thus typically copied to the corresponding tape archive system through N. Thus aspects of the invention employ cloud object storage to store archived data of high performance computing applications such as the high performance computing applications executing on the sites through N of using a decoupled middleware process.

As shown in the archived complex parallel file based I O either directly from the high performance computing application through N or from storage in a corresponding parallel file system through N comprised of the data to be archived is processed by a corresponding I O Conversion Middleware process through N. The I O Conversion Middleware processes comprise a log structured file system middleware process such as a Parallel Log Structured File System PLFS as modified herein to provide the features and functions of the present invention. See for example John Bent et al. PLFS A Checkpoint Filesystem for Parallel Applications Association for Computing Machinery SC09 November 2009 incorporated by reference herein. I O Conversion Middleware processes are discussed further below in conjunction with .

The log structured file system middleware process can execute for example on a burst buffer node or on the corresponding compute node site . The burst buffer node can be embodied for example as an Active Burst Buffer Appliance ABBA commerically available from Los Alamos National Labs LANL and EMC Corporation. A burst buffer hardware node ensures that checkpoint performance is not sacrificed in the case where cloud storage might be slower than existing parallel file systems.

As shown in the I O conversion middleware process converts the archived complex parallel file based I O to a corresponding object based I O through N. The object based I O is provided to a cloud storage application programming interface API of a cloud object storage system . In one exemplary embodiment the I O conversion middleware process comprises a software module for providing the object based I O to the cloud storage application programming interface API .

The exemplary I O Conversion Middleware process comprises an I O transformation stage and an Abstract Storage Interface to a plurality of I O formats. The exemplary Abstract Storage Interface performs file I O and directory operations. The exemplary Abstract Storage Interface can be implemented as a Virtual C class.

For an exemplary set of I O formats the exemplary Abstract Storage Interface supports a Parallel Virtual File System PVFS I O format module a Portable Operating System Interface POSIX I O format module a Hadoop Distributed File System HDFS I O format module and a Simple Storage Service S3 I O format module provided by Amazon Web Services . It is noted that existing PLFS file systems provide an Abstract Storage Interface to a PVFS I O format a POSIX I O format and an HDFS I O format . An existing PLFS file system is extended as described herein to provide an Abstract Storage Interface to an S3 I O format module . It is noted that while aspects of the invention are described in conjunction with an exemplary S3 cloud storage protocol other cloud storage protocols could be employed as would be apparent to a person of ordinary skill in the art.

Each exemplary format through communicates with an API through of the associated file system such as the PVFS file system Mounted file system for POSIX and HDFS file system . In the case of a cloud storage system the S3 I O format communicates with an S3 API .

Since most cloud storage protocols use objects and not files the exemplary I O Conversion Middleware process converts a file interface into an object interface. For example the exemplary I O Conversion Middleware process converts files to a plurality of Get Put operations on a set of objects. In an object based cloud storage system such as the Amazon S3 system referenced above a put command passes data for an entire object and a get command retrieves the data for an entire object. See for example Amazon S3 Tools Command Line S3 Client Software and S3 Backup downloadable from http s3tools.org usage .

In addition since a number of cloud storage protocols do not provide directory operations the exemplary S3 I O format module of the I O Conversion Middleware process can handle directory operations by returning an error on directory operations building a namespace in its own private object and or embedding full directory paths into the name of each file object.

Further since a number of cloud storage protocols do not allow partial file I O and entire objects must be read and written the exemplary S3 format module of the I O Conversion Middleware process can handle this internally by buffering entire objects. The Abstract Storage Interface will issue partial read and write operations and the S3 I O format module will apply partial read and write operations to the buffer. The S3 I O format module will flush an entire object upon a write close and will fetch an entire object upon a read open.

The processing device in the processing platform comprises a processor coupled to a memory . The processor may comprise a microprocessor a microcontroller an application specific integrated circuit ASIC a field programmable gate array FPGA or other type of processing circuitry as well as portions or combinations of such circuitry elements and the memory which may be viewed as an example of a computer program product having executable computer program code embodied therein may comprise random access memory RAM read only memory ROM or other types of memory in any combination.

Also included in the processing device is network interface circuitry which is used to interface the processing device with the network and other system components and may comprise conventional transceivers.

The other processing devices of the processing platform are assumed to be configured in a manner similar to that shown for processing device in the figure.

Again the particular processing platform shown in is presented by way of example only and system may include additional or alternative processing platforms as well as numerous distinct processing platforms in any combination with each such platform comprising one or more computers servers storage devices or other processing devices.

It should again be emphasized that the above described embodiments of the invention are presented for purposes of illustration only. Many variations and other alternative embodiments may be used. For example the techniques are applicable to a wide variety of other types of devices and systems that can benefit from the replicated file system synchronization techniques disclosed herein. Also the particular configuration of system and device elements shown in can be varied in other embodiments. Moreover the various simplifying assumptions made above in the course of describing the illustrative embodiments should also be viewed as exemplary rather than as requirements or limitations of the invention. Numerous other alternative embodiments within the scope of the appended claims will be readily apparent to those skilled in the art.

