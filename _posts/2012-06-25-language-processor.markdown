---

title: Language processor
abstract: A referring expression processor which uses a probabilistic model and in which referring expressions including descriptive, anaphoric and deictic expressions are understood and generated in the course of dialogue is provided. The referring expression processor according to the present invention includes: a referring expression processing section which performs at least one of understanding and generation of referring expressions using a probabilistic model constructed with a referring expression Bayesian network, each referring expression Bayesian network representing relationships between a reference domain (D) which is a set of possible referents, a referent (X) in the reference domain, a concept (C) concerning the referent and a word (W) which represents the concept; and a memory which stores data necessary for constructing the referring expression Bayesian network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08868407&OS=08868407&RS=08868407
owner: Honda Motor Co., Ltd.
number: 08868407
owner_city: Tokyo
owner_country: JP
publication_date: 20120625
---
The present invention relates to a referring expression processor for processing referring expressions a language processor including the referring expression processor and a referring expression processing method.

Assume that a robot communicates with a person using a speech dialogue system or the like. Assume that there exit a plurality of desks and a plurality of chairs in a room and a person specifies a desk by a referring expression the white desk with red legs . Referring expressions are language expressions intended by speakers to pointing at specific entities of interest to hearers. Operation of a language processor of a robot for identifying the desk specified by a person based on the referring expression is referred to as understanding of referring expressions. Operation of the language processor of the robot for generating referring expressions which represent the desk specified by the robot and which is easily understandable by persons in order to make a person identify the desk is referred to as generation of referring expressions. Referring expressions made by persons as a matter of course depend on knowledge of the persons. Accordingly the language processor has to utilize data on knowledge of persons when carrying out understanding and generation of referring expressions.

A probabilistic model can be used by the language processor to utilize data on knowledge of persons when carrying out understanding and generation of referring expressions.

JP2010 224536A filed by Honda Motor discloses a language processor which handles referring expressions for referring to portions of an object and a probability calculating method used in language processing by the language processor.

However JP2010 224536A does not disclose a mechanism by which referring expressions including descriptive anaphoric and deictic expressions are understood and generated in the course of dialogue.

Accordingly there is a need for a referring expression processor for processing referring expressions a language processor including the referring expression processor and a referring expression processing method which use a probabilistic model and in which referring expressions including descriptive anaphoric and deictic expressions are understood and generated in the course of dialogue.

A referring expression processor according to the first aspect of the invention includes a referring expression processing section which performs at least one of understanding and generation of referring expressions using a probabilistic model constructed with a referring expression Bayesian network each referring expression Bayesian network representing relationships between a reference domain D which is a set of possible referents a referent X in the reference domain a concept C concerning the referent and a word W which represents the concept and a memory which stores data necessary for constructing the referring expression Bayesian network.

The referring expression processor according to the present aspect uses a probabilistic model constructed with a referring expression Bayesian network each referring expression Bayesian network representing relationships between a reference domain D which is a set of possible referents a referent X in the reference domain a concept C concerning the referent and a word W which represents the concept. Accordingly referring expressions including descriptive deictic or anaphoric expressions can be understood and generated by the referring expression processor. Further each referring expression Bayesian network includes a reference domain D which is a set of possible referents and therefore referring expressions can be processed according to the circumstances by the referring expression processor.

In a referring expression processor according to one embodiment of the present invention each referring expression Bayesian network is constructed in the course of dialogue each time a referring expression is processed.

By the referring expression processor according to the present embodiment a referring expression can be processed according to development of the dialogue.

In a referring expression processor according to another embodiment of the present invention a way of determining the reference domain is changed depending on types of referring expressions.

By the referring expression processor according to the present embodiment a referring expression can be processed with a higher accuracy by taking types of referring expressions into consideration.

In a referring expression processor according to another embodiment of the present invention the reference domain is determined to include all elements possible referents when a referring expression contains a demonstrative.

By the referring expression processor according to the present embodiment a referring expression can be processed with a higher accuracy by considering a single reference domain which includes all elements when the referring expression contains a demonstrative.

In a referring expression processor according to another embodiment of the present invention a plurality of prediction models for reference domains which have saliency as a parameter are constructed and one of the plurality of prediction models is selected for use depending on whether a referring expression refers to a single entity or a set of entities.

By the referring expression processor according to the present embodiment a referring expression can be processed with a higher accuracy by selecting one of the plurality of prediction models for use depending on whether a referring expression refers to a single entity or a set of entities.

A language processor according to the second aspect of the present invention includes a referring expression processor according to the present invention.

The language processor according to the resent aspect includes a referring expression processor according to the present invention and therefore it can process a referring expression with a higher accuracy as described above.

A method for processing a referring expression according to the third aspect of the present invention includes the steps of constructing by a referring expression processing section of a language processor a referring expression Bayesian network representing relationships between a reference domain D which is a set of possible referents a referent X in the reference domain a concept C concerning the referent and a word W which represents the concept using data stored in a memory obtaining by the referring expression processing section a probability P X D by marginaliazing the referring expression Bayesian network and obtaining by the referring expression processing section x which maximizes P X D to select x as the referent of the referring expression.

The method for processing a referring expression according to the present aspect uses a referring expression Bayesian network representing relationships between a reference domain D which is a set of possible referents a referent X in the reference domain a concept C concerning the referent and a word W which represents the concept. Accordingly referring expressions including descriptive deictic or anaphoric expressions can be understood and generated by the method. Further each referring expression Bayesian network includes a reference domain D which is a set of possible referents and therefore referring expressions can be processed according to the circumstances by the method.

The language processor is provided with a referring expression processing section and a memory as characteristic elements.

The referring expression processing section is provided with a probabilistic model used to calculate a probability that a reference expression represents a candidate referent. The memory stores data used by the probabilistic model. The referring expression processing section updates the probabilistic model in the course of dialogue. When understanding a reference expression that is when identifying the referent indicated by the reference expression the referring expression processing section calculates probabilities that the reference expression represents candidate referents and regards the referent which shows the maximum probability as the referent indicated by the reference expression. Further when generating a reference expression that is when selecting a referring expression that represents a referent the referring expression processing section calculates probabilities that candidate reference expressions represent the referent and selects the referring expression which shows the maximum probability as the reference expression which represents the referent. The referring expression processing section and the memory constitute a referring expression processor. The components of the referring expression processor will be described in detail later.

A speech recognition section recognizes human speech divides the speech into morphemes which are the smallest elements of the language and determines parts of speech of the morphemes using a dictionary for example. A structure analyzing section analyzes a sentence structure based on information of morphemes obtained by the speech recognition section .

A surface expression realizing section generates an expression of natural language including a referring expression which has been generated by the referring expression processing section . A speech synthesizing and displaying section performs speech synthesis of the expression of natural language or displays the expression of natural language.

The language processor further includes a language understanding section a language generating section and a dialogue managing section . The language understanding section receives the results of structure analysis from the structure analyzing section performs processing for understanding language except processing of referring expressions performed by the referring expression processing section and sends the results to the dialogue managing section . The language generating section performs processing for generating language except generation of referring expressions performed by the referring expression processing section and sends the results to the surface expression realizing section . The dialogue managing section receives from the referring expression processing section referents which referring expressions indicate receives from the language understanding section the results of processing for understanding language except processing of referring expressions performed by the referring expression processing section and performs processing of the received inputs. The dialogue managing section generates outputs based on the inputs and other conditions and sends the outputs to the referring expression processing section and the language generating section . The referring expression processing section receives the outputs of the dialogue managing section and generates a proper referring expression. The language generating section receives the outputs of the dialogue managing section and performs processing for generating language except generation of referring expressions performed by the referring expression processing section .

Here the probabilistic model used by the referring expression processing section will be described. The probabilistic model uses referring expression Bayesian networks.

Reference domains Susan Salmon Art and Laurent Romary. 2000. Generating referring expressions in multimodal context. In Proceedings of the INLG 2000 workshop on Conference in Generated Multimedia Mitzpe Ramon Israel June Susan Salmon Art and Laurent Romary. 2001. Reference resolution within the framework of cognitive grammar. In Proceedings of the International Colloquium on Cognitive Science San Sabastian Spain May and Alexandre Dennis. 2010. Generating referring expressions with reference domain theory. In Proceedings of the 6International Natural Language Generating Conference INLG pages 27 35 will be described. Each reference domain is a set which includes referents. An entity included in a reference domain can be either an individual entity or another reference domain. Each reference domain d has its focus and degree of saliency a non negative real number . The focus and degree of saliency are denoted as foc d and sal d respectively. Reference domains are sorted in descending order according to saliency.

The referent 1na reference domain depends on which reference domain is presupposed. That is if one presupposes or the referent of the right piece should be piece 1. If one presupposes the referent of the same referring expression should be piece 5.

The above described documents by Salmon Art and Romary do not employ probabilistic approaches but employ approaches based on logic symbol operation.

Although referring expression Bayesian networks can deal with not only simple referring expressions but also compound referring expressions a case in which simple referring expressions are dealt with will be described below for the sake of simplicity.

A referring expression Bayesian network for a simple referring expression instance of N words has 2N 2 discrete random variables W . . . W C . . . C X and D. Here V denotes the domain of a random variable V. W contains the corresponding observed word wand a special symbol word that represents other possibilities i.e. W . Each Whas a corresponding node C. C contains M concepts that can be expressed by wi and a special concept that represents other possibilities i.e. C . 1 are looked up from the concept dictionary which will be described later. D contains L 1 reference domains recognized up to that point in time i.e. D . . . . is the ground domain that contains all the individual entities to be referred to in a dialogue. At the beginning of the dialogue D . Other L reference domains are incrementally added in the course of the dialogue. X contains al the possible referents i.e. K individual entities and L 1 reference domains. Thus . . . . . . .

Probability distributions are given as probability tables since all the random variables used in a referring expression Bayesian network are discrete. Four types of probability tables used by referring expression Bayesian networks are described below. P W C X W is the probability that a hearer observes w from c and x which the speaker intends to indicate.

In most cases Wi does not depend on X i.e. W W . X is however necessary to handle individualized terms names .

There are several conceivable ways of probability assignment. One simple way is for each c W C 1 W C 1 and for W w W C 1 . Here T is the number of possible words for c is a predetermined small number such as 10. C D C D is the probability that concept c is chosen from C to indicate x in d.

The developers of dialogue systems cannot provide P C X D in advance because C is context dependent. Therefore an approach of composing C D from is taken. Here is the relevancy of concept to referent x with regard to d and 0 1. 1 means full relevancy and 0 means no relevancy. 0.5 means neutral. For example when x is a suitcase a concept BOX will have a high relevancy to x such as 0.8 while a concept BALL will have a low relevancy to x such as 0.1. If x is not in d R c x d is 0. Concept will be assigned a high probability if none of c C has a high relevancy to x.

If c is static R c x d I is numerically given in advance in the form of a table. If not static it is implemented as a function by the dialogue system developer that is . Here I is all the information available from the dialogue system.

For example given a situation such as shown in the relevancy function of a positional concept LEFT can be implemented as below. 

Here u uand uare respectively the horizontal coordinates of x the leftmost piece in d and the rightmost piece in d which are obtained from I. If x is a reference domain the relevancy is given as the average of entities in the reference domain. P X D D is the probability that entity x in reference domain d is referred to which is estimated according to the contextual information at the time the corresponding referring expression is uttered but irrespective of attributive information in the referring expression. The contextual information includes the history of referring so far discourse and physical statuses such as the gaze of the referrer situation . D is called the prediction model. The prediction model will be described in connection with experiment later. P D D is the probability that reference domain d is presupposed at the time the referring expression is uttered. Data to estimate this probabilistic model cannot be collected because reference domains are implicit. Therefore three a priori approximation functions based on the saliency of d are examined. Saliency is proportional to recency. Saliency will be described in connection with experiment later. Uniform Model This model ignores saliency. This is introduced to see the importance of saliency. D l D Linear Model This model distributes probabilities in proportion to saliency. sal d represents saliency of d.

In step S of the referring expression processing section creates referring expression Bayesian networks REBN for all possible referents x and obtains possibility W for each of them.

In step S of the referring expression processing section selects x which shows the maximum possibility as the referent of the referring expression.

In step S of the referring expression processing section obtains P D . A method for obtaining P D has been described above.

In step S of the referring expression processing section obtains P C X D . A method for obtaining P C X D has been described above.

In step S of the referring expression processing section obtains P W C X A method for obtaining P W C X has been described above.

In step S of the referring expression processing section marginalizes P W C X D by an existing method and obtains W .

In step S of the referring expression processing section receives a referent and determines candidates of w.

In step S of the referring expression processing section obtains W using referring expression Bayesian networks by the process shown in the flowchart of .

In step S of the referring expression processing section determines whether or not all W have been processed. If all W have been processed the process goes to step S. If all W have not been processed the process returns to step S.

In step S of the referring expression processing section selects W which maximizes W as the referring expression.

Thus the referring expression processor according to the present embodiment can perform both understanding and generation of referring expressions with a single probabilistic model using referring expression Bayesian networks.

Experiments for evaluating referring expression processing according to the present embodiment will be described.

As data for the evaluation the REX J corpus Phlipp Spanger Masaaki Yasuhara Ryu Iida Takenobu Tokunaga Asuka Terai and Naoko Kuriyama 2010. REX J Japanese referring expression corpus of situated dialog. Language Resources and Evaluation. Online First DOI 10.1007 s10579 010 9134 8 was used. The REX J corpus consists of 24 human human dialogues in each of which two participants solve a Tangram puzzle of seven pieces shown in . The goal of the puzzle is combining seven pieces to form a designated shape. One of two subjects takes the roll of operator OP and the other takes the roll of solver SV . The OP can manipulate the virtual puzzle pieces displayed on a PC monitor by using a computer mouse but does not know the goal shape. The SV knows the goal shape but cannot manipulate the pieces. The states of the pieces and the mouse cursor operated by the OP are shared by the two subjects in real time. Thus the two participants weave a collaborative dialogue including many referring expressions to the pieces. In addition to referring expressions the positions and directions of the pieces the position of the mouse cursor and the manipulation by the OP were recorded with timestamps and the IDs of relevant pieces.

Table 1 shows referring expressions. In the table each of the referring expressions is shown with its referent. The first referring expression okk sankaku big triangle a big triangle in the table is ambiguous and refers to either piece 1 or 2. The seventh and eighth referring expressions refer to the set of pieces 1 and 2. The other referring expressions refer to an individual piece.

To avoid problems due to errors in structural analysis the corpus has been annotated with intermediate structures REX graphs from which referring expression Bayesian networks are constructed. The intermediate structures are shown as parenthesized lists of separated words.

BNJ http bnj.sourceforge.net is used for probabilistic computation. Implementations that are more or less specific to the task domain of REX J will be described below.

Relevancy functions were implemented for the remaining 27 concepts. Some of them will be described below.

This expression refers to a group of combined pieces. When x is a single piece single x true relevancy is set to a value r obtained from the static relevancy table. When x is a group of pieces connected to form a shape shape x true relevancy is set to 1.

A list of reference domains will be described below. In the course of reference resolution understanding of referring expressions reference domains are added into a list and updated by the following procedure. In the list reference domains are sorted in descending order according to saliency.

Assume that at each time of reference resolution all the previous reference expressions are correctly resolved. Therefore after each time of resolution if the correct referent of the last referring expression is a set a new reference domain equivalent to the set is added into the list of reference domains unless the list contains another equivalent reference domain already. In either case the saliency of the reference domain equivalent to the set is set to 1 unless the reference domain is at the head of the list already. Here is the largest saliency value in the list that is the saliency value of the head reference domain at the moment.

Before each time of reference resolution it is checked whether the piece that is most recently manipulated after the previous referring expression constitutes a perceptual group by using perceptual grouping described later at the onset time of the target referring expression. If such a group is recognized a new reference domain equivalent to the recognized group is added into the list of reference domains unless the list contains another equivalent reference domain. In either case the saliency of the reference domain equivalent to the group is set to 1 unless the reference domain is at the head of the list already and the focus of the equivalent reference domain is set to the most recently manipulated piece.

When a new reference domain is added to the list a complementary reference domain and a submerging reference domain are also inserted after in the list. Here and .

Perceptual grouping will be described below. Here when the minimum distance between two pieces is not greater than a predetermined value the two pieces are regarded as being in contact with each other and only sets of pieces being in contact with one another are recognized as groups. This method is less general but works satisfactorily in the REX J domain due to the future of the Tangram puzzle.

In step S of the dialogue managing section updates the list of reference domains based on the results of perceptual grouping immediately before reference resolution performed by the referring expression processing section .

In step S of the referring expression processing section puts a saliency obtained from the list of reference domains into the above described models of saliency to obtain P D .

In step S of the dialogue managing section updates the list of reference domains according to the results of referring expression immediately after reference resolution performed by the referring expression processing section .

For constructing the prediction model P X D which has been described above a ranking based method Ryu IIDA Shumpei Kobayashi and Takenobu Tokunaga. 2010. Incorporating extra linguistic information into reference resolution in collaboration task dialogue. In 48 pages 1259 1267 Uppsala Sweden July using SVM Thorsten Joachism. 2006. Training linear SVMs in linear time. In pages 217 226 Philadelphia Pa. USA August was adopted. This model ranks entities according to 16 binary features such as whether the target entity is previously referred to a discourse feature whether the target is under the mouse cursor a mouse cursor feature etc.

When a target is a set i.e. a reference domain discourse features for it are computed as in the case of a piece meanwhile mouse cursor features are handled in a different manner. That is if one of the group members meets the criterion of a mouse cursor feature the group is judged as meeting the criterion.

Rank is represented as rank is contextual information. D is obtained by the following equation using rank.

The 24 dialogues were used for evaluation. These 24 dialogues contain 1474 simple referring expression instances and 28 compound referring expression instances. In addition to compound referring expressions referring expressions mentioning complicated concepts for which it is difficult to implement relevancy functions in a sort time were excluded. After excluding those referring expressions 1310 referring expressions were available. Out of the 1310 referring expressions 182 referring expressions 13.2 refer to sets and 612 referring expressions are demonstrative pronouns such as sore it .

It was assumed that referring expressions are independent of speaker roles i.e. SV and OP. All referring expressions were mixed and processed serially.

It was assumed that no error comes from preprocessing including speech recognition morphological analysis and syntactic analysis and all the correct referents of past are known.

In human human dialogue sometimes information helpful for resolving a referring expression is provided after the referring expression is uttered. However such future information is not considered.

Many languages including English grammatically require indication of numeral distinctions by using such as articles singular plural forms of nouns and copulas etc. Although Japanese does not have such grammatical devices it would be possible to predict such distinctions by using a machine learning technique with linguistic and gestural information. Therefore the effect of providing such information was observed. In the following experiment the singular plural distinctions were provided to expression Bayesian networks by looking at the annotations of the correct referents in advance. This is achieved by adding a special evidence node C where C C 1 and 0 if x is a piece. On the contrary 0 and 1 if x is a set.

As a baseline of the experiment a P D model which is called Mono domain was prepared. In Mono domain D consists of a single reference domain which contains individual pieces and the reference domains recognized up to that point in time. That is 

In the experiment in the case that referring expressions contain a demonstrative better performance was obtained when Mono domain was used than when reference domains obtained by the above described models were used. Whenever referring expressions contain a demonstrative Mono domain was used to obtain the following results.

Table 2 shows results of the experiment. The performance of reference resolution is presented by category and by condition in terms of accuracy. The accuracy is a ratio of the number of correctly resolved referring expressions to the number of referring expressions.

In evaluation three categories were set up that is Single Plural and Total Category Single is the collection of referring expressions referring to a single piece. Plural is the collection of referring expressions referring to a set of pieces. Total is the sum of them. Ambiguous referring expressions such as the first one in Table 1 are counted as Single and the resolution of such a referring expression is considered correct if the resolved result is one of the possible referents.

 w o S P info. indicates experimental results without single plural distinction information. w S P info. indicates experimental results with it. Obviously S P information has a significant impact.

While the best performance for category Single was achieved with the Linear model the best performance for Plural was achieved with the Exponential model If it is possible to know whether a referring expression is of Single or Plural that is S P information is available a suitable P D model can be selected. Therefore by switching models the best performance of Total with S P information reached 83.2 and a gain of 2.0 was achieved sign test p

By introducing referring domains resolution in category Plural achieved a significant advancement. The highest gain from the baseline was 9.3 points sign test p

Moreover more referring expressions containing positional concepts such as LEFT and RIGHT were correctly resolved in the cases of Uniform Linear and Exponential

Table 3 summarizes the resolution results of four positional concepts with S P information. Numerical values in Table 2 indicate the total number of referring expressions and the number of correctly resolved referring expressions. While the baseline resolved 65 of them the Liner model correctly resolved 75 sign test p

At each time of resolution a dedicated Bayesian network is constructed for the referring expression in question. The constructed Bayesian network deals with either descriptive deictic or anaphoric referring expressions in a unified manner. Referring expression Bayesian networks incorporate the notion of reference domains which enables the resolution of referring expressions with context dependent attributes and handling of referring expressions to sets. Referring expression Bayesian networks have the potential to be a standard approach that can be used for any and all task oriented applications such as personal agents in smart phones in car systems service robots and the like.

