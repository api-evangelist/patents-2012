---

title: Reading files stored on a storage system
abstract: A system and method for reading files stored on a storage system is disclosed. The method includes communicatively coupling one or more remote systems for reading files stored in storage with a first set of files according to a predetermined data format and in a cache memory with a second set of files, the second set of files being a subset of the first set of files. Next one or more remote systems are received at least one read request for reading a sequence of files. A determination is made, among the files of the sequence of files, whether one or more cached files are already stored in the cache memory and whether one or more remaining files are not already stored in the cache memory. Creating, within the one or more remaining files, an order according to which the remaining files should be read on the storage system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08862815&OS=08862815&RS=08862815
owner: International Business Machines Corporation
number: 08862815
owner_city: Armonk
owner_country: US
publication_date: 20121116
---
This application is based upon and claims priority from prior European Patent Application No. 11189769.0 filed on Nov. 18 2011 the entire disclosure of which is herein incorporated by reference.

The invention relates to the field of cache architecture for storage system and specifically to a method for reading files on a storage system.

Despite the significant progress of HDD hard disk drive technology over the past years magnetic tape systems constitute an integral part of current tiered storage infrastructures. Tape technology offers several important advantages including low cost long term storage of data as well as for backup and disaster recovery purposes energy savings security lifetime and reliability.

Once data has been recorded in tape systems the medium is passive. This means that it simply sits in a rack and no power is needed. Compared with similar disk based systems a tape based archive consumes approximately 290 times less power. In terms of security once data has been recorded and the cartridge removed from the access system the data is inaccessible until the cartridge is reinstalled in the active system. Security is further enhanced by drive level encryption which was introduced in Linear Tape Open generation 4 drives LTO 4 and is also standard in enterprise level tape drives. The tape medium has a lifetime of 30 years however this is rarely taken advantage of because of the rapid advances in tape hardware and the cost savings associated with migration to higher capacity cartridges. In terms of reliability LTO 4 tape has a bit error rate that is at least an order of magnitude better than that of a SAS Serial Attached SCSI HDD. Moreover the fact that tape media is removable and interchangeable means that in contrast to HDDs mechanical failure of a tape drive does not lead to data loss because a cartridge can simply be mounted in another drive.

All of the above advantages contribute to the major net advantages of tape system which are cost and reliability. Estimates of cost savings between disk and tape range from a factor of three to more than 20.

Hard disks provide random access to data and generally contain a file index managed by a file system. These files can be accessed by means of standard sets of application programming interfaces APIs using various operating systems and applications. Tape in contrast is written in a linear sequential fashion typically using a technique called shingling which provides backward write compatibility but also implies that new data can only be appended at the end and that previously written areas can only be reclaimed if the entire cartridge is reclaimed and rewritten. In traditional tape systems an index of the files written on a given cartridge is usually only kept in an external database managed by an application such as a proprietary back up application. The need to access an external database to retrieve data renders data on tape much less portable and accessible than with alternative storage methods such as a HDD or a USB Universal Serial Bus drive.

To address these deficiencies a new file system referred to as Linear Tape File System LTFS has recently been introduced in the LTO 5 tape drive systems to enable efficient access to tape using standard and familiar system tools and interfaces. LTFS is implemented by taking advantage of the dual partition capabilities supported in the new LTO 5 format. A so called index partition is used for writing the index and the second much larger partition for the data itself. The index partition is used for the directory of the file system whereas the data partition is used to store the actual user s files in the file system. Placing the index on a separate partition is advantageous because it can be rewritten without impacting the actual data. LTFS exposes a POSIX like file system interface to the user manages the file system index in the index partition and stores the data in the data partition. The file system represented by the LTFS software makes files and directories show up on the desktop with a directory listing while the files are actually located on tape. File system users can drag and drop files to and from tape and can run applications developed for disk systems. In library mode the content of all volumes in the library can be listed and searched without mounting the individual cartridges. All these features help reduce tape file management and archive costs and eliminate the dependency on a middleware layer. Hence the cost per gigabyte GB stored is reduced. In addition tape becomes cross platform portable LTFS is available on Linux Apple Mac OS X Microsoft Windows enabling and facilitating the sharing of data between platforms. These features enable significant new use cases for tape such as video archives medical images etc. Considering the cost advantages of tape over other storage solutions the demonstrated potential for the continued scaling of tape cartridge capacity and cost per GB as well as the increasing usability of tape provided by advances such as the LTFS tape appears set to play an important role in the exploding market for archival data storage solutions.

However even with LTFS files are stored in a sequential manner on tape which causes non negligible longer access times during I O operations such as read and write.

The documents Implementing an Automated Digital Video Archive based on the video edition of Xendata Software XenData White Paper April 2007 US 2008 0040539 A1 US2010 0211731 A1 U.S. Pat. No. 7 864 479 B2 U.S. Pat. No. 5 829 046 U.S. Pat. No. 7 644 204 B2 U.S. Pat. No. 6 711 580 B2 SW COPANTM Virtual Tape Library 300T TX Driving to best practices in archiving L. DuBois March 2007 Page 6 The case for massive arrays of idle disks D. Colarelli D. Grunwald and M. Neufeld Dept. of Computer Science Univ. of Colorado Boulder Jan. 7 2002 Page 3 Optimizing virtual tape performance improving efficiency with disk storage system D. Cuddihy Atto Technology Incorporation Embedded Software Group June 2007 Page 6 are related to the field of the invention.

According to a first aspect the invention is embodied as a method for reading files stored on a storage system wherein the storage system comprises storage means storing a first set of files according to a predetermined data format and cache memory storing a second set of files the second set of files being a subset of the first set of files the storage system being configured to allow one or more remote systems for reading files stored on the storage means and or on the cache memory the method comprises 

determining among the files of the sequence whether one or more cached files are already stored on the cache memory and whether one or more remaining files are not already stored on the cache memory 

reading said one or more remaining files on the storage system according to said order and storing the remaining files on the cache memory.

the non volatile memory which is used as the cache memory comprises an array of hard disk and or solid state drives 

the storage means comprises at least one magnetic tape medium storing the first set of files according to Linear Tape File System data format and wherein the locations of said remaining files as stored on the storage system is determined according to a starting block for each remaining file as part of the metadata of the Linear Tape File System data format 

the cache memory comprises a first region that is managed using a First In First Out policy management and a second region managed that is managed using a Least Recently Used policy management the first and second regions being adapted to store said second set of files according to a set of rules for cache capacity management 

According to another aspect the invention is embodied as a computer program stored on a computer readable medium for reading files stored on a storage system comprising code means for causing a computer to take the steps of the method according to the invention.

code means for managing the storage means as Linear Tape File System and wherein the storage means comprises a standalone tape library having at least one magnetic tape medium managed using the Linear Tape File System 

cache memory storing a second set of files the second set of files being a subset of the first set of files 

The invention describes a method for reading files stored on a storage system. A storage system refers to computer components and recording media that retain digital data. The storage system comprises storage means storing a first set of files according to a predetermined data format. A data format refers to a format for encoding data for storage on a storage medium in a computer file system. The storage system also comprises a cache memory storing a second set of files the second set of files being a subset of the first set of files. The cache memory is a component that stores data so that future requests for that data can be served faster. The storage system is configured to allow one or more remote systems for reading files stored on the storage means and or on the cache memory. A remote system generally refers to any system or application located at a remote location for the storage system. The method for reading files stored on a storage system comprises receiving from one or more remote systems at least one read request for reading a sequence of files. A sequence of files refers to a well ordered finite collection of files usually related to each other in some way. The method comprises determining among the files of the sequence whether one or more cached files are already stored on the cache memory and whether one or more remaining files are not already stored on the cache memory. The method comprises determining within said one or more remaining files an order according to which said remaining files should be read on the storage system given locations of said remaining files as stored on the storage system according to said predetermined data format. The location of files on the storage system refers to the organisation or position of the files the storage system. The positioning of the files may be carried out by physically or virtually dividing the data space. The method comprises reading said one or more remaining files on the storage system according to said order and storing the remaining files on the cache memory.

Thus the focus of the proposed invention is on techniques that improve performance of a storage system such as a tape storage system e.g. a tape storage system based on LTFS not only in terms of access latency but also in terms of throughput and space utilization. To that end the storage system uses storage means in concert with a cache memory which is used as a caching layer above the storage means. The storage system reads the requested files with an optimized read allowing a cache pre fetching of files. Thus the method according to the invention provides not only a faster access to the most recently and or frequently cached files but also is designed to speed up use cases such as backup or restore and migration operations of files stored on storage means.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a method system or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

The storage system further comprises storage means storing a first set of files according to a predetermined data format. For instance the storage means may be a sequential access media such as a standalone tape drive or tape library that can support a multitude of tape drives or heads. The standalone tape drive is used to operate on linear tape on one or more tape cartridges. The predetermined data format of the data stored on the tape drive may use a LTFS format data format that holds the file content data and associated file metadata. Thus the data stored on the tape drive and written using LTFS format can be exchanged with others systems able to understand LTFS format.

The storage system further comprises a cache memory storing a second set of files the second set of files being a subset of the first set of files. The cache memory optimizes performances of the storage system exploiting temporal and spatial locality of workloads. The cache memory is a read cache. Optionally the cache memory may also be a write cache. The read cache improves performance by transparently storing data such that future requests for that data can be served faster. If requested data is contained in the cache that is if a cache hit occurs this request can be served by simply reading the cache which is comparably faster than reading from the backend storage device. Otherwise a cache miss occurs and the data has to be fetched from the slower backend storage device.

In practice the storage system comprises a non volatile memory which is used as the cache memory. Advantageously the non volatile memory allows to retain the files stored thereon when the storage system is turned off. The non volatile memory which is used as the cache memory may comprise an array of hard disk drives and or solid state drives. The array of large capacity HDDs and or SSDs may be configured in a RAID Redundant Array of Independent Disks scheme. The cache memory controller may expose a single logical volume to the operating system of the server thus making easier the management of the cache memory. Also a conventional disk file system such as but not limited to ext3 ext4 or NTFS is installed on that logical volume and is used for all I O operations to the disk array. The cache memory that is the whole disk array is dedicated to caching and is not shared with other components of the system.

The cache memory may be a file level cache memory. Alternatively the cache memory may be a block level cache memory. In this case HDDs and or SSDs of the array are used as raw device with no file system and then volumes are created and an operating system connects to these volumes and uses them as individual hard drives. Block level cache memory is usable for almost any kind of application including file storage database storage virtual machine file system VMFS volumes and more.

Typically the storage system comprises a server which comprises the CPU and DRAM the bus the display controller the communication controller. The server is attached to the storage means that may run an LTFS software and expose the underlying tape capacity via a standard file system interface. The server is further directly attached to the cache memory . The server runs an operating system such as but not limited to the Linux trademark operating system. The server is connected to the network and thereby remote network users and applications can mount storage means e.g. LTFS file system and directly store or retrieve data from the storage means.

Hence the storage system comprises one or more storage devices e.g. HDDs SSDs array used as a cache memory that may be logically configured into a single logical address space and storage means that may comprise one or more tape drives operating in parallel as shown in . The storage system further comprises one or more storage devices such as magnetic tape medium. The tape library is typically managed using an LTFS file system. It is to be understood that another file system may be used. The LTFS file system runs in the server to which both the tape library and the HDD array are directly attached. The cache memory is used as a cache for the LTFS file system providing advantageously fast random access to the data stored on the storage means.

At steps it is monitored whether the storage system receives at least one read request for reading a sequence of files from one or more remote systems. In other words a decision is made whether the read request matches a certain pattern. The pattern might be denoted by files being read sequentially from a directory. As shown on the remote systems may be an application. The request is received by the storage system through its communication controller and appropriate interfaces .

At step it is determined among the files of the sequence of files whether one or more cached files are already stored on the cache memory and whether one or more remaining files are not already stored on the cache memory. In other words it is determined which files among the requested files are located on the cache and on the storages means. This amounts to say that the names of all files which have been matched before are determined otherwise said the files stored on the cache memory.

Next at step the files stored on the cache memory are read. This provides faster access to the most recently frequently cached files.

Then at step it is determined within the one or more remaining files an order according to which the remaining files should be read on the storage system. Thus a ranking of the requested files of the sequence of files stored on the storage means is carried out. Otherwise said the files are arranged in some sequence. The ordering of these files is performed given the locations of remaining files as stored on the storage system according to their predetermined data format.

In a sequential access media such as a standalone tape drive managed by LTFS the ordering of the files according to their location on tape is enabled by the LTFS format which includes a starting block for each file as part of the LTFS metadata available to the user through a virtual extended attribute.

Referring now to it is shown an example of locations of files as stored on a storage system according to predetermined data format. Especially show files arranged in a sequential access media such as a standalone tape drive or tape library managed by LTFS.

The storage system obtains read and write commands from one or more remote systems. A remote system may conduct a read for all files which are stored on a directory or on a subdirectory. However these files might not be arranged sequentially on the tape because some files might have been changed over time and may reside in subsequent locations. Files that get modified or overwritten on an LTFS cartridge are appended on tape rather than be modified in place. The situation described above is shown in 

In the files can be ordered according to their location or position on the tape managed by LTFS files file and file which are toward the beginning of tape followed by files file and file which are in the middle of the tape and finally file file which is located at the end of the tape.

Referring back to at step one or more remaining files on the storage system are read in accordance with the ordering step . The remaining files are also stored on the cache memory that is the files are copied from the storage means to the cache memory. Optionally the file files may be copied on the storage means in the same order as they are read. It is to be understood that the reading and the copy of the files stored on the storage means may be carried out concomitantly.

Alternatively at step the remaining files are first stored on the cache memory in accordance with the ordering step and then read from the cache memory. In this case the reading may also be done in accordance with the ordering step.

Thus the method according to the invention provides a pre fetching of files stored on the storage means to the cache memory thus allowing to speed up common tape specific use cases such as backup restore and migration. Indeed these operations of backup restore and migration require reading a sequence of files which are stored on the cache memory in accordance with the invention. Typically the pre fetching of the files stored on the storage means to the cache memory may apply to all the files stored in a directory or sub directory of the storage means. Hence the method of the invention allows to pre fetch all the files stored in the directory to the cache memory.

It is to be understood that the method according to the invention not only applies for all files which are stored in one directory. It can apply for any scenario where multiple files are read the storage means regardless of the files are stored on a single storage device of the storage means. For example an LTFS storage may comprises one tape or on multiple tapes. In this case the files of the sequence of files are ordered according to the tape on which they are stored and according to their location on this tape. As a result files are read on each tape in a sorted order and tapes are read in a sorted order.

Referring now to an example of data path view between a remote system such as an application or a client and the storage system depicted on is shown. The storage system is remotely accessed by systems such as an application or a client e.g. via a network. Other systems might be a file system server such as GPFS General Parallel File System cluster or NAS Network attached storage filer.

Remote systems may access the storage system either by mounting it using a network file system or by reading from and writing data to it using the FTP File Transfer Protocol protocol or the SSH Secure SHell protocol. It is to be understood that any other protocol may be used for remotely accessing the storage system .

The storage system provides appropriate interfaces as shown in so that the storage system can be used to accommodate storage needs for a multitude of applications . In the storage system comprises a multitude of tape drives as storage means managed using LTFS software . The following are examples of applications for managing files stored on the tape drives including but not limited to 

1 Backup of a GPFS or other file system connected to the storage system over the network. The entire GPFS file system or individual directories or file sets can be backed up into the storage system. Full or incremental backups can be taken and multiple versions can be supported on the same or different tape cartridges. Additionally multiple backups originating from the same or different file systems clusters can be supported in the same appliance. Advantageously LTFS enables the backup to be self contained and self describing on the tape cartridge saving the user from the need to deploy and maintain a TSM server. In addition the file attributes of GPFS can be preserved on LTFS and also enforced with some modifications to LTFS. The backup process which can be orchestrated either by a GPFS node or by the tape appliance itself is outlined in the following steps 

a. A GPFS policy running in the cluster identifies the files that have changed since the last backup 

e. When the process finishes the tape cartridge may be removed and be put into a vault or be moved to any other system.

Files can be restored from the backup by just reading the tape in the same or any other tape system and leveraging the file system interface provided by LTFS which allows to keep the same name space as in GPFS. This means any file which has been backed up from the filer can have the name path and file in LTFS which allows easy recovery.

2 Migration of files from a GPFS or other file system i.e. using the tape storage as a tier in the storage hierarchy. The user specifies migration criteria for files or directories in the form of user specified GPFS policies and the system seamlessly places the data on tape by migrating files that meet the aforementioned specified criteria to the tape appliance. For each file migrating to the tape appliance the file is replaced in GPFS by a file stub a placeholder . Thereby the files remain in the GPFS namespace and can be accessed as normal files by the users and the existing applications. Upon access to a migrated file the file is recalled from the tape appliance.

3 Integration with NAS filers e.g. NetApp filers to copy old snapshots from the filer to LTFS and delete older snapshots from the filer. The advantage is that older snapshots which typically require more storage capacity are stored on LTFS can seamlessly be accessed through the LTFS file system interface which is can be a NAS interface such as NFS or CIFS provided by the NAS filer as well.

4 In Media Management MAM the medium often contains multiple versions of the same data stream. A common practice is to have a high definition version of an audio video stream together with a so called proxy which is a low resolution version of the same content. It would be very beneficial to cache the files pertaining to the proxy as this is being used more frequently to edit cut the content to produce a cut list that would be later on applied to the hi def original stream to produce a playout stream or for direct playout.

5 Graphical User Interface for remotely managing the storage system including but not limited to media management versioning vaulting format check and recovery of the stored files.

The method for reading files stored on a storage system according to the invention may be implemented on as a computer program running on the server and executed by the server. In practice the method is implemented with the code part adapted to manage the storage means. For instance and in reference to the method may be implemented inside the LTFS code of the LTFS software adapted to manage the tape drives .

Alternatively the method may be implemented outside the server as an external module. Thereby a given file system of the storage means can be replaced with any other tape file system in the future. It is to be understood that such an external module needs to interface with both the OS of the storage system and the file system of the storage means.

Preferably the computer program implementing the method according to the invention is a user space program component. Advantageously this allows to improve the portability as a user space software component as opposed to a kernel space one allows for a low implementation complexity.

Referring now to another example of data path view of the storage system depicted on is shown. The storage system comprises a network interface e.g. the communication controller in . In all I O operations to the storage system are realized as LTFS file system operations. For instance a client write to the storage system will always end up to be a write operation to an LTFS file starting at a specific offset and with a specific length in bytes as illustrated on . In a first scenario a remote user issues a write to file ltfs greetings.txt using an NFS mount to the storage system. The write is passed to LTFS by the server not shown . Then LTFS finds this file to be already cached in the HDD cache and the write is absorbed on the HDD with ltfs greetings.txt being an ext3 file on the HDD file system. In a different scenario another remote user wants to read some bytes from a file on the storage system using the FTP protocol. The user issues an FTP get request which the appliance server translates into an LTFS read request. LTFS looks up the requested file in the cache but does not find it to be there. Therefore LTFS reads the requested file from the tape library and returns the first 100 bytes to the user. At that point LTFS may choose to cache the file on the HDDs or not.

Referring now to an example of the cache memory of the storage system depicted on is now discussed. The cache memory is typically a non volatile storage and therefore the cache memory may safely hold both modified and unmodified data on a file level.

Typically the cache memory is divided into first and second regions or spaces. The first and second regions are adapted to store files originally stored in the storage means. The storage of files in the first and second regions is performed in accordance with a set of rules for cache capacity management.

In practice the first region is a FIFO First In First Out region and the second region is an LRU Least Recently Used region . This amounts to say that the cache memory is divided into a FIFO cache and a LRU cache. The FIFO region is managed using a First In First Out replacement policy while the LRU region is managed using a Least Recently Used policy. The FIFO region is typically destined to hold files that will only be accessed at most once after they are written to the cache. This is for instance the case of a backup write verification process. The LRU region is typically destined to cache files that have a high probability of multiple accesses in the near future.

As shown in user writes will usually write their data to the FIFO cache while user reads will usually be served by the LRU cache. However this is not a requirement indeed incoming data may also be written to the LRU cache if the user hints that the data will be accessed multiple times in the near future. On the other hand user reads may be served from the FIFO cache if the requested data is found to be there.

Optionally at the same time files are moved between the two regions of the cache depending on their workload indeed the cache memory has a limited storage capacity size and its partition to a FIFO and LRU sections requires certain level of control. In other words cache capacity is managed in accordance with a set of rules. The following rules for cache capacity management may be used 

If the FIFO region is full then the oldest files are evicted. Evicting files from the cache may require copying them first to tape 

If the LRU region is full then the files with the least number of access and the oldest last access time are evicted. Evicting files from the cache may require copying them first to tape 

If the FIFO region is full and the LRU region has at least 50 free capacity then the FIFO region gains 30 of the LRU region capacity 

If the LRU region is full and the FIFO region has at least 50 free capacity then the FIFO region gains 30 of the LRU region capacity.

It is to be understood that the aforementioned percentages are design parameters and might change depending on the specific application and workload.

