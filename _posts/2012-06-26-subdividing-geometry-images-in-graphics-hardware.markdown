---

title: Subdividing geometry images in graphics hardware
abstract: A system may include a graphics memory, a data bus, a processor, and a vertex shader. The data bus may be operatively connected to the graphics memory. The processor may send vertex data to the graphics memory via the data bus. The vertex shader may read the vertex data from the graphics memory and may subdivide the vertex data into subdivided vertex data. The vertex shader may also write the subdivided vertex data to the graphics memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08462159&OS=08462159&RS=08462159
owner: Intel Corporation
number: 08462159
owner_city: Santa Clara
owner_country: US
publication_date: 20120626
---
This application is a continuation of U.S. patent application Ser. No. 13 238 231 filed on Sep. 21 2011 now U.S. Pat. No. 8 217 942 which is a continuation of U.S. patent Ser. No. 13 097 312 filed on Apr. 29 2011 which issued as U.S. Pat. No. 8 044 957 which is a divisional of U.S. patent application Ser. No. 12 787 520 filed on May 26 2010 which issued as U.S. Pat. No. 7 956 860 which is a divisional of U.S. patent application Ser. No. 10 926 875 filed on Aug. 26 2004 which issued as U.S. Pat. No. 7 750 914.

Implementations of the claimed invention generally may relate to processing graphical images and more particularly to processing graphical images using geometry images.

Next the polygons may be clipped to the screen in appropriate positions act . Pixel shaders may then shade each polygon act . Pixel shaders typically include hardware that execute a set of instructions on each fragment as it passes through the graphics pipeline before being rendered to the screen. Pixel and vertex shaders may have identical or different instruction sets. Additionally the instruction sets they execute may be different than the instructions exposed to a programmer.

After shading if a particular pixel is in front of any previously rendered pixels it may be written to the frame buffer act . In some graphical engines alpha blending may occur. Alpha blending is a mechanism to facilitate the implementation of partially transparent objects and typically may be realized through an additional channel to the color channels used in a traditional three dimensional 3D graphics pipeline.

Recently a technique of representing the surface geometry of graphical images has been proposed that may have certain advantages. Such a technique may remesh an arbitrary graphical surface onto a completely regular structure called a geometry image. The geometry image may capture the surface geometry of a graphical image as a two dimensional 2D array of quantized points. Surface signals such as normals and or colors may be stored in similar 2D images using the same surface parameterization as the geometry image. Further discussion of geometry images may be found in for example Xianfeng Gu et al. Geometry Images SIGGRAPH 2002 Proceedings pp. 355 361 and F. Losasso et al. Smooth Geometry Images Eurographics 2003 pp. 138 145 and 273. To better understand what a geometry image is and how it may represent a 3D graphical object a brief explanation will be provided.

3D Model may be cut along its edges to form a different e.g. non rabbit shaped 2D shape. Cut illustrates one such cut. This different shape may be warped or parameterized using known techniques to form a regular shape . Regular shape may include connected vertices from model e.g. illustrated as triangles with the cut being located at the outer edge s of shape . Thus regular shape retains both the x y z position values of the vertices in model as well as the connection relationships between these vertices. It should be noted that although regular shape is illustrated as a square other types of regular shapes e.g. circles etc. may also be used.

The polygons in regular shape may be regularly sampled to generate sampled shape . Each sampled point in sampled shape may be a new vertex that both retains a positional value e.g. an x y z coordinate and that is implicitly connected to other vertices in sampled image . That is vertices in sampled image may be connected be edges to other vertices to their top bottom left and right sides by virtue of the regular sampling of regular shape .

Sampled image may be converted into a red green blue RGB or any other color space color image by mapping the three channel x y z coordinates of the vertices in sampled image to the three channel RGB space r g b coordinates to produce geometry image . Each pixel in geometry image may represent a sampled vertex in model with the red green and blue values of the pixel representing the x y z spatial position of the sampled vertex. The neighbor vertices of the corresponding sampled vertex in model are determined by the neighboring pixels to a given pixel in geometry image . In other words the neighbor vertices of model are known by the neighbor pixels in geometry image and the positional values of these vertices are known by the color values for pixels in geometry image .

Although geometry image has been explained with regard to positional information geometry images may be generated for any information associated with the vertices of model . For example normals which are x y z vectors that point into space may also be represented by a geometry image . Also color values and or texture coordinates may also be represented by geometry images . Representing models as images may allow one to use existing image processing algorithms such as image compression algorithms.

Although it is possible to compress geometry images such geometry images even if compressed may in some instances be sent to a graphics processor over a data bus. In some cases the bandwidth of the data bus may limit the resolution and or visual fidelity able to be displayed by the graphics processor from the geometry images.

The following detailed description refers to the accompanying drawings. The same reference numbers may be used in different drawings to identify the same or similar elements. In the following description for purposes of explanation and not limitation specific details are set forth such as particular structures architectures interfaces techniques etc. in order to provide a thorough understanding of the various aspects of the claimed invention. However it will be apparent to those skilled in the art having the benefit of the present disclosure that the various aspects of the invention claimed may be practiced in other examples that depart from these specific details. In certain instances descriptions of well known devices circuits and methods are omitted so as not to obscure the description of the present invention with unnecessary detail.

Main memory may include a storage device to store geometry images. Main memory may include a random access memory RAM device such as a dynamic RAM DRAM double data rate RAM DDR RAM etc. Main memory may store pre computed geometry images and or graphical data from which to compute geometry images.

Processor may include a general purpose processor a specific purpose processor and or logic configured for a specific purpose. Processor may be arranged to distribute geometry images from main memory to graphics memory via data bus . Processor may send the geometry images via data bus under control of a program such as a rendering game graphical creation or other type of graphics related program. In some implementations processor may compute the geometry images from other information in main memory and store the geometry images in main memory . In some implementations processor may compress the geometry images e.g. via JPEG 2000 or another lossless scheme before transmission via data bus .

Data bus may connect processor to graphics memory . Data bus may use a typical interconnect protocol or may use a custom communication protocol. Data bus may have an associated bandwidth that defines a maximum amount of data that it can transfer in a given time. In some implementations the bandwidth of data bus may limit the performance of other portions of system e.g. shaders and or . In some implementations the bandwidth of data bus may not limit the overall performance of system .

Graphics memory may include a storage device to store geometry images. Graphics memory may include a random access memory RAM device such as a dynamic RAM DRAM double data rate RAM DDR RAM etc. Graphics memory may receive and store geometry images from processor and vertex shaders . In addition to storing geometry images via write operations graphics memory may provide such geometry images to vertex shaders and pixel shaders via read operations. For example graphics memory may store various per vertex data associated with the geometry images. Such vertex data may include one or more of vertex positions texture coordinates color coordinates or normal vectors.

Vertex shaders may be arranged to read the vertex data from graphics memory and to subdivide the vertex data to generate higher resolution vertex data. Vertex shaders may have a parallel architecture and may have a larger instruction set than for example pixel shaders . Vertex shaders may use various vertex generation programs and subdivision schemes to increase the resolution of the vertex data as will be described further herein. Vertex shaders may also write the higher resolution vertex data to graphics memory .

Because of a relatively high bandwidth access to graphics memory vertex shaders may write a relatively large amount of higher resolution vertex data to graphics memory . Typical subdivision schemes may increase the amount of data in a geometry image by a factor of four. Vertex shaders may be arranged to perform one or more levels of subdivision for a given geometry image and once subdivided vertex data stored in graphics memory for example may be used by vertex shaders to generate a second level of subdivided data e.g. at a higher finer resolution for storage in graphics memory .

Pixel shaders may be arranged to read the subdivided vertex data from graphics memory and prepare it for display. Pixel shaders may have a higher bandwidth connection to graphics memory than for example vertex shaders and pixel shaders may be able more limited in number of instructions and instruction set than vertex shaders . For example pixel shaders may be arranged to read the new higher resolution geometry images from graphics memory rasterize the images and send the rasterized pixel data to frame buffer . In some implementations pixel shaders may rasterize the new geometry images using the lower resolution geometry images from processor which may remain in graphics memory as display primitives.

Frame buffer may be arranged to receive pixel data from pixel shaders and buffer it if necessary prior to display. Frame buffer may also output data to a display or display interface possibly under control of a graphics processor not shown .

Processing may begin with processor obtaining textures geometry images and any other associated values for vertex positions in an image act . In some implementations processor may compute the values and in some implementations processor may read the values from main memory . In addition to obtaining a geometry image processor may also create one or more of a texture coordinate map and a color coordinate map. Detailed procedures for creating geometry images e.g. cutting a mesh along edge paths and parameterizing the resulting chart into a square may be found in for example Xianfeng Gu et al. Geometry Images SIGGRAPH 2002 Proceedings pp. 355 361. Such texture map geometry image and or color map may be implemented as arrays having specified widths and heights.

Texture color and or normal maps may be created in the same fashion as the vertex map in . For textures to and tv may be stored in the red and green channels respectively. Likewise for color r g and b values may be stored into the r g and b values for the texture map. Because textures are normally just arrays of colors both color and texture maps use r g and b. Finally x y and z values of the normals may be stored into the r g and b channels of the texture map. It should be noted that such mapping need not be restricted to a 2D structure such as an image. Rather the techniques described herein may support textures normals and colors by consuming any number of channels that are mapped into r g b and if necessary alpha. If more than 4 channels of vertex related information or data are desired additional texture maps may be used for this information. Thus the technique described with regard to may be used with somewhat arbitrary and or complex vertex data.

Also in act processor may create placeholder arrays for the textures geometry images and colors when subdivided one or more times. Such placeholder arrays may be sent over data bus in shorthand form using minimal bandwidth to reserve space in graphics memory for the subdivided textures geometry images etc. In some implementations the placeholder arrays may be generated locally by vertex shaders in response to a command from processor . In any event the placeholder arrays may be initialized to zero and stored in graphics memory .

Processing may continue with processor sending the textures geometry images and any other values e.g. color coordinates and or normal vectors to graphics memory via data bus act . In some implementations processor may submit the textures geometry images and any other values to a graphics application programming interface API which may handle transporting the textures and geometry images to graphics memory . In some implementations the textures geometry images etc. may be compressed e.g. via a lossless scheme such as JPEG 2000 before transmission over data bus .

Vertex shaders may read the stored textures geometry images and any other values collectively vertex data from graphics memory and may subdivide the vertex data act . As previously mentioned subdivision of a two dimensional image e.g. a geometry image may increase the resolution of the image by roughly four times. In some implementations vertex shaders may implement the subdivision using the Catmull Clark technique outlined in Ed Catmull and Jim Clark Recursively Generated B Spline Surfaces on Arbitrary Topological Meshes Computer Aided Geometric Design Vol. 10 Nov. 6 1978.

Other subdivision techniques may be employed however by vertex shaders . In some implementations vertex shaders may subdivide the vertex data using the butterfly technique outlined in Subdividing Reality Employing Subdivision Surfaces for Real Time Scalable Photorealism by Stephen Junkins Game Developers Conference proceedings 2000. In some implementations vertex shaders may subdivide the vertex data using the loop technique outlined in C. T. Loop Smooth Subdivision Surfaces Based on Triangles M. S. Thesis Department of Mathematics University of Utah August 1987. In some implementations vertex shaders may subdivide the vertex data using the Doo Sabin technique outlined in D. Doo and M. Sabin Behavior of Recursive Division Surfaces Near Extraordinary Points Computer Aided Design Vol. 10 Nov. 6 1978.

Vertex shaders may write the subdivided output vertex data to graphics memory act . In some implementations vertex shaders overwrite one or more placeholder arrays in graphics memory with the output vertex data. In some implementations vertex shaders may create new structures in graphics memory for the output vertex data as needed.

Depending on a number of levels of desired subdivision vertex shaders may repeat acts and one or more times as illustrated by the dashed arrow in . For example if more than one subdivision operation is desired e.g. to produce a greater resolution vertex shaders may read and further subdivide once subdivided or twice subdivided if repeating act a second time output vertex data stored in graphics memory in a previous act . Because subdivision may depend on vertex data at the immediately preceding resolution e.g. the output of the prior subdivision in some implementations vertex shaders may overwrite and or delete vertex data of a higher resolution to free space in graphics memory . For example when performing a second or higher level of subdivision the original vertex data sent from processor may be overwritten and or deleted.

Other techniques may also be employed when subdividing to save space in graphics memory and or other resources of system . For example space in graphics memory may be saved by not subdividing texture normal and or color coordinates as fully as for example the associated geometry images. In such a case pixel shaders may just reference a lower level of subdivision e.g. only once subdivided data for a twice or more subdivided resolution and divide by 4 for each lookup. As one example if generating and or storing a 256.times.256 normal map along with a corresponding 256.times.256 geometry image is not desirable a normal map from the 64.times.64 level of resolution may be used by pixel shaders instead. For an entry at index 32 32 in the position array position 8 8 in the 64.times.64 normal map may be referenced by pixel shaders during their processing. Thus pixel shaders may use one or more maps of a lower resolution e.g. a normal map when formatting other vertex data e.g. a geometry image or other structure that has been subdivided to a higher resolution by vertex shaders .

In some implementations an appropriate normal may be computed and then the closest normal may be looked up in the old normal map. The resulting normal data may be stored in a normal map of any size. Other techniques may be used to avoid for a given resolution fully subdividing all graphical data in graphics memory .

Subdivision may not be desired in some areas e.g. areas within a geometry image . For those areas the existing geometry image normal image and or texture maps may be left alone. For the other areas that are desirable to subdivide a subdivision scheme may be employed e.g. Catmull Clark . For borders between the two regions e.g. subdivided and not some vertex information may be duplicated.

Another technique to save space in graphics memory may be to compress the data stored therein e.g. the original vertex data and or the subdivided vertex data via a lossless compression scheme. One such scheme that may be suitable for compressing for example subdivided geometry images may be JPEG 2000 which may achieve compression ratios of about 2.5 to 1. Data compression may be used instead of or in addition to other techniques for reducing the amount of data stored in graphics memory .

Processing may continue with pixel shaders preparing the subdivided vertex data stored in graphics memory for display act . Pixel shaders may rasterize and or otherwise format the stored vertex data e.g. geometry images color maps etc. for display. In some implementations pixel shaders may prepare the subdivided vertex data using one or more lower resolution sets of vertex data e.g. original geometry images as display primitives. Although not explicitly shown in the formatted graphical images may then be displayed from frame buffer .

The above described system and scheme of subdividing vertex data via vertex shaders may in some implementations increase a visual fidelity resolution of displayed data for a given bandwidth of data carried by data bus . For example vertex data that uses most or substantially all of the bandwidth of data bus may be subdivided by vertex shaders to increase display resolution over what may otherwise be possible due to the bandwidth of data bus . In some implementations such a subdivision scheme may facilitate producing a given visual fidelity resolution using less bandwidth of data bus than if subdivision was not performed. For example the display resolution may remain the same as that in the case where no subdivision was performed but subdivision allows the former case to use substantially less bandwidth of data bus for the same resolution.

To further aid in understanding the above described system and process an example will be presented. In this example processor may create or read from main memory in act three n.times.n n being an integer such as 8 16 32 etc. arrays G T and C. G may be a geometry image. T may be a texture coordinate map with each position containing corresponding texture coordinates. C may be a color coordinate cap with each position containing corresponding red green and blue color values. G T and C may be at an original resolution e.g. 8.times.8 16.times.16 etc. .

Also in act for each level of subdivision desired e.g. two levels processor and or vertex shaders may create a placeholder array map for each of G T and C at a respective subdivided resolution. For a first level of subdivision G T and C may be created with a size resolution of 4 n.times.4 n because subdivision may increase size resolution of an array image by a factor of four. For a second level of subdivision G T and C may be created with a size resolution of 4 4 n.times.4 4 n i.e. 16n.times.16n . For convenience G T C G T and C may be initialized to zero.

In act processor may send structures G TO C G T C G T and C to graphics memory via data bus . In some implementations such operation may be performed using a graphics API. This operation may initialize space in graphics memory to be filled in later by vertex shader .

Vertex shaders may then subdivide G T and C to generate first subdivided vertex data G T and C in act . For example if the particular subdivision scheme employed is Catmull Clark subdivision scheme new face points for a face may be calculated by averaging old points defining the face. New edge points may be Calculated by averaging midpoints of old edges with the average of the two new face points of the faces sharing an edge. New vertex points may be calculated by averaging Q n 2 R n S n 3 n where Q equals the average of new face points of all faces adjacent to old vertex point R equals the average of midpoints of all old edges incident on old vertex point and S is the old vertex point. Other subdivision schemes than Catmull Clark may be used in some implementations.

As each set of points in G T and C is created vertex shaders may store the values in the corresponding placeholder structures in graphics memory in act . When the first subdivision is sufficiently complete vertex shaders may further subdivide G T and C to generate second subdivided vertex data G T and C in act . Vertex shaders may store the further subdivided values in the corresponding placeholder structures G T and C in graphics memory in act . As previously explained G T or C may not undergo a second level of subdivision in some implementations. Pixel shaders may read the finally subdivided vertex data e.g. G T and C if all have been twice subdivided from graphics memory and prepare it for display via frame buffer In implementations where G T and C are not all subdivided twice pixel shaders may prepare G and one or more less subdivided structures such as T and or C for display.

Although the above illustrative example includes a specific implementation the claimed invention is not necessarily limited thereto. For example the initial vertex data may include different graphical data than G T and C such as normal data. The number of subdivisions performed by vertex shaders may be less than or greater than two. Similarly a different subdivision scheme than Catmull Clark may be used in some implementations.

The foregoing description of one or more implementations provides illustration and description but is not intended to be exhaustive or to limit the scope of the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of various implementations of the invention.

For example although the subdivision scheme herein has been described with regard to vertex shaders in some implementations other graphics hardware may be used to implement subdivision. Such other hardware e.g. other types of shaders etc. may be suitable if it has the ability to read vertex data from and write subdivided vertex data to graphics memory .

Further the subdivision scheme described herein may be performed on an as needed basis e.g. substantially in real time by vertex shaders in some implementations and it may be pre computed by vertex shaders in some implementations. Also in some implementations vertex shaders may send the subdivided vertex data directly to pixel shaders rather than first writing it to graphics memory .

Moreover the acts in need not be implemented in the order shown nor do all of the acts necessarily need to be performed. Also those acts that are not dependent on other acts may be performed in parallel with the other acts. Further at least some of the acts in this figure may be implemented as instructions or groups of instructions implemented in a machine readable medium.

No element act or instruction used in the description of the present application should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Variations and modifications may be made to the above described implementation s of the claimed invention without departing substantially from the spirit and principles of the invention. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

