---

title: Predictive upload of snapshot data
abstract: A snapshot of a volume is taken by proactive uploading of scheduled snapshot data before the scheduled snapshot time has arrived. A volume snapshot schedule of once a day may be set up to a service provider using a speed-limited network connection. Using a determined upload speed of the network connection and a list of changes to the volume since a prior snapshot, a snapshot system may determine an appropriate time to start uploading volume data so that the snapshot may be completed at or after the scheduled snapshot time. By using the list of changes and available bandwidth of the network connection, the snapshot may be completed earlier than had it been started at the time of the snapshot and the available bandwidth of the network connection may be more efficiently used.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09170891&OS=09170891&RS=09170891
owner: Amazon Technologies, Inc.
number: 09170891
owner_city: Reno
owner_country: US
publication_date: 20120910
---
Many companies and other organizations operate networks that connect computing resources to support their operations such as with the computing systems being co located e.g. as part of a local network or instead located in multiple distinct geographical locations e.g. connected via one or more private or public intermediate networks . For example data centers housing significant numbers of interconnected computing systems have become commonplace such as private data centers that are operated by and on behalf of a single organization and public data centers that are operated by entities such as businesses to provide computing resources to customers.

Some public data center operators provide network access power and secure installation facilities for hardware owned by various customers while other public data center operators provide full service facilities that also include hardware resources made available for use by their customers. However as the scale and scope of public and private data centers have increased the tasks of provisioning administering and managing the physical computing resources have become increasingly complicated.

In the following description various embodiments will be described. For purposes of explanation specific configurations and details are set forth in order to provide a thorough understanding of the embodiments. However it will also be apparent to one skilled in the art that the embodiments may be practiced without the specific details. Furthermore well known features may be omitted or simplified in order not to obscure the embodiment being described.

Techniques described and suggested herein include taking a snapshot of a volume by proactive uploading of scheduled snapshot data before the scheduled snapshot time has arrived. For example a customer may set up a volume snapshot schedule of once a day to an off site service provider using a speed limited Internet connection. Using a determined upload speed of the Internet connection and a list of changes to the volume since a prior snapshot a snapshot system may determine an appropriate time to start uploading volume data so that the snapshot may be completed at or after the scheduled snapshot time. By using the list of changes and available bandwidth of the Internet connection the snapshot may be completed earlier than had it been started at the time of the snapshot and the available bandwidth of the Internet connection may be more efficiently used.

In one embodiment a storage appliance is placed at a customer premises. The storage appliance appears as a block storage volume to computing resources at the customer premises. The storage appliance responds to read and write requests from the client computing resources with the read request receiving a response including the stored data and write requests storing an associated write request data. For write requests changes to the data of the volume are stored in another data store which may be termed the working storage. The working storage stores the changes as entries in a queue with the queue containing at least the entries since a previous snapshot was performed. The storage appliance also interfaces with a service provider over an external network for storage of a snapshot. Using an amount of changed data reflected in the entries since the last snapshot the amount of upload throughput available to the storage appliance may be used to determine an upload time of how long the changes will take to upload to the service provider. If the amount of upload time is equal to or more than the remaining time to the scheduled snapshot with a delay factor or a buffer factor or no factor the storage appliance begins uploading the change data described in the entries in the working storage. Changes to already uploaded data may be re uploaded. Once the scheduled snapshot time occurs the working storage may mark the last entry of the snapshot. Remaining entries before and including the last entry of the snapshot may be uploaded to the service provider to finish the snapshot. For example a storage appliance determines the time TS until a next snapshot a throughput B to a service provider an amount D of changed data to upload and two factors K and L representing delay postpone or advance prepone of timing. If TS

In some embodiments a storage gateway may monitor changes to a data store external to the storage gateway. The data store may field the requests for read and write requests while the storage gateway monitors the data store and or the requests. Depending on the embodiment a write request may be forwarded in part or in whole to the storage gateway or the storage gateway may review the data store for changes. The storage gateway may track the changes to the data store. Upon determining the tracked changes should be uploaded to a service provider as part of a snapshot the storage gateway may perform read requests on the tracked data and upload the tracked data to the service provider.

In some embodiments further optimizations may be performed. In one embodiment data collisions in the working storage may be removed from a snapshot so that only the latest change represented by an entry is uploaded to the service provider. In another embodiment the upload may be delayed such that data collisions are given more time to be resolved before upload to improve the efficiency of the use of the upload bandwidth. In yet another embodiment only portions of a block or object may be uploaded and the service provider may update stored information with the portion.

In some embodiments the storage appliance and the service provider may use differing storage technologies. Conversion may be needed for the storage technologies. The conversion may occur at the client side before upload or the service provider side after upload. For example a storage appliance uses block storage and a service provider uses object storage. In this example optimum storage of the object store is 4 megabyte objects while the data store uses 4 kilobyte blocks. If a service provider does not have a method to update objects any change within a 4 megabyte object may necessitate a re upload of the 4 megabyte object. However if the storage service is able to update or mutate objects only the changes to the object may be uploaded. For example a service provider using object storage with immutable objects uses a storage helper that receives the update from the storage appliance. A new object is created by using an old object referenced in the update and merging the changes into the new object. A reference to the old object as part of a snapshot may be updated to reflect the new object.

It should be noted that a snapshot or a backup is used in some embodiments for the purpose of example clarity. However it should be recognized that a process or system can be used for either a backup and or a snapshot. In many embodiments in which a snapshot is discussed a backup may also be applicable. Similarly in many embodiments in which a backup is discussed a snapshot may also be applicable.

Turning now to an illustrative example of an environment is shown in which a predictive snapshot may be implemented in accordance with at least one embodiment. A client data center is connected to a storage service through an external network such as the Internet or private network capacity. The client data center may back up data such as a data store snapshot to the storage service over the external network . The external network may include limitations such as available bandwidth or throughput.

The client data center may contain multiple client computing systems that store information through a storage gateway . The storage gateway may be configured to appear as a block storage device to the client computing systems such that the client computing systems may read and write data to the storage gateway . The storage gateway may store the data in a data store . For each write to the data store an entry documenting the change may be stored in a second data store that may be called working storage . In some embodiments the working storage is a queue that receives and or organizes changes in order.

A snapshot may be represented in the queue as a difference between a prior snapshot and a set of entries in the working storage. For example a prior snapshot was taken at entry number in the working storage. A new snapshot is requested when the latest entry in the working storage was at entry number . Thus the new snapshot should contain the prior snapshot updated with the information in entries through . If the snapshot is remotely located such as in a service provider over an external network only the changes in entries through need be transferred to the service provider to save on expended external network usage. The working storage may continue to accept entries such as entries through as the new snapshot is known to end at entry .

The storage gateway may communicate with a storage service through an interface to the storage service such as an application programming interface API . The received data may be placed directly into storage and associated with a snapshot or further processed through a storage helper configured to further process incoming data. In some embodiments a storage helper performs a task of linking stored data with a specific snapshot. In other embodiments a storage helper converts block data information into object data information. In yet other embodiments a storage helper creates a new object to store by updating a prior object from storage with data received from storage gateway reducing the amount of information transferred over the external network . In some embodiments multiple storage helpers are used. The storage helpers may be modules code processes hardware software plugins or other computing tools used together with excuting on or separately from the storage service .

The storage gateway may use the working storage information to gain an advantage in time on a future scheduled backup. The storage gateway may determine a throughput of the external network of data that may be transferred to the storage service . This determination may be performed by historical analysis estimated load test measurements expected throughput or other estimation or determination of speed. The storage gateway may then determine the amount of changes that must be uploaded to the storage service by examining the entries in the working storage . The time remaining before the scheduled backup may also be determined. Using the throughput and amount of changes a determination on the amount of time required for the transfer may be determined. If the amount of time for the transfer is equal to or less than the time remaining before the scheduled backup the backup may be started. In some embodiments the time remaining or time for the transfer may be further altered with a factor to postpone or prepone the start of upload to data in the working storage . Any uploaded data that is further changed may be replaced by a second upload of the changed data. Upon a scheduled time for the scheduled backup the last working storage entry may be noted. Further changes may be stored in the working storage for further scheduled backups. However the uploading of the remaining entries in the working storage up to the last working storage entry may be uploaded to make the backup complete.

Turning now to an illustrative example is shown of an alternate environment in which a predictive snapshot may be implemented in accordance with at least one embodiment. In the example shown a client data center is connected to a service provider providing a storage service via the Internet . The client data center may include multiple client computing resources such as servers connected through internal networking to a gateway to the Internet a storage gateway and a data store . The servers may read and write information to the data store . The storage gateway may receive change information about the writes to the data store such as by receiving copies of the writes or by monitoring the data store . The storage gateway may store the tracking information in entries in working storage to identify changed data of the data store . Using the working storage the storage gateway may determine an efficient time to start upload of the data from the data store identified in the entries in working storage since a last snapshot. The efficient time may include historical data upload speed historical loads amount of data to upload and time remaining until a next scheduled snapshot and probabilities of data collisions in the time remaining. The data may be uploaded over a secure channel to the service provider . The service provider may store the data as related to a snapshot in object storage or further process the data through a storage helper to store in object storage . In the example shown in the data will need to be converted from block storage to object storage as the data store and object storage are of different storage types. At the time of the scheduled snapshot a last entry may be marked such that an end of the changes to upload for a snapshot is known. The storage gateway may then complete the snapshot by finishing the upload of any entries not yet uploaded to the service provider .

Turning now to an illustrative diagram of systems involved in a predictive snapshot in accordance with at least one embodiment is shown. The predictive snapshot may be seen as three phases a change management phase an optimization phase and a transmission phase . The optimization phase and transmission phase may also operate during two stages of uploading data to a service provider an upload of predictive pre snapshot data and an upload of post snapshot data. These phases however may operate at the same time and in any order. In the change management phase changes are stored in working storage as the changes are made to a local data store . A client computing resource such as a server process sends a change such as a write request to a storage gateway . The storage gateway causes the change to be written to the local data store and the working storage as a change entry . In some embodiments the change entry includes the changed data. In other embodiments the change entry is a reference to the local data store .

The local data store may prevent the overwriting of information that is in a closed snapshot but that is not yet uploaded to the service provider . An open snapshot may be represented by entries in a working storage that form part of a future snapshot. A closed snapshot may be represented by entries in a working storage that form part of a past snapshot and occur before or at a last entry of the snapshot. The snapshot may close at or near the time of the scheduled snapshot. Closing the snapshot may be based at least in part on the time of the scheduled backup which may mean that the time is selected from a set of times that is limited by the scheduled time e.g. it has to be within 2 hours of the scheduled time . In one embodiment changes that would affect an entry in the working storage that forms part of a closed snapshot may be stored in a journal that is applied after the uploading of the snapshot is complete. For example a write request is received from a client server to the storage gateway . The storage gateway may review the working storage to see if the location of the write is protected by an entry that is part of a closed snapshot. If not the write may occur. If the write is protected by an entry the entry may be stored on a journal to be applied after the snapshot upload is complete. In another embodiment changes to the local data store are directly stored in the working storage such that any changes to the local data store may be immediately applied. In yet another embodiment a link between working storage entry and a set of local storage blocks is created where the local storage blocks are marked dirty along with latest working storage entry that corresponds to the local storage block. When a working storage entry is processed and uploaded the corresponding local storage blocks that don t have any other later updates will be marked clean. In some cases the local store may not have all the data such as when the local store is operating in a caching mode.

The uploading of data to the service provider can be separated into two stages of uploading. The first stage is a predictive pre snapshot upload in which data predicted to be in a future snapshot is proactively uploaded before the snapshot is taken. The second stage is an upload of data that forms part of snapshot request in the past. The two phases are separated by the scheduled snapshot request. Predicting which data will form part of a future snapshot is useful during the first stage. The prediction process may be optimized by determining a probability that an entry will be overwritten in the remaining time before the snapshot is taken. In some embodiments the entries are prioritized for upload based on the smallest probability first or the greatest probability of not being overwritten . In other embodiments entries that fail to meet or exceed a probability threshold are skipped and entries that meet or exceed a probability threshold are included in the upload before the snapshot is taken. On the other hand in the second stage of upload all data forming the snapshot such as those identified by the write log must be uploaded to the service provider in order to consider the snapshot complete.

As part of the two stages of uploading the uploading may be accomplished by an optimization phase and a transmission phase . In the optimization phase a determination is made of which data to transmit to the service provider at what point in time. In the embodiment shown a storage gateway determines a time to begin uploading data. This time may be based on factors that include network speed time remaining until a scheduled snapshot and an amount of data to transmit over the network. The working storage may be examined for data collisions. A data collision is an overwrite of a prior write to a data store. Colliding entries may be removed from the working storage and the last entry may be selected as long as the colliding entry is completely overwritten.

In the transmission phase snapshot data is transmitted to the service provider according to the determinations made in the optimization phase. The storage gateway uploads information from the working storage according to optimizations from the optimization phase . Here colliding entries are skipped because of the optimzation performed in the optimization phase . Entries other than the colliding entries are retrieved from the local data store and sent by the storage gateway to the service provider over a communication channel. Communications channels may include secure or insecure HTTP HTTPS FTP TCP IP ethernet token ring RS232 or other communications technology hardware and or software.

Turning now to an illustrative diagram of systems involved in a predictive restore in accordance with at least one embodiment is shown. In one embodiment the predictive restore may be used to synchronize a remote volume to a snapshot that is not yet complete. The predictive restore may cause data from a predictive snapshot to be proactively sent to a remote volume before a snapshot is taken such that the predictive restore may complete faster than if the restore happened after the snapshot was taken. The predictive restore may be seen as three phases a change management phase an optimization phase and a transmission phase . These phases however may operate at the same time and in any order. In the change management phase changes are stored in working storage as the changes are made to a local data store . A client computing resource such as a server process sends a change such as a write request to a storage gateway to cause the change to be written to the local data store and the working storage as a change entry .

In the optimization phase a determination is made of which data to send to the service provider and restore volume at what point in time. The information will not only be uploaded to the service provider but also the restore volume . In the embodiment shown a storage gateway determines a time to begin uploading data to the service provider and the restore volume . This time may be based on factors that include network speed time remaining until a scheduled restore and an amount of data to transmit over the network. The working storage may be examined for data collisions. A data collision is an overwrite of a prior write to a data store. Colliding entries may be removed from the working storage to form non colliding working storage and the earliest change entry selected as long as the colliding entry is completely overwritten.

In the transmission phase snapshot data is uploaded to the service provider and restore volume according to the determinations made in the optimization phase. Prior snapshot information from the data store may be copied to the restore volume . The storage gateway uploads information from the working storage according to optimizations from the optimization phase . Here colliding entries are skipped because of the optimization performed in the optimization phase . Entries other than the colliding entries are retrieved from the local data store and uploaded by the storage gateway from the service provider over a communication channel. Communications channels may include secure or insecure HTTP HTTPS FTP TCP IP ethernet token ring RS232 or other communications technology hardware and or software. The storage gateway receives the data and applies the data to the restore volume .

In another embodiment this mechanism of predictive restore is part of asynchronous replication between two remote volumes. A second volume is updated via commit points or snapshot points from a first volume. The second volume is updated on a continuous basis such that each snapshot point from the first volume is restored onto the second volume in less time than if the entire snapshot were transferred between the volumes after the snapshot was taken. In some cases a snapshot may complete transfer approximately at the same time snapshot is taken.

Turning now to shows an illustrative example of an environment in which a predictive snapshot is used with a block storage system and an object storage system in accordance with at least one embodiment. A storage system tracks changes to block storage using a working storage . The working storage and block storage may be built upon a storage system such as a hard drive solid state storage virtual storage system database or other storage technologies. The working storage includes entries identifying changes to the block storage in the order the changes were accomplished. A snapshot is represented by a grouping of changes to the block storage since a prior snapshot.

The storage system may compile information to send as part of a snapshot to a service provider . In the embodiment shown the service provider uses object based storage but does not have a storage helper based for conversion from block storage . The storage system retrieves an entry from the working storage and retrieves necessay information from the block storage to compile an object for storage with the service provider . The object is sent over an external network to the service provider for storage. For example in the embodiment shown the entry identifies a change at block location for a length of 2 blocks. As an object is four blocks and always starts at a boundary of four the object is created by retrieving blocks and the modified block . The object is then sent to the service provider .

Turning now to shows an illustrative example of an environment in which a predictive snapshot is used with a block storage system to mutate an object within an object storage system in accordance with at least one embodiment. As seen in the working storage tracks changes of the block storage in order to create a snapshot . However if the service provider has a mutate helper only block is retrieved and sent over the external network . The mutate helper requests an old object containing the old block from the object storage . The mutate helper then creates an object to hold the old object blocks and the current block . The object is then stored in object storage as associated with the new snapshot. This mutate help allows for a reduction in the amount of redundant data transferred over the external network .

In another embodiment a smaller object may be created with metadata instructing that changes in the smaller object be applied to a prior larger object. For example a change to a prior object is stored as a new object with a corresponding change in metadata to reflect that the new object is now included in the volume as applied to the prior object. This allows a system to create a strongly consistent data store from eventually consistent data stores such as object data stores.

Turning now to an illustrative example of a process that may be used to perform a predictive snapshot in accordance with at least one embodiment is shown. The process may be performed by a system such as seen in including a storage service a storage gateway data store and working storage . The storage gateway may track changes to a data store since a last snapshot and determine available throughput to a storage service . Using the available throughput and a scheduled snapshot time the storage service may cause an upload of the changes to the data store to begin before a scheduled snapshot. After the time of the scheduled snapshot remaining changes to the data store may be uploaded to complete the snapshot. By leveraging the prior snapshot and changes since the snapshot to the data store the bandwidth and time used to upload the changed data to the storage service may be reduced as compared to upload of a full snapshot.

Some or all of the process or any other processes described herein or variations and or combinations thereof may be performed under the control of one or more computer systems configured with executable instructions and may be implemented as code e.g. executable instructions one or more computer programs or one or more applications executing collectively on one or more processors by hardware or combinations thereof. The code may be stored on a computer readable storage medium for example in the form of a computer program comprising a plurality of instructions executable by one or more processors. The computer readable storage medium may be non transitory.

Turning now to an illustrative example is shown of a process that may be used to perform a predictive snapshot upload based at least in part on a time to upload changes in accordance with at least one embodiment. The process may be performed by a system such as seen in including a storage service a storage gateway data store and working storage . The storage gateway may track changes to a data store since a last snapshot and determine available throughput to a storage service . The storage gateway may also determine a time remaining until a next snapshot. Using the working storage the storage gateway may determine an amount of changes needed to be uploaded to the storage service . Using the determined throughput remaining time and amount of changes the storage gateway may begin the upload of changes to the data store when the time required for the upload equals or is greater than the time to the next snapshot plus or minus a delay. This allows the storage gateway to get a head start on the uploading of changes to the data store that make up the snapshot so that the snapshot may be marked as completed more quickly. This proactive uploading also allows the storage gateway to make use of potentially expensive upload bandwidth that would be potentially wasted if not used. The upload bandwidth of the storage gateway to the storage service is potentially more expensive because longer distance communications are often slower and more expensive than short distance local communications. When the time for the snapshot arrives the last change or entry in the working storage may be marked . The changes may be uploaded to the storage service until the snapshot is complete. Once the marked entry is uploaded along with the other changes between the prior snapshot last entry and the marked entry the snapshot is complete.

Turning now to an illustrative example is shown of a process that may be used to perform a predictive snapshot based at least in part on predicted collisions in accordance with at least one embodiment. The process may be performed by a system such as seen in including a storage service a storage gateway data store and working storage . The storage gateway may track changes to a data store since a last snapshot. Using information such as the available throughput and a scheduled snapshot time the storage service may cause an upload of the changes to the data store to begin before a scheduled snapshot. Optimizations may be made such as removing collisions from the queue in the working storage . The storage gateway may determine a probability that each entry will be overwritten before the snapshot is closed. Using these probabilities such as computed by a heat map technique the data associated with the least probability of change may be selected to be uploaded first to avoid a re upload of data that is overwritten. If possible the amount of data sent to the storage service over the external network is minimized by determining to send only the changed data as a mutation to data existing in the storage service otherwise a collection may be determined to be sent. The selected data is then sent to the storage service . If the scheduled snapshot time has not yet arrived the process may be repeated starting at using the steps to update information as necessary such as step if a collision has occurred . Once the snapshot time passes the remaining data for the snapshot may be uploaded according to the working storage .

Turning now to an illustrative example is shown of a process that may be used to perform a predictive snapshot by prioritizing uploads in accordance with at least one embodiment. The process may be accomplished by a system such as seen in including a storage service a storage gateway data store and working storage . The storage gateway may still track changes to a data store since a last snapshot. The storage gateway may determine a time remaining until a next snapshot TS . The storage gateway may determine available throughput to a storage service B . Using the working storage the storage gateway may determine an amount of changes needed to be uploaded to the storage service D . Using a delay coefficient K and a delay factor L the determined throughput B remaining time TS and amount of changes D the storage gateway may begin the upload of changes to the data store when TS

The illustrative environment includes at least one application server and a data store . It should be understood that there can be several application servers layers or other elements processes or components which may be chained or otherwise configured which can interact to perform tasks such as obtaining data from an appropriate data store. As used herein the term data store refers to any device or combination of devices capable of storing accessing and retrieving data which may include any combination and number of data servers databases data storage devices and data storage media in any standard distributed or clustered environment. The application server can include any appropriate hardware and software for integrating with the data store as needed to execute aspects of one or more applications for the client device handling a majority of the data access and business logic for an application. The application server provides access control services in cooperation with the data store and is able to generate content such as text graphics audio and or video to be transferred to the user which may be served to the user by the Web server in the form of HTML XML or another appropriate structured language in this example. The handling of all requests and responses as well as the delivery of content between the client device and the application server can be handled by the Web server. It should be understood that the Web and application servers are not required and are merely example components as structured code discussed herein can be executed on any appropriate device or host machine as discussed elsewhere herein.

The data store can include several separate data tables databases or other data storage mechanisms and media for storing data relating to a particular aspect. For example the data store illustrated includes mechanisms for storing production data and user information which can be used to serve content for the production side. The data store also is shown to include a mechanism for storing log data which can be used for reporting analysis or other such purposes. It should be understood that there can be many other aspects that may need to be stored in the data store such as for page image information and to access right information which can be stored in any of the above listed mechanisms as appropriate or in additional mechanisms in the data store . The data store is operable through logic associated therewith to receive instructions from the application server and obtain update or otherwise process data in response thereto. In one example a user might submit a search request for a certain type of item. In this case the data store might access the user information to verify the identity of the user and can access the catalog detail information to obtain information about items of that type. The information then can be returned to the user such as in a results listing on a Web page that the user is able to view via a browser on the user device . Information for a particular item of interest can be viewed in a dedicated page or window of the browser.

Each server typically will include an operating system that provides executable program instructions for the general administration and operation of that server and typically will include a computer readable storage medium e.g. a hard disk random access memory read only memory etc. storing instructions that when executed by a processor of the server allow the server to perform its intended functions. Suitable implementations for the operating system and general functionality of the servers are known or commercially available and are readily implemented by persons having ordinary skill in the art particularly in light of the disclosure herein.

The environment in one embodiment is a distributed computing environment utilizing several computer systems and components that are interconnected via communication links using one or more computer networks or direct connections. However it will be appreciated by those of ordinary skill in the art that such a system could operate equally well in a system having fewer or a greater number of components than are illustrated in . Thus the depiction of the system in should be taken as being illustrative in nature and not limiting to the scope of the disclosure.

The various embodiments further can be implemented in a wide variety of operating environments which in some cases can include one or more user computers computing devices or processing devices which can be used to operate any of a number of applications. User or client devices can include any of a number of general purpose personal computers such as desktop or laptop computers running a standard operating system as well as cellular wireless and handheld devices running mobile software and capable of supporting a number of networking and messaging protocols. Such a system also can include a number of workstations running any of a variety of commercially available operating systems and other known applications for purposes such as development and database management. These devices also can include other electronic devices such as dummy terminals thin clients gaming systems and other devices capable of communicating via a network.

Most embodiments utilize at least one network that would be familiar to those skilled in the art for supporting communications using any of a variety of commercially available protocols such as TCP IP OSI FTP UPnP NFS CIFS and AppleTalk. The network can be for example a local area network a wide area network a virtual private network the Internet an intranet an extranet a public switched telephone network an infrared network a wireless network and any combination thereof.

In embodiments utilizing a Web server the Web server can run any of a variety of server or mid tier applications including HTTP servers FTP servers CGI servers data servers Java servers and business application servers. The server s also may be capable of executing programs or scripts in response requests from user devices such as by executing one or more Web applications that may be implemented as one or more scripts or programs written in any programming language such as Java C C or C or any scripting language such as Perl Python or TCL as well as combinations thereof. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase and IBM .

The environment can include a variety of data stores and other memory and storage media as discussed above. These can reside in a variety of locations such as on a storage medium local to and or resident in one or more of the computers or remote from any or all of the computers across the network. In a particular set of embodiments the information may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers servers or other network devices may be stored locally and or remotely as appropriate. Where a system includes computerized devices each such device can include hardware elements that may be electrically coupled via a bus the elements including for example at least one central processing unit CPU at least one input device e.g. a mouse keyboard controller touch screen or keypad and at least one output device e.g. a display device printer or speaker . Such a system may also include one or more storage devices such as disk drives optical storage devices and solid state storage devices such as random access memory RAM or read only memory ROM as well as removable media devices memory cards flash cards etc.

Such devices also can include a computer readable storage media reader a communications device e.g. a modem a network card wireless or wired an infrared communication device etc. and working memory as described above. The computer readable storage media reader can be connected with or configured to receive a computer readable storage medium representing remote local fixed and or removable storage devices as well as storage media for temporarily and or more permanently containing storing transmitting and retrieving computer readable information. The system and various devices also typically will include a number of software applications modules services or other elements located within at least one working memory device including an operating system and application programs such as a client application or Web browser. It should be appreciated that alternate embodiments may have numerous variations from that described above. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code can include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the a system device. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. It will however be evident that various modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims.

Other variations are within the spirit of the present disclosure. Thus while the disclosed techniques are susceptible to various modifications and alternative constructions certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood however that there is no intention to limit the invention to the specific form or forms disclosed but on the contrary the intention is to cover all modifications alternative constructions and equivalents falling within the spirit and scope of the invention as defined in the appended claims.

The use of the terms a and an and the and similar referents in the context of describing the disclosed embodiments especially in the context of the following claims are to be construed to cover both the singular and the plural unless otherwise indicated herein or clearly contradicted by context. The terms comprising having including and containing are to be construed as open ended terms i.e. meaning including but not limited to unless otherwise noted. The term connected is to be construed as partly or wholly contained within attached to or joined together even if there is something intervening. Recitation of ranges of values herein are merely intended to serve as a shorthand method of referring individually to each separate value falling within the range unless otherwise indicated herein and each separate value is incorporated into the specification as if it were individually recited herein. All methods described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. The use of any and all examples or exemplary language e.g. such as provided herein is intended merely to better illuminate embodiments of the invention and does not pose a limitation on the scope of the invention unless otherwise claimed. No language in the specification should be construed as indicating any non claimed element as essential to the practice of the invention.

Preferred embodiments of this disclosure are described herein including the best mode known to the inventors for carrying out the invention. Variations of those preferred embodiments may become apparent to those of ordinary skill in the art upon reading the foregoing description. The inventors expect skilled artisans to employ such variations as appropriate and the inventors intend for the invention to be practiced otherwise than as specifically described herein. Accordingly this invention includes all modifications and equivalents of the subject matter recited in the claims appended hereto as permitted by applicable law. Moreover any combination of the above described elements in all possible variations thereof is encompassed by the invention unless otherwise indicated herein or otherwise clearly contradicted by context.

All references including publications patent applications and patents cited herein are hereby incorporated by reference to the same extent as if each reference were individually and specifically indicated to be incorporated by reference and were set forth in its entirety herein.

