---

title: HIT testing of visual objects
abstract: Various embodiments for hit testing of visual objects are described herein. Data of visual objects is generated in a two-dimensional clip space. The data of visual objects includes two-dimensional projections of the visual objects. Cursor coordinates are transformed into the clip space and bounding box calculations are performed using the transformed cursor coordinates and the generated data. Hit testing is performed when there is a hit on a bounding box of at least one of the visual objects in the clip space. The hit testing is performed in a three-dimensional space. A result is then presented on a user interface based on the hit testing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09280449&OS=09280449&RS=09280449
owner: SAP SE
number: 09280449
owner_city: Walldorf
owner_country: DE
publication_date: 20120510
---
Several applications involve rendering of visual objects on a user interface. A rendering pipeline or method is typically used to render visual objects. The rendering pipeline includes a series of steps starting from an input to final rendering. These steps include for example transformations rasterizing clipping etc. depending on the type of graphics pipeline. In addition to rendering hit testing calculations are performed to recognize which object is selected by the user. Information about objects and cursor location is used for hit testing. Typically a Graphics Processing Unit GPU performs the rendering and in parallel a Central Processing Unit CPU performs hit testing calculations. But if there are large number of visual objects hit testing calculations consume significant CPU resources. This leads to performance issues such as reduced response time.

Embodiments of techniques for hit testing of visual objects are described herein. In the following description numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize however that the invention can be practiced without one or more of the specific details or with other methods components materials etc. In other instances well known structures materials or operations are not shown or described in detail to avoid obscuring aspects of the invention.

Reference throughout this specification to one embodiment this embodiment and similar phrases means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more embodiments.

Graphics pipeline refers to a process for rendering images on a screen. A graphics pipeline includes several stages in the process of rendering images. illustrates stages of a graphics pipeline as an example. It should be noted that types and number of stages in a graphics pipeline can vary depending on the type of graphics rendering platform or graphic application programming interfaces API . Also graphics pipelines continue to evolve and there can be refinements and changes to the stages in the pipeline. Some or all the stages of the pipeline can be programmable thereby providing flexibility for creating graphics for a variety of applications. The first stage is input assembly stage where primitive data such as points lines and triangles is read from user provided buffers. The data is assembled into primitives which are used in other stages in the pipeline . Vertices can be assembled into different primitive types. This data is then provided to a vertex shader stage where vertices are processed. Vertices are processed by performing operations such as transformations skinning and lighting. In vertex shader stage operations are performed for each vertex and a corresponding output vertex is produced for each vertex. In geometry shader stage entire primitives are processed. The input includes a fall primitive which is three vertices for a triangle two vertices for a line or a single vertex for a point. Each primitive can also include vertex data for any edge adjacent primitives.

In stream output stage primitive data is streamed from the pipeline to memory on its way to a rasterizer. Data can be streamed out to the rasterizer. Data streamed out to memory can be provided back into the pipeline as input data or read back from a CPU. The rasterizer stage is responsible for clipping primitives preparing primitives for a pixel shader and determining how to invoke pixel shaders. The pixel shader stage receives interpolated data for a primitive and generates per pixel data such as color. The output merger stage combines various types of output data such as pixel shader values depth and stencil information with the contents of the render target and depth stencil buffers to generate the final pipeline result.

In several interactive applications a user selects one or more visual objects that are displayed on a screen. A user can select a desired visual object using a mouse. In case of touchscreen displays a desired visual object can be selected by touching it on the screen. Visual objects are selected for various purposes depending on the type of application. In some applications a very large number of visual objects need to be displayed on a user interface. These visual objects can have same geometry. illustrates one such user interface that includes a large number of visual objects. In this example the visual objects are pins . These pins can be presented on a map or any topography. The pins have same geometry but are of different sizes to provide a three dimensional effect. For example a pin s location is captured in three dimensions namely an X dimension a Y dimension and a Z dimension. A pin having higher value of Z dimensional coordinate can have reduced size compared to a pin having lower value of Z dimensional coordinate to portray the three dimensional effect. Each pin is associated with a location in the map . A user can select a pin to know more details about data associated with a location corresponding to that pin .

In one embodiment if the visual objects have complex structure and include larger number of vertices e.g. greater than five vertices then the number of vertices of the objects are reduced before generating data of visual objects. As an example vertex data can be grouped or batched together to reduce the number of vertices. In one embodiment when the visual objects have a large number of vertices an additional step can be performed to obtain three dimensional bounding boxes. These three dimensional bounding boxes will have reduced number of vertices compared to the vertices of the visual objects. This additional step generates a stream output to the CPU.

Referring back to at cursor coordinates are transformed into the clip space. The cursor coordinates are obtained from user actions on the user interface as shown in . The user actions include selection of a visual object by using a mouse or by touching the visual object in case of touchscreen devices. The coordinates of the cursor indicate location of the cursor with respect to the screen space. This transformation is a normalizing transformation of the cursor coordinates. The transformed cursor coordinates is a point defined by X and Y coordinates in the clip space as shown in .

Referring back to at bounding box calculations are performed using the transformed cursor coordinates and the data of the visual object in the clip space. First minimum bounding boxes are calculated for the visual objects. A minimum bounding box can be a smallest rectangle or any polygon that encloses a visual object. In one embodiment a minimum bounding box is a smallest rectangle that encloses the transformed vertices in the clip space of a particular visual object. graphically illustrates bounding boxes for the transformed vertices of the visual objects in the clip space . The transformed cursor coordinates and the calculated bounding boxes are then used to determine if there is hit by the cursor on any of the bounding boxes . The transformed cursor coordinates represent a point in the clip space. If this point is within a bounding box then it is considered that there is a hit on that bounding box. In one embodiment a bounding box algorithm performs bounding box calculations. A bounding box algorithm checks whether a point lies within a bounding box which can be a rectangle.

In some cases the visual objects in the clip space may overlap indicating that they are at different depth or Z dimension. The cursor coordinates may have a hit on more than one of these overlapping objects. Therefore in one embodiment the bounding boxes can have a z dimensional value which can be used to detect a visual object among the overlapping visual objects.

Referring back to at hit testing is performed when there is a hit on a bounding box of a visual object in the clip space. For example if there is a hit on a bounding box of a visual object X in the clip space then hit testing is performed to determine whether the user selected the visual object X in the screen space. The space where hit testing is performed is a three dimensional space as shown in . The visual objects are represented in three dimensions in this three dimensional space corresponding to their arrangement in the UI screen space e.g. . Specifically the vertices and location information of the visual objects are represented in three dimensions.

If there is a hit on a bounding box of a visual object X in the clip space then hit testing is performed for the visual object X in the three dimensional space. In one embodiment a picking algorithm is used for hit testing. Referring to the picking algorithm converts cursor position in the screen space into three dimensions and creates a line in the three dimensional space using the view direction. If the created line intersects a visual object X then there is a hit on that visual object . This indicates that the user had selected the visual object X in the screen space.

In one embodiment the visual objects in the three dimensional space are divided into triangles and the picking algorithm performs hit testing based on these triangles. The picking algorithm processes the triangles to determine if the line intersects a triangle. When the line intersects a triangle then it is determined that there is a hit on the corresponding visual object.

In typical hit testing techniques several matrix transformations are performed depending on the number of visual objects. Matrix transformations include operations such as scaling translation rotation projections etc. Also both bounding box calculations and picking calculations are performed by the CPU in the three dimensional space. Significant CPU resources are consumed if there are numerous visual objects as in the example shown in . Referring to the CPU performs bounding box calculations and picking calculations and the GPU performs rendering. The CPU and GPU are in communication during the rendering and hit testing process. By performing bounding box calculation in clip space and then performing picking calculations on one or more visual objects that have a hit on their bounding box the number of matrix transformations required for picking calculations is drastically reduced. Instead of applying matrix transformations for all the visual objects for the hit testing and bounding box calculations the CPU applies matrix transformations only to those visual objects that have a hit on their bounding box in the clip space. The reduction in number of matrix transformations reduces load on the CPU and improves overall performance of the CPU.

Referring to if a visual object such as a pin is determined to be selected based on the hit testing calculations a result is displayed on the user interface . This result is associated with the selected pin . The type of result displayed varies depending on the application. As an example the result can include information associated with the selected pin . As another example the result can include a change in graphical properties of the selected pin .

Some embodiments of the invention may include the above described methods being written as one or more software components. These components and the functionality associated with each may be used by client server distributed or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as functional declarative procedural object oriented lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively the components maybe implemented in server and client applications. Further these components may be linked together via various distributed programming protocols. Some example embodiments of the invention may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level e.g. a graphical user interface . These first and second computer systems can be configured in a server client peer to peer or some other configuration. The clients can vary in complexity from mobile and handheld devices to thin clients and on to thick clients or even other servers.

The above illustrated software components are tangibly stored on a computer readable storage medium as instructions. The term computer readable storage medium should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term computer readable storage medium should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store encode or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described represented or illustrated herein. Examples of computer readable storage media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROMs DVDs and holographic devices magneto optical media and hardware devices that are specially configured to store and execute such as application specific integrated circuits ASICs programmable logic devices PLDs and ROM and RAM devices. Examples of computer readable instructions include machine code such as produced by a compiler and files containing higher level code that are executed by a computer using an interpreter. For example an embodiment of the invention may be implemented using Java C or other object oriented programming language and development tools. Another embodiment of the invention may be implemented in hard wired circuitry in place of or in combination with machine readable software instructions.

A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases such as relational transactional hierarchical multi dimensional e.g. OLAP object oriented databases and the like. Further data sources include tabular data e.g. spreadsheets delimited text files data tagged with a markup language e.g. XML data transactional data unstructured data e.g. text files screen scrapings hierarchical data e.g. data in a file system XML data files a plurality of reports and any other data source accessible through an established protocol such as Open DataBase Connectivity ODBC produced by an underlying software system e.g. ERP system and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams broadcast data and the like. These data sources can include associated data foundations semantic layers management systems security systems and so on.

In the above description numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize however that the invention can be practiced without one or more of the specific details or with other methods components techniques etc. In other instances well known operations or structures are not shown or described in details to avoid obscuring aspects of the invention.

Although the processes illustrated and described herein include series of steps it will be appreciated that the different embodiments of the present invention are not limited by the illustrated ordering of steps as some steps may occur in different orders some concurrently with other steps apart from that shown and described herein. In addition not all illustrated steps may be required to implement a methodology in accordance with the present invention. Moreover it will be appreciated that the processes may be implemented in association with the apparatus and systems illustrated and described herein as well as in association with other systems not illustrated.

The above descriptions and illustrations of embodiments of the invention including what is described in the Abstract is not intended to be exhaustive or to limit the invention to the precise forms disclosed. While specific embodiments of and examples for the invention are described herein for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. These modifications can be made to the invention in light of the above detailed description. Rather the scope of the invention is to be determined by the following claims which are to be interpreted in accordance with established doctrines of claim construction.

