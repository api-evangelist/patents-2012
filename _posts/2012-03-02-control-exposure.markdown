---

title: Control exposure
abstract: Control exposure techniques are described. In one or more implementations, a determination is made by a computing device as to which of a plurality of controls correspond to one or more inputs detected using one or more magnetometers, cameras, or microphones. A result of the determination is exposed by the computing device to one or more applications that are executed by the computing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09250713&OS=09250713&RS=09250713
owner: Microsoft Technology Licensing, LLC
number: 09250713
owner_city: Redmond
owner_country: US
publication_date: 20120302
---
This application claims priority under 35 U.S.C. Section 119 e to U.S. Provisional Application No. 61 567 026 filed Dec. 5 2011 and titled Extensible Model to Control UI with Voice or Motion Sensors the entire disclosure of which is hereby incorporated by reference.

The way in which users are able to interact with a computing device is ever increasing. For example interaction with a computing device was initially performed using text. Therefore a user typically entered the text using a keyboard and viewed an output by the computing device that was also in text.

These techniques were then expanded into graphical user interfaces in which a user could interact with a cursor control device such as a mouse. The techniques continued to expand as graphical user interfaces were configured to recognize gestures made by a user to provide inputs to the computing device. For example gestures may be used to select objects interact with a video game and so on. However these techniques conventionally relied on operations that were performed by an application itself such as to recognize which motions corresponded to which gestures and thus may complicate coding of the application by application developers.

Control exposure techniques are described. In one or more implementations a determination is made by a computing device as to which of a plurality of controls correspond to one or more inputs detected using one or more magnetometers cameras or microphones. A result of the determination is exposed by the computing device to one or more applications that are executed by the computing device.

In one or more implementations a system is implemented by a computing device. The system includes one or more applications that are executable on hardware of the computing device and a module that is implemented at least partially using the hardware of the computing device. The module is configured to receive one or more inputs that describe user interaction that is detected without using touch determine which of the one or more applications are a target of the one or more inputs convert the one or more inputs into events that are consumable by the targeted applications and expose the events to the targeted applications.

In one or more implementations one or more computer readable storage media comprise instructions stored thereon that responsive to execution by a computing device causes the computing device to implement an operating system configured to expose one or more events via an application programming interface for one or more controls identified by the operating system from inputs received from one or more cameras of the computing device.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Input techniques that may be utilized to interact with a computing device have evolved from text input techniques typically implemented using a keyboard to gestures that may be captured using a camera. However conventional techniques relied on the applications themselves to recognize the gestures and thus were not extensible could result in duplicative coding across applications and so forth.

Control exposure techniques are described. In one or more implementations a module may be incorporated as part of an operating system of a computing device. The module may be configured to process inputs. The inputs may originate from a variety of input devices such as magnetometers cameras microphones and so on. Thus in some instances these inputs may be used to support a natural user interface that does not involve touch. The inputs may be processed by the module for exposure to applications of the computing device such as events as associated with one or more controls and so on. This may be used to support an extensible system and may do so while maintaining system consistency e.g. extensible in such a manner that the user experience is not compromised. Thus the module may provide this functionality to applications without the applications having to know how these events and or controls were implemented further discussion of which may be found in relation to the following figures.

In the following discussion an example environment is first described that is operable to employ the described herein. Example illustrations of the techniques and procedures are then described which may be employed in the example environment as well as in other environments. Accordingly the example environment is not limited to performing the example techniques and procedures. Likewise the example techniques and procedures are not limited to implementation in the example environment.

The computing device is also illustrated as including a processing system and an example of computer readable storage media which in this instance is memory . The processing system is not limited by the materials from which they are formed or the processing mechanisms employed therein. For example the processing system may be comprised of semiconductor s and or transistors e.g. electronic integrated circuits ICs such as a system on a chip CPUs functional blocks and so on. In such a context executable instructions may be electronically executable instructions. Alternatively the mechanisms of or for processing system and thus of or for a computing device may include but are not limited to quantum computing optical computing mechanical computing e.g. using nanotechnology and so forth. Additionally although a single memory is shown a wide variety of types and combinations of memory may be employed such as random access memory RAM hard disk memory removable medium memory and other types of computer readable media.

The computing device is further illustrated as including an operating system . The operating system is configured to abstract underlying functionality of the computing device to applications that are executable on the computing device . For example the operating system may abstract the processing system memory network input output and or display functionality of the computing device such that the applications may be written without knowing how this underlying functionality is implemented. The application for instance may provide data to the operating system to be rendered and displayed by the display device without understanding how this rendering will be performed. The operating system may also represent a variety of other functionality such as to manage a file system and user interface that is navigable by a user of the computing device .

The operating system is also illustrated as including a NUI input module which may be included as part of input output functionality supported by the operating system . Thus the NUI input module is representative of functionality relating to recognition of inputs and or provision of outputs by the computing device . For example the NUI input module may be configured to identify gestures and cause operations to be performed that correspond to the gestures and so on. The inputs may be detected for processing by the NUI input module in a variety of different ways.

For example the operating system may be configured to receive one or more inputs via touch interaction with a hardware device such as a controller as illustrated. Touch interaction may involve pressing a button moving a joystick movement across a track pad use of a touch screen of the display device e.g. detection of a finger of a user s hand or a stylus and so on. Recognition of the touch inputs may be leveraged by the operating system to interact with a user interface output by the computing device such as to interact with a game an application browse the internet change one or more settings of the computing device and so forth. A variety of other hardware devices are also contemplated that involve touch interaction with the device. Examples of such hardware devices include a cursor control device e.g. a mouse a remote control e.g. a television remote control a mobile communication device e.g. a wireless phone configured to control one or more operations of the computing device and other devices that involve touch on the part of a user or object.

The NUI input module may be leveraged by the operating system to support a natural user interface NUI that may recognize interactions that may not involve touch. For example the computing device may include a NUI input device . The NUI input device may be configured in a variety of ways to detect inputs without having a user touch a particular device such as to recognize audio inputs through use of a microphone. For instance the NUI input module may be configured to perform voice recognition to recognize particular utterances e.g. a spoken command as well as to recognize a particular user that provided the utterances.

In another example the NUI input device that may be configured to support recognition of gestures presented objects images and so on through use of a camera. The camera for instance may be configured to include multiple lenses so that different perspectives may be captured and thus determine depth. The different perspectives for instance may be used to determine a relative distance from the NUI input device and thus a change in the relative distance. The different perspectives may be leveraged by the NUI input module as depth perception. The images may also be leveraged by the NUI input module to provide a variety of other functionality such as techniques to identify particular users e.g. through facial recognition objects and so on.

The NUI input module may leverage the NUI input device to perform skeletal mapping along with feature extraction of particular points of a human body e.g. 48 skeletal points to track one or more users e.g. four users simultaneously to perform motion analysis. For instance the NUI input device may capture images that are analyzed by the NUI input module to recognize one or more motions made by a user including what body part is used to make the motion as well as which user made the motion. An example is illustrated through recognition of positioning and movement of one or more fingers of a user s hand and or movement of the user s hand as a whole. The motions may be identified as gestures by the NUI input module to initiate a corresponding operation.

A variety of different types of gestures may be recognized such a gestures that are recognized from a single type of input e.g. a motion gesture as well as gestures involving multiple types of inputs e.g. a motion gesture and an object gesture made using an object. Thus the NUI input module may support a variety of different gesture techniques by recognizing and leveraging a division between inputs. It should be noted that by differentiating between inputs in the natural user interface NUI the number of gestures that are made possible by each of these inputs alone is also increased. For example although the movements may be the same different gestures or different parameters to analogous commands may be indicated using different types of inputs. Thus the NUI input module may provide a natural user interface that supports a variety of user interaction s that do not involve touch.

Accordingly although the following discussion may describe specific examples of inputs in instances different types of inputs may also be used without departing from the spirit and scope thereof. Further although in instances in the following discussion the gestures are illustrated as being input using a NUI the gestures may be input using a variety of different techniques by a variety of different devices such as to employ touchscreen functionality of a tablet computer.

In one or more implementations the NUI input module may be configured to expose a result of processing of inputs received from the NUI input device for consumption by the one or more applications . Thus in this example a developer of the applications may access leverage this functionality without specifically encoding this processing as part of the application itself. Further discussion of exposure of this functionality by the NUI input module may be found in relation to the following figure.

As part of this the NUI input module may provide controls that are usable by the applications . The controls for instance may support a default set of commonly used paradigms that involve canned behaviors examples of which include magnetism motion data voice commands and so forth. The NUI input module may also follow a programming model that supports third party scalability along with algorithms for magnetism and data structures that may be exposed to support extensibility for third parties e.g. the applications .

In one or more implementations the NUI input module is configured to receive inputs from one or more input devices such as cameras and or microphones of the NUI input module as previously described. The NUI input module may then produce a set of events to which the applications may subscribe. The events for instance may pertain to motion detected using a camera voice detected using a microphone magnetometer or other sensors of the computing device .

For example the operating system may route these inputs to the NUI input module . The NUI input module may then determine a current state of one or more of the applications e.g. is the application currently being executed listening for events and so on. From this state the NUI input module may determine a target of the inputs and therefore convert the inputs to be compatible with the target e.g. one or more of the applications .

These inputs may then be exposed to the applications in a variety of ways such as associated with a particular one of the controls as events via an application programming interface as commands and so on. The events for instance may be configured as specific to the NUI input device as keyboard events e.g. such that a NUI input gesture is converted to a keyboard input and so forth.

To determine how the inputs are to be converted for compatibility with the applications the NUI input module may perform one or more handshaking operations with the applications . For example the NUI input module may perform a handshake with a runtime in question with respect to application state to negotiate a result that is compatible with the applications . Examples of data points that may be used relate to magnetism focus pre defined gestures application state and so on.

For example the NUI input module may leverage NUI handles control pack behavior and a control pack experience user interface XUI which itself employs a dashboard and content player . These modules may be thought of as part of a living room experience. The NUI input module may also include modules that are used for a basis of the determination as well as a source of the inputs examples of which are illustrated as a NUI speech library a NUI input library and audio visual AV . Thus the NUI input module may use these modules to look at a current state of an application runtime determine a target of the input and convert it into a paradigm that is exposed on the public surface via the controls such as through use of new e.g. motion based or legacy e.g. keyboard events.

There are a variety of different modes of programmability supported by the NUI input module . In a first mode the NUI input module may output a raw stream that is not processed by the NUI input module and thus application developers may use this raw stream to develop operations e.g. gestures that are not otherwise supported by the NUI input module . A second mode is used to support controls and the layout thereof in a user interface. This mode may include baked in behaviors and or may be built into the applications based on design specifications supported by the NUI input module . Further the NUI input module may support heuristics to determine how to configure a result computed by the NUI input module for consumption by a target. As previously described this may involve a handshake between the application runtime in question to negotiate how the result is to be output.

The following discussion describes techniques that may be implemented utilizing the previously described systems and devices. Aspects of each of the procedures may be implemented in hardware firmware software or a combination thereof. The procedures are shown as a set of blocks that specify operations performed by one or more devices and are not necessarily limited to the orders shown for performing the operations by the respective blocks. In portions of the following discussion reference will be made to the environment of and the systems of .

A result of the determination is exposed by the computing device to one or more applications that are executed by the computing device block . The result for instance may identify the control as well as an operation to be performed e.g. a press of a particular button movement of a slider control panning selection of content a cut and paste and so forth. Thus the NUI input module may expose a variety of functionality such that a developer of the applications may efficiently leverage this functionality. A variety of other examples are also contemplated.

A determination is made as to which of the one or more applications are targeted by the one or more inputs block . As previously described the NUI input module may perform a handshake to determine a state of the applications and thus determine which applications are available to receive events what events the applications are looking for and so forth.

The one or more inputs are converted into events that are consumable by the targeted applications block . Continuing with the previous example the NUI input module may use a result of the handshake to determine how to expose the one or more inputs e.g. which events controls and so forth are supported by the applications . The events are then exposed to the targeted applications block e.g. via an application programming interface. A variety of other examples are also contemplated as previously described.

The example computing device as illustrated includes a processing system one or more computer readable media and one or more I O interface that are communicatively coupled one to another. Although not shown the computing device may further include a system bus or other data and command transfer system that couples the various components one to another. A system bus can include any one or combination of different bus structures such as a memory bus or memory controller a peripheral bus a universal serial bus and or a processor or local bus that utilizes any of a variety of bus architectures. A variety of other examples are also contemplated such as control and data lines.

The processing system is representative of functionality to perform one or more operations using hardware. Accordingly the processing system is illustrated as including hardware element that may be configured as processors functional blocks and so forth. This may include implementation in hardware as an application specific integrated circuit or other logic device formed using one or more semiconductors. The hardware elements are not limited by the materials from which they are formed or the processing mechanisms employed therein. For example processors may be comprised of semiconductor s and or transistors e.g. electronic integrated circuits ICs . In such a context processor executable instructions may be electronically executable instructions.

The computer readable storage media is illustrated as including memory storage . The memory storage represents memory storage capacity associated with one or more computer readable media. The memory storage component may include volatile media such as random access memory RAM and or nonvolatile media such as read only memory ROM Flash memory optical disks magnetic disks and so forth . The memory storage component may include fixed media e.g. RAM ROM a fixed hard drive and so on as well as removable media e.g. Flash memory a removable hard drive an optical disc and so forth . The computer readable media may be configured in a variety of other ways as further described below.

Input output interface s are representative of functionality to allow a user to enter commands and information to computing device and also allow information to be presented to the user and or other components or devices using various input output devices. Examples of input devices include a keyboard a cursor control device e.g. a mouse a microphone a scanner touch functionality e.g. capacitive or other sensors that are configured to detect physical touch a camera e.g. which may employ visible or non visible wavelengths such as infrared frequencies to recognize movement as gestures that do not involve touch and so forth. Examples of output devices include a display device e.g. a monitor or projector speakers a printer a network card tactile response device and so forth. Thus the computing device may be configured in a variety of ways as further described below to support user interaction.

Various techniques may be described herein in the general context of software hardware elements or program modules. Generally such modules include routines programs objects elements components data structures and so forth that perform particular tasks or implement particular abstract data types. The terms module functionality and component as used herein generally represent software firmware hardware or a combination thereof. The features of the techniques described herein are platform independent meaning that the techniques may be implemented on a variety of commercial computing platforms having a variety of processors.

An implementation of the described modules and techniques may be stored on or transmitted across some form of computer readable media. The computer readable media may include a variety of media that may be accessed by the computing device . By way of example and not limitation computer readable media may include computer readable storage media and computer readable signal media. 

 Computer readable storage media may refer to media and or devices that enable persistent and or non transitory storage of information in contrast to mere signal transmission carrier waves or signals per se. Thus computer readable storage media refers to non signal bearing media. The computer readable storage media includes hardware such as volatile and non volatile removable and non removable media and or storage devices implemented in a method or technology suitable for storage of information such as computer readable instructions data structures program modules logic elements circuits or other data. Examples of computer readable storage media may include but are not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage hard disks magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or other storage device tangible media or article of manufacture suitable to store the desired information and which may be accessed by a computer.

 Computer readable signal media may refer to a signal bearing medium that is configured to transmit instructions to the hardware of the computing device such as via a network. Signal media typically may embody computer readable instructions data structures program modules or other data in a modulated data signal such as carrier waves data signals or other transport mechanism. Signal media also include any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media include wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media.

As previously described hardware elements and computer readable media are representative of modules programmable device logic and or fixed device logic implemented in a hardware form that may be employed in some embodiments to implement at least some aspects of the techniques described herein such as to perform one or more instructions. Hardware may include components of an integrated circuit or on chip system an application specific integrated circuit ASIC a field programmable gate array FPGA a complex programmable logic device CPLD and other implementations in silicon or other hardware. In this context hardware may operate as a processing device that performs program tasks defined by instructions and or logic embodied by the hardware as well as a hardware utilized to store instructions for execution e.g. the computer readable storage media described previously.

Combinations of the foregoing may also be employed to implement various techniques described herein. Accordingly software hardware or executable modules may be implemented as one or more instructions and or logic embodied on some form of computer readable storage media and or by one or more hardware elements . The computing device may be configured to implement particular instructions and or functions corresponding to the software and or hardware modules. Accordingly implementation of a module that is executable by the computing device as software may be achieved at least partially in hardware e.g. through use of computer readable storage media and or hardware elements of the processing system . The instructions and or functions may be executable operable by one or more articles of manufacture for example one or more computing devices and or processing systems to implement techniques modules and examples described herein.

As further illustrated in the example system enables ubiquitous environments for a seamless user experience when running applications on a personal computer PC a television device and or a mobile device. Services and applications run substantially similar in all three environments for a common user experience when transitioning from one device to the next while utilizing an application playing a video game watching a video and so on.

In the example system multiple devices are interconnected through a central computing device. The central computing device may be local to the multiple devices or may be located remotely from the multiple devices. In one embodiment the central computing device may be a cloud of one or more server computers that are connected to the multiple devices through a network the Internet or other data communication link.

In one embodiment this interconnection architecture enables functionality to be delivered across multiple devices to provide a common and seamless experience to a user of the multiple devices. Each of the multiple devices may have different physical requirements and capabilities and the central computing device uses a platform to enable the delivery of an experience to the device that is both tailored to the device and yet common to all devices. In one embodiment a class of target devices is created and experiences are tailored to the generic class of devices. A class of devices may be defined by physical features types of usage or other common characteristics of the devices.

In various implementations the computing device may assume a variety of different configurations such as for computer mobile and television uses. Each of these configurations includes devices that may have generally different constructs and capabilities and thus the computing device may be configured according to one or more of the different device classes. For instance the computing device may be implemented as the computer class of a device that includes a personal computer desktop computer a multi screen computer laptop computer netbook and so on.

The computing device may also be implemented as the mobile class of device that includes mobile devices such as a mobile phone portable music player portable gaming device a tablet computer a multi screen computer and so on. The computing device may also be implemented as the television class of device that includes devices having or connected to generally larger screens in casual viewing environments. These devices include televisions set top boxes gaming consoles and so on.

The techniques described herein may be supported by these various configurations of the computing device and are not limited to the specific examples of the techniques described herein. This functionality may also be implemented all or in part through use of a distributed system such as over a cloud via a platform as described below.

The cloud includes and or is representative of a platform for resources . The platform abstracts underlying functionality of hardware e.g. servers and software resources of the cloud . The resources may include applications and or data that can be utilized while computer processing is executed on servers that are remote from the computing device . Resources can also include services provided over the Internet and or through a subscriber network such as a cellular or Wi Fi network.

The platform may abstract resources and functions to connect the computing device with other computing devices. The platform may also serve to abstract scaling of resources to provide a corresponding level of scale to encountered demand for the resources that are implemented via the platform . Accordingly in an interconnected device embodiment implementation of functionality described herein may be distributed throughout the system . For example the functionality may be implemented in part on the computing device as well as via the platform that abstracts the functionality of the cloud .

Although the invention has been described in language specific to structural features and or methodological acts it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as example forms of implementing the claimed invention.

