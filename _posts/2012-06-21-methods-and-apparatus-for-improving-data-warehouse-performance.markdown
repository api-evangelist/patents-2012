---

title: Methods and apparatus for improving data warehouse performance
abstract: Methods and apparatus for improving data warehouse performance are disclosed. An example method to transform a first database into a second database includes generating a first mapping file associated with a fact table of the first database, the first mapping file referenced by a first hierarchical directory file path, generating a second mapping file associated with a dimension table, the second mapping file referenced by a second hierarchical directory file path, and retrieving data from the second database using the first and second mapping files via sequential navigation of the first and second hierarchical directory file paths.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08738576&OS=08738576&RS=08738576
owner: The Nielsen Company (US), LLC.
number: 08738576
owner_city: Schaumburg
owner_country: US
publication_date: 20120621
---
This patent arises from a continuation of U.S. application Ser. No. 12 400 962 filed Mar. 10 2009 which issued as U.S. Pat. No. 8 219 521 on Jul. 10 2012 which is a continuation of U.S. application Ser. No. 12 088 809 filed Mar. 31 2008 which issued as U.S. Pat. No. 7 523 124 on Apr. 21 2009 which is a continuation of International application No. PCT US2007 104834 filed Jun. 26 2007 which claims priority from U.S. Provisional Application Ser. No. 60 816 423 filed Jun. 26 2006 entitled Methods and Apparatus for Improving Data Warehouse Performance and which are hereby incorporated herein by reference in their entireties.

This disclosure relates generally to data formatting and analysis and more particularly to methods and apparatus for improving data warehouse performance.

Storage retrieval and processing of various types of data permits businesses to engineer new business plans and or adjust existing business plans for optimum performance. For example a wireless telephone company may manage a data warehouse to store existing and or new subscriber information. If the wireless company processes such collected data growth trends may be discovered that suggest new market opportunities and or overburdened markets in need of service equipment rehabilitation and or addition. Analysis of business data stored in a data warehouse may allow the business to convert such data into business intelligence learn more about their customers and or make various management decisions based on empirical information rather than heuristics.

Non business related organizations may also analyze warehoused data to meet various engineered objectives. For example governments and or municipalities may study population growth and or population movement to better prepare city infrastructure and or services for increased use. Similarly such population trend analysis may illustrate that allocated budgets may be redirected from lesser needed city projects to higher prioritized projects in neighborhoods with substantial population growth rates.

A data warehouse may maintain copies of data for subsequent analysis. Data may include population data financial data business data and or behavioral data such as cable television subscriptions home buying behavior and or broadcast programming consumption. The data warehouse may be stored in a variety of ways including in a relational database a multidimensional database a flat file a hierarchical database an object database etc. Reports generated from the data warehouse are typically created to expose specific metrics important to the business government entity and or other group s . The reports typically consume a finite amount of processing and memory resources which may result in diminished data warehouse performance as the size of the stored data increases.

Moreover if multiple clients seek reports from a particular data warehouse at overlapping times the decreased performance capabilities may result in unsatisfactory wait times for the clients and or an inability to run queries in a manner responsive to quickly changing client demands. For example some data warehouses may require multiple hours of processing time to generate a report for a client. If the client subsequently chooses an alternate set of parameters for the report then the client must wait a significant amount of time for the next opportunity to run a query on the overburdened data warehouse. At other times depending on the processing loads of the data warehouse the processing time may be lower thereby making it difficult for a data warehouse manager to efficiently allocate and or manage data warehouse processing time for multiple clients.

Data warehouses are collecting a large amount of information regarding one or more subjects of interest such as for example spending habits of consumers and or businesses transaction data e.g. financial market transactions real estate transactions etc. population growth information and or multi media broadcast viewing behavior to name a few. Businesses that maintain and control data warehouse facilities and or provide data storage processing analysis and or report generating services are faced with challenges created by virtue of this growth. Generally speaking as a data warehouse storage capacity is consumed additional processing power and or processing cycles are needed to analyze the increasing amount of collected data. As used herein data analysis processing may include but is not limited to searching for trends between collected data parameters executing statistical functions on the collected data accumulating calculated results and or generating reports reflecting the results of a query for end user review. Data processing analysis and or storing functions of the data warehouse compete for processing resources thereby taxing the data warehouse system as the collected data grows.

Data warehousing businesses that offer such storage and or processing services to clients sometimes attempt to manage client expectations by adding processors to computer servers adding storage space to the data warehousing system s and or implementing data warehousing subsystems. In addition to changes and or updates applied to a data warehousing infrastructure to improve performance these data warehousing businesses may also provide their clients with advance notice of turn around times for completed reports to ensure clients are not disappointed. If the client knows in advance how much time a given report may take then client expectations may be accurate resulting in increased client satisfaction. However irrespective of advance notice to the clients excessively long report generation processing time may still result in client dissatisfaction. Additionally report generation processing time may be dependent upon time of day usage factors that cause expected processing time s to fluctuate unexpectedly thereby making it difficult to accurately provide advance notice to the client.

To accommodate diverse clients the data warehouse business may employ a number of data marts. As used herein a data mart is one or more smaller databases focused on one or more particular business es and or subject s . However despite the fact that a data mart size is less than that of the aggregate data warehouse data mart s may grow to a substantially large size thereby creating a negative effect on report generation and other database performance characteristics.

The example methods and apparatus described herein may be used to improve data warehouse performance. In general the example methods and apparatus illustrated herein may be employed by a data warehouse on site and or provided to one or more clients as an application programming interface API to be run on one or more personal computers servers and or other computing platforms. The API may include a graphical user interface GUI and or the data warehouse may provide turn key solutions to their clients in response to simple web based report requests.

As discussed in further detail below the data warehouse optimizer of the illustrated example is in communication with one or more data warehouses . Each data warehouse may include one or more databases to store one or more types of data. In the illustrated example one data warehouse is communicatively connected directly to the data warehouse optimizer . Direct connections to the data warehouse may be accomplished via one or more connections and or communication protocols including but not limited to the universal serial bus USB communication protocol and or the FireWire communication protocol i.e. IEEE 1394 . Additionally the data warehouse optimizer and the data warehouses of the illustrated example are communicatively coupled via a network such as an intranet and or the Internet. Suitable network connections include but are not limited to Ethernet communication protocols IEEE 802.11 Wi Fi Bluetooth 900 MHz 1.6 GHz and or mobile communications protocols e.g. CDMA TDMA GSM AMPS EDGE etc. .

The data warehouse optimizer of the illustrated example receives data analysis instructions and extracts relevant data from one or more data warehouses in response to the analysis instructions . Rather than inundate each of the data warehouses with both a data query acquisition and statistical processing the data warehouse optimizer of the illustrated example extracts e.g. copies specific data which is responsive to a given set of instructions from one or more of the data warehouses and stores the extracted data to a temporary memory . As such the data warehouse optimizer relieves the data warehouses from the responsibility of performing complex statistical data processing thereby allowing each of the data warehouses to focus on the tasks of data storage archival and data provisioning in response to requests. The memory may be implemented using a mass storage optical magnetic and or solid state memory and may be used to store the executable API mentioned above and or data collected from the data warehouse s that is to be used for building block statistics as discussed in further detail below.

Although only one optimizer is shown in persons of ordinary skill in the art will appreciate that multiple optimizers may be employed. The data warehouse optimizer s of the illustrated example are implemented on a computer such as a personal computer PC . Persons of ordinary skill in the art will appreciate that costs of computers and or computer hardware have decreased thereby making PCs a cost judicious alternative for dedicated processing tasks. Additionally or alternatively the data warehouse optimizer s may be implemented on a server including one or more hard disk drives to store collected data received from the data warehouses . The PCs and or servers implementing the optimizer s may be located at or near the data warehousing business facility to process client requests. Alternatively the PCs and or servers implementing the optimizer s may be owned by one or more clients. Thus for example a data warehouse optimizer may execute as an API on the client machine to create and or process the data analysis instructions . Such APIs may be sold or licensed to the clients and or the data warehousing business may charge the client a per transaction fee to use the API.

An example data warehouse optimizer is shown in further detail in . In the illustrated example the data warehouse optimizer includes a communication interface a data retriever an analyzer and a report generator . Additionally the example data retriever includes a structured query language SQL generator and a scheduler . As discussed above the communication interface enables communication via a dedicated connection a direct connection and or a network such as an intranet or the Internet. Communication to from the example data warehouse optimizer may occur via web pages e.g. Active Server Pages command line user interfaces graphical user interfaces and or kiosks. The communication interface may include one or more protective measures e.g. a firewall to shield the data warehouse optimizer from unauthorized use and or tampering.

Data analysis instructions such as an XML file are received by the communication interface and provided to the data retriever . The data analysis instructions may contain one or more parameters attributes statistics and or formatting instructions for the requested report s . For example the data analysis instructions may specify the type s of data of interest and or that data should be extracted from a data warehouse for a particular time period e.g. day week month etc. a particular broadcast program e.g. sporting event movie sit com etc. and or for a particular demographic group e.g. children teenagers adults senior citizens Mexican Americans Polish Americans etc. . The data analysis instructions may also specify a particular data warehouse from which the data is to be retrieved.

Many data warehouses may contain private privileged e.g. attorney client communications social security numbers bank account numbers etc. and or business sensitive data. Thus the data analysis instructions may also contain one or more authentication parameters to control connection and or access to an entire data warehouse or specific facets of the data warehouse. Accordingly the data retriever of the illustrated example may invoke the communication interface to establish a connection for data transfer. Authentication between the data warehouse optimizer and a data warehouse may include but is not limited to secure sockets layer SSL digital certificates password protection encryption and or public key cryptography.

Once the example data warehouse optimizer connects to a particular data warehouse the SQL generator may create query commands specific to the requested data identified in the data analysis instructions . In some examples the instructions may recite SituationComedy as a data parameter for which the data warehouse optimizer is to analyze viewership numbers. Similarly the instructions may recite Retirees as another data parameter for which the data warehouse optimizer is to analyze viewership numbers. However exact parameter nomenclature between the data analysis instructions and one or more of the data warehouses may not exist. As such the data retriever may resolve any disparity between one or more of the data warehouses and the analysis instructions using for example metadata. Thus for instance while the example data analysis instructions may recite SituationComedy the data warehouse may instead employ the term sitcom. The metadata maps the nomenclature between one or more terms so that a lack of exact parity between the data warehouses and the analysis instructions does not prevent data processing from occurring. The data retriever of the illustrated example accomplishes metadata resolution by associating frequently used alternative nomenclature with the nomenclature employed by a particular analysis instruction e.g. an XML file . Alternatively the data analysis instructions may include any number of alias nomenclature terms to associate with data warehouse nomenclature such that if a first attempt to match an analysis parameter with a data warehouse parameter fails then an alternate nomenclature term from the analysis instructions may be attempted.

In other examples the data retriever resolves data analysis instructions in coded values employed by one or more data warehouses. Coded values may be used rather than explicit values to for example save memory. For example the data warehouse may employ an integer number scale from 1 to 4 for a representation of four different income levels. A value of 1 may represent an income threshold between 10 000 and 20 000 a value of 2 may represent an income threshold between 20 000 and 40 000 a value of 3 may represent an income threshold between 40 000 and 70 000 and a value of 4 may represent income thresholds exceeding 70 000. As such the data retriever may resolve i.e. translate any data received from the warehouse in for example an income column to the appropriate income threshold after for example retrieving entries corresponding to a particular value of 1 to 4. Thus for example if the data analysis instructions request only threshold incomes between 20 000 and 40 000 then in this example the data retriever will generate SQL query instructions using the associated value 2 which is understood by the target data warehouse as a valid query input term.

In the illustrated example the scheduler can be structured to periodically and or aperiodically copy some or all of the data that is related to the data analysis instructions and or building block statistics from one or more data warehouses to the memory . Thus while the preceding examples illustrate the data retriever acquiring data from the data warehouses in response to receiving data analysis instructions the relevant data warehouse information e.g. one or more parameters attributes statistics and or formatting instructions may already be stored in the memory as a result of a retrieval occurring in the prior periodic aperiodic and or manual data acquisition invoked by the scheduler . Thus it may not be necessary to query the data warehouse s in response to a given instruction set .

As discussed above data warehouses may experience periods of heavy use such as during the Super Bowl or Olympic Games when a large portion of a country may be watching a significant event s . The scheduler may retrieve relevant data from the data warehouse during periods when such heavy use is not likely to occur e.g. to replicate relevant portions of the database thereby ensuring faster query response times due to less burdened data warehouse processor s . Similarly data warehouse activity may be lower during the early morning hours. Thus the scheduler may be configured to acquire e.g. replicate one or more portion s of the data warehouses every day for example at 2 00 AM.

After data extraction from one or more data warehouses and storage to memory is complete the data warehouse optimizer may invoke the analyzer to process the data in view of the data analysis instructions . Rather than invoke data analysis via SQL commands instructions to be performed by one or more processors of the data warehouse s data analysis may be performed by the data warehouse optimizer . The optimizer may be programmed in any desired computer language. Persons of ordinary skill in the art will appreciate that Java programs are platform independent and may execute much faster than other programs implemented with SQL scripts. Therefore Java is particularly well suited for implementing some or all of the optimizer .

The data warehouse optimizer of the illustrated example is particularly well suited for business intelligence BI reporting applications. The optimizer of the illustrated example is able to perform statistical calculations directly in the database s of the data warehouse s and or on the data in the memory . SQL based approaches become increasingly inefficient and cumbersome when the reporting requirements of the data analysis instructions become more complex and the data sets of the database s are large. Unlike simple SQL extract commands realized by use of the data warehouse optimizer SQL based calculations typically require multi pass SQL and temporary tables that perform relatively slowly. Additionally because the data extracted from the data warehouses is focused on a client s particular objectives as determined by the data analysis instructions subsequent data processing of that data by the data warehouse optimizer executes faster because there is less non relevant data to sort through.

The analyzer of the illustrated example begins data analysis by processing building block statistics also referred to herein as primary statistics . Generally speaking the primary building block statistics may include one or more calculations based on data directly available from the data warehouse s . On the other hand composite statistics also referred to herein as secondary statistics may be calculated based on in part results obtained from the primary statistics and or additional data from the data warehouse s . The building block statistics may be generated by a multi phase process. For instance one or more preliminary phases of grouping and organization may make subsequent composite statistical calculations possible. For example building block statistics may include but are not limited to a sum of viewers watching a particular broadcast program a histogram of broadcast programming viewership nationwide an average viewership of broadcast programming by state etc. As discussed above while the examples illustrated herein are particular to broadcast programming and or viewership the systems methods and apparatus described herein may apply without limitation to any type of data warehousing subject matter. The building block statistics may also include categorization of discrete buckets of information and one or more subgroups contained therein. For example a bucket of type demographic may be calculated from the collected data. For any particular data sample size such as a single day multiple days weeks and or months the demographic bucket may contain different demographic subgroups. For instance a data sample during a weekend may include a demographic bucket having a relatively large percentage of adult males watching television programs during afternoon hours. As another example a data sample during weekdays may include a demographic bucket having a relatively large percentage of women of ages 40 60 watching television programs during afternoon hours.

Metadata also allows the data warehouse optimizer to determine which data to obtain from a data warehouse . In some examples the metadata contains relationships between facts and dimensions of a star schema. Such relationships permit the SQL generator of the example data retriever to generate appropriate SQL based extraction commands. In another example the data warehouse optimizer via the analyzer examines the composite statistics generated by the data analysis instructions . Furthermore the metadata may determine based on requested composite statistics which building block statistics are needed to calculate the composite statistics.

Composite statistics on the other hand may employ some or all of the building block statistics. Such composite statistics may be calculated by the analyzer of the illustrated example during one or more processing phases subsequent to the building block phase s . For example a composite statistic may include determining a percentage of women of ages 40 60 watching television during the weekday that are in an income threshold of 70 000 or more. In this example the composite statistic is based on the block statistics of 1 women aged 40 60 and 2 women with an income of 70 k or more. In other examples a composite statistic may include determining the relative percentage viewership for football versus Olympic Games watched by the adult males during a given weekend. Such a composite statistic may be based on one or more building block statistics

The report generator of the illustrated example utilizes report formatting parameters specified in the data analysis instructions and or default parameters to provide the client with processed data results. Reports may be provided in one or more formats including but not limited to tab delimited files spreadsheets graphs histograms pie charts and or trend analysis curves. The report generator of the illustrated example may additionally or alternatively invoke a web server of the communication interface to generate such report information in a web browser viewable format.

Flowcharts representative of example machine readable instructions that may be executed to implement the example data warehouse optimizer of and or are shown in . In these examples the machine readable instructions represented by each flowchart may comprise one or more programs for execution by a a processor such as the processor of b a controller and or c any other suitable device. The one or more programs may be embodied in software stored on a tangible medium such as for example the memory see but persons of ordinary skill in the art will readily appreciate that the entire program or programs and or portions thereof could alternatively be executed by a device other than the processors and or embodied in firmware or dedicated hardware e.g. implemented using an application specific integrated circuit ASIC a programmable logic device PLD a field programmable logic device FPLD discrete logic etc. . For example the processor the I O controller the memory controller and or the network interface could be implemented using any combination of software hardware and or firmware. Also some or all of the blocks represented by the flowcharts of may be implemented manually. Further although the example machine readable instructions are described with reference to the flowcharts illustrated in persons of ordinary skill in the art will readily appreciate that many other techniques for implementing the example methods and apparatus described herein may alternatively be used. For example with reference to the flowcharts illustrated in the order of execution of the blocks may be changed and or some of the blocks described may be changed eliminated combined and or subdivided into multiple blocks.

Referring to the communication interface of the data warehouse optimizer may receive analysis instructions in the form of for example a text file binary file XML file or other instruction format block . If the analysis instructions require data from one or more data warehouse s block then the SQL generator and data retriever of the data warehouse optimizer acquire relevant data from the warehouse s block as discussed below in view of . If the analysis instructions require only locally stored data e.g. data previously retrieved from the warehouse s by the scheduler block then the analyzer of the data warehouse optimizer processes the data stored in the local memory block .

If no analysis instructions are received by the data warehouse optimizer block then the scheduler of the data warehouse optimizer determines if a scheduled acquisition time has been reached block . As discussed above in examples where the data warehouse s are implemented in whole or in part the scheduler may be configured to query and acquire a copy of any new data found in the relevant portion s of the warehouse s each day at 2 00 AM block . If an acquisition time has not occurred block control returns to block . If the acquisition time has occurred block a request for the corresponding relevant data is invoked block .

Returning to block after data has been processed pursuant to the analysis instructions block as discussed further in view of the report generator generates a report for the client s block . Control then returns to block .

As discussed above the composite statistics may be calculated in part by using earlier calculated building block statistics. The analyzer processes such composite statistics in view of the target parameters and or previously calculated building block statistic results block . Much like the building block statistics the composite statistics may be calculated in one or more batches and or groupings. Upon completion of any one particular composite statistical instruction the analyzer determines if the analysis instructions include additional composite statistical instructions block . If more composite statistical instructions are to be calculated process control returns to block .

Employing the data warehouse optimizer of the illustrated example allows a highly scalable alternative to traditional BI reporting methods that perform complex statistical calculations sorting and or grouping in a SQL based manner. Data warehouses are typically expensive monolithic servers that require significant expense to upgrade. In light of the above disclosed approach to data retrieval grouping and statistical calculations less expensive PCs may be employed in a scalable manner to generate client reports much faster than prior techniques. Persons of ordinary skill in the art will appreciate that other programming languages may be used to implement all or part of the data warehouse optimizer . Such programming languages may include but are not limited to ASNI C C and or C .

In order to more efficiently store and access data obtained from one or more warehouses the example system may further be provided with a data formatter as shown in . An example data formatter may be implemented as a part of the data retriever of and or operate as a separate module of the data warehouse optimizer . Without limitation the example data formatter may be completely separate from the data warehouse optimizer and or execute data formatting techniques on data warehouse information before storing it to the memory .

The example data formatter of includes a communication interface or may share the communication interface of a scheduler which may be the scheduler of a data warehouse extractor an organizer a compression engine and a memory . The memory may be external to the example data formatter may access the example memory shown in and or may be implemented by the memory .

The communication interface operates in a manner similar to that of the communication interface of . For example the communication interface enables communication between the data formatter and one or more data warehouses such as the warehouses shown in . Communication may occur via network connections that employ Ethernet communication protocols IEEE 802.11 Wi Fi Bluetooth 900 MHz 1.6 GHz and or mobile communications protocols e.g. CDMA TDMA GSM AMPS EDGE etc. . Additionally or alternatively communication to from the example data formatter may occur via direct connections that employ the universal serial bus USB communication protocol and or the FireWire communication protocol i.e. IEEE 1394 . Data received from the data warehouses by the communication interface may be sent to from any one of the scheduler data warehouse extractor the organizer the compression engine and or the memory .

Data stored in a data warehouse may take one or more forms including offline operational databases offline data warehouses real time data warehouses and or integrated data warehouses. Data sources of the data warehouses may refer to any electronic repository of information and may include mainframe databases e.g. IBMS DB2 VSAM ISAM Adabas etc. client server databases e.g. Oracle Informix SQL Server etc. and or PC databases e.g. Microsoft Access . Data warehouses typically store data that is grouped together by subject areas which may reflect the general usage of the data e.g. customers products finances etc. . Such grouping may include use of a dimensional approach in which information is stored as facts which may be numeric or textual data specific to transactions and or events. Additionally or alternatively dimensions e.g. structural schema elements of a database warehouse may contain reference information that allows transactions to be classified in different ways. For example a sales transaction may be broken up into facts including a number of product s ordered and the price s paid. Additionally dimensions may include other factors such as sale date customer information product details geographic location of the sale and which salesperson made the sale.

While the data warehouse optimizer and the data formatter may operate with any database schema a star schema is discussed below for illustrative purposes. The star schema includes a single fact table having a compound primary key e.g. FL Viewership Jun. 20 2006 as shown in . The fact table contains quantitative or factual data about a subject of interest for example a business and or other organization. Each of the different keys e.g. ProgramID and or Household of of a fact table includes a corresponding dimension table which may include additional columns of facts and or different attributes of the example business.

The communication interface may be invoked by the scheduler on a periodic aperiodic and or predetermined basis to connect to one or more data warehouses. Many data warehouses contain sensitive and or private data. Thus such warehouses may require authentication before access and or extraction of the data contained therein. Authentication between the data formatter and a data warehouse may include but is not limited to secure sockets layer SSL digital certificates password protection encryption and or public key cryptography.

Once the data formatter connects to one or more particular data warehouse s the data warehouse extractor constructs one or more query commands such as SQL based extraction commands to obtain data from the data warehouse s . The extraction commands from the data warehouse extractor typically operate in a substantially non discriminatory manner and acquire all data from a time period of interest e.g. a particular day from multiple days from a particular week and or from any other timeframe . Without limitation the data warehouse extractor may construct extraction commands in a more discriminating manner which may require SQL based extraction commands of greater complexity. For example the data warehouse extractor may review and or parse all or part of the data analysis instructions to obtain specific parameters that should be extracted from the data warehouse s . Data extracted from the data warehouses may be saved in the memory for later organization and or organization may occur in real time during the data extraction process.

The organizer creates a hierarchical directory file path structure based on the structure domain specific details of the data warehouse s from which the data was obtained. For example in a star schema configuration for the data warehouses every dimension is modeled as a directory. As described above the dimension s may be one or more structural schema elements of a database and or warehouse and each dimension may have one or more columns of data. A dimension for products for example may include columns relating to product identification product cost product size etc. Each dimension directory may contain a number of separate directories for each column of the dimension. Generally speaking the organizer may create a first hierarchical directly file path associated with the highest e.g. most broad most general abstraction of the data warehouse s . Further the organizer may create a second hierarchical directory file path associated with one or more abstraction s of the data warehouse s that are more narrow than that of the first hierarchical directory file path. Any number of additional hierarchical directory file path s may be created by the example organizer to accommodate one or more data warehouse.

Under each column of a given dimension is a first binary file containing mappings of dimension keys to identifier ID data e.g. id.bin . Each key e.g. such as the one or more keys of a fact table that result in a dimension table is a primary key of the dimension and the ID is a numeric that represents a value of that column. Each column also includes a second binary file containing mappings of ID data to values e.g. valuemap.bin . Using both of these files allows derivation e.g. via a query based on the data analysis instructions of an actual value of a column for a certain key by sequentially mapping through the file mapping hierarchy in a sequential manner. For example if a fact table included a key named Household and the household dimension table included a key named Income then associated values for a query may be determined by following a logical hierarchical directory path of DIM Household Income to retrieve corresponding values e.g. value11.bin in . Navigation of one or more hierarchical directory paths described herein further reduces and or eliminates a need for SQL commands when accessing data. As a result data access may be simplified via directory navigation using for example a web browser kiosk and or a directory tree.

Upon completion of the hierarchical directory structures by the organizer the compression engine may compress all of the binary files to save storage space. Compression techniques may include but are not limited to shrinking methods reducing methods imploding methods and or tokenizing methods. A ZIP file format may be employed to take advantage of its open format and prolific availability. The compression engine may also compress the whole hierarchical directory into a single ZIP file with a date key filename such as a Julian date code illustrated in below.

The example data formatter creates the hierarchical directory path in a manner that reflects the structure of the data warehouse which in the illustrated example of is a star structure. In particular the organizer of the data formatter creates a fact table path a ProgramID dimension table path and a Household dimension table path . As discussed above each of the corresponding directories includes an associated binary file column containing mapping and or data information. The example hierarchical directory path also includes individual directory tag paths for the ProgramID and Household dimension tables . For example upon navigating to one of the highest dimension table paths e.g. or of the directory path the corresponding binary file of column may contain mapping information to illustrate additional paths to which navigation may be performed. Thus navigation to NMR DIM ProgramID which is associated with the binary file e.g. a dimension mapping file value1.bin provides mapping information to allow navigation to one or more of the binary files of the directory tag paths . To that end directory navigation may include any number of nested directory paths each one sequentially accessed to provide additional mapping information e.g. one or more navigation options and or data e.g. viewership information . In the illustrated example of a first hierarchical directory file path includes the fact table path a second hierarchical directory file path includes either the dimension table path NMR DIM ProgramID or NMR DIM Household and a third hierarchical directory file path may include any one of the directory tag paths . When the organizer completes the hierarchical directory path the compression engine may save the directory as a ZIP file .

The data warehouse extractor of the illustrated example constructs query commands block for the target data warehouse such as SQL based commands to retrieve data. For example the data warehouse extractor may construct simple SQL based data extraction commands having minimal qualification constraints such as requesting all data for a particular hour range of hours day range of days week etc. The query commands are then executed block and data returned from the data warehouse s is stored to the memory block .

The organizer arranges the received data block into one or more hierarchical directory path s which reflect domain specific details of the originating data warehouse s . As discussed above while the illustrated examples employ a star schema format the systems and methods described herein are not limited thereto and may accommodate any database schema. Upon completion of the hierarchical directory path organization block the compression engine may compress the directory into for example a ZIP file block . Control then returns to block .

The example data warehouse optimizer of is substantially the same as the example data warehouse optimizer of except for the addition of the data formatter within the data retriever . Similar components are identified in with similar labels from and will not be discussed further.

The processor of is coupled to a chipset which includes a memory controller and an input output I O controller . As is well known a chipset typically provides I O and memory management functions as well as a plurality of general purpose and or special purpose registers timers etc. that are accessible or used by one or more processors coupled to the chipset . The memory controller performs functions that enable the processor or processors if there are multiple processors to access a system memory and a mass storage memory .

The system memory may include any desired type of volatile and or non volatile memory such as for example static random access memory SRAM dynamic random access memory DRAM flash memory read only memory ROM etc. The mass storage memory may include any desired type of mass storage device including hard disk drives optical drives tape storage devices etc.

The I O controller performs functions that enable the processor to communicate with peripheral input output I O devices and and a network interface via an I O bus . The I O devices and may be any desired type of I O device such as for example a keyboard a video display or monitor a mouse etc. The network interface may be for example an Ethernet device an asynchronous transfer mode ATM device an 802.11 device a digital subscriber line DSL modem a cable modem a cellular modem etc. that enables the processor system to communicate with another processor system.

While the memory controller and the I O controller are depicted in as separate functional blocks within the chipset the functions performed by these blocks may be integrated within a single semiconductor circuit or may be implemented using two or more separate integrated circuits.

Although certain methods apparatus systems and articles of manufacture have been described herein the scope of coverage of this patent is not limited thereto. To the contrary this patent covers all methods apparatus systems and articles of manufacture fairly falling within the scope of the appended claims either literally or under the doctrine of equivalents.

