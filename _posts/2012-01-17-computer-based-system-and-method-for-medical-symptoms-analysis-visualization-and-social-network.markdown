---

title: Computer based system and method for medical symptoms analysis, visualization and social network
abstract: A computer system and related method for analysis of medical symptoms on a body of a living being is provided. The system comprises a first portion of computer readable medium which stores digital representation of a plurality of tissue layers in the body. The system also includes a processor unit and a second portion of computer readable medium. The second portion of the computer readable medium stores instructions executable by the processor unit to perform the steps of displaying at least one tissue layer from the plurality of the tissue layers on a display device, receiving a first input indicating a locale on the displayed at least one tissue layer, receiving a second input associating a medical symptom description to the indicated locale, and including information about the medical symptom description and the associated locale in the digital representation of the body. Related methods are also provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08963914&OS=08963914&RS=08963914
owner: 
number: 08963914
owner_city: 
owner_country: 
publication_date: 20120117
---
The present invention claims priority to the U.S. Provisional Application No. 61 433 947 titled GATHERING VISUALIZING AND ANALYZING PATIENT AND DOCTOR INPUT ON A 3D AVATAR TO IMPROVE QUALITY OF MEDICAL CARE EMPOWER PATIENTS AND FORGE NEW SOCIAL BONDS filed Jan. 18 2011 which is herein incorporated by reference.

The present invention is generally related to techniques for analysis of medical conditions. More particularly it provides a computer based system and method for recording medical symptoms and facilitates analysis of the recorded information to provide variety of facilities.

As the field medicine grows more complex the task of gathering relevant patient symptom data faces several challenges. The amount and dimensionality of medical data generated by hospitals continues to grow. Advances in computing technologies can now facilitate the collection and storage of large quantities of medical data which can be advantageously used for treatments that are tailored to individuals.

As dimensionality grows the granularity of medicine may increase. It may be possible to describe medical conditions more precisely and to also formulate more precise treatment plans. If properly used high directionality may improve healthcare by reducing the chances of mis diagnosis. On the other hand it may be disastrous if health workers such as doctors and nurses assign a treatment based on irrelevant artifacts of the data. Part of the challenge health workers face is finding appropriate ways to infer important medical variables such as a living being s medical state an explanation for the state i.e. what actions led to that state and a course of treatment.

However in some senses patients also face tremendous challenges in today s medical landscape one challenge being communicating information in a format that can be understood and used by a health worker. This may be difficult because the information may describe something that is difficult for the worker to observe such a living being s perceived symptoms feelings of symptoms . It may additionally be difficult because precise accurate communication may involve the patient understanding complex medical terminology such as terminology describing anatomy or medical conditions or medical treatment procedures.

Another challenge that also plagues the medical field can be summarized by the notion that people are only human. That is human errors on the part of at patient or a health worker may lead to undesirable outcomes. One difficulty a patient might have is memory they may for example forget the details of past symptoms or may mis remember them. A corresponding error on the side of a health worker could be misplacing a portion of person s medical file or brushing over important details while scanner a patient s file. Such errors may certainly carry the potential to do lasting damage to a patient. A failure to consider a representative and accurate subset of a person s medical symptoms may lead the path towards misdiagnosis.

An additional challenge is that patients may often feel alone or isolated by the growing complexity of medicine. One may for instance feel powerless and weak in the company of health workers who may seem extraordinarily knowledgeable. The patient representative may feel pressured to put faith in health workers ability for providing quality medical advice. However empowered patient representatives who take an active role in the medical process may actually contribute to a higher quality diagnosis and treatment. One struggle in healthcare is thus to empower patient representatives.

A further challenge that exists for many patients is developing an understanding of their own body their strengths weakness and limitations from a medical perspective. As medicine becomes increasingly complex and as medical procedures and tests become harder for the general public to understand and interpret a patient may have difficulty assimilating information about his symptoms. Thus over time he may fail to recognize detrimental trends habits and life style choices. This is remarkable because vigilance is a one key for preventing early onset of disease. Staying constantly watchful alert and empowered patients who learn to observe monitor and track patterns in their behavior have the power to learn from mistakes and improve their medical condition over time. Alas it seems too often that medical knowledge is used to treat illness which could have been prevented had the patient realistically understood the condition of his her body and acted in a manner to improve it. Thus one challenge in health care is educating patients about their own medical symptoms helping them get in touch with their bodies so that they can make more responsible lifestyle choices.

To help a patient live a better life it might not simply be enough for a health worker to deduce a medical cause and identify a treatment plan. One additional challenge is arming patients with logical and social reinforcement that may assist him her in living a healthier life.

Accordingly the present invention provides computer based techniques for improved medical symptoms analysis that can address one or more challenges described above and others.

It is an object of the present invention to provide computer based techniques for analysis of medical conditions. More specifically the present invention provides a computer based system and method for analysis visualization and social networking for medical conditions.

In a specific embodiment the present invention provides a computer system for analysis of medical symptoms on a body of a living being. The system comprises a first portion of computer readable medium which stores a digital representation of the body. The digital representation of the body comprises representation of a plurality of tissue layers at a plurality of depths in the body respectively. Each of the plurality of the tissue layers can be a three dimensional representation. The system also comprises a processor unit and a second portion of computer readable medium that stores instructions executable by the processor unit. The instructions are executable to perform the steps of displaying at least one tissue layer from the plurality of the tissue layers on a display device receiving a first input indicating a locale on at least one displayed tissue layer receiving a second input associating a medical symptom description to the indicated locale and including information about the medical symptom description and the associated locale in the digital representation of the body. In alternative specific embodiments the related methods are also provided.

Various benefits and or advantages may be obtained from the present invention. For example the present invention can facilitate an easy to use process using readily available computer technologies for recordation of medical symptoms over a period of time. Moreover the present invention can facilitate variety of analyses on the recorded information. Depending upon the embodiment the analyses can facilitate variety of applications. For example the analysis can facilitate identification of subjects with similar medical conditions which can further facilitate forming a social network among them. As another example the social network can be used to assist in medical diagnosis.

The invention can facilitate providing users a better understanding of the body. Notably this may not necessitate an in depth study of biology on users part. The interactivity of the data collection can facilitate creating a link between the scientific practice of medicine and an intuitive grasp of health. While the technicalities of medical practice can be too detailed for users to incorporate into their daily understanding embodiments of the present invention can permit them to incorporate visualization symptom data and various results of symptom analysis into their habitual conception of health. This can contribute to a greater attention on medicine as a personal user focused science. Embodiments of the invention can contribute to higher user awareness and connectivity to health.

Embodiments of the present invention may contribute to higher user awareness and connectivity to health thus alleviating a degree of the isolation patients representatives feel in the healthcare system. Thus embodiments may include tools which may help people group together socially to accomplish a common goal of managing and improving health.

It can also aid representatives and patients alike in maintaining adequate and extensive records identifying trends and a host of other functions that are often either exaggerated or neglected through typical human memory of symptoms.

These and other various objects features advantages and benefits of the present invention can be more fully appreciated with reference to the detailed description and accompanying drawings that follow.

The following detailed description of the invention refers at various places to the accompanying drawings and specific environments applications platforms examples computer screenshots and implementations. The detailed description is provided for thorough understanding of the present invention and is illustrative rather than limiting.

The present invention can be generally understood as a system and method for interactively collecting storing and analyzing medical data from a user via computer interpretable instructions computer program . Medical data can be understood as any data which may correlate with the health of a living being such as symptom data. In a specific embodiment of the present invention interactivity may be understood to occur via a user interface which is the point where interaction between humans and machines occurs. It can be understood as hardware and software components that provide a means of input and output allowing the user to manipulate a system and allowing the system to indicate the effects of the user s manipulation respectively.

The processor may also communicate with input devices via the system bus . The input device s may include any peripherals by which a user can provide data and control signals to the computer. These signals may be single or multi modal where modes of input are audio video mechanical input etc. Examples of input devices include computer mouse computer stylus touch screen keyboard camera video camera microphone motion sensors accelerometers natural input devices such as the Microsoft Kinect or the Microsoft Surface which may allow users to carry out relatively natural motions movements or gestures that may quickly control the computer physical device representing a living being where regions of the device are sensitive to touch and additional input devices some of which may combine multiple types of user input.

Additionally the processor may communicate with output devices via the bus . Output devices are used to transmit signals from the processor and may be used to signal the user.

Additionally the processor may communicate with a network interface via the bus . The network interface may facilitate the transfer of information across an informational network which will be described in more detail below.

In the specific embodiment the user can input medical symptom data via Graphical User Interface GUI elements which can be understood as graphical icons and visual indicators shown on a display device that a user may employ to interact with a computer system. For instance the user can enter text describing a symptom via a GUI text box. To associate this medical symptom with a 3D locale on a Body Layer additional user input may be handled in a manner discussed below . Then the specific embodiment may create a computer object can with data attributes to store both the symptom data and the location information can be appended to the DBR to save the information. In general many types of symptom data can be tagged including textual audio visual and numeric data. In an additional embodiment it may be possible to tag any time of symptom data that can be represented in a computer readable format.

In the context of a specific embodiment the interactivity may be provided via a process of a user providing an input signal to the computer via an input device the processor interpreting a digital representation of the signal the processor modifying a state in memory via the bus and the processor outputting a signal which gets communicated to the user via an output device .

The present invention may be understood in the general context of a series of computer executable instructions such as program being executed by a computer. Such computer instructions can include tasks that involve creating or modifying various types of data structures. These tasks may often be implemented on a single computer yet they may also be performed in distributed computing environments where a network links together remote computational devices.

The present invention may be operational with numerous other computing system environments. In various embodiments the precise location of storage and execution of the computer executable instructions may vary. For example in one alternative the end user computers may feature minimal processing and memory storage facilities and the server device s may perform the bulk of information storage and processing. In one of such embodiments the end user computer can be understood as kiosk which provides a means for a user to provide input and observe output from one or more servers. In an alternative embodiment end user devices may do more processing and data storage and examples of such devices may include smart phone tablet or a PC end user device.

A specific embodiment of the present invention uses a computer object called a Digital Body Representation DBR to store a living being s health medical data in computer memory . The specific embodiment uses data within the DBR to assist in gathering input from a user displaying information to a user via output devices analyzing the user s medical symptoms.

In the present embodiment medical health data of an individual may be added to the DBR via typical user interfaces and means of input for end user computers . For example in some configurations of a computer system an individual may enter some medical data through a command line user interface or via a graphical user interface GUI elements such as text boxes or menus that are shown on a display device.

Additionally the DBR of the specific embodiment contains two or more Body Layers which may be advantageous for facilitating user input. Body Layers include 3D visualization data for a subset of body tissues which can be used to display the tissues on a device to assist in the gathering displaying and analyzing medical information. For clarity the three dimensions 3D may be understood in terms of three dimensions in positional space such as along 3 coordinate axes e.g. x y z or up down left right forward backward .

Body Layers in the specific embodiment include bone layer muscle layer and skin layer however Body Layers are not necessarily limited to these three layers. Each Body Layer may include any subset of tissues in the body. Thus Body Layers in a specific embodiment may include the tissues grouped by tissue type e.g. epithelial layer endothelial layer innervated tissue layer etc. function e.g. digestion layer respiration layer nervous system layer etc. however the invention is not limiting in the types of tissues that may be grouped together to form Body Layers. Preferably at least some portion of any two layers in the DBR can represent tissues at different depths from the surface of the body.

As an aside before disclosing in detail methods for interacting with DBRs the reader should note that the invention allows the DBR to be represented in computer memory in various ways. For example the specific embodiment implements a data structure for a DBR via a nested object oriented paradigm where computer objects consist of data fields which may reference other objects computer readable data byte code representations of numerical data audio video and other data or other information. Thus a DBR of a specific living being is an instance of an object as are the Body Layers that it references. Objects in the specific embodiment are mutable which means that data may be modified or appended to them.

In the specific embodiment the structural information is contained in a 3D model including structural geometric data that defines the shape of the Body Layer in 3D space. For example in a specific embodiment geometric data may include a collection of 3D vertices points in 3D space connected by various mathematical entities such as triangles lines curved surfaces etc. . Thus geometric data may provide a mathematical representation of 3D shape which may be illustrated as a wire frame consisting of connected vertices .

In the specific embodiment texture data can be understood as information that can be applied to the 3D model in order to shade its appearance e.g. to texture a wireframe . In one embodiment texture data can take the form of a 2D image such as a bit map image where patterns and colors on the image contain texturing information for the 3D model.

In the specific embodiment computer graphics software applies the texture data to the 3D model creating a textured 3D Body Layer in a simulated virtual 3D scene a computer object that includes data describing the position and rotation of 3D objects. Additionally the computer graphics software in the specific embodiment processes the data contained within the virtual 3D scene to create output signals that can be visualized by an end user on a display device a type of output device which provides visual feedback to a user such as a computer monitor screen television printer 2D 3D projector etc. . In the specific embodiment the 3D scene can be understood as including an active and an inactive or hidden portion wherein the active portion contains 3D information which can be processed and outputted as a signal to a display device for viewing whereas 3D information contained in an inactive or hidden portion may not be processed and outputted for visual display. In the specific embodiment 3D information may be communicated between active and inactive components of a 3D scene thus at some times a 3D object may be displayed and at other times hidden based on which portion it is associated with.

In a specific embodiment the computer graphics software uses a technique called texture wrapping to apply Texture data such as a 2D image to a 3D model . Conceptually the process of texture wrapping is similar to wrapping patterned paper around a plain generic box. The plain box is similar to a 3D model in that it contains geometric information but may lack detail and texture and like the texture image the patterned paper contains color and texture information but is flat and 2D lacking the geometrical information of the box.

In the specific embodiment graphics software such as Open GL distributed by Khronos Group of Beaverton Oreg. uses a pre defined mapping from geometrical units such as vertexes in the 3D model to 2D coordinates on the Texture to wrap textures around the 3D model. Then based on the mapping the texture information e.g. pixel data is stretched around the surface of the 3D model.

In a specific embodiment video game engines contribute a subset of the functionality of computer graphics routines . Video Game engines such as Unity 3D provided by Unity Technologies of San Francisco Calif. can be understood as a collection of computer executable routines which provide application programming interface API for displaying and interacting with 3D models. In the specific embodiment the processor uses game engine routines process information contained from the 3D virtual scene into signals that can be interpreted by display devices to portray a visual representation of the 3D virtual scene . For example a game engine may implement the process of rendering by projecting 3D data from the virtual scene onto a 2D surface which can be visualized by a computer screen. Alternative embodiments such as embodiments using alternative display devices may utilize different graphics routines to suit the particular configuration of the hardware components.

Visualizations of 3D Body Layers can be used to provide interactive feedback for user input in ways that may have advantages in certain scenarios. For instance providing such input may induce a patient user to pause and pay attention to how his her body feels. It may encourage introspection and lead to the making of a personal appraisal of the medical causes which may be a way to empower patients. Additionally such techniques may provide an avenue for an individual to describe medical symptoms which may be otherwise difficult to express. Furthermore the methods outlined below may store symptom data in a regular way with a format that may be conducive to later analysis.

Many symptoms that a person may experience have a spatial component which may be difficult to describe or remember precisely. For example some medical symptoms such as swelling rashes lacerations itching numbness occur over specific regions of the body at specific depths in different tissues. Additionally symptoms may occur through a range of motion such as when a user does an action. For example one specific person may experience tenderness in the tendons around the knee when he raises a leg as in going up stairs but not while walking on a flat surface. Symptom data associated with actions is more specific and may provide the detail required for a good medical diagnosis. Visual input via 3D Body Layers may allow users to enter data about location and movement in predefined sequence of steps resulting in data which can be advantageous realistic regularized and useful for a human trying to get in touch with his body.

Additionally in the specific embodiment symptom data may be represented visually and symbolically on or near the surface of the Body Layer. These symptom data may give the layer a painted appearance where portions of the layer may be colored textured to represent medical information symbolically. For example a painted region on the body of one color texture e.g. blue on the layer may represent the prevalence of a first symptom such as itch over that region however a painted region with different color texture e.g. red may represent a different symptom such as swelling .

In a specific embodiment the process for associating symptom data with specific locales on the 3D Body Layers is called tagging and may involve a user selecting one or more Body Layers indicating a locale indicating a symptom description and appending tagged symptom data to the DBR.

In a specific embodiment of the present invention user input may be interpreted to change which Body Layers are displayed and visible to the user. Recall that the virtual 3D scene defines which 3D objects may be shown in a display device. In the specific embodiment Body Layers can be shown or hidden by changing the information that is contained within the 3D scene. That is removing the 3D model representing the Body Layer s structure from the scene can hide a Body Layer that is visible on the display. Conversely a Body Layer that was previously hidden can be brought back into display by adding its 3D model to the virtual scene. In the specific embodiment user input entered via a Graphical User Interface GUI element such as a menu can change which layers are displayed. The menu allows a user to communicate information about which Body Layers to display and which Body Layers to hide to the processor . Then the processor can alter objects in memory such as the virtual 3D scene in a manner that complies with the user s intent.

In an alternative embodiment the user may partially hide one or more Body Layers by changing the opacity with which they are displayed. For example a user may set the opacity of a skin and muscle layer to a low degree for translucence in order to see an underlying bone layer.

In the specific embodiment flow of steps begins with the selection of one or more Body Layers to be displayed and the specification of a symptom format. The user may for example use GUI elements to indicate which layer s should be tagged as well as whether the symptom is a textual description or a painted symbolic description an audio file etc. In a specific embodiment of the present invention location tagged audio data may be converted into textual data using voice recognition software routines.

In the specific embodiment upon selecting layers such as from a GUI element such as a menu the non selected layers are hidden and the selected layers are displayed on the display device.

In the specific embodiment upon the user indicating one or more layers and a symptom description such as a textual description audio description visual description or a symbolic visual pattern representing a symptom the user may indicate a query locale in the virtual 3D space via methods described below . The query locale is a 3D location close to a portion of a displayed Body Layer. The query locale is used to search the 3D models of the displayed layers to find the geometrical units such as vertexes close to the query locale. Then a data storage object such as a texture file may be created or modified to associate these geometrical units locale data with symptom data. In alternative embodiments the data storage object may have various types and constructions but may share a common ability to associate locale data with symptom data in memory . An example of other such objects include entries in a relational database.

In the specific embodiment the query locale may be used to modify texture objects to create interactive visual symptom tagging of symbolic data painting . As previously described painting a symptom may cause the color of the layer at a particular locale on to change in order to reflect a system symbolically. In the present embodiment this occurs via determining and modifying the region of the texture image that is responsible for the texturing the layer near the query locale. As illustrated in the specific embodiment of a portion of the muscle layer corresponding to the calves has been shaded with a texture which is wrapped onto the model using a pre defined mapping in the specific embodiment. The first step requires the user to indicate such as via a GUI or other user interface the symptom that he she desires to indicate such as swelling itching burning etc. . Next the user indicates a query locale which is converted into a locale on the 3D Body Layer by methods described below which becomes the location where the painting will occur. Then texture coordinates that map to the locale can be found by using the query locale to query the geometric data of the model to find close by vertices and subsequently looking up the texture coordinates for those vertices . Next the texture can be modified at these coordinates so that the body shows the painted symptom when the display is updated . Then the symptom data can be appended to the DBR. In the specific embodiment the texture image is copied and appended to the DBR each time the user indicates a symptom by painting. This way each time the user paints the new symptom data which is stored in the texture image gets appended to the DBR. In an alternative embodiment the texture image is processed after painting and the symptom data is converted into a categorical format which can be stored in an alternative data object from a texture image. In an additional alternative embodiment 

The process by which a user indicates a locale on the 3D Body Layer such as may vary based on specific hardware configurations such as the types of input peripherals that are used to gather user input.

In the specific embodiment a user inputs information to the computer via a pre defined set of gestures and body actions which can be recorded by the motion sensor and interpreted by a processor . Thus via the interpretation of gestures a user can signal the processor in various ways to indicate for instance a type of symptom that the user seeks to input or location tag .

In the specific embodiment a user s posture is determined using a pre defined set of algorithms that process the data collected by the motion sensor. The motion sensor in the specific embodiment can be understood as a camera that takes a series of photographs over a short period of time and uses techniques to identify parts of the images that change over time. For example the motion sensor can use various background subtraction schemes such as background averaging to detect motion. Then the 3D posture or the arrangement of the user s body parts in the real world is inferred . This learning can be understood as the processor forming a description in memory that describes how each limb in the body is oriented in the 3D space of the real world . Thus such a representation stores information that describes which parts of the body are close to each other and which parts are far.

In the specific embodiment the process for learning the posture of the user is implemented using techniques disclosed by A. Jain T. Thorm H. P. Seidel and C. Theobalt in MovieReshape Tracking and Reshaping of Humans in Videos which was published in the journal Association of Computing Machinery Transactions on Graphics Volume 29 number 5 in 2010. However alternative embodiments may use alternate algorithms to determine the user s position such as specialized computer vision algorithms or algorithms used to infer user position in the motion sensor called the Kinect or Xbox Kinect manufactured by Redmond Wash. based Microsoft Corporation.

The specific embodiment may interpret changes in the user s posture a gesture as a type of input when the gesture can be recognized. In other words the specific embodiment may respond to a gesture if the gesture can be identified among a set of pre defined gestures stored in computer memory . Thus a user may move his her body in a particular manner to communicate a particular intent to the processor. For instance some types of arm movements could indicate to the processor that the user wants to paint a location onto a 3D Body Layer while another gesture may indicate to the processor that the user wants to tag a descriptive symptom to a particular part of a 3D Body Layer.

In the specific embodiment after indicating the intent to tag some symptom data such as for painting data similar to or for tagging other data the processor uses information about the user s posture and gestures to select a 3D locale on a specific Body Layer. For example in the specific embodiment the user can indicate a locale by tapping on a particular part of his body to indicate a general area of a symptom and can subsequently indicate the Body Layer on which the user perceives the symptom by using a second gesture.

In the specific embodiment the process of calculating the location on the 3D Body Layer corresponding to the real life location of an area on the body that the user tapped involves the processor analyzing the posture of the user to determine which area from a pre defined list of areas on the user s real body is closest to the location of the tap . Then the specific embodiment uses a pre defined mapping to find the corresponding locale on the 3D Body Layer. For example the processor may first analyze the user s position as he taps on his body to recognize that he is tapping on the tip of his left elbow. Then the mapping can be queried to find the 3D location of the point in the virtual 3D scene that corresponds to the tip of the left elbow for a specific Body Layer.

In an additional embodiment user gestures may be used to specify a type of symptom to paint such as but not limited to swelling itching burning tingling laceration rashes tightness cramps indigestion. In a further additional embodiment user gestures may be used to change which Body Layers are displayed e.g. on the monitor .

In the specific embodiment what the user observes on screen is a rendering of a virtual 3D scene . For illustrative purposes the image on the screen can conceptualized as displaying the view that might be seen from a window positioned at a specific location in 3D world facing a portion of the virtual 3D scene . The view from the window can be described mathematically as the projection of mathematical information from the 3D scene onto the window.

As a user indicates a locale by clicking on a portion of the model indicated by an X the coordinates of the click can be mapped to a specific location on the window into the virtual 3D world. This specific location like the window has a definite position in the 3D virtual world. To identify a locale on the 3D Body Layer a ray can be projected from this specific location to find a locale on 3D Body Layer. Various algorithms may be used to determine where the ray intersects the 3D Body Layer. The specific embodiment uses algorithms packaged in a video game engine to do this calculation.

In the specific embodiment a user can indicate how symptoms change along a range of motion by repeatedly turning portions of the 3D Body Layer and entering symptom data for the layer in that position. In the specific embodiment when the user location tags a symptom the symptom data contains an additional attribute that stores information such the orientations and positions of the joints in the 3D model about the 3D Body Layer s position at the time of the tagging.

This method of location tagging can be used to indicate how symptoms apply along a range of motion. For example one specific embodiment of the present invention stores several 3D models for each Body Layer where each 3D model describes the structure of the layer when the body is in a particular posture. Thus one 3D model may show the musculature from a sitting position while another 3D model may store the info of the musculature from a standing position. However in a preferred embodiment the user can turn adjust manipulate portions of a 3D Body Layer such as moving the arm portion to change the position of the arm to indicate various postures in a range of motion and may append symptom data corresponding to a particular posture of the DBR. Thus a user can indicate symptoms along a range of motion by indicating symptoms along a range of postures.

The flow of begins when the user has indicated e.g. by way of GUI input an intent to indicate motion. Then the user repositions the displayed layer via a process for turning portions of the body to be described below to indicate a start position . From the start position a new data object representing a portion of the movement called a motion description object is appended to the DBR. Motion description objects may include sequential index information posture information values describing transforms of joints in the displayed layers and symptom data .

Every time user repositions the layer a new motion descriptor object is appended and the symptoms tagged are associated with the corresponding motion descriptor object. Then as long as the position is not changed the inputted data will be associated with the motion description object. However if the user repositions the displayed layers a new motion description object will be created with an incremented index now i 1 and new data about the joint transforms. Data that are subsequently indicated are associated with this second motion description object. This process may continue with additional positions and Motion description objects until the user indicates that the movement has been indicated fully e.g. via GUI . An object relating the motion description objects may be created to indicate that they all indicate steps along one movement. Additionally movement description objects may contain temporal data.

The process for turning a portion of a 3D Body Layer may have additional benefits besides assisting a user in storing symptom data along a range of motion. For example some positions of the 3D Body Layer might be hard to location tag when the 3D Body Layer is in certain positions e.g. if the Body Layer is showing body structures of a person standing up with legs together for it may be difficult to tag symptoms on the inside portion of the thigh. A process to use user input to change the orientation of limbs for example could help to reveal locales on the body which may need to be tagged.

Joints are defined in a hierarchical manner understood as parent child relationships. Thus in the specific embodiment a computer joint representing the wrist is associated with all polygons from the wrist region of the 3D model through to the finger regions. The computer joint for the wrist is also as in the human anatomical model dependent on the elbow joint which is associated with all polygons on the 3D model from the elbow region to the finger region.

In this specific embodiment the 3D representation of the layer includes individual joints such as that have defined locations in the simulated 3D space . The joints are ordered hierarchically so modifications in the rotation position of the parent joint modifies the rotation and position of the child joints e.g. spine moves elbow moves wrist. User input such as from a GUI menu which allows users to select a joint by name can be used to turn a parent joint causing associated geometrics of child joints to be transformed. Moving a joint induces a hierarchical transform .

Rotating a joint may cause these associated polygons to move. Additionally the hierarchical relationships between joints cause child joints to move in structured ways as parent joints move thus the polygons associated with child joints move as well. After updating the polygon positions the display may be updated. In an additional embodiment hidden layers are moved simultaneously with the visible layer s so that for example if a user changes which layer is displayed the posture remains constant.

In a further additional embodiment position data from a motion sensor can be used to modify the transforms of joints in the body causing the visual representation in the display to assume the same body posture as the user.

In specific embodiments the interactivity capabilities of the present invention may extend to using information that has been inputted into a DBR to assist a user in analyzing medical symptoms. Some types of analysis to be disclosed below include diagnosing of the medical condition that best explains the data in a DBR or finding DBRs which contain similar symptom data. However other methods of analysis may also process and display the processing output on the visual representation of the 3D Body Layers.

In a specific embodiment of the present invention the latter type of analysis can be understood in the context of using information in a DBR to compute a result the result symptom which can be displayed on the visual representation of the 3D Body Layers. Such result symptoms may be used to portray the symptom data in the DBR in a meaningful way that may help a user understand the manner in which symptoms are distributed on different locales on the body and how a person s symptom data changes over time. An example of an analysis method that computes a result symptom and displays it on the 3D representation of a Body Layer is a method that plays back the symptom data in the DBR so a user can watch the progression of symptoms through time on the Body Layer. A second analysis method that computes and displays a result symptom can be summarized as a merging method which takes a plurality of symptom data and displays it simultaneously on the Body Layers so that a user may for instance try to observe patterns where symptoms occur.

The user may customize certain attributes to regulate the types of data that will be played back. Such attributes may include which layer s will be displayed which specific symptoms will be used in the visualization the time range over which to display symptoms the rate of the playback etc.

Upon initiation of playback the system can query the DBR for symptom data sort the data by date and time and filter by user criteria . Then the filtered data may be loaded onto the model in a time dependent fashion. For example suppose the user indicates the desire to play back symptom data from a given time range at a given rate say 10 hours of data in 10 seconds. Then if the system updates the visual representation every second it may seek to load symptom data inputted over that time duration at 1 hour intervals. For each time point at which the processor seeks to update the display filtered data corresponding to that time will be used to update stores in memory such as a representation of the virtual 3D scene and update the visual representation . Alternatively the system may collate symptom data for each hour into a point snapshot for that interval using a variety of techniques such as maximum value average value etc. and associate the point snapshot with each second display.

Subsequently updating the visual representation with data from time points at regular intervals may create a flowing experience similar to watching a film. In one specific embodiment the rate of playback is 0 which allows users to step forward or backward through time manually. Further additional embodiments may include a subset of the following functionalities rotate or reposition the view during playback pause playback play backwards through time adjust rate of playback during play.

In certain embodiments it may be desirable to display a visual representation that combines data from one or more times and one or more Body Layers. For example this feature could be used to observe if symptoms predominantly occur in certain parts of the body. Another instance when this may be desirable would be if one wished to visualize merged data from multiple DBRs representing multiple people. A single visual representation could for example be used to see how painted data overlaps on different living beings who were administered the same treatment.

In a specific embodiment painted data taken from the same layer over a different times are merged by combining texture pixel data pixel by pixel in a repeated fashion. In an additional embodiment the pixel data are combined in an additive process where attributes such as intensity are used to create additive representations while merging. Additional techniques may be used to combine symptom data including various image filtering techniques.

In an alternative embodiment symptom data including painted data from multiple layers may be combined. Thus the result symptom may express data from multiple layers. One method to implement multi layer merging involves using rays to create a mapping between layer textures which may be stretched around differently shaped 3D models. For example a point on the inside of the plurality of layers is chosen and several rays are projected outwards in several directions. Locations where some of these rays intersect multiple layers may be used with corresponding texture mapping data to create a table that maps coordinates between textures of different Body Layers. Then a data combination function such as an additive calculation may be used. Once the data are combined a resulting texture can be displayed showing merged symptom data.

The user may customize some attributes to regulate the types of painted data that will be used to form the calendar result symptom attributes may include which layer s will be displayed which subset of symptoms will be used in the visualization the time range over which to display symptoms etc. The system may query the DBR for symptom data sort the data by date and time and filter by user criteria.

In the specific embodiment the system can access an object which contains model zone mapping data which indicates the spatial region corresponding to a physical portion of the body e.g. arm leg or quadrant etc. but does not necessarily reflect a grouping represented by the layers. For example with layers of bone skin and muscle some regions may include upper body and lower body or left hip left thigh left calf left heel etc. The model region mapping relates individual polygons in a model to a particular zone. Additionally since polygons in the model may be associated with texture coordinates it may be possible to map texture coordinates to regions.

In the specific embodiment the calendar takes the form of a 2D graph showing intensity versus time for a series of regions. To calculate intensity of a symptom at a given time in a given region textures from multiple layers may be parsed as described by the following sequence of steps. An embodiment utilizing the sequence of steps below may represent different symptoms as different colors on a texture file e.g. swelling may be indicated by a distinct color from itching .

In one specific embodiment every layer may be analyzed at times chosen by the user and inputted into the GUI. For each spatial coordinate in the texture file of the layer if the corresponding vertex is in the region chosen by the user the content of the texture file at that point will be analyzed. If the texture file contains data that indicate a symptom at that point e.g. a colored pixel the intensity of that symptom will be returned and displayed on the calendar possibly grouped with the intensity values of other points in the region as chosen by the user.

In an alternative embodiment a result symptom is created by summing the intensity of the symptom at a given point on the texture file with the symptom intensity of the corresponding spatial location on every other layer chosen by the user. This summation returns a combined intensity across layers by region.

In an embodiment a variant of above sequence can be adapted and used to plot points that express intensity of one symptom against time. Additional embodiments may determine intensity of more than one symptom in a zone. In another embodiment the calendar described may be exported into a commonly understood format such as XML .

Under certain circumstances it may be desirable to use data stored within a DBR to model aspects of a person s health. In a specific embodiment of the present invention over any duration of time a person s health can be understood as a combination of certain variables health variables that may each take on a range of specific values. For example these variables can be symptoms treatments and or medical condition. In the specific embodiment data contained within DBR is used to calculate the relationships between these variables and to make predictions answering questions about a person s health.

In this specific embodiment a plurality of DBRs representing a plurality of living beings may be stored in computer memory . Then given a DBR corresponding to a first living being a query DBR it may be desirable to find one or more DBRs corresponding to a second living being deemed similar. In a specific embodiment of the present invention the task of finding similar DBRs can be understood as an unsupervised or partially supervised learning task where the aim is to use a subset of the data stored inside DBRs to cluster them into similarity groups clusters . The term unsupervised learning means that objects to be classified are not class labeled a priori in clustering the aim is to group data that may be of the same class.

First data from a subset of DBRs in the system are reduced into a vector such as or of features where a feature may be understood as a combination of data objects in a DBR such as a numerical combination discrete barcodes representing combinations of data discrete tags representing combinations of data Boolean data reflecting processed data etc. Notice that in general features may be discrete or continuous in type. Then a similarity metric may be used to find similar DBRs or rank them by similarity . In one embodiment similarity is determined by using Hamming distance as an estimator for similarity between any two DBRs where the Hamming distance between two sequences of equal length is the number of positions at which the corresponding symbols are different. In this specific embodiment the Hamming distance between DBRs of similar living beings would be hypothesized to be small relative to the Hamming distance between DBRs of dissimilar living beings. Hamming distance can be used to order DBRs by similarity to a query DBR .

In alternative embodiments Hamming distance or a similar distance metric may be further employed to apply a technique called Locally Sensitive Hashing which has been applied to several problem domains including image similarity identification gene expression similarity identification and audio similarity identification. In yet alternative embodiment a nearest neighbor algorithm can be used to construct an M dimensional Tree which is a space partitioning data structure for organizing points in an M dimensional feature space. In a further alternative embodiment clustering can be implemented by a by kernel estimator. Persons of ordinary skill in the art can contemplate additional clustering techniques for the purpose on comparing DBRs to query DBR and they are included within the scope of the present invention.

In an embodiment the process for finding similar DBRs may include the construction and querying of a hierarchical data structure which groups similar DBRs. Such a data structure is a Clustering Decision Tree CLTree described in detail by B. Liu X. Yiyuan P. Yu in Clustering via Decision Tree Construction Published in Proceedings of the ninth international conference on Information and knowledge management 2000 herein included by reference.

Depending upon the embodiments similarity can be understood in terms of a Boolean variable or a non Boolean variable. Two DBRs can be similar or dissimilar Boolean or they can be similar to a degree. Both representations of similarity are consistent with the present invention. A continuous similarity value may be converted to a Boolean via a threshold function such as a sigmoid or step function . In further additional embodiments additional schemes and metrics may be used to assess similarity between DBRs for example combination of Boolean and non Boolean variables.

In certain embodiments information about similarity can be utilized to form a social network which is a structure made up of individuals called nodes which are connected by one or more specific types of interdependency. In this specific embodiment for each user of the system there is provided a data storage object User object that represents that user which may contain attributes referencing DBRs that the user uses. Then the social network can be formed by establishing connections between User objects that use DBRs which are found to be similar according to certain predetermined and or user selectable criteria. For example a social network can be formed among users with ages 30 40 who experience lower back pain 20 of the time during a day.

In an alternative embodiment the social network can be formed by repeatedly selecting a first user and querying other users for similarity to the first user where links may connect the first user to similar users. In an additional further embodiment the links in the social network may be dynamically updated based on how the similarity between for instance two people may change over time. For example at for some durations of time two individuals may have very similar symptoms and may benefit from therapeutic aspects of knowing someone else with similar symptoms. However at some point the similarity between these two people may change so that they start to become more different for example one person s condition could suddenly change and improve. Thus the connections between users may also be updated over time to reflect changes in similarity. This may be implemented by constructing social networks based on similarities multiple times over a duration.

The User object may contain attributes which can be used to represent links to other User objects. Determining which users should be linked and how the linkage should take place can be determined by assessing DBR similarity as previously discussed then extending the similarity relationships between DBRs to the User objects. For instance users of DBRs that are deemed similar may have links connecting them.

In an alternative embodiment of the present invention the nodes of the social network may be DBRs. For example the links between these nodes may be extended from DBR to DBR. Thus in an additional embodiment where the social network is used for social purposes such as for user to user communication the users are connected to each other based on the medical records that they may access.

In one embodiment of the invention this extension of DBR similarity to users requires additional logical processing. For instance certain types of links may be suited for certain types of users. For example some users who are doctors nurses therapists that advise a large number of patients may be treated differently than users who are primarily patients.

Under some circumstances a social network may be used to facilitate the exchange of information between two or more users where the exchange may depend in some way on the linkage relationships between the users. For instance in one specific embodiment of the invention a first set of users who are all directly and mutually linked may communicate with each other via an interactive forum that is exclusive to users in the first set so that another user who is not directly linked to a user in the first set may not participate. Several computer tools and software are readily available today to implement social networking interaction. For example several open source web application frameworks including Django and Ruby on Rails employ a reusable app feature that simplifies the rapid construction of social web applications. One such package of social applications for Django is an open source collection of tools called Pinax.

In an alternative embodiment the social network uses DBRs as the nodes for storing linkage information as opposed to the User object. In a further additional embodiment a link between nodes is not necessarily Boolean but is a value which indicates which indicates the strength of the link such a value may be discrete or continuous. In an additional embodiment the strength of the link between two users may influence how they may exchange information.

Under certain circumstances it may be desirable to use data stored within a DBR to model aspects of a person s health. In a specific embodiment of the present invention over any duration of time a person s health can be understood as a combination of certain variables health variables that may each take on a range of specific values. For example these variables can be symptoms treatments and medical condition. In the specific embodiment data contained within DBR is used to calculate the relationships between these variables and to make predictions answering questions about a person s health. Furthermore analysis based on these variables may employ the use of similarity relationships between people to make predictions.

In the specific embodiment arrows connecting the boxes represent dependency relationships between health variables for example an arrow from a parent variable A to a child variable B suggests that the value of the variable B may depend be influenced by the value of the variable A. The illustration of the specific embodiment shows three types of arrows between various types of variables. An arrow is directed from Medical condition such as to symptom in the same time range. This arrow can be understood by the notion of symptom being due to an underlying cause which is the medical condition. Another arrow goes from one medical condition variable such as to another medical condition variable at the next time step. This arrow can be understood by recognizing that the medical condition relates to some intrinsic properties of the individual s physiological body that persist through time. A simple example may assist in clarifying what these first two arrows mean. Consider a person who has a painful sore throat symptom one day which is actually due to a bacterial infection a medical condition it may be reasonable to think that some symptoms will persist for several days if the infection. Suppose the next day the person also has a sore throat and additionally has fever . The specific embodiment may explain the progression of the symptoms using the medical condition variable the bacterial infection which caused the symptoms on the first day persisted and progressed in the person s body over the course of time so that on the next day the body condition was an even more larger infection causing more pronounced symptoms .

In the present embodiment the previously mentioned third arrow signifies the relationship between a treatment variable such as and the subsequent medical condition . This relationship can be understood by recognizing that any action behavior a person does at a given time may influence the physical biological state of the body in immediately after the action is competed thus it influences the medical condition in a subsequent time interval.

The relationships between the variables illustrated by arrows in can be understood in stochastic terms. That is the relationship described by an arrow may actually be observed only a fraction of the time. This is because no matter how specifically a model may try to model the body of a living being it is not possible to be completely certain about a prediction. Some causes for this uncertainty could be error that comes from the process of recording and storing medical symptom data. Another cause for such error may be the sheer complexity of the body which makes it hard to model. A specific embodiment of the present invention deals with uncertainty by adopting a probabilistic approach to make predictions about health variables.

Probability can be understood as a framework for working with uncertainty in variables. In the case where a variable s value is known with certainty that variable can be defined as a particular value however in the case where the variable s value is not known with absolute certainty a probability distribution may be used to express the range of values that a variable is likely to assume. An example of a probability distribution is a normal Gaussian distribution sometimes called a bell curve . This distribution describes a variable with an average value and a standard deviation which describes the spread of the distribution. A large standard deviation suggests that there is low certainty about value of the variable and that it may frequently take on values in a wide range whereas a small standard deviation suggests that the variable will typically assume a value close to the mean.

In a specific embodiment of the present invention health variables can be described by a categorical probability distribution. A categorical probability distribution of a variable which can assume k states can be understood as a collection of k numbers where each number is a probability that the variable is a specific state.

During prediction the specific embodiment determines categorical distributions for variables using a list of states scenarios that each variable can assume.

In a specific embodiment a probability model is constructed reflecting aspects of the relationships between variables described in . A probability model can be understood as a mapping or as a function which uses input data to calculate probability distributions such as a categorical distribution over the states scenarios of unknown uncertain variables. In an additional embodiment of the present invention the probability model contains one or more parameters which are used to define the mapping. The parameters may be numerical and their values may be determined by a technique called parameter estimation or training described below .

In the specific embodiment defining the Bayesian network can be understood as the process of indicating the logical dependence relationships that may exist between variables. The specific embodiment uses a pre defined Bayes net structure a portion of which is graphically represented to illustrate such dependence relationships between variables shaded boxes using arrow notation. Recall that an arrow extending from a parent variable A to a child variable B suggests that the value of the variable B may depend be influenced by the value of the variable A. Notice that the Bayesian Network can contain multiple types of variables including the Health Variables in a configuration consistent with the logic illustrated in . In the graph which represents the network immediately after it has been defined the arrows between variables indicate that the parent variable may influence the child without specifying how it does so. For example an arrow between a medical conditions and a symptom over the same range of time does not specify how the probability distributions of symptoms depends on the medical condition but only that such a dependence relationship may exist. Alternatively predetermined starting values may also be assigned to probability distributions based upon prevalent knowledge about the relationships.

In the specific embodiment these relationships between variables are specified during the process of estimating training the parameters of the network using information including training data . In the specific embodiment parameter estimation can be understood as converting patterns within the training data into one or more parameters using a pre defined algorithm thus the set of training data that is used to in parameter estimation has a direct impact on the quality of the model. In one specific embodiment of the present invention data from a plurality of the DBRs are used to train the model. In an additional embodiment the plurality of DBRs includes DBRs that are similar to a query DBR. In an alternative embodiment data from a single DBR is used to train the probability model.

In a specific embodiment of the present invention a predefined algorithm called Expectation Maximization is used to train the models of the Bayesian Net and implementation details may be found in the book Artificial Intelligence a Modern Approach 3rd ed by Stuart Russell and Peter Norvig published by Pearson 2010 which is herein incorporated by reference.

In a specific embodiment of the present invention the Bayes Net can be queried to produce a probability distribution of a health variable over a set of scenarios for a specific user. Querying involves using a subset of the data stored in his her DBR as input to the Bayesian net and using a combination of pre defined algorithms to make estimations about an uncertain variable such as a health variable representing medical condition treatment or symptom. In the specific embodiment the algorithms that calculate probability distributions of variables in Bayesian networks can be generally understood as doing iterative calculations.

For illustrative purposes consider a user of a specific embodiment of the invention who is a runner trying the find out the probability that he will recover from a knee injury in time for a major race in the future. Assuming the specific embodiment employs the use of structured Dynamic Bayesian Net whose parameters have been estimated answering the runner s question becomes a matter of projecting knowledge about the current medical condition into the future to predict a future medical condition such as . As previously discussed in relation to medical condition at a time depends on the previous medical condition and the prior treatments thus the condition at the time of the race depends on an earlier treatment and an earlier medical condition which in turn is unknown because it is in the future depends on a previous treatment and a previous medical condition . Thus an interactive process which projects probability distributions of the runner s medical condition and treatments into the future one time step at a time can calculate a distribution over medical conditions at a time in the future.

Many computational techniques and algorithms may be used to query the Bayesian net and determine probability distributions for different types of variables including medical condition treatment and symptoms at different points in time. In one embodiment of the invention an algorithm known as exact inference may be used to calculate a probability distribution for any node in the network using mathematical probability relationships implicit in the structure of the network. This technique can be applied to calculate distributions for medical condition treatment and symptom variables at the current time interval future time intervals and past intervals. In an additional embodiment aspects of the exact inference algorithm are replaced by algorithms called forwards and backwards algorithms commonly used in statistics and robotics to solve a class of problem called a Hidden Markov Model. In an additional embodiment a pre defined sampling scheme may be used to determine probability distributions of uncertain variables in a Bayesian net where examples of sampling schemes include Gibbs Sampling and Particle Filtering.

In an alternative embodiment the relationships between the health variables may be different. In a further additional embodiment the Bayesian network may include a subset of the health variables described and may additionally contain additional variables. Alternative embodiments of the present invention may use a probability model different from a Dynamic Bayesian Network including parametric and non parametric models to calculate distributions over health variables. In additional embodiments of the present invention rather than outputting a probability distribution the model outputs the maximum likelihood or maximum a priori or Bayesian estimate for a variable. It is to be understood the specific references to statistical models and procedures above is for illustrative purposes only. Persons of ordinary skill in the art can contemplate various alternatives and modifications which are to be included within the scope of the present invention.

Additional embodiments may include following additional or alternative features the DBR may be represented in multiple ways the DBR representation may assume multiple forms in memory at different instances in time for example format may change to back up data in a relational database such as MySQL the 3D model data may be stored in a coordinate system different than Cartesian the display information of the surface on a 3D model may be stored by a data object different from a 2D Texture image e.g. layers may contain a mapping information to portions of a 3D model the DBR may be implemented in a relational database 3D Body Layers may be custom made for living beings and or customized from base template two or more body layers may include the same 3D structure but may display different depths of the body using alternative textures and or texture mapping different living beings may have a different collection of layers any layer may be constructed de novo for each person any layer may be customized from base template for any living being the layers may be constructed utilizing body scans the layers may be modeled in 3D modeling software such as Maya provided by Autodesk of San Rafael Calif. more than one texture can be used to add detail to a 3D model s surface vector based images such as SVG format images are used as texture files texture information may be stored in a format different from 2D texture image the system and method may be used for animals audio data can be used in the methods for prediction of health variables for example a voice recognition software can extract words which can be analyzed and sorted into feature vectors which can be used for probabilistic modeling.

Alternative embodiments may provide one or more following features embodiments may use special and or general purpose hardware and or software for achieving aspects of interactivity including the display of the Body Layers and the processing of user input other input devices e.g. in addition or instead of the pointing device described in illustrative embodiments other output devices e.g. may be used in addition or instead of the computer screen described in illustrative embodiments the steps of layer selection symptom selection and navigation may be performed in different order and combination the selection of layers indication of a symptom type transformation of the layers and or the input of additional user input may be handled by non GUI elements or GUI elements in a different configuration than those described additional symptom types may be painted besides than those indicated including irritation itch tingling swelling burning crawling rash and other medical symptoms additional types of data may be tagged generally including all forms of computer readable data painted data may indicate gradation quantity intensities of symptoms e.g. severe burn intermediate burn mild burn visually by means including using different colors or shades painted data may be saved in an object that is not necessarily a texture after parsing and additional processing to extract information from the texture used for displaying texture data may be stored in a data object via a process that does not require information from a 2D texture for example when the user paints symptoms the 3D coordinates may be collected and processed into a data storage object after which the 2D texture may be updated to reflect the data object. Various such modifications extensions and alternatives will be apparent to persons of ordinary skill in the art and are included within the scope of the present invention.

Accordingly the present invention provides computer based system and method for recording and analysis of medical conditions. While specific embodiments are described herein alternative embodiments will be apparent to person of ordinary skill in the art in which one or more acts described herein can be modified performed in different order or omitted without departing from the spirit of the invention. Moreover one or more acts can be added to those described herein. Such alternatives and modifications are included within the scope of the present invention.

