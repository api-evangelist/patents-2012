---

title: Method and apparatus for creating an information security policy based on a pre-configured template
abstract: A method and apparatus for creating a policy based on a pre-configured template is described. In one embodiment, source data having a tabular structure is identified. Further, one of multiple policy templates is used to automatically create a policy for detecting information from any one or more rows within the tabular structure of the source data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08813176&OS=08813176&RS=08813176
owner: Symantec Corporation
number: 08813176
owner_city: Mountain View
owner_country: US
publication_date: 20120625
---
This application is a continuation of U.S. patent application Ser. No. 10 892 615 filed on Jul. 15 2004 which is a continuation in part of U.S. patent application Ser. No. 10 833 538 filed on Apr. 27 2004 which is a continuation in part of U.S. patent application Ser. No. 10 607 718 filed on Jun. 27 2003 which is a continuation in part of U.S. patent application Ser. No. 10 431 145 filed on May 6 2003 which is a continuation in part of U.S. patent application Ser. No. 10 247 002 filed on Sep. 18 2002 and assigned to the assignee of the present application. The material of U.S. patent application Ser. Nos. 10 892 615 10 833 538 10 607 718 10 431 145 and 10 247 002 is hereby incorporated by reference.

The present invention relates to the field of processing data more particularly the present invention relates to creating an information security policy based on a pre configured template.

A modern organization typically maintains a data storage system to store and deliver records concerning various significant business aspects of the organization. Stored records may include data on customers or patients contracts deliveries supplies employees manufacturing etc. A data storage system of an organization usually utilizes a table based storage mechanism to store the information content. A table based storage mechanism may include relational databases client server applications built on top of relational databases e.g. Siebel SAP etc. object oriented databases object relational databases document stores and file systems that store table formatted data e.g. CSV files Excel spreadsheet files etc. password systems single sign on systems etc.

Table based storage systems typically run on a computer connected to a local area network LAN . This computer is usually made accessible to the Internet via a firewall router or other packet switching device. Although the connectivity of a table based storage system to the network provides for more efficient utilization of information maintained by the table based storage system it also poses security problems due to the highly sensitive nature of this information. In particular because access to the contents of the table based storage system is essential to the job function of many employees in the organization there are many possible points of possible theft or accidental distribution of this information. Theft of information represents a significant business risk both in terms of the value of the intellectual property as well as the legal liabilities related to regulatory compliance.

Theft of information may occur if access control associated with the table based storage system has failed either because it has been misconfigured or the trust in the authorized parties is misplaced. Various search mechanisms have been used to detect theft of sensitive information. The description of these search mechanisms is provided below.

Relational structures hold data in a fashion that presents naturally intuitive ways to query the data and has the added advantage of hiding the details of the underlying disk storage system from the user. The typical applications for database systems involve the storage and retrieval of a large number of smaller pieces of data that can be naturally formatted into a table structure. Relational databases have high utility because the types of queries that most people care about can be optimized using the well known index structures outlined below.

The queries requested of relational database systems use a naturally intuitive predicate logic called Structured Query Language SQL that allows the user to succinctly request the tabular data that she he may be looking for. Database tables almost always come equipped with an index that makes queries based on SQL more efficient. These indices are stored in memory using a data structure called a B tree. The salient characteristics of B trees most relevant to the current discussion are as follows 

There are a number of references to original works in the field of database systems. The first is the seminal work on relational databases by E. F. Codd. A Relational Model of Data for Large Shared Data Banks Communications of the ACM 13 6 377 387 1970.

The second reference is one of the first published works on the B Tree data structure that is the fundamental data structure that enables efficient queries of the type outlined above. See Rudolf Bayer and Edward M. McCreight Organization and Maintenance of Large Ordered Indices Record of the 1970 ACM SIGFIDET Workshop on Data Description and Access Nov. 15 16 1970 Rice University Houston Tex. USA Second Edition with an Appendix pages 107 141 ACM 1970.

Information retrieval is a broad field that deals with the storage and retrieval of textual data found in documents. These systems are different from those of database systems chiefly in their focus on standard documents instead of tabular data. Early examples of this system were developed as part of the SMART system at Cornell. Today the best known information retrieval applications are web based search engines like Google Inktomi and AltaVista. The typical way to use these systems is to find a reference to a document that is part of a larger set of digital documents. The user experience for these applications usually consists of a series of queries interleaved with browsing of the results. Results of the queries are presented in order of descending relevance and the user is able to refine the queries after further browsing. As with relational databases the huge popularity of these systems is due to the ability of the underlying indices to deliver quick responses to the types of queries that people find most useful.

Most of these systems are based on indices that are derived from so called concordances that are built up from the collection of documents indexed. These concordances contain a data structure that lists for each word the location of each occurrence of that word in each of the documents. Such data structures allow quick lookups of all documents that contain a particular term. For user queries that ask for all documents that contain a collection of terms the index is structured so that it represents a large number of vectors in Euclidean vector space of high dimension. The user s list of query terms is then also re interpreted as a vector in this space. The query is run by finding which vectors in the document space are nearest to the query vector. This last approach has a variety of different optimizations applied to it for accuracy and speed and is called the cosine metric .

As mentioned above the typical user interaction with these sorts of systems is an iterative cycle of querying browsing refining and back to querying again. Query results are usually large numbers of documents that are ranked in order of relevance and the false positive rate can be very high. Here are some classic examples of queries.

One of the first significant implementation projects of information retrieval systems is the SMART system at Cornell. This system contains many of the essential components of information retrieval systems still in use today C. Buckley Implementation of the SMART Information Retrieval System Technical Report TR85 686 Cornell University 1985

The WAIS project was an early application of the massively parallel super computer produced by Thinking Machines Inc. This is one of the first fielded information retrieval systems made available over the Internet. This primary reference source for this work is by Brewster Kahle and Art Medlar An Information System for Corporate Users Wide Area Information Servers. Technical Report TMC 199 Thinking Machines Inc. April 1991 version 3.19.

Among the many contemporary commercial vendors of Internet search services is Google. Google s real break through in search accuracy is its ability to harvest data from both the text of the documents that are indexed as well as the hyper link structure. See Sergey Brin Lawrence Page The Anatomy of a Large Scale Hypertextual Web Search Engine http dbpubs.stanford.edu 8090 pub 1998 8

The growth of the Internet and affordable means of copying and distributing digital documents spurred research interest in technologies that can help detect illegal or inappropriate copies of documents. The primary application for this work was to detect the violation of copyright law and to detect plagiarism. There is also significant interest in this problem as it relates to spam email AKA unsolicited commercial email detection and automatic elimination. The technical term applied to describe most of these techniques is file shingling in which adjacent sequences of document fragments are reduced to shingles by hash codes and then stored in a lookup table in the same sequence as they are found in the document.

File shingling provides a very quick way to look for similarity between two documents. In order to provide protection to a specific document e.g. a text file the document is shingled by hashing the document sentence by sentence and storing these hashed sentences in a table for quick lookup. In order to test a new document to see if it contains fragments of copyrighted content the same hash function is applied to each fragment of the test message to see if the fragments appear in a similar order as they do in the copyrighted content. The technique is quick because the time required to lookup an individual fragment can be very fast.

The typical user interaction with a file shingling system is passive instead of active. File shingling systems are usually set up to process documents automatically and deliver the query results to a user asynchronously. A typical file shingling application might be spam prevention where a set of messages is used to create an index of restricted content that an organization does not want delivered to its email systems. In this scenario the query is just the automatic processing of email messages and appropriate automatic routing.

With respect to document equivalency queries for each test document t find all documents d in our collection of indexed documents that have the same contents as t. For the case of spam detection the set d could be all of the known active spam messages and the document t could be an incoming email message.

With respect to cut and paste detection queries for each test document t find all documents d in our collection of indexed documents in which some fragment of d occurs in t. For the case of plagiarism detection the set d could be all of the previously submitted essays for a particular class and the document t could be a new paper written by a student who is suspected of plagiarism.

The main published research projects in file shingling are called KOALA COPS and SCAM. They all use variants on the basic file shingling approach described above with variants that optimize performance and accuracy. For information on KOALA see N. Heintze Scalable Document Fingerprinting Proceedings of Second USENIX Workshop on Electronic Commerce November 1996. http www 2.cs.cmu.edu afs cs user nch www koala main.html. For information on COPS see S. Brin J. Davis and H. Garcia Molina Copy Detection Mechanisms for Digital Documents Proceedings of the ACM SIGMOD Annual Conference May 1995. For information on SCAM see N. Shivakumar and H. Garcia Molina SCAM A Copy Detection Mechanism for Digital Documents Proceedings of 2nd International Conference in Theory and Practice of Digital Libraries DL 95 June 1995 http www db. stanford.edu shiva SCAM scamInfo.html and also see by N. Shivakumar and H. Garcia Molina Building a Scalable and Accurate Copy Detection Mechanism Proceedings of 1st ACM Conference on Digital Libraries DL 96 March 1996 http www db. stanford. edu pub papers performance.ps.

A variety of commercial applications referred to as content filtering systems implement protection measures. There are two major types of applications in this category web site restriction monitoring software and email content control. In both cases the main algorithm currently in use is pattern matching against a set of regular expressions for a set collection of text fragments that would indicate data misuse. An example might be to restrict all browsing at URLs that contain the text fragment XXX . An example for the email content control category is stopping and blocking all email that contains the words proprietary and confidential but not the words joke or kidding .

A method and apparatus for creating a policy based on a pre configured policy template is described. In one embodiment source data having a tabular structure is identified. Further one of multiple policy templates is used to automatically create a policy for detecting information from any one or more rows within the tabular structure of the source data.

A method and system for creating a policy based on a pre configured policy template is described. Source data having a tabular structure is identified. In one embodiment the source data is identified based on user selection of the source data from a list of sources. Further one of policy templates is used to automatically create a policy for detecting information from any one or more rows within the tabular structure of the source data. In one embodiment the policy templates are pre configured based on corresponding regulations concerning sensitive data maintained by an organization. In one embodiment a list of pre configured policy templates is presented to a user to allow the user to select a policy template for the policy being created.

In the following description numerous details are set forth to provide a more thorough explanation of the present invention. It will be apparent however to one skilled in the art that the present invention may be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form rather than in detail in order to avoid obscuring the present invention.

Some portions of the detailed descriptions which follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as processing or computing or calculating or determining or displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The present invention also relates to apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium such as but is not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct more specialized apparatus to perform the required method steps. The required structure for a variety of these systems will appear from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

A machine readable medium includes any mechanism for storing or transmitting information in a form readable by a machine e.g. a computer . For example a machine readable medium includes read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other form of propagated signals e.g. carrier waves infrared signals digital signals etc. etc.

The template store stores policy templates configured based on regulations concerning handling of sensitive information maintained by an organization. These regulations may include for example the Health Insurance Portability and Accountability Act HIPAA ensuring the confidentiality of electronic protected health information California Senate Bill 1 SB1 or Senate Bill 1386 SB1386 controlling customer information leaving the company and affiliates the Gramm Leach Bliley Financial Services Modernization Act controlling customer information leaving a financial institution the Cardholder Information Security Program CISP controlling handling of customer credit card information maintained by an organization etc. In one embodiment policy templates are pre configured based on input provided by individuals familiar with the relevant regulations and stored on a server not shown . When a regulation changes a corresponding policy template is modified. In one embodiment the system periodically polls the server for new templates or updated versions of existing templates and updates the contents of the template data store based on information downloaded from the server. In one embodiment a template includes a set of clauses also referred to herein as rules that specify conditions triggering a policy violation. The clauses may be composed using logical connectives of first order logic e.g. AND OR NAND NOR NOT equivalent nonequivalent etc. .

The user interface module is responsible for presenting user interfaces facilitating user input pertaining to policies. As will be discussed in more detail below a user interface may allow a user to choose a pre configured template and source data for a policy. Alternatively if a user decides not to use a template a user interface may allow the user to specify source data and provide parameters for each rule of the policy as well as logical connectives between the rules.

The policy specifier is responsible for defining the policy based on policy parameters identified by a user. In one embodiment the policy specifier receives the policy parameters from the user interface module . In another embodiment the policy specifier receives the policy parameters from an Application Programming Interface API or via a configuration file formatted in text or a defined data format e.g. extensible markup language XML or binary format .

The policy specifies which information should be present in a message to trigger a violation. In one embodiment the policy identifies source data and specific components of the source data. The source data may be any data whose relationships allow it to be structured in a tabular format. In other words the source data may be stored in a tabular format e.g. data in a relational database data maintained by client server applications built on top of relational databases data in document stores and file systems that store table formatted data e.g. CSV files or Excel spreadsheet files etc. or it may be stored in a non tabular format but have such relationships as to allow it to be stored in a tabular format e.g. data stored as comma separated values in a flat file a password database or a single sign on system relational data in an object oriented database etc. . In one embodiment the source data includes contents of multiple sources e.g. multiple databases multiple document stores multiple file systems multiple files etc. . The content of each source has a tabular structure i.e. relationships among content components allow the content to be structured in a tabular format .

In one embodiment the policy includes a rule indicating that a violation will be triggered if the message includes fragments matching information from specific columns within any single row of the source data. In addition the policy may include rules specifying other requirements with respect to message fragments that match information from the source data.

In some embodiments the policy includes rules that are applicable to the characteristics of the entire message e.g. a rule requiring that a sender and or a recipient of the message satisfy a specific pattern a rule requiring that the message be carried using a specific protocol a rule requiring that a destination of the message posted for public discussion match a specific newsgroup name etc. . In other embodiments the policy includes rules that are applicable to the characteristics of message sub components e.g. a rule requiring that a message attachment be of a specific type or size or have a specific file attachment name . In yet other embodiments the policy includes rules requiring that the message contain a specific keyword s or an expression matching a specific regular expression pattern.

The action identifier is responsible for defining which actions e.g. reporting violations intercepting and blocking messages containing detected violations re routing messages containing detected violations etc. should be taken when a certain type of violation is detected. In one embodiment the action identifier provides a user interface facilitating the user input of action conditions. In other embodiments the action identifier receives action conditions as parameters supplied by an Application Programming Interface API or via a configuration file formatted in text or a defined data format e.g. XML or binary format .

In one embodiment a single user interface is used to facilitate user input of policy parameters and user input of action conditions.

The index creator is responsible for creating an index for the source data defined by the policy specifier . In one embodiment in which the source data includes contents of multiple sources an index is created for the content of each source. In one embodiment the created index contains no copies of the database data or contains only encrypted or hashed copies of database data. Such an index may be created using a tuple storage mechanism that provides a data structure for storing multiple tuples associated with fragments of the database data. Examples of the tuple storage mechanism include a hash table a vector an array a tree a list or a table in a relational database management system. As will be described in more detail below the data stored in the indices only retains the relative placement of the elements in the database in relation to other elements. For example in the case of a hash table the index may store for each fragment of the database data e.g. a data fragment inside a database cell the fragment s hash code together with its row number and column number.

The violation detector is responsible for receiving policies from the policy specifier receiving search indexes from the index creator and monitoring messages to detect violations of the abovementioned policies. The violation detector may be responsible for monitoring messages sent over the network e.g. email messages messages posted on the Internet for public discussion etc. as well as data processed by personal computing devices and data stored on data storage media of personal computing devices such as portable computers desktop computers Personal Digital Assistants cell phones etc. The information content being monitored may contain free form text that is not associated with any known tabular structure. In one embodiment multiple violation detectors are implemented at different locations to provide scalability and or protect multiple possible points of egress of information.

The action regulator is responsible for evaluating detected violations determining which actions to perform for each detected violation based on the action conditions and performing the identified actions. In one embodiment multiple action regulators are implemented at different locations along with corresponding violation detectors .

In one embodiment the system consists of two components a policy management system PMS and a data monitoring system DMS . The PMS is responsible for defining policies and detection conditions creating an index for each source data specified by the policies and sending the policies and detection conditions together with the source data index to the DMS. The DMS is responsible for monitoring messages based on the information received from the PMS and performing appropriate actions when policy violations are detected. In one embodiment the PMS and the DMS are coupled to a computer network that communicates any of the standard protocols for the exchange of information. In one embodiment the two subsystems PMS and DMS run on one Local Area Network LAN . However the PMS and DMS may be incorporated into the same physical or logical system. In another embodiment the PMS and DMS may not necessarily reside on the same LAN. The PMS may reside on the same LAN as the data source but the DMS may reside on a different LAN that is separated from the LAN on which PMS resides. In this configuration the two distinct LANs may ultimately be coupled together via the Internet but separated by firewalls routers and or other network devices. This is an advantageous configuration for the case where a company wants to restrict another company that needs their database data such as a law firm or marketing agency from violating the first company s database data policy.

In another embodiment the system is directed to monitoring information content residing on a personal computing device of a user to detect user operations that may involve a potential misuse of data e.g. saving or accessing restricted source data on any storage device on the computing system using restricted source data in an application printing restricted source data using restricted source data in any network communication protocol etc. . In this configuration the PMS component of the system may reside on a server and the DMS component of the system may reside on a device coupled to the server via a public network e.g. the Internet or a private network e.g. LAN .

Processing logic begins by receiving user input pertaining to a policy processing block . As will be discussed in more detail below the user input may specify source data that contains sensitive information and a pre configured policy template to be used for the policy. Alternatively the user input may specify source data and rule parameters for the policy such as parameters concerning the source data e.g. specific columns of the source data the minimum number of columns of the source data the minimum number of rows of the source data etc. . In one embodiment the source data includes contents of multiple sources e.g. multiple databases multiple document stores multiple file systems multiple files etc. with the content of each source having a tabular structure.

The user input may also specify characteristics of the message e.g. a sender or recipient identifier pattern a protocol to carry messages a destination of the message posted for public discussion e.g. a specific newsgroup name etc. or certain characteristics of a message sub component e.g. a message attachment type or size a file attachment name etc. . In addition the user input may specify keywords or a regular expression pattern.

At processing block processing logic defines the policy based on the user input pertaining to the policy.

At processing block processing logic identifies action conditions specifying which action should be taken when a certain violation is detected. In one embodiment the action conditions are identified based on user input. Alternatively the action conditions are pre programmed e.g. requiring that each violation triggered by the presence of information from the source data in a message be reported to a certain user .

Next processing logic deploys the index processing block and the policy to each location at which content monitoring takes place processing block . In one embodiment processing logic also deploys action conditions to each location at which content monitoring is occurring.

Subsequently at processing block processing logic monitors content traveling over network infrastructure or residing on the user s personal computer.

Upon detecting a policy violation processing block processing logic determines which action should be taken in response to the detected violation processing block . For example processing logic may decide based on action conditions to report a violation to intercept and block the content violating the policy to re route the content violating the policy etc.

Processing logic begins with determining whether a policy template should be used for defining a policy processing box . In one embodiment processing logic makes this determination based on user input e.g. provided via a user interface specifying whether the policy should be defined using a pre configured policy template. Alternatively processing logic makes this determination automatically. For example processing logic may decide whether a policy template should be used based on the user s characteristics e.g. the user name the user position within the organization etc. or some other information.

If the determination made at processing box is positive processing logic selects a pre configured template for the policy processing block . In one embodiment the selection is made based on user input specifying the template e.g. by selecting a template from a list of templates displayed to the user . Alternatively the selection is made automatically based on the type of organization associated with the user e.g. selecting an HIPAA template if a user is an employee at a hospital or some other information.

As discussed above pre configured templates correspond to regulations concerning handling of sensitive information maintained by an organization. These regulations may include for example the HIPAA SB1 SB1386 the Gramm Leach Bliley Act the CISP etc. In one embodiment policy templates are pre configured based on input provided by individuals familiar with the relevant regulations.

In one embodiment a template includes a set of clauses composed using logical connectives of first order logic. In one embodiment a template includes a clause specifying which information from the source data should be present in a message to trigger a violation. For example a clause may indicate that a violation will be triggered if the message contains matching information from specific columns inclusion columns within any single row of the source data. A clause may also indicate a minimum number of these inclusion columns and or a minimum number of matches found in the message. As will be discussed in more detail below each match includes a collection of tokens from the message that match information from a single row of the source data. In addition a clause may specify exclusion columns i.e. columns whose data should not be present in the found match . In one embodiment inclusion and or exclusion columns are from different data sources selected for the policy.

In another embodiment a template includes a clause specifying conditions applicable to the characteristics of the entire message. For example a clause may indicate that a violation will be triggered if a sender and or a recipient of the message satisfies a specific pattern the message is carried using a specific protocol or a destination of the message posted for public discussion match a specific newsgroup name.

In yet another embodiment a template includes a clause specifying conditions applicable to the characteristics of a specific message sub component e.g. an attachment . For example a clause may indicate that a violation will be triggered if a message sub component is of a specific type or size or has a specific file name.

In still another embodiment a template includes a clause indicating that a violation will be triggered if the message contains a specific keyword s or an expression matching a specific regular expression pattern.

In yet another embodiment a template includes a combination of two or more of the abovementioned clauses.

At processing block processing logic selects source data for the policy. In one embodiment the selection is made based on user input specifying the source data e.g. a user selection from a list of sources . Alternatively the selection is made automatically based on specific characteristics associated with the user or the organization of the user. In one embodiment each data source in the list has been preprocessed e.g. source column names were mapped to column names used in a template . In one embodiment the selected source data includes contents of multiple sources e.g. as specified by the user s selection of multiple sources from the list .

At processing block processing logic creates a policy for the selected source data based on the selected template.

If the determination made at processing box is negative i.e. templates should not be used for creating a policy processing logic identifies the source data based on user input processing block receives policy parameters specified by the user for the policy rules processing block and creates a policy for the source data using the specified policy parameters processing block .

Afterwards at processing block processing logic presents the policy to the user. The user may then request to add a new rule to the policy or remove or modify any existing rule of the policy.

Processing logic begins with comparing a set of inclusion columns from source data that are specified by a relevant template e.g. a template selected by the user processing block . If each inclusion column in the set specified by the template has a matching column in the source data processing box processing logic creates a policy based on the original template processing block . As discussed above in one embodiment the inclusion columns in the set are from multiple sources e.g. multiple databases multiple document stores multiple file systems multiple files etc. with the content of each source having a tabular structure.

If any inclusion column from the set specified by the template does not have a matching column in the source data processing box processing logic removes each inclusion column that does not have a matching column in the source data from the set specified by the template processing block .

If processing logic determines that all columns have been removed from the set specified by the template processing box processing logic removes the relevant clause from the template processing block and uses the modified template when creating a policy processing block .

If processing logic determines that some columns still remain in the set specified by the template processing box processing logic further determines whether the number of remaining columns is below the minimum number of inclusion columns that is specified in the template processing block . If not processing logic creates a policy based on the original template processing block . If so in one embodiment processing logic updates the minimum number of inclusion columns in the clause of the template with the number of remaining columns processing block and uses the template so modified to create the policy processing block .

In another embodiment if the number of remaining columns is below the minimum number of inclusion columns that is specified in the template processing logic removes the relevant clause from the template and creates a policy based on the remaining clauses of the template.

Further processing logic determines whether the template selected by the user specifies exclusion columns processing box . If so processing logic compares a set of exclusion columns that are specified by the template with the columns in the source data processing block . If each exclusion column in the set specified by the template has a matching column in the source data processing box processing logic uses exclusion column data from the original template when creating the policy processing block . If any exclusion column from the set specified by the template does not have a matching column in the source data processing box processing logic removes each exclusion column that does not have a matching column in the source data from the set specified by the template processing block .

If processing logic determines that all exclusion columns have been removed from the set specified by the template processing box processing logic removes the exclusion clause from the template processing block and creates a policy based on the modified template processing block .

If processing logic determines that some columns still remain in the set specified by the template processing box processing logic uses the remaining exclusion columns when creating the policy processing logic .

Referring to a user interface presents a list of pre configured templates and allows a user to select a template from the list.

Referring to a user interface presents a list of data sources and allows a user to select one or more data source from the list. The list of data sources includes data sources that were preprocessed e.g. columns of a data source were mapped to columns of the template . For each preprocessed data source the user interface specifies which columns recommended by the template are not present in the data source. In addition the user interface allows the user to choose a data source that has not been preprocessed.

Referring to a user interface displays parameters of the created policy including general information about the policy e.g. the policy s name description status and date of the latest modification and parameters of its rule . The user can edit or remove the rule or add a new rule.

As discussed above templates may not be used to create a policy. Rather the policy may be created based on user input specifying various parameters for policy rules. These policy parameters may identify the source data and specify columns in the source data. In one embodiment the columns are specified to request that the matches returned by the search include information from any single row of the source data and that the information from the single row include data from each of the specified columns.

In one embodiment the policy parameters specify a value for a particular column. This column value is specified to request that the matches returned by the search include information from any single row of the source data that the information from the single row include data from the particular column and that this data be equal to the specified value.

In one embodiment the policy parameters provide a minimum number of columns in addition to the specified columns from the source data. The minimum number of columns is provided to request that the matches returned by the search include information from any single row of the source data and that the information from the single row include data from at least this number of the specified columns.

In one embodiment the policy parameters specify exclusion columns. The exclusion columns are specified to request that the matches returned by the search include information from any single row of the source data and that the information from the single row exclude data from any of the specified exclusion columns.

In one embodiment the policy parameters specify a minimum number of rows to request that the matches returned by the search include information from at least this number of random rows of the source data.

In one embodiment the user input pertaining to the policy parameters is facilitated via a user interface. illustrate exemplary user interfaces that facilitate user input of policy parameters according to one embodiment of the present invention. The policy parameters shown herein are arbitrary and modifiable in various areas of the user interfaces.

Referring to a user interface allows a user to specify the name of the source data and the file name containing the source data. The user interface also allows the user to perform field mapping between data source fields and system column names.

Referring to a user interface allows a user to provide policy parameters associated with source data . Specifically the user interface allows the user to specify inclusion columns a minimum number of inclusion columns exclusion columns a minimum number of rows i.e. incident minimum . According to the example illustrated in the specified policy parameters require that a match returned by the search include information from at least one random row of the source data that the information from one row contain data from at least two of the checked inclusion columns and that this information exclude data from any of the combined columns .

Referring to a user interface displays a set of rules contained in the policy associated with source data . For a first rule the specified policy parameters require that a match returned by the search include information from at least one row minimum matches of the source data and that the information from one row contain data from at least one of three specified columns .

For a second rule the specified policy parameters require that a match returned by the search include information from at least one row minimum matches of the source data and that the information from one row contain data from at least two of four specified columns and exclude matches confined to the fields specified in .

For a third rule the specified policy parameters require that a match returned by the search include information from at least 10 possibly non adjacent rows minimum matches of the source data and that the information from each of the 10 rows contain data from both columns .

Referring to a user interface displays rules of the policy associated with source data . The first rule requires that the recipient of the violating content match pattern . The second rule requires that the content be in an attachment of type . The third rule requires that the attachment be less than size 50 KB as specified by . The fourth rule requires that the match returned by the search include data matching keywords . The fifth rule requires that the match returned by the search include data matching keywords . The sixth rule requires that the match returned by the search include data matching an expression . The seventh rule requires that a match returned by the search include information from at least one row minimum matches of the source data and that that the information from each row contain data from at least two of specified columns .

As discussed above violations are detected by searching information content using predefined policies. In one embodiment a search is performed using an abstract data structure index derived from source data. In one embodiment this index contains no copies of the source data or contains only encrypted or hashed copies of the source data. This embodiment specifically avoids storing any representation of the data itself so that in the case of a hacker breaking into the host that runs the DMS which utilizes the index when performing content searches as discussed above the data that is exposed to theft is inconsequential. The index may be created using a tuple storage mechanism that provides a data structure for storing multiple tuples associated with fragments of the database data. Examples of the tuple storage mechanism include a hash table a vector an array a tree a list or a table in a relational database management system. In the process described below the data stored in the indices only retains the relative placement of the elements in the database in relation to other elements. For example in the case of a hash table the index may store for each fragment of the database data e.g. a data fragment inside a database cell the fragment s hash code together with its row number column number and type of the column.

In another embodiment indices contain fragments of the intellectual property that is under protection thus reducing the value of the solution by exposing that information to security threats.

In yet another embodiment copies of a small amount of frequently used strings and numbers from the database that represent a large proportion of the data in the system is still stored directly in the index along with the rest of the information on relative placement of data in the database table s . This is done by storing copies of these common strings themselves instead of hash codes. As a result indices may include the row numbers column numbers and type of the source data but instead of storing a hash code it stores the string itself. For the rest of the cells of the database that are not quite so common only the row numbers column numbers and type of the source data are stored while specifically not storing copies of these strings. This approach uses the fact that the statistical distribution of string and numeric data in databases is often skewed so that the most common terms account for a very large percentage of the overall volume of data stored. Storing these common terms in a separate index helps index query efficiency since the small number of common terms accounts for a large proportion of the queries and these queries can be run using standard quick techniques from the literature e.g. hash table lookups bitmaps etc. . The reason that this is not a security vulnerability is that this small number of terms that account for a disproportionate share of volume of source data are the least valuable pieces of data. The terms John and Smith are very common inside databases that contain names but the theft of these terms is relatively worthless. In this embodiment the system is still carefully avoiding storing copies of data of less common terms of higher value e.g. credit card numbers SSN uncommon names etc. .

Referring to processing logic begins with determining whether the source data is stored in a standard tabular format processing box . If not processing logic converts the source data into a standard tabular format processing block . Each cell in the resulting table stores a fragment of the source data. In one embodiment each data fragment is a token. A token may be a single word or a cluster of words e.g. words enclosed in quotation marks . For example while the word this may represent a token stored in a database cell the phrase this token may also represent a standalone token if it is stored as a single string in a database cell.

Next processing logic creates a tuple storage structure derived from the source data processing block . A tuple storage structure provides a mechanism for storing multiple tuples associated with the fragments of the source data. Examples of tuple storage structures include a hash table a vector an array a tree or a list. Each type of the tuple storage structure is associated with a method for retrieving a set of tuples for any given content fragment the set of tuples may be empty if no match is found in the tuple storage structure .

Further processing logic stores information about the position of each data fragment within the source data in a corresponding tuple processing block . In one embodiment the information about the position of a data fragment includes the number of a row storing the data fragment in the source data. In another embodiment this information also includes the number of a column storing the data fragment in the source data and optionally the data type of the column.

Afterwards processing logic sorts the tuples in a predetermined order e.g. in the ascending lexicographic order processing block .

Thus the resulting abstract data structure i.e. the index only contains information about the relative placement of data records in the context of the larger whole but does not include any fragments of the source data itself.

In one embodiment the contents of the index are treated cryptographically e.g. with a hash function or using an encryption function with a cryptographic key to further secure the index from theft.

Exemplary search techniques will now be described in more detail. is a flow diagram of one embodiment of a process for searching information content for source data. The process is performed by processing logic that may comprise hardware circuitry dedicated logic etc. software such as is run on a general purpose computer system or a dedicated machine or a combination of both.

Referring to processing logic begins with identifying information content processing block . The information content includes free from text and may be included in a file e.g. an archived email message stored on a hard drive of a computer or in a block of data transmitted over a network e.g. an email message transmitted over a network using any type of a network protocol . As discussed above the information content to be searched may be selected based on theft detection conditions specified by the user.

Next processing logic detects in the information content a sequence of content fragments that may possibly contain a portion of source data processing block . The detected sequence of content fragments may be a set of adjacent or non adjacent tokens within the information content. Each token may correspond to either a word or a phrase. The detected sequence of content fragments may be a portion of the received information content or the entire information content. In another embodiment the detected sequence of content fragments is considered as a set of subsets of tokens in which each subset of tokens may possible contain a portion of source data.

In one embodiment processing logic decides that a sequence of content fragments may possibly contain a portion of the source data upon determining that the sequence of content fragments resembles column formatted data. This determination may be made by parsing the received information content to identify separated lines as may be indicated for example by tags or and finding that these separated lines contain a similar number of tokens and optionally the similar data types of the tokens.

In another embodiment processing logic decides that a sequence of content fragments may possibly contain a portion of the source data upon parsing the entire information content and searching blocks of contiguous tokens for source data. In one embodiment the blocks of contiguous tokens are defined based on user specified parameters such as a user specified width of each block and a user specified position of each block within the information content e.g. the user may require that the two adjacent blocks be separated by a certain number of tokens .

In yet another embodiment processing logic decides that a sequence of content fragments may possibly contain a portion of the source data upon finding in the information content an expression of a predefined format. Such expression may be for example an account number a social security number a credit card number a phone number a postal code an email address text formatting indicating a monetary or numeric value e.g. signs together with digits etc. Once the expression is found processing logic decides that a region of text surrounding the expression may possibly contain a portion of the source data. The size of this region may be defined by a predetermined number of tokens on each side of the found expression.

In yet another embodiment processing logic decides that a sequence of content fragments may possibly contain a portion of the source data upon determining that the word usage or the word distribution in the information content or in some portion of the information content resembles a statistical pattern that indicates a possible containment of the source data in the information content.

In still another embodiment processing logic decides that a sequence of content fragments may possibly contain a portion of the source data upon determining that certain properties associated with the received information content indicate a possible containment of the source data in the information content based on the history of previous violations. These properties may include for example the destination of the information content e.g. a recipient of an electronic message the origin of the information content the time of transmission associated with the information content the size of transmission associated with the information content the types of files contained in the transmission e.g. multipurpose Internet mail extension MIME types of files etc. In one embodiment the history of previous violations is maintained by identifying for each detection of source data the properties of the information content in which the source data was detected and recording these properties in a previous violation database. Subsequently when processing logic decides whether a sequence of content fragments within the new information content may possibly contain a portion of source data processing logic identifies the properties of the new information content and searches the previous violation database for these properties. If a match is found processing logic determines whether the previous violations associated with the matching property indicate a possible containment of source data in the new information content. This indication may be based on the number of previous violations associated with the matching property or the frequency of previous violations associated with the matching property. For example this indication may be based upon the total number of violations that a particular sender has committed or the frequency of those violations over a given time period.

Afterwards upon detecting a sequence of content fragments that may possibly contain a portion of the source data processing logic makes a determination as to whether any subset of these content fragments matches a subset of the source data and is in accordance with the policy parameters discussed above processing block .

Referring to processing logic begins with parsing the sequence of content fragments identified at processing block of into content fragments e.g. tokens . Then for each content fragment processing logic searches the abstract data structure for a set of matching tuples processing block . For example a word Smith contained in the information content may have several occurrences in the source data that are reflected in the abstract data structure. Specifically each of these occurrences has a corresponding tuple in the abstract data structure. During the search processing logic retrieves a set of tuples corresponding to the occurrences of the word Smith in the source data. Each tuple stores information about the position of this data fragment within a database or a table storing the source data. In one embodiment the positional information includes the row number of a cell storing the data fragment. In another embodiment the positional information also includes a column number of this cell and optionally the data type of the column.

Next processing logic combines the matching tuple sets found for all the content fragments processing block and then groups the combined matching tuple sets by row numbers into groups L processing block . As a result each group L referred to herein as an accumulator contains matching tuple sets that all have the same column number i.e. the matching tuple sets in each group L correspond to fragments of the source data that all appear to be from the same row in the database.

Further processing logic sorts the groups L by the number of matching tuple sets contained in each group processing block and in one embodiment selects those groups that have tuple sets with distinct column numbers processing block . Afterwards processing logic determines whether any of the selected groups satisfy policy parameters processing block .

Referring to processing logic begins with determining whether the policy parameters specify inclusion columns decision box . If not processing logic proceeds to decision box . If so processing logic determines whether the policy parameters specify a minimum number M of inclusion columns decision box . If number M is specified processing logic searches for groups with tuples from at least M number of the inclusion columns processing block and determines whether any such groups are found i.e. the number of found groups is greater than 0 decision box . If the determination made at decision box is positive processing logic proceeds to decision box . If the determination made at decision box is negative processing logic decides that no violation has been detected processing block .

If number M is not specified decision box processing logic searches for groups with tuples from each specified inclusion column processing block and determines whether any such groups are found decision box . If the determination made at decision box is positive processing logic proceeds to decision box . If the determination made at decision box is negative processing logic decides that no violation has been detected processing block .

At decision box processing logic determines whether the policy parameters specify any key words or expressions. If not processing logic proceeds to decision box . If so processing logic searches for groups with tuples matching the specified keywords or expressions processing block and determines whether any such groups are found decision box . If the determination made at decision box is positive processing logic proceeds to decision box . If the determination made at decision box is negative processing logic decides that no violation has been detected processing block .

At decision box processing logic determines whether the policy parameters specify exclusion columns. If not processing logic proceeds to decision box . If so processing logic searches for groups with tuples that are not from all of the exclusion columns processing block and determines whether any such groups are found decision box . If the determination made at decision box is positive processing logic proceeds to decision box . If the determination made at decision box is negative processing logic decides that no violation has been detected processing block .

At decision box processing logic determines whether the policy parameters specify a minimum number L of rows. If not processing logic decides that a violation is detected processing block . If so processing logic determines whether the most recent number of found groups is not less than L decision box . If this determination is positive processing logic decides that a violation is detected processing block . If the determination made at decision box is negative processing logic decides that no violation has been detected processing block .

Referring to processing logic begins with receiving parameter m that identifies the minimum number of inclusion columns i.e. data source columns whose data needs to be included in the search result processing block .

Next processing logic receives parameter S specifying the set of inclusion columns and confirms that S is greater or equal to m processing block .

At processing block processing logic receives parameter r specifying the minimum number of rows. Parameter r requires that the search result contain data from at least r rows of the source data.

At processing block processing logic receives parameter E specifying a set of exclusion columns i.e. data source columns whose data has to be excluded from the search result and confirms that for each e member if E e is equal to m.

At decision box processing logic determines whether G is greater than r. If so processing logic decides that a match is detected processing block . If not processing logic decides that no match is detected processing block .

Exemplary embodiments of a search process will now be described. are flow diagrams of alternate embodiments of a process for searching an incoming message using a hash table index of source data. The process is performed by processing logic that may comprise hardware circuitry dedicated logic etc. software such as is run on a general purpose computer system or a dedicated machine or a combination of both.

Referring to processing logic begins with parsing an incoming message processing block . Next processing logic determines whether the parsed portions of the incoming message contain column formatted data processing box . In one embodiment lexical analysis may be used to identify lines in the parsed portions of the incoming message e.g. by finding tags or that are used to separate lines and then detecting that the number of tokens found in adjacent lines is identical in number and in type. In one embodiment processing logic stores the type of each token along with the total number of tokens.

If the determination made at processing box is negative processing transitions to processing block . Otherwise processing transitions to processing block where processing logic sets i equal to the first line that resembles column formatted data.

Next processing logic applies a hash function H k to each token in line i processing block finds a set of tuples at H k in the hash table for each token in line i adds the tuples to list L and regroups list L into a set of accumulators processing block in which each individual accumulator s tuples have the same row number value. Further processing logic sorts that list L by the length of each Ai processing block and checks for unique occurrences of columns in sorted list L processing block . At processing block optional pre processing logic may be performed to filter the tokens before insertion into list L so that only those tuples with type matching the lexical type of the original token k are added to L. It should be noted that in some other embodiments checking for unique occurrences of columns may be skipped for reasons of speed or simplicity. In yet other embodiments tuples are simple singletons containing row numbers only i.e. no column number and no type indicator .

Afterwards if the incoming message contains more lines that resemble column formatted data processing box processing logic increments i to the next line that resembles column formatted data processing block and the process transitions to processing block . Otherwise processing logic reports lines of text with Ai that exceed the predetermined size and have unique column numbers processing block .

Referring to processing logic begins with receiving user specified parameters of width W and jump J processing block and parsing an incoming message processing block . Parameter W specifies the number of contiguous tokens in each block of contiguous tokens that is to be searched during a single iteration and parameter J specifies the required number of tokens between the two adjacent blocks.

Next processing logic sets the value of the location variable S to zero processing block and defines a block textblock to be searched by collecting W contiguous tokens of the message starting at S processing block .

Further processing logic applies a hash function H k to each token in the textblock processing block finds a set of tuples at H k in the hash table for each token in the textblock adds the tuples that have the same type as the corresponding tokens in the textblock to list L processing block regroups list L into a set of accumulators processing block sorts that list L by the length of each Ai processing block and checks for unique occurrences of columns in sorted list L processing block .

Afterwards processing logic increments Sby J number of tokens processing block and determines whether location Sis still within the message processing box . If the determination is positive the process transitions to processing block . Otherwise processing logic reports textblocks with Ai that exceed the predetermined size and have unique column numbers processing block .

Referring to processing logic begins with parsing an incoming message processing block and looking for a first expression having a user specified format processing block . Such expression may be for example an account number a social security number a credit card number text formatting indicating a monetary or numeric value e.g. signs together with digits etc. If the matching expression is not found the process transitions to processing block . Otherwise the process transitions to processing block where processing logic defines a block textblock to be searched by collecting W contiguous tokens before and after the matching expression. For example the textblock may consist of 10 tokens immediately preceding the matching expression the matching expression itself and 10 tokens immediately following the matching expression.

Further processing logic applies a hash function H k to each token in the textblock processing block finds a set of tuples at H k in the hash table for each token in the textblock adds the tuples that have the same type as the corresponding tokens in the textblock to list L processing block regroups list L into a set of accumulators processing block sorts that list L by the length of each Ai processing block and checks for unique occurrences of columns in sorted list L processing block .

Afterwards processing logic determines whether the message has anymore expressions of the user specified format processing box . If this determination is positive the process transitions to processing block . Otherwise processing logic reports textblocks with Ai that exceed the predetermined size and have unique column numbers processing block .

Database query mechanisms are significantly different from the teachings described herein. One difference is that B trees actually contain fragments of the database tables that they index. In the approach described above there are no copies of the database data stored inside the index. The reason that this is important is that as mentioned above the DMS has to have a copy of the index in order to protect the data from escape however the DMS is also best deployed in a position in the network where it may be exposed to significant threats. Keeping the index that the DMS uses free of any components of the database data is a key requirement.

Another difference between standard database query mechanisms and the invention outlined here has to do with the types of queries that are required. The standard set of queries used in relational databases is based on predicate logic using connectives like AND and OR. This basic system does not work well for detection of database data that is typically cut and paste into email and webmail messages. Database data that is cut and paste into email messages is typically from reports and will often contain data in each line that is extraneous and not found inside the database table. An example could be an email message that contains for example account information for a bunch of customers. Such a message will contain plenty of records from the core database that requires protection e.g. first name last name social security number etc. but could also contain information not in the core database tables. A typical example is information that is joined from other databases. Another example is simple line formatting tokens that separate fields of database data. Because of the possibility of this extra data that s typically found on each of these lines the standard predicate logic connectives like AND and OR applied to each token on the line of an outgoing message produce either too many hits as is the case with OR or zero hits as is the case with AND . In the description herein the system is able to detect the presence of n or more tokens that are all from the same row of a database table even in the case where n is much smaller than the total number of tokens in the line. This is another significant difference between the present invention and the prior art mentioned above for database and document query mechanisms.

There are several major differences between the techniques described above and information retrieval technologies. Firstly the indices for these systems contain inside the concordances the same terms that are stored in the database that is to be protected. Here again since the system deploys this index into a location on the network that is potentially under hacker threat this is a definite disadvantage. Secondly these query systems run Boolean queries using the forms of predicate logic like AND and OR. As mentioned above this approach is at a distinct disadvantage for detecting database records that have been possibly joined with extraneous data from other tables.

The technique of file shingling is similar to but substantially different from the technique described herein. In file shingling the subject of interest is text data prose software outlines etc. . In the techniques described here the focus is on protecting database data. One difference is that database data from a given database table may appear with the row order or column order permuted arbitrarily in the test message. These permutations are the simple result of the query mechanisms typically applied to extract database data. A database query could result in a block of database data that comes in arbitrary column order and arbitrary row order. For this reason the basic technique of file shingling will not work if applied to database data. File shingling assumes that the same linear sequence is followed between the protected document and the test document.

There are many important differences between Internet content filtering systems and the teachings described herein. As mentioned above Internet content filtering systems are based on keyword searches. The novel techniques described above build an abstract data structure from the database data that it seeks to protect. This abstract data structure does not contain fragments of the text it is trying to protect. A keyword filtering system must contain some representation of the text that it is searching for in order to run its queries. The second major difference is that these Internet content filtering systems are not intended to protect database data. Using regular expression matching to detect violations of an organizations privacy policy on database data will also lead to a very inaccurate method of detection. These systems are primarily applied to stop employee abuse of the Internet as it relates to pornographic or abusive content and language. Such systems if applied to the protection of database data would use regular expressions to match database records. This would also result in transferring fragments of the database data to the computer on the network where security risks are maximized.

System further comprises a random access memory RAM or other dynamic storage device referred to as main memory coupled to bus for storing information and instructions to be executed by processor . Main memory also may be used for storing temporary variables or other intermediate information during execution of instructions by processor .

Computer system also comprises a read only memory ROM and or other static storage device coupled to bus for storing static information and instructions for processor and a data storage device such as a magnetic disk or optical disk and its corresponding disk drive. Data storage device is coupled to bus for storing information and instructions.

Computer system may further be coupled to a display device such as a cathode ray tube CRT or liquid crystal display LCD coupled to bus for displaying information to a computer user. An alphanumeric input device including alphanumeric and other keys may also be coupled to bus for communicating information and command selections to processor . An additional user input device is cursor control such as a mouse trackball trackpad stylus or cursor direction keys coupled to bus for communicating direction information and command selections to processor and for controlling cursor movement on display .

Another device that may be coupled to bus is hard copy device which may be used for printing instructions data or other information on a medium such as paper film or similar types of media. Furthermore a sound recording and playback device such as a speaker and or microphone may optionally be coupled to bus for audio interfacing with computer system . Another device that may be coupled to bus is a wired wireless communication capability to communication to a phone or handheld palm device.

Note that any or all of the components of system and associated hardware may be used in the present invention. However it can be appreciated that other configurations of the computer system may include some or all of the devices.

Whereas many alterations and modifications of the present invention will no doubt become apparent to a person of ordinary skill in the art after having read the foregoing description it is to be understood that any particular embodiment shown and described by way of illustration is in no way intended to be considered limiting. Therefore references to details of various embodiments are not intended to limit the scope of the claims which in themselves recite only those features regarded as essential to the invention.

