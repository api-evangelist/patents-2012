---

title: Prioritization and assignment manager for an integrated testing platform
abstract: A method of prioritizing and assigning test scripts is provided in a testing platform configured to organize, manage, and facilitate the debugging of test scripts. The test scripts are used in testing software modules. The method includes receiving a plurality of test scripts, applying a predetermined set of factors to each test script, and assigning a weight value to each factor based on a relative importance of the factor. A priority value is set for each test script based on the weighted factors, and the test script is assigned to a queue position for execution based on the corresponding priority value, where the assigned test script is associated with one or more bias factors. The test script is then selected from the testing queue and forwarded if the bias factors indicate that requirements of the test script match corresponding bias factors of the testing individual.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09286193&OS=09286193&RS=09286193
owner: Accenture Global Services Limited
number: 09286193
owner_city: Dublin
owner_country: IE
publication_date: 20120411
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 61 474 516 filed Apr. 12 2011 which is incorporated by reference in its entirety herein.

This disclosure relates to software testing and in particular this disclosure relates to an integrated platform for developing debugging and executing tests to insure the integrity and functionality of software systems.

The development of computer software involves a rigorous testing process to insure that the software functions as intended. During the testing process testers write various test scripts for performing different types of tests necessary to ensure that the computer software is functioning as designed. The testers also set up and run the test scripts while tracking the results and report the test result to appropriate personnel. This process is inefficient and time consuming and requires significant tester involvement.

Further as businesses continue to rely on computer software and complex software packages an increasing number of highly complex computer software has been developed to meet business demands. Due to the increased complexity and scale such software programs require a large scale testing process involving far more testers and test scripts than were required previously. Such increases are related to organizations centralizing their testing and moving to an outsourced testing model. Traditionally testing was embedded into the systems development life cycle SDLC for each project but now central discrete testing functions exist within organizations which test across multiple projects and releases.

Testing tools have been developed to assist the testers in performing the various steps of the testing process. However existing testing tools are not able to provide the required functionality and efficiency to overcome the challenges posed by the large scale testing process.

Testing of various products and or software products has increased in complexity and scope. In the past relatively small groups of designers and developers perhaps 10 to 30 in number developed various tests for testing and verifying the function of software modules or code segments. Such small groups of individuals have been manageable. However as the number of individuals contributing to the project becomes large redundancy and complexity increase which contributes to increased cost and an increase in the number of errors. Therefore a need exists to address the problems noted above.

The next generation testing NGT system provides a managed service platform for centralized development debugging and implementation of software testing where hundreds to perhaps thousands of individuals can collaborate in developing and implementing a very large array of modules or test scripts that form a suite of tests. The next generation testing system is not limited only to testing of software modules and may be used for the testing of hardware as well provided that test result signals and indicators that reflect the state of the hardware are provided to the testing system.

For example the next generation testing system may be used by an organization or software development house to test and verify the function and operation of a large software package or application or set of applications such as an accounting system an invoicing system an operating system version release or any other system. The next generation testing system may be used in a test factory where many hundreds of individuals perform final tests or quality control tests on the same or similar products for example a PC operating system testing prior to release.

The next generation testing system may be used to develop and debug the tests and may also be used to implement the final testing procedures to verify the release or final quality control of an actual product undergoing testing prior to shipping. The next generation testing system may be used to a plan and develop the testing of a product for release b plan and estimate the effort or manpower required to develop the testing process c manage the preparation process d manage the distribution of the test scripts to the testing personnel and e automate the test process.

A method of prioritizing and assigning test scripts is provided in an integrated testing platform where the testing platform is configured to organize manage and facilitate the debugging of test scripts prepared by a testing individual. The method includes receiving a plurality of test scripts applying a predetermined set of factors to each test script and assigning a weight value to each factor based on a relative importance of the factor. A priority value is set for each test script based on the weighted factors corresponding to the test script and the test script is assigned to a queue position for execution based on the corresponding priority value where the assigned test script is associated with one or more bias factors. A selected test script is then identified from the testing queue and forwarded to a testing individual if the bias factors indicate that requirements of the test script match corresponding bias factors of the testing individual. The test script may be assigned in real time when the tester clicks a get next icon.

Other embodiments of systems methods features and their corresponding advantages will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems methods features and advantages be included within this description be within the scope of the invention and be protected by the following claims.

Turning back to the test planning tool estimates and plans the preparation work and manpower requirements involved in the start of a particular software release. The test planning tool provides an indication of the plurality of skill sets required to test the various test scripts and the different skill groups associated with the testing personnel available. The test planning tool also provides assisted estimation. The test planning tool may use a three stage process to provide estimation at increasing levels of accuracy. Information is used from previous releases to improve estimates. Pluggable architecture for client specific calculations may be used. The test planning tool also provides deconstruction of requirements into tests.

The test planning tool assists the user in breaking down requirements into a required number of tests. Collaborative working capabilities allow a divide and conquer approach. The test planning tool further provides resource forecasting by skill. Early foresight of skills required to support the testing activities is made possible and graphical display of availability versus demand may be presented. The test planning tool further helps to shape the test organization by promoting cross skilling. The test planning tool also provides regression pack suggestions. Using a meta data driven approach the system suggests an appropriate regression pack. Risk based testing scores can be used to size the pack accordingly. The test planning tool essentially quantifies what items need to be tested what skill sets are required to perform the tests and whether the required skill sets are present in the resources provided.

The modular script designer is used to design new tests or test scripts in a modular way and increases the efficiency of the testing effort and the organization by maximizing the benefit of test scripts that have been written by other designers engineers or testing individuals. This avoids redundancy by reusing test scripts that others have created and which have been functionally verified.

The modular script designer provides for re use of modules rather than complete scripts as a test script is composed of several test modules and where each module represents a logical part of a test for example a login to an application.

Each test script created by a testing individual or test creator using the modular script designer includes associated data corresponding to approval history of the test script and the functional location or hierarchy of the test script with respect to other test scripts that are executed before and after the test script at issue. The associated data for a test script also includes a description of the function of the test script and a description identifying the products for which the test script is used.

Once a test script has been designed using the modular script designer it is saved and eventually uploaded to the standard test tool which is a separate and independent commercially available testing device or system used by the next generation testing system . As mentioned above the next generation testing system does not replace the low level or basic testing tool. For example the basic testing tool may be a Hewlett Packard HP Quality Center testing tool IBM Rational Quality Manager or other commercially available basic testing tool which may run under the control and direction of the next generation testing system . The next generation testing system is integrated with all of the various basic testing tools and allows communication to and from the various basic testing tools.

The PAM queue may be a list of the scripts in order of the priority for execution. The more urgent scripts to be executed are at the top of the list. The prioritization and assignment manager determines the order of the scripts within the PAM queue based on the PAM configuration . The PAM queue receives from the testing tool scripts that are scheduled for release. The testing tool may be a commercially available testing tool such as HP Quality Center .

When the testers access the get next feature via a user interface the prioritization and assignment manager distributes appropriate scripts and from the PAM queue to the appropriate testers and for execution respectively. The prioritization and assignment manager determines which script or to distribute to which tester based on the skills or experience and background of the testers and . Then the prioritization and assignment manager displays the script or to the assigned tester or through the modular script designer . After the scripts are distributed the prioritization and assignment manager displays to the testers and the details of the assigned scripts and .

After reviewing a script or the prioritization and assignment manager allows the testers to select an action from a plurality of actions. The plurality of actions may include for example accepting the script deferring the script escalating the script rejecting the script marking the script as out of scope or blocking the script . The prioritization and assignment manager may display the plurality of actions to the testers to select from a drop down menu.

For example if the prioritization and assignment manager assigns a script to a tester and the tester accepts the script the desktop toolbar loads the script for execution and the prioritization and assignment manager changes the status of the script to assign the identification of the tester . If the tester defers the script the prioritization and assignment manager prompts the tester to enter information regarding the deferral including a date and time until which the script should be deferred and a reason for deferring . If the tester escalates the script or rejects the script the prioritization and assignment manager prompts the tester to enter information about the escalation including a reason .

If the tester marks the script as out of scope the prioritization and assignment manager prompts the user to choose whether to raise or link to a defect which may be a new defect or an existing defect. If the tester chooses to link a defect the PAM permits the tester to choose a defect or defects to link to the script . If the tester blocks the script the prioritization and assignment manager prompts the tester to link the script with a new or existing defect and allows the test lead to un assign the script and override priority to increase priority of the script and re assign the script .

After the tester enters details or information such as a date time for deferring a script a reason for escalating or rejecting a script or links a script to a defect after marking a script as out of scope or blocking a script the prioritization and assignment manager lets the tester save the details or information for the script and sends the script back to the PAM queue . Alternatively the tester may choose not to save the details by canceling and closing the script from view .

The prioritization and assignment manager is an important element of the next generation testing system . The prioritization and assignment manager tracks all of the tests or test scripts in the suite of tests as part of a list in a database and assigns a priority to each of the individual test scripts based on a given set of prioritization factors and assignment factors.

Prioritization factors may be script attributes including for example impact of failure likelihood of failure lead time business priority estimated effort and test end date. The prioritization and assignment manager may use prioritization factors to assign a numeric rating to a script for stack ranking e.g. to evaluate a priority for execution of the script.

Assignment factors may be user attributes evaluated to weight a user against a set of scripts that are available for testing and may be a numerical value assigned to a script for an individual user. Assignment factors may include for example skills required skills of a tester status of a script script workstream tester workstream script author a user s previous experience with a script or its predecessor and information regarding the tester to whom the script is assigned. The prioritization and assignment manager may use assignment factors to assign a numeric value to a script for an individual user. The priority of a particular test script determines its position in the testing queue. The prioritization and assignment manager may use the prioritization factors and assignment factors together to match and assign a script to a user at the time of a request.

The prioritization and assignment manager provides a centralized automated prioritization of test scripts with real time assignment logic. All test scripts are prioritized based on a centralized set of factors which can be configured centrally to influence the entire test operation for example to improve performance against KPIs Key Process Indicators . The prioritization and assignment manager further provides a skill based assignment and provides a pull rather than a push approach. Testers may click a Get Next icon on their desktop screen to be assigned the next script to execute. The next script is chosen in real time based on weighted assignment factors.

Each of the factors used to assign priority to the test script may be weighted. In one example a developer may be presented with a screen having a plurality of sliders or buttons corresponding to each test script. Moving the slider to the right may increase the priority level associated with the corresponding test script while a moving the slider to the left may decrease the priority level associated with the corresponding test script. Thus the tester may assign a priority level to a test script based on the tester s judgment and expertise. The prioritization of the various test scripts may affect the relationship and interaction between all of the various test scripts. The prioritization and assignment manager may perform the prioritization function in a batch mode after receiving input from the test script creator.

Some of the factors associated with the assigned priority of the test scripts may have feedback or decision tree capability so that for example if a test is performed and returns a failure indication the prioritization and assignment manager can identify the other test scripts which may be impacted by the failure.

The prioritization and assignment manager also assigns a set of skills to each of the test scripts in the next generation testing system to optimize use of the work force personnel. For example various test scripts are assigned to testing personnel based on the skill set of the particular testing individual. For example a tester may click a Get Next button or icon on a screen to request that a new test script be sent to that tester. The prioritization and assignment manager may access a database containing the skill sets of each tester and assign the next highest priority test script to that tester based on the tester s skill set and the skill set required by the test script so as to optimize the productivity of the system and the testing personnel overall. Once the tester receives the test script he or she will run the test script.

The prioritization and assignment manager may also provide a pluggable framework for new factors. New decision factors can be added by defining a new factor class. The factor may be presented through the user interface and can be weighted in the decision logic. This could be used to enable advanced Applied Statistic decision models.

The following table shows a list of PAM configuration factors that may be used in a prioritization and assignment manager . Each factor may be associated with a ranking or weighting that may be configured for each project. Rankings may be numbers assigned to elements of a factor for example high medium or low and may be elements of factors such as impact of failure IOF business priority BP and likelihood of failure LOF factors. Weightings may be numeric values assigned to the factor itself and may be a value between 0 and 1 at increments of 0.1. Other implementations may include fewer additional or other weightings and factors.

The prioritization and assignment manager may designate a subset of factors that are rated for prioritization and assignment with help from supporting factors. Ratable factors may include for example prioritization factors such as impact of failure likelihood of failure business priority and lead time and assignment factors such as author bias history bias home team bias and skills match.

Factors may be divided into types or categories including enabler factors which may be factors that help determine whether a script can be included for assignment consideration e.g. whether a script can be included in a prioritization queue or an assignment queue factors for calculating ratings and holding data that are directly used in rating calculations factor data which may be factors that provide additional information about a script or user factor weighting which may be project level configuration data used to normalize ratings to reflect business preference and configurable factors which may be multiple factors that are configurable by test leads or managers.

The following table shows examples of factors types for each factor and data source for each factor. Other implementations may include fewer additional or other factors types and sources.

In one embodiment the prioritization and assignment manager may include a prequeue a priority queue an assignment queue and a status queue. The prequeue may be a list of all scripts in the current release. The priority queue may be a list of scripts sorted in descending order by script prioritization ratings. The assignment queue may be a transitory queue created in the memory of the prioritization and assignment manager when a tester requests a script assignment. The assignment queue may include a subset of the priority queue. The status queue may be a state maintenance table and may be linked to the priority queue and assignment queue.

The prequeue may store all attributes for each script to support generation of a priority queue and an assignment queue and to improve performance of the prioritization and assignment manager . The prioritization and assignment manager determines which scripts to store in the prequeue by the script release start date and script release end date. If the prequeue baseline date falls between the script release start date and the script release end date then the script is in the current release and the prioritization and assignment manager stores the script in the prequeue. The prequeue table may store data using common data types which may be source types translated into common prequeue data types common status codes which may be source status codes translated into common PAM status codes and source to destination column mapping which may be source columns mapped to common prequeue columns. The prioritization and assignment manager may use the prequeue to connect to external testing systems to extract data from the external testing systems with a provider pattern to load the data into the prequeue table.

The prioritization and assignment manager may determine which scripts to store in the priority queue based on the test set open date and test set closed date for each script. If the priority queue baseline date is between the test set open date and the test set closed date for a script then the prioritization and assignment manager stores the script in the priority queue. Prioritization ratings may include impact of failure rating likelihood of failure rating business priority rating and lead time rating.

The impact of failure IOF rating may be calculated as shown in Equation 1 below. IOF rating IOF factor IOF weighting Eqn. 1 

The likelihood of failure LOF rating may be calculated as shown in Equation 2 below. LOF rating LOF factor LOF weighting Eqn. 2 

The business priority BP rating may be calculated as shown in Equation 3 below. BP rating BP factor BP weighting Eqn. 3 

The lead time LT rating may be calculated as shown in Equation 4 below. LT rating EstimatedEffort LT days TestSet closed date EstimatedEffort LT days LT weighting Eqn. 4 

The NGT priority rating may be equal to the sum of all prioritization ratings. Scripts in the priority queue may be sorted by the NGT priority rating of each script. The prioritization and assignment manager may use the priority queue to assign scripts to a tester on demand for example when a tester clicks a Get Next button or icon to request a next script to test.

When a tester requests a next script for testing the prioritization and assignment manager may generate the assignment queue based on the following enabler factors skills required NGT status exclude blocked script and calendar. The prioritization and assignment manager may include in the assignment queue scripts that have skills required that are part of a user s active skills. The prioritization and assignment manager may also include in the assignment queue scripts that have NGT status of rejected escalated deferred assigned or preassigned. The prioritization and assignment manager may further include scripts that have an exclude block script factor set to N indicating that the script is not excluded or blocked.

The prioritization and assignment manager may exclude from the assignment queue scripts that have an estimated test completion date that overlaps with a user holiday calendar where the estimated completion date ECD may be calculated as shown in Equations 5 and 6 below. ECD today s date total number of days for testing Eqn. 5 total number of days for testing EstimatedEffort LT Eqn. 6 

For example if a user holiday starts on a leave start date and ends on a leave end date a script may be included in the assignment queue if the estimated completion date falls before or is less than the leave start date. But the script is not included in the assignment queue if the estimated completion date of the script is greater than the leave start date.

The prioritization and assignment manager may determine the order in which skills are listed in the assignment queue based on assignment ratings including for example author bias rating history bias rating home team bias rating and skills match rating. The prioritization and assignment manager may determine the author bias rating as follows if script author is the end user then author bias rating is equal to author bias weighting otherwise the author bias rating is zero. History bias may indicate whether a particular user has previously executed a version of the script. The prioritization and assignment manager may determine the history bias rating as follows if the end user tested the script or a previous version of the script in the past then the history bias rating is equal to the history bias weighting otherwise the history bias rating is zero. The prioritization and assignment manager may obtain script execution history records from the external testing tool or script execution history records may be stored in a database. The prioritization and assignment manager may determine the skills match rating as follows select a subset of scripts from the priority queue based on the testing tool instance e.g. a project within an external testing tool and taking into account assignment enabler factors for each script in the subset the skills match rating is equal to the count of non mandatory matched skills divided by the count of mandatory skills multiplied by the skills match weighting.

The prioritization and assignment manager may further calculate NGT assignment rating as shown in Equation 7 below. NGT assignment rating assignment ratings assignment weighting NGT priority rating NGT priority weighting Eqn. 7 

Scripts in the assignment queue may be sorted in descending order by the NGT assignment rating. The prioritization and assignment manager may assign scripts to a tester in order of NGT assignment rating beginning with the script with the highest NGT assignment rating.

The prioritization and assignment manager may use the status queue to decouple user actions against an instance of a script during script assignment or override from queue refreshing. When a script status is assigned or rejected the prioritization and assignment manager will retain the script state even if the priority queue is dropped or recreated. Script state may refer to PAM attributes associated with a script instance in the priority queue. The status queue may retain the attributes so that the prioritization and assignment manager may continue to assign scripts while the priority queue is being regenerated.

The prioritization and assignment manager may prioritize tests according the following characteristics 

Priority based ordering The ability to prioritize tests based on the Risk Based Testing value associated with each test and the associated business priority 

Defect Impact Tests that have defects blocking them should be moved to the bottom of the queue and tests with defects against one of the modules in the script should be moved down the queue 

Data Availability Tests that have no data available should be move to the bottom of the queue and tests with limited data available should be moved down the list 

Pull Model The assignment model may be a pull model e.g. the testers may request their next test through the GUI and the system will assign the next test 

Prep Execute Assignment The system may assign both test preparation and execution work to the testers 

Automation Assignment The ability to assign scripts that are automated to the automation controller rather than sending the script to a manual tester 

Override Priority Allow test managers to override the priority of certain scripts or scenarios to ensure execution at a particular date or time and

Pre Requisite Management Verify that pre requisites are met before assigning out a script where prerequisites may include time related requirements e.g. must be executed out of hours and dependent script requirements e.g. must be run after a successful execution of script X .

The Additional Factors tab may allow the tester to enter additional information regarding releases. The Additional Rating Factor tab may have a Releases dropdown which includes releases from test tool. The user may select a release from dropdown which displays Release Start Date and Release End Date for the release and a list of cycles belonging to the release. A Warranty Period days dropdown menu may allow the user to set a warranty period of the release with values from 0 100. Then the prioritization and assignment manager may display on the Additional Factors tab the Release Cycle Name Release Cycle Priority Release Cycle Activation and Release Cycle Complexity in columns for each cycle in the release. The Release Cycle Name column may include the name of each cycle. The Release Cycle Priority column may include a textbox to input a value from 0 to 100 default value is 0 which may indicate the probability of automated assignment of script from that cycle. The Release Cycle Activation column may include a dropdown with values including Assign scripts until cycle End Date allows assignment of script till cycle s end date Assign scripts past cycle End Date allows assignment of the script past cycle end date but within warranty period of release and Don t assign scripts from this cycle prevents assignment of script in that cycle . The Release Cycle Complexity column may include a dropdown with complexity values including Very Complex Complex Medium Simple and Very Simple. Complexity values may indicate the proficiency level of a skill that is preferred for testing the script. The prioritization and assignment manager may assign a script to a tester who has skills matching the proficiency level indicated. The user may click a Save button to save the selected values of Release Cycles to a database or a Cancel button to close the tab without saving the selected values.

The prioritization and assignment manager may also process legacy scripts which are scripts that are not modularized. Modularization is the process of grouping tests into small modules that describe a piece of functionality. The modules combine together to form test scripts or cases. The prioritization and assignment manager may process the legacy scripts through a legacy script user interface. The legacy script user interface may maintain the following factors for legacy scripts likelihood of failure impact of failure lead time business priority and script skills required. The legacy script user interface may allow a user to search the QC lab and display legacy scripts to the user and may allow the user to modify the factors maintained.

The test execution toolbar is a toolbar visible on the tester s computer screen and provides an indication of every major tool available to the tester and every major test that the tester may or must invoke. It is conveniently displayed to the tester to increase efficiency. The test execution toolbar may provide in line test execution. The test execution toolbar allows a tester to load a test execute the test and record the status from the toolbar. Test scripts can be opened directly within the toolbar which saves room on a tester s desktop and avoids certain keystrokes such as ALT Tabbing between screens. Defect raising and screen capture may be part of the process. The text execution tool bar may also provide an embedded approvals lists. All module script approvals may be shown in the toolbar and an approver can quickly open the relevant script module for approval. The test execution toolbar also allows quick access to all NGT tools. A quick launch bar may be provided to enable the tester to quickly access all of the NGT tools. The toolbar may also handle login management for NGT. A user profile section is available to change user information. The test execution toolbar is also dockable with an auto hide function. The test execution toolbar may be docked to the left hand side of the screen and it can be selected to be visible or auto hide. An extendable framework allows additional panels to be added to the toolbar. The test execution toolbar may be integrated with the prioritization and assignment manager to allow a tester to request the next test that should be run.

The automation controller is an application that may run on a virtual machine such as in a server farm or a computing machine in a cloud environment. The automation controller may communicate with the prioritization and assignment manager to request the next test script in the testing queue and facilitate opening of the test script using the basic testing tool described above such as HP Quick Test Pro.

The automation controller may execute the test script using the basic testing tool and record the results back into the basic testing tool. The next test script is then requested and the process is repeated. The automation controller further provides modular design and partial automation. Automation scripts may be developed as modules and each automation module may have one or more manual modules mapped against it. Partial automation enables rapid execution of automated parts of scripts. Essentially the automation control is used where applicable to automate the execution of test scripts.

An additional feature of the automation controller seeks to maximize the return on investment or ROI associated with each test script that is run automatically. The automation controller selects for automation the test scripts that provide the greatest ROI collectively. The choice whether to automate a particular test script using the automation controller may be based on the ROI associated with the test script. For example a particular test script may be a test script that handles initial login by a user. Because a test script that handles initial login by user may be used by hundreds of different test scripts without variation this testing script provides a high ROI and as such may be a good candidate for automation. The ROI essentially is a measure of increased efficiency attained by automation of the test script.

The test data supply chain creates a mapping between the test script and the type or quantity of data that is required by the test script in order to execute properly. When the test script is created using the modular script designer the creator specifies the type of data that is required for the test script and specifies the type of output data generated as a result of running the test script essentially quantifying the input and output parameters of the test script. As different test scripts are added to the queue of test scripts to be handled by the prioritization and assignment manager and executed thereafter the test data supply chain organizes the test scripts in an efficient manner so as to optimize management of the input data required by the corresponding test script.

The test data supply chain may provide a data catalogue. Data types are modeled and stored in a database. The test data team can check data in and out of the catalogue. Also rules can be specified to enable basic data mining. The test data supply chain also provides mapping data to test scripts. During preparation the data type required is selected against the script. Also using the modular script designer data parameters can be mapped directly to script parameters to allow automated assignment at run time. The test data supply chain further provides monitoring of stock levels and re ordering. The test data supply chain can monitor demand versus capacity for all types of data and as data gets used by test scripts the levels are updated. The test data supply chain can order additional data from the data team or via an automated provision. The test data supply chain may also be integrated with the PAM . The stock levels can be used during prioritization to avoid running scripts that do not have available test data or where stock levels are low.

For example if fifty specific test scripts require input data type A and twenty seven specific test scripts require input data type B the test data supply chain may organize the required data types for each script and provides the data to the test script in a just in time manner to avoid redundancy and reduce complexity. Further such test data may change throughout the lifecycle of the testing process based on the results of a particular test. Accordingly the test data supply chain tracks the required changes and updates the data sets required for the corresponding test scripts so that as the test scripts are being executed up to date test data is available to the test script.

The reporting portal handles the reporting functions for the next generation testing system . The reporting portal may be based on the Microsoft Business Intelligence system which is a commercially available software package. The reporting portal also includes an off line data warehouse DW to avoid testing tool degradation. An off line DW may be maintained to avoid queries directly on the external testing tool. A dimension based data model is used for simplified reporting. Further data is pre aggregated in a multidimensional online analytical processing MOLAP database to provide quick analysis. The reporting portal further provides cube based metrics and KPIs. Using SS Analysis Services measures and targets may have been pre defined which can be included into reports. PowerPivot a spreadsheet add in available from Microsoft Corporation allows data to be quickly analyzed in spreadsheet programs such as Microsoft Excel for ad hoc reports. Further the reporting portal provides integration with solutions such as Microsoft SharePoint . Where data from systems other than the HP Quality Center is required for example financial production data the solution can receive data from solutions such as Microsoft SharePoint . The SSIS component allows the solution to be easily extended to direct data sources where required. The reporting portal provides an interface to the various modules of the next generation testing system and handles all of the report generation report format manipulation and other reporting functions.

The defect management tool permits each testing individual to quickly identify and track defects in the testing process. When raising new defect various fields of the defect will be pre populated based on the current test that is being executed. The defect management tool may simplify the process for raising tracking and updating defects. The defect management tool may provide a defect watch list. Toolbar based list of defects with real time Red Amber or Green RAG status indicators may be provided. Red status indicates that a defect is not actively being resolved amber status indicates that the defect is in the process of being resolved and green indicates that the defect is resolved. The defect management tool may allow quick access to full information of the defects to see the latest status. The defect management tool may also provide in line defect raising with test history. While executing a test through the toolbar screenshots and test steps may be captured. When a defect is raised this information is pre populated in the defect. Screenshots and other attachments can be uploaded directly. The defect management tool also reduces alt tab operations. By including core defect management in the toolbar the defect management tool is able to reduce the need to alt tab into an external testing system such as the HP Quality Center . The defect management tool also enables automated un blocking of scripts to further avoid time spent in the external testing system. The defect management tool further provides team based views. Managers have a team view to enable them to see the defects currently impacting their team with the relevant size and status.

The prioritization and assignment manager test data supply chain and its associated controller may reside on a server or central server along with a workflow system configured to schedule and handle execution of various tasks. However multiple servers may also be used. The workflow system may be provided by Microsoft Windows Workflow Foundation which also may execute on one or more of the servers.

An integration layer provides communication and functionality between the unified desktop a database the prioritization and assignment manager and the test data supply chain . The database stores all of the test scripts and other required data. The integration layer may be a dll file resident on the servers and on the client machine such as the unified desktop and functions as a common API interface. The integration layer is decoupled from the downstream basic testing tools such as an HP Quality Center tool or an IBM Rational Quality Manager by virtue of a pluggable architecture.

The prioritization and assignment manager and the test data supply chain and its associated controller execute under the workflow system which resides on the server . The automation controller preferably resides on a separate and independent server or set of servers . The server that runs the automation controller may be similar to the computer that runs the unified desktop because the automation controller essentially emulates the unified desktop when executing test scripts.

The automation controller receives the prioritized test scripts from the prioritization and assignment manager and accesses multiple virtual machines to perform its tests. The virtual machines may be cloud based machines. Each virtual machine includes a functional automation tool such as Hewlett Packard s HP Quick Test Pro referred to as QTP which receives the test script from the prioritization and assignment manager and then executes the actual test script. Results from the test are reported back through the integration layer .

The next generation testing system and may be embodied as a system cooperating with computer hardware components and or as computer implemented methods. The next generation testing system may include a plurality of software modules or subsystems. The modules or subsystems may be implemented in hardware software firmware or any combination of hardware software and firmware and may or may not reside within a single physical or logical space. For example the modules or subsystems referred to in this document and which may or may not be shown in the drawings may be remotely located from each other and may be coupled by a communication network.

The computer or machine may be a personal computer or a server and may include various hardware components such as RAM ROM hard disk storage cache memory database storage and the like also referred to as memory subsystem . The computer may include any suitable processing device such as a computer microprocessor RISC processor reduced instruction set computer CISC processor complex instruction set computer mainframe computer work station single chip computer distributed processor server controller micro controller discrete logic computer and the like as is known in the art. For example the processing device may be an Intel Pentium microprocessor x86 compatible microprocessor or equivalent device and may be incorporated into a server a personal computer or any suitable computing platform.

The memory subsystem may include any suitable storage components such as RAM EPROM electrically programmable ROM flash memory dynamic memory static memory FIFO first in first out memory LIFO last in first out memory circular memory semiconductor memory bubble memory buffer memory disk memory optical memory cache memory and the like. Any suitable form of memory may be used whether fixed storage on a magnetic medium storage in a semiconductor device or remote storage accessible through a communication link. A user or system interface may be coupled to the computer and may include various input devices such as switches selectable by the system manager and or a keyboard. The user interface also may include suitable output devices such as an LCD display a CRT various LED indicators a printer and or a speech output device as is known in the art.

To facilitate communication between the computer and external sources a communication interface may be operatively coupled to the computer system. The communication interface may be for example a local area network such as an Ethernet network intranet Internet or other suitable network . The communication interface may also be connected to a public switched telephone network PSTN or POTS plain old telephone system which may facilitate communication via the Internet . Any suitable commercially available communication device or network may be used.

Integration layer provides backend agnostic access to the upstream layers business components layer and presentation layer and enables plug ability via a common interface to one or more backend systems such as QC Rational and Team Foundation Server. Integration layer implements the following design pattern an abstract base class inherits from ProvideBase which is a class available with Microsoft s .Net framework each concrete implementer in turn inherits from the abstract class above Appropriated Provider which may be an NGT component that communicates with a backend system such as QC is loaded based on type definition in a .config file. The integration layer also includes the integration fa ade . Integration fa ade exposes a simplified interface to the business components layer and reads data from a combination of data transfer objects from one or more backend repository or cache e.g. Windows Server R2 and merges them to a common super data transfer object to return to the business components layer . Integration layer also includes NGT components which interface between the integration fa ade and the data layer and may provide mapping functionality for the integration layer if required. The integration layer also includes caching components and testing tool components . Testing tool components are providers servicing requests for data read write from a Testing Tool .

The data layer includes data access components which centralize the logic necessary to access underlying NGT data store exposing methods to allow easier and transparent access to the database. It also includes data helper utilities which are used to centralizing generic data access functionality such as managing database connections. The data layer also includes service agents which provide Windows Communication Foundation services proxy for talking to application server services. The data layer may be an Enterprise Library Data Access Application Block or a custom designed data layer. Alternatively object relational mapping tools such as Entity Spaces available from EntitySpaces LLP Genome available from TechTalk GmbH LINQ to SQL available from Microsoft Corporation Entity Framework also available from Microsoft Corporation or LLBLGen Pro available from Solutions Design may be used to generate the data layer components.

Cross cutting functions in the NGT may include for example security exceptions handling locking and communication. The NGT may also include a local cache . Outputs from the NGT may include for example email functionality or other information communication functionality. Emails may include notifications to testers regarding script rejection or approval notifications to approvers regarding scripts that are ready for review and notifications regarding security concerns system exceptions and auditing. The NGT may also communicate information to testing tool and an NGT database .

The logic circuitry and processing described above may be encoded or stored in a machine readable or computer readable medium such as a compact disc read only memory CDROM magnetic or optical disk flash memory random access memory RAM or read only memory ROM erasable programmable read only memory EPROM or other machine readable medium as for examples instructions for execution by a processor controller or other processing device.

The medium may be implemented as any device that contains stores communicates propagates or transports executable instructions for use by or in connection with an instruction executable system apparatus or device. Alternatively or additionally the logic may be implemented as analog or digital logic using hardware such as one or more integrated circuits or one or more processors executing instructions or in software in an application programming interface API or in a Dynamic Link Library DLL functions available in a shared memory or defined as local or remote procedure calls or as a combination of hardware and software.

In other implementations the logic may be represented in a signal or a propagated signal medium. For example the instructions that implement the logic of any given program may take the form of an electronic magnetic optical electromagnetic infrared or other type of signal. The systems described above may receive such a signal at a communication interface such as an optical fiber interface antenna or other analog or digital signal interface recover the instructions from the signal store them in a machine readable memory and or execute them with a processor.

The systems may include additional or different logic and may be implemented in many different ways. A processor may be implemented as a controller microprocessor microcontroller application specific integrated circuit ASIC discrete logic or a combination of other types of circuits or logic. Similarly memories may be DRAM SRAM Flash or other types of memory. Parameters e.g. conditions and thresholds and other data structures may be separately stored and managed may be incorporated into a single memory or database or may be logically and physically organized in many different ways. Programs and instructions may be parts of a single program separate programs or distributed across several memories and processors.

While various embodiments of the invention have been described it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the invention. Accordingly the invention is not to be restricted except in light of the attached claims and their equivalents.

