---

title: Storyline presentation of content
abstract: Described herein are systems and methods for generating one or more storylines of content. Tags descriptive of events in the content are generated. Based at least in part on the tags, a storyline is generated from the tags describing the related events throughout the content. Some storylines may comprise multiple tags. A user may select one or more storylines for presentation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09430115&OS=09430115&RS=09430115
owner: Amazon Technologies, Inc.
number: 09430115
owner_city: Reno
owner_country: US
publication_date: 20121023
---
Broadcast distribution of content such as video audio and so forth has formed a particular style of accessing and presenting content to users. A user would consume content transmitted in a serial fashion being presented with portions of the content whether desired or not. As a result the user may be faced with wasting time watching or listening to content which is not of interest to them.

Pre recorded content such as videotapes digital versatile disks DVDs audio cassette tapes and so forth provide users the capability to fast forward or skip ahead to another scene. However these capabilities are cumbersome and may result in an undesirable user experience.

Certain implementations will now be described more fully below with reference to the accompanying drawings in which various implementations and or aspects are shown. However various aspects may be implemented in many different forms and should not be construed as limited to the implementations set forth herein. Like numbers refer to like elements throughout.

User may access a wide variety of content including video audio electronic books eBooks and more. This content may be pre recorded and streamed to devices such as televisions smartphones tablets in vehicle entertainment systems and so forth for consumption. Traditionally users have been able to consume content in a linear fashion defined by the broadcaster or content producer. For example a movie played on a broadcast television channel is presented and the user watches from beginning to end.

As described above users have the capability to fast forward or skip ahead in some pre recorded content such as videotapes digital versatile disks DVDs audio cassette tapes and so forth. However these capabilities are cumbersome and may result in an undesirable user experience. For example a user wishing to skip ahead through video content on a DVD either resorts to fast forwarding through the content or using a skip to the next scene which may go farther than the user wishes. Furthermore this interaction still calls for manual intervention.

Described in this application are systems and methods for generating storylines associated with content. Within the content certain events may take place such as a particular character being on screen a particular topic or subject being discussed particular voice and so forth. For example in a video an event may be the lead character being in an image frame. In another example in an audiobook an event may be dialogue associated with a particular character or voiced by a particular character.

A tag may be associated with these events. The tag stores information descriptive of the event. For example the tag may contain information identifying a character appearing in the video and a start and stop time for that appearance. One or more of the tags may be embedded within the content or stored in a file associated with the content.

A storyline may be generated from these tags. The storyline is an association of tags and their underlying events across time in the content. For example several tags may indicate the presence of a particular character in various portions of a television episode. A storyline associated with that character may be generated from those tags.

The storyline may be used to present the content on a device to the user. For example the user may wish to view only portions of the content which include the particular character of interest. Instead of inconveniently manually fast forwarding through the content the user may select the storyline for that character. During presentation of the storyline the portions of the content which are designated in the storyline are presented. Portions of the content which are not designated in the storyline are omitted from presentation.

The storylines may be based on a character actor location object activity theme and so forth. For example a baseball game may include storylines for particular athletes color commentary background of the athletes when the ball is in play and so forth. A single storyline may be presented or two or more storylines may be presented concurrently. Continuing the example the user may select a storyline presenting the performance of a particular athlete or a storyline which presents the performances of all athletes but omits opening and closing ceremonies color commentary and other portions of the content.

Storylines may change over time. For example a storyline may extend across a series of pieces of content including television episodes movies and so forth. As new content is added to the series the associated storylines may be updated to reflect this new content.

Presenting content using the storylines may improve the user experience by allowing the user to consume content which is most meaningful to them. Furthermore by providing different storylines for the same content new avenues for production distribution licensing and presentation are opened. For example users may purchase rights to have different storylines for the same content presented.

A content interface is depicted as presented by a device . The content interface may present several storylines associated with a particular piece of content. In this example the particular piece of content is a Western film entitled Burnt Sage. Storylines are depicted for a location such as Ed s Mercantile characters such as Johnny and Chet and activities such as Riding. A user may select one or more of these storylines to watch.

The device may be a television set top box smartphone table portable computer desktop computer in vehicle entertainment system and so forth. The device may comprise one or more processors one or more memories one or more displays one or more input output I O interfaces and one or more network interfaces . The device may include other devices not depicted here such as speakers.

The processor may comprise one or more cores and is configured to access and execute at least in part instructions stored in the one or more memories . The one or more memories comprise one or more computer readable storage media CRSM . The one or more memories may include but are not limited to random access memory RAM flash RAM magnetic media optical media and so forth. The one or more memories may be volatile in that information is retained while providing power or non volatile in that information is retained without providing power.

The display is configured to present visual information to the user. The display may comprise a reflective or emissive display configured to present images to the user. An emissive display emits light to form an image. Emissive displays include but are not limited to backlit liquid crystal displays plasma displays cathode ray tubes light emitting diodes image projectors and so forth. Reflective displays use incident light to form an image. This incident light may be provided by the sun general illumination in the room a reading light and so forth. Reflective displays include but are not limited to electrophoretic displays interferometric displays cholesteric displays and so forth. The display may be configured to present images in monochrome color or both. In some implementations the display of the device may use emissive reflective or combination displays with emissive and reflective elements.

The one or more I O interfaces may also be provided in the device . These I O interfaces allow for coupling devices such as keyboards joysticks touch sensors cameras microphones speakers haptic output devices external memories and so forth to the device .

The one or more network interfaces provide for the transfer of data between the device and another device directly such as in a peer to peer fashion via the network or both. The network interfaces may include but are not limited to personal area networks PANs wired local area networks LANs wireless local area networks WLANs wireless wide area networks WWANs and so forth. The network interfaces may utilize acoustic radio frequency optical or other signals to exchange data between the device and other devices such as one or more server . . . S another device and the so forth. As used herein letters in parenthesis such as S indicate an integer value greater than zero.

The one or more memories may store instructions or modules for execution by the processor s to perform certain actions or functions. The following modules are included by way of illustration and not as a limitation. Furthermore while the modules are depicted as stored in the memory in some implementations these modules may be stored at least in part in external memory such as in the server which is accessible to the device via the network . These modules may include an operating system module configured to manage hardware resources such as the I O interfaces and provide various services to applications or modules executing on the processor .

A content presentation module is configured to present content such as with the display . The content presentation module may access the content from the memory or retrieve at least a portion of the content from the server using the network . A content interface module is configured to provide a user interface such as the content interface described above. The content interface module provides one or more user interfaces and is configured to accept and process input from the user.

The device may receive data from the server using the network . The data may include one or more of the content content metadata one or more tags or one or more storylines . As described above the content may comprise audio video electronic books and so forth.

The content metadata provides information about the content such as title genre cast of characters and so forth. The content metadata is discussed in more detail below with regard to .

The tags provide machine readable information about events taking place at a particular point in the content . For example the tag may comprise markup language data indicating a particular character has appeared in the scene and start and stop times for that appearance. The tags are described in more detail below with regard to .

The storylines are based at least in part on associating tags with similar or the same information across time in one or more pieces of the content . For example tags which reference the same character may be combined to provide a character storyline . The storylines may also include several different tags .

The storyline may manifest across more than one piece of content . Over time a collection of one or more tags which define a particular storyline may change. For example a storyline about a particular character may be modified over time when the character marries. Or a storyline following a plot may be combined with other storylines at later times or be bifurcated as new sub plots are formed. As a result the set of one or more tags which define a storyline in the first few episodes of a series of content may differ from that storyline at the conclusion of the series. Generation composition and use of the tags and the storylines are discussed below in more detail.

Intrinsic within the content are one or more events . The events may include but are not limited to the appearance of a character a scene recorded in a particular location presentation of an object a particular activity dialogue or discussion on a particular topic a particular sound and so forth. In one implementation the events are some thing or action perceptible to the user during presentation of the content .

The events may correspond to an entire scene may occur within a scene or may occur across several scenes. For example the event of an appearance of a particular character may extend across three contiguous scenes while the event of appearance of a particular object may only appear for a few moments within a scene. Each event has at least one corresponding occurrence time which specifies the point or interval in the content at which the event takes place.

The content metadata may include a title a genre data about characters casting production data related content and other data M . The title provides data about the title of the content . For example the title of the content in the illustrations is Burnt Sage. The genre indicates one or more categories to which the content has been designated. Continuing the example the genre of the content may be Western Adventure. 

The character casting data may indicate the cast of characters and actors associated with those characters. For example the content may have the characters of Ed Chet and Johnny which are played by Clint Woods John Morrison and Harry Coburn respectively. Production data may include data such as year filmed filming locations and so forth. The related content may indicate other pieces of content . . . N which are affiliated with the content such as sequels spin offs and so forth.

The server or in some implementations the device may generate one or more of the tags based at least in part on the content . The content metadata may also be used as well to generate the tags .

As described above the tags provide machine readable information about events taking place at a particular point in the content . In some implementations this encoding may use a markup language such as extensible markup language XML . In this illustration the tags include a description and an occurrence time . The description provides information about the event which is associated with the tag . For example the tag encodes information describing that the scene takes place in Ed s Mercantile . The occurrence time may specify a particular point in time in the content or an interval within the content such as shown here.

In some implementations the tags may include reference information associating the tag with a particular portion of the content or designating the particular portion of the content at which the event described by the tag occurs. For example as shown here the occurrence time specifies a start time and an end time for when the location of Ed s Mercantile is presented. While times are shown other referents may be used such as frame number byte count and so forth.

The tag may include a reference to one or more occurrence times in the content. For example a single tag with the description of Chet may contain information as to all of the occurrence times at which Chet appears in the content .

In other implementations the tags may be placed into a data structure or otherwise associated with particular portions of the content . For example the tags may be embedded within the video data .

A given portion of a scene of the content may have many tags associated with it or none whatsoever. For example the end credits of a movie may have tags indicating the topic of credits while a busy street scene may have many tags describing the actors location objects and so forth.

Once the tags associated with the content are available one or more storylines may be generated. Generation of the tags and the storylines is discussed below in more detail with regard to the server in .

Four storylines are depicted in this illustration. A location storyline two character storylines and an activity storyline . As illustrated the storylines are made up of a series of events . In this representation the storylines are associated with a root which indicates the title of the content . In some implementations the storylines may extend across multiple pieces of content. For example the root and the storylines may extend across the movie Burnt Sage as well as the episodes of the television series Burnt Sage Revisited and a sequel movie Burnt Sage the Sodbusters. Furthermore the storylines may include different types of content. For example the storylines may include different forms of content such as video audio only content such as audiobooks text such as from eBooks and so forth which are in the Burnt Sage series.

The storylines in this representation may have a sample image . The sample image may be acquired from a portion of the content present in the respective storyline. For example for the location storyline the sample image is of a scene in which the location Ed s Mercantile is shown.

The location storyline comprises events as described by tags which relate to a particular location. This may be a particular location within the content or a particular location used in generating the content . For example the location storyline may be the name of the location in the content such as Ed s Mercantile or may an actual location used during filming such as Backlot Stage in Burbank Calif.

The character storylines and comprise events as described by tags which relate to one or more characters. For example the storyline is based on the tags which reference the character Johnny while the storyline is based on those tags which reference the character Chet. As mentioned above the storylines may extend across multiple pieces of content. For example the storyline for the character Johnny may include occurrences and information from that character s other appearances in Burnt Sage Revisited and Burnt Sage the Sodbuster. 

The activity storyline comprises events as described by tags which relate to one or more actions or activities. For example as shown here the activity of Riding will associate into a single storyline those events which have tags associated with cowboys as well as tags associated with horses.

A cursor or other indicator may be used to provide the user with feedback as to which of the one or more storylines are selected for presentation. As described above the user may select for presentation a single storyline or several storylines . In one implementation the presentation may be serial in that a first storyline is presented then and so forth. In another implementation the user may select to present the multiple storylines concurrently. For example the user may select to present the character storyline about Johnny along with the activity storyline of riding so that while watching the movie the user will see content which includes Johnny or horseback riding.

In this implementation an element representative of the complete content timeline is depicted along with a current location being presented. This element provides a linear timeline of the content. Positions relative to the complete content timeline may be proportionate to the time within the content . For example a position at the extreme left of the complete content timeline is associated with the beginning of the content while the extreme right is associated with the end. In this example the location currently being presented on the display is at time 00 12.

Here the character storyline and the activity storyline are presented. Indicators are used to represent locations within the content at which the events specified in the tags are present. For example indicator illustrated as upside down triangles corresponds to portions of the content in which horseback riding has been tagged. Similarly indicator illustrated as a star corresponds to portions of the content in which the character Chet appears.

A duration indicator of the events as tagged may be provided. As described above the tags may include information such as start and end times within the content . From this information or similar information the duration of the event may be determined and the duration indicator may be presented.

Navigation controls or other controls may be presented in the user interface . These controls may allow the user to scroll or otherwise move among the different storylines available. In some implementations the user interface may also present controls allowing the user to build a storyline for tags associated with the content .

Similar to that described above with regard to in some implementations a cursor sample image and so forth may be presented in the user interface .

In this illustration time increases from left to right as indicated by arrow . Depending upon the portions of the content indicated by the tags in the storylines the total duration of the content as presented to the user may vary.

In this illustration the various events are depicted at their relative positions within the content . A representation of complete content is depicted. Should the user select to present the content without applying any of the storylines the entire movie Burnt Sage would run a total of 92 12 minutes seconds .

In comparison the character storyline for Johnny comprises a subset of the events in particular those events which have tags implicating Johnny. For example these may be tags indicating that Johnny is in the picture or is a subject of dialogue by other characters. The character storyline when presented from beginning to end is shorter than the complete content finishing in 57 23.

The character storyline for Chet comprises different events than those associated with Johnny . As a result this storyline includes events such as Coffee s on while omitting Looking for trouble .

Finally as depicted here the action storyline is briefest of all with only three events involving horseback riding in this piece of content . As a result the total running time for this storyline is 30 25. Portions of the content which do not have tags indicating horseback riding such as the Gang s all here or coffee s on do not appear in this storyline and thus would not be presented to the user.

By selecting one or more storylines of particular interest the user may be able to consume content they might not otherwise have time for. For example the user may be a fan of the character Chet but only has about an hour to watch the movie. By selecting the character storyline the user is able to consume the portions of the content of particular interest and within the available time. Should the user wish to later view another storyline or view the complete content those options may also be available.

The processor may comprise one or more cores and is configured to access and execute at least in part instructions stored in the one or more memories . The one or more memories comprise CRSM. The one or more memories may include but are not limited to random access memory RAM flash RAM magnetic media optical media and so forth. The one or more memories may be volatile in that information is retained while providing power or non volatile in that information is retained without providing power.

The one or more I O interfaces may also be provided in the server . These I O interfaces allow for coupling the I O devices such as keyboards displays touch sensors external memories cryptographic processors and so forth to the server .

The one or more network interfaces provide for the transfer of data between the server and another device directly such as in a peer to peer fashion via the network or both. The network interfaces may include but are not limited to PANs LANs WLANs WWANs and so forth. The network interfaces may utilize acoustic radio frequency optical or other signals to exchange data between the server and another device such as router network switch another server and so forth.

The one or more memories may store instructions or modules for execution by the processor to perform certain actions or functions. The following modules are included by way of illustration and not as a limitation. Furthermore while the modules are depicted as stored in the memory in some implementations these modules may be stored at least in part in external memory such as in other devices which are accessible to the server via the network . These modules may include an operating system module configured to manage hardware resources such as the I O interfaces and provide various services to applications or modules executing on the processor .

The one or more memories may also store a datastore . The datastore may comprise one or more databases files linked lists or other data structures. The datastore may be configured to store content content metadata tags storylines storyline determination parameters or other data . The storyline determination parameters are used to determine the association between tags and their inclusion into the storyline . The storyline determination parameters are discussed in more detail below with regard to .

A server interface module may be stored in the memory and configured to provide a user interface application interface or both which handles inputs and outputs from the user the device and so forth during operation of the server . For example the server interface module may be configured to provide an application programming interface which the content presentation modules may use to access the server and initiate presentation of one or more of the storylines .

A content distribution module may be stored in the memory . The content distribution module is configured to manage and provide content to the device . The content distribution module may apply one or more storylines to the content for presentation. The content may be provided to the device for presentation using a transfer of a complete file representative of the presented content or by streaming portions of the content to the device.

A recognition module stored in the memory is configured to recognize events or event constituents within the content . The recognition of events or event constituents may be manual automatic or a combination thereof. The recognition module generates data about components of the events . The recognition module may provide facial recognition voice recognition to identify a particular speaker speech recognition to transform spoken words to text for processing object recognition optical character recognition and so forth. For example the recognition module may be configured to identify the frames in which a particular character is visible. In another example the recognition module may be configured to detect the presence of a particular trademark on objects within the images.

The recognition module may also access data such as the content metadata to generate data about the components of the events . For example the recognition module may identify speech from a particular actor and using the content metadata associate the dialogue of that particular actor with the actor s character in the content .

The memory may also store a tag generation module configured to use data provided by the recognition module the content metadata and so forth to generate one or more of the tags . For example the tag generation module may use data from the recognition module to associate a portion of the content with the character of Johnny and generate the corresponding tag . The generation of the tags may be manual automatic or a combination thereof.

The tag generation module may be configured to look for data embedded within the content . An image frame with a barcode or other data may be inserted into the content which contains information which may be used to generate the tag . For example a single frame containing a barcode with information such as the name of a character appearing in the subsequent frames may be provided by a production company or content distributor. During presentation the single frame may be imperceptible to the user. In some implementations the content distribution module may be configured to remove these embedded frames prior to presentation by the device .

A storyline module is stored in the memory . The storyline module is configured to generate one or more storylines based on one or more of the tags which are descriptive of the events in the content . The storyline module may be configured to adjust boundaries of the portion of the content specified by the tags . For example the tag may specify time a start time of 7 07 and an end time of 11 17. However the storyline module may adjust the storyline such that during presentation the content is provided from 7 00 to 12 00.

In another implementation the storyline module may be configured to adjust the boundaries of the portion of the content to correspond to scene changes changes in camera views visual effects blanking signals and so forth. For example the storyline module may be configured to change the start time of the tag to 6 56 at which time there is a change in camera angle and the end time of the tag to 13 15 to correspond with a transition between scenes.

The storyline module may also be configured to provide or designate for presentation transition effects. For example a fade to black may be used to exit one portion of content designated by the tag while a fade in from black to the image may be used to present the next portion of content in the storyline . In other implementations other transitions effects may be used. For example audio may be ramped down or ramped up in an audiobook or a page may be inserted into an eBook. The adjustment of boundaries insertion of transition effects and other actions by the storyline module may be provided to improve the overall user experience. For example the insertion of transition effects may be used to prevent jarring transitions from one portion of the content to the next during presentation.

The storyline module may be configured to generate the storylines in advance of distribution or on demand. The generation of the storylines may be based at least in part on one or more of the storyline determination parameters which are described below with regard to .

Other modules may be present in the memory as well. For example a digital rights management module may be present and configured to manage access rights to the content .

The storyline determination parameters may include estimated tag reliability . The estimated tag reliability provides a metric as to how accurately the tag relates to the actual event . For example a manually entered tag may be given a high reliability while a tag generated automatically and based on several variable inputs such as voice and speech recognition may be assigned a lower estimated tag reliability . The estimated tag reliability may also be defined as a confidence interval for the data upon which the tag is based. In some implementations a tag reliability threshold may be specified such that tags are included in a particular storyline when they meet or exceed the threshold.

A correlation threshold may specify a tolerance or correlation factor by which different tags may be associated with one another in the same storyline . For example the tag for the location Ed s Mercantile may have a correlation with the tag for the character Ed which is above the threshold. As a result a storyline may be generated which includes both tags and .

A duration threshold may be specified. The storyline module may be configured to disregard during storyline generation those tags which have a duration below the threshold. For example a tag for an event comprising a single mention of the character Chet may not be included in the character storyline .

A storyline length may be specified which defines a minimum maximum or minimum and maximum length for the storyline. For example the storyline length may be set to 60 minutes. The storyline module may select the tags from those with the highest estimated tag reliability to the least building the storyline until the storyline length of 60 minutes is reached.

User feedback may be used to generate the storylines . The users may provide feedback as to whether a particular portion of the storyline . This feedback may include selection that the content is irrelevant good bad or another rating or indication about the desirability to include of that portion of the content . For example a portion of the content which is ranked by a threshold number of users may be removed from the storyline . The user feedback may also include manually generated or modified tags .

User preferences may also be specified. For example a particular user may define particular events which they prefer to generate storylines about. Other parameters may be specified such as a threshold number of tags required to generate a separate storyline .

Different storyline determination parameters may be applied with storylines of differing scope the scope ranging from globally across all users to an individual user or group of users. For example a global storyline which is accessible to all users may specify the estimated tag reliability but omit a duration threshold . In comparison a user specific version of the same storyline may be based on the global storyline but apply a duration threshold . The user specific version of the storyline may be considered a subset of the global storyline .

At each of these events a tag has been generated. The storyline module has generated the storyline from the tags which share a common description that of Chet . These tags reference the same character Chet but are associated with different locations or portions of content. These tags may be in the same or different chapters in the content. For example the tags and are both in the chapter while a single tag is found in chapter . During presentation of the content as defined by the storyline the user may thus see only portions of a particular chapters in particular those portions which are indicated by the occurrence time tags instead of the entire chapter.

In one implementation during presentation of the content as defined by the storyline the user may experience a sequential flow of the events indicated by the tags in a particular arrangement. This arrangement may be by increasing time within the content . For example as shown here the user would be presented first with the scene the gang s all here followed by hard ride trouble arises roping looking for trouble coffee s on and back to the barn. 

Block presents a portion of the content to the user. Block receives user input descriptive of one or more of a character location theme or other event or event components which are present in the portion of the content . For example the user may enter information indicating that the portion of content from 7 07 to 11 17 includes the character of Merle. 

Block generates one or more tags based at least in part on the input. For example the tag generation module may generate the tag for the event of the appearance of the character Merle. 

Block associates the one or more tags with the portion of the content . For example the tag may include the content location reference . In other implementations the tag may be associated with a particular portion of the content .

In one implementation the user input from a plurality of users may be used to validate a given tag . For example several users may need to enter the same or similar tags before the tag is used to generate a storyline . In another implementation the user may be presented with an automatically generated tag and be asked to validate the tag is correct.

Block accesses at least a portion of content . For example the content may be video content such as the movie Burnt Sage. 

Block determines the content metadata associated with the content . The content metadata may be associated with one or more occurrence times in the content the entire piece of content and so forth. For example the content metadata may comprise the genre and the characters casting data a scene or chapter listing indicating intervals within which those scenes or chapters appear production notes for particular scenes or chapters and so forth.

Block generates one or more tags associated with the content based at least in part on information in the content metadata and the one or more occurrence times . For example the content metadata may provide information about production notes such as the type of camera used to generate an image where the content is video content. The one or more tags may refer to the portions of the content recorded with the camera.

In some implementations the content metadata may be used with other information to generate the tags . For example as described below with regard to block using information about the cast found in the content metadata facial recognition may be used to determine that in one scene Clint Woods John Morrison and Harry Coburn who play the characters of Ed Chet and Johnny respectively are present. This may be used to generate tags indicating where the characters appear in the content .

Block determines person data indicative of appearance of a person in the content at the one or more occurrence times in the content . The recognition module may be configured to use facial recognition to distinguish and identify different faces. In one implementation the determination may be distinguishing one person from another without identifying the person. For example the system may determine that a scene includes two different characters but has not determined their identity. In another implementation the determination may include identifying the person such as associating the person with a character name actor name and so forth. As described above information about the cast found in the content metadata may be used to aid in this determination with identification.

Block generates one or more of tags associated with the content based at least in part on the determined person data and the one or more occurrence times . For example the tag may specify that the character Merle has an occurrence time from time 07 07 to 11 17 in the content .

Block determines location data indicative of a location associated with the content at the one or more occurrence times in the content . For example the location data may be determined based at least in part on content metadata such as production notes indicating where the content was recorded. Or the recognition module may use image recognition to determine a location based on images appearing in the content where the content includes imagery. For example the recognition module may use optical character recognition to read the sign on an exterior image of Ed s Mercantile to determine the location as Ed s Mercantile. 

Block generates one or more of the plurality of tags associated with the content based at least in part on the determined location data and the one or more occurrence times . Continuing the example of the tag may indicate that the location is Ed s Mercantile with an occurrence time of 04 13 to 11 17 in the content .

Block determines object data indicative of an object appearing in the content at the one or more occurrence times . For example the recognition module may identify a saddle in the image.

Block generates one or more tags associated with the content based at least in part on the determined object data and the one or more occurrence times . For example the tag may indicate that a saddle appears at times 51 13 to 55 21.

Block determines text data associated with the one or more occurrence times in the content . The text data may comprise information from retrieving one or more text captions recognizing speech with a speech recognition module or recognizing writing with an optical character recognition module. For example the recognition module may use optical character recognition to read signs or text appearing in video content . The text data may also be based at least in part on closed captions open captions subtitles and so forth.

Block generates one or more tags associated with the one or more pieces of content based at least in part on information in the determined text data and the one or more occurrence times . For example where the text is generated from dialogue with two characters discussing Chet a tag associating the event of the dialogue may be generated.

Block accesses the content or a portion thereof. In some implementations block may be omitted. Block accesses a plurality of tags associated with the content . As described above the tags may comprise information indicative of events in the accessed content and the occurrence times . For example the tags generated as described above with regard to may be accessed.

As also described above the events may include but are not limited to appearance of a particular character in a portion of the content appearance of a particular object in a portion of the content a particular location in a portion of the content dialog associated with a portion of the content or a particular sound in a portion of the content.

The storyline may combine tags which are associated with different events . In some implementations block may determine a correlation between two or more tags . This correlation may indicate that the tag for the location Ed s Mercantile may have a correlation with the tag for the character Ed . This correlation may be used to determine which groupings of tags form relationships which may be relevant to the user during presentation. For example tags indicating appearance of Chet and Johnny may be highly correlated and a storyline may be generated as described next which includes tags for both characters. The storylines may thus include tags which have different descriptions but are correlated so as to correspond to a particular theme. Continuing this example the theme may be the relationship between the characters Chet and Johnny. 

In another implementation different tags may be manually combined. For example the activity storyline of riding may be based on a combination of tags indicating cowboys and horses.

Block generates one or more storylines . The generating may comprise selecting one or more tags based on one or more criteria arranging the selected one or more tags and storing the arrangement of the selected one or more tags as the storyline .

The selection of the one or more tags may be based on one or more criteria applied to the description and in some implementations the occurrence time . The one or more criteria may include a character name an actor name a theme a plot line a location an object or an activity. For example tags containing description information indicating a particular character may be selected.

The arranging may comprise sorting the tags by the occurrence time in ascending order from lowest occurrence time to greatest occurrence time . This arrangement provides a sequential presentation of the content designated by the storyline . In other implementations other arrangements may be used such as arranging by increasing time of the chronology of the story. For example a storyline for a character which features may flashback and flash forward scenes may result in a storyline which presents the scenes showing the flashbacks first consistent with their earlier appearance in the internal chronology of the story as being earlier events. The storing may comprise writing the arrangement in the CRSM such as the memory of the device or the memory of the server .

In implementations where the correlation between the tags is to be considered the criteria for the selecting the one or more tags may include the tags having a determined correlation with one another greater than the correlation threshold .

The storyline comprises a data structure associating tags with their corresponding descriptions and occurrence times across time in the content . For example the tags which reference the same character of Chet may be used to generate the character storyline . The storyline may be configured to present portions of the content designated by the plurality of tags while omitting portions of the content undesignated by the plurality of tags .

Block generates a stream of the content comprising portions of the content indicated by the one or more storylines. Block sends the stream of the content to the device . As described above the one or more portions of the content which are not designated may be omitted from sending. In some implementations the one or more storylines may be provided to the device which may then select from locally stored content or direct the server to deliver the portions designated in the storyline in the sequence indicated by the storyline .

In some implementations the server may deliver to the device a data structure which comprises the occurrence times associated with the portions of the content indicated by the tags in the storyline . The device may then request the specific occurrence times from the server or skip through the content delivered by the server .

Block accesses one or more pieces of content or portions thereof. For example the content Burnt Sage and Burnt Sage Revisited may be retrieved from the datastore . In some implementations block may be omitted.

Block accesses a storyline associated with the one or more pieces of content . As described above the storyline comprises one or more existing tags .

Block accesses one or more additional tags associated with the content . For example these may be tags generated as described above for a new episode of Burn Sage Revisited or a new movie in the series.

Block determines a correlation between the one or more additional tags and the one or more existing tags in the storyline . The one or more existing tags are those which make up the storyline . This correlation thus provides for the addition of tags to the existing storyline . In some implementations the tags from one storyline may be subsumed into another storyline as described above.

Block selects one or more of the additional tags having a correlation with the one or more existing tags which is greater than a correlation threshold. For example an additional tag such as of the character Johnny which is highly correlated to the existing tag of the character storyline may be selected.

Block adds the selected one or more additional tags to the storyline . The additional tags may be added to the storyline such that the arrangement of the tags in sequence is maintained. With these additional tags the storyline is now updated to include additional material such as from a new episode.

In some implementations the storyline may be pruned. Block determines one or more tags in the storyline having a correlation with other tags in the storyline which is below the correlation threshold. The correlation threshold may be static or dynamically adjustable. Block removes the one or more tags below the correlation threshold from the storyline . In some implementations the one or more removed tags may used to form a separate storyline or may be added to another existing storyline . Block may store the modified storyline which now comprises the one or more additional tags and no longer comprises the one or more removed tags.

Block generates a stream of the content comprising portions of the content indicated by the one or more storylines. Block sends the stream of the content to the device . For example as described above the stream may comprise the entire content from which the device presents the particular portions indicated by the storyline . In another example the stream may comprise only those portions designated in the storyline .

Block presents a user interface configured to receive selection by a user of one or more of the storylines . For example the user interface may be presented showing the various storylines for the content Burnt Sage. As described above the user may select one or more of the storylines for presentation.

In some implementations the order of presentation of the various storylines may be based at least in part on one or more of the storyline determination parameters or other parameters associated with the storylines . For example a storyline which has tags which are highly correlated with one another may presented at a beginning of a list of available storylines while the storyline which has the tags with the lowest correlation to one another may be presented at an end of the list.

Block receives user input indicative of a selection from the user interface. For example the server or the device may receive the selection from the user s cursor to watch the character storyline for Johnny. 

Block presents one or more portions of the content designated by the selected one or more storylines . As described above the one or more portions not designated may be omitting from presentation. In some implementations the one or more portions not designated may be omitted from streaming or transmission such that only the designated portions are provided to the device .

In some implementations the presentation of the storylines or the selection thereof may be incorporated into the presentation of the content. For example during the opening scene at Ed s Mercantile the various characters may leave at different times or through different exits. The user may be presented with a user interface which allows them to follow that character thus selecting the storyline associated with the particular character. This following may include presentation of content which shows the camera point of view changing to appear to follow the character as they exit.

The operations and processes described and shown above may be carried out or performed in any suitable order as desired in various implementations. Additionally in certain implementations at least a portion of the operations may be carried out in parallel. Furthermore in certain implementations less than or more than the operations described may be performed.

Certain aspects of the disclosure are described above with reference to block and flow diagrams of systems methods apparatuses and or computer program products according to various implementations. It will be understood that one or more blocks of the block diagrams and flow diagrams and combinations of blocks in the block diagrams and the flow diagrams respectively can be implemented by computer executable program instructions. Likewise some blocks of the block diagrams and flow diagrams may not necessarily need to be performed in the order presented or may not necessarily need to be performed at all according to some implementations.

These computer executable program instructions may be loaded onto a special purpose computer or other particular machine a processor or other programmable data processing apparatus to produce a particular machine such that the instructions that execute on the computer processor or other programmable data processing apparatus create means for implementing one or more functions specified in the flow diagram block or blocks. These computer program instructions may also be stored in a computer readable storage media or memory that can direct a computer or other programmable data processing apparatus to function in a particular manner such that the instructions stored in the computer readable storage media produce an article of manufacture including instruction means that implement one or more functions specified in the flow diagram block or blocks. As an example certain implementations may provide for a computer program product comprising a computer readable storage medium having a computer readable program code or program instructions implemented therein said computer readable program code adapted to be executed to implement one or more functions specified in the flow diagram block or blocks. The computer program instructions may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operational elements or steps to be performed on the computer or other programmable apparatus to produce a computer implemented process such that the instructions that execute on the computer or other programmable apparatus provide elements or steps for implementing the functions specified in the flow diagram block or blocks.

Accordingly blocks of the block diagrams and flow diagrams support combinations of means for performing the specified functions combinations of elements or steps for performing the specified functions and program instruction means for performing the specified functions. It will also be understood that each block of the block diagrams and flow diagrams and combinations of blocks in the block diagrams and flow diagrams can be implemented by special purpose hardware based computer systems that perform the specified functions elements or steps or combinations of special purpose hardware and computer instructions.

Many modifications and other implementations of the disclosure set forth herein will be apparent having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. Therefore it is to be understood that the disclosure is not to be limited to the specific implementations disclosed and that modifications and other implementations are intended to be included within the scope of the appended claims. Although specific terms are employed herein they are used in a generic and descriptive sense only and not for purposes of limitation.

