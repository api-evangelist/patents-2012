---

title: System and method for managing a computing cluster
abstract: A method and system for managing a computing cluster including hosting a plurality of machines in a networked computing cluster, wherein the plurality of machines include service instances running on hosts, where the services have configured machine state; and wherein machine state includes configuration data and software of the machine; integrating the plurality of machines of the cluster with at least one configuration controller component; and the at least one configuration controller component, altering the machine state of at least one service instance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09590849&OS=09590849&RS=09590849
owner: Twilio, Inc.
number: 09590849
owner_city: San Francisco
owner_country: US
publication_date: 20120509
---
This application is a continuation in part of U.S. patent application Ser. No. 13 167 562 entitled System and Method for Managing a Computer Cluster and filed on 23 Jun. 2011 which claims priority to U.S. Provisional Application No. 61 357 938 filed 23 Jun. 2010 titled SYSTEM AND METHOD FOR MANAGING A PLURALITY OF HOSTS which is incorporated herein by this reference in its entirety.

This invention relates generally to the cloud computing field and more specifically to a new and useful method and system for managing a computing cluster in the cloud computing field.

There are increasingly more and more cloud based services and platforms. While the use of cloud computing has been influential in allowing new products to be developed and built management of a computing cluster on which the service or platform runs is still a challenge. Each machine or device in the computing cluster typically has its configuration set individually. However changes in other machines can impact how one might configure a particular machine and synthesizing such information is not easily accomplished. Thus there is a need in the cloud computing field to create a new and useful method and system for managing a computing cluster. This invention provides such a new and useful method and system.

The following description of the preferred embodiments of the invention is not intended to limit the invention to these preferred embodiments but rather to enable any person skilled in the art to make and use this invention.

As shown in a method for managing a computer cluster of a preferred embodiment includes hosting a plurality of machines in a networked computing cluster S connecting the plurality of machines of the cluster to a configuration controller S the configuration controller storing individual machine state for the plurality of machines S determining a new machine state from the state of the plurality of machines S and updating a machine in the computing cluster with the new machine state S. The method functions to create an interface for easy monitoring configuration and or orchestration of a computing cloud. More preferably the method enables a machine to be reconfigured based on changes in other related machines in the cloud not just changes for that particular machine. The method is preferably implemented in a system substantially similar to the one described below but may be implemented by any suitable system. In one preferred embodiment the method is used with a computing cluster for a telephony platform but the computing cluster may alternatively be for any suitable application. The machines are preferably managed and operated but may alternatively be part of a third party system s that are simply controlled through a configuration controller. The method preferably includes pushing new machine state to a machine. These steps preferably implement a publishing and subscribing model of communication which functions to provide real time control over the computing cluster.

Step S which includes hosting a plurality of machines in a networked computing cluster functions to operate a plurality of devices or hosts that require orchestration. The computing cluster is preferably an Internet based plurality of machines i.e. hosts but may alternatively be an internally networked plurality of machines. The machines preferably provide computing and or storage capabilities. A machine is preferably a server but may alternatively be any suitable dedicated device or virtual device. A machine may alternatively be a virtual machine wherein a single device facilitates running a plurality of virtual machines. A machine is preferably configured with machine state to perform a particular task. In one preferred embodiment the computing cluster is used for a telephony platform. For a telephony platform the plurality of machines is preferably composed of call routers load balancers call queues media processors message routing devices resource databases and or any additional devices. The machines may alternatively be setup for any suitable type of computing cluster. The networked computer cluster is preferably hosted by the entity administering the method but the computer cluster may alternatively be hosted on a third party platform or the whole of the computer cluster may alternatively be distributed over a plurality of platforms or computing clusters. The entity administering the method preferably has some level of operational control of the machines composing the computing cluster either directly an API of third party service or any suitable control mechanism.

Step S which includes connecting the plurality of machines of the cluster to a configuration controller functions to create channels to send and receive messages between a central device e.g. a configuration controller and the devices making up a computing cluster infrastructure. The communication channels are preferably implemented through a pubsub infrastructure as shown in but any suitable communication system may alternatively be used. As part of the pubsub infrastructure Step S preferably includes subscribing to notifications of a plurality of machines S and receiving subscription requests from a plurality of machines S. External or internal hub s may be used as a message broker for relaying published messaged to those who have a subscription. By subscribing to notifications of a machine the configuration controller preferably receives operation information as the information is changed. A machine may have information actively requested from it. S may alternatively occur automatically without receiving an instruction requesting the information. S preferably occurs whenever machine state or operation changes. For example when the status of a machine changes such as due to an error the machine preferably publishes the information and the hub routes the information to the configuration controller because of the subscription to the machine. The configuration controller preferably maintains an updated database of machine state through such subscriptions as described in Step S. Step S preferably functions to establish individual subscriptions of a machine to messages generated by the configuration controller. The configuration controller can preferably selectively publish messages to any suitable subset of the plurality of machines that have a subscription. This may be accomplished in a variety of ways. A machine may have a plurality of types of subscriptions such as one subscription unique to messages for that machine a subscription to messages directed to machines with a particular status a subscription to messages directed to machines with a particular role and or any suitable subscription type. The subscriptions may alternatively be targeted through publication filtering. A subscription by the machine to the configuration controller preferably includes machine state. Information such as IP address or any suitable identifier role status or other operation information may additionally be communicated to the configuration controller. The machine state data of the configuration controller may be used to selectively publish information to hosts. For example a plurality of machines may have individual subscriptions to the messages of a configuration controller. At some point in time the configuration controller may only want to send a message to machines that have the role of a load balancer. The message is preferably only published to machines that have the role of a load balancer by filtering where the message is published. During communication data may be encrypted with a shared secret. A secret key or cryptographic code can be used to uniquely verifies communication between a machine and a configuration controller. The secret key is preferably supplied at boot time of the machine but may alternatively be established at any suitable time. The secret key is preferably included in communications between a host and the cloud manager or used to sign a communication. Any suitable authorization or security measures may alternatively be used. Other forms of communication may alternatively be used. In one variation a content delivery network system is used as an intermediary for machine state sharing. Machines preferably post machine state to the content delivery network CDN and the configuration controller preferably pulls the machine state information from the CDN as shown in .

The configuration controller may have several variations of infrastructure. One preferred variation includes a single configuration controller machine integrated with the plurality of machines. A plurality of configuration controllers may additionally be used. In one variation the configuration controller is implemented in an active passive configuration as shown in . In an active passive configuration one machine preferably acts as a primary configuration controller and a second configuration controller preferably acts as a secondary configuration controller that can be used when needed. In yet another variation the configuration controller is implemented in an active active configuration as shown in . In an active active configuration there are a plurality of configuration controllers cooperatively managing the cluster. Machine state is preferably stored in a shared resource in this variation. In yet another variation the machines of the cluster cooperatively function as the configuration controller in a peer to peer type configuration as shown in . In this variation a configuration controller service preferably runs on each machine. The configuration controller may alternatively have any suitable architecture and implementation.

Step S which includes the configuration controller storing individual machine state for the plurality of machines functions to store state information for machines of the computing cluster. The configuration controller is preferably a device or platform from which computing cluster orchestration may be carried out. The configuration controller may itself be distributively hosted. Machine state of a machine preferably includes configuration data and software. The machine state may additionally include operational data. The operational data may be external to the machine. The configuration data is preferably similar to file system related data. The software is preferably the code or source code executed by the machine. The operational data is resources such as a database media resources persistent data or any suitable data used in operation. The machine state may alternatively include any suitable combination of the configuration data software operational data and or other machine related data. The machines preferably publish changes in machine state to the configuration controller. Alternatively the configuration controller may periodically poll the machines. In yet another alternative the configuration controller pulls machine state from a CDN. The machine state is preferably stored in a database. The machine state database may be any suitable database or device for storing data such as a mySQL database JSON or an XML file. The machine state database preferably stores a record for each machine including the machine state. This information may include internal and or external IP addresses of the machines status role s capacity load and or any suitable operation information. As discussed further below the database may additionally store a security key for each machine to securely identify a machine. Current machine state is preferably stored and additionally past machine state may be stored as a version history of the machines. The version history is preferably the machine state from different points in time. These versions may be used in comparing the machine state from different times or from different machines and resolving problems.

Step S which includes determining a new machine state from the state of the plurality of machines functions to calculate a next state for a machine based on overall state of the cluster. A new machine state is preferably calculated based on the current machine state. The new machine state is additionally or alternatively calculated based on the machine state of associated machines of the computing cluster. The associated machines are preferably machines that interact directly or indirectly with the machine. Machines may alternatively be associated based on shared machine state e.g. having the same role or status . For example two machines that are configured as indicated in the machine state to be load balancers may be associated with each other. Calculating a new machine state based on the machine state of at least a second machine enables the machines to be updated more intelligently. Additionally a plurality of new machine states may be calculated for a plurality of machines. A new machine state may be any suitable change to a machine state. The configuration data may be changed. The software may change which may be an update to a new version of software or change in role. The operational data may change such as changes in a database resource of a machine. In some variations the new machine state may be a defined as provisioning a new machine to scale the computing cluster reprovisioning a machine to a new role restarting a machine or deprovisioning a machine to scale down.

The calculation of a new machine state is preferably initiated by a change in the computing cluster. In one variation calculation of a new machine state is due to the change in machine state as a result of operation. For example if a machine encounters an error then new machine states are preferably calculated for other machines to accommodate for the down machine. This may include provisioning a new machine with a previous machine state of the down machine or could alternatively be a redistribution of the machines responsibilities to other machines. This transfer of responsibilities is preferably conveyed through the new machine states. Similarly the calculation of a new machine state may be due to the usage and or capacity of the machine. Load and capacity may be communicated through the configuration data in the machine state. In another variation calculation of a new machine state is due to outside initiation. The configuration controller preferably includes an API which may be used by an outside system or operator. An operator may issue instructions to change elements of the computing cluster. For example an instruction may be set to scale particular resources up or down to update software to change operational data or perform any suitable orchestration instruction. The calculation of new machine state may alternatively or additionally be calculated using auto provisioning self healing and or any suitable algorithm. A finite state machine may be run to determine the new machine state of a particular machine as shown in .

In one variation the machines of the computing cluster include a plurality master devices each with a dedicated load balancers as shown in . Having a plurality of masters and load balancers distributes responsibility and creates a more scalable computing cluster. The master device preferably provides high level services but may serve any suitable service. In a preferred embodiment where the computing cluster is a telephony platform the master device is preferably a call router as shown in . The dependent machines may be any suitable support of load balanced machines such as media processors caches queues proxy servers or any suitable machines. The dependent machines i.e. machines managed by each load balancer are preferably conveyed in the machine state of the load balancer. Load balancers may be configured with new machine state based on changes in the machines for which they provide load balancing. Provisioning of a machine e.g. provisioning a new machine deallocating a machine etc. that is load balanced by a particular load balancer preferably causes a recalculation of machine state for at least one load balancer. When the load balancer is updated with the new machine state the load balancer and master device may be restarted to start load balancer of the changed dependent machines.

Step S which includes updating a machine in the computing cluster with the new machine state functions to set the machine to the new machine state. The new machine state is preferably communicated to the machine through the established channels of communication. The new machine state is preferably published through a hub and distributed to machines that have the appropriate subscription established in Step S. Publications may be filtered which functions to direct the new machine state to the appropriate machine s . As discussed above a new machine state can preferably be selectively published or filtered based on any suitable machine characteristic such as IP address or ID status role capacity load and or any suitable aspect. Once new machine state is received at the machine the machine may require being restarted to initialize the new machine state. Alternatively the new machine state may be initialized during run time.

Additionally a method of the preferred embodiment includes the step of receiving a message through an API of the configuration controller S which functions to allow outside instructions for management of the computing cluster. The API is preferably a convenient interface for users or systems to access and change the computing cluster system. The API is preferably a RESTful API but may alternatively be any suitable API such as SOAP. Additionally a user interface may be used as a front end control providing an alternate way for users to interact with the configuration controller through the API. The API is preferably used to alter configuration of a machine or machines. A user and or an outside system may issue API calls. The API may additionally be used to access information about the computing cluster. The configuration controller through the communication channels established in S preferably has stored and updated information about the machines. Additionally or alternatively the configuration controller may communicate with a machine requesting information. For example an HTTP GET message using a common HTTP client tools such as curl piped into an extensible stylesheet language transformation XSLT processor can be used to generate any suitable type of configuration file. The command shown in could be used with a suitable XSLT file to generate a firewall ruleset allowing access to only running hosts in the cloud. The API may alternatively be used for transferring data allocating or reprovisioning resources and or any suitable cloud computing management. Additionally a change to one machine may cause the determination of new machine state of a second machine. For example allocating a new device may require the determination of a new machine state for a load balancer.

As shown in a method for managing a computer cluster of a second preferred embodiment of the invention includes hosting a plurality of machines in a networked computer cluster S integrating a plurality of machines of the cluster with at least one configuration controller component S and altering the machine state of at least one service instance S. The method functions to create an interface for easy configuration and or orchestration of a computing cloud. The steps of the method may be used in any suitable combination with the steps of method above and any of the variations of two methods may additionally be applied to either of the embodiments. Step S S and S is preferably substantially similar to Step S S and S except as noted below. Method may additionally be applied to a machine or host such that multiple services of a machine may be impacted through one update.

As used in the description of method a service instance preferably runs on a host. A host is preferably a machine that has one or more service instances running on the host machine. A service instance refers to a specific implementation of a service. A service preferably describes a type of module that performs a particular task or tasks within the computing cluster. For a telephony platform the services of a computing cluster may include call routers load balancers call queues media processors message routing devices resource databases and or any additional devices. In some variations a service may be a dependent service. In other words a first service i.e. the dependent service may require at least a second service. The second service may additionally be dependent on other services. The dependencies of services are preferably acyclical. A host may additionally run a load balancer for services that the hosted services depend upon as shown in . If multiple services of a host share a common dependency on a service then a single load balancer may be used for that service. Each service instance preferably has machine state but a host may additionally have machine state. As described above machine state preferably includes configuration data and software i.e. business logic . The machine state may additionally include operational data and or any suitable description of the state of a service.

Step S which includes updating the machine state of at least one service instance functions to alter operation of a machine in cluster. Updating may include starting a service instance stopping a service instance removing a service instance updating the version of a service instance or reverting a version of a service changing type of service or any other suitable change. The update is preferably accomplished by sending a new machine state to a service instance. The machine state is preferably versioned so that the new machine state may be supplied through a version controlled version of the machine state. The software and configuration data are preferably version controlled while operational data is preferably automatically updated as shown in . The updating of the machine state may be initiated by an outside entity or alternatively through automatic monitoring.

One variation of the method includes receiving a specified service update S. An API or interface may be used for users or system to supply new machine state to the configuration controller. The specified service update preferably includes at least one service to update. The update may additionally include a sub group parameter to update a sub group of the instances of the specified service. If sub group parameter is note included all instances of the specified service are preferably updated with the new machine state. The sub group parameter may be used to update a particular instance e.g. using an instance ID update a fixed number update a percentage of service instances update a type of sub group e.g. service instance of a particular version number update a services based on a combination of conditions e.g. updating either 33 or 20 instances whichever is greater or updated according to any suitable way of specifying a sub group.

The method additionally preferably includes identifying service instances S which functions to determine which service instances to alter in Step S. Service instances may be identified by processing a configuration file. The file is preferably describes the architecture of the plurality of machines. In one example a markup language may be used to describe the configuration as shown in . Sub group parameters may be used to identify the appropriate service instances. Additionally the Step S may include identifying service instances that are dependent on a particular service instance. In this way when a service instance has machine state altered all service instances that depend on that service instance are notified of the change. Preferably a dependency graph is created to show the dependency relationships of the services of a computing cluster as shown in . The dependency graph is preferably acyclical. When building a dependency graph the configuration of the services may additionally be validated. For example cycles may be identified and eliminated. When altering machine state in Step S the service instances are preferably altered in an order based on the dependency graph. This may be from leaf nodes to dependent services or from dependent services to leaf nodes of the dependency graph. The order may additionally be based on what machine state changes are occurring. In the dependency graph dependency order follows the connections starting at the leaf nodes. In the variation where there is a load balancer for a service then that load balancer is preferably updated when the service being load balanced is altered.

In another variation the method includes monitoring the operation status of machines and or services of the computing cluster. A scaling parameter is preferably set so that services may be scaled automatically when the scaling parameter is satisfied. The scaling parameter may be threshold a pattern of events or any suitable parameter to trigger the altering of service and or host machine state. Thresholds are preferably set for appropriate operation parameters and when a machine or a service instance reaches the threshold scaling of a service may be automatically initiated by altering the machine state of appropriate services. A threshold is preferably set for provisioning and for deprovisioning such that the computing cluster can scale up and down. The configuration controller preferably manages this monitoring but monitoring may alternatively occur on the machine or by any suitable component. In a telecommunication platform the computing cluster preferably has very unique scaling requirements as compared to other systems. Large spikes may occur at any time. Telecommunication platforms additionally have a plurality of types of input channels. For example a telecommunication platform preferably supports voice sessions messaging e.g. SMS and or MMS video and any other suitable type of input channel. The types of input channels typically have different service requirements. Service may be monitored and automatically altered according to the type of input channel. Services that are shared between services may additionally be pooled between types of input channels. The type of input channels of a telecommunication platform may include voice video messaging e.g. SMS or MMS or any suitable type of input channel.

Additionally the method may be used to orchestrate a computing cluster being used with sustained session. A sustained session is preferably any suitable session that requires sustained use of a service instance for the duration of the session. Some examples of sustained sessions include voice calls and video streams that occur on telecommunications platforms. A service instance handling an operation for a sustained session is preferably kept at a constant state until all sustained sessions come cease use of that service instance. Preferably the service instances that are dependent on such a service instance are altered appropriately in preparation and when the sustained session ends then the service instance is altered.

As shown in the system of the preferred embodiment for managing a computer cluster preferably includes a computing cluster and a configuration controller . The system functions to provide an interface for easy monitoring and configuration of the computing cluster . The configuration controller preferably additionally includes an access application programming interface API machine state database and a machine communication system . The system may be used with any suitable cloud computing environment. One preferred embodiment uses the system with a telephony network platform such as the one described in patent application Ser. No. 12 417 630 filed 2 Apr. 2009 entitled System and Method for Processing Telephony Sessions which is incorporated in its entirety by this reference.

The computing cluster of the preferred embodiment functions to provide the base infrastructure a user is wishing to manage. The computing cluster is preferably composed of a plurality of machines or computing resources machines. The machines may be identical in setup or may alternatively be composed of a variety of systems such as web servers voice over Internet protocol VoIP systems media processors load balancers databases proxy servers caches queues and or any suitable computing device and or storage devices. The computing cluster may be composed of a variety of hardware systems software platforms and or virtual machines. A machine preferably has operation information available to interested parties preferably access through the configuration controller . The operation information preferably includes machine status e.g. booting running shut down etc. internal Internet protocol IP address external IP role e.g. web server VoIP load balancer media processor etc. capacity load and or any suitable operation settings or information. A machine preferably manages communication of the operation information and self operation such as performing roles or changing status . A machine additionally has machine state information. The machine state information preferably includes configuration data software and operational data. The configuration data is preferably similar to file system related data. The software is preferably the code or source code executed by the machine. The operational data is resources such as a database media resources persistent data or any suitable data used in operation. The machine state may alternatively include any suitable combination of the configuration data software operational data operational information and or other machine related data. A machine may alternatively have a parent device that manages monitors and communicates operation information of the machine such as a load balancer in charge of a plurality of resources.

The configuration controller of the preferred embodiment functions to act as an interface to controlling the computing cluster . The configuration controller functions to simplify the management and control of a cloud computing environment. The configuration controller preferably includes an access API a machine state database and a machine communication system . The configuration controller additionally includes a state machine engine that generates new machine state of a machine. The inputs to the state machine engine preferably include the old machine state. A plurality of machine states of associated machines may additionally be input into the state machine engine.

The access API preferably functions to act as an interface for interested parties to interact with operation information and change the operation of machines within the computing cluster . The access API is preferably a REST API Representational State Transfer API as is known in the art but the access API may alternatively be a SOAP Simple Object Access Protocol API or any suitable programmatic communication interface. A REST API preferably follows RESTful practices as is well known in the art. RESTful is understood in this document to describe a Representational State Transfer architecture. RESTful Hypertext Transfer Protocol HTTP requests are preferably made to the configuration controller . The HTTP requests are preferably stateless thus each message communicated preferably contains all necessary information for operation of a user command. The configuration controller preferably does not need to remember or store previous communications to be aware of the state. The machines machine state and related resources are preferably viewed as addressable resources. Consistent with the RESTful conventions a GET request of a resource may return the current state of a resource while PUT may update the state PUT or POST may be used to create a new resource and DELETE may be used to destroy a resource. The access API can preferably be used by users to access operation information of one or more of the machines in the computing cluster . For example as a REST API a simple HTTP request using the access API can obtain a list of machines and can preferably filter information on status role or any suitable operation information. The operation information is preferably returned in an HTTP response preferably containing the operation information formatted as xml.

The machine state database preferably functions to store operation information of the machines of the computing cluster . The machine state database may be any suitable database or device for storing data such as a mySQL database or an XML file. The machine state database preferably stores a record for each machine . The information stored for each machine preferably includes machine state internal and or external IP addresses of the machines status role s capacity load and or any suitable operation information. The database may additionally store a security key for each machine to securely identify a machine .

The machine communication system preferably functions to be a communication infrastructure between machines of the computing cluster no and the configuration controller . The machine communication system is preferably a publishing and subscription service such as pubsub messaging system. As shown in the pubsub variation of the machine communication system preferably has a number of configured subscriptions and publication channels. The configuration controller preferably subscribes to the notifications published by the machines . These notifications preferably include the operation information submitted by the machines. The machines preferably individually subscribe to messages from the configuration controller or any suitable party such as other machines . New machine state is preferably communicated from the configuration controller to the machines. There is preferably a hub that the machines and the configuration controller communicate through using the pubsub system. The configuration controller may function as a hub or an outside system may be used as a hub. Additionally there may be any suitable number of hubs such as for a system geographically distributed.

Additionally the system of the preferred embodiment preferably includes a secret key shared by a machine and the configuration controller . The secret key is preferably a cryptographic code that uniquely verifies communication between the machine and configuration controller . The secret key is preferably supplied at boot time of the machine but may alternatively be established at any suitable time. The secret key is preferably included in communications between a machine and the configuration controller .

As shown in a system for creating distributed groups in accordance with a preferred embodiment can include a cloud manager a database and a remote computer such as for example a distributed cloud based computing cluster . The system preferably functions to manage the creation distribution maintenance and or life cycle of one or more groups that can be created by individual application developers system engineers and or users of a cloud based computing platform. As used herein a group can include one or more different types of hosts each host related internally to the other in a predetermined fashion. Suitable types of hosts can include for example a database host an http host an html host a voice transform host an http request host an SMS host an IP messaging host a text to speech conversion host a recording host a queuing host and or a host controlling host i.e. a local controller of a set of hosts or group controller . Preferably the computing cluster is distributed in a cloud based system which can be entirely decentralized and or distributed from any central node or controller. One example implementation of the preferred system can include multiple iterations of the computing cluster each containing substantially identical groups distributed throughout multiple regions worldwide for implementing an international cloud based telephony platform. Accordingly one preferred function of the system is to allow for local creation generation and management of groups throughout multiple regions in a substantially automated and easily replicated manner.

As shown in the preferred system can include a cloud manager that functions to permit a user i.e. a telephony system administrator to create and or define a group of hosts for use in a cloud based telephony system of the type described herein. The preferred cloud manager can include a communications module having a user interface through which a user can input instructions make selections and receive displayable information from the cloud manager . Suitable user interfaces can include for example web based and or stand alone applications that permit user access into the cloud manager . A preferred user interface functions at least in part to receive commands from the user and transmit those commands to the cloud manager for execution as set forth herein. The preferred system can also include an access API which preferably functions to act as a machine interface between the cloud manager and the computing cluster to create and or change the operation of machines hosts and or groups within the computing cluster . As noted elsewhere herein the access API is preferably a REST API as is known in the art but the access API may alternatively be a SOAP API or any suitable programmatic communication interface. A REST API preferably follows RESTful practices as is well known in the art. The access API can preferably be used by users to access and or change operation information of one or more of the groups in the computing cluster . For example as a REST API a simple HTTP request using the access API can obtain a list of groups and can preferably filter information on status role or any suitable operation information. The operation information is preferably returned in an HTTP response preferably containing the operation information formatted as an xml file.

As shown in the system preferably includes a cloud manager which functions to simplify and automate the creation of a group of hosts on and or at the computing cluster . The cloud manager preferably includes an access API and a communications module described above. The preferred cloud manager can additionally include a state machine engine that generates new machine state of a machine. The inputs to the state machine engine preferably include the old machine state. A plurality of machine states of associated machines may additionally be input into the state machine engine. The preferred cloud manager can further include a server that interfaces with a file repository not shown to retrieve fetch and or pull definition files from the repository. The server component of the preferred cloud manager can also compile newly retrieved fetched and or pulled definition files into group types which can be locally stored at a database . As described below in greater detail the cloud manager can also start initiate launch generate and or create one or more groups at the computing cluster .

As shown in the preferred system can further include a database which functions to store operation information of the groups of the computing cluster . The database may be any suitable database or device for storing data such as a mySQL database or an XML file. Alternatively the database can be a distributed database such as ZooKeeper or a quorum based database. The database preferably stores a record for each group. The information stored for each group preferably includes at least group definitions and group configurations group status group role s capacity load and or any suitable operation information relating to the group or any portion thereof. Collectively the group definitions and group configurations can define a group policy or rule set that delineates the particular functional state s of the group and or the host members of the group. In another variation of the preferred system the database can additionally store a security key token or hash to securely identify each group on the computing cluster .

In one example implementation the preferred system permits a user to select one or more groups and or types of groups that he or she desires to be implemented on the computing cluster . For example a user can select a particular type of group i.e. a voice group that can include one or more types of hosts that are necessary or desirable for performing voice telephony functions through a cloud based platform. Suitable voice group hosts can include for example a database host an http host an html host a voice transform host an http request host a queuing host and or a host controlling host i.e. a local controller of a set of hosts or group controller . Preferably upon receipt of the desired configuration the cloud manager consults the database to determine the exact configuration and or rules applicable to the selected group and then interfaces with the computing cluster and instructs the computing cluster to initiate the group as requested. Preferably the cloud manager can interact directly with the cloud provider to provide the proper size boot sequence interconnectivity and or functionality of each host within the selected group. Preferably when starting a new group the preferred system provides for an automated process for bringing up clean servers at the computing cluster and installing software and or other configurations that substantially match the desired state set forth in by the group definitions in the database . The preferred cloud manager can also be configured to monitor and or terminate any or all groups that it creates as described herein.

Preferably each group includes a local group controller as shown in . In this example configuration of the preferred system once the selected group is configured and operational then the group controller can take over local control of the group at the computing cluster without need or requirement of further instruction from the cloud manager . Preferably the group controller be configured as a host itself internal to the computing cluster and further configured to communicate with monitor and or control each other host within its predefined group. In variations of the example configuration of the preferred system the group controller can be further configured to maintain its predefined group in its defined state. For example if host A in the group fails or crashes the group controller can automatically respond by reinstating a new host A that complies with the functional and performance requirements for that type of host as set forth by the database . In another variation of the example configuration of the preferred system the group controller can be configured to automatically notify the cloud manager and or the database in response to any failure crash and or operational difficulty with any of the hosts within its group. The alarm function of the group controller preferably enables the preferred system to run automated diagnostics or debugging exercises in response to repeated and or systematic failures within certain types of group deployments. As an example any of the following conditions can constitute a failure of the type that can elicit remediation by the group controller a host program error a host program crash a cloud hardware failure a cloud software firmware failure a communication network failure and or a dependency failure i.e. if a basic host fails all hosts that depend from the basic host will also be subject to failure .

In another variation of the preferred system the group controller can be responsive to external parameters in determining its group configuration and or operations. For example the user can establish one or more threshold conditions as part of setting up the group at the cloud manager and or incorporate such threshold conditions into the group definitions themselves at the database . Example threshold conditions can include changing business conditions and or changing resource allocations either of which can be handled either proactively or reactively by the preferred system . In another example implementation of the preferred system the user can establish that if a certain call volume is achieved and or expected the group controller is to create or generate more host resources to meet the increased demand. Thus a call center might reasonably expect an increased voice call demand during the holiday season when people are anticipated to spend more time speaking with loved ones over a voice connection. Accordingly the preferred system can be configured to automatically create more voice group resources either in response to the increased demand i.e. through a feedback loop or in anticipate of the increased demand i.e. though user expectations statistical modeling and the like . Group expansion contraction in response to a threshold conditions is preferably controlled through one or both of the API or the group controller . Alternatively one or both of the API and the group controller can coordinate with the database to register and or approve of the changes in the group configurations i.e. expanded or contracted group definitions . In another alternative the definition of a threshold condition sensitive group can include an underlying variable resource definition that allows for the group controller to expand contract the size and or scope of the group in response to existing or predicted conditions.

As shown in a method for creating distributed groups in accordance with a preferred embodiment can include receiving at a cloud manager an instruction to initiate a group of hosts on a remote server in block SKI receiving a selection of a group profile at the cloud manager from a database the group profile including a set of group definitions and configurations corresponding to one or more hosts in block S transmitting from the cloud manager to the remote server a command to initiate a group controller residing on the remote server in block S and at the remote server initiating the one or more hosts in response to and at the direction of the group controller in block S. The method preferably functions to manage the creation distribution maintenance and or life cycle of one or more groups that can be created by individual application developers system engineers and or users of a cloud based computing platform. As noted above a group can include one or more different types of hosts including for example a database host an http host an html host a voice transform host an http request host an SMS host an IP messaging host a text to speech conversion host a recording host a queuing host and or a host controlling host i.e. a local controller of a set of hosts or group controller . Preferably the method can be performed by one or more of a cloud manager a database and or a remote server. Preferably the remote server can include a distributed cloud based computing cluster such as that described above. In one example implementation of the preferred method the method can function to populate multiple computing clusters with substantially identical groups and distributed throughout multiple regions worldwide for implementing an international cloud based telephony platform. Accordingly one preferred function the method is to allow for local creation generation and management of groups throughout multiple regions in a substantially automated and easily replicated manner.

As shown in the preferred method can include block S which recites receiving at a cloud manager an instruction to initiate a group of hosts on a remote server. Block S preferably functions to retrieve capture input initiate and or receive a set of instructions from a user relating to the implementation creation and or generation of one or more hosts operable on a remote server. Preferably block S is performed at or by a cloud manager of the type described above which is configured for causing instructing and or commanding the creation of the group at the remote server. Preferably a user interface is integrated into the cloud manager to permit the user to have simple access the computing cluster. In one variation of the preferred method the instruction received in block S can include a selection of a group from a predetermined set of groups having predefined functions or capabilities. As an example a user might be able to select a voice group a messaging group a video group an infrastructure group or any combination thereof where each type of group can include one or more distinct hosts or combinations of hosts for performing set types of functions within the overall telephony system. In one variation of the preferred method block S can be performed by an access API of the type described above. As noted elsewhere herein the access API is preferably a REST API as is known in the art but the access API may alternatively be a SOAP API or any suitable programmatic communication interface. A REST API preferably follows RESTful practices as is well known in the art. A suitable access API can preferably be used by users to access and or change operation information of one or more of the groups in the computing cluster. For example as a REST API a simple HTTP request using the access API can obtain a list of groups and can preferably filter information on status role or any suitable operation information. The operation information is preferably returned in an HTTP response preferably containing the operation information formatted as an xml file.

As shown in the preferred method can further include block S which recites receiving a group profile at the cloud manager from a database. Preferably in block S the group profile includes a set of group definitions and configurations corresponding to one or more hosts. Block S preferably functions to provide the cloud manager with the specifications and definitions of the selected group as stored and or recorded at the database. As noted above a suitable database preferably functions to store operation information of the groups of the computing cluster. The database can be any suitable database or device for storing data such as a mySQL database or an XML file. Alternatively the database can be a distributed database such as ZooKeeper or a quorum based database. The database preferably stores a record for each group. The information stored for each group preferably includes at least group definitions and group configurations group status group role s capacity load and or any suitable operation information relating to the group or any portion thereof. As noted above collective group definitions and group configurations can define a group policy or rule set that delineates the particular functional state s of the group and or the host members of the group. In another variation of the preferred method the database can additionally store a security key token or hash to securely identify each group on the computing cluster.

As shown in the preferred method can additionally include block S which recites transmitting from the cloud manager to the remote server a command to initiate a group controller residing on the remote server. Block S preferably functions to begin formation of a group having one or more hosts at the remote server through delegation of the process to the group controller. As shown in the preferred method can additionally include block S which recites initiating the one or more hosts in response to and at the direction of the group controller. Preferably the group controller is enabled to initiate and or create the remaining host s in its group in response to the group profile. Alternatively the cloud manager can initiate the group controller and an additional one or more hosts substantially simultaneously in block S. For example block S can including initiating the group controller a database host and an http host by the cloud manager while block S can include initiating an additional database host an html host and a voice transform host by the group controller in response to the group profile. Those of skill in the art will readily appreciate that actuation of the group hosts can be initially accomplished by any suitable combination of the cloud manager and the group controller at the discretion of the user and or optimization of the available computing resources.

As shown in one variation of the preferred method can include block S which recites scaling the one or more hosts at the remote server in response to a predetermined threshold condition. Block S preferably functions to automatically and reliably generate create and or initiate one or more types of hosts at the remote server in response to attainment or exceeding a predetermined threshold condition. Alternatively block S can also preferably function to automatically and reliable eliminate delete and or terminate one or more types of hosts at the remote server in response to attainment of exceeding the predetermined threshold condition. Preferably scaling can include increasing or decreasing the number and or type of hosts at the remote server. The group controller preferably performs Block S although additional external control can be provided by or at the cloud manager by changing one or more aspects or measurements of the predetermined threshold condition. In another variation of the preferred method the predetermined threshold can include a business metric such as for example an expected desired call quality an expected desired latency value an expected desired user experience and the like. As an example a business user can establish a business metric that all voice transmissions are to be at or above a certain level of quality and should the actual or predicted voice quality drop beneath that threshold the group controller preferably automatically initiates additional hosts in order to accommodate the actual or predicted traffic and maintain the appropriate voice quality. In another variation of the preferred method the predetermined threshold can include a usage metric such as for example a certain number of voice transmissions SMS transmissions network traffic and the like. Thus the user can establish a usage metric that indicates in response to a certain traffic volume the group controller preferably automatically increases decreases the number of hosts and or the types of hosts in the group in order to accommodate the increase decrease in network traffic. Alternatively the predetermined threshold condition can include any user defined threshold or metric that requires scaling of the group resources in an automated and reliable manner. Each of the foregoing aspects of the preferred method permit the user to set one or more parameters and then delegate the authority to make any desired changes to the group controller such that the group controller can maintain the optimal operating state of the group on the fly and without any needed intervention or instruction from the user.

In another variation of the preferred method block S can further include initiating the one or more hosts in a predetermined order. Preferably the predetermine order includes initiating independent hosts substantially prior to dependent hosts. As an example some types of hosts might be dependent upon other types of hosts i.e. an http host might depend upon a database host for its functionality. Consequently in this variation of the preferred method block S can include initiating the database host substantially prior to initiating the http host. Preferably the database host will be fully configured prior to beginning the initiation of the http host. Alternatively the database host initiation can be started but not necessarily finished in its entirety prior to beginning the initiation of the http host. In another variation of the preferred method block S can include initiating multiple dependent hosts from multiple independent hosts at substantially the same time i.e. generating multiple http and or html hosts from multiply initiated database hosts within the same group. In still another variation of the preferred method the predetermined order in which the hosts are initiated can be established according to user request resource availability system demands i.e. servicing immediate needs over future needs locality or region in which the groups computing cluster are located and or any other suitable or desirable condition or ordering.

As shown in in another variation the preferred method can further include block S which recites initiating a second one or more hosts in response to and at the direction of the group controller at a second remote server. Block S preferably functions to generate an additional group configuration at the first remote server in a second remote server. In one alternative variation of the preferred method the second one or more hosts are substantially identical to the first one or more hosts i.e. the second group is a replica or mirror of the first group. For example block S can optionally function to create a distributed backup of the first group as a failsafe. Additionally block S can optionally function to create an operational replica of the first group in the event that the first group experiences a substantial failure such as a cloud failure a hardware failure a system wide power failure or the like. In another alternative variation of the preferred method block S can include creating the second set of one or more hosts in a different country or region than the first host. For example a user with substantial international traffic can create a first group operational in the United States and have matching or substantially identical groups automatically created in Europe and Asia to ensure a robust and efficient international telephony system distributed over multiple computing clusters.

As shown in another variation of the preferred method can include block S which recites transmitting a request to amend the one or more hosts from the database to the group controller in response to a change in the group profile. Block S preferably functions to automatically and reliably cause modification amendment and or adjustment in the group composition in response to a change in the group profile. Block S is preferably performed automatically from the database in response to a change in the group profile i.e. the addition or deletion of certain hosts the functions of one or more hosts or the definitions of the group itself. Alternatively block S can be performed by one or both of the database or the cloud manager. As shown in in response to the request made in block S a variation of the preferred method can include amending the one or more hosts by the group controller in response receipt of the request to amend the one or more hosts from the database in block S. Block S preferably functions to automatically and reliable modify amend and or adjust the group composition in response to the request from the database. Alternatively the request to which block S responds can be from either one or both of the database or the cloud manager. Exemplary amendments and modifications to the group configuration can include for example addition or deletion of a host change in the function of a host change in the rules governing the group composition change in the rules governing the group operation and or a change in the definition of the group that require any of the foregoing modifications or amendments.

As shown in another variation of the preferred method can include block S which recites amending the one or more hosts by the group controller in response to a triggering event at the remote server. Block S preferably functions to automatically and reliably modify alter and or amend the one or more hosts composing the group in response to a triggering event at the remote server. Preferably block S is performed automatically by the group controller in accordance with a set of instructions rules and or definitions relating to the proper configuration and or operation of its group. As an example the group definitions might require that a certain number of http hosts be operating at any given time such that in the event of failure of one the http hosts the group controller preferably automatically responds and generates a replacement http host and directs traffic to the new host in lieu of the failed host. Preferably any changes to the one or more hosts can include reinitiating the one or more hosts to state substantially identical to a preexisting state at the triggering event so that the user experience is entirely seamless and there is substantially zero loss in the information or state of the system. In another variation of the preferred method block S can include adjusting the flow of data to and or the load placed on any of the one or more hosts in order to improve traffic routing and or processing of the various requests being directed at the respective hosts. Additional features and aspects of a preferred system and method of managing distributed groups of hosts is described in detail below with reference to .

As shown in a system for managing distributed groups in accordance with a preferred embodiment can include a cloud manager a database a computing cluster and a monitor . The system preferably functions to manage the creation distribution maintenance and or life cycle of one or more groups that can be created by individual application developers system engineers and or users of a cloud based computing platform. As used herein a group can include one or more different types of hosts each host related internally to the other in a predetermined fashion. The preferred system can further function to ensure that each host and or each machine at the computing cluster is booted maintained updated and managed in an appropriate and desirable order. The preferred system can further include a configurations repository not shown configured for receiving and storing commits relating to the structure and or function of one or more groups. The cloud manager preferably additionally includes an access API and a machine communication system of the type described above. The preferred system can be used with any suitable cloud computing environment. One preferred embodiment uses the system with a telephony network platform such as the one described in patent application Ser. No. 12 417 630 filed 2 Apr. 2009 entitled System and Method for Processing Telephony Sessions incorporated by reference above.

As shown in the preferred system can include an access API which preferably functions to act as an interface for interested parties to interact with operation information and create and or change the operation of machines and or groups within the computing cluster . As noted above the access API is preferably a REST API as is known in the art but the access API may alternatively be a SOAPAPI or any suitable programmatic communication interface. Any HTTP requests are preferably stateless thus each message communicated preferably contains all necessary information for operation of a user command. The cloud manager preferably does not need to remember or store previous communications to be aware of the state. The groups and all related resources are preferably viewed as addressable resources. Consistent with the RESTful conventions a GET request of a resource returns the current state of a resource while PUT updates the state both PUT or POST creates a new resource and DELETE destroys or terminates a resource. The access API can preferably be used by users to access and or change operation information of one or more of the groups in the computing cluster . For example as a REST API a simple HTTP request using the access API can obtain a list of groups and can preferably filter information on status role or any suitable operation information. The operation information is preferably returned in an HTTP response preferably containing the operation information formatted as an xml file.

As shown in the preferred system can further include a communications module which preferably functions to be a communication infrastructure between the computing cluster the database and the cloud manager . The machine communication system is preferably a publishing and subscription service such as pubsub messaging system of the type described above with reference to . The preferred system can additionally include a hub not shown through which the cloud manager and the computing cluster communicate using the pubsub system. The cloud manager or any other suitable external system can function as a hub in the preferred system . Preferably one or more hubs can be used in a geographically distributed system .

As shown in the system preferably includes a cloud manager which functions to simplify the management and control of a cloud computing environment. The cloud manager preferably includes an access API and a machine communication system . The preferred cloud manager can additionally include a state machine engine that generates new machine state of a machine. The inputs to the state machine engine preferably include the old machine state. A plurality of machine states of associated machines may additionally be input into the state machine engine. The preferred cloud manager can further include a server that interfaces with a file repository not shown to retrieve fetch and or pull definition files from the repository. The server component of the preferred cloud manager can also compile newly retrieved fetched and or pulled definition files into group types which can be locally stored at the database . As described below in greater detail the cloud manager can also launch one or more groups at the computing cluster as well as the monitor module .

As shown in the preferred system can further include a database which functions to store operation information of the groups of the computing cluster . The database may be any suitable database or device for storing data such as a mySQL database or an XML file. Alternatively the database can be a distributed database such as ZooKeeper or a quorum based database. The database preferably stores a record for each group. The information stored for each group preferably includes at least group definitions and group configurations group status group role s capacity load and or any suitable operation information relating to the group or any portion thereof. The database can additionally store a security key token or hash to securely identify each group on the computing cluster .

The computing cluster of the preferred system can include one or more of a plurality of machines groups of machines states of machines and or any combination thereof. As noted above suitable machines can be identical in setup or may alternatively be composed of a variety of systems such as web servers voice over Internet protocol VoIP systems media processors load balancers databases proxy servers caches queues and or any suitable computing device and or storage devices. The preferred computing cluster can additionally include a variety of hardware systems software platforms and or virtual machines. As noted above each machine in a group preferably has operation information available to interested parties preferably access through the cloud manager . The operation information preferably includes machine status e.g. booting running shut down etc. internal Internet protocol IP address external IP role e.g. web server VoIP load balancer media processor etc. capacity load and or any suitable operation settings or information. A group preferably includes at least a group definition and a group configuration. Preferably the group definition includes a domain specific language DSL that permit the group s to be compiled into group types by the cloud manager . Suitable group configuration attributes can include a condition class and or an action class. Preferably each of the group definition and group configuration are maintained statelessly thereby permitting RESTful configuration monitoring and updating throughout the system according to the principles set forth above.

As shown in the preferred system can further include a monitor module which preferably functions to continuously monitor the status of each group in the computing cluster and to ensure that such current status is consistent with and or substantially identical to a desired status of the user. As shown in a monitor module can monitor a plurality of groups A . . . N. Alternatively each group A . . . N can be monitored by a dedicated monitor module that is the exclusive monitor of the group state at the database and the computing cluster . Preferably the monitor module includes a set of rules defining a rules engine that can be applied in a substantially continuous manner to each of the database and the computing cluster . In operation the group status is updated via the API to the database and in most cases the matching group at the computing cluster is placed into the desired state. The monitor module preferably checks the actual status of the group in the computing cluster and using the rules engine compares the actual state of the group to the desired group state stored in the database . Preferably the rules engine includes a series of when then rules or scripts such that the monitor module only takes action then in response to a predetermined set of conditions when . As an example if the database indicates that a group is to be started but the computing cluster indicates that no hosts have been booted then the monitor module directs the computing cluster to boot the desired hosts. Similarly if one or more hosts are running but are not present in the load balancer then the monitor module directs the computing cluster to transfer the hosts into the load balancer. Preferably the monitor module operates the rules engine in a substantially or entirely stateless manner such that the prior status of the system is not stored maintained or otherwise determinative of the present behavior of the monitor module .

As shown in a method for managing distributed groups in accordance with a preferred embodiment can include at a first computer receiving a group including a group configuration and a group definition in block S storing an initial state of the group at a database in block S at the first computer receiving an instruction to start the group in a cloud telephony system in block S and from the first computer launching the group at a computing cluster in block S. The method preferably functions to readily enable a user to establish create adjust update and or monitor one or more machine groups usable in a distributed computing system. The preferred method can be used in any suitable cloud computing environment. The preferred method is also usable in a telephony network platform such as the one described in patent application Ser. No. 12 417 630 filed 2 Apr. 2009 entitled System and Method for Processing Telephony Sessions incorporated by reference above.

As shown in the preferred method includes block S which recites receiving a group including a group configuration and a group definition at a first computer. Block S preferably functions to receive pull request retrieve and or fetch one or more aspects relating to a group to a first computer. Preferably the first computer is a cloud manager having an access API and communications module of the type described above. Preferably group configurations and or group definitions can be stored on a file repository by any user from which they can be received at the first computer. As noted above block S can include both passive receipt i.e. having files pushed to the first computer active retrieval i.e. requesting or fetching the requisite files or any suitable combination thereof. In one variation of the preferred method block S can further include compiling the group definitions into group types based on one or more of the group configurations. Preferably a group configuration can include a set of rules having one or both of a condition class and an action class. As used herein a condition class can refer to a state or mode in which the group can be and an action class can refer to an action or operation that the group can perform or that can be performed on the group to create a desired condition. Preferably each group has its own set of definitions in a domain specific language that complements the condition action classes for that particular group.

As shown in the preferred method includes block S which recites storing an initial state of the group at a database. Block S preferably functions to push write record generate create and or memorize a file relating to an initial state of the group as defined by its group definition and or one or more group configurations. Preferably block S can be performed at a database of the type described above with reference to . As noted above the database can be integrated into a cloud manager or maintained at one or more discrete and or remote locations. As noted above a suitable database can include any device for storing data such as a mySQL database or an XML file. Block S preferably includes storing a record for each group which can include at least group definitions and group configurations group status role s capacity load and or any suitable operation information relating to the group or any portion thereof. Block S can additionally include storing a security key token or hash to securely identify each group on the computing cluster.

As shown in the preferred method can include block S which recites receiving an instruction to start the group in a cloud telephony system at the first computer. Block S preferably functions to interface with a user to mediate the creation or generation of a group in a distributed network such as the computing cluster described above. Preferably the group can include at least a definition in a domain specific language as well as a set of configurations that set forth conditions and actions applicable to the group. The group can further include a host type roles for the host an instance count and or an instance size. As noted above each of these aspects of the group can be received and compiled at the first computer and stored on the database. Accordingly a simple instruction from a user can be transmitted to the first computer. Preferably block S includes receiving a stateless or RESTful instruction thereby minimizing the complexity of interacting with the cloud telephony system.

As shown in the preferred method can further include block S which recites from first computer launching the group at a computing cluster. Block S preferably functions to push post generate and or create a group at the remote computing cluster which as noted above is preferably configured to host a cloud telephony system. The computing cluster of the preferred method can include one or more of a plurality of machines groups of machines states of machines and or any combination thereof. As noted above suitable machines can be identical in setup or may alternatively be composed of a variety of systems such as web servers voice over Internet protocol VoIP systems media processors load balancers databases proxy servers caches queues and or any suitable computing device and or storage devices. As noted above each machine in a group preferably has operation information available to interested parties which can include machine status e.g. booting running shut down etc. internal Internet protocol IP address external IP role e.g. web server VoIP load balancer media processor etc. capacity load and or any suitable operation settings or information. As noted above a group of machines preferably includes at least a group definition and a group configuration. Preferably the group definition includes a domain specific language that permit the group s to be compiled into group types by the first computer. Suitable group configuration attributes can include a condition class and or an action class. Preferably each of the group definition and group configuration are maintained statelessly thereby permitting RESTful configuration monitoring and updating according to the principles set forth above.

As shown in one variation of the preferred method can include launching a monitoring loop configured to monitor the database and the computing cluster in block S and applying a rules engine including a stateless application of the set of rules at the monitoring loop in block S. Block S preferably functions to cause create generate and or launch a monitoring process that interacts with the group database and the computing cluster. Block S preferably functions to establish a set of procedures processes and or applications for the monitoring loop to follow in a predetermined manner in response to one or more predetermined inputs. Preferably the monitoring loop is an infinite loop running in a substantially stateless or RESTful manner thereby permitting constant real time or near real time monitoring and or updating of the group states with little or no data persistence data storage consumption data processing consumption bandwidth loss or degradation in system performance. As noted above in one variation of the preferred method each individual group has its own unique and dedicated monitoring loop. Alternatively one or more monitoring loops can be configured to monitor one or more groups as determined by the user in establishing the initial state of the group.

As shown in another variation of the preferred method can include block S which recites checking the group status at one of the computing cluster or the database by the monitoring loop. Block S preferably functions to provide the rules engine at the monitoring loop with the necessary data to determine whether the existing state of the groups at the computing cluster is consistent with or identical to a desired state of the group as stored at the database. In another variation of the preferred method shown in block S recites adjusting the group status at the computing cluster by the monitoring loop in accordance with the rules engine in response to one of a change in state of the group at one of the database or the computing cluster. Block S preferably functions to change alter update conform and or adjust an existing group status at the computing cluster to match that of the database using one or more of the set of rules in the rules engine. Preferably block S is performed automatically and substantially simultaneously in response to a difference between the group state at the computing cluster and the database as determined in block S.

As shown in variations of the preferred method can function to continuously and indefinitely control the state of the group at the computing cluster to match the desired state of the group as stored at the database. As described above the group status can be generated and or updated via the API to the database. In block S the matching group is launched at the computing cluster in the desired state. Block S preferably checks the actual status of the group in the computing cluster and using the rules engine compares the actual state of the group to the desired group state stored in the database. As noted above the rules engine preferably includes a series of when then rules or scripts such that the monitor loop only takes action then in response to a predetermined set of conditions when . In the example noted above if the database indicates that a group is to be started but the computing cluster indicates that no hosts have been booted in block S then the monitor loop directs the computing cluster to boot the desired hosts in block S. Similarly if one or more hosts are running but are not present in the load balancer as determined in block S then the monitor loop directs the computing cluster to transfer the hosts into the load balancer in block S. As noted above a preferred rules engine is substantially or entirely stateless such that the prior status of any group is not stored maintained or otherwise determinative of the present behavior of the monitor loop.

An alternative embodiment preferably implements the above methods in a computer readable medium storing computer readable instructions. The instructions are preferably executed by computer executable components preferably integrated with a distributed networked computing cluster with a plurality of machines and a configuration controller. The computer readable medium may be stored on any suitable computer readable media such as RAMs ROMs flash memory EEPROMs optical devices CD or DVD hard drives floppy drives or any suitable device. The computer executable component is preferably a processor but the instructions may alternatively or additionally be executed by any suitable dedicated hardware device.

As a person skilled in the art will recognize from the previous detailed description and from the figures and claims modifications and changes can be made to the preferred embodiments of the invention without departing from the scope of this invention defined in the following claims.

