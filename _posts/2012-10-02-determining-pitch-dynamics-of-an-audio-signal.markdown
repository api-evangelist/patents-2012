---

title: Determining pitch dynamics of an audio signal
abstract: A first-pitch metric function based on a first audio sample and a second pitch-metric function based on a second audio sample may be determined. The first and second pitch-metric functions may have either local minima or local maxima that correspond to candidate pitch values of the first and the second audio samples, respectively. The first and the second pitch-metric functions may be transformed to generate a first and a second transformed pitch-metric function, respectively. A correlation function based on a correlation between the first and the second transformed pitch-metric function may also be determined. A lower-dimensionality representation of the correlation function may further be determined. The lower-dimensionality representation may convey information indicative of pitch dynamics between the first and second audio sample. A computing device having a processor and a memory may perform an action based on the information indicative of the pitch dynamics.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08645128&OS=08645128&RS=08645128
owner: Google Inc.
number: 08645128
owner_city: Mountain View
owner_country: US
publication_date: 20121002
---
Pitch is generally understood as a perception of a tonality of a sound. In the context of speech a change in pitch of may convey contextual information regarding the speaker s mood or intent as well as a variety of other effective or affective states. For example a speaker may change the pitch of the speaker s voice to convey sarcasm emphasis or emotion. Additionally pitch may differentiate two chromatically similar words in tonic languages such as Mandarin Chinese.

In a first example embodiment information indicative of pitch dynamics may be determined. An audio signal may be sampled to provide a first audio sample and a second audio sample. A first pitch metric function as a function of a pitch parameter based on the first audio sample and a second pitch metric function as a function of a pitch parameter based on the second audio sample may be determined. The first pitch metric function may have either local minima or local maxima that correspond to likely candidate pitch values of the first audio sample. The second pitch metric function may have either local minima or local maxima that correspond to a candidate pitch values of the second audio sample. The first pitch metric function may be transformed to generate a first transformed pitch metric function. The second pitch metric function may be transformed to generate a second transformed pitch metric function. A correlation function based on a correlation between the first transformed pitch metric function and the second transformed pitch metric function may also be determined. A lower dimensionality representation of the correlation function may also be determined. The lower dimensionality representation of the correlation function may convey information indicative of pitch dynamics of the audio signal from the first audio sample to the second audio sample. A computing device having a processor and a memory may perform an action based on the information indicative of the pitch dynamics.

In a second example embodiment a non transitory computer readable memory having stored thereon instructions executable by a computing device is provided. The instructions when executed by the computing device may cause the computing device to perform functions in accordance with the first example embodiment.

In a third example embodiment a computing device is provided. The computing device may include at least one processor a data storage and program instructions in the data storage. The program instructions upon execution by the at least one processor may cause the computing system to perform functions in accordance with the first example embodiment.

These as well as other aspects advantages and alternatives will become apparent to those of ordinary skill in the art by reading the following detailed description with reference where appropriate to the accompanying drawings. Further it should be understood that the description provided in this summary section and elsewhere in this document is intended to illustrate the claimed subject matter by way of example and not by way of limitation.

Certain computer systems and applications configured to process human speech may utilize information regarding a change in pitch of an audio signal. For example automatic speech recognition ASR systems may use the change in pitch to process an utterance in order to determine the meaning of the utterance and or a speaker s intent in speaking the utterance. As another example a computing device configured to run a query by hum application may utilize a change of pitch or sequence of changes in pitch in an audio signal of a user s voice to identify a command. In these scenarios the pitch dynamics of the audio signal such as a change in pitch and rate of change in the pitch may have more significance than an actual value of the pitch e.g. a fundamental frequency at a given time.

Pitch is well correlated to waveform periodicity and can be represented as a fundamental frequency which is a physical property of the speech waveform. In the scenarios described above information regarding the pitch dynamics of the speech waveform such as a change in pitch or a rate of change in pitch may be sufficient for a task such that it is not necessary to estimate an actual value of the pitch of the speech waveform at a given time. Furthermore information regarding pitch dynamics may be in an unprocessed form suitable for modem statistical learning algorithms avoiding a need to estimate the pitch and or derivatives of the pitch of the speech waveform at a given time.

As used herein the term pitch refers to and is synonymous with the fundamental frequency of a waveform. Additionally the term pitch dynamics refers to any set of parameters that includes information regarding a change in pitch between two portions of an audio signal which may include but is not limited to a change in pitch a magnitude of a change in pitch and a rate of change in pitch.

Disclosed herein are example methods systems and computing devices for determining information indicative of pitch dynamics of an audio signal. An example method may include sampling an audio signal to provide a first audio sample and a second audio sample. The example method may also determining first and second pitch metric functions based on the first and second audio samples respectively. The pitch metric functions may be based on one of a number of possible time domain frequency domain mixed time frequency domain or analysis by synthesis pitch principles. Depending on the principle upon which the pitch metric functions are based the pitch metric functions may have either local minima or local maxima that correspond to candidate pitch values of the respective audio samples.

The example method may further include transforming the first pitch metric function and the second pitch metric function to generate a first transformed pitch metric function and a second transformed pitch metric function. The example method may additionally include determining a correlation function based on a correlation between the first transformed pitch metric function and the second transformed pitch metric function. The correlation function may in one example be a cross correlation function.

The correlation function may convey information indicative of the pitch dynamics of the audio signal from the first sample to the second sample. Because the correlation function may have many dimensions the example method may also include determining a lower dimensionality representation of the correlation function. The lower dimensionality representation may include fewer dimensions than the correlation function.

The example method may additionally include performing an action based on the information indicative of the pitch dynamics. If the computing device functions as an ASR system the computing device may use the information indicative of the pitch dynamics to train the ASR system or to identify a text string from a corpus of text strings. As another example the computing device may identify a command based on the information indicative of the pitch dynamics. Other applications may also be possible.

The methods devices and systems described herein can be implemented using client devices and or so called cloud based server devices. Under various aspects of this paradigm client devices such as mobile phones and tablet computers may offload some processing and storage responsibilities to remote server devices. At least some of the time these client services are able to communicate via a network such as the Internet with the server devices. As a result applications that operate on the client devices may also have a persistent server based component. Nonetheless it should be noted that at least some of the methods processes and techniques disclosed herein may be able to operate entirely on a client device or a server device.

Furthermore the server devices described herein may not necessarily be associated with a client server architecture and therefore may be interchangeably referred to as computing devices. Similarly the client devices described herein also may not necessarily be associated with a client server architecture and therefore may be interchangeably referred to as user devices. 

This section describes general system and device architectures for such client devices and server devices. However the methods devices and systems presented in the subsequent sections may operate under different paradigms as well. Thus the embodiments of this section are merely examples of how these methods devices and systems can be enabled.

Network may be for example the Internet or some other form of public or private Internet Protocol IP network. Thus client devices and may communicate using packet switching technologies. Nonetheless network may also incorporate at least some circuit switching technologies and client devices and may communicate via circuit switching alternatively or in addition to packet switching.

A server device may also communicate via network . Particularly server device may communicate with client devices and according to one or more network protocols and or application level protocols to facilitate the use of network based or cloud based computing on these client devices. Server device may include integrated data storage e.g. memory disk drives etc. and may also be able to access a separate server data storage . Communication between server device and server data storage may be direct via network or both direct and via network as illustrated in . Server data storage may store application data that is used to facilitate the operations of applications performed by client devices and and server device .

Although only three client devices one server device and one server data storage are shown in communication system may include any number of each of these components. For instance communication system may comprise millions of client devices thousands of server devices and or thousands of server data storages. Furthermore client devices may take on forms other than those in .

User interface may comprise user input devices such as a keyboard a keypad a touch screen a computer mouse a track ball a joystick and or other similar devices now known or later developed. User interface may also comprise user display devices such as one or more cathode ray tubes CRT liquid crystal displays LCD light emitting diodes LEDs displays using digital light processing DLP technology printers light bulbs and or other similar devices now known or later developed. Additionally user interface may be configured to generate audible output s via a speaker speaker jack audio output port audio output device earphones and or other similar devices now known or later developed. In some embodiments user interface may include software circuitry or another form of logic that can transmit data to and or receive data from external user input output devices.

Communication interface may include one or more wireless interfaces and or wireline interfaces that are configurable to communicate via a network such as network shown in . The wireless interfaces if present may include one or more wireless transceivers such as a Bluetooth transceiver a Wifi transceiver perhaps operating in accordance with an IEEE 802.11 standard e.g. 802.11b 802.11g 802.11n a WiMAX transceiver perhaps operating in accordance with an IEEE 802.16 standard a Long Term Evolution LTE transceiver perhaps operating in accordance with a 3rd Generation Partnership Project 3GPP standard and or other types of wireless transceivers configurable to communicate via local area or wide area wireless networks. The wireline interfaces if present may include one or more wireline transceivers such as an Ethernet transceiver a Universal Serial Bus USB transceiver or similar transceiver configurable to communicate via a twisted pair wire a coaxial cable a fiber optic link or other physical connection to a wireline device or network.

Processor may include one or more general purpose processors e.g. microprocessors and or one or more special purpose processors e.g. digital signal processors DSPs graphical processing units GPUs floating point processing units FPUs network processors or application specific integrated circuits ASICs . Processor may be configured to execute computer readable program instructions that are contained in data storage and or other instructions to carry out various functions described herein.

Thus data storage may include one or more non transitory computer readable storage media that can be read or accessed by processor . The one or more computer readable storage media may include volatile and or non volatile storage components such as optical magnetic organic or other memory or disc storage which can be integrated in whole or in part with processor . In some embodiments data storage may be implemented using a single physical device e.g. one optical magnetic organic or other memory or disc storage unit while in other embodiments data storage may be implemented using two or more physical devices.

Data storage may also include program data that can be used by processor to carry out functions described herein. In some embodiments data storage may include or have access to additional data storage components or devices e.g. cluster data storages described below .

Server device and server data storage device may store applications and application data at one or more places accessible via network . These places may be data centers containing numerous servers and storage devices. The exact physical location connectivity and configuration of server device and server data storage device may be unknown and or unimportant to client devices. Accordingly server device and server data storage device may be referred to as cloud based devices that are housed at various remote locations. One possible advantage of such cloud based computing is to offload processing and data storage from client devices thereby simplifying the design and requirements of these client devices.

In some embodiments server device and server data storage device may be a single computing device residing in a single data center. In other embodiments server device and server data storage device may include multiple computing devices in a data center or even multiple computing devices in multiple data centers where the data centers are located in diverse geographic locations. For example depicts each of server device and server data storage device potentially residing in a different physical location.

In some embodiments each of the server clusters A B and C may have an equal number of server devices an equal number of cluster data storages and an equal number of cluster routers. In other embodiments however some or all of the server clusters A B and C may have different numbers of server devices different numbers of cluster data storages and or different numbers of cluster routers. The number of server devices cluster data storages and cluster routers in each server cluster may depend on the computing task s and or applications assigned to each server cluster.

In the server cluster A for example server devices A can be configured to perform various computing tasks of server device . In one embodiment these computing tasks can be distributed among one or more of server devices A. Server devices B and C in server clusters B and C may be configured the same or similarly to server devices A in server cluster A. On the other hand in some embodiments server devices A B and C each may be configured to perform different functions. For example server devices A may be configured to perform one or more functions of server device and server devices B and server device C may be configured to perform functions of one or more other server devices. Similarly the functions of server data storage device can be dedicated to a single server cluster or spread across multiple server clusters.

Cluster data storages A B and C of the server clusters A B and C respectively may be data storage arrays that include disk array controllers configured to manage read and write access to groups of hard disk drives. The disk array controllers alone or in conjunction with their respective server devices may also be configured to manage backup or redundant copies of the data stored in cluster data storages to protect against disk drive failures or other types of failures that prevent one or more server devices from accessing one or more cluster data storages.

Similar to the manner in which the functions of server device and server data storage device can be distributed across server clusters A B and C various active portions and or backup redundant portions of these components can be distributed across cluster data storages A B and C. For example some cluster data storages A B and C may be configured to store backup versions of data stored in other cluster data storages A B and C.

Cluster routers A B and C in server clusters A B and C respectively may include networking equipment configured to provide internal and external communications for the server clusters. For example cluster routers A in server cluster A may include one or more packet switching and or routing devices configured to provide i network communications between server devices A and cluster data storage A via cluster network A and or ii network communications between the server cluster A and other devices via communication link A to network . Cluster routers B and C may include network equipment similar to cluster routers A and cluster routers B and C may perform networking functions for server clusters B and C that cluster routers A perform for server cluster A.

Additionally the configuration of cluster routers A B and C can be based at least in part on the data communication requirements of the server devices and cluster storage arrays the data communications capabilities of the network equipment in the cluster routers A B and C the latency and throughput of the local cluster networks A B C the latency throughput and cost of the wide area network connections A B and C and or other factors that may contribute to the cost speed fault tolerance resiliency efficiency and or other design goals of the system architecture.

As shown in client device may include a communication interface a user interface a processor and data storage all of which may be communicatively linked together by a system bus network or other connection mechanism .

Communication interface functions to allow client device to communicate using analog or digital modulation with other devices access networks and or transport networks. Thus communication interface may facilitate circuit switched and or packet switched communication such as POTS communication and or IP or other packetized communication. For instance communication interface may include a chipset and antenna arranged for wireless communication with a radio access network or an access point. Also communication interface may take the form of a wireline interface such as an Ethernet Token Ring or USB port. Communication interface may also take the form of a wireless interface such as a Wifi Bluetooth global positioning system GPS or wide area wireless interface e.g. WiMAX or LTE . However other forms of physical layer interfaces and other types of standard or proprietary communication protocols may be used over communication interface . Furthermore communication interface may comprise multiple physical communication interfaces e.g. a Wifi interface a Bluetooth interface and a wide area wireless interface .

User interface may function to allow client device to interact with a human or non human user such as to receive input from a user and to provide output to the user.

Thus user interface may include input components such as a keypad keyboard touch sensitive or presence sensitive panel computer mouse trackball joystick microphone still camera and or video camera. User interface may also include one or more output components such as a display screen which for example may be combined with a presence sensitive panel CRT LCD LED a display using DLP technology printer light bulb and or other similar devices now known or later developed. User interface may also be configured to generate audible output s via a speaker speaker jack audio output port audio output device earphones and or other similar devices now known or later developed. In some embodiments user interface may include software circuitry or another form of logic that can transmit data to and or receive data from external user input output devices. Additionally or alternatively client device may support remote access from another device via communication interface or via another physical interface not shown .

Processor may comprise one or more general purpose processors e.g. microprocessors and or one or more special purpose processors e.g. DSPs GPUs FPUs network processors or ASICs . Data storage may include one or more volatile and or non volatile storage components such as magnetic optical flash or organic storage and may be integrated in whole or in part with processor . Data storage may include removable and or non removable components.

Generally speaking processor may be capable of executing program instructions e.g. compiled or non compiled program logic and or machine code stored in data storage to carry out the various functions described herein. Therefore data storage may include a non transitory computer readable medium having stored thereon program instructions that upon execution by client device cause client device to carry out any of the methods processes or functions disclosed in this specification and or the accompanying drawings. The execution of program instructions by processor may result in processor using data .

By way of example program instructions may include an operating system e.g. an operating system kernel device driver s and or other modules and one or more application programs e.g. address book email web browsing social networking and or gaming applications installed on client device . Similarly data may include operating system data and application data . Operating system data may be accessible primarily to operating system and application data may be accessible primarily to one or more of application programs . Application data may be arranged in a file system that is visible to or hidden from a user of client device .

Application programs may communicate with operating system through one or more application programming interfaces APIs . These APIs may facilitate for instance application programs reading and or writing application data transmitting or receiving information via communication interface receiving or displaying information on user interface and so on.

In some vernaculars application programs may be referred to as apps for short. Additionally application programs may be downloadable to client device through one or more online application stores or application markets. However application programs can also be installed on client device in other ways such as via a web browser or through a physical interface e.g. a USB port on client device .

At block the method includes sampling and buffering an audio signal. A computing device may receive an audio signal x n from a user interface component such as a microphone or from another computing device via a network connection. The computing device may down sample the audio signal x n to determine a sampled audio signal. Down sampling the audio signal may remove high frequency components that are unnecessary for determining a change in pitch of the audio signal. In one example the computing device may use a fixed sampling rate such as a sampling rate of about 8 kHz. In another example the computing device may vary the sampling rate. In yet another example the computing device receives the audio signal as the sampled audio signal.

The computing device may then buffer the sampled audio signal to determine a buffered audio signal x n k where k is a frame index. In one example the length of each frame may be a fixed value such as a value between 25 msec and 65 msec. In another example the computing device may vary the length of the each frame based on a signal to noise ratio SNR of the audio signal. Varying the sampling rate may allow the computing device to account for a change in the noise level of the audio signal that may affect subsequent processing of the frames of the buffered audio signal. For instance the computing device may be configured to vary the length of each frame from about 25 msec to about 65 msec. If the SNR is high the length of each frame may be closer to about 65 msec whereas the length of each frame may be closer to about 25 msec for a low SNR.

At block the method includes determining a pitch metric function for two frames. A pitch metric function may in some instances be defined as a function of the fundamental frequency of a waveform. The pitch metric function may convey information related to the probability of a frequency being a fundamental frequency of the speech audio signal. In one example a pitch metric function may exhibit local maxima at the frequencies that are candidate pitch values. In another example a pitch metric function may exhibit local minima at the frequencies that are candidate pitch values.

When the audio signal contains a single sound source i.e. a voice then one candidate pitch value may be the actual pitch of the sound source e.g. a singer . When the audio signal contains more than one sound source i.e. a singer and a guitar then more than one candidate pitch values may correspond to the actual pitch values of the sound sources. A set of candidate pitch values may contain as many actual pitch values as a number of sound sources. The set may also contain candidate pitch values that may not be related to a sound source due to noise. Additionally the set may also contain candidate pitch values that are harmonically related to the actual pitch value of a sound source e.g. double or half .

A pitch metric function g p k may convey information related to a likelihood of a pitch parameter p corresponding to a candidate pitch value of the buffered audio signal x n k . That is the pitch metric function g p k may convey information indicative of a given frequency being the fundamental frequency of a waveform included in the buffered audio signal x n k . The pitch parameter could be a frequency a period or other parameter that characterizes the pitch of the kframe. For instance if the pitch parameter is frequency the pitch metric function g p k may convey information indicative of a likelihood that a given frequency is the fundamental frequency of the buffered audio sample x n k . The computing device may determine a first pitch metric function g p l and a second pitch metric function g p m . The frames l and m could be successive frames i.e. with m l 1. Alternatively l and m could be non successive frames i.e. with m l 1.

The pitch metric function g p k may be based on one of a number of possible time domain frequency domain mixed time frequency domain or analysis by synthesis pitch estimation principles. If the pitch metric function g p k is a time domain function then the pitch parameter may be a pitch period. Thus the pitch metric function g p k may indicate a likelihood as a function of pitch period that a given pitch correlates to a candidate pitch value of the kframe of the buffered audio signal x n k . In one example pitch metric function g p k may be based on the YIN estimator which is given in part by the following equation 

If the pitch metric function g p k is based on a frequency domain principle then the pitch parameter may be frequency. Thus the pitch metric function may g p k may indicate a likelihood as a function of frequency that a given frequency corresponds to the candidate pitch value of the kframe of the buffered audio signal x n k . In one example the pitch metric function may be based on a harmonic sinewave model given by the following equation 

If the pitch metric function g p k is based on an analysis by synthesis principle the pitch parameter may also be frequency. In this case the pitch metric function g p k may convey information indicative of a likelihood that a frequency corresponds to a candidate pitch value based on a characteristic of the kframe of the buffered audio signal x n k . For instance if the characteristic is the SNR of the kframe one example of a pitch metric function based on an analysis by synthesis principle may be given by the following equation SNR SNR SNR 

where x is the kframe of the buffered audio the signal x n k SNR f x is a normalized SNR of x at a frequency f SNR is a signal to noise ratio of x at a frequency f and SNR f x is a stochastic integration of SNR f x using a white Gaussian noise model for x. SNRis used to account for possible low frequency bias that may develop when down sampling the audio signal x n . Candidate pitch values of the kframe may correspond to frequencies that correspond to a local maxima of the pitch metric function g p k .

At block the method includes sampling the pitch metric functions on a logarithmic pitch parameter axis to determine transformed pitch metric functions. The computing device may determined a transformed pitch metric function g logp k for the kframe by sampling the pitch metric function g p k on a logarithmic pitch parameter axis using a logarithmic base z. For instance if the pitch parameter is frequency the pitch metric functions g p l g p m are sampled on a log frequency axis. In one example the computing device may use a logarithmic base of two to determine the transformed pitch metric functions. In this example the transformed pitch metric function may be written as g logp k . In another example the computing device may use a different logarithmic base to determine the transformed pitch metric function.

The computing device may sample the first pitch metric function on the logarithmic pitch parameter axis to determine a first transformed pitch metric function g logp l . The computing device may also sample the second pitch metric function on the logarithmic pitch parameter axis to determine a second transformed pitch metric function g logp m . Additionally sampling the pitch metric functions g p l g p m on the logarithmic pitch parameter may include filtering the pitch metric functions. For instance since a human voice may have a fundamental frequency between about 55 Hz and about 355 Hz the transformed pitch metric functions may reduce the spectral range down to a range of pitch parameters corresponding to a frequency range of about 55 Hz to about 355 Hz.

In one example the computing device may also apply a modification factor A to the pitch parameter when determining the transformed pitch metric functions. The modification factor may adjust the scaling of the pitch parameter on the logarithmic pitch parameter axis. For instance the computing device may determine the transformed pitch metric function g log A p l and the second pitch metric function g log A p m .

At block the method includes determining a correlation function based on a correlation between the transformed pitch metric functions. Since the first transformed pitch metric function g logp l and the second transformed pitch metric function g logp m are functions of a logarithm of the pitch parameter changes in the pitch parameter between the two frames may have an approximately linear relationship. Thus a correlation function r t k may convey information indicative of pitch dynamics between the two frames such as information indicative of a magnitude of a change in pitch and or a rate of change of the pitch.

Additionally for a slow varying waveform in which the pitch does not change substantially between two frames the correlation function r t k may not be adversely affected by errors that affect traditional pitch estimation techniques such as halving or doubling of the pitch frequency or pitch period. Furthermore since the correlation function r t k is not based on estimations of actual frequencies or periods corresponding to the pitch of a given frame the correlation function r t k may not be as adversely affected by noise in the audio signal x n as other methods or processes that employ an initial pitch estimation step.

In one example the correlation function r t k may be a cross correlation between the first transformed pitch metric function and the second transformed pitch metric function. In this example the correlation function r t m may be given by the following equation 

As previously stated the correlation function r t k may convey information indicative of the pitch dynamics of the audio signal x n k from the lframe to the mframe. are graphs of example correlation functions that may convey information indicative of the pitch dynamics between two frames of the audio signal x n . Specifically are graphs of example cross correlation functions in which the pitch parameter is frequency while are graphs of example cross correlation functions in which the pitch parameter is pitch period.

In another example the pitch parameter is a period and the cross correlation function r t k represents a correlation between the first transformed pitch metric function g log A p l and the second transformed pitch metric function g log A p m as a function of a lag period. In this example a peak value of the correlation function r t m corresponding to a negative lag period may convey information indicative of a change in pitch that is positive. That is because the pitch period is inversely proportional to the pitch a decrease in the pitch period between the frames may indicate that a pitch of the mframe is greater than a pitch of the lframe. Conversely a peak value of the correlation function r t k that corresponds to a positive lag period may convey information indicative of a change in pitch that is negative.

Additionally the correlation function r t k may convey information indicative of a rate of change of the pitch. For example if fis greater than f as indicated in then the first example correlation function may convey information indicative of a rate of change of the pitch from that is greater than a correlation function having a peak value that corresponds to f.

Returning to the computing device may also determine a normalized correlation function r t m . Normalizing the correlation function r t m may enhance the pitch dynamics for weakly periodic signals. However normalizing the correlation function r t m may also make the correlation function more susceptible to noise. In one example the computing device determines a normalized correlation function upon determining that the SNRs of the audio signals x n l x n m are above a threshold SNR.

At block the method includes determining a lower dimensionality representation of the correlation function that conveys information indicative of the pitch dynamics. While the correlation function r t k or the normalized correlation function r t k may convey information indicative of the pitch dynamics the correlation function r t k may have many dimensions i.e. parameters perhaps as many as several hundred dimensions or more. A lower dimensionality representation a f k of the correlation function r t k may compress the correlation function r t k while retaining information indicative of the pitch dynamics between the first audio sample x n l and the second audio sample x n m .

Because a speech waveform is typically slow varying the lower dimensionality representation a f k may include a sufficient number of dimensions to accurately reproduce the information indicative of the pitch dynamics included in the correlation function r t k . The lower dimensionality representation a f k may thus allow the computing device to more efficiently process the audio signal x n when performing an action based on the information indicative of the pitch dynamics. A level of accuracy of a reproduction of the information indicative of the pitch dynamics may vary with the SNR of the first frame x n l and the second frame x n m . That is the higher the SNR of the frames the higher the level of accuracy of the reproduction.

In one example the computing device may determine the lower dimensionality representation a f k of the correlation function r t k or the normalized correlation function r t k by determining a discrete transform such as a discrete cosine transform. For a typical speech waveform the lower dimensionality representation a f k may have about eight to ten dimensions. In another example the computing device may determine the lower dimensionality representation a f k using another discrete transform.

In yet another example the computing device may select from a number of possible transforms or techniques to determine the lower dimensionality representation a f k based on the SNR of the lframe and or mframe of the buffered audio signal x n k . For instance if the SNRs are above a threshold SNR the computing device may determine the lower dimensionality representation a f k using a discrete cosine transform. If the SNRs are below the threshold SNR the computing device may determine the lower dimensionality representation a f k using a different transform perhaps by using a discrete Fourier transform. Other examples may also be possible.

At block the method includes performing an action based on the information indicative of the pitch dynamics. In one example the computing device functions as an ASR system. The computing device may use the information indicative of the pitch dynamics to identify a text string corresponding to an utterance from a corpus of text stings. For instance the computing device may determine that an utterance could correspond to two chromatically similar text strings. The computing device may distinguish between the text strings based on the information indicative of the pitch dynamics perhaps by processing the information indicative of the pitch dynamics to determine whether a change in pitch is greater than a threshold. That is the computing device may identify a first text string if the change in pitch is below the threshold and the computing device may identify a second text string if the change in pitch is above the threshold. Alternatively the computing device may use the information indicative of the pitch dynamics to train the ASR system. In this scenario the computing device may not process the information indicative of the pitch dynamics. Rather the computing device may train the ASR system using the information indicative of the pitch dynamics.

In another example the computing device may function as an emotion recognition system. The computing device may utilize the information indicative of the pitch dynamics to identify an emotion of a speaker. For example certain pitch dynamics may indicate that a speaker is happy. The computing device may process the information indicative of the pitch dynamics and may perform an action in response to determining that the information indicative of the pitch dynamics indicates that the user is happy.

In yet another example the computing device may be a component of a query by hum system. A user of the computing device may use a change in pitch of the user s voice to cause the computing device to execute a command. For instance a first command may correspond to a first pitch dynamic and a second command may correspond to a second pitch dynamic. The computing device may process the information indicative of the pitch dynamics to identify one of the first command or the second command as the user requested command.

After performing the steps of block the method may end. In one example the computing device may perform additional iterations of the method . For instance in a second iteration of the method the computing device may determine a second change in pitch between frames m l m .

The above detailed description describes various features and functions of the disclosed systems devices and methods with reference to the accompanying figures. In the figures similar symbols typically identify similar components unless context dictates otherwise. The illustrative embodiments described in the detailed description figures and claims are not meant to be limiting. Other embodiments can be utilized and other changes can be made without departing from the spirit or scope of the subject matter presented herein. It will be readily understood that the aspects of the present disclosure as generally described herein and illustrated in the figures can be arranged substituted combined separated and designed in a wide variety of different configurations all of which are explicitly contemplated herein.

For situations in which the systems discussed here collect personal information about users the users may be provided with an opportunity to opt in out of programs or features that may collect personal information e.g. information about a user s preferences or a user s utterances made to an ASR system . In addition certain data may be anonymized in one or more ways before it is stored or used so that personally identifiable information is removed. For example a user s identity may be anonymized so that the no personally identifiable information can be determined for the user and so that any identified user preferences or user interactions are generalized for example generalized based on user demographics rather than associated with a particular user.

With respect to any or all of the message flow diagrams scenarios and flow charts in the figures and as discussed herein each step block and or communication may represent a processing of information and or a transmission of information in accordance with example embodiments. Alternative embodiments are included within the scope of these example embodiments. In these alternative embodiments for example functions described as steps blocks transmissions communications requests responses and or messages may be executed out of order from that shown or discussed including in substantially concurrent or in reverse order depending on the functionality involved. Further more or fewer steps blocks and or functions may be used with any of the message flow diagrams scenarios and flow charts discussed herein and these message flow diagrams scenarios and flow charts may be combined with one another in part or in whole.

A step or block that represents a processing of information may correspond to circuitry that can be configured to perform the specific logical functions of a herein described method or technique. Alternatively or additionally a step or block that represents a processing of information may correspond to a module a segment or a portion of program code including related data . The program code may include one or more instructions executable by a processor for implementing specific logical functions or actions in the method or technique. The program code and or related data may be stored on any type of computer readable medium such as a storage device including a disk drive a hard drive or other storage media.

The computer readable medium may also include non transitory computer readable media such as computer readable media that stores data for short periods of time like register memory processor cache and or random access memory RAM . The computer readable media may also include non transitory computer readable media that stores program code and or data for longer periods of time such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks and or compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. A computer readable medium may be considered a computer readable storage medium for example or a tangible storage device.

Moreover a step or block that represents one or more information transmissions may correspond to information transmissions between software and or hardware modules in the same physical device. However other information transmissions may be between software modules and or hardware modules in different physical devices.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope and spirit being indicated by the following claims.

