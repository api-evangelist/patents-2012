---

title: Three dimensional contriver tool for modeling with multi-touch devices
abstract: A method, apparatus, article of manufacture, and computer readable storage medium provides the ability to perform a three-dimensional (3D) modeling operation. A modeling tool is activated in a 3D modeling application. A visual representation (having three separate regions) of a grid system tool is displayed on a digital modeling canvas of the 3D modeling application. The grid system controls whether a gesture is captured as a modeling operation or a navigation operation. A starting touch event (of the gesture) is received in/on one of the three separate regions. The region where the starting touch event is received determines the operation that is to be performed/selected. The operation may be a 3D geometry creation operation, a restroking operation, or a navigation operation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08902222&OS=08902222&RS=08902222
owner: Autodesk, Inc.
number: 08902222
owner_city: San Rafael
owner_country: US
publication_date: 20120116
---
This application is related to the following co pending and commonly assigned patent applications which applications are incorporated by reference herein 

U.S. patent application Ser. No. 13 085 195 filed on Apr. 12 2011 entitled Transform Manipulator Control by Gregory W. Fowler Jason Bellenger and Hans Frederick Brown 

U.S. patent application Ser. No. 13 351 128 filed on the same date herewith entitled DYNAMIC CREATION AND MODELING OF SOLID MODELS by Gregory W. Fowler Jason Vincent Ma and Hans Frederick Brown and

U.S. patent application Ser. No. 13 351 133 filed on the same date herewith entitled GESTURES AND TOOLS FOR CREATING AND EDITING SOLID MODELS by Gregory W. Fowler Jason Vincent Ma and Hans Frederick Brown.

The present invention relates generally to three dimensional 3D modeling and in particular to a method apparatus and article of manufacture for a 3D contriver tool that is used for dynamically creating editing and navigating a 3D model on a multi touch device.

Many 3D modeling and drawing applications are used in both desktop and multi touch devices. However none of the existing multi touch 3D modeling or drawing applications provide a comprehensive 3D modeling system that take advantage of the multi touch capabilities available across multiple mobile devices without interfering with basic 3D navigation or requiring proficiency in the art of 3D modeling. To better understand the problems and deficiencies of the prior art a description of prior art modeling applications and activities may be useful.

Some prior art modeling applications e.g. the Spaceclaim Engineering application have explored multi touch interactions in the context of 3D modeling tasks. However such prior art applications mimic the interaction available via a mouse pointer. These interactions are not tailored for laymen to use without 3D modeling experience. Many of the operations also require two hand interactions that may not be adequate for smaller devices and require more muscle memory.

In some cases specific creation tools e.g. extrude revolve offset etc. may have been implemented for multi touch use. However such creation tools are all static modality tools or commands that require proper selection. The tools are detached from the 3D navigation experience and do not fully take advantage of the multi touch input devices.

In view of the above it may be understood that 3D modeling activities and tasks generally imply and require an understanding mastering of concepts such as coordinate systems tool operations tool selection sequence and validity of selections. Accordingly what is needed is the capability to easily perform a variety of modeling operations including creation modification and navigation on a multi touch input device without multiple steps or selection requirements.

Embodiments of the invention provide a 3D contriver tool that introduces new multi touch gestures and interactions that combine multiple concepts into a simple predictable workflow that mimics how brushes are used on an empty canvas. By simply touching a designated space the user can rapidly create forms without having to worry about tool sequencing profiles selection direction etc.

Additionally once a form is laid down in space the user can continue adjusting the form geometry without having to launch an edit tool or invoke a special mode. By simply re stroking the form the system detects a modification operation and automatically switches to that operational mode.

Furthermore embodiments of the invention introduce a soft 3D navigation tumbling activation deactivation method that does not require the usage of multi finger gestures or special modes. This transient navigation consists of tracking multi touch inputs outside a virtual modeling box plane that provides a 3D modeling environment that flows naturally without enforcing mode tool switching or difficult clutch gestures to learn.

All of the above functionality is presented to the user as a single tool that is highly context sensitive. The tool exposes all of the above interactions without interfering with 3D Navigational activities e.g. pan zoom tumble .

In the following description reference is made to the accompanying drawings which form a part hereof and which is shown by way of illustration several embodiments of the present invention. It is understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present invention.

Embodiments of the invention provide a multi touch 3D modeling system that is based on the idea of using life like drawing tools on a blank canvas. A single tool provides the ability to automatically control creating positioning editing scaling and posing based on the view direction and multi touch events. All of these operations are provided within the same context and without exiting the tool for 3D navigation operations.

Accordingly a user is provided with access to a number of modeling interactions e.g. creating editing that create base geometry that can be refined and later sculpted using 3D modeling tools. With the single tool referred to herein as a 3D contriver tool the user can explore new 3D creations without requiring special commands or modes. Such an approach maintains the artistic flow that users appreciate from prior art brushing and stroking systems.

In one embodiment the computer operates by the general purpose processor A performing instructions defined by the computer program under control of an operating system . The computer program and or the operating system may be stored in the memory and may interface with the user and or other devices to accept input and commands and based on such input and commands and the instructions defined by the computer program and operating system to provide output and results.

Output results may be presented on the display or provided to another device for presentation or further processing or action. In one embodiment the display comprises a liquid crystal display LCD having a plurality of separately addressable liquid crystals. Alternatively the display may comprise a light emitting diode LED display having clusters of red green and blue diodes driven together to form full color pixels. Each liquid crystal or pixel of the display changes to an opaque or translucent state to form a part of the image on the display in response to the data or information generated by the processor from the application of the instructions of the computer program and or operating system to the input and commands. The image may be provided through a graphical user interface GUI module A. Although the GUI module A is depicted as a separate module the instructions performing the GUI functions can be resident or distributed in the operating system the computer program or implemented with special purpose memory and processors.

In one or more embodiments the display is integrated with into the computer and comprises a multi touch device having a touch sensing surface e.g. track pod or touch screen with the ability to recognize the presence of two or more points of contact with the surface. Examples of multi touch devices include mobile devices e.g. iPhone Nexus S Droid devices etc. tablet computers e.g. iPad HP Touchpad portable handheld game music video player console devices e.g. iPod Touch MP3 players Nintendo 3DS PlayStation Portable etc. touch tables and walls e.g. where an image is projected through acrylic and or glass and the image is then backlit with LEDs .

Some or all of the operations performed by the computer according to the computer program instructions may be implemented in a special purpose processor B. In this embodiment the some or all of the computer program instructions may be implemented via firmware instructions stored in a read only memory ROM a programmable read only memory PROM or flash memory within the special purpose processor B or in memory . The special purpose processor B may also be hardwired through circuit design to perform some or all of the operations to implement the present invention. Further the special purpose processor B may be a hybrid processor which includes dedicated circuitry for performing a subset of functions and other circuits for performing more general functions such as responding to computer program instructions. In one embodiment the special purpose processor is an application specific integrated circuit ASIC .

The computer may also implement a compiler which allows an application program written in a programming language such as COBOL Pascal C FORTRAN or other language to be translated into processor readable code. Alternatively the compiler may be an interpreter that executes instructions source code directly translates source code into an intermediate representation that is executed or that executes stored precompiled code. Such source code may be written in a variety of programming languages such as Java Perl Basic etc. After completion the application or computer program accesses and manipulates data accepted from I O devices and stored in the memory of the computer using the relationships and logic that was generated using the compiler .

The computer also optionally comprises an external communication device such as a modem satellite link Ethernet card or other device for accepting input from and providing output to other computers .

In one embodiment instructions implementing the operating system the computer program and the compiler are tangibly embodied in a non transient computer readable medium e.g. data storage device which could include one or more fixed or removable data storage devices such as a zip drive floppy disc drive hard drive CD ROM drive tape drive etc. Further the operating system and the computer program are comprised of computer program instructions which when accessed read and executed by the computer causes the computer to perform the steps necessary to implement and or use the present invention or to load the program of instructions into a memory thus creating a special purpose data structure causing the computer to operate as a specially programmed computer executing the method steps described herein. Computer program and or operating instructions may also be tangibly embodied in memory and or data communications devices thereby making a computer program product or article of manufacture according to the invention. As such the terms article of manufacture program storage device and computer program product as used herein are intended to encompass a computer program accessible from any computer readable device or media.

Of course those skilled in the art will recognize that any combination of the above components or any number of different components peripherals and other devices may be used with the computer .

A network such as the Internet connects clients to server computers . Network may utilize ethernet coaxial cable wireless communications radio frequency RF etc. to connect and provide the communication between clients and servers . Clients may execute a client application or web browser and communicate with server computers executing web servers . Such a web browser is typically a program such as MICROSOFT INTERNET EXPLORER MOZILLA FIREFOX OPERA APPLE SAFARI etc. Further the software executing on clients may be downloaded from server computer to client computers and installed as a plug in or ACTIVEX control of a web browser. Accordingly clients may utilize ACTIVEX components component object model COM or distributed COM DCOM components to provide a user interface on a display of client . The web server is typically a program such as MICROSOFT S INTERNET INFORMATION SERVER .

Web server may host an Active Server Page ASP or Internet Server Application Programming Interface ISAPI application which may be executing scripts. The scripts invoke objects that execute business logic referred to as business objects . The business objects then manipulate data in database through a database management system DBMS . Alternatively database may be part of or connected directly to client instead of communicating obtaining the information from database across network . When a developer encapsulates the business functionality into objects the system may be referred to as a component object model COM system. Accordingly the scripts executing on web server and or application invoke COM objects that implement the business logic. Further server may utilize MICROSOFT S Transaction Server MTS to access required data stored in database via an interface such as ADO Active Data Objects OLE DB Object Linking and Embedding DataBase or ODBC Open DataBase Connectivity .

Generally these components all comprise logic and or data that is embodied in or retrievable from device medium signal or carrier e.g. a data storage device a data communications device a remote computer or device coupled to the computer via a network or via another data communications device etc. Moreover this logic and or data when read executed and or interpreted results in the steps necessary to implement and or use the present invention being performed.

Although the term user computer client computer and or server computer is referred to herein it is understood that such computers and may include thin client devices with limited or full processing capabilities portable devices such as cell phones notebook computers pocket computers multi touch devices and or any other devices with suitable processing communication and input output capability.

Of course those skilled in the art will recognize that any combination of the above components or any number of different components peripherals and other devices may be used with computers and .

Embodiments of the invention are implemented as a software application 3D contriver tool on a client or server computer . Further as described above the client or server computer may comprise a thin client device or a portable device that has a multi touch based display.

The 3D contriver tool for multi touch devices can be grouped in different clusters of functionality that are described in the present application and or the related applications identified and cross referenced above as follows 

Embodiments of the invention e.g. system will provide a single tool that permits multiple modeling operations and navigation within the same context without requiring complex gestures or modes.

The center region represents an area that will generate geometry if a touch event is detected see below for more detail regarding modeling operations .

The first outer region represents an area that will either trigger a re stocking operation re brushing the geometry after the initial creation when a form is active or trigger a tumbling orbit navigation if no form is active see below for more details on re stroking modeling operations .

The second outer region fall off grid represents an area that will always trigger a tumbling orbit navigation if a touch event is detected. Any other touch event detected outside of the fall off grid will also trigger tumbling orbit navigation.

Embodiments of the invention perform the desired operation based on where the touch event commences and not where the gesture following the touch event proceeds. Thus merely by commencing a touch event gesture at a particular location with respect to the grid a particular operation is performed. The FIGs. and description that follow illustrate examples of the different operations that may be performed based on the grid .

To respond to the user tumbling orbiting in space embodiments of the invention dynamically switch to one of the dominant planes XY XZ YZ and update the graphical representation of the grid accordingly.

In view of it may be noted that embodiments of the invention evaluate the action that is to be executed based on where the touch event begins commences rather than where the touch event proceeds or ends. Accordingly in since the touch event gesture begins in area a navigation e.g. tumbling orbiting operation is performed.

The user starts brushing from a position inside the modeling grid . As the user drags a finger along any path the system dynamically creates a 3D form . The form shaping is interactive and updates the form every time it samples the gesture . Such form shaping is performed dynamically in real time as the user performs the stroke gesture. Accordingly as the user is moving a finger the model is changing. In the prior art the ability to dynamically create a model in such a manner was not provided. Instead prior art users were required to draw a curve select the drawn curve and select a profile. Thereafter the user would perform a sweep jigging operation process. Such a sweep operation is not dynamically created as the user inputs a gesture but instead is based on an already drawn curve that is selected by the user.

Once the user finishes brushing i.e. at describing the path the system finishes the shaping of the 3D form . The user can then tumble orbit e.g. as described above with respect to or re stroke the 3D form e.g. as described below .

Thus since the gesture commenced in region a creation modeling operation is performed based on the user s gesture . As illustrated a 3D form is dynamically created and conforms to the shape of the gesture stroke . To perform the modeling creation operation the user did not need to select a creation operation e.g. from a menu or otherwise . Instead the user simply began the gesture within region . In response a 3D form is displayed on the grid and is dynamically updated to conform to the stroke while the stroke is drawn. Again since the gesture stroke began inside of region it doesn t matter if the stroke proceeds outside of region . Instead what enables the modeling operation is where the stroke commences.

Accordingly the grid system of the invention enables the user to perform a desired operation merely by beginning a gesture in a particular area region of the grid system .

The user starts re stroking from a position A inside the modeling grid . As the user drags his her finger along any path A the system dynamically reshapes the 3D form . The form re shaping is dynamic interactive and updates the form every time it samples the gesture i.e. dynamically in real time .

In the re stroking modifies the 3D form in relationship to the current XY grid. Once the user finishes re stroking i.e. at A thereby describing the path A the system finishes re shaping the 3D form and the user can then either tumble orbit or re stroke the 3D form .

Accordingly as described above since the operation gesture is commenced at a location A within area region a restocking operation is performed i.e. since form is active . If the operation were conducted outside of region i.e. in region an orbit tumbling operation would be conducted.

In the user continues interacting with the modeling tool and the model of . The image shows the final state of the grid system while the modeling tool is active . The captured gesture B occurs commences outside of the grid system i.e. in region thus invoking a tumble orbit. The resulting viewing angle determines that the YZ plane is dominant and all re stroking operation will be projected to the YZ plane.

The re stroking modifies the 3D form in relationship to the current YZ grid. Once the user has finished the re stroking gesture at point C describing the path C the system finishes the re shaping of the 3D form and the user can then either tumble orbit or re stroke the 3D form .

Thus as described above since the stroke C begins at a point C within region a reshaping operation is performed. Further the operation is performed in the YZ plane due to the rotation tumbling that was performed as described above with respect to .

At step a modeling tool is activated in a 3D modeling application that is executing on a computer e.g. a multi touch device .

At step in response to the activation a visual representation of a grid system tool is displayed on a digital modeling canvas. Such a grid system controls whether a gesture is captured as a modeling operation or as a navigation operation. The visual representation comprises three separate regions. Further the grid system may be displayed on a blank canvas that does not contain any geometric objects.

The visual representation of the grid system tool may be a polygonal shaped grid e.g. square parallelogram etc. having three separate regions. The first region has one or more first cells that define a center region of the polygonal shaped grid. The second region of the grid has one or more second cells that surround and are visually distinguishable from the first region. The third region has one or more third cells that surround the second region and define a boundary of the polygonal shaped grid. Further the third region is visually distinguishable from both the first and second areas. The regions may be visually distinguishable from each other based on a difference in densities between the cells e.g. in the third region and second region by color e.g. blue for cells in the first region or some other mechanism e.g. highlighting resolution color of grid lines shading of cells etc. . The grid system tool as set forth herein can be seen throughout the figures specifically FIGS. and AB.

At step an operation that is appropriate based on the starting touch event location is performed. In this regard if the starting touch event is in a first of the three separate regions a 3D geometry geometry form is created based on the gesture. If the starting touch event is in a second region a restroking operation if a 3D geometry is active or a navigation operation if no geometry is active is performed. Lastly if the starting touch event is in a third region or outside of the visual representation of the grid system a navigation operation based on the gesture is performed.

The navigation operation may modify a viewing angle of the digital modeling canvas. Based on such a viewing angle a dominant plane can be determined. The grid system tool may then automatically and dynamically i.e. in real time without additional user input adapt itself and display consistent with the dominant plane. In other words the visual representation of the grid system tool may re orient or tumble to display at a different angle based on the rotation tumbling performed by the user via the gesture .

This concludes the description of the preferred embodiment of the invention. The following describes some alternative embodiments for accomplishing the present invention. For example any type of computer such as a multi touch device mainframe minicomputer or personal computer or computer configuration such as a timesharing mainframe local area network or standalone personal computer could be used with the present invention.

In summary embodiments of the invention provide a single tool that is displayed with different regions. The single tool provides the ability for the user to perform a variety of operations simply by beginning a touch event or cursor click event within a particular region. The tool may be used to navigate tumble a 3D model create a 3D geometric form e.g. on a blank canvas or otherwise and or edit a an existing 3D geometric form. The operation selected performed is based on where the touch event begins and not where the gesture associated with the touch event progresses. Nonetheless once an operation is selected the operation is based on the user s gesture.

The foregoing description of the preferred embodiment of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto.

