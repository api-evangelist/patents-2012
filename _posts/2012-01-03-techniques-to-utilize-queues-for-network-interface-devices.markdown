---

title: Techniques to utilize queues for network interface devices
abstract: In general, in one aspect, included are descriptions of providing a single network interface from physical network interfaces that provides a number of receive queues equal to the sum of the number of receive queues provided by each of the physical network interfaces.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08660133&OS=08660133&RS=08660133
owner: Intel Corporation
number: 08660133
owner_city: Santa Clara
owner_country: US
publication_date: 20120103
---
The present application is a continuation of U.S. patent application Ser. No. 10 917 728 filed on Aug. 12 2004 entitled TECHNIQUES TO UTILIZE QUEUES FOR NETWORK INTERFACE DEVICES which is hereby incorporated herein by reference in its entirety and for all purposes.

Network based communications between computers are increasing in speed. Advances in network speeds however have not been fully utilized due to latency that may be associated with processing protocol stacks at computers. Receive side scaling RSS is a feature in operating systems that allows network interface devices that support RSS to direct packets of certain Transmission Control Protocol Internet Protocol TCP IP flows to be processed on a designated Central Processing Unit CPU . The RSS feature scales the received traffic across multiple processors in order to avoid limiting the receive bandwidth to the processing capabilities of a single processor.

Note that use of the same reference numbers in different figures indicates the same or like elements.

Host system may include multiple processing units processor to processor N host memory and host storage . Each of processors to N may be implemented as Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors multi core or any other type of processor. Host memory may be implemented as a volatile memory device e.g. RAM DRAM or SRAM . Host storage may be implemented as a magnetic disk drive optical disk drive tape drive an internal storage device an attached storage device a network accessible storage device and or any type of non volatile storage device. Routines and information stored in host storage may be loaded into host memory and executed by the one or more processors.

Processors to N may be communicatively coupled to a chipset not depicted . The chipset may include a host bridge hub system that may provide intercommunication among processors to N host memory and bus . The chipset may also include an I O bridge hub system not shown that may couple the host bridge bus system to bus . The chipset may include one or more integrated circuit chips such as those selected from integrated circuit chipsets e.g. graphics memory and I O controller hub chipsets although other one or more integrated circuit chips may also or alternatively be used.

Bus may provide intercommunication between host system and network interfaces to N. Bus may be compatible with Peripheral Component Interconnect PCI described for example at Peripheral Component Interconnect PCI Local Bus Specification Revision 2.2 Dec. 18 1998 available from the PCI Special Interest Group Portland Oreg. U.S.A. as well as revisions thereof PCI Express described in The PCI Express Base Specification of the PCI Special Interest Group Revision 1.0a as well as revisions thereof PCI x described in the PCI X Specification Rev. 1.0a Jul. 24 2000 available from the aforesaid PCI Special Interest Group Portland Oreg. U.S.A. as well as revisions thereof serial ATA described for example at Serial ATA High Speed Serialized AT Attachment Revision 1.0 published on Aug. 29 2001 by the Serial ATA Working Group as well as related standards Universal Serial Bus USB and related standards or other interconnection technologies.

Computer system may utilize network interfaces to N to intercommunicate with network . Network may be any network such as the Internet an intranet a local area network LAN storage area network SAN a wide area network WAN or wireless network. Network may exchange traffic with computer system using the Ethernet standard described in IEEE standard 802.3 2002 and related standards or any communications standard.

Packet buffer may include multiple buffers and each buffer may store at least one ingress packet received from a network such as network . Packet buffer may store packets received by network interfaces to N that are queued for processing at least by device driver operating system intermediate driver TCBs to Y and or applications .

Receive queues may include input queues and output queues. Input queues may be used to transfer descriptors from host system to one or more of network interfaces to N. A descriptor may be transferred to a single network interface. A descriptor may describe a location within a buffer and length of the buffer that is available to store an ingress packet. Output queues may be used to transfer return descriptors from any of network interfaces to N to host system . A return descriptor may describe the buffer in which a particular ingress packet is stored within packet buffer and identify features of the packet such as the length of the ingress packet hash values and packet types and checksum pass fail. In one embodiment receive queues may include multiple input and multiple output queues. In one embodiment where there are multiple network interfaces to N intermediate driver may allocate the receive queues associated with each of network interfaces to N for use by any of the network interfaces to N.

Device driver may be device drivers for each of network interfaces to N. Although not depicted in one embodiment there may be a separate device driver for each of the multiple network interfaces. Device driver may create descriptors and may manage the use and allocation of descriptors in receive queue . Device driver may request transfer of descriptors to network interfaces to N using one or more input queues. Device driver may signal to one of network interfaces to N that a descriptor is available on an input queue. Device driver may determine the location of the ingress packet in packet buffer based on a return descriptor that describes such ingress packet and device driver may inform operating system as well as other routines and tasks of the availability and location of such stored ingress packet.

In one embodiment OS may be any operating system that supports steering of packet processing across multiple processors such as but not limited to receive side scaling RSS . For example OS may be implemented using Microsoft Windows HP UX Linux or UNIX although other operating systems may be used. Some embodiments of RSS permit network interfaces with multiple receive queues to direct packets of a given TCP flow to a specific queue so that packets in each specific queue will be processed by a specific processor. In one embodiment OS may be executed by each of the processors to N. In one embodiment when a Microsoft Windows operating system is used the ndis.sys driver may be utilized at least by device driver and intermediate driver . For example the ndis.sys driver may be utilized to define application programming interfaces APIs that can be used for transferring packets between layers.

In one embodiment intermediate driver may allocate the receive queues associated with each of network interfaces to N for use by any of the network interfaces to N so that network interfaces to N appear as a single virtual network interface with multiple receive queues to layers above intermediate driver such as but not limited to OS and TCBs to Y. For example for two network interfaces with two receive queues each intermediate driver provides a single virtual network interface with four receive queues e.g. four input and four output receive queues . In one embodiment intermediate driver may allocate each return descriptor for completion among a selected output receive queue among multiple output receive queues based on factors such as but not limited to fault tolerance link aggregation and load balancing of output receive queue utilization. Where multiple network interfaces such as network interfaces to N are used intermediate driver allows taking advantage of features of OS of directing packets for processing by a specific processor even when the device driver for one or any of network interfaces to N do not support use of multiple receive queues.

In one embodiment intermediate driver may determine which of processors to N is to process each ingress packet and provide the ingress packet into the appropriate TCB queue among TCB queues in accordance with an embodiment of the present invention.

In addition to or as an alternative to providing load balancing of packet processing by processors to N intermediate driver may provide for load balancing of traffic received from a network by network interfaces to N. In one embodiment intermediate driver may provide for load balancing of traffic received from a network among network interfaces to N. For example in one embodiment intermediate driver may include the capability to alter ARP replies described in Ethernet standards to request that traffic from a source device is thereafter addressed to a particular network interface among network interfaces to N for load balancing of packets received among network interfaces to N. Accordingly packets thereafter may be transmitted from a source node to the selected network interface among network interfaces to N so that load balancing may take place among network interfaces to N. For example intermediate driver may use ARP replies to allocate a first connection for receipt at a first network interface and a second connection for receipt at a second network interface.

Each of TCB queues to Y may be associated with respective TCBs to Y and allocated for storing or for associating with descriptors of packets to be processed by an associated TCB. Each of TCBs to Y may perform processing on ingress packets allocated in an associated TCB queue in TCB queues to Y in conformance with TCP IP protocol processing. Further details of the TCP IP protocol are described in the publication entitled Transmission Control Protocol DARPA Internet Program Protocol Specification prepared for the Defense Advanced Projects Research Agency RFC 793 published September 1981 . Any of processors to N may execute any number of TCBs to Y. TCBs to Y and TCB queues to Y can be allocated for each processor at system initialization or during run time. For example a new TCB and corresponding TCB queue can be allocated each time a connection is established such as for a when an application opens or a new file transfer operation.

Applications can be one or more machine executable programs that access data from host system or network . An application may include for example a web browser an email serving application a file serving application or a database application.

The machine executable instructions depicted in may be implemented as any or a combination of hardwired logic software stored by a memory device and executed by a microprocessor firmware an application specific integrated circuit ASIC and or a field programmable gate array FPGA .

Transceiver may include a media access controller MAC and a physical layer interface both not depicted capable of receiving and transmitting packets in conformance with the applicable protocols such as Ethernet as described in IEEE 802.3 although other protocols may be used. Transceiver may receive and transmit packets from and to network via a network medium.

Bus interface may provide intercommunication between network interface and bus . Bus interface may be implemented as a PCI PCI Express PCI x serial ATA and or USB compatible interface although other interconnection standards may be used . For example bus interface may include and utilize a direct memory access DMA engine to perform direct memory accesses from and into host memory and or host storage of host system . For example DMA engine may perform direct memory accesses to transfer ingress packets into a buffer in packet buffer .

Descriptor manager may initiate access of descriptors from an input queue of the receive queue. In one embodiment where there are multiple network interfaces to N intermediate driver may allocate the input receive queues associated with each of network interfaces to N for use by any of the network interfaces to N. For example descriptor manager may inform DMA engine to read a descriptor from a selected input queue of receive queue and store the descriptor. Descriptor manager may store descriptors that describe candidate buffers in packet buffer that network interface can use to store ingress packets.

Queue controller may determine a buffer of packet buffer to store at least one ingress packet. In one embodiment based on the descriptors in descriptor storage queue controller may create a return descriptor that describes a buffer to store an ingress packet. Return descriptors may be allocated for transfer to host system using an output queue. In one embodiment where there are multiple network interfaces to N intermediate driver may allocate the output receive queues associated with each of network interfaces to N for use by any of the network interfaces to N. In one embodiment intermediate driver may allocate each return descriptor for completion among a selected output receive queue among multiple output receive queues based on factors such as but not limited to fault tolerance link aggregation and load balancing of output receive queue utilization. Queue controller may instruct DMA engine to transfer each ingress packet into a buffer in packet buffer identified by a return descriptor. For example queue controller may place the return descriptor in an output queue and provide an interrupt to inform host system that an ingress packet is stored as described by the return descriptor in the output queue.

Memory may be implemented as a volatile memory device e.g. RAM DRAM or SRAM . Memory may provide buffering and storage for information leaving and entering network interface such as but not limited to descriptors and packets.

Network interface may be implemented as any or a combination of hardwired logic software stored by a memory device and executed by a microprocessor firmware an application specific integrated circuit ASIC and or a field programmable gate array FPGA .

In block intermediate driver may allocate the input and output receive queues associated with each of network interfaces to N for use by any of the network interfaces to N.

In block device driver may transfer one or more descriptor to a network interface . For example device driver may create one or more descriptors that each describe at least one location in packet buffer in which to store header and payload portions of a packet received from network . Descriptors can be placed on the input queue of the receive queues for transfer to a specified network interface .

In block a network interface may receive at least one packet from network . For example the packet may be compliant with Ethernet format although other formats are permissible.

In block the network interface may store one or more packet payload s and header s into host system . For example network interface may transfer one or more packet payload s and header s into host memory based on the packet buffer location in a descriptor s . For example queue controller of the network interface may determine which buffer in packet buffer is to store the ingress packet based on available descriptors. For example based on the determined packet buffer in packet buffers DMA engine of the network interface may transfer the received ingress packet into the packet buffer of packet buffers in host memory or system memory as the case may be .

In block network interface may create a return descriptor for the packet. For example the return descriptor may describe the storage location of the packet in packet buffer .

In block network interface may transfer the return descriptor to host system using a selected output receive queue among any of the available receive queues of network interfaces to N. For example intermediate driver may select an output receive queue based on factors such as fault tolerance link aggregation and load balancing of output receive queue utilization. For example queue controller of network interface may write the return descriptor to the selected output queue. For example network interface may notify device driver via an interrupt to request ingress packet processing. Queue controller of network interface can create an interrupt to inform device driver that an ingress packet is stored as described by a return descriptor in the selected output queue.

In block intermediate driver may determine which of processors to X is to process the ingress packet. In one embodiment device driver may issue a request to OS e.g. deferred procedure call to notify OS to use intermediate driver . Intermediate driver may identify the processor by identifying a TCB queue among TCB queues that is to store or is to be associated with the ingress packet. In one embodiment a specified number of TCB queues among TCB queues to Y are associated with each processor. In one embodiment two TCB queues are allocated to store or be associated with packets to be processed by each processor although other numbers of TCB queues may be used. In one embodiment to associate a packet with the processor intermediate driver may determine a hash value using hashing control based on packet header information and may utilize a table which associates TCB queues with hash values. The hash value may be calculated using connection specific information in each incoming packet header e.g. for TCP IP packets N tuple information such as packet source IP address destination IP address source port destination port and protocol may be used . For example the table may associate hash values with TCB queues based on an unload analysis . For example the unload analysis may consider which processor is least busy by considering the fullness of associated TCB queues as well as other factors such as processor utilization.

In block intermediate driver may allocate the packet into the selected TCB queue among TCB queues to Y. In one embodiment allocating the packet may include passing to the appropriate TCB queue a pointer that identifies the packet descriptor or packet buffer. Thereafter a packet is available in a TCB queue for processing at least in compliance with TCP IP.

In one embodiment each TCB queue is associated with a TCB among TCBs to Y and a TCB associated with a TCB queue processes packets in an associated TCB queue in a first in first processed manner. Thereafter a TCB may perform packet header processing to determine the protocol context associated with the current connection and TCP protocol compliance. TCP protocol compliance may comprise for example verifying the sequence number of an ingress packet to ensure that the packet is within a range of numbers that was agreed upon between the communicating nodes verifying the payload size to ensure that the packet is within a range of sizes that was agreed upon between the communicating nodes ensuring that the header structure conforms to the protocol and ensuring that the timestamps are within an expected time range. After processing the TCP stack may provide the data portion of the packet to the associated application s among applications .

In action intermediate driver may issue a request to a source of any packet to transmit future packet s to a specified network interface among network interfaces to N. For example in one embodiment intermediate driver may include capability to alter ARP replies described in Ethernet standards to request that traffic from a source device is thereafter addressed to a particular network interface among network interfaces to N for load balancing of packets received among network interfaces to N. Accordingly packets thereafter may be transmitted from a source node in the network to the selected network interface among network interfaces to N so that traffic received from a network may be balanced among network interfaces to N.

At and network interfaces and may receive respective packets and . At and network interfaces and may provide descriptors for respective packets and to host system using assigned output receive queues among multiple output receive queues and transfer access to such descriptors to device driver . At and network interfaces and may transfer packets and for storage into packet buffers . At and device driver may transfer access to headers for respective packets and to intermediate driver .

At and intermediate driver may transfer access to packets and to the appropriate TCB queues among TCB queues determined using hash control . For example intermediate driver may assign packets for access by any of TCB queues to based at least on an unload analysis. In this example packet may be assigned to TCB queue whereas packet may be assigned to TCB queue however packets and may be assigned to other TCB queues among those depicted as well as not depicted. For example in another assignment packet may be assigned to TCB queue whereas packet may be assigned to TCB queue .

The drawings and the forgoing description gave examples of the present invention. While a demarcation between operations of elements in examples herein is provided operations of one element may be performed by one or more other elements. The scope of the present invention however is by no means limited by these specific examples. Numerous variations whether explicitly given in the specification or not such as differences in structure dimension and use of material are possible. For example packet may include information encapsulated according to any protocols. The scope of the invention is at least as broad as given by the following claims.

