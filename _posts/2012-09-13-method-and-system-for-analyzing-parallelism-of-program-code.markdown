---

title: Method and system for analyzing parallelism of program code
abstract: Methods and systems are provided for analyzing parallelism of program code. According to a method, the sequential execution of the program code is simulated so as to trace the execution procedure of the program code, and parallelism of the program code is analyzed based on the result of the trace to the execution procedure of the program code. Execution information of the program code is collected by simulating the sequential execution of the program code, and parallelism of the program code is analyzed based on the collected execution information, so as to allow programmers to perform parallel task partitioning of the program code with respect to a multi-core architecture more effectively, thus increasing the efficiency of parallel software development.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09047114&OS=09047114&RS=09047114
owner: International Business Machines Corporation
number: 09047114
owner_city: Armonk
owner_country: US
publication_date: 20120913
---
This application is a continuation of and claims priority from U.S. application Ser. No. 12 141 571 filed on Jun. 18 2008 now U.S. Pat. No. 8 316 355 which is based on based upon and claims priority from Chinese Patent Application No. 200710109089.5 filed Jun. 18 2007 the disclosures of which are hereby incorporated by reference in their entirety.

The present invention relates to the field of data processing and more particularly relates to a method and system for analyzing parallelism of program code based on emulation for a multi core architecture and an emulator for tracing the execution of program code.

As continuously increasing demands are placed on computers the capability of a single processor primary frequency line width etc. also increases continuously. However it can be predicted that such increases in the capability of the single processor will finally reach a high point. Thus when the capability of a single processor increases to a certain point in order to continuously obtain higher microprocessor performance it has to be developed in a different direction. The main factors for promoting the continuous increases in microprocessor performance are rapid progress in semiconductor manufacturing technology and the continuous development of the processor architecture. By using the current semiconductor manufacturing technology the number of transistors integrated in a microprocessor can reach several hundred million and the structure of a microprocessor is ensured to develop in a more complicated direction. Thus under such technical development and demands the multi core multiprocessor architecture becomes essential.

The multi core architecture enhances the parallelism of program execution by integrating a plurality of microprocessor cores on a chip. Each microprocessor core is a relatively simple single thread microprocessor or a comparatively simple multi thread microprocessor in nature. In the multi core architecture the plurality of microprocessors can execute tasks in parallel so that the parallelism at the thread level is relatively high. Further the multi core architecture can obtain such advantages as high primary frequency short design and validation period simple control logic good expansibility easy implementation low power consumption and low communication delay by adopting relatively simple microprocessors as the processor cores. Therefore in the future development trend no matter whether it is a mobile application an embedded application a desktop application or a server application the multi core architecture will be adopted.

However while the multi core architecture has a lot of advantages it also creates system and program design challenges and other challenges. That is because the multi core architecture encapsulates a plurality of processor execution cores in a single processor as long as the design of software is appropriate the complete parallel execution of a plurality of threads of the software can be supported by the multi core architecture. Accordingly the design of such a multi core architecture forces the development of software to go in the parallelization direction so as to realize the advantages of the multi core architecture.

However under the x86 architecture developers of application programs still remain in the single thread development mode. As the multi core architecture is being gradually employed on PCs servers embedded systems game consoles and so on traditional sequential programming concepts under the x86 architecture will be weakened by the concurrency and synchronization. Especially for a programmer on CELL multi core architecture like heterogeneous memory constraint systems in which each processor core has a limited 256 KB local storage the programmer should transform from a sequential programming design concept to a parallel one. That is programmers should learn how to design application programs for a multi core architecture like CELL i.e. learn how to carry out parallel program design . However in parallel program design identification of parallelism and partition of parallel tasks of the functions in program code are always considered as a kind of art that is highly dependent on the programmers domain knowledge experience and architectural understanding. Without enough support tools parallelism analysis and task partitioning greatly reduce the overall parallel software development productivity.

Therefore there is a need for an efficient and accurate technology for analyzing parallelism of program code to facilitate the design of parallel programs to perform parallelism analysis and task partitioning of program code more efficiently with respect to a multi core architecture so as to increase the efficiency of the development of parallelism software.

According to one aspect of the present invention there is provided a method for analyzing parallelism of program code. The sequential execution of the program code is simulated so as to trace the execution procedure of the program code and parallelism of the program code is analyzed based on a result of the trace of the execution procedure of the program code.

According to another aspect of the present invention there is provided an emulator for tracing an execution procedure of program code. The emulator includes a simulated execution environment for simulating an execution environment of a target system in which the program code will be executed sequentially and an execution procedure tracing unit for tracing the sequential execution of the program code in the simulated execution environment so as to obtain execution information of the program code.

According to a further aspect of the present invention there is provided a system for analyzing parallelism of program code. The system includes an emulator for tracing an execution procedure of program code and a parallelism analyzing unit for analyzing parallelism of the program code based on a result of a trace of the execution procedure of the program code obtained by the emulator.

In a multi core architecture for an application program having a great deal of calculations there will be a lot of data processing and complicated data dependency. If data partitioning is not performed then only a low frequency single core performs serial processing so the execution period will be very long. Thus in the multi core architecture parallelization should be correctly performed on such an application program.

The parallelization of an application program is in fact the compressing of the time complexity of a lengthy serial algorithm by way of increasing the space complexity reconstructing the past algorithm structure in which one operation is executed in one cycle as the parallel algorithm in which a plurality of operations are executed in one cycle which is the main task of parallelization. That is parallelization finds the tasks that can be executed in parallel in an application program and allocates them to a plurality of processor cores to execute in parallel so that more than one event occurs at one time or in one period. But this kind of parallelization is not a simple process because even if a plurality of processor cores in the multi core architecture can execute a plurality of tasks in a program simultaneously there may be a conflict of operation resource among the tasks. During the simultaneous operation of the plurality of processor cores a lot of resources such as cache memory and BUS etc. are in fact shared. If the parallelization is incorrect for example if parallelization is performed on tasks that cannot be executed in parallel then the execution result obtained by the application program may be incorrect. For example if tasks that can be executed in parallel originally are not parallelized then the result is the reduction of utilization efficiency of the processor cores. In view of this the present invention provides systems and methods for analyzing parallelism of program code efficiently to release programmers from complicated parallelism identification and task partitioning.

Preferred embodiments of the present invention will be described in detail hereinafter in conjunction with the drawings.

At step parallelism of the program code is analyzed. Specifically at this step dependencies among function calls in the program code are analyzed based on the tracing result of the sequential execution procedure of the program code i.e. the execution information collected at step . At this step the function calls in the program code that do not conflict for memory access are determined as ones having no dependency. This step will be described in detail below in conjunction with .

This embodiment of the present invention optionally comprises step in which the analysis result for parallelism of the program code is presented to the user. Specifically at this step what is presented to the user is the dependencies among the function calls in the program code determined at step to allow the designer of the program code to find the tasks in the program code that have no dependency so that they can be executed in parallel by a plurality of processor cores. In one embodiment the dependencies among the function calls in the program code are expressed in the form of a tree diagram. The tree diagram will be detailed below in conjunction with . In addition in other embodiments the dependencies among the function calls in the program code are presented in any other form such as a list text etc.

The execution procedure tracing step in the method of will be described in detail in conjunction with which is a detailed flowchart of the execution procedure tracing step .

As shown in first at step for program code for which parallelism analysis is to be performed the execution environment of its target system is simulated. Specifically in this embodiment this step is implemented by using an emulator. That is at this step the target system on which the program code is to be used practically is simulated on a main system current system by using an emulator to provide the execution environment of the target system for the program code. In this embodiment of the present invention the target system is a CELL multi core system i.e. the program code for which parallelism analysis is to be performed is designed for the CELL system . In addition in this embodiment of the present invention the simulated execution environment comprises a simulated memory a memory management unit a pipeline and a simulated register and so on which are the most basic system components for the execution of the program code. However the present invention is not limited to this. As long as the sequential execution of the program code can be ensured and what is simulated is the environment of the target system the execution environment can comprise any other system components. The above emulator will be detailed below in conjunction with .

Next at step the program code is loaded into the simulated execution environment of the target system. Specifically at this step the program code is loaded into the simulated memory in the simulated execution environment and a symbol table in the program code is analyzed to obtain the addresses of the functions in the program code. Because the name size and memory address of each function in the program code are recorded in the symbol table the address of each function can be obtained according to the corresponding name of the function.

At step an instruction to be currently executed in the program code is acquired for execution. Specifically because the value of the simulated instruction register in the simulated execution environment indicates the virtual address of the instruction to be currently executed at this step first the virtual address in the simulated instruction register is acquired and transferred to the memory management unit so as to convert the virtual address into a physical address then according to the acquired physical address the instruction to be executed is acquired from the corresponding location of the simulated memory and decoded into a binary format for execution. In the meantime the simulated instruction register automatically points to the next instruction to be executed.

Next the subsequent steps trace the execution procedure of the program code and record execution information.

At step it is determined whether the instruction is a function call return instruction such as a call x86 or b1 PPC . If so the process proceeds to step otherwise the process turns to step .

At step for the current instruction that was determined to be a function call return instruction at step it is further determined whether the function it invokes is a system API Application Programming Interface such as a C library function. If so the process proceeds to step otherwise the process turns to step .

At step for the current instruction that was determined as a function call return instruction at step it is further determined whether the function it invokes is a memory allocation instruction or a free instruction i.e. instruction malloc or free . If so the process proceeds to step otherwise the process proceeds to step .

Next because it was determined at step that the function the current instruction invokes is malloc or free among the system APIs at step the related memory allocation free information during the execution of the current instruction is recorded into a memory allocation log. Specifically at this step the system cycle time information allocated memory size and memory address during the execution of the current instruction are recorded into the memory allocation log. Then the process proceeds to step to execute the system API invoked by the instruction.

Next since it was determined at step that the current instruction is a function call return instruction and the function it invokes is not a system API then at step the related function call information during the execution of the current instruction is recorded into a function call log. Specifically at this step the system cycle and the ID of the function invoked by the current instruction during the execution of the instruction are recorded into the function call log. In order to facilitate user identification preferably the ID of the function adopts the name of the function. However because during the execution of the instruction the function it invokes is indicated by an address before being recorded into the log the address of the invoked function is first converted into the corresponding name of the function according to the symbol table in the program code mentioned above and then the name of the function is recorded into the log.

Next at step for the current instruction that was determined as not being a function call return instruction at step it is further determined whether it is a load store instruction. If so the process proceeds to step otherwise it turns to step to determine whether there exists a next instruction.

Next since it was determined at step that the current instruction is a load store instruction at step the related memory access information during the execution of the current instruction is recorded into a memory access log. Specifically at this step the system cycle data address and data size accessed by the current instruction and read write type during the execution of the instruction are recorded into the memory access log. Then the process proceeds to step to determine whether there exist a next instruction.

At step if there exists a next instruction then the process returns to step to continue to acquire and execute the next instruction. If there is no next instruction then the process proceeds to step .

At step the logs generated through the above steps are preprocessed. Specifically at this step the locality or non locality of the memory access operations or memory allocation operations of each function in the program code are analyzed and the memory type item in the records corresponding to the memory access operations or memory allocation operations is correspondingly set in the above mentioned logs. For example if variable i is a local variable in function A then for the memory access operations with respect to variable i in function A the memory type item in the records corresponding to the memory access operations is set as local in the logs to indicate that the memory access operations do not depend on the memory operations in other functions and can be performed locally.

In seemingly function a and b have overlapping parts on memory operations on stack i and j and heap p and q but in fact it can be analyzed from the main code sections of the two functions that they do not conflict in memory operations and can be allocated to different processor cores to execute on the basis of the local memories of the processor cores. Therefore in this case the memory type in the records corresponding to the stack i j and heap p q operations of the two functions is set as local in the logs to indicate the heap and stack operations do not depend on or conflict with heap and stack operations with respect to the same variables in other functions and can be performed locally.

Further in respectively it can be seen that both functions a and b use the same lock i to protect their critical sections. However it can be seen from the main code sections of the two functions that they do not operate on the same memory variable thus there is no conflict in memory operations. Therefore in this case the memory type in the records corresponding to the locking operations of the two functions is set as local in the logs so as to indicate the locking operations do not conflict with locking operations with respect to the same variable in other functions and can be performed locally.

Hereinafter a specific example is given to describe the tracing result obtained by using the process of . shows two segments of simple program code in which main is a main function and add is a subfunction invoked by the main function. is a log in which the execution information of the two segments of program code of is recorded. It can be seen that the log sequentially records all of the memory access information memory allocation information function call information and so on of the execution procedures of the two segments of program code in the order of timestamp execution cycle . The specific meaning of each field in the log is shown in .

The above is a detailed description of the execution procedure tracing step of . It should be noted that in the process shown in although the process of recording execution information at steps is performed after the execution of the instruction at step this is only for the purpose of convenience for description but is not limitative. In a practical implementation steps can be performed simultaneously with the execution of the instruction of step .

In addition it is also noted that in the above process shown in although the execution information of the program code is classified and recorded into different logs according to the type of instruction in a practical implementation all of the execution information of the program code can be recorded using only one log instead of configuring a function call log a memory allocation log and a memory access log respectively. In this case the above plurality of logs can be generated on the basis of the one log during parallelism analysis. Further in embodiments of the present invention no matter whether the execution information is recorded using one log or a plurality of logs the recorded information is not limited to the above function name memory address memory type and so on but instead besides the above information types other more detailed information related to the execution of program code can also be recorded.

The parallelism analysis step in the method of will be described in detail in conjunction with which is a detailed flowchart of the parallelism analysis step .

As shown in first at step an invocation tree is generated for the program code for which the parallelism analysis is currently performed. Specifically at this step the invocation tree of the program code is generated by representing the main function in the program code with the root node the function calls of the program code in its sequential execution procedure with nodes under the root node and the further invocation relations between the function calls with the parent and child relation between corresponding nodes. As described above in conjunction with all of the information related to various function calls to a non system API of the program code is recorded in the function call log. Therefore at this step the function calls of the program code in its execution procedure can be identified based on the logs generated in the above process of . Each node in the invocation tree generated at this step represents a function call of the program code in its execution procedure and each node comprises the following items.

Function identification func id This is the identification of the invoked function in the function call corresponding to the node. In an embodiment of the present invention the ID is the name of the invoked function.

Invoked function list callee list This is a list of various levels of invoked functions down to the function call corresponding to the node i.e. which indicates the stack status up to the function call . In an embodiment of the present invention the list is composed of the names of the various levels of invoked functions. For example if a main function main invokes a function tree and the function tree further invokes a function node during its execution then for the invocation of the function node the invoked function list callee list of its corresponding node is main tree .

Invocation number call number This is used to differentiate different function calls having identical function IDs and invoked function lists i.e. which is used to differentiate different invocations of the same function . The invocation number can be represented by a number or by other IDs.

Next at step based on the execution information log recorded in the above process of for each node in the above invocation tree a read access record set and a write access record set of its corresponding function call are obtained. That is each node in the above invocation tree further comprises the following items 

Read access record set read set which is the set of records of read accesses to a memory during the function call corresponding to the node and

Write access record set write set which is the set of records of write accesses to a memory during the function call corresponding to the node.

Because all of the information of the program code related to various function calls to a non system API and various memory accesses is recorded in the logs at this step based on the logs function calls to a non system API function of the program code in its execution procedure are identified and the statistics of the memory access records and write access records during the function calls are obtained respectively as the read access record set and write access record set of the node which the function call corresponds to respectively.

At step the invocation tree is optimized. Specifically at this step it is assumed that nodes A and B are two leaf nodes under the same parent node in the invocation tree if 

1 a record Rin the read access record set read set of A and a record Rin the write access record set write set of B relate to the same non local memory address p or

2 a record Rin the write access record set write set of A and a record Rin the read access record set read set of B relate to the same non local memory address p or

3 a record Rin the write access record set write set of A and a record Rin the write access record set write set of B relate to the same non local memory address p.

If so then the nodes A and B are merged into one new node to indicate the interdependency of A and B. The determination of an identical non local memory address is made based on the memory address information and memory type information in the read and write access records.

That is at this step for the function calls under the same function in the program code based on the memory address and memory type in each record of their read access record sets and write access record sets it is determined whether the write access record set of one of the function calls contains the records related to the same non local memory address as that in the read access record set or write access record set of another of the function calls. If so then it is determined that the two function calls are dependent on each other and cannot be executed in parallel. Otherwise it is determined that the two function calls are not dependent on each other and can be executed in parallel.

Hereinafter the process of will be described by way of an example. shows two segments of simple program code where main is a main function and add is a subfunction invoked by the main function. shows a log in which the execution information of the two segments of program code of is recorded. It can be seen that the log records all of the memory access information function call information and so on of the execution procedures of the two segments of program code sequentially in the order of timestamps execution cycle . Further because there is no memory allocation free instruction malloc and free in the two segments of program code no information related to the memory allocation free is recorded.

Taking the above program code in and the corresponding execution information log in as examples by using the above process of the final invocation tree of the program code a part of which is shown in is obtained. Here node add main 0 read set write set and node add main 1 read set write set cannot be merged thus indicating that the first invocation and the second invocation of function add by the main function main are not dependent on each other and can be executed in parallel.

The final invocation tree generated by using the process can be presented to the user at the above step of so as to show the dependencies between the function calls of the program code with the relations between the nodes in the invocation tree allowing the user to get a direct view of the parallelism of the program code.

In addition it should be noted that the tree analysis technique adopted by the above parallelism analysis process of is only one embodiment of the present invention and is not a limitation. In other embodiments the analysis and presentation of the dependencies between function calls can be implemented by any form such as list text and so on.

At the optional step for the various levels of function calls of the program code in its execution procedure code and data sizes are analyzed. Specifically in one embodiment the step is implemented according to the following formula 

That is at this step for each function call callA of the program code in its execution procedure the sum of the code size of the invoked function A itself corresponding to the function call and the code sizes of the functions f invoked further by the function A during the function call callA is obtained as the code size of the function call callA and the sum of the space sizes accessed in various memory accesses i by the function call callA during its lifetime is obtained as the data size of the function call callA.

The above step is most useful for a case in which the program code for which the parallelism analysis is being currently performed is to be applied to a multi core architecture like CELL in which each processor core is provided with limited local storage such as 256 KB . Because in such a system the size of the task size of code and data manageable by each processor core is limited by its local storage when allocating tasks to the processor cores it should be considered first whether the sizes of the tasks are suitable for the processor cores. However for a multi core architecture in which the processor cores are not limited in the local storage size when performing a parallelism analysis on the program code it is not necessary to consider whether the sizes of the allocated tasks are suitable for the processor cores so the above step is not needed.

In addition if step is performed the code sizes and data sizes of the function calls obtained at the step should further be presented to the user at the above step of . The code sizes and data sizes of the function calls can be presented along with the corresponding nodes in the invocation tree.

The above is a detailed description of the embodiment of the parallelism analysis process of the program code in . It should be noted that in the process shown in although step for obtaining the read access record set and the write access record set is performed after step for generating an invocation tree this is only for the purpose of convenience and is not limitative. In a practical implementation step can be performed while generating the invocation tree at step .

The above is a description of the method for analyzing parallelism of program code according to an embodiment of the present invention. It can be seen from the above that this embodiment first collects execution information necessary for the parallelism analysis for the program code by simulating the sequential execution of the program code then analyzes the dependencies between function calls based on the collected execution information and then presents the analysis result to the user in a visual form.

Therefore in this embodiment owing to the simulation of the practical execution of the program code the memory access information and the potential dependencies introduced by the system calls controlled by I O for example at the kernel level can be collected so the parallelism analysis based thereon will be more accurate and can allow programmers to perform the partitioning of the parallel tasks of the program code with respect to the multi core architecture more effectively. Further by using this embodiment the parallelism analysis for the program code can be performed independently of the hardware and OS of the target system.

In addition although the above description of the parallelism analysis for the program code is given with respect to the case of a CELL system the present invention is not so limited. The present invention can also be applied to the parallelism analysis for the program code of other multi core architectures such as Simple Scalar Power system chip etc.

As shown in the system for analyzing parallelism of program code according to this embodiment of the present embodiment comprises an emulator a parallelism analyzing unit and a presenting unit .

The emulator is used to trace the execution procedure of the program code for which parallelism analysis is to be performed in order to collect the execution information.

The simulated memory is a memory block allocated from the memory of a main system current system and is used as the physical memory in the target system environment simulated by the emulator .

The memory management unit MMU is used to convert a virtual address into a physical address during the memory access of the program code. The memory management unit comprises a translation look aside buffer TLB which is a cache and stores the mapping relation between virtual addresses and physical addresses. The address translation performed by the MMU is a searching of the TLB to find a matched pair of virtual address and physical address thus obtaining the needed physical address.

The pipeline comprises an instruction fetching unit an instruction decoding unit and an instruction executing unit . The instruction fetching unit fetches instructions from the simulated memory into the pipeline the instruction decoding unit analyzes the binary format of each instruction and the instruction executing unit executes the action of each instruction.

The simulated register is used as the register of the target system simulated by the emulator for storing an intermediate calculation result in which a PC register records the location of the instruction to be executed virtual address .

The execution procedure tracing unit is used to trace the sequential execution procedure of the program code in the emulator so as to obtain the execution information of the program code. Specifically this unit determines the type of the current instruction executed in the emulator . If the instruction is a function call return instruction for invoking a non system API then the current execution cycle and the ID of the invoked function are recorded into logs. If the instruction is a function call return instruction for invoking the memory allocation or free function among the system APIs then the current execution cycle and the allocated memory size memory address are recorded into the logs. If the instruction is a load store instruction then the current execution cycle and data address data size read write type and memory type are recorded into the logs.

The trace preprocessing unit is used for analyzing the corresponding memory type of memory access operations and memory allocation operations recorded in the above logs and recording the memory type information into the logs.

As shown in after the emulator starts the instruction fetching unit reads the value in the PC register so as to obtain the address of the next instruction and transfers the address to the memory management unit for conversion from a virtual address to the physical address. Then the instruction fetching unit reads an instruction from the corresponding location of the simulated memory according to the obtained physical address while the value of the PC register automatically points to the next instruction.

As shown in when the instruction executing unit executes a load store instruction first the unit obtains a data address from the instruction itself or a register and transfers the address to the MMU for conversion from a virtual address to the physical address. Then the instruction executing unit loads or stores data to a corresponding location of the simulated memory according to the obtained physical address while the execution procedure tracing unit records corresponding memory access information.

As shown in when the instruction executing unit executes a branch instruction first it updates the value in the PC register to the target address of the branch instruction and discards all of the instructions in the pipeline . Then the instruction fetching unit fetches a corresponding instruction into the pipeline according to the new value in the PC register while the execution procedure tracing unit records corresponding function call information.

The above is the detailed description of the emulator for tracing execution procedure of program code according to an embodiment of the present invention. By using the emulator according to this embodiment execution information which is detailed and useful for the parallelism analysis of program code can be obtained.

Returning to the parallelism analyzing unit is used to based on the result of the tracing of the execution procedure of the program code by the emulator learn the execution actions as well as time information and memory type information corresponding to the execution actions of the program code in its execution procedure recorded in the tracing result to perform the parallelism analysis. As shown in the parallelism analyzing unit comprises an invocation tree constructing unit an access record obtaining unit an invocation tree optimizing unit and a code data size analyzing unit .

The invocation tree constructing unit is used to based on the tracing result obtained by the emulator represent the various function calls of the program code in its execution procedure with nodes and the relations between the function calls with the relation between the nodes to generate an invocation tree of the program code.

The access record obtaining unit is used to based on the tracing result obtained by the emulator for each node in the invocation tree generated by the invocation tree constructing unit obtain the read access record set and write access record set during its corresponding function call.

The invocation tree optimizing unit is used to for leaf nodes under the same parent node in the invocation tree based on their read access record sets and write access record sets determine whether there exists an access conflict between them with respect to a non local memory address and further to merge the leaf nodes having a memory access conflict between them with respect to a non local memory address into one node.

The code data size analyzing unit is used to for each of the function calls of the program code in its execution procedure obtain the sum of the code size of the invoked function itself corresponding to the function call and the code sizes of the functions invoked further by the invoked function during the function call as the code size of the function call and obtain the sum of the space sizes accessed in various memory accesses by the function call during its lifetime as the data size of the function call.

Next the presenting unit is used to present to the user the analysis result for the parallelism of the program code. In this embodiment the analysis result comprises a graphical or textual representation of the dependencies between function calls of the program code as well as the code size and data size of each of the function calls.

The above is the description of the system for analyzing parallelism of program code according to an embodiment of the present invention. It can be seen from the above description that this embodiment first collects execution information necessary for the parallelism analysis for the program code with an emulator then analyzes the dependencies between function calls based on the collected execution information and then presents the analysis result to user in a visual form.

Therefore in this embodiment owing to the simulation of the practical execution of the program code by an emulator the memory access information and the potential dependencies introduced by the system calls controlled by I O for example at the kernel level can be collected so the parallelism analysis based thereon will be more accurate and can allow programmers to perform the partitioning of the parallel tasks of the program code with respect to the multi core architecture more effectively. Further by using this embodiment the parallelism analysis for the program code can be performed independently of the hardware and OS of the target system.

The system for analyzing parallelism of program code and its various components can be implemented by hardware circuitry such as extremely large scale integrated circuit or gate arrays semiconductors such as one or more logic chips or transistors or programmable hardware devices such as field programmable gate array programmable logic device etc. or can be implemented in the form of one or more processors executing corresponding software or can be implemented by a combination of hardware circuitry and corresponding software. And these various components can be physically implemented together or can be physically independent but operationally interoperable with each other.

While there has been illustrated and described what are presently considered to be the preferred embodiments of the present invention it will be understood by those skilled in the art that various other modifications may be made and equivalents may be substituted without departing from the true scope of the invention. Additionally many modifications may be made to adapt a particular situation to the teachings of the present invention without departing from the central inventive concept described herein. Furthermore embodiments of the present invention may not include all of the features described above. Therefore it is intended that the present invention not be limited to the particular embodiments disclosed but that the invention include all embodiments falling within the scope of the appended claims.

