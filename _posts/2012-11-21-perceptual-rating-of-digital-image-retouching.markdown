---

title: Perceptual rating of digital image retouching
abstract: A method is provided for automatically providing a digital image rating of photo retouching. The method includes the step of receiving at a computer, including a processor, a first set of pixel data of an original image and a second set of pixel data of a retouched image. The method also includes using the processor to determine a plurality of geometric statistics and a plurality of photometric statistics from the first and second sets of pixel data. The method further includes the step of using the processor to quantify a rating of the retouched image based upon the geometric statistics and photometric statistics to indicate deviation of the retouched image from the original image. A system is also provided to perform the steps.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09135690&OS=09135690&RS=09135690
owner: The Trustees of Dartmouth College
number: 09135690
owner_city: Hanover
owner_country: US
publication_date: 20121121
---
This application claims the benefit of priority to U.S. Provisional Patent Application Ser. No. 61 562 934 filed Nov. 22 2011 which is incorporated by reference herein. This application further claims the benefit of priority to U.S. Provisional Patent Application Ser. No. 61 606 775 filed on Mar. 5 2012 which is incorporated by reference herein.

This invention was made with government support under contract number cns 0708209 awarded by the national science foundation NSF . The government has certain rights in the invention.

In recent years advertisers and magazine editors have been widely criticized for taking digital image retouching to an extreme. Impossibly thin tall and wrinkle and blemish free models are routinely splashed onto billboards advertisements and magazine covers. The images however are often the result of digital image retouching.

Retouched images are ubiquitous and have created an idealized and unrealistic representation of physical beauty. A significant amount of literature has established a link between these images and men s and women s satisfaction with their own physical appearance. Such concern for public health has led the American Medical Association to recently adopt a policy to discourage the altering of photographs in a manner that could promote unrealistic expectations of appropriate body image. Concern for public health and for the general issue of truth in advertising has also led the United Kingdom France and Norway to consider legislation that would require digitally altered images to be labeled.

Popular image editing software such as Adobe Photoshop allows photo editors to easily alter a person s appearance. These alterations may affect the geometry of the subject and may include slimming of legs hips and arms elongating the neck improving posture enlarging the eyes or making faces more symmetric. Other photometric alterations affect skin tone and texture. These changes may include smoothing sharpening or other operations that remove or reduce wrinkles cellulite blemishes freckles and dark circles under the eyes. A combination of geometric and photometric manipulations allows image retouchers to subtly or dramatically alter a person s appearance.

In an embodiment a method is provides an image retouching rating. The method includes the step of receiving at a computer including at least one processor a first set of pixel data of an original digital image and a second set of pixel data of a retouched digital image. The method also includes using the at least one processor to determine a plurality of geometric statistics and a plurality of photometric statistics from the first and second sets of pixel data. The method further includes the step of using the at least one processor to generate a rating of the retouched image based upon the geometric statistics and photometric statistics to indicate deviation of the retouched image from the original image.

In another embodiment the method further includes determining a plurality of geometric statistics comprising a first mean and a first standard deviation of geometric distortion of retouching between the first and second sets of pixel data corresponding to a first portion of a human body. In certain embodiments the first portion of the human body is a portion of the face.

In another embodiment the method further includes determining a second mean and a second standard deviation of geometric distortion of retouching between the first and second sets of pixel data corresponding to a second portion of the human body wherein the second portion is different from the first portion.

In another embodiment the method further includes determining a plurality of photometric statistics including a third mean and a third standard deviation between the first and second sets of pixel data of the frequency response of a linear filter corresponding to a first portion of the human body.

In yet another embodiment the method further includes determining a plurality of photometric statistics including a fourth mean and fourth standard deviation of structural similarity SSIM characterized by contrast and structural modification.

In yet another embodiment the step of generating includes executing using the processor a non linear support vector regression SVR to compute the image retouching rating based upon the plurality of statistics and characterization data defining the training parameters of the SVR.

In another embodiment the method further includes determining within a touchup filter whether the retouched image is to be displayed by a browser based upon the image retouching rating and a rating threshold displaying the retouched image within the browser when the retouched image is to be displayed and displaying an image outline within the browser when the retouched image is not to be displayed wherein the browser is in communication with a web server.

In another embodiment the method further includes defining within a browser a rating selector that specifies a maximum image retouching rating value for retouched images to be displayed within the browser sending the maximum image retouching rating value to a web server in communication with the browser and receiving a webpage for display within the browser with at least one retouched image having an image retouching rating equal or less than the maximum rating value.

A system is also provided to perform the steps in the above embodiments. Additional embodiments and features are set forth in part in the description that follows and in part will become apparent to those skilled in the art upon examination of the specification or may be learned by the practice of the invention. A further understanding of the nature and advantages of the present invention may be realized by reference to the remaining portions of the specification and the drawings.

The present disclosure may be understood by reference to the following detailed description taken in conjunction with the drawings as described below. For purposes of illustrative clarity certain elements in the drawings are not drawn to scale.

This application discloses among other things how to automatically compute a quantitative and perceptually meaningful rating of image retouching. The application also discloses rating a photograph based upon a degree by which the photograph has been digitally altered by explicitly modeling and estimating geometric and photometric changes. This rating has been demonstrated to correlate well with perceptual judgments of image retouching and may be used to objectively judge by how much a retouched image has strayed from reality.

Benefits of the disclosed methods and systems may include providing a perceptually relevant rating of image retouching that helps find a balance between the competing interests of editing images for selling products and discouraging photographic alterations that promote unrealistic expectation of body image. Providing an image retouching rating alongside a published image may inform the public of the extent to which images have strayed from reality. Such a rating may also provide incentive for publishers and models to reduce usage of the more extreme forms of digital image retouching that are common today. This rating may also help image retouchers and editors because even when original and retouched images are available it is often difficult to see and quantify the extent of image alterations.

Benefits of the disclosed methods and systems may also include providing a fast and automatic rating to users and publishers. The core computational component of the disclosed system is typically fully automatic however a user may annotate the hair head face and body in certain embodiments. When deploying an industry wide rating system this annotation could either be done automatically or with fairly minimal user assistance.

The rating quantifies the perceptual impact of geometric and photometric retouching by modeling common image retouching techniques. Geometric changes are modeled for example with a dense locally linear but globally smooth motion field. Photometric changes are modeled in certain embodiments with a locally linear filter and a generic measure of local image similarity SSIM . These model parameters are typically automatically estimated from the original and retouched images. The extent of image manipulation is for example quantified with eight summary statistics extracted from these models.

In one embodiment algorithm includes a geometric and photometric calculator for determining statistics and a support vector regression SVR for generating rating based upon characterization data geometric statistics and photometric statistics .

Geometric statistics and photometric statistics together statistics of are extracted by geometric and photometric calculator by comparing the original image to the retouched image . In one embodiment the amount of photo distortion or perceptual distortion is quantified from eight summary statistics that are extracted from geometric and photometric models. These statistics consist of four geometric measurements e.g. geometric statistics and four photometric measurements e.g. photometric statistics .

For example geometric statistics determined by calculator may use an 8 parameter affine model that is used to model a geometric transformation between local regions in the before and after images e.g. original and retouched images. The luminance transformation is modeled with a 2 parameter model embodying brightness and contrast. This 8 parameter model is given by 1 

where fand fare the local regions of the before and after images c and b are contrast and brightness terms mare terms of a two by two affine matrix and tand tare translation terms. The luminance terms c and b are incorporated only so that the geometric transformation can be estimated in the presence of luminance differences between the before and after images or the original and retouched images.

A quadratic error function in these parameters is defined for example by approximating the right hand side of Equation 1 with a first order truncated Taylor series expansion. This error function is then minimized using standard least squares optimization. Because these geometric parameters are estimated locally throughout the image the resulting global transformation can lead to unwanted discontinuities. A global penalty on large motions and a smoothness constraint are imposed by penalizing the local model parameters proportional to their magnitude and the magnitude of their local gradient. The addition of this smoothness constraint requires an iterative minimization which is boot strapped with the result of the least squares optimization. This optimization is embedded within a coarse to fine differential architecture in order to contend with both large and small scale geometric changes. A model of missing data is also incorporated that contends with the case when portions of the after image have been entirely removed or added relative to the before image.

Once estimated the geometric transformation is represented as a dense two dimensional 2D vector field 

This estimation is performed only on the luminance channel of a color image. The before and after images initially are histogram equalized to minimize any overall differences in brightness and contrast. The background in each image is replaced with white noise in order to minimize any spurious geometric distortion. This geometric model embodies the basic manipulation afforded by for example the Photoshop liquify tool used by photo retouchers to alter the global or local shape of a person.

In this example the first two geometric statistics e.g statistics 1 2 are the mean and standard deviation of the magnitude of the estimated vector field v x y shown in Equation 2 projected onto the gradient vector of the underlying luminance channel. This projection emphasizes geometric distortions that are orthogonal to image features which are more perceptually salient. These two statistics are computed only over the face region which quantify geometric facial distortion. The third and fourth geometric statistics e.g statistics 3 4 are the mean and standard deviation of the magnitude of the estimated vector field v x y Equation 2 projected onto the gradient vector and computed over the body region. These projected vectors are weighted based on specific body regions.

In a particular embodiment the bust waist thigh regions are weighted by a factor of 2 the head hair regions are weighted by a factor of and the remaining body regions have unit weight a full range of weights were explored and the final results are not critically dependent on these specific values . These two statistics quantify geometric body distortion and are computed separately from the facial distortion because observers weight facial and body distortions differently.

Photometric statistics are for example determined by calculator using either a linear filter model or a similarity measure SSIM. For example basic photometric retouches between local regions in the after image i.e. the retouched image and the geometrically aligned before image i.e. the original image are modeled with a linear filter h x y of size nine by nine pixels given by 3 

where is the convolution operator and fis the geometrically aligned before image region Equation 1 . The filter h x y is estimated locally using a conjugate gradient descent optimization with a Tikhonov regularization. The regularization is used to enforce symmetry i.e. zero phase on the estimated filter h. This estimation is performed only on the luminance channel of a color image.

Photometric retouches that are not captured by Equation 3 are measured with the similarity measure SSIM. This measure embodies contrast and structural retouches C x y as follows 4 

where and are the standard deviations of the image regions fand f and is the covariance of fand f. The various constants are 1 1 C 0.03 and C C 2. Note that in this implementation of SSIM the brightness term is excluded because it does not impact observers judgments. For the same reason SSIM is computed only on the luminance channel of a color image. This photometric model embodies special effects afforded by various Photoshop filters.

In this particular example the first two photometric statistics e.g. statistics 5 6 are the mean and standard deviation of the structural similarity SSIM or contrast and structural modification C x y in Equation 4 computed over the face region. The third and fourth photometric statistics e.g. statistics 7 8 are a measure D of the frequency response of the linear filters h x y shown in Equation 3 . D is expressed as the following 6 

where H and F are unit sum normalized one dimensional 1D frequency responses of the filter h and the local region fwhich are computed by integrating their 2D Fourier transforms across orientation. The parameter D is positive when h is a blurring filter negative when h is a sharpening filter and is tailored to the analysis of people in which filtering is commonly used to remove or enhance facial features. The mean and standard deviation of parameter D computed over the face region are the final two statistics.

In summary a total of eight summary statistics have been described. The first four geometric statistics are mean and standard deviation of the estimated vector field computed separately over the face and body. The second four photometric statistics are the mean and standard deviation of SSIM and the frequency response of the linear filters.

Characterization data is for example defines a set of training parameters used to train the SVR model used by algorithm . To generate characterization data for example four hundred sixty eight before after images were collected from a variety of on line resources primarily the websites of photo retouchers showcasing their services. These images spanned the range from minor to radical amounts of retouching.

A group of 390 observers was recruited to perform perceptual ratings through Amazon s Mechanical Turk. This crowd sourcing utility has become popular among social scientists as a way to quickly collect large amounts of data from human observers around the world. Observers were initially shown a representative set of 20 before after images in order to help them gauge the range of distortions they could expect to see. Observers were then shown 70 pairs of before after images and asked to rate how different the person looked between the images on a scale of 1 to 5 . A score of 1 means very similar and a score of 5 means very different. This yielded a total of 50 ratings per each of 468 images. The presentation of images was self timed and observers could manually toggle between the before and after images as many times as they chose observers are better able to see the amount of retouching within the images when toggling rather than viewing side by side . In order to measure the consistency of observer responses each observer rated a random set of five images three times each. The presentation of these images was evenly distributed throughout the trial. Each observer was paid 3 for their participation and a typical session lasted 30 min. Given the uncontrolled nature of the data collection some data filtering was necessary. Approximately 9.5 of observers were excluded because they frequently toggled only once between the before and after image and they responded with high variance on the repeated trials.

The SVR technique was used to generate characterization data as a mapping between the observer ratings and eight summary statistics e.g. statistics extracted from the geometric and photometric models of photo retouching at step . Each statistic was individually scaled into the range 1 1 . Specifically a nonlinear SVR with a Gaussian radial basis kernel was employed. A leave one out cross validation was performed in which the SVR was trained on 467 of 468 image ratings and tested on the remaining image. This training and testing was repeated 468 times in which each image was individually tested. The SVR has two primary degrees of freedom 1 the scalar specifies the spatial extent of the kernel function and 2 the scalar c specifies the penalty applied to deviations of each data point from the regression function. These parameters were selected by performing a dense 2D grid search to maximize the correlation coefficient of each training set. The results of the above crowd sourcing technique may then be stored into memory as characterization data .

Processor executes algorithm to process original digital image data and retouched digital image data . Those skilled in the art would appreciate that algorithm may be executed by multiple processors . Algorithm further generates an output a rating indicating deviation of the retouched digital image data from the original digital image data . Output rating may be stored within memory or transferred as an output to exterior devices other than computer . In one embodiment algorithm also includes an eight parameter model. Memory may represent one or more of a magnetic or optical disk and or an electronic memory integrated circuit e.g. RAM ROM FLASH and so on .

Step uses Equation 1 to measure geometric differences for face and body with eight parameters and then computes vector field based upon six of the eight parameters using Equation 2 . Step computes mean and standard deviation of magnitude of the vector in face and body. Step uses Equation 3 to measure photometric differences for the face and then uses Equations 6 to calculate the measure D. Step computes mean and standard deviation of D. Step uses Equations 4 and 5 to measure photometric differences for the face and computes C x y . Step computes mean and standard deviation of C x y .

In step machine learning techniques such as SVR are then used to relate these summary statistics to perceptual judgments made by human observers. It is shown below in that the summary statistics combine to yield a metric that correlates well with perceptual ratings of photo alteration.

To determine which of the eight summary statistics were most critical for predicting observer ratings we trained and tested 255 SVRs one for each possible subset of size 1 to 8. The best performing SVR with one statistic consisted of the mean of the geometric facial distortion statistic 1 as described above which yielded an R value of 0.58. The best performing SVR with two statistics consisted of the standard deviation of the geometric body distortion and the standard deviation of the photometric SSIM statistics 4 and 6 which yielded an R value of 0.69. And the best performing SVR with three statistics consisted of adding the standard deviation of the geometric facial distortion to the previous SVR statistics 4 5 and 6 which yielded an R value of 0.76. The best performing SVR of size 6 had an R value of 0.80 equal to that of the full set of size 8. This subset of size 6 consisted of the statistics 1 2 4 6 7 and 8 as described above. Although six statistics are sufficiently powerful they are extracted from each component of the geometric and photometric models. Therefore there is little cost in using all eight statistics in terms of computational complexity or in terms of training the SVR.

A linear SVR was also tested to validate the use of a nonlinear SVR over a simpler linear SVR. The R value for the linear SVR is 0.72 as compared to 0.80 for the nonlinear SVR. The mean absolute prediction error is 0.34 with a standard deviation of 0.27 as compared to 0.30 and 0.24 for the nonlinear SVR. The max absolute error jumps from 1.19 to 1.93. Overall the nonlinear SVR affords a considerably better prediction of observer ratings as compared to a linear SVR.

The perceptual rating of the present disclosure is compared against two standard image similarity perceptual ratings. A perceptual rating based only on the mean and standard deviation of a standard application of SSIM yields an R value of 0.52 as compared to our approach that had an R value of 0.80. A perceptual rating based on only the mean squared error between the before and after image performed much worse with an R value of only 0.30. Standard image similarity perceptual ratings perform poorly because they do not compensate for or measure large scale geometric distortions.

In the above embodiments the system compares original and retouched images of human subjects. However the system may also be trained for comparing images of other subjects. For example the system may be trained to compare images of landscape portraits still life and wildlife. Similarly the system may be trained to compare images of art restorations. For example a rating of restored art may be used for evaluation purposes wherein a poorly restored image may be awarded a high rating indicating significant change to the image content .

Server may represent one or more computers that are connected to Internet . For example server includes a memory and a processor not shown for clarity of illustration that respectively store and execute instructions of algorithm and instructions of certificate generator .

In one example of operation a publisher desires to publish a retouched digital image together with a certified rating that defines an amount of retouching applied to an original image to form retouched digital image . Publisher sends a message containing original image and retouched image to server requesting a certified rating of retouched image . Within server algorithm is executed to process original image and retouched image and to generate a rating . Certificate generator utilizes private key known only to certificate generator to generate certificate containing rating and an image ID that uniquely identifies retouched image . In one example image ID is a checksum of data within retouched image . In another example image ID is retouched image .

Once certificate is generated server sends certificate to publisher as message for example. Message may also contain public key . Publisher decrypts certificate using public key and optionally verifies that rating applies to retouched image using image ID . Publisher may retain certificate as evidence of rating for retouched image for example to show compliance to a rating standard.

The rating system may also be applied to other human judgments wherein the system may predict how an object may be judged. For example the rating may be applied to judging a photography contest and rating images for a scientific journal.

Observation model may be defined for any observable set of features that a user of system wishes to automatically rate. Using the example shown above observations include retouched features of a human as determined by comparing an original digital image and a retouched digital image. Observation model is thus used to define the features within the images that are of interest and defines a weighting for each of the features. Observation model may define parameters for features that are not always present within observations but that are applied when the feature is present.

The mathematical model may also be applied in reverse wherein a user may automatically retouch an image to have a desired rating. For example where a magazine desires to publish only lightly retouched images the system may be used to reduce the amount of retouching of a heavily retouched image until that image has a rating of 1 thereby meeting the magazine publishing criteria. Since system measures geometric and photometric change between an original digital image and a retouched image system may be used to reduce the level of retouching of the retouched image until a determined rating thereof is at a desired rating level. Specifically the geometric and photometric models are generative in nature and define how an image is retouched from the original digital image to get to the retouched digital image.

Browser operating on a user s computer for example accesses web site via Internet to generate a web page display . Browser includes a touch up filter that compares ratings of images received from web site to a rating threshold and does not display images that have a rating greater than rating threshold .

In the example of rating threshold has a value of 2 image has a rating with a value of 1 and image has a rating with a value of 3. Touch up filter in cooperation with browser allows image to be displayed as image within web page display because rating is less than or equal to rating threshold . Touch up filter in cooperation with browser prevents image from being displayed within web page display because rating is greater than rating threshold . In one embodiment browser displays an image placeholder to indicate where image would have been displayed within web page display .

Browser running on a user s computer for example has rating selector with a value of 2 indicating that browser should display images with rating values of 2 or less. An application server running on or in communication with web server generates web page for display within browser based upon a value of rating selector . In the example of rating selector has a value of 2 and application server generates web page with image and optionally the value of associated rating because rating has the highest value that is less than or equal to the value of rating selector .

In one example of operation rating selector forms part of a parental control setting for browser such that browser does not display images such as image that have a rating e.g. rating value greater than the value of rating selector .

In one embodiment a file format is used that stores images and with the same file together with their respective rating values. This file format may store an original image and any retouches that allow generation of retouched images for a desired rating value.

In one example of operation server sends via Internet evaluation data to a crowd source server where a plurality of evaluators evaluate evaluation data to generate results . Results include a rating value for each retouched image as perceived by each evaluator together with other values of the evaluator s interaction with crowded source server such as one or more of time taken a number of times the evaluator switched between each original and retouched image and so on. Results are sent to server where they are processed by SVR training module to generate characterization data that controls rating algorithm to automatically rate a retouched image in comparison to an original image.

Once characterization data and rating algorithm are combined to form rating module rating module may be transferred to other computers to determine a rating of retouched images as compared to original images. In the example of rating module is a software package that is purchased by publisher and used to rate retouched image against original image to determine rating . Rating module is implemented as instructions stored on computer readable media that when executed by a processor determines the rating of the retouched image as described above.

Having described several embodiments it will be recognized by those skilled in the art that various modifications alternative constructions and equivalents may be used without departing from the spirit of the invention. Additionally a number of well known processes and elements have not been described in order to avoid unnecessarily obscuring the present invention. Accordingly the above description should not be taken as limiting the scope of the invention.

It should thus be noted that the matter contained in the above description or shown in the accompanying drawings should be interpreted as illustrative and not in a limiting sense. For example the above example describe processing of two original and retouched digital images however the systems and methods may also be used to process video images which may be considered a sequence of still images. The following claims are intended to cover generic and specific features described herein as well as all statements of the scope of the present method and system which as a matter of language might be said to fall there between.

