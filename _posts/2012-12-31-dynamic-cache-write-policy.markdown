---

title: Dynamic cache write policy
abstract: A system, processor and method to monitor specific cache events and behavior based on established principles of quantized architectural vulnerability factor (AVF) through the use of a dynamic cache write policy controller. The output of the controller is then used to set the write back or write through mode policy for any given cache. This method can be used to change cache modes dynamically and does not require the system to be rebooted. The dynamic nature of the controller provides the capability of intelligently switching from reliability to performance mode and back as needed. This method eliminates the residency time of dirty lines in a cache, which increases soft errors (SER) resiliency of protected caches in the system and reduces detectable unrecoverable errors (DUE), while keeping implementation cost of hardware at a minimum.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09058282&OS=09058282&RS=09058282
owner: Intel Corporation
number: 09058282
owner_city: Santa Clara
owner_country: US
publication_date: 20121231
---
The present disclosure relates to processor architecture and in particular a method and apparatus to dynamically control cache write policy for increased reliability.

As cache memory sizes increase cache structures tend to be more vulnerable to soft errors SER and detectable unrecoverable errors DUE due to the cache retaining modified data for a longer length of time. If a soft error corrupts a modified cache line the line s data cannot be retrieved or correctly written back. Also with increasing cache sizes and high demand workloads the architectural vulnerability factor AVF also increases resulting in overall reduction of system reliability. What is needed is a cache policy that addresses the susceptibility that occurs when lines remain modified for extended periods of time.

Embodiments of disclosed subject matter pertain to increasing reliability by controlling cache write policy to force write backs of modified lines to system memory or other backing store under prescribed circumstances. At least one embodiment addresses performance penalties that result when conventional periodic flushing and scrubbing are used to decrease vulnerability.

At least one embodiment dynamically controls cache write policy based on observations of the cache vulnerability due to dirty data residencies in order to decrease the rate of soft errors occurring and improve AVF in the system while reducing the amount of performance penalty incurred.

In the following description details are set forth by way of example to facilitate discussion of the disclosed subject matter. It should be apparent to a person of ordinary skill in the field however that the disclosed embodiments are exemplary and not exhaustive of all possible embodiments.

In at least one embodiment a disclosed method dynamically controls cache write policy in a system for increased SER reliability. In at least one embodiment a cache controller includes a write policy controller that counts the total number of dirty lines in a cache each clock cycle. In some embodiments the tracking is accomplished by associating a first counter with a cache line and incrementing a value of the first counter for a write event i.e. a write to the cache line when the cache line is unmodified i.e. a write event to an already dirty line should not increment the counter. In some embodiments the first counter value is decremented or cleared when a write back event occurs. In at least one embodiment using the tracked number of the dirty lines in the cache in a given cycle an average number of dirty lines over a plurality of clock cycles is computed. In at least one embodiment the time interval used to compute the average number of dirty residencies may be a quantum of 1024 or some relevant number of cycles.

In at least one embodiment the average number of dirty lines is compared with the stored dirty residency threshold which is based on a percentage of the cache occupied by dirty data. If determination is made that the average dirty residency value is greater than the stored threshold value the cache policy is switched to a write through mode. If the average dirty residency value is less than the stored threshold value the write back mode cache policy is selected. Once the cache policy is switched to write through mode the write policy controller remains in write through mode until the average dirty residency value drops below the stored threshold value at which point the cache policy may be switched back to write back mode.

In at least one embodiment the dynamic control of the cache policy can be accomplished without having to require a system reboot. The system operation may continue while the dirty lines are being flushed. In at least one embodiment an enhancement to the write policy controller is a configurable memory bandwidth override capability. The memory bandwidth usage is monitored and if a predetermined threshold value is exceeded the cache policy may be overridden and set back to a cache write back mode. In at least one embodiment an enhancement to the write policy controller includes a built in hysteresis that requires the stored dirty threshold value to be exceeded for a configurable number of consecutive cycles before the cache policy may switch to a write through mode. Additionally a hysteresis that requires the stored dirty threshold value to be exceeded for a configurable number of consecutive cycles before the cache policy may be reverted back to a write back mode.

In some embodiments a disclosed processor includes multiple execution cores and their associated cache memories a crossbar a last level cache a cache controller and a dynamic cache write controller. At least one embodiment includes an execution core to execute instructions and a last level cache LLC to provide fast access to near memory data needed by the processor cores. In some embodiments a cache controller controls communication between the crossbar with the LLC.

In at least one embodiment the cache controller includes a write policy controller to modify cache write policy dynamically based on observation of the cache vulnerability due to dirty data. The write policy controller tracks the number of dirty lines in a cache in a given cycle. In some embodiments the tracking is accomplished by associating a counter with a cache line when unmodified and incrementing the counter s value for a write event to the cache line and clearing or decrementing the counter s value for a write back event. In at least one embodiment using the tracked number of the dirty lines in the cache in a given cycle an average number of dirty lines over a plurality of clock cycles is computed. In at least one embodiment the average number of dirty lines is compared with a stored dirty residency threshold which is based on a percentage of the cache occupied by dirty data. If determination is made that the average number of dirty lines value is greater than the stored threshold value a write through mode policy is selected. If the average number of dirty lines value is less than the stored threshold value the write back mode policy is selected. Once the cache policy is switched to write through mode the write policy controller remains in write through mode until the average dirty residency value drops below the stored threshold value at which point the cache policy is switched back to write back mode.

In some embodiments a disclosed multiprocessor system includes a processor and storage accessible to the processor. The system includes first storage to store an operating system and dirty cache line information.

In at least one embodiment the processor in the disclosed multiprocessor system includes multiple execution cores and their associated cache memories a crossbar a last level cache a cache controller and a dynamic cache write controller. In at least one embodiment the processor s uncore region includes a write policy controller to modify cache write policy dynamically based on observation of the cache vulnerability due to dirty data. The write policy controller keeps track of the number of dirty lines in a cache in a given cycle. The tracking is accomplished by incrementing a first value for a write event to a clean or unmodified line and decrementing the said first value for a write back event when a write renders a line dirty. In at least one embodiment using the tracked number of the dirty lines in the cache the average number of dirty lines over a plurality of clock cycles is computed. In at least one embodiment the average number of dirty lines is compared with a stored dirty residency threshold which is based on a percentage of the cache occupied by dirty data. If determination is made that the average number of dirty lines value is greater than the stored threshold value a write through mode cache policy is selected. If the average number of dirty lines value is less than the stored threshold value the cache policy remains in the write back mode. Once the cache policy is switched to write through mode the write policy controller may remain in write through mode until the average dirty residency value drops below the stored threshold value at which point the cache policy may be switched back to write back mode.

Throughout this disclosure a hyphenated form of a reference numeral refers to a specific instance of an element and the un hyphenated form of the reference numeral refers to the element generically or collectively. Thus for example widget refers to an instance of a widget class which may be referred to collectively as widgets and any one of which may be referred to generically as a widget .

Referring now to a block diagram of selected elements of processor is shown. While processor may be a multi core processor including a plurality of processor cores the disclosed method is applicable for a single core processor as well. In the embodiment of processor is shown with a core region including first execution core and second execution core . It is noted that other elements of processor besides execution cores may be referred to as an uncore region . Although two cores are depicted in the example embodiment in for descriptive clarity in various embodiments a different number of cores may be employed using elements of the depicted architecture. Execution cores may comprise a number of sub elements also referred to as clusters that provide different aspects of overall functionality. For example execution cores may each include front end execution pipeline and a first level L1 data cache .

In front end may be responsible for fetching instruction bytes and decoding those instruction bytes into micro operations that execution pipeline may consume. Thus front end may be responsible for ensuring that a steady stream of micro operations is fed to execution pipeline . Execution pipeline may be responsible for scheduling and executing micro operations and may include buffers for reordering micro operations and a number of execution ports not shown in .

During operation memory requests from execution pipeline may first access L1 data cache before looking up any other caches within a system. In the embodiment shown in L1 data cache may be a final lookup point for each execution core before a request is issued to the LLC which is a shared cache among execution cores .

As shown in processor includes last LLC which may be a higher level cache that operates in conjunction with L1 data cache . Thus L1 data cache and LLC may represent a cache hierarchy. In particular embodiments first execution core and second execution core within processor are not equipped with direct means of communicating with each other but rather communicate via crossbar which may include intelligent functionality such as cache control data queuing P P protocols and multi core interfacing. Crossbar may thus represent an intelligent uncore controller that interconnects execution cores with LLC .

As shown in uncore region may include a cache controller to control communication between crossbar with LLC . Dynamic cache write policy controller may use communication line to communicate with cache controller . Write policy controller may monitor specific cache events and behavior in LLC and based on the output of the controller may set the write back or write through mode policy. While in this embodiment write policy controller is depicted monitoring and controlling LLC the disclosed dynamic cache write policy controller may be utilized to monitor and set the write back or write through policy for any given cache in a processor system in order to improve the AVF and reduce the number of soft errors. Although embodiments illustrated in the drawings and described herein may refer to controlling the write policy of a shared or last level cache the write policy of any cache memory including caches that are private with respect to a specific processor core may be controlled in the same manner.

Referring now to a block diagram of elements of a dynamic cache write policy controller. A controller to provide dynamic intelligence to set the write back or write through mode in order to increase SER tolerance for any given cache in a processor system. Write policy controller communicates bi directionally with the cache controller through communication line . The cache controller communicates through communication line to provide write policy controller the number of dirty lines in the cache through to block . Write policy controller then computes the average number of dirty residency per cycle known as a quantum for reducing SER.

The number of dirty lines is tracked in a given cycle by incrementing on each write event and decrementing on each write back event when a write renders a line dirty. A write event to an already dirty line should not increment the counter. Dirty lines per quantum read out data and reset to zero every 1024 cycles is modified by dividing by number of cycles to compute the average residency per cycle .

The average dirty residency per cycle is then compared to the stored dirty residency threshold value . In some embodiments dirty residence threshold value is a programmable value the may be changed under program control to provide dynamic configurable control over the cache write policy and associated reliability concerns. The dirty residency threshold value is based on the percentage of cache occupied by dirty data and may be configurable. If during comparison the average dirty residency per cycle is found to be higher than the stored dirty residency threshold value multiplexor would set write through mode and communicate the setting to . The cache would be set to write through mode until the average dirty residency per cycle drops below the dirty residency threshold value at which point it would switch back to write back mode .

In an additional enhancement to write policy controller addresses the issue of performance degradation due to conversion to write through mode as write through caches provide inferior system performance in comparison to write back caches. Write policy controller may be enhanced to monitor the memory bandwidth usage. If write policy controller determines that memory bandwidth usage due to reasons not related to the write through mode is increasing and that the write through mode may hamper performance beyond some acceptable threshold write policy controller may override the cache policy and keep the cache in write back mode . The result of and memory bandwidth usage override are necessary with the use of AND gate in order to override the cache policy. This memory bandwidth override threshold is configurable and has the added feature of the ability to be enabled or disabled.

Referring now to a flow diagram of a method to dynamically control cache write policy for increased reliability. In process block the write policy controller tracks the total number of dirty lines in the cache as communicated by the cache controller. Write policy controller then computes the average number of dirty residencies in process block . In decision block the average number of dirty residencies is compared to the stored dirty residency threshold value. If determination is made that the average number of dirty residencies value is higher than the stored dirty residency threshold the cache policy is set to write through mode . If the average number of dirty residencies is not higher than the threshold value the write back mode cache policy is selected . In decision block the write policy controller determines if the average number of dirty lines value drops below the stored dirty residency threshold value. If determination is made that the value drops below the stored dirty residency threshold value the write back mode cache policy is selected . Otherwise the write through mode cache policy is selected .

Referring now to a flow diagram of a method to dynamically control cache write policy with a memory bandwidth override control option. In process block the write policy controller tracks the total number of dirty lines in the cache as communicated by the cache controller. Write policy controller then computes the average number of dirty residencies in process block . In decision block the average number of dirty residencies is compared to the stored dirty residency threshold value. If the average number of dirty residencies is not higher than the stored dirty residency threshold value the cache policy selects the write back mode as the cache policy .

If determination is made that the average number of dirty residencies value is higher than the stored dirty residency threshold decision block then determines if the memory bandwidth threshold is exceeded. If the memory bandwidth usage threshold is exceeded write policy controller may override the cache policy and keep the cache in write back mode . If determination is made that memory bandwidth usage threshold is not exceeded a write through mode cache policy is selected . In decision block the write policy controller determines if the average number of dirty lines value drops below the stored dirty residency threshold value. If determination is made that the value drops below the stored dirty residency threshold value the cache policy is switched back to the write back mode . Otherwise the write through mode cache policy is selected .

Embodiments may be implemented in many different system types. Referring now to a block diagram of selected elements of a processor system in accordance with an embodiment of the present disclosure. shows a system in which a processor memory and input output devices are interconnected by a number of point to point P P interfaces as will be described in further detail. However in other embodiments not shown in the processor system may employ different bus architectures such as a front side bus a multi drop bus and or another implementation. Although a processor is depicted in the example embodiment of for descriptive clarity in various embodiments a different number of processors may be employed using elements of the depicted architecture.

In processor platform is a point to point interconnect system and includes processor . While only a single processor is depicted in processor platform the platform may support multiple processors. As shown in processor is a multi core processor including first execution core and second execution core . It is noted that other elements of processor besides execution cores may be referred to as an uncore region while execution cores may also be referred to as core region . In different embodiments not shown in a varying number of cores may be present in a particular processor. Execution cores may comprise a number of sub elements not shown in also referred to as clusters that provide different aspects of overall functionality. For example execution cores may each include a memory cluster not shown in that may comprise one or more levels of cache memory. Other clusters not shown in in execution cores may include a front end cluster and an execution pipeline cluster. Execution cores may include a L1 data cache.

In particular embodiments execution cores within processor are not equipped with direct means of communicating with each other but rather communicate via crossbar which may include intelligent functionality such as cache control data queuing P P protocols and multi core interfacing. Crossbar may thus represent an intelligent uncore controller that interconnects execution cores with memory controller MC last level cache memory LLC and P P interface among other elements. In particular to improve performance in such an architecture cache controller functionality within crossbar may enable selective caching of data within a cache hierarchy including LLC and one or more caches present in execution cores . In certain implementations of processor system crossbar is referred to as a global queue.

In LLC may be coupled to a pair of processor execution cores respectively. For example LLC may be shared by execution core and execution core . LLC may be fully shared such that any single one of execution cores may fill or access the full storage capacity of LLC . Additionally MC may provide for direct access by processor to memory via memory interface . For example memory may be a double data rate DDR type dynamic random access memory DRAM while memory interface and MC comply with a DDR interface specification. Memory may represent a bank of memory interfaces or slots that may be populated with corresponding memory circuits for a desired DRAM capacity.

Processor may also communicate with other elements of processor system such as near hub and far hub which are also collectively referred to as a chipset that supports processor . P P interface may be used by processor to communicate with near hub via interconnect link . In certain embodiments P P interfaces and interconnect link are implemented using Intel QuickPath Interconnect architecture.

As shown in near hub includes interface to couple near hub with first bus which may support high performance I O with corresponding bus devices such as graphics and or other bus devices. Graphics may represent a high performance graphics engine that outputs to a display device not shown in . In one embodiment first bus is a Peripheral Component Interconnect PCI bus such as a PCI Express PCIe bus and or another computer expansion bus. Near hub may also be coupled to far hub at interface via interconnect link . In certain embodiments interface is referred to as a south bridge. Far hub may provide I O interconnections for various computer system peripheral devices and interfaces and may provide backward compatibility with legacy computer system peripheral devices and interfaces. Thus far hub is shown providing network interface and audio I O as well as providing interfaces to second bus third bus and fourth bus as will be described in further detail.

Second bus may support expanded functionality for microprocessor system with I O devices and touchscreen controller and may be a PCI type computer bus. Third bus may be a peripheral bus for end user consumer devices represented by desktop devices and communication devices which may include various types of keyboards computer mice communication devices data storage devices bus expansion devices etc. In certain embodiments third bus represents a Universal Serial Bus USB or similar peripheral interconnect bus. Fourth bus may represent a computer interface bus for connecting mass storage devices such as hard disk drives optical drives disk arrays which are generically represented by persistent storage that may be executable by processor .

The embodiment of system emphasizes a computer system that incorporates various features that facilitate handheld or tablet type of operation and other features that facilitate laptop or desktop operation. In addition the embodiment of system includes features that cooperate to aggressively conserve power while simultaneously reducing latency associated with traditional power conservation states.

The embodiment of system includes an operating system that may be entirely or partially stored in a persistent storage . Operating system may include various modules application programming interfaces and the like that expose to varying degrees various hardware and software features of system . The embodiment of system includes for example a sensor application programming interface API a resume module a connect module and a touchscreen user interface . System as depicted in may further include various hardware firm features include a capacitive or resistive touch screen controller and a second source of persistent storage such as a solid state drive .

Sensor API provides application program access to one or more sensors not depicted that may be included in system . Examples of sensors that system might have include as examples an accelerometer a global positioning system GPS device a gyro meter an inclinometer and a light sensor. The resume module may be implemented as software that when executed performs operations for reducing latency when transition system from a power conservation state to an operating state. Resume module may work in conjunction with the solid state drive SSD to reduce the amount of SSD storage required when system enters a power conservation mode. Resume module may for example flush standby and temporary memory pages before transitioning to a sleep mode. By reducing the amount of system memory space that system is required to preserve upon entering a low power state resume module beneficially reduces the amount of time required to perform the transition from the low power state to an operating state. The connect module may include software instructions that when executed perform complementary functions for conserving power while reducing the amount of latency or delay associated with traditional wake up sequences. For example connect module may periodically update certain dynamic applications including as examples email and social network applications so that when system wakes from a low power mode the applications that are often most likely to require refreshing are up to date. The touchscreen user interface supports a touchscreen controller that enables user input via touchscreens traditionally reserved for handheld applications. In the embodiment the inclusion of touchscreen support in conjunction with support for communication devices and the enable system to provide features traditionally found in dedicated tablet devices as well as features found in dedicated laptop and desktop type systems.

Referring now to a representation for simulation emulation and fabrication of a design implementing the disclosed techniques. Data representing a design may represent the design in a number of manners. First as is useful in simulations the hardware may be represented using a hardware description language or another functional description language which essentially provides a computerized model of how the designed hardware is expected to perform. The hardware model may be stored in a storage medium such as a computer memory so that the model may be simulated using simulation software that applies a particular test suite to the hardware model to determine if it indeed functions as intended. In some embodiments the simulation software is not recorded captured or contained in the medium.

Additionally a circuit level model with logic and or transistor gates may be produced at some stages of the design process. This model may be similarly simulated sometimes by dedicated hardware simulators that form the model using programmable logic. This type of simulation taken a degree further may be an emulation technique. In any case re configurable hardware is another embodiment that may involve a tangible machine readable medium storing a model employing the disclosed techniques.

Furthermore most designs at some stage reach a level of data representing the physical placement of various devices in the hardware model. In the case where conventional semiconductor fabrication techniques are used the data representing the hardware model may be the data specifying the presence or absence of various features on different mask layers for masks used to produce the integrated circuit. Again this data representing the integrated circuit embodies the techniques disclosed in that the circuitry or logic in the data can be simulated or fabricated to perform these techniques.

In any representation of the design the data may be stored in any form of a tangible machine readable medium. An optical or electrical wave modulated or otherwise generated to transmit such information a memory or a magnetic or optical storage such as a disc may be the tangible machine readable medium. Any of these mediums may carry the design information. The term carry e.g. a tangible machine readable medium carrying information thus covers information stored on a storage device or information encoded or modulated into or on to a carrier wave. The set of bits describing the design or the particular part of the design are when embodied in a machine readable medium such as a carrier or storage medium an article that may be sold in and of itself or used by others for further design or fabrication.

To the maximum extent allowed by law the scope of the present disclosure is to be determined by the broadest permissible interpretation of the following claims and their equivalents and shall not be restricted or limited to the specific embodiments described in the foregoing detailed description.

