---

title: Automatic mute control for video conferencing
abstract: In one example, a device executes one or more video communication processes that receive audio streams and video streams from a plurality of computing devices participating in a video communication session associated with the one or more video communication processes. The device evaluates one or more properties of the audio streams, including the volume of an audio signal among the audio streams. The device selects a first group of the audio streams to mute in the video communication session, based at least in part on the one or more properties of the audio streams. The device distributes a second group of the audio streams in the video communication session, while muting the first group of audio streams in the video communication session.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08681203&OS=08681203&RS=08681203
owner: Google Inc.
number: 08681203
owner_city: Mountain View
owner_country: US
publication_date: 20120820
---
Computers may be used for video conferencing in which users on different computing devices equipped with microphones and cameras. A video conferencing system conveys audio and video data among the different devices. Two or more participants are then able to see and hear each other from remote locations.

In general this disclosure includes an intelligent automatic mute feature for a video conferencing application. During video conferencing side conversations of those who are not addressing the other participants or background noises in the audio inputs can distract from or disrupt the intended speaker at any point in time. The more participants there are in a video conferencing session the more audio inputs there are and the more possibilities for extraneous noises to be distributed in the video conferencing session. Individual participants may try to address this issue by manually muting their audio inputs but manually muting and unmuting one s own audio input may be distracting or tedious and various participants may not reliably mute their audio input when appropriate such that other participants to a video conferencing session may still be exposed to distracting sounds from someone who isn t manually muting their input. In various examples discussed below an intelligent mute feature may automatically mute video conferencing participants who aren t addressing the other participants and whose audio inputs might otherwise be a source of distracting or disrupting noise while allowing the video conferencing application to continue distributing the audio inputs from one or more intended speakers to the other participants.

In one example a method includes executing one or more video communication processes that receive audio streams and video streams from a plurality of computing devices participating in a video communication session associated with the one or more video communication processes. The method further includes evaluating one or more properties of the audio streams from the plurality of computing devices the one or more properties comprising a volume of an audio signal among the audio streams. The method further includes selecting a first group of the audio streams from the plurality of computing devices to mute in the video communication session based at least in part on the one or more properties of the audio streams. The method further includes distributing a second group of the audio streams from the plurality of computing devices in the video communication session while muting the first group of audio streams from the plurality of computing devices in the video communication session.

In another example a computing device includes at least one processor at least one data storage device at least one network interface and machine readable code stored on the at least one data storage device. The machine readable code includes executable instructions that are executable by the at least one processor. The machine readable code thereby configures the at least one processor to receive audio streams and video streams via the network interface from a plurality of client computing devices participating in a video communication session associated with one or more video communication processes. The machine readable code further configures the at least one processor to evaluate one or more properties of the audio streams from the plurality of client computing devices. The machine readable code further configures the at least one processor to select a first group of the audio streams to refrain from distributing to the client computing devices in the video communication session based at least in part on one or more properties of the audio streams from the plurality of client computing devices. The machine readable code further configures the at least one processor to distribute the video streams in the video communication session via the network interface. The machine readable code further configures the at least one processor to distribute a second group of the audio streams in the video communication session via the network interface while refraining from distributing the first group of the audio streams in the video communication session.

In another example a computer readable storage medium includes executable instructions that include a video communication module and a smart mute module. The video communication module when executed by a computing device configures at least one processor of the computing device to receive audio streams and video streams via a network interface from a plurality of client computing devices participating in a video communication session associated with the video communication module. The smart mute module when executed by a computing device configures at least one processor of the computing device to evaluate one or more properties of the audio streams from the plurality of client computing devices select a first group of the audio streams from the plurality of client computing devices to refrain from distributing in the video communication session based at least in part on the one or more evaluated properties of the audio streams from the plurality of client computing devices and indicate to the video communication module to refrain from distributing the first group of audio streams from the plurality of client computing devices. The video communication module when executed by a computing device further configures at least one processor of the computing device to distribute a second group of the audio streams from the plurality of client computing devices in the video communication session while refraining from distributing the first group of the audio streams from the plurality of client computing devices in the video communication session.

The details of one or more embodiments are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

In accordance with common practice the various described features are not drawn to scale and are drawn to emphasize one or more features relevant to the present application. Like reference characters denote like elements throughout the figures and text.

Video conferencing may provide a richer and more natural venue for remote communication among two or more participants than other available alternatives such as a telephone conference or email. Businesses or other enterprises with people in different locations may use video conferencing to quickly and naturally communicate information with each other. According to aspects of this disclosure a video communication application provides video conferencing capability among participants at two or more locations. A video communication application may convey video and audio data from each of the participants in a video communication session to each of the other participants. However the more participants there are in a video communication session the more audio signals may be distributed to all the other participants. If one or more of the participants is also engaging in more or less intermittent conversation at their own location or is in an environment where other people are conversing in the background or otherwise has ambient noise from their environment these unhelpful sounds may be fed to the audio feeds for all the other participants in the video communication session.

Any of the users may be able to address this issue by manually muting their own audio input. However it may become inconvenient and annoying for a given participant to manually mute their audio input particularly if the participant wants to communicate with the other participants and or their side conversations or background noise at their location are intermittent and the participant has to manually activate and deactivate the mute on their audio input over and over. Additionally one or more of the participants may forget to mute or not think of manually muting their audio signal when they engage in side conversations or experience intrusive background noise at their location and the potentially unhelpful or intrusive sounds are conveyed to all the other participants in the video communication session interfering with those who are trying to convey and listen to the contents of the video communication session despite the existence of the capability for manual mute in the video communication application.

In various examples a system of this disclosure resolves these issues by providing an automatic audio mute on participants in a video communication session. In one example described as follows one or more video communication applications video communication background processes or other video communication processes may be implemented in a web application hosted on a server device and may include a smart mute functionality which may be provided by a smart mute module or algorithm as part of the video communication application or other video communication process. The smart mute module may evaluate one or more properties of the audio streams from each of the participants in a video communication session. For example the smart mute module may evaluate who the current intended speaker is in the video communication session or it may distinguish when an audio stream is conveying side conversations or background noise that are likely to interfere with the other participants experience of the video communication session. Based on the one or more properties it evaluates from each of the audio streams the smart mute module may select one or more of the participants audio streams to automatically mute. The smart mute module in this example may thereby automatically make the video communication session more orderly easier to understand clearly and a more helpful and more enjoyable experience for its participants.

A video communication session as used herein is a broad term encompassing as its plain and ordinary meaning including but not limited to one or more objects which may be stored in and or are executable by hardware which may enable video communication clients coupled to the one or more objects to exchange information. The one or more objects may include data and or provide functionality of a video communication session as described herein.

The video communication session may enable multiple participants not only to see and speak with each other but also to share navigate through and make edits to documents share and watch videos share and listen to audio feeds play games and browse the internet together among other modes of interacting and sharing content. Video communication sessions may support multi way audio and or video communication. For example client devices associated with participants may send audio and or video streams to a server device that may forward the audio and or video streams to the other client devices coupled to the video communication session. Client devices receiving the audio and or video streams may output the audio and or video streams to the users of the client devices.

As used throughout this disclosure headings are included to improve the clarity of the disclosure and are not necessarily used to define separate embodiments. In some examples features of various embodiments may be combined and or used from among contents discussed under multiple headings in accordance with aspects of the present disclosure.

The video communication process may be or include a video communication application including e.g. a web application a client application etc. a video communication module a video communication background process or other video communication background process. While a single server device is illustratively depicted the functions of server device may be distributed among multiple server devices which may also be hosted in one or more data centers for example. While many examples herein are discussed in terms of a video communication application each of these is also illustrative of and applicable to any type of video communication process.

In the examples depicted in computing device A is a desktop computer computing devices B and C are tablet computers and computing devices D F are smartphones. As shown in each of computing devices A F is displaying video feeds of participants in a video communication session or video conferencing session with each other. While six particular computing devices are illustratively depicted in the example of in other examples two three ten or any number of computing devices of any type may participate in a video communication system. Computing devices A F or other computing devices included in a video communication session may include any of a variety of different types of computing devices such as smartphones tablet computers laptop computers desktop computers servers processor enabled televisions gaming consoles portable media players e book readers smart wristwatches and any other type or form factor of computing device.

As a particular example computing device A includes a display screen A displaying a graphical user interface GUI for a video communication client application i.e. a client GUI A that includes multimedia content A participant panel A and control panel A. Client GUI A may include graphical elements such as text video feeds and visual data. The graphical elements displayed by client GUI A may more generally include any visually perceptible representation. Multimedia content A shows a video feed for the user of computing device A who is one of the participants in the video communication session and who is currently the focus of attention in the video communication session. Participant panel A displays smaller sized video feeds of the other participants in the video communication session i.e. the users of the other computing devices B F. Participant panel A may also display a smaller sized video feed of the user s own video input at other times during the video communication session e.g. when she is not the focus of attention in the video communication session.

Control panel A provides graphical user interface elements such as icons and or widgets enabling the user to enter various inputs for controlling the video communication session and or the user s participation in it. Client GUI A is rendered in a web browser in the example of computing device A and includes address bar where a user may enter a URL for accessing the video communication process running on server device . Computing device A receives video streams from the other computing devices B F as distributed by server device and renders the video feeds depicted in client GUI A based on those video streams. Computing device A also includes speakers A and similarly receives audio streams from one or more of the other computing devices B F as distributed by server device and provides audio feeds through speakers A based on those audio streams. Display screen A and speakers A are illustrative examples of output devices for computing device A while any of a variety of other output devices may also be used such as separate peripheral video and audio output equipment that may be physically or wirelessly connected to or in communication with computing device A. This may include separate or additional 2D or 3D video display screens or monitors and or separate stand alone speakers for example.

Computing device A further includes a camera A that may be configured for capturing video data such as real time video data of the user of computing device A and sending the video data in a video stream to server device . Computing device A also includes a microphone A that may capture audio data in the presence of computing device A such as spoken word audio inputs from the user of computing device A and sending the audio data in a real time audio stream to server device . Camera A and microphone A are illustrative examples of input devices for computing device A while any of a variety of other input devices may also be used such as separate peripheral video and audio recording equipment that may be physically or wirelessly connected to or in communication with computing device A.

The example of computing device B is a mobile tablet computing device and has a somewhat different client GUI B rendering on its display screen B. Computing device B runs a dedicated client video communication application as opposed to accessing the video communication web application through a web browser as with computing device A. Similarly to client GUI A on computing device A client GUI B also displays a large sized multimedia content B currently showing the video feed for the user of computing device A. Client GUI B also displays a participant panel B but unlike the example of client GUI A client GUI B also includes a source video feed B that shows the video feed from computing device B itself i.e. showing the user of computing device B. The user may then be able to see and keep track of how he appears in his own video feed to the other participants in the video communication session. Participant panel B currently shows the other users besides the users of computing devices A and B. Client GUI B also displays control panel B.

Computing devices C F are illustratively shown with still other variations of client GUIs that include a larger size multimedia content taking up most of the real estate of their display screens plus a smaller sized source video feed each showing the device s own video feed back to its user but no participant panel. Computing devices C F may include any of a variety of different kinds of computing devices running any of a variety of different operating systems and client application versions and configurations for participating in the video communication session. These computing devices C F may also have the capability of displaying a participant panel or a control panel but simply may have those features turned off in the view illustratively depicted in . In other implementations computing devices may run video communication client applications that lack one or more of these features or that also include other features besides those illustratively depicted here.

Computing devices A F are all communicatively connected with server through network which may be the Internet a local area network LAN or any other network or combination of networks. Network connecting computing devices A F with server device may include wired or wireless communication channels capable of sending and receiving communication data. Network may include a network connection using a Transmission Control Protocol and Internet Protocol TCP IP protocol stack or a User Datagram Protocol UDP network connection over IP or other Internet Layer and Transport Layer protocols. Network may include the Internet a local area network LAN an enterprise network a wireless network a G wireless network a cellular network a telephony network a Wi Fi network a wide area network WAN a WiMAX network one or more other types of networks or a combination of two or more different types of networks e.g. a combination of a cellular network and the Internet . Network may incorporate any of a wide variety of servers gateways routers other network nodes and wired or wireless communication channels capable of communicating data. Users A F are each depicted proximate to their own computing devices A F which enable the users A F to video conference with each other from separate locations whether in different rooms of the same building or in separate locations anywhere in the world.

Computing devices A F and server device may exchange audio streams A F of audio data for audio feeds collected by computing devices A F and video streams A F of video data for video feeds collected by computing devices A F over network . In various example computing devices A F and server device may exchange audio streams A F and video streams A F using any of a variety of Application Layer protocols on top of TCP or UDP for communicating the video and audio data as well as requests responses controls and negotiating the connection such as Real Time Streaming Protocol RTSP Real time Transport Protocol RTP Real time Control Protocol RTCP Hypertext Transfer Protocol HTTP and or Hypertext Transfer Protocol Secure HTTPS for example. In various examples the video streams A F may be encoded in a format such as H.263 or H.264. In other examples other protocols or formats may be used. In other examples some or all of audio streams A F and video streams A F may be transferred encrypted such as for example using Secure Real time Transport Protocol SRTP or any other encrypted transfer protocol.

Computing devices A F may each include a communication application that includes cooperates with or runs a client side video communication module . Any one or more of computing devices A F may run a different version or configuration of communication application such as different versions for different operating systems for example. Video communication module may be a portion of communication application a plug in for communication application a separate application or may involve any of these or other arrangements. For example in computing device A communication application may be a web browser application and video communication module may be a plug in for the web browser application that enables video communication in the web browser. As another example in computing device B video communication module may be a stand alone application that may be downloaded separately and launched from its own icon on a home screen and may make use of other computing resources on computing device B represented by communication application .

As also shown in each of computing devices A F also includes user input and output components illustratively represented in computing devices A and B with computing device A comprising microphone A speakers A camera A and screen A and computing device B comprising microphone B speakers B camera B and screen B. Any of computing devices A F may use any kind of user input output devices for collecting audio and video data and providing audio and video outputs including for a video communication session. Various user input output components may be detachable or not an integrated part of a given computing device but the computing device may still be configured to have user input output components operably connected to them such as with connectors jacks drivers processing cards or other elements allowing audio and or video input and or output components to be operably connected with either a hardline or wireless connection. Any of computing devices A F may also include or be attached to any of a variety of additional user input output components such as video projectors keyboards keypads buttons mice trackpads trackballs joysticks compression sensors etc. For computing device B or for any applicable computing device the display screen may be a presence sensitive screen i.e. a touchscreen.

Server device may include one or more server hardware devices and may include one or multiple processors. Software executing on server device may execute on a single processor or may execute on multiple processors e.g. for distributed or multi threaded processing . Server device runs web server which includes a video communication module . Video communication module may be a web application or a part of a web application that enables video communication sessions for video conferencing. Web server also includes smart mute module which may be part of the same web application as video communication module or part of video communication module or may be a separate application that communicates with video communication module . Video communication module may set up manage and later tear down video communication sessions including representative video communication session that video communication module has set up to connect users A F in the example depicted in .

For example user A may initially use computing device A to connect with video communication module on server device and enter inputs to cause video communication module to initiate a video communication session . User A may then invite or permit other users B F to join video communication session . The other users B F may also connect with video communication module and video communication session on server device . Client side video communication modules running on computing devices A F may establish audio and video connections with server side video communication module running on server device . Computing devices A F and server device may then send and receive audio streams A F and video streams A F to each other for video communication session . Server side video communication module may dynamically update which computing devices A F are connected to video communication session and update the display in client GUIs on computing devices A F accordingly such as by adding or removing a participant icon in a participant panel in client GUIs when a user joins in or quits video communication session .

Users A F may also use computing devices A F to send and receive any of a variety of other types of data in video communication session such as document data in a document module or application for sharing and viewing a document together for example. This may be a presentation document or a word processing document that may be displayed in the client GUIs on computing devices A F for example.

Video communication module running on server device may then receive audio streams A F and video streams A F from computing devices A F respectively. Audio streams A F and video streams A F may include spoken word and other voice inputs and video images in real time from users A F respectively.

Smart mute module may evaluate one or more properties of the audio streams A F. Smart mute module may then potentially select a first group of one or more of the audio streams to mute i.e. to refrain from distributing in the video communication session based at least in part on the one or more properties it has evaluated of the audio streams A F. In this example smart mute module may then indicate to video communication module to mute the selected audio streams i.e. to refrain from distributing in the video communication session the selected first group of audio streams that smart mute module has selected for muting.

Smart mute module thereby provides a capability for automatically muting any one or more audio streams among audio streams A F from any one or more of computing devices A F based on criteria it uses for evaluating whether to mute one or more of the audio streams. For example the smart mute module may distinguish audio streams that encode audio signals that are mainly quiet or that include intermittent side conversation or background noise as opposed to an audio stream that encodes a participant clearly speaking to the other participants in the video communication session . Smart mute module may select those audio streams that convey side conversation or background noise to mute while distributing or refraining from muting audio streams that convey spoken word content with properties consistent with being intended for the video communication session in this example.

As part of this example smart mute module may evaluate an average volume of an audio signal of one or more of the audio streams A F where the average volume corresponds to the volume loudness or intensity of the audio input captured by a microphone or other audio input device of the source computing device . Smart mute module may evaluate the average volume over multiple intervals of time where each interval may be between one and ten seconds inclusive or some other interval appropriate for evaluating whether the audio stream conveys a clear human speaker or a lack thereof side conversations background noise or other likely possibilities.

As a particular example user A may be clearly speaking to the other users B F participating in video communication session while the other users B F are listening to user A. Smart mute module may evaluate audio signals A F and identify audio stream A as having the highest average volume potentially by a meaningful margin from among audio signals A F in this example. Smart mute module may evaluate only the volume in the audio signals for the audio streams A F or smart mute module may also evaluate other properties of A F. Smart mute module may conclude that audio stream A conveys an audio signal with a consistently moderate volume and or that is otherwise consistent with clearly articulated steadily delivered human speech while audio streams B F convey audio signals with low volume and or that are otherwise consistent with ambient noise and that may have occasional signals consistent with side conversations or intrusive background noises. Smart mute module may then select audio streams B F to mute i.e. to refrain from distributing in video communication session while smart mute module continues to allow video communication module to distribute audio stream A in the video communication session.

User A may naturally pause in her speech from time to time and the pauses may sometimes be several seconds long. Smart module may evaluate audio stream A from user A s computing device A over multiple intervals of time such as in rolling averages of five or ten second intervals at a time for example and refrain from concluding from a pause of several seconds that audio stream A no longer represents an intended speaker in video communication session . On the other hand if audio stream A shows a decrease in volume or other characteristics of its audio signal consistent with just ambient level background noise for over intervals of time such as ten seconds for example smart module may conclude that user A is no longer an intended speaker in video communication session . Smart mute module may evaluate for a decrease in volume over any of various intervals of time such as between one and ten seconds inclusive for example or any interval of time that is indicative of a relevant transition in intended speaker in the video communication session . Smart module may then implement an appropriate change in video communication session such as to un mute or release the mute on audio signals B F and begin distributing all the audio streams A F until subsequent evaluation shows a good reason for another change in its automatic muting selections.

Smart mute module may on the other hand also evaluate for an increase in volume in the audio signal of an audio stream that is currently muted as a potential criterion for automatically unmuting that audio stream. This may be useful when one of the muted participants interrupts or interjects or begins intentionally addressing the other participants in some other way. The automatic mute feature may still allow for quickly and automatically unmuting a participant who suddenly begins speaking in a way intended for the other participants without having to wait for or override the automatic mute feature to be heard. In one illustrative example the smart mute module may detect an increase in volume in an audio signal in audio stream B for example which may be among a group of audio streams B F previously selected to mute and to refrain from distributing. In response to detecting the increase in volume in the audio signal in audio stream B smart mute module may quickly and automatically begin distributing audio stream B in the video communication session potentially quickly enough that neither user B nor the other participants notice any lag time in his automatic mute being released and his audio stream B being distributed to the other participants.

Smart mute module may also use audio signal analysis and comparison techniques for evaluating not just volume but more specific properties of the audio signal. Smart mute module may compare the audio signal from any of audio streams A F with properties of a single clearly articulated human speaker properties of jumbled or low level human speech from multiple speakers or properties of ambient noise or other forms of background noise for example. Smart mute module may be programmed with libraries of examples of each of these types of audio signals or simplified representations of categories of signals. Smart mute module may also be trained to recognize each of these or other types of audio signals using techniques of pattern recognition or machine learning in various examples. In various examples smart mute module may evaluate audio streams A F to determine whether the audio streams A F are conveying human speech from a single speaker. Smart mute module may then select at least one of the audio streams A F that smart mute module determines is not conveying human speech from a single speaker to mute and to refrain from distributing.

In some examples smart mute module may also evaluate the video streams A F that accompany the audio streams A F and also use information from the video streams A F in selecting audio streams to mute. For example smart mute module may evaluate one or more of the video streams A F to determine whether the video streams are conveying video data that represents a human figure. Smart mute module may incorporate the idea that if the video data do not show a human figure in the picture such as if the participant at that computing device has gotten up and stepped away for a while it is more likely that the accompanying audio stream from that computing device is not necessary to distribute in the video communication session and is appropriate for muting. Smart mute module may therefore select for automatic muting at least one of the audio streams from one of the computing devices with a video stream that is determined not to be conveying video data representing a human figure.

In various examples when users A F also use computing devices A F to send and receive document data for a document application such as to share a document and enter inputs to navigate through the document smart module may also evaluate the document data as another factor to use in selecting audio streams to mute or refrain from muting. For example video communication module may receive document data for a document application such as a presentation file for a presentation application or a slide deck application from computing device A. The document application may be another web application running on server device and the document data video communication module receives from computing device A may be user inputs to access and navigate through the document in one example or the document application may be running on computing device A in another example. Video communication module may distribute the document data among the at least some of computing devices A F to enable the document to be displayed on computing devices A F.

Smart module may also base its selection of which audio streams to mute or not at least in part on which of computing devices A F is sending document data for the document application. This may include not only document data from the user who initially shared the document but also document data representing inputs from another one or more users who are navigating through making edits to or otherwise manipulating the document. The smart mute module may make selections that reflect the idea that a user who is sharing a document or entering inputs to navigate through or manipulate the document is more likely to be an intended speaker that the other participants intend to listen to. The smart mute module may therefore refrain from selecting audio streams to mute and to refrain from distributing when those audio streams are from computing devices that are sharing or sending document data while smart mute module may be more likely to select other audio streams to mute from computing devices that are not sharing or sending document data for the document. In other words selecting a group of the audio streams to refrain from distributing may be based at least in part on selecting one or more of the audio streams other than an audio stream received from the computing device from which the document data is received to refrain from distributing while distributing the audio stream from the computing device from which the document data is received.

Smart module may implement changes in the muting state of video communication session by indicating the change in muting state to video communication module . Such indications or communications between smart module and video communication module may take any of a variety of forms and may be a useful abstraction in various examples of a smart mute functionality interacting with the management of video communication session and or video communication module . For example smart mute module may be or include a method class library subroutine or other object within a larger communication application that may also include video communication module or that may be video communication module .

Each of computing devices A F may connect to others of computing devices A F or to any other number of computing devices through server device . In other examples computing devices A F may connect directly to each other. That is any two of computing devices A F or other computing devices may be connected together in a peer to peer fashion either directly or through network . A peer to peer connection may be a network connection that partitions tasks or workloads between peers e.g. a first computing device A and a second computing device B without centralized coordination by a server e.g. server . Computing devices and may exchange communication data such as audio streams A F and video streams A F via a peer to peer connection. In other examples any combination of computing devices A F may communicate in a peer to peer manner.

While various examples are described with each of computing devices A F transmitting a single audio stream and video stream any or all of computing devices A F may also capture and transmit multiple audio streams and or video streams . For example users E and E are both using computing device E together. As seen in participant panels A and B on display screens A and B respectively in the example of users E and E both appear together in a single video feed which may be generated by a single camera on computing device E. In another example computing device E may include multiple cameras and or microphones or have multiple cameras and or microphones either operatively attached to it operatively in communication with it or included in it and users E and E and potentially additional users may each orient a separate camera on themselves and speak into their own individual microphone. Computing device E may then send multiple audio streams E E etc. and or multiple video streams E E etc. to server . Server may then evaluate and distinguish among the multiple audio streams E E etc. from computing device E individually and potentially select one of these audio streams to mute while refraining from muting another one or more of these audio streams. For example if smart mute module evaluates properties of the audio streams to be consistent with user E speaking to the other participants in video communication session while user E is remaining quiet or conversing intermittently in the background with other passersby smart mute module may select an audio stream from user E to mute while refraining from muting the audio stream from user E in this example.

A video communication session as used herein is a broad term that encompasses its plain and ordinary meaning and includes but is not limited to one or more objects which may be stored in and or be executable by hardware which may enable communication client devices coupled to the one or more objects to exchange information. The one or more objects may include data and or provide functionality of a video communication session as described herein. For instance video communication session may include data that among other things specifies client computing devices A F coupled to video communication session . Video communication session may further include session information such as a duration of video communication session security settings of video communication session and any other information that specifies a configuration of video communication session . Web server may send and receive information from client computing devices A F coupled to video communication session thereby enabling users participating in the video communication session to exchange information.

Web server as shown in may perform one or more operations that enable communication application running on any one of computing devices A F to communicate with video communication module executing on server device and to initiate or access video communication session . In various examples communication application on one of computing devices A F may include functionality to send an initiation request to server device to create or initiate video communication session . Server device may communicatively couple computing device A F to video communication session in response to receiving one or more initiation requests. Web server may generate manage and terminate video communication sessions such as video communication session .

As shown in the example of server device includes one or more processors memory a network interface one or more storage devices input device and output device . Server device may include one or more of any of these components and one or more types or sub components of any of these components. Server device also includes an operating system that is executable by server device . Server device in the example of further includes web server that is also executable by server device . Each of components and as well as data streams and may be interconnected physically communicatively and or operatively by communication channels A B for inter component communications. Communication channels A B may include any type of bus communication fabric or other type of element for communicating data.

Processors in one example are configured to implement functionality and or process instructions for execution within server device . For example processors may be capable of processing instructions stored in memory or instructions stored on storage devices .

Memory in one example is configured to store information within server device during operation. Memory in some examples may be described as a computer readable storage medium. In some examples memory is a temporary memory meaning that long term storage is not a primary purpose of memory . Memory in some examples may be a volatile memory such that memory does not maintain stored contents when the computer is turned off. This may include random access memory RAM dynamic random access memory DRAM static random access memory SRAM and other forms of volatile memory known in the art. In some examples memory is used to store program instructions for execution by processors . Memory in one example is used by software or applications running on server device e.g. applications to temporarily store information during program execution.

Storage devices in some examples also include one or more computer readable storage media. Storage devices may be configured to store larger amounts of information than memory . Storage devices may further be configured for long term storage of information. In some examples storage devices include non volatile storage elements. Examples of such non volatile storage elements include magnetic hard discs optical discs floppy discs flash memories or forms of electrically programmable memories EPROM or electrically erasable and programmable EEPROM memories.

Server device in some examples also includes a network interface . Server device in one example utilizes network interface to communicate with external devices via one or more networks such as one or more wireless networks. Network interface may be a network interface card such as an Ethernet card an optical transceiver a radio frequency transceiver or any other type of device that can send and receive information. Other examples of such network interfaces may include Bluetooth G and WiFi radios in mobile computing devices as well as Universal Serial Bus USB . In some examples server device utilizes network interface to wirelessly communicate with an external device such as computing devices A F of .

Server device in one example also includes one or more input devices . Input device in some examples may be configured to receive input from a user through audio tactile or video feedback. Examples of input device include a presence sensitive screen a mouse a keyboard a voice responsive system a video camera a microphone or any other type of device for detecting a command from a user.

One or more output devices may also be included in server device . Output device in some examples is configured to provide output to a user using tactile audio or video output. Output device in one example includes a presence sensitive screen and may utilize a sound card a video graphics adapter card or any other type of device for converting a signal into an appropriate form understandable to humans or machines. Additional examples of output device include a speaker a cathode ray tube CRT monitor a liquid crystal display LCD or any other type of device that can generate intelligible output to a user.

Server device may include operating system . Operating system in some examples controls the operation of components of server device . For example operating system in one example facilitates the interaction of one or more applications e.g. web server with processors memory network interface storage device input device and output device .

As shown in web server may include video communication module video communication session module and smart mute module as described above with reference to . Applications web server video communication module video communication session module and smart mute module may each include program instructions and or data that are executable by server device . For example video communication session module and smart mute module may include instructions that cause web server executing on server device to perform any one or more of the operations and actions described in this disclosure.

Video communication module document module and smart mute module are each referred to as modules in the most generic sense that they are portions of machine readable code in any form and are not meant to limit them to any particular form or particular type of division of machine readable code. For example video communication module may be a stand alone video communication session application and document module may be a stand alone document application while smart mute module may be incorporated as a method or class that forms part of the video communication session application or is called by the video communication session application and that makes calls to or otherwise communicates with the document application . In other examples video communication module and smart mute module may each be implemented as one or more methods classes objects libraries subroutines or other portions of machine readable code as part of a larger application. In other examples video communication module document module and smart mute module may each be stand alone applications that communicate with each other. In other examples video communication module may be an application that has already been running on server device and smart mute module may be a new patch or upgrade to video communication module or part of a new version of video communication module .

In various examples video communication module may be implemented as a version of any one of the Google i.e. Google Plus Gmail iGoogle Orkut or other web applications operated by Google Inc. of Mountain View Calif. The smart mute module may be implemented as a new feature of the video conferencing capability of any one or more of these web applications. The document module may be implemented as a version of the Google Docs web application operated by Google Inc. for example. The document module may serve as a document application for documents in the form of presentations word processing documents spreadsheets drawings forms or other types of documents and may be used in conjunction with video communication module and may communicate with video communication module and or smart mute module for example. These examples are provided with the understanding that new features and new versions of these web applications are frequently implemented and various aspects of this disclosure may be implemented as novel aspects of versions of these examples rather than existing in prior versions. The video communication module incorporating the functionality of smart mute module may be adapted to run a client user interface in any of a variety of browser applications dedicated video conferencing applications or other applications on any of a number of different desktop laptop tablet smartphone or other computing devices running any of a variety of different traditional or mobile operating systems.

Web server may use any of a variety of tools or technologies for implementing the functions described herein. In various examples web server may be programmed using Java. In various examples web server may use server side JavaScript and may use the V JavaScript engine developed by Google Inc. and or libraries for server side JavaScript. Any action performed by any element or feature comprised in or running on server device may in general be attributed to server device . Any of the functions of server device described herein may also equivalently be abstracted among multiple servers a data center or any combination of servers and or data centers.

In accordance with aspects of the present disclosure smart mute module shown in may evaluate one or more properties of the audio streams select a first group of the audio streams to refrain from distributing to the client computing devices A F as shown in in the video communication session based at least in part on one or more properties of the audio streams and communicate to the video communication module to refrain from distributing the first group of audio streams as described in this disclosure.

Web server also includes user roles data store communicatively accessible to video communication module and smart mute module . User roles data store may include information associated with one or more of users A F such as user roles of users A F within a company or other enterprise. Smart mute module may receive and use information from user roles data store in addition to properties of audio streams A F in evaluating whether to mute any of audio streams A F such that smart mute module may select one or more of audio streams A F to refrain from distributing in video communication session based at least in part on the user roles indicated in user roles data store .

For example user roles data store may provide data on user roles that includes data indicating that computing device A is associated with user A and that user A is the CEO of the company. In other examples user roles data store may provide data showing that user A has another senior position within an enterprise. User roles data store may provide user role data showing that computing devices B E are associated with users B E and its user role data may include specific information on the user roles of B E. This user role data may show that users B E have positions below the senior position in the enterprise. The user roles data store may not have user role data associated with user F or computing device F that user F is using and that is connected to video communication session . For example user F may be a participant from outside the enterprise to which the other users belong or may be new and not yet have his data incorporated in user roles data store .

Smart mute module may respond in any of a variety of ways to the user role data it receives from user roles data store or that it doesn t receive from user roles data store in the case of a user such as user F. For example smart mute module may base a selection of one or more audio streams to mute based at least in part on selecting audio streams B F received from computing devices B F associated with the users who have positions below user A s position as CEO or other senior position in the enterprise. Smart mute module may then indicate to video communication module to mute or to refrain from distributing audio streams B F in video communication session .

This selection may be based only in part on the user role information as well as on the properties of the audio streams A F themselves so this does not mean that smart mute module simply mutes users B F and allows the audio stream from user A to be distributed in video communication session to users B F in this example. Rather smart mute module may take the audio stream properties and the user role data into account and potentially also along with further data such as document application data being sent in video communication session in this example. For instance smart mute module may generally rely in the first instance on properties of the audio streams such as audio signals distinguishing between human speech clearly intended for video communication session versus side conversations ambient noise or other background noise but also bias its decisions toward allowing user A to speak to the other users and muting one or more of the other users B F when there are conflicting signals on who is currently intending to speak to the other users. Smart mute module may also evaluate any of these and other forms of data according to complex algorithms that may be adapted or refined through expert rules design pattern recognition machine learning or any other techniques.

User roles data store may include any suitable data structure to store information such as a database lookup table array linked list etc. In one example user roles data store may include user identifiers that identify users A F associated with computing devices A F coupled to server device . User roles data store may contain information related to a profile of a participant including but not limited to an identity of the participant a designation of the participant for the video communication session e.g. moderator host presenter etc. a geographical location of the user or other information. Additional information may be included in user roles data store pertaining to statistics of a particular user including for example how much time a given user has been an active speaker in the current video communication session and or previous video communication sessions for example. Smart mute module may include any of these factors in its evaluations as well such as biasing toward refraining from muting a user whose user role indicates she is the moderator or main presenter for the current video conferencing session and biasing toward muting the other participants or raising the likelihood of unmuting other participants as the length of time one speaker has been speaking increases for example.

Additional client side user roles data stores not depicted in may in some examples also be included on one or more of computing devices A F and may update user roles data store on web server during video communication session . User roles data store may execute a query on the client side user roles data stores on computing devices A F when their users initially join video communication session and update its information as may be warranted from the data it receives from the client side user roles data stores on computing devices A F in this example.

As shown in the example of computing device A includes one or more processors memory a network interface one or more data storage devices power source one or more microphones B one or more speakers B one or more cameras B and display screen B which may be a touchscreen or presence sensitive screen in the example of computing device B. Computing device B also includes operating system that may be stored on one or more storage devices and execute on one or more processors . Each of components B B B B and may be interconnected physically communicatively and or operatively for inter component communications.

Operating system in various examples may control the operation of components of computing device A and facilitate operation of higher level software applications. Computing device A in this example further includes applications including communication application that is also executable by computing device A. Operating system in one example facilitates the interaction of communication application with processors memory network interface data storage device power source one or more microphones B one or more speakers B one or more cameras B and display screen .

As shown in communication application may include video communication module . Communication application and video communication module may each include program instructions and or data that are executable by computing device A or by at least one of the one or more processors of computing device A. For example communication application and or communication module may include computer executable software instructions that cause computing device A to perform one or more of the operations and actions described in the present disclosure. In various examples operating system and communication application may include code and or data that are stored on one or more data storage devices and that are read and executed or processed by one or more processors and may in the process be stored at least temporarily in memory .

In this illustrative implementation of computing device A operating system may include an operating system kernel which may include various device drivers kernel extensions and kernel modules for example. Operating system may also interact with a set of libraries which may include various more or less standard specialized and or proprietary libraries such as a media framework which may implement various basic functions for controlling the content displayed on display screen B including the video feed content and other content provided by communication application .

In this illustrative implementation of computing device B operating system may also interact with a runtime which includes various core libraries as well as a virtual machine which may be the Dalvik virtual machine in one example implementation. Virtual machine may abstract certain aspects and properties of computing device B and allow higher level applications to run on top of virtual machine so that software code in the higher level applications is compiled into bytecode to be executed by the virtual machine .

For example software for applications such as communication application may be written in C which may be executable as native code by computing device B or may also be written in Java then compiled to virtual machine executable bytecode to be executed by virtual machine . As one illustrative example libraries may include the Standard C Library libc which provides native support for C functions. In different implementations the operating system and or the virtual machine may be able to execute code written in various other languages such as Objective C C JavaScript Python Ruby Clojure or Go for example either natively or compiled into a virtual machine executable bytecode or compiled into an assembly language or machine code native to the CPU of computing device A for example. Various examples may not use a virtual machine and use applications that run natively on the computing device A or that use some other technique compiler interpreter or abstraction layer for interpreting a higher level language into code that runs natively on computing device A.

In various examples computing device A may also have various application programming interfaces APIs that are native to operating system and that run on top of operating system and which are intended to provide resources that automate or facilitate higher level applications that access the one or more APIs. These one or more APIs may include object libraries or other libraries toolsets or frameworks and may be associated with a native programming environment for writing applications. Computing device B may also have a different specific organization of APIs libraries frameworks runtime and or virtual machine associated with or built on top of operating system other than the example organization depicted in .

Higher level applications such as communication application may therefore make use of any of various abstractions properties libraries or lower level functions that are provided by any of operating system OS kernel libraries media framework runtime core libraries virtual machine or other compilers interpreters frameworks APIs or other types of resources or any combination of the above with which computing device B is configured to enable functions such as sending audio stream B and video stream B from microphone B and camera B to server device displaying a video feed based on video stream B in source video feed B in client GUI B receiving other audio streams and video streams from server device as part of a video communication session display video feeds in the participant panel B and or the multimedia content B in client GUI B based on the other video streams received from server device and provide an audio output via speakers B based on the other audio streams received from server device

The one or more processors in various examples may be configured to implement functionality and or process instructions for execution within computing device B. For example processors may be capable of processing instructions stored in memory or instructions stored on data storage devices . Computing device B may include multiple processors and may divide certain tasks among different processors. For example processors may include a central processing unit CPU which may have one or more processing cores. Processors may also include one or more graphics processing units GPUs and or additional processors. Processors may be configured for multi threaded processing. Processors and or operating system may divide tasks among different processors or processor cores according to certain criteria such as to optimize graphics rendering or to optimize the user experience. For example processors and or operating system may reserve a particular processing thread or processor or processing core or a portion thereof for certain tasks such as rendering translational motion of graphical elements or for rendering still images or video frames within a video output such as video feeds and other graphical elements displayed in client GUI B.

Various tasks or portions of tasks may also be divided among different layers of software and hardware. For example a processing thread may oversee higher level management of video display while being configured to push much of the processing burden of decoding and rendering the graphics for video feeds through GPU hardware that is optimized for the task.

Memory in various examples may be configured to store information within computing device B during operation. Memory in various examples may be a computer readable storage medium. In various examples memory is a temporary memory and computing device B relies more on one or more data storage devices than memory for long term storage. Memory in various examples may be a volatile memory meaning that memory does not maintain stored contents for a long duration of time once it is powered down such as when computing device B is turned off. Examples of volatile memories that may characterize memory include random access memories RAM dynamic random access memories DRAM static random access memories SRAM and other forms of volatile memories. In various examples memory may be used to store program instructions for execution by processors . Memory in various examples may be used by software or applications running on computing device B to temporarily store data and or software code during execution of an application.

One or more data storage devices in various examples may include a computer readable storage medium or multiple computer readable storage media. Data storage devices may be configured to store larger amounts of information than memory . Data storage devices may further be configured for long term storage of information. In various examples data storage devices include non volatile storage elements. Examples of such non volatile storage elements include magnetic hard discs optical discs floppy discs flash memories or forms of electrically programmable memories EPROM or electrically erasable and programmable EEPROM memories. In other examples memory may also be configured for long term data storage and any of a variety of technologies may blur the lines between memory and data storage and between volatile and non volatile. Memory and data storage devices may also include any of various caches buffers and other temporary memories that may be incorporated at any of various levels of a processing architecture and with various latency and capacity profiles including a dedicated cache exclusive to a processing core or processing chip.

Computing device B in various examples may also include a network interface . Computing device B in one example utilizes network interface to communicate with external devices such as server device via one or more networks which may include one or more wireless networks. Network interface may be or include a network interface card such as an Ethernet card an optical transceiver a radio frequency transceiver or any other type of component that is configured to send and receive information. Other examples of such network interfaces may include Bluetooth G and WiFi radios configured for mobile computing devices as well as USB. In various examples computing device B may use network interface to communicate wirelessly with an external device such as server device of or other networked computing device such as during a video communication session .

Computing device B in various examples may also include one or more input and or output devices such as display screen B which may be configured to display client GUI . Display screen B may include a liquid crystal display LCD display screen or display screen that uses another type of graphical output technology. Display screen B is also a touchscreen that comprises an electrically capacitive layer sensitive to the presence of touch and configured to translate the positions of touch inputs and the motions of touch inputs as they change position over time into signals to provide to a driver for the touchscreen or other feature for receiving the information on the touch inputs in the example of computing device B.

Computing device B may also include or be configured to connect with any of a variety of other input and or output devices such as physical buttons a physical keyboard a mouse a touchpad a trackball a voice user interface system an accelerometer a vibration component a sound card a video graphics adapter card or any other type of device for detecting and or interpreting inputs from a user or for converting a signal into a form of graphical audio tactile or other form of user output that can be sensed by a user.

Computing device B in various examples may include one or more power sources which may be rechargeable and provide power to computing device B. Power source in various examples may be a lithium ion battery a nickel cadmium battery a nickel metal hydride battery or other suitable power source.

In various examples all of or portions of communication application and or video communication module may be a part of or native to operating system libraries and or runtime . In various examples communication application may receive input through network interface of computing device B. Computing device B may for example receive audio streams and video streams through network interface from a network connected server device such as server device shown in .

Client GUI B of may be generated by video communication module executing in communication application on client device . Communication application may be a social networking application an email application a dedicated video communication application a web browser application a web feed reader application for example. In various examples communication application may be implemented as a version of a client side mobile application of the Google Gmail iGoogle Orkut or other applications provided by Google Inc. and configured for any of a variety of different mobile device operating systems or mobile device manufacturers or models. Communication application may exchange data and instructions back and forth with a web application running on a remote server such as server device of . Video communication module may include one or more objects methods classes libraries subroutines applications or any other portions of software for implementing features of the client side video conferencing user interface such as client GUI B.

As shown in client GUI B includes multimedia content B source video feed B participant panel B and control panel B. As depicted in multimedia content B is displaying a video feed for one of the participants in the video communication session and participant panel B is displaying video feeds for the other participants in the video communication session. As discussed herein multimedia content B may also display any kind of multimedia content including video documents images animations or any other visual output. In some examples multimedia content B and participant panel B may be accompanied by one or more audio feeds other audio output.

In some examples client GUI B includes participant panel B. Participant panel B may include one or more video feeds or other representations for the other participants in the video communication session e.g. users associated with other client computing devices coupled to a video communication session . For example participant panel B may include video feeds encoded by video streams from video input devices of computing devices A and C F of while computing devices A and C F are coupled to video communication session hosted by server device as shown in . As discussed herein smart mute module running on server may configure video communication module on server device to control whether or when audio feeds are provided together with any one or more of the video feeds being displayed in multimedia content B and participant panel B in client GUI B on computing device B. The audio feeds may be encoded by audio streams based on audio data received via audio input devices on each of the other computing devices A and C F with the audio streams received by video communication module running on server device .

The video feeds in multimedia content B and participant panel B in client GUI B and accompanying audio feeds may include representations of visual expressions and actions and audible sounds of users A F using computing devices A F coupled to video communication session . For instance camera B of computing device B may generate visual data encoded in a video stream B that conveys the visual appearance and expressions of user B. Computing device B may send the video data as a video stream B to server device which may then distribute the video stream to the other computing devices A and C F participating in the video communication session . Computing device B may also render the video feed encoded in video stream B within client GUI B as source video feed B. In this way user B may see his own visual appearance and expressions in source video feed B as they may also appear in video feeds in multimedia content A C F or participant panels A etc. participant panels not depicted for computing devices C F in on other computing devices A and C F participating in video communication session .

In various examples video communication module on server device may also receive an audio stream B that encodes an audio feed of audio input received by computing device B and that may include user B s conversation or other audio expressions while user B is viewing multimedia content B. For example microphone B of computing device B may generate audio stream B of data representing audible sounds from user B or from the ambient environment around user B. Computing device B may send audio stream B to server device . In some examples computing device B may also include audio processing capability for filtering out at least some ambient environmental sounds as opposed to spoken word input from user B before sending audio stream B to server device where audio stream B may be received by video communication module .

Smart mute module may then evaluate one or more properties of audio stream B potentially together with one or more other criteria and indicate or communicate to video communication module if smart mute module selects audio stream B to mute i.e. to refrain from distributing in the video communication session. Video communication module may then distribute audio stream B in the video communication session if smart mute module does not indicate that it has selected audio stream B to mute while video communication module may refrain from distributing audio stream B in the video communication session if smart mute module does indicate that it has selected audio stream B to mute.

This particular arrangement is one example and in other examples smart mute module may affirmatively indicate to video communication module for each individual audio stream whether it is selected to mute or to distribute or smart mute module may indicate to video communication module only those audio streams that it has selected to distribute. Video communication module may use a default of distributing all audio streams in the video communication session unless it is notified by smart mute module that one or more audio streams are selected to mute or video communication module may use a default of refraining from distributing any of audio streams in the video communication session unless it is notified by smart mute module that one or more audio streams are selected to distribute or video communication module may not use a default of its own and follow whatever the most recent indications are from smart mute module of whether to mute or to distribute any one or more of audio streams .

When video communication module distributes any one or more of the audio streams in the video communication session server device may distribute those audio streams to any or all of computing devices A F that are participating in video communication session while it may refrain from distributing any given one of audio streams back to whichever one of computing devices A F from which it originated. For example as video communication module receives audio stream B from computing device B if smart mute module does not select audio stream B to refrain from distributing in video communication session server device may distribute audio stream B to the rest of the computing devices A and C F that are participating in the video communication session . If smart module has not selected any of audio streams to mute server device may distribute each of the audio streams A F to each of the other computing devices A F that are participating in the video communication session other than the computing device from which each audio stream originated. In some examples server device may also distribute an audio stream back to its source computing device from which it originated. Any given one of computing devices A F may output audio feeds from all the audio streams it is receiving in the video communication session . For example computing device B may output audio feeds from all the audio streams it is receiving in the video communication session via speakers B.

In some examples users may select a video feed to display as multimedia content B. For example user B using computing device B may select one of one or more video feeds displayed in participant panel B to display as multimedia content B. Participant panel B may at one point in time show video feeds from all five of the other computing devices A and C F participating in video communication session and user B may select the video feed from computing device A for enlarged display in multimedia content B as is shown in . The video feed from computing device A is based on video stream A as received and distributed by server device and that outputs video data and audio data of user A. In one example multimedia content B may initially show the video feed from the user s own computing device B and then move the display of the video feed from the user s own computing device B to source video feed B in the corner of client GUI B as shown in once the user selects one of the other video feeds to display in multimedia content B. Client GUI B may also manipulate the content of the participant panel B as the state of the video communication session changes such as by adding and removing video feeds as other participants join or leave video communication session or changing the positions or sizes with which the video feeds are displayed for example.

As seen in client GUI B may also include control panel B. Control panel B may include one or more control buttons that enable user B to control various functions of video communication module and or computing device B. For example control panel may include control buttons and as shown in . In this example a user may select control button to exit the video communication session control button enables a user to control the settings for video communication session control button enables a user to manually mute the audio input from the user s computing device B and refrain from sending an audio stream B to server device control button enables a user to manually block the video input from the user s computing device B and refrain from sending a video stream B to server device and control button enables a user to select additional multimedia content to access and contemporaneously display in the video communication session .

Control button for controlling the settings for video communication session may enable a user to select from among options for who may be invited to video communication session what permissions other participants in video communication session may have what video feeds or other content is displayed in multimedia content B or for adjusting security settings for example. Control button for controlling the settings for video communication session may enable a user to select a smart mute feature of video communication module . By controlling the settings in a menu accessed via control button the user may turn the smart mute feature off or on and control whether the smart mute module running on server device is activated and performs smart mute functions for the video communication session . In various examples the capability of opting whether or not to engage the smart mute function may be reserved for an initiator of the video communication session a user with administrative permissions or other class of user other than general participants in video communication session .

The additional multimedia content accessed with control button may be a document for a document application for example that a user may share with the other participants of the video communication session and have it displayed in the client GUIs of the other participants computing devices A and C F. This may be a document in a presentation application in a word processing application in a spreadsheet application in a text editor application in an integrated development environment IDE application in a scientific publishing application or any other kind of application. The document application may be document module running on server device as shown in or it may be running locally on the user s computing device B in various examples. The user of computing device B or other participants in the video communication session may enter inputs for manipulating the document such as by moving between slides in a presentation application document or scrolling through a word processing application or a text editor application for example.

Control button may also enable the user to access any of a variety of other types of additional media such as a video file an image file an audio file a website a user interface for a separate web application or locally hosted application a user interface for a database or other data store a game or any other type of content or application. In whatever case and wherever the additional multimedia content is filed the user may be able to share the additional multimedia content with the other users in the video communication session .

While certain features are displayed in the examples of client GUI B as depicted in and as described above other examples a client GUI for a video communication application of the present disclosure may include more fewer or other variations of features than the examples discussed above either in accordance with user selected options by default or by implementation. For example in another option that a user may select the multimedia content B may be expanded to a full screen view such that source video feed B participant panel B and control panel B are all removed from the material displayed in client GUI B and multimedia content B is expanded to fill the entire real estate of display screen B or of client GUI B. In another example a user may select an option in which the multimedia content B is expanded to a full screen view occupying the entire real estate of display screen B or of client GUI B except for a relatively small region in one corner or off to one side in which source video feed B is still displayed such as how source video feed B is displayed in so that the user still retains a view of his own video feed while the rest of the client GUI B is filled with the view of multimedia content B for example.

In process a server device may execute one or more video communication processes such as video communication module which receive audio streams A F and video streams A F from a plurality of computing devices A F participating in a video communication session associated with the one or more video communication processes . Video communication module may evaluate one or more properties of the audio streams A F such as the volume of their audio signals or audio signal characteristics that correspond to either clearly articulated human speech or background noise in various illustrative embodiments and may evaluate additional information together with the properties of the audio streams A F such as the video streams A F user role data e.g. associated with user roles data store or document application input e.g. associated with document module in various illustrative embodiments. Video communication module may select a first group of the audio streams A F to refrain from distributing in the video communication session based at least in part on the one or more properties of the audio streams and potentially also based at least in part on any additional data that video communication module evaluates. Video communication module may distribute a second group of the audio streams A F in the video communication session while refraining from distributing the first group of audio streams in the video communication session .

Various techniques described herein may be implemented in software that may be written in any of a variety of languages making use of any of a variety of toolsets frameworks APIs programming environments virtual machines libraries and other computing resources as indicated above. For example software code may be written in Java C Objective C C Go Python Ruby Scala Clojure assembly language machine code or any other language. As one specific illustrative example aspects of the disclosure discussed above may be implemented in a software module written in Java that is executable on virtual machine of which may be the Dalvik virtual machine for example.

In one example the video conferencing web application may be written in Java but be configured to provide content in JavaScript in the users browsers on the client computing devices. For example the web application may use Java servlets and may include functionality to optimize JavaScript to dynamically generate HTML in Java and JavaScript and to access JavaScript libraries for supporting DOM AJAX and JSON functions across different types of client computing devices and browsers. In another example the web application may use server side JavaScript and may be configured for providing JavaScript content to the browsers and for compiling server side JavaScript to machine code for accelerating performance on the server for example. In other examples all or portions of the web application may also be written in Python Ruby Clojure or any other programming language. In other examples the video conferencing application comprising the smart mute module may run directly on one or more computing devices that are involved in the client facing video conferencing interface.

The browser may use a video conferencing API plug in and or a plug in for configuring a communications protocol and or associated libraries for video conferencing. In one example the video conferencing web application uses an Extensible Messaging and Presence Protocol XMPP interface and the browsers on the client computing devices use a communications plug in configured for using XMPP with libraries for operating a video conferencing interface over RTP and or RTMP. For example the communications plug in may be configured with the libjingle library to implement the Jingle protocol for video conferencing. In another example the web application may use the SIP protocol. The web application may be configured for suitable video and audio standards such as the H.264 standard for video processing and the G.711 standard for audio processing for example. Any other suitable technologies or standards for web servers browsers or applications configured for video conferencing video processing and audio processing may also be used in various examples.

The smart mute module and the video communication module may both be incorporated in a web application. The smart mute module may be configured for asynchronous input output with the video communication module and be configured to monitor audio feeds continuously and make rapid decisions when to send an output for muting or unmuting any of the audio feeds.

In other examples the smart mute module may be a separate application or part of a separate application and communicate with a video conferencing web application or a client side video conferencing application or plug in or a browser or other program otherwise configured for video conferencing. Different aspects of evaluating properties of the audio streams A F or other data may be divided among different layers of software between server device and computing devices A F in various embodiments. For example the video communication module running on one of computing devices A F may include an asynchronous event notification API that communicates a notification to video communication module running on server device when the video communication module running on one of computing devices A F detects a relevant user input to control panel A F a relevant change in the audio stream A F or video stream A F or a relevant update in user role data for the user A F of the particular computing device A F.

Aspects of the disclosure may be equally applicable and implemented in any browser or operating system and using any other APIs frameworks or toolsets. Aspects described herein for transmission decoding and rendering of data for video output or video content which may be considered interchangeably herein with media output or media content that also includes audio output or audio content may make use of any protocol standard format codec compression format HTML element or other technique or scheme for encoding processing decoding rendering or displaying an audio output or a video output.

Various techniques described herein may be implemented in hardware software firmware or any combination thereof. Various features described as modules units or components may be implemented together in an integrated logic device or separately as discrete but interoperable logic devices or other hardware devices. In some cases various features of electronic circuitry may be implemented as one or more integrated circuit devices such as an integrated circuit chip or chipset.

If implemented in hardware this disclosure may be directed to an apparatus such as a processor or an integrated circuit device such as an integrated circuit chip or chipset. Alternatively or additionally if implemented in software or firmware the techniques may be realized at least in part by a computer readable data storage medium comprising instructions that when executed cause a processor to perform one or more of the methods described above. For example the computer readable data storage medium may store such instructions for execution by a processor.

A computer readable medium may form part of a computer program product which may include packaging materials. A computer readable medium may comprise a computer data storage medium such as random access memory RAM read only memory ROM non volatile random access memory NVRAM electrically erasable programmable read only memory EEPROM flash memory magnetic or optical data storage media and the like. In various examples an article of manufacture may comprise one or more computer readable storage media.

In various examples the data storage devices and or memory may comprise computer readable storage media that may comprise non transitory media. The term non transitory may indicate that the storage medium is not embodied in a carrier wave or a propagated signal. In certain examples a non transitory storage medium may store data that can over time change e.g. in RAM or cache . Machine readable code may be stored on the data storage devices and or memory and may include executable instructions that are executable by at least one processor. Machine readable code and executable instructions may refer to any form of software code including machine code assembly instructions or assembly language bytecode software code in C or software code written in any higher level programming language that may be compiled or interpreted into executable instructions that may be executable by at least one processor including software code written in languages that treat code as data to be processed or that enable code to manipulate or generate code.

The code or instructions may be software and or firmware executed by processing circuitry including one or more processors such as one or more digital signal processors DSPs general purpose microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs or other equivalent integrated or discrete logic circuitry. Accordingly the term processor as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition in some aspects functionality described in this disclosure may be provided within software modules or hardware modules.

The various embodiments described above and depicted in as well as additional embodiments are within the scope of the following claims.

