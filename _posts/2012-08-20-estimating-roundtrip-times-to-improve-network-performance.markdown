---

title: Estimating round-trip times to improve network performance
abstract: Disclosed are various embodiments for estimating round-trip times to improve performance of networks. Multiple connections are opened to a network device. Round-trip times associated with sending packets to the network device via the connections are measured. Another connection to the same or a different network device is opened. A round-trip-time estimate for the other connection is initialized based at least in part on the measured round-trip times for the multiple connections, and in some embodiments, network device proximity data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09013998&OS=09013998&RS=09013998
owner: Amazon Technologies, Inc.
number: 09013998
owner_city: Seattle
owner_country: US
publication_date: 20120820
---
Internet protocol IP is a best effort network protocol. Packets which are sent by way of IP are not guaranteed to reach their destination. For example packets may be dropped by overloaded IP routers. Furthermore IP does not guarantee any particular delivery sequence for packets. If packets do ultimately arrive they may be out of order. However protocols such as transmission control protocol TCP may view out of order packets as a sign of network congestion. As a result notwithstanding the lack of a guarantee for in order delivery with IP it is desirable to maintain in order delivery of packets.

The present disclosure relates to avoiding flow collisions in networks that employ flow based hashing. Networking devices such as routers switches etc. may be configured to provide in order delivery when possible. To this end flow based hashing may be employed in a networking device to maintain in order delivery of packets. Flow based hashing functions are used to forward network packets belonging to the same flow through the same route or egress port. By forwarding packets of the same flow through the same route the probability of out of order delivery may be reduced.

With a layer 4 protocol such as TCP user datagram protocol UDP etc. a flow may be identified as a n tuple containing network packet header fields such as a network protocol a source port a source network address a destination port and or a destination network address. In one scenario packets having these fields in common are often said to belong to the same flow. In other scenarios other fields such as virtual local area network VLAN tags quality of service tags etc. may be used to determine whether packets belong to a flow. A hash may be generated from one or more of these fields in order to assign the packets to one of multiple egress ports or routes. Although flow based hashing may function well to prevent out of order delivery flow based hashing may also adversely impact network performance. By persistently forwarding flows through the same route a scenario exists in which flows are assigned to overburdened routes while other routes go underutilized. Congestion and dropped packets may result due to these flow collisions even when there is little overall network contention. The use of overlay networks may worsen the problem as multiple overlay flows may be aggregated into a fewer number of substrate network flows to which flow hashing is applied. For example several disparate TCP or UDP flows initiated by different virtual machines or applications in a virtualized server environment may overlay a single internet protocol IP substrate flow between the service hosting domains of two physical servers.

Various embodiments of the present disclosure introduce solutions to avoid flow collisions when flow based hashing is employed. For example one or more port numbers that define the flow may be changed to provide a different hashing result. Flow collision avoidance may also be provided for overlay networks that include a port field or other field used for hashing in the overlay header. Port numbers may be changed randomly in response to interruptions of flows in response to congestion and or in other circumstances.

In one embodiment network wide congestion may be detected via network health monitoring and incorporated in flow collision avoidance measures for example to minimize unnecessary flow avoidance churn or otherwise to respond more efficiently to incipient overall congestion or the like. In another embodiment flow congestion may be detected in an overlay endpoint handling multiple flows. In yet another embodiment cross connection round trip times may be employed to improve round trip time estimation and network performance. A spatial correlation of round trip times may also be employed to improve round trip time estimation and network performance. In the following discussion a general description of the system and its components is provided followed by a discussion of the operation of the same.

With reference to shown is a networked environment according to various embodiments. The networked environment includes for example a plurality of source network devices . . . N a plurality of destination network devices . . . N networks and and a router . The source network devices are in data communication with the router through ingress ports by way of the network . The destination network devices are in data communication with the router through egress ports by way of the network . The networks and each may correspond to one or more networks such as for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks. In various embodiments the networks and may be internet protocol IP based networks or other networks where for example flow based hashing may be employed.

The source network devices and the destination network devices may correspond to any device coupled to a network which is capable of sending and or receiving routable network packets with header control fields amenable to flow hashing. To this end the source network devices and the destination network devices may open connections or sockets to other network devices reachable by way of the networks . Such connections may employ UDP TCP or other protocols. Although described as source or destination devices for purposes of discussion it is understood that the source network devices and the destination network devices may be interchangeable may initiate connections in either direction and such communication may be bidirectional via the networks 

Each of the source network devices and the destination network devices may correspond to computing devices such as server computers network switches desktop computers laptop computers personal digital assistants cellular telephones smartphones set top boxes music players web pads tablet computer systems game consoles electronic book readers or other devices with like capability. Each of the source network devices and the destination network devices may have one or more network interfaces coupled to the networks or . Further each of the source network devices and the destination network devices may include a network protocol stack capable of processing data received at various layers. Each of the source network devices and the destination network devices may include one or more network hosts where each network host is associated with a different network address.

The router corresponds to any router switch bridge etc. capable of routing packets or datagrams to and from the network and the network . Although the router is shown as being coupled to two logical networks in this example the router may be coupled to any number of logical networks as desired. The router may include a number of ports which have been denoted here purely for purposes of discussion as ingress ports and egress ports . Because the communication between the source network devices and the destination network devices may be bidirectional the ingress ports and egress ports may be interchangeable. In this non limiting example four ingress ports are shown denoted a b c and d and four egress ports are shown denoted e f g and h. Any number of ports may be employed in various embodiments although the concepts herein primarily apply to systems which are logically routing to at least two egress ports.

The router may include flow hashing logic that is configured to perform flow based hashing wherein flows are assigned to particular egress ports through a hashing approach. In one embodiment the flow hashing logic may include a hashing function and a hash seed as parameters which control the flow based hashing. Although one router is shown for purposes of illustration and discussion it is understood that the networks and may include any number of routers which may implement flow hashing logic . Further in some cases router functionality may be implemented within network interface controllers NICs or virtual NICs of the source network devices the destination network devices and or other network devices within the networks . Such NICs and virtual NICs may also implement flow hashing logic . It is noted a particular flow may be processed by multiple instances of flow hashing logic within the networked environment .

Various flows of packets which may be unidirectional or bidirectional are sent from the source network devices to the destination network devices via the network the router and the network . The flows may correspond to TCP connections UDP connections and or other types of connections where packet header control fields are amenable to identifying a common flow. Each flow includes flow identification information comprising for example a protocol name a source address a source port a destination address a destination port and or other data. In some embodiments flows may be identified by VLAN tags and or any other arbitrary data in the packet format. The protocol name identifies the type of flow e.g. UDP TCP etc. .

The source address may correspond to an IP address e.g. 32 bits 64 bits etc. of a host on a source network device . The source port may identify a socket e.g. 16 bits etc. of a host at the source address . The destination address may correspond to an IP address e.g. 32 bits for IP version 4 128 bits for IP version 6 etc. of a host on a destination network device . The destination port may identify a socket e.g. 16 bits etc. of a host at the destination address .

Next a general description of the operation of the various components of the networked environment is provided. To begin a host at a source network device opens a connection e.g. TCP UDP etc. to a host at a destination network device . Upon establishment of the connection the host at the source network device sends a flow of packets to the destination network device . The packets in the flow are routed through the network through the router and through the network to the host at the destination network device .

The packets in the flow may be received by the router at one or more of the ingress ports . The router then determines an appropriate route for the packets from a routing table using a routing protocol. In this context a route corresponds to a particular egress port . Generally speaking the router may determine that one route exists multiple routes exist or that the packets are unroutable. If the packets are unroutable they may be dropped by the router . If the packets are routable by a single route the router may proceed to forward them to the egress port corresponding to the single route.

However if the packets are routable by multiple routes the router may be configured to consistently select one route from the multiple routes to avoid out of order arrival by the packets in the flow . To this end the flow hashing logic employs the hashing function as configured by the hash seed to hash at least a portion of the flow identification information to select one of the multiple routes. For example suppose that the flow is routable through any of egress ports e f or g. The flow hashing logic may apply the hashing function to one or more fields of the flow identification information to select port f. Port f continues to be selected for all packets in the flow having the flow identification information to avoid creating out of order situations.

Although the flow hashing logic may be configured to randomly assign flows to egress ports in various circumstances network congestion may result. A route through port f may be overburdened and lack network capacity while a route through port e may be underutilized. Flow collisions as used herein refers to flows which are assigned to the same egress port and which result in network congestion. The network congestion may be unnecessary because without flow based hashing the packets may be distributed among the routes. Notwithstanding these issues it may be desirable not to disable flow based hashing due to the out of order packet problem.

To better this situation and relieve the unnecessary network congestion flows may be reassigned to other routes. A first approach may involve changing the hashing function or the hash seed to produce different assignments of flows to egress ports . However the router may correspond to commodity hardware and may not support such a change or otherwise changing the hashing function for the entire router may cause several flows through the router to be disrupted.

An alternative approach may involve perturbing or changing the flow identification information for the particular flow so that the existing flow hashing logic will produce a different assignment result. In such an approach it may be desirable to change the source port and or the destination port rather than the protocol name the source address or the destination address which could substantially affect routing or processing.

The perturbation of the flow identification information may be performed according to a randomized process including a pseudo randomized process. The perturbation may instead be performed at regular intervals if desired. By switching the flow from one route assignment to another the perturbation may cause a temporary or singular out of order packet situation that may impact performance. Thus it may be desirable not to perform the perturbation too frequently or beyond a certain interval.

Alternatively the perturbation of the flow identification information may be performed in response to a sign of network congestion such as a dropped packet a delayed packet etc. Congestion detection may be performed through acknowledgements of received packets from the destination network devices indications of lost missing or delayed packets from the destination network devices and so on. With various protocol stacks a packet which is delayed beyond a certain time may be regarded as lost even if it is received later.

In some cases the perturbation of the flow identification information may be scheduled relative to a temporary interruption in the flow . A temporary interruption in the flow makes it more likely that the packets already in transit within the congestion window of the host on the destination network device will be received before packets of the perturbed flow that are routed differently. Consequently out of order packets may be avoided.

In various embodiments the perturbation may be initiated by the source network device the destination network device the router or any other network device that processes the flow . It may be preferable to situate the initiation logic in a network device that is capable of detecting congestion affecting the flow . The network device which initiates the perturbation is further configured to update a state associated with the flow . Further the network device which initiates the perturbation may be configured to notify either the source endpoint or the destination endpoint for the flow. For example the source network device and the destination network device may each update the socket associated with the flow to use the new source port and or destination port . In another embodiment a network device may instead request a change to the flow hashing logic in the router to effect a perturbation.

Turning now to shown is another networked environment which implements an overlay network according to various embodiments. The networked environment includes for example a plurality of source endpoints . . . N a plurality of destination endpoints . . . N overlay network endpoints and substrate networks and and the router with ingress ports and egress ports . In contrast to the networked environment the networked environment implements an overlay network on top of the substrate networks and as will be described.

The source endpoints are in data communication with the overlay network endpoint . The overlay network endpoint maps or encapsulates the data from the source endpoints for transit on the substrate network . The mapped or encapsulated data is received by the router through ingress ports . The destination endpoints are in data communication with the overlay network endpoint . The overlay network endpoint unmaps or de encapsulates the data received via the substrate network from the router through egress ports . The substrate networks and each may correspond to one or more networks such as for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks. In various embodiments the substrate networks and may be internet protocol IP based networks or other networks where for example flow based hashing may be employed.

The source endpoints and the destination endpoints may correspond to any device coupled to a network which is capable of sending and or receiving routable network packets with header control fields amenable to flow hashing as known in the art. For example the source endpoints and the destination endpoints may correspond to the source network devices and the destination network devices respectively. The source endpoints and the destination endpoints may open connections or sockets to other network devices reachable by way of the overlay network. Such connections may employ UDP TCP or other protocols. Although described as source or destination endpoints for purposes of discussion it is understood that the source endpoints and the destination endpoints may be interchangeable may initiate connections in either direction and such communication may be bidirectional via the overlay network.

Each of the source endpoints and the destination endpoints may correspond to computing devices such as server computers network switches desktop computers laptop computers personal digital assistants cellular telephones smartphones set top boxes music players web pads tablet computer systems game consoles electronic book readers or other devices with like capability. Each of the source endpoints and the destination endpoints may have one or more network interfaces in data communication with the overlay network endpoint or . In some cases one or more source endpoints may be executed in the same network device as the overlay network endpoint and one or more destination endpoints may be executed in the same network device as the overlay network endpoint . Further each of the source endpoints and the destination endpoints may include a network protocol stack capable of processing data received at various layers. Each of the source endpoints and the destination endpoints may include one or more network hosts where each network host is associated with a different network address on the overlay network.

The overlay network endpoints and are configured to map and unmap or encapsulate or de encapsulate as the case may be overlay network data to be sent via the substrate networks and and the router . The overlay network endpoints and may employ for example a layer 4 overlay protocol a layer 3 overlay protocol or other protocols. Although described as overlay network endpoints and as an alternative the overlay network endpoints and may be said to correspond to substrate network endpoints. The router may correspond to the router as in which may include flow hashing logic that is be configured to perform flow based hashing wherein flows are assigned to particular egress ports through a hashing approach.

Various flows of packets which may be unidirectional or bidirectional are sent from the source endpoints to the destination endpoints via the overlay network implemented by the networked environment . The flows may correspond to TCP connections UDP connections and or other types of connections where packet header control fields are amenable to identifying a common flow . Each flow may include flow identification information comprising for example a protocol name a source address a source port a destination address a destination port and or other data.

The flows are mapped by the overlay network endpoint and to substrate flows . This mapping may involve encapsulation by adding additional packet framing in some embodiments. The substrate flows include substrate flow identification information . The substrate flow identification information may include for example a substrate source address and a substrate source port associated with the overlay network endpoint a substrate destination address and a substrate destination port associated with the overlay network endpoint and or other data.

Next a general description of the operation of the various components of the networked environment is provided. To begin a source endpoint opens a connection e.g. TCP UDP etc. to a destination endpoint via the overlay network. Upon establishment of the connection the source endpoint sends a flow of packets to the destination endpoint . The packets in the flow are routed to the overlay network endpoint which maps them to a substrate flow for transit through the substrate network the router and the substrate network . The packets of the substrate flow arrive at the overlay network endpoint which unmaps the substrate flow to the flow and routes the packets to the appropriate destination endpoint via the overlay network.

The packets in the substrate flow may be received by the router at one or more of the ingress ports . The router then determines an appropriate route for the packets from a routing table using a routing protocol. In this context a route corresponds to a particular egress port . Generally speaking the router may determine that one route exists multiple routes exist or that the packets are unroutable. If the packets are unroutable they may be dropped by the router . If the packets are routable by a single route the router may proceed to forward them to the egress port corresponding to the single route.

However if the packets are routable by multiple routes the router may be configured to select one route from the multiple routes to avoid out of order arrival by the packets in the substrate flow . To this end the flow hashing logic employs the hashing function as configured by the hash seed to hash at least a portion of the substrate flow identification information to select one of the multiple routes. For example suppose that the substrate flow is routable through any of egress ports e f or g. The flow hashing logic may apply the hashing function to one or more fields of the substrate flow identification information to select port f. Port f continues to be selected for all packets in the substrate flow having the substrate flow identification information to avoid creating out of order situations.

In various embodiments the overlay network endpoint may aggregate multiple different flows into substrate flows having the same source and destination addresses. To accommodate flow based hashing by the router and to avoid assigning the different flows to the same egress port where multiple egress ports are potential routes the substrate flow identification information may include one or more identifiers e.g. substrate source port substrate destination port etc. which are generated from at least a portion of the flow identification information for the mapped flow . To this end the overlay network endpoint may include flow hashing logic to generate the substrate source and or destination ports from the flow identification information . In one non limiting example the flow hashing logic of the overlay network endpoint may hash the 16 bit source port to fit into an 8 bit substrate source port. The flow hashing logic of the router may then assign the substrate flow to a route based at least in part on the substrate source port and or other information in the substrate flow identification information .

The problems associated with flow collisions may be apparent in overlay networks as well. Similar solutions to those used in may be used with respect to overlay networks. A perturbation to the substrate flow identification information may be effected by changing a hash seed or hashing function in the flow hashing logic of the router . In various embodiments such a change may be initiated by the router the overlay network endpoints or the source endpoints the destination endpoints and or other network devices. Such a change may be initiated randomly at an interval in response to detecting congestion or at other times. The change may be scheduled relative to a temporary interruption in the substrate flow to reduce out of order packets.

Alternatively a perturbation to the substrate flow identification information may be effected by changing a hash seed or hashing function in the flow hashing logic of the overlay network endpoint . For example where the substrate source port is generated by the hashing function in the overlay network endpoint a change to the hashing function may result in a different substrate source port for the substrate flow . In various embodiments such a change may be initiated by the overlay network endpoints or the source endpoints the destination endpoints and or other network devices. Such a change may be initiated randomly at an interval in response to detecting congestion or at other times. The change may be scheduled relative to a temporary interruption in the flow to reduce out of order packets.

A first alternative approach may involve perturbing or changing the flow identification information for the flow so that the existing flow hashing logic in the overlay network endpoint will produce different substrate flow identification information . For example changing the flow identification information may produce different source or destination port information in the substrate flow identification . As a byproduct this can perturb the substrate routing as long as ports are accounted for in the flow hashing logic of router . A second alternative approach may involve perturbing or changing the substrate flow identification information directly. The perturbation of the flow identification information and or the substrate flow identification information may be performed according to a randomized process including a pseudo randomized process. The perturbation may instead be performed at regular intervals if desired. By switching the flow and or the substrate flow from one route assignment to another the perturbation may cause a temporary or singular out of order packet situation that may impact performance. Thus it may be desirable not to perform the perturbation too frequently or beyond a certain interval.

Alternatively the perturbation of the flow identification information and or the substrate flow identification information may be performed in response to indications of network congestion such as a dropped packet a delayed packet etc. Congestion detection may be performed through acknowledgements of received packets from the destination endpoints and or the overlay network endpoint indications of lost missing or delayed packets from the destination endpoints and or the overlay network endpoint and so on. With various protocol stacks a packet which is delayed beyond a certain time may be regarded as lost even if it is received later.

The perturbation of the flow identification information may be scheduled relative to a temporary interruption in the flow and or the perturbation of the substrate flow identification information may be scheduled relative to a temporary interruption in the flow and or the substrate flow . A temporary interruption in the flow or substrate flow makes it more likely that the packets already in transit within the congestion window of overlay network endpoint or the destination endpoint will be received before packets of the perturbed substrate flow or the perturbed flow that are routed differently. Consequently out of order packets may be minimized.

In various embodiments the perturbation may be initiated by the source network device the destination network device the router or any other network device that processes the flow . It may be preferable to situate the initiation logic in a network device that is capable of detecting congestion affecting the flow . The network device which initiates the perturbation may be further configured to update a state associated with the flow . Further the network device which initiates the perturbation may be configured to notify either the source endpoint or the destination endpoint for the flow. For example the source network device and the destination network device may each update the socket associated with the flow to use the new source port and or destination port . In another embodiment a network device may instead request a change to the flow hashing logic in the router to effect a perturbation.

Such a perturbation may be initiated in various embodiments by the router the overlay network endpoints or the source endpoints the destination endpoints and or other network devices. Such a change may be initiated randomly at an interval in response to detecting congestion or at other times. The change may be scheduled relative to a temporary interruption in the substrate flow to reduce out of order packets.

Continuing now to shown is a networked environment according to various embodiments. The networked environment includes one or more computing devices coupled to a network in the networked environment and or . The networked environment may be coupled to any number of routers . . . N switches bridges hubs etc. Likewise the networked environment may be coupled to any number of routers . . . NN switches bridges hubs etc.

The computing device may comprise for example a server computer or any other system providing computing capability. Alternatively a plurality of computing devices may be employed that are arranged for example in one or more server banks or computer banks or other arrangements. For example a plurality of computing devices together may comprise a cloud computing resource a grid computing resource and or any other distributed computing arrangement. Such computing devices may be located in a single installation or may be distributed among many different geographical locations. For purposes of convenience the computing device is referred to herein in the singular. Even though the computing device is referred to in the singular it is understood that a plurality of computing devices may be employed in the various arrangements as described above.

Various applications and or other functionality may be executed in the computing device according to various embodiments. Also various data is stored in a data store that is accessible to the computing device . The data store may be representative of a plurality of data stores as can be appreciated. The data stored in the data store for example is associated with the operation of the various applications and or functional entities described below.

The components executed on the computing device for example include a network monitoring service and other applications services processes systems engines or functionality not discussed in detail herein. The network monitoring service is executed to monitor various network devices in the networked environment and or including for example the router and or other devices. The network monitoring service may employ simple network management protocol SNMP and or other protocols and technologies that enable monitoring the status health and or other information regarding network devices.

The data stored in the data store includes for example network health data and potentially other data. The network health data describes the current health of various network devices employed in the networked environments and or . The network health data may include network congestion information relative to various network device employed in the networked environments and or . The network health data may be generated in response to actions of the network monitoring service and or other services or network devices.

Next a general description of the operation of the various components of the networked environment is provided. To begin the network monitoring service monitors various network devices in the networked environments and or thereby generating the network health data stored in the data store . To this end the network monitoring service may obtain network health reports from the routers via SNMP polling or other protocols and or technologies in order to generate the network health data . In another embodiment the routers may send health data to the network monitoring service directly through a variety of application programming interfaces or other protocols. In other embodiments a combination of polling from the network monitoring service and posting to the network monitoring service may be employed. The network health data may be used to assist in determining whether to perform the perturbations to flow identification information or substrate flow identification information described in connection with .

When the flow identification perturbations or hashing changes are performed in response to network congestion it may be desirable to have network congestion information from the network health data to determine for example whether the detected congestion affects multiple routes or merely affects a single route in the router . If the congestion is affecting multiple routes or is a network wide problem flow identification perturbations or hashing changes may be unlikely to assist the situation. The flow identification perturbations or hashing changes are designed to ameliorate situations where flow collisions have created suboptimal local route selection e.g. the flows are aggregated onto a single egress port causing congestion on that egress port while other egress ports are underutilized.

However the congestion may be network wide or affecting all of the potential egress ports . In such a case changing the flow identification or hashing mechanism will provide no benefit. Further such changes may result in out of order packets or other detrimental conditions. Accordingly the change initiators from the networked environment and or may be configured to initiate a change responsive to network congestion information in the network health data obtained from the network monitoring service . Specifically the change to the flow identification or hashing mechanism may be implemented when the congestion experienced by a flow or substrate flow is caused by local flow collisions. Conversely the change initiators may refrain from making such a change when the congestion experienced by a flow or substrate flow is not likely caused by local flow collisions and is instead caused overloading denial of service attacks equipment failure and or other reasons.

Although describes a network monitoring service that aggregates network health data it is understood the various endpoints and network devices in the networked environments and may maintain local network health information such as congestion information etc. In some embodiments a network device or endpoint may choose to perturb a flow or substrate flow on the basis of locally available congestion information rather than congestion information from a global network monitoring service .

Referring next to shown is a networked environment according to various embodiments. The networked environment includes a source endpoint and a plurality of destination endpoints . . . N by way of a network . Some of destination endpoints e.g. destination endpoints and may be situated in a proximate area . The source endpoint and the destination endpoints may correspond to separate network hosts provided in one or more network devices as described in connection with . The network may include for example the Internet intranets extranets wide area networks WANs overlay networks local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks. The source endpoint may include a network stack such as a TCP stack UDP stack etc. The network stack may maintain a plurality of RTT estimates .

The networked environment may also include a computing device in data communication with the source endpoint and or the destination endpoints by way of the network . The computing device may comprise for example a server computer or any other system providing computing capability. Alternatively a plurality of computing devices may be employed that are arranged for example in one or more server banks or computer banks or other arrangements. For example a plurality of computing devices together may comprise a cloud computing resource a grid computing resource and or any other distributed computing arrangement.

Such computing devices may be located in a single installation or may be distributed among many different geographical locations. For purposes of convenience the computing device is referred to herein in the singular. Even though the computing device is referred to in the singular it is understood that a plurality of computing devices may be employed in the various arrangements as described above. Although the computing device is described separately from the source endpoint and the destination endpoints it is understood that the source endpoint and or one or more of the destination endpoints may be provided by the computing device in some embodiments.

Various applications and or other functionality may be executed in the computing device according to various embodiments. Also various data is stored in a data store that is accessible to the computing device . The data store may be representative of a plurality of data stores as can be appreciated. The data stored in the data store for example is associated with the operation of the various applications and or functional entities described below.

The components executed on the computing device for example include a global data service and other applications services processes systems engines or functionality not discussed in detail herein. The global data service is executed to serve up globally applicable network data such as proximity data in response to requests for a measure of logical or physical proximity between two network hosts such as the destination endpoints . The data stored in the data store includes for example network host proximity data and potentially other data. The network host proximity data indicates the physical and or logical proximity between network hosts in the networked environment . The network host proximity data may be manually preconfigured or automatically generated by the global data service .

Next a general description of the operation of the various components of the networked environment is provided. To begin it is desirable to have an accurate estimate of round trip time for the use of TCP and or other protocols. Round trip time corresponds for the time it takes for a packet to be sent from a local host to a remote host plus the time it takes for an acknowledgement to be received from the second host. Round trip time is important for automatic repeat request ARQ protocols such as TCP because if no acknowledgement is received from the remote host within a timeout period a packet is considered lost and is resent.

If the round trip time estimate employed by the protocol stack is too short a packet that is received by the remote end may be considered lost merely because the acknowledgment is not received by the local end in time. Likewise if the round trip time estimate is too long the local end may be delayed in resending a packet that was not received by the remote end. In addition the round trip time estimate may affect the operation of congestion control parameters. For example a received packet that merely appears to be lost due to an incorrect round trip time estimate may incorrectly cause a congestion avoidance state to be entered. Although an estimate of round trip time may be learned empirically for a particular connection through sending of data and receiving acknowledgments various embodiments herein provide initial estimates of round trip time for connections. For example these initial estimates may be selected manually or inferred from design specifications of the networking devices and the topology of the network . That is each network device may introduce e.g. a 90percentile time delay and the route between two hosts may encompass a predictable number or set of network devices. These may be aggregated to predict an overall round trip maximum estimate.

Also a source endpoint may include automatic cache invalidation for the stored round trip time estimates to provide a time bound for the data. To this end the cache of stored round trip time estimates may be invalidated upon address reassignment. For example if logical addresses are used an address may be re provisioned and the new server using the address may be nowhere near the server to which the address was formerly assigned. Address reassignment is typically done through a centralized service such as dynamic host configuration protocol DHCP . Such a service could potentially notify the global data service of the address invalidations namely that a new address would be assigned and the stored round trip time estimates would need to be recalculated for routes involving that address. Once a round trip time estimate expires the source endpoint may retrieve a properly updated estimate from the global data service . Alternatively the source endpoint may periodically update the estimated round trip time at some reasonable interval e.g. 5 minutes or another interval or whenever a new socket is opened to an address.

In a first embodiment a source endpoint may open one or more connections to a particular destination endpoint by way of the network . Packets are sent and received via the connection and an estimate of the round trip time may be developed. The source endpoint may store the round trip time estimate in association with an identifier of the destination endpoint e.g. a network address etc. . When the source endpoint opens a subsequent connection to the particular destination endpoint the source endpoint may initialize the estimate of round trip time to the destination endpoint based at least in part upon the stored round trip time estimate associated with the destination endpoint .

In a second embodiment network host proximity data from a global data service is employed by the source endpoint to estimate round trip times based at least in part on network host proximity. For example the source endpoint may open one or more connections to the destination endpoint thereby developing an estimate of round trip times for the destination endpoint in accordance with the first embodiment. The destination endpoint may be proximate to the destination endpoint by being situated in a proximate area such as a data center a rack in a data center or other similar shared location.

One component of round trip time may depend on the length of the media through which two hosts are connected. Thus if two destination endpoints and are physically near one another the round trip time between the source endpoint and the destination endpoint may be a good approximation for the round trip time between the source endpoint and the destination endpoint

The approximation may also depend on the logical routing between the respective hosts. For example if two destination endpoints and are physically near one another but the connections between the source endpoint and each are routed substantially differently in the network the round trip time between the source endpoint and the destination endpoint might not be a good approximation for the round trip time between the source endpoint and the destination endpoint . Conversely if two destination endpoints and are not physically near one another but the connections between the source endpoint and each are routed similarly in the network the round trip time between the source endpoint and the destination endpoint might be a good approximation for the round trip time between the source endpoint and the destination endpoint

The global data service may automatically learn the logical proximities between network hosts through comparison of similar round trip times. For example a source endpoint might report round trip times for various destination endpoints to the global data service and proximity might be inferred. Alternatively the physical proximity between destination endpoints may be manually preconfigured for the global data service .

In the second embodiment when a source endpoint wishes to make a connection to a destination endpoint the source endpoint may communicate with the global data service to obtain network host proximity data indicating whether destination endpoint is physically or logically proximate to the destination endpoint . In some cases the network host proximity data may be cached or otherwise maintained by the source endpoint . For example the source endpoint may automatically infer proximity via similar observed round trip times.

If the source endpoint determines that the destination endpoint is proximate to the destination endpoint and if the source endpoint already has a round trip time estimate for the destination endpoint then the source endpoint may initialize a round trip time estimate for the destination endpoint from the estimate for the destination endpoint . This decision to use a similar estimate may be made according to a threshold for proximity. Alternatively the estimate for the destination endpoint may be determined more generally as a function of the proximity between the destination endpoints and and the round trip time estimate for the destination endpoint

In other embodiments the source endpoint may monitor detected round trip times for the destination endpoints in order to detect congestion caused by flow collisions. If the network host proximity data indicates that two destination endpoints and are near one another the measured round trip times to each should be the same or approximately so. If the measured round trip times differ the congestion causing the latency may be due to flow collisions which may suggest an opportunity to perturb one or more flows to avoid the congestion.

In such embodiments the round trip times may be ascertained via probing via internet control message protocol ICMP ping or another approach. For example a network device or endpoint may have a list of neighboring devices on a network and may periodically send pings to the neighboring devices in order to measure round trip times. In one scenario such probing may be scheduled for times of low network utilization. In another scenario such probing may occur irrespective of network utilization.

Referring next to shown is a flowchart that provides one example of the operation of a portion of the source network device according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the source network device as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the source network device according to one or more embodiments.

Beginning with box the source network device sends a flow of packets from a source endpoint to a destination endpoint at a destination network device . The sending may involve forwarding the flow of packets to an intermediate destination in a network e.g. a gateway. In box the source network device determines whether the flow identification information for the flow is to be perturbed. For example the source network device may be configured to perturb the flow identification information randomly at predefined intervals in response to detecting congestion etc. In some embodiments the source network device may be configured to request a change to flow hashing logic implemented in the router or other equipment in the network or network instead of changing the flow identification information directly. If the source network device determines not to perturb the flow identification information the source network device returns to box and continues sending the flow of packets.

If instead the source network device determines that the flow identification information for the flow is to be perturbed the source network device continues from box to box . In box the source network device determines whether a temporary interruption in the flow is detected. For example the perturbation may be performed relative to such a temporary interruption. In other embodiments however the perturbation may be performed irrespective to a temporary interruption.

If a temporary interruption is not detected the source network device may move to box and continue sending packets for the flow until such an interruption is detected. The source network device then returns to box . If instead a temporary interruption in the flow is detected the source network device moves from box to box .

In box the source network device notifies the destination endpoint of an impending perturbation. Alternatively the source network device may update some other type of state to effect the perturbation. In box the source network device obtains an acknowledgment from the destination endpoint . In box the source network device implements a change to the flow identification information for the flow . For example the source network device may change the source port the destination port and or other data employed in the flow identification information . In some embodiments the change to the flow identification information may be effected first by the destination network device . The change may be effected by implementing a change to an active connection associated with the flow that is maintained by a network stack. The source network device then returns to box and continues sending the flow of packets according to the perturbed flow identification information .

Referring next to shown is a flowchart that provides another example of the operation of a portion of the source network device according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the source network device as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the source network device according to one or more embodiments.

Beginning with box the source network device sends a flow of packets from a source endpoint to a destination endpoint at a destination network device . The sending may involve forwarding the flow of packets to an intermediate destination in a network e.g. a gateway. In box the source network device determines whether the flow identification information for the flow is to be perturbed. For example the source network device may be configured to perturb the flow identification information randomly at predefined intervals in response to detecting congestion etc. In some embodiments the source network device may be configured to request a change to flow hashing logic implemented in the router or other equipment in the network or network instead of changing the flow identification information directly. If the source network device determines not to perturb the flow identification information the source network device returns to box and continues sending the flow of packets.

If instead the source network device determines that the flow identification information for the flow is to be perturbed the source network device continues from box to box . In box the source network device determines whether a temporary interruption in the flow is detected. For example the perturbation may be performed relative to such a temporary interruption. In other embodiments however the perturbation may be performed irrespective to a temporary interruption.

If a temporary interruption is not detected the source network device may move to box and determine whether a limit has been reached for waiting for an interruption. If a limit has not been reached the source network device moves from box to box and continues sending packets for the flow until such an interruption is detected. The source network device then returns to box . If instead a temporary interruption in the flow is detected the source network device moves from box to box . If the limit has been reached the source network device moves from box to box as well.

In box the source network device effects a perturbation to the flow identification information . Unlike in the destination network device may already know of the impending perturbation without a handshake sequence via communication via an upper layer protocol a predetermined perturbation sequence and or other approaches. In some cases the destination network device may not be informed of the perturbation. Depending on the overlay protocol used certain identification information may be modified with the data still arriving transparently at the destination network device . The source network device then returns to box and continues sending the flow of packets according to the perturbed flow identification information .

Referring next to shown is a flowchart that provides still another example of the operation of a portion of the source network device according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the source network device as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the source network device according to one or more embodiments.

Beginning with box the source network device sends a flow of packets from a source endpoint to a destination endpoint at a destination network device . The sending may involve forwarding the flow of packets to an intermediate destination in a network e.g. a gateway. In box the source network device determines whether the flow identification information for the flow is to be perturbed. For example the source network device may be configured to perturb the flow identification information randomly at predefined intervals in response to detecting congestion etc. In some embodiments the source network device may be configured to request a change to flow hashing logic implemented in the router or other equipment in the network or network instead of changing the flow identification information directly. If the source network device determines not to perturb the flow identification information the source network device returns to box and continues sending the flow of packets.

If instead the source network device determines that the flow identification information for the flow is to be perturbed the source network device continues from box to box . In box the source network device effects a perturbation to the flow identification information . Unlike in the destination network device may already know of the impending perturbation without a handshake sequence via communication via an upper layer protocol a predetermined perturbation sequence and or other approaches. In some cases the destination network device may not be informed of the perturbation. Depending on the overlay protocol used certain identification information may be modified with the data still arriving transparently at the destination network device . The source network device then returns to box and continues sending the flow of packets according to the perturbed flow identification information .

Moving on to shown is a flowchart that provides one example of the operation of a portion of the overlay network endpoint according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the overlay network endpoint as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the overlay network endpoint according to one or more embodiments.

Beginning with box the overlay network endpoint obtains a packet in flow of packets sent via an overlay network from a source endpoint . In box the overlay network endpoint maps the packet from the flow into a substrate flow of packets. In box the overlay network endpoint determines whether to perturb the mapping. For example the overlay network endpoint may determine to perturb the substrate flow identification information randomly at predefined intervals in response to congestion in response to a request from the source endpoint or destination endpoint and or at other times.

If the overlay network endpoint decides to perturb the mapping the overlay network endpoint continues to box and effects a state change to perturb the mapping of the packet to a substrate flow . To this end the overlay network endpoint may change a hashing function or a hash seed employed in the flow hashing logic of the overlay network endpoint that may be used to generate a source port or other field in the substrate flow identification information . Alternatively the overlay network endpoint may otherwise negotiate a change with the overlay network endpoint relative to any field in the substrate flow identification information . In some embodiments the overlay network endpoint may instead request a hashing related change to be effected in the router or other networking equipment. In some cases the overlay network endpoint may effect a change without a specific change indicating communication with the overlay network endpoint

In box the overlay network endpoint sends the substrate flow to the overlay network endpoint via the substrate network . Thereafter the portion of the overlay network endpoint ends. If in box the overlay network endpoint instead determines not to perturb the substrate flow identification information the overlay network endpoint continues to box directly from box .

Turning now to shown is a flowchart that provides one example of the operation of a portion of the source network device according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the source network device as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the source network device according to one or more embodiments. Additionally in other embodiments the functionality described with respect to may be implemented in other network devices e.g. the overlay network endpoints the router the destination network devices and so on.

Beginning with box the source network device sends a flow of packets to a destination endpoint at a destination network device . In box the source network device determines that congestion is affecting the flow . Such congestion may be caused by generalized network congestion or local flow collisions from flow based hashing in the router . In box the source network device obtains network congestion information from the network monitoring service .

In box the source network device determines whether the congestion experienced by the flow is caused by local flow collisions. The determination is made based at least in part on the network congestion information obtained from the network monitoring service . If the source network device determines that the congestion experienced by the flow is caused by local flow collisions the source network device moves to box and effects a perturbation to the flow identification information . Alternatively a change to flow hashing logic may be requested. In one scenario a network monitoring service may be configured to instruct the source network device to perturb the flow so as to use a particular route that is known not to be congested. In another scenario the perturbation may be made irrespective to the consequent routing. Thereafter the portion of the source network device ends. Where the functionality of is implemented by an overlay network endpoint the overlay network endpoint may effect a perturbation to the substrate flow identification information .

If instead the source network device determines that the congestion experienced by the flow is not caused by router local flow collisions e.g. the congestion is in fact network wide congestion etc. the source network device moves instead from box to box . In box the source network device refrains from effecting a perturbation to the flow identification information . Thereafter the portion of the source network device ends. Where the functionality of is implemented by an overlay network endpoint the overlay network endpoint may refrain from effecting a perturbation to the substrate flow identification information .

Referring next to shown is a flowchart that provides one example of the operation of a portion of the source endpoint from the networked environment according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the source endpoint as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the overlay network endpoint according to one or more embodiments.

Beginning with box the source endpoint opens one or more connections to a first network host at a destination endpoint by way of a network . For example such connections may be TCP connections or other types of connections. In box the source endpoint measures and records round trip times to the first network host through the connection for multiple packets sent via the connection. Alternatively the source endpoint may send ICMP pings or other connectionless probing traffic to the first network host to determine round trip times. In box the source endpoint opens another connection to the first network host at the destination endpoint by way of the network . In box the source endpoint initializes an estimate of the round trip time between the source endpoint and the first network host for the other connection based at least in part on the round trip times measured and recorded for the connection s to the first network host in box .

Next in box the source endpoint opens a connection to a second network host at a destination endpoint . In box the source endpoint obtains proximity data indicating the physical and or logical proximity between the first network host and the second network host. To this end the source endpoint may make a request to the global data service for the network host proximity data relating the physical and or logical location of the first network host to the second network host. In some cases the proximity data may be locally determined by probing the round trip times for neighboring hosts where hosts are considered to be proximate based at least in part on round trip time similarity.

In box the source endpoint initializes an estimate of the round trip time for the connection from the source endpoint to the second network host based at least in part on the round trip times measured and recorded for the connection s to first network host in box and the proximity data. Thereafter the portion of the source endpoint ends.

With reference to shown is a schematic block diagram of the computing device according to an embodiment of the present disclosure. The computing device includes at least one processor circuit for example having a processor a memory one or more network interfaces all of which are coupled to a local interface . To this end the computing device may comprise for example at least one server computer desktop computer mobile computer smart phone router etc. For example the computing device may correspond to a source network device a destination network device an overlay network endpoint a router a computing device a source endpoint a destination endpoint a computing device and or other types of network devices which may be employed in the networked environments or . The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated.

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor may be flow identification perturbation logic a network stack a network monitoring service a global data service and or potentially other applications. The flow identification perturbation logic may be executed to perturb flow identification information and or substrate flow identification information as has been described. The network stack corresponds to a TCP IP stack a UDP IP stack and or other network stack logic. Also stored in the memory may be a data store storing measured round trip times and or other data. In addition an operating system may be stored in the memory and executable by the processor .

It is understood that there may be other applications that are stored in the memory and are executable by the processor as can be appreciated. Where any component discussed herein is implemented in the form of software any one of a number of programming languages may be employed such as for example C C C Objective C Java JavaScript Perl PHP Visual Basic Python Ruby Delphi Flash or other programming languages.

A number of software components are stored in the memory and are executable by the processor . In this respect the term executable means a program file that is in a form that can ultimately be run by the processor . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory and run by the processor source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory and executed by the processor or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memory to be executed by the processor etc. An executable program may be stored in any portion or component of the memory including for example random access memory RAM read only memory ROM hard drive solid state drive USB flash drive memory card optical disc such as compact disc CD or digital versatile disc DVD floppy disk magnetic tape or other memory components.

The memory is defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memory may comprise for example random access memory RAM read only memory ROM hard disk drives solid state drives USB flash drives memory cards accessed via a memory card reader floppy disks accessed via an associated floppy disk drive optical discs accessed via an optical disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

Also the processor may represent multiple processors and the memory may represent multiple memories that operate in parallel processing circuits respectively. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any processor and any of the memories or between any two of the memories etc. The local interface may comprise additional systems designed to coordinate this communication including for example performing load balancing. The processor may be of electrical or of some other available construction.

Although the flow identification perturbation logic the network stack the network monitoring service the global data service and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits having appropriate logic gates or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowcharts of show the functionality and operation of an implementation of portions of the source network device the overlay network endpoint and the source endpoint . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor in a computer system or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowcharts of show a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in may be executed concurrently or with partial concurrence. Further in some embodiments one or more of the blocks shown in may be skipped or omitted. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also any logic or application described herein including the flow identification perturbation logic the network stack the network monitoring service or the global data service that comprises software or code can be embodied in any non transitory computer readable medium for use by or in connection with an instruction execution system such as for example a processor in a computer system or other system. In this sense the logic may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the logic or application described herein for use by or in connection with the instruction execution system.

The computer readable medium can comprise any one of many physical media such as for example magnetic optical or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives memory cards solid state drives USB flash drives or optical discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

