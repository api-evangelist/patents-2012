---

title: Real-time predictive intelligence platform
abstract: A real-time predictive intelligence platform comprises: receiving from a user through a meta API definitions for predictive intelligence (PI) artifacts that describe a domain of an online transaction system for least one business entity, each of the PI artifacts including types, component modules and behavior bundles; exposing an entity API based on the PI artifacts for receiving entity events from the online transaction system comprising records of interactions and transactions between customers and the online transaction system; responsive to receiving an entity event through the entity API, executing the component modules and behavior bundles to analyze relationships found between past entity events and metrics associated with the past entity events, and computing a probabilistic prediction and/or a score, which is then returned to the online transaction system in real-time; and processing entity event replicas using modified versions of the PI artifacts for experimentation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09159024&OS=09159024&RS=09159024
owner: Wal-mart Stores, Inc.
number: 09159024
owner_city: Bentonville
owner_country: US
publication_date: 20121207
---
This application claims the benefit of provisional Patent Application Ser. No. 61 567 850 filed Dec. 7 2011 assigned to the assignee of the present application and incorporated herein by reference.

Retailers and financial institutions typically collect large amounts of data and use business intelligence and analytics to make sense of the data. As the volume of data being generated and analyzed has increased so has the need for analyzing this data in real time. This increasingly data rich environment offers tremendous potential for improving business results by making increasingly data driven decisions. This same growth in data volume and the growing need to make more decisions more rapidly is pushing retailers to look at new approaches and technology. Many retailers are adopting predictive analytics to extract more meaning from their data. These mathematical techniques process large amounts of historical data to make predictions about the future. They allow a retailers and financial institutions to make probabilistic predictions such as how likely is this transaction to be fraudulent how loyal is this customer what offer will be most effective at increasing basket size for these customers and more. These predictions these probabilities can be used to improve decision making throughout the organization.

Predictive analytics provides an enhanced view of customers and makes predictions about their current and future transaction behavior. This technique can be applied to a myriad of challenges including customer segmentation merchandising optimization information security marketplace trust and safety and buyer fraud. However within many organizations the promise of predictive analytics is inhibited by a misalignment between technical and data science resources.

Once the data scientist builds the algorithms the algorithms are released to a business developer who must map and recode the algorithms into the entity s business logic of the online transaction system . In other words for every piece of data that the data scientist used to build the algorithms the business developer tries to map the data back to the original transactional data. An application developer must also convert the algorithms written with one of the statistical tools into a language used in the online transaction system . The resulting code is then released into the online transaction system for use by the customers .

To ensure that the models and scores in the algorithms were created correctly a validation cycle is performed shown by the dashed arrows where the online transaction data is collected again and the data scientist verifies whether the algorithms are working correctly. If any discrepancies are found the data scientist notifies the business developer . The business developer then corrects the problem in the business logic and the cycle continues. The cycle for a medium size complexity model may take anywhere from 3 to 6 months.

There are number of problems with the traditional analytic development systems. One problem is that the data scientist builds the algorithms in off line system on transaction data that is extracted transformed and loaded ETL from a production database . Therefore the transaction data on which these algorithms are built is often very different from the transaction data in the online transaction system . The data scientist then has to work with the business developer to accurately map the data between the online and off line systems and resulting in many iterations and long lead times to get the algorithms working in production.

Another problem is that the algorithms are written in a mathematically precise statistical language such as R SaS MATLAB and must be translated into languages such as Java Python C Ruby and the like used to implement the business logic used of the online transaction system . That means the algorithms must be reinterpreted from a mathematical precise world into a domain specific world of the business entity which is a mismatch. This mismatch results in the data scientist having to work with the business developer to accurately convert the algorithms . This process results in many iterations and delays in deploying the algorithms developed by the data scientist . The above two problems may be typically referred to as the life cycle problem.

Yet another problem with traditional analytic development systems that the software components implementing the system are custom built for a specific type of application or use case domain . The application business logic and data base schemas are custom built for each application. This makes it very difficult if not impossible for a business entity to share data and analytics about user behavior within various departments of the business entity or across different business entities that want to share data and analytics.

A related problem is that different departments within the same business entity may have separate sets of algorithms which are computed and integrated differently. The reason is because there is no common frame of reference that allows a determination of whether the information and analysis from one set of algorithms such as for a loyalty program are applicable for another set of algorithms such as fraud or risk. The underlying infrastructure does not support different analytical algorithms to be composed and aggregated in a clean manner rather each one evolves independently because there is no common metadata model.

Accordingly it would be desirable to provide an improved analytic development system referred to herein as a real time predictive analytics platform.

The exemplary embodiment provides methods and systems for a real time predictive intelligence platform. Aspects of exemplary embodiment include receiving from a user through a meta API definitions for predictive intelligence PI artifacts that describe a domain of an online transaction system for least one business entity each of the PI artifacts including types component modules and behavior bundles exposing an entity API based on the PI artifacts for receiving entity events from the online transaction system comprising records of interactions and transactions between customers and the online transaction system responsive to receiving an entity event through the entity API executing the component modules and behavior bundles to analyze relationships found between past entity events and metrics associated with the past entity events and computing a probabilistic prediction and or a score which is then returned to the online transaction system in real time and processing entity event replicas using modified versions of the PI artifacts for experimentation.

According to the method and system disclosed herein the exemplary predictive intelligence platform provides real time predictive analytics to one or more business entities to enable the business entities to make decisions on business transactions activities in real time. The predictive intelligence platform enables the entities to define their domains using metadata thereby eliminating the need custom software.

The exemplary embodiment relates to a real time predictive intelligence platform. The following description is presented to enable one of ordinary skill in the art to make and use the invention and is provided in the context of a patent application and its requirements. Various modifications to the exemplary embodiments and the generic principles and features described herein will be readily apparent. The exemplary embodiments are mainly described in terms of particular methods and systems provided in particular implementations. However the methods and systems will operate effectively in other implementations. Phrases such as exemplary embodiment one embodiment and another embodiment may refer to the same or different embodiments. The embodiments will be described with respect to systems and or devices having certain components. However the systems and or devices may include more or less components than those shown and variations in the arrangement and type of the components may be made without departing from the scope of the invention. The exemplary embodiments will also be described in the context of particular methods having certain steps. However the method and system operate effectively for other methods having different and or additional steps and steps in different orders that are not inconsistent with the exemplary embodiments. Thus the present invention is not intended to be limited to the embodiments shown but is to be accorded the widest scope consistent with the principles and features described herein.

A business entity refers to an organization that provides an online transaction system for use by customers.

Predictive Intelligence PI Platform refers to a metadata driven web service that provides real time predictive analytics to one or more business entities to enable the business entities to make decisions on business transactions activities in real time and without have to write custom software.

Predictive Intelligence PI Artifacts are designed and produced by the business entity and its business operations using the PI platform to capture and represent the business activities from the business entity s online transaction system. The PI platform processes the PI artifacts to provide the business entity information insight and intelligence about the business transactions activities occurring on the online transaction system.

A Domain is a logical grouping of PI artifacts that provide a clear boundary for applying name space security and privacy policies as well as collaboration policies for each PI artifact group. The business entity can own or describe one or more domains for access and or for creation of PI artifacts for each domain and a domain may have zero or more child or sub domains.

The exemplary embodiments describe a predictive intelligence platform in form of a metadata driven web service that provides real time predictive analytics to one or more business entities to enable the business entities to make decisions on business transactions activities in real time. Because the predictive intelligence platform defines the domains of the business entities using metadata the need for the business entities to write custom software is eliminated.

The PI platform deploys a metadata driven system that enables the business entity to dynamically define custom data and event activity types relationships and a programmatic application programming interface API to receive probabilistic predictions about the events occurring on the online transaction system in real time. In one embodiment the PI platform may include a domain configuration component an analytical platform a decision engine and an integration component .

The domain configuration component may include a graphical user interface GUI and a meta API . The GUI and or the meta API allow users such as scientists and or domain business analysts to define manage and monitor full lifecycle creation modification and removal of an event API and predictive intelligence PI artifacts for the business entity. The PI artifacts are stored and managed under a domain.

In one embodiment the PI artifacts may comprise data and event types that may be stored in a type schema component models that may be stored in a component repository behavior bundles that may be stored in a behavior bundle repository and policies that may be stored in a policy repository . The data and event types are defined by the user to capture relevant business activities and operations. The component modules are designed and deployed by the user to provide reusable services and analytical models in terms of algorithms and functions with related data. The behavior bundles are designed and deployed to process entity events update PI instance data trigger the updating of analytical models and to perform predictive computations.

According to one embodiment after the types in the PI artifacts are created by the users the PI platform may automatically expose a set of corresponding event APIs based on the types in PI artifacts . The event API defines how the business entity transmits entity events from the online transaction system into the PI platform . In one embodiment the entity events comprise records of interactions and transactions between the customers and the online transaction system . Examples of entity events may include customer logins page clicks customer browsing history and buying and selling information for instance. The buying and selling information may include an account number a product ID a merchant ID a sales amount a credit card number a device ID an IP address and the like.

In one embodiment the GUI is built on top of the Meta API which may include data service APIs and web service APIs. The Meta API allows the users to define the types in the PI artifacts such as data graphs and time series metrics for analyzing and tracking the entity events for example. In one embodiment the GUI includes an advanced integrated development environment IDE for the users to design and deploy the component modules and PI behavior bundles in the PI artifacts . The GUI may also enable the users to view and analyze business metrics and dashboards to query and visualize data models such as the data graphs and to drill down to runtime predictions and decision choices.

The Integration component provides an extensible plug in architecture for runtime integration of services. As part of defining the PI artifacts the users may use the integration component to integrate the PI artifacts with external services external data and or big data some of which may be provided by a third party provider. Examples of the external services may include analytical and statistical services such as R SAS etc. email and address verification services credit report services and the like. Examples of the external data may include IP geo location data product catalog data and the like. Examples of the big data may include services such as Mem Cache Hadoop and the like. The external services and data and could be subject to service agreements on pay for usage which may be enforced by PI Platform .

The integration component surfaces the external services the external data and or the big data to the users in a manner in which the users do not have to write scripts to access the data. The external services the external data and the big data may be exposed to the PI platform via the component modules of the PI artifacts . The interfaces to access these services and data may be exposed to the IDE of the domain configuration component for the users to reference. The visibility of these services in the GUI may be controlled by policies defined and granted by the business entity.

Once the PI artifacts and the event API are configured for the online transaction system the decision engine is invoked at runtime and begins receiving entity events from the online transaction system . The entity events are input to the predictive intelligence platform through the event API .

The decision engine may employ one or more event consumers which may be assigned to different processing functionality and or different entity event types. The event consumers may call one or more behavior execution engines to invoke corresponding behavior bundles the processing of entity events by the event consumers updates the instances of the types. The decision engine also employs one or more advisory services which may also call the behavior execution engines to analyze the entity events based on the types behavior bundles algorithms and models from the component modules defined by the PI artifacts

Based on this analysis the advisory service computes advisory responses for the events and returns the advisory responses to the online transaction system . In one embodiment the advisory responses may include probabilistic predictions regarding the events such as a probabilistic prediction of a particular transaction being fraudulent. In one embodiment the advisory responses may include a score for the entity events in addition to or instead of a probabilistic prediction. The business entity may then use the advisory responses to help make business decisions regarding the entity events .

In one embodiment the entity events may also include feedback to the business about the correctness of the advisory responses . For example the business entity may send a notification of whether a chargeback was received for a credit card transaction that was approved by the PI platform . The PI platform may use the feedback to modify the PI artifacts and improve future advisory responses. In one embodiment the feedback regarding the advisory responses is received via the event API in batch. For example the PI platform may receive a list of charge backs or fraudulent activity for a particular month. In another embodiment the feedback may be received for single events or transactions. In another embodiment once the business entity defines the PI artifacts the PI platform may receive a large batch of historical event data to populate the newly defined data structures and to compare the live entity events with the historical entity events to calculate the current advisory responses .

According to one aspect of exemplary embodiment the analytics platform maintains replicas of the PI platform components including a domain configuration component an integration component an event API and a decision engine for handling the life cycle problem. In one embodiment entity events that occur in the online transaction system may be copied and recorded in real time for subsequent played back on the analytical platform in a time compressed way. This allows the users to replay the transactions defined by the entity events at very high speed using experimental versions of the PI artifacts. This allows the users to inject the experimental versions into the decision engine without any downtime without the business entity having to write custom applications.

In one embodiment the GUI the domain configuration component the analytical platform the decision engine and the integration component may be implemented as software components or as a combination of hardware and software. Although the GUI the domain configuration component the analytical platform the decision engine and the integration component are shown as separate components the functionality of each may be combined into a lesser or greater number of modules components. In addition the components shown in may be executed by any type and combination of computers and servers that have memory and at least one processor.

Although not shown the servers and computers comprising the PI platform include hardware components of typical computing devices including one or more processors input output devices computer readable media e.g. memory and storage devices e.g. flash memory hard drive optical disk drive magnetic disk drive and the like containing computer instructions that implement the functionality disclosed when executed by the processor. The servers and the computers may further include wired or wireless network communication interfaces for communication over the network.

The process may begin by receiving from a user through the meta application programming interface API definitions for predictive intelligence PI artifacts that describe a domain of an online transaction system for at least one business entity each of the PI artifacts including types component modules and behavior bundles block .

The domain configuration component automatically creates and exposes the domain specific event API based on the PI artifacts that will receive entity events transmitted from the online transaction system wherein the entity events comprise records of interactions and transactions between customers and the online transaction system block .

The decision engine is responsive to receiving the entity events through the domain specific entity API to execute the behavior bundles and referenced component modules related to the entity event to analyze relationships found between past entity events and time series metrics associated with the past entity events to compute at least one of a probabilistic prediction and a score related to the entity event and to return an advisory response to the online transaction system comprising the at least one of a probabilistic prediction and score block .

The analytical platform allows the user to optimize the PI artifacts by saving past entity events as entity event replicas and processes the entity event replicas using modified versions of one or more of the event API the types component modules and the behavior bundles for experimentation block .

Composite data types that support domain specific ontologies and semantic data for information data models 

Time series metrics definitions that define a temporal summary of business activity segmentation permutation 

Advisory response types that represent recommendations based on real time prediction and decision models in response to business events 

In one embodiment the users may define the data and event types under a set of predefined high level meta categories that govern the definition of event types via the GUI and the meta API using a flexible Schema Definition Extended JSON Schema which supports but not limited to 

In one embodiment the component modules may include but are not limited to a services that can access local remote data and or behaviors and can be invoked by the behavior bundles and b analytical models comprising algorithms and functions with related data.

The behavior bundles contain rules and procedures for processing the entity events authored using a PI rule language. The PI rule language and its associated IDE support both declarative and functional programming constructs which are suitable for the users such as data scientists. The behavior bundles may include but are not limited to 

Defining event processing logic for creating and updating instances of the data graph and time series metrics 

Designing and applying analytical models that calculate and update data entity scores of the data graphs based on the all related PI data instances 

Analytical models algorithms logic that enable comparison of the quality of the probabilistic predications based on real time experimentations.

A logical grouping of PI artifacts defines the business domain of a business entity and is fully customizable by the business entity using the PI platform . Each business entity may create or associate more than one domain . Each domain may have zero or more child domains. According to one embodiment portions of the domains may be shared between departments of the same business entity or between different business entities and based on policy for data sharing and aggregation thereby increasing intelligence of the PI platform .

Relationships between the segments of the PI artifacts include the following. The data and event types govern type instances which are created and updated by the decision engine during runtime. The component modules depend on both the data and event types and the type instances . The behavior bundles depend on the data and event types and use both the component modules and the type instances .

Once the PI artifacts are defined the domain configuration component automatically exposes the domain specific event API based on the PI artifacts .

For each new data and event type defined for a domain of a business entity the domain configuration component may automatically generate a properly segmented type schema and the type specific event API which also includes data binding validation and IDE integration. The domain configuration component may also produce tooling APIs for type specific ETL .

According to an exemplary embodiment the domain configuration component manages and represents the data and event types in the type schema and in the instance store which stores instances of the data and event types during runtime using both a relational data store e.g. SQL and a non relational data store e.g. dynamic noSQL .

In one embodiment the type instances are all under domain scope. The PI platform further segments the instance store for extended type level properties by domains. This enables complete removal of domain specific properties attributes represented by while still maintaining the usefulness and the validity of anonymized data entities and relationships represented by as well as associated entity scores and activity matrixes which reference type instances .

Accordingly the data is structured at a category level but non structured at entity level. This enables heterogeneous sub graphs from different domains to be connected.

To support effective analytical models on fraud risk reputation and advisories a comprehensive information network is required. However traditional graph representations of social networks such as P2P networks mobile computing and online communities and the like are generally isolated to the respective domains. The unique implementation of each network makes it difficult to join them together to form a super set network of greater value.

According to another aspect of the exemplary embodiment the PI platform provides an extensible multi cross domain information network that is meta data driven to overcome the deficiencies of traditional social network approaches. The information network provides a foundation for building reliable reputation risk management advisory promotion and other services that depend on a comprehensive identity network.

The information network of the exemplary embodiment may be implemented as an information data graph which is defined as one of the data and event types . The data graph includes nodes such as customers products merchants and the like edges or links connecting the nodes which represent relationships between the nodes and indexes for data graph traversal and retrieval.

As can be seen in the PI platform completely segments the data store for domain node properties and domain specific edge properties. This enables privacy and data sharing policy for cross domain access.

Even with complete removal of domain specific edge node properties of one domain or business entity the PI platform may still use the anonymized data graph to gain valuable insight for other business entities from its network effects. For example anonymized identities nodes and relationships edges from other domains and their associated node rankings and scoring as well as behavior matrices can provide valuable information to enhance the analytical model of any given domain. According to the exemplary embodiment the data graphs can be defined extended and integrated via metadata definitions without programmatic modifications of the PI platform .

As described in after the PI artifacts are defined in step and the domain specific entity API is automatically created in step the decision engine computes and returns an advisory response containing probabilistic prediction and or a score related to the entity event to the online transaction system during runtime.

According to one embodiment the PI platform runtime process is a sequence of processing steps performed in response to an entity event or a stream of entity events submitted to the PI platform where PI artifacts are analyzed to produce an optimal synchronous or asynchronous advisory response to the entity event and PI artifacts are updated maintained in response to the entity event to increase the intelligence of the PI platform so as to provide more optimal advisory responses to future entity events.

The runtime process of the decision engine may support a distributed processing model where event consumers process live instances of the PI artifacts and support the execution of the behavior bundles which contain rules and procedures for processing the entity event. The rules and procedures in the behavior bundles query and update the data models defined in the PI artifacts and invoke PI component modules.

The event service may handle all events entered into PI system via the event API . The event service initiates a set of processing sequences by the decision engine to process an entity event and or produce an advisory response . In one embodiment both transactional and task activity may enter the PI platform via the Entity API or driver. Invocation of the entity API for transactional activity create entity events while discrete activities such as file upload of data instructions that invoke the entity API may create tasks. In one embodiment the processing of entity events may occur in real or near real time while task processing may occur according to a schedule once or periodic .

All events are saved into the master event queue to support distributed event stream processing. According to one aspect of the exemplary embodiment different event consumers are provided to process the same entity event for different purposes those event consumers could be further split to handle different types of entity events for parallel processing.

Entity event processing by the event consumers results in computation of data entity scores and advisory responses and subsequent updates to instances of the PI artifacts including the data graphs the time series metrics and the data entity scores . These updates are governed by the insight gathered from the analytical platform and executed by the PI runtime via defined and deployed rules and procedures in the behavior bundles.

Each entity event can be subscribed and processed by one or more event consumers where each event consumer comprises 

An event sub queue that holds a sub set of entity events from the master event queue for processing by the event consumer 

An event selector that selects only relevant entity events from the master event queue for storage in an event sub queue 

An event processor that process the selected entity events in the event sub queue by calling a behavior execution engine to execute a set of the behavior bundles. The star symbols in denote the possible execution locations for the behavior bundles by the behavior execution engine . The number of event consumers that are used can be scaled up based on functionalities and data domains which may provide reliability flexibility and scalability.

By default all event consumers can process entity events independently. However entity event stream processing can support processing order among the event consumers . For example an event consumer responsible for generating the data graphs and the time series metrics may process independent of each other but processing by the event consumer responsible for generating the data entity scores may be dependent on the aforementioned two event consumers.

The advisory services uses the data graphs the time series metrics and the data entity scores to generate the advisory responses which are saved and also sent back to requestor via the event service and the entity event API .

In one embodiment a replica of the master event queue may be sent to the analytical platform to able the users to replay production versions of the entity events within the analytical platform . The usage of the IDE and the behavior bundle repository of behavior bundles in both production and in the analytical platform enables the users domain data scientists to promote and demote analytic models and processing logic based on offline analytics provided by the analytics platform .

PI artifact updating maintenance and processing flow are bound to compute and store units in a given deployed environment. Configuration may control this binding and can be changed during system execution for performance and or scaling requirements. The PI Process supports experimentation which allows multiple named groups of PI artifacts to be evaluated during event processing and the tracking of impacted PI artifacts from those behaviors.

The event processor is also responsible for invoking one or more behavior execution engines . Each of the behavior execution engines is responsible for loading a proper sub set of rules and procedures from the behavior bundles stored in behavior bundle repository as well as dependent component modules from the component repository .

The behavior bundles may be categorized into functions procedures and rules which can be designed by the users e.g. data scientists and domain experts. The behavior bundles may be deployed dynamically at runtime. The procedures and rules are executed by the execution engine including any arguments. Functions can be invoked with or without arguments and return a value. All categories of behavior bundles can invoke functions with without arguments and the functions return a value. The order of rule execution can be declared and the execution of the rules and procedures e.g. paths and decisions may be tracked by framework and saved in a behavior execution tracking repository .

The event consumer uses component proxy handlers to load processing logic in the form of dynamic component modules to enforce the usage permission billing and metering. The event consumer runtime process supports dynamic deployment re deployment of the component modules which contain services that can be invoked by the behavior bundles to access local remote data and or behaviors as well as algorithms. In one embodiment different versions of the component modules may be developed and managed under their principal domain. Usage of the component modules during both configuration and runtime are governed through policies which are enforced by the PI platform s IDE and runtime proxies . In one embodiment different versions of the component modules can be deployed to the same event consumer runtime to be accessed by different domain behavior bundles. The runtime services provide full life cycle support such as configuration initialization and tear down.

According to a further aspect of the exemplary embodiment the analytical platform shown in allows the user to optimize the PI artifacts by processing entity event replicas executing modified versions of the PI artifacts for offline experimentation and discovery. As described above the analytical platform comprises a copy of the execution environment of the PI platform for extended experimental support. This also provides the ability to save snapshots of the execution environment for reuse. Experimental capabilities of the PI platform include the following 

Vectoring the ability to define the runtime event flow to interact with one or more experiments and what percentage of event processing each experiment should process.

Results capture the ability to observe and review modified and or generated PI artifacts per experiment.

Results analysis the ability to enable comparison analysis across one or more experiments to identify the modified PI artifacts that contribute to optimized predictive results.

Promote Demote the ability to promote top performing PI artifacts and demote or replace sub optimal PI artifacts into from other PI platforms and or analytical platforms .

The major steps of experimentation Definition Vectoring Results capture Results analysis and Promote Demote also can all be directly performed in either the analytical platform or during runtime of the PI platform to process the entity events .

Processing or replaying the entity event replicas on the analytics platform using modified versions of the PI artifacts allows the users to experiment with and optimize the PI artifacts defined for the entity. For example six months of entity events may be replayed using experimental PI artifacts including types data graphs time series metrics rules and procedures and scores to determine which combination of components comprising the experimental PI artifacts and event API perform best. Top performing components can then be promoted into the PI platform and underperforming components can be demoted from the PI platform without any downtime. The users can thus push the desired combination of components from the experimental PI artifacts and the event API to the production environment all without having to write any code.

A method and system for providing a real time predictive intelligence platform has been disclosed. The present invention has been described in accordance with the embodiments shown and there could be variations to the embodiments and any variations would be within the spirit and scope of the present invention. For example the exemplary embodiment can be implemented using hardware software a computer readable medium containing program instructions or a combination thereof. Software written according to the present invention is to be either stored in some form of computer readable medium such as a memory a hard disk or a CD DVD BD and is to be executed by one or more processors. Accordingly many modifications may be made by one of ordinary skill in the art without departing from the spirit and scope of the appended claims.

