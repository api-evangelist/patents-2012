---

title: Opportunistic job processing in a distributed computer environment
abstract: A central storage configured to store one or more input files and an executable file. A work order frontend is configured to receive, from the client, a representational state transfer (RESTful) message that contains a reference to the one or more input files in the central storage. The work order frontend is further configured to transmit, to a global-level manager, a work order. The global-level manager is configured to access the work order. The global-level manager is further configured to partition the one or more input files into multiple shards, the work order into multiple jobs, each job being associated with one or more of the multiple shards and the executable file. The global-level manager is further configured to distribute the jobs among a plurality of clusters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08935318&OS=08935318&RS=08935318
owner: Google Inc.
number: 08935318
owner_city: Mountain View
owner_country: US
publication_date: 20120328
---
This application claims priority from U.S. Provisional Application Ser. No. 61 468 417 filed Mar. 28 2011.

This document relates to processing jobs which are to be performed on computers in a distributed computer environment.

Computing resources are used by computer programs during execution. The resources include disk space memory allocation network bandwidth and processor cycles. Modern computers are designed to enable multitasking the sharing of a single resource among multiple processes.

Distributed computing is an architecture that pools computer resources across multiple computer machines to carry out a single or multiple related processes. Computer code may be specially designed to be split or can be executed by other code that is designed to split the executing code across multiple computer machines a feature sometimes called parallelization.

In one aspect a system includes one or more processing devices. The system further includes a central storage configured to store one or more input files from a client. The central storage is further configured to store an executable file. The system further includes one or more storage devices storing instructions that when executed by the one or more processing devices cause the one or more processing devices to implement a work order frontend configured to receive from the client a representational state transfer RESTful message that contains a reference to the one or more input files in the central storage. The work order frontend is further configured to transmit to a global level manager a work order that includes a reference to the executable file and a reference to the one or more input files in the central storage. The instructions when executed by the one or more processing devices cause the one or more processing devices to implement the global level manager configured to access the work order. The global level manager is further configured to partition using the references to the executable file and the one or more input files the one or more input files into multiple shards the work order into multiple jobs each job being associated with one or more of the multiple shards and the executable file. The global level manager is further configured to distribute the jobs among a plurality of clusters to be processed using underutilized computing resources in the clusters. The instructions when executed by the one or more processing devices cause the one or more processing devices to implement the plurality of clusters. Each cluster includes one or more task level managers configured to process a job distributed to the cluster using underutilized computing resources in the clusters and generate a job output based on the processing.

Implementations can include any all or none of the following features. The central storage may be under the same administrative control as the work order frontend. The work order frontend may be further configured to provide the client with a graphical user interface to generate the RESTful message and wherein the RESTful message may be received through the graphical user interface. The graphical user interface may be configured to send the one or more input files and the executable file to the central storage. To distribute the jobs among a plurality of clusters the global level manager may be configured to distribute the references to the executable file and the one or more input files. To process a job distributed to the cluster the cluster may be configured to access using the references to the executable file and the one or more input files the executable file and the one or more input files in the central storage. The RESTful message is received from the client as part of a Hypertext Transfer Protocol HTTP request.

In one aspect a method is performed by one or more processors. The method includes storing at a central storage one or more input files from a client. The method further includes storing an executable file. The method further includes receiving at a work order frontend and from a client a representational state transfer RESTful message that contains a reference to the one or more input files in the central storage. The method further includes transmitting to a global level manager a work order that includes a reference to the executable file and a reference to the one or more input files in the central storage. The method further includes accessing at the global level manager the work order. The method further includes partitioning using the references to the executable file and the one or more input files the one or more input files into multiple shards partition the work order into multiple jobs each job being associated with one or more of the multiple shards and the executable file. The method further includes distributing the jobs among a plurality of clusters to be processed using underutilized computing resources in the clusters. The method further includes processing by one or more task level managers of the plurality of clusters a job distributed to the cluster using underutilized computing resources in the clusters and generate a job output based on the processing.

In one aspect a system includes one or more processing devices. The system further includes a central storage configured to store one or more input files from a client. The central storage is further configured to store an executable file. The system further includes a work order frontend configured to receive from the client a representational state transfer RESTful message that contains a reference to the one or more input files in the central storage. The work order frontend is further configured to transmit to a global level manager a work order that includes a reference to the executable file and a reference to the one or more input files in the central storage. The system further includes the global level manager configured to access the work order. The global level manager is further configured to partition using the references to the executable file and the one or more input files the one or more input files into multiple shards the work order into multiple jobs each job being associated with one or more of the multiple shards and the executable file. The global level manager is further configured to distribute the jobs among a plurality of clusters to be processed using underutilized computing resources in the clusters. The system further includes the plurality of clusters. Each cluster includes one or more task level managers configured to process a job distributed to the cluster using underutilized computing resources in the clusters and generate a job output based on the processing.

Various implementations of the subject matter described here may provide one or more of the following advantages. In one or more implementations spare resources in a computer system may be monetized. In one or more implementations a three tier structure may facilitate the efficient delegation of low priority jobs. Sorting input data by size can permit a minimization of bandwidth required to move the data. Also with certain examples server side virtual clients can provide a secure and light weight execution environment for untrusted code. In one or more implementations calculating and tracking process throughput can enable a system to respond and increase process throughput.

The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features and advantages will be apparent from the description and drawings and from the claims.

Very large distributed systems made up of hundreds or thousands of computers are often not utilized to full capacity. Spare resources in the form of idle cycles memory and network bandwidth may be available for the processing of very low priority jobs. In order to utilize those spare resources a computer system may accept very low priority jobs from paying customers and process those jobs using the spare resources.

Modules e.g. cages of rack mounted computers are arranged in the space in rows that are separated by access aisles in the form of worker walkways. Each cage can include multiple racks e.g. four to eight racks and each rack includes multiple computers e.g. trays.

The facility also includes a power grid which in this implementation includes a plurality of power distribution lines that run parallel to the rows . Each power distribution line includes regularly spaced power taps e.g. outlets or receptacles. The power distribution lines may be bus bars suspended on or from a ceiling of the facility. Alternatively bus bars could be replaced by groups of outlets that are independently wired back to a power supply e.g. elongated plug strips or receptacles connected to the power supply by electrical whips. As shown each cage can be connected to an adjacent power tap e.g. by power cabling .

A number of facilities may be owned by the same organization and may be geographically dispersed in different geographic areas across one or more states countries and or continents. The facilities may be communicably linked through a data network such as the Internet or via a private network such as a fiber network owned by a company that operates the facility. Each facility such as facility may have a number of different features. For example some facilities may have different hardware and software operating costs or usage profiles. In addition each facility may exhibit a partial or total failure from time to time. The failures may be planned such as when part of a facility is taken off line for upgrades or maintenance. The failures may also be unplanned such as when a facility loses electrical power or is subject to a natural disaster.

In a computer system made up of many facilities that are designed and dedicated to carry out a range of tasks some underutilization of resources is likely. Many task requirements ebb and flow for example the system may have heavy usage during the day when most local users are awake and when businesses are open. Additionally redundancies are often built into such a computer system to handle outages and downtime. When the daily usage patterns ebb and there are no outages or downtime some of the resources in the system are likely to be underutilized. These underutilized resources can be tasked with low priority jobs provided by customers or clients.

Such low priority jobs can be held and then opportunistically processed in batches by the system . The system can consider known or predicted factors of the facilities when creating the batches. For example batches may be scheduled initially to run during times of low utilization of the facilities . The batches can be organized so that data transfers which often have an associated cost are minimized. In some implementations the size of each batch can also be based on the expected use patterns of higher priority jobs. The resources of the facilities may be scheduled using bin packing algorithms that imperfectly utilize the resources of the facilities in a predictable way e.g. an expected number of unused CPU cycles per minute . In such a case the system can design the batches to use those expected unused resources e.g. the expected number of unused CPU cycles per minute in a batch to be completed in one minute .

In the system a client can submit a work order which contains an input file and binary code to a global level manger for completion. The binary code can be executable code written by or for the client that operates on the input file to produce some output data that is of use or value to the client. Example binary code and input files can include but are not limited to financial analysis code and transaction data primary research code and test data created by a university researcher or bioinformatics application Basic Local Alignment Search tool BLAST code and bioinformatics data. In some implementations any code that can be adequately parallelized and distributed may be appropriate for use as the binary code . The binary code can be compiled with one or more frameworks or libraries that provide for example communication and distribution capabilities used for compatibility in the system . The input file can be formatted according to one or more published data formats used by the system . One such data format may specify that the input file be sharded or partitioned at a particular size.

The global level manager can receive the input file and the binary code and can create a job that specifies that the binary is to be run on the input file . The global level manager can also facilitate the storage of the input file and binary code in a central storage either directly or by another system. The central storage can serve the input file and binary code to other components of the system as requested.

The central storage can include storage facilities that are located at a number of geographically dispersed facilities . The input file and binary code can be initially uploaded to a central storage facility that is geographically near the uploading client and then can be replicated across a regional national or international domain.

The system can use a multi tiered such as a three tiered model for job distribution and completion. A global level manager acting as the top tier can distribute portions of the work order called jobs and shards of the input file or references thereof to cluster level managers in the second tier. The cluster level managers can register with a global level discovery service to post their availability to accept jobs. Each cluster level manager can further distribute the jobs to task level managers . The task level managers can register with a cluster level discovery service that is associated with their cluster to post their availability to accept jobs. In some implementations the cluster level discovery service and the global level discovery service are services that are shared by other systems that are running on the same clusters and networks. The cluster level discovery service and the global level discovery service can be configured as database tables in databases shared by many systems.

In some implementations responsibilities are assigned to the lowest tier possible. For example the cluster level manger not the global level manager can be responsible for distributing jobs to task level managers . Information about the completion of jobs e.g. job opportunistic termination assignments can be transmitted up to the global level manager for for example global coordination and reporting.

The task level managers can report completion of a job to the cluster level manager who can pass that report up to the global level manager. Additionally the task level manager can collect an output shard that has been created by the job and can facilitate the storage of the output shard in the central storage either directly or by another system. After receiving reports that all relevant jobs have been completed the global level manager can collect all of the output shards in the central storage associated with the job and create an output file

The cluster level manager can be a long running job that runs at production priority i.e. a higher priority than the jobs to be distributed . The cluster level manger can receive jobs from the global level manager and assign those jobs to the individual task level managers . The cluster level manager can share information with the global level manager . For example the cluster level manager can record the job that is assigned to each task level manager and can monitor the progress of the job.

The task level manager can be a job running at a lower priority than the cluster level manager but at a higher priority level than the jobs to be distributed. The task level manager can create and manage multiple native clients each native client hosting a worker created from the binary code to complete an assigned work assignment. The worker processes the job and reports the results to the task level manager .

In some implementations the jobs contain references to data needed to process the jobs not the data itself. When the cluster level manager receives a job or a group of jobs the cluster level manager can retrieve the needed input data from the central storage and store the input data in a cluster cache . The input data can be a subset of the input file that is needed to process the jobs that are received by the cluster level manager . The cluster cache can transfer the input data to the task level managers as needed. For example the cluster cache can provide a protocol to facilitate peer to peer data transfer within cluster with each task level manager and the cluster cache acting as a peer. The task level manager can provide the needed input data to each worker so that the respective worker can process a job. As such the cluster may be configured to only retrieve the input data from the central storage once and provide it to many task level managers without additional transfers from the central storage .

When a job is completed by the worker the task level manager can receive output data from the worker . The task level manager can provide the output data to the central storage and can notify the cluster level manager that the job has been completed. The cluster level manager can pass the notification to the global level manager optionally aggregating and or summarizing multiple reports first.

A data distribution service can facilitate cluster to cluster level data replication. For example input data in the cluster cache of one cluster may be needed by another cluster . Instead of retrieving some or all of that input data from the central storage the data distribution service of the cluster may request the input data from the other cluster .

In some implementations the number of task level managers in a cluster may be constant. For example each and every computer or a constant subset of the computers may have one task level manager . Alternatively the number of task level managers in the cluster can vary according to for example the load of jobs received by the cluster level manager . In this case the cluster level manager can launch and destroy task level managers which run as software processes as needed.

Some workers in the same task level manager may be from the same customer or client and may use some of the same input data . In these cases the task level manager can be configured to share the shared input data with the workers from a common local cache. If the workers are from different customers or clients no such sharing may be permitted.

For example a client may submit a work order whose algorithm requires comparing N large data objects e.g. database shards to M small data objects e.g. query shards . Such a work order requires N M combinations and can be distributed between N M workers. One such example work order is the bioinformatics application Basic Local Alignment Search Tool BLAST .

In some implementations input data is larger than the binary code . Within the input data database shards and binary large objects BLOBs are generally larger than structured data such as database queries. The input data can be sorted by largest data type then by each progressively smaller data type in the input data to create input data groups. In the data the input data is sorted by database index shard then by query shard .

The global level manager can assign to each cluster one database index shard and each query shard . Additionally the global level manager can assign workers to each cluster for each combination of input data that is for every combination of data index shard and query shard . The workers can process their associated input e.g. worker 1 3 can process database index shard 1 and query shard 3 to produce a corresponding output e.g. output 1 3 .

Under the scheme shown here the largest data objects database index shards are moved to a cluster only once. The database index shards need not be replicated in whole or in part between different clusters. The scheme shown can be calculated and created proactively before or as work assignments are distributed by the global level manager permitting network and cluster level caching.

An executable job and an input resource are received at a global level manager . For example a client can develop executable binary code designed to operate on an input file . The global level manager can provide an web interface or application protocol interface API to receive the binary code and the input file . The global level manager can store the input file and the binary code in the central storage and create object references that point to the stored input file and the binary code .

Input data shards are generated from the input resource . For example a first type of input resource can be identified as being larger than a second type of input and the first type and second type of input can each be split into a plurality of shards. The global level manager for example by manipulating the object references or issuing commands to the central storage can split the input file into two or more input data shards such as the database index shards and the query shards . The input data shards can be for example limited by raw disk size or number of data elements.

Prefix values can be created in order of shard input size . For example each of the first type input shards can be associated with a copy of every second type input shard. For each database index shard the global level manager can create jobs specifying one database index shard and each query shard .

The global level manager can distribute each first type input shard to a cluster from among a plurality of clusters along with the associated second type input shards and the executable file . Workers are created for each first type input shard and second type input shard combination as appropriate so that the first type input shard and the second type input shard are processed by the executable file using underutilized computing resources in the cluster . For example the global level manager can distribute the jobs to the clusters . The clusters can receive the jobs and fetch the referenced database index shards and query shards from the central storage .

Output data can be assembled and received . For example the clusters can distribute the jobs database index shards and query shards to task level managers for processing. The task level managers can create workers to process the database index shards and query shards and collect the resulting output data . The task level workers can report task completion to the global level manager via the cluster level managers and store the output data in the central storage . The global level manager can collect the output data as it is stored or upon completion of the final job and can prepare the output data for transfer to the client as output file .

The customer computer can communicate with a work order RESTful frontend and submit a RESTful request . For example the work order RESTful frontend can serve to the customer computer a webpage that can accept the input file and the binary code and generate the RESTful request . In another example the work order RESTful frontend may accept from a client application on the customer computer an API message specifying the RESTful request . In either case the user of the customer computer need not design or format the RESTful request manually.

The RESTful request can include one or more object references that reference an object . The object may be any type of data object associated with the RESTful request including the input file and the binary code . The customer computer can send the object to the central storage for example before submission of the RESTful request to the work order RESTful frontend .

The work order RESTful frontend can validate and convert the RESTful request into a global level work order and transmit the global level work order to the global level manager . The global level work order can for example contain the object reference from the RESTful request but have removed identifying information that specifies the real identity or financial information of the user of the customer computer . Instead the global level work order may contain for example unique anonymized user identification information.

The global level manager can split the global level work order into one or more cluster level jobs for processing by the cluster level managers . The cluster level job may also contain the object reference from the global level job and the RESTful request .

The cluster level manager can receive a cluster level job and identify the object from the object reference as required for processing the global level job . The cluster level manager can request and receive the object from the central storage .

The customer computer can generate a work order . For example the customer computer may collect or create the input file and the binary code and use them to generate a work order according to one or more specifications published by for example the work order RESTful frontend .

The central storage can receive and store the data object . For example the customer computer can send the binary code or the input file to the central storage as the object or as more than one object. The central storage can accept and store the object and return to the customer computer an object reference that describes the location of the object in the central storage .

The work order RESTful frontend can receive from the client computer a work order containing the reference to the data object . For example upon completion of transfer of the object to the central storage the customer computer can send the RESTful request to the work order RESTful frontend . The work order RESTful frontend can verify the account of the user of the customer computer transact any financial actions associated with the RESTful request and generate the global level work order from the RESTful request .

The global level manager can partition the work order and assign the job to a plurality of clusters for processing . For example after reception of the global level work order the global level manager can identify a group of clusters available to process portions of the global level work order . The global level manager can partition the global level work order into cluster level work order orders that can specify which processes in the global level work order are to be performed by each cluster and can include the object reference for input to the processes.

A cluster level manager in each cluster can receive the job with the object reference and can fetch the data object from the central storage system . For example the cluster level manager can parse the cluster level job to identify the object reference and can request the object from the central storage . When received the cluster level manager can store the object in the cluster s cluster cache so that it is available to the cluster s task level manager .

When the task level manager receives the binary code it is validated by validator as it is loaded into a native client . If validator determines that the binary code is not compliant with a set of validation rules the binary code is rejected and hence not executed . Otherwise if binary code passes validation it can be safely executed in the native client . During execution native client provides a very limited interface between the binary code and other software entities and hardware resources moderating all external requests made by binary code as well as the way in which these requests are made .

In some implementations the system allows safe execution of the binary code in the form of an x86 binary code module in the cluster thereby enabling the binary code to serve as an application component that can achieve native performance but is structurally constrained from accessing many of the components of the cluster . Although the following description uses the Intel x86 processor architecture the techniques described are not limited to this architecture and can be applied to a wide range of processor and or hardware architectures e.g. the PowerPC and ARM architectures .

Note that the described system may simultaneously address both performance and portability issues while eliminating security risks thereby allowing developers to use portable untrusted native code modules in their applications without requiring application users to risk the security of their devices and or data.

In some implementations the system includes a modified compilation chain that includes a modified compiler assembler and linker that are used to generate safe compliant executable program binaries a loader validator that loads the module into memory and confirms that the untrusted module is compliant with a set of code and control flow integrity requirements and a runtime environment that provides data integrity and moderates both the module s ability to access resources and how the module accesses such resources. The compilation and validation processes ensure that unwanted side effects and communications are disabled for the untrusted module while the secure runtime environment provides a moderated facility through which a limited set of desirable communications and resource accesses can safely occur. These components are described in more detail in the following sections.

In some implementations complementary compilation and validation processes ensure that only safe native code modules are created and loaded into the system. The compilation process involves using a compiler an assembler and a linker which work together to generate a system compliant binary native code module. The validator loads this native code module into memory and confirms that the native code module is indeed system compliant. Note that validating the compiled module at load time as the last action prior to execution allows the system to use but not trust the output of the compiler. Such validation can also detect any malicious actions that attempt to compromise the safety of the native code module between compilation and execution.

Note that the system can use a combination of compiler based techniques and static binary analysis e.g. analysis of assembly code during validation to achieve safety with lower execution overhead than dynamically analyzing and rewriting executable code at runtime as is commonly done in some virtual machine environments . Additionally static binary analysis facilitates implementing the validator and runtime environment in a small trusted code base thereby facilitating security verification for the code base and reducing the likelihood of bugs and or vulnerabilities. In some embodiments however the system may also use dynamic analysis and code rewriting techniques.

In some implementations creating a system compliant native code module involves following a set of restrictions and or policies that preserve the integrity and security of code control flow and data. Preserving code integrity involves ensuring that only safe instructions can be executed by the native code module and that no unsafe instructions can be inserted at runtime via dynamic code generation or self modifying code. Restricting the instruction set which is available to the native code module also can help to make decoding the native code module during validation more reliable. Preserving control flow integrity involves ensuring that control flow instructions in the native code module cannot violate security by calling instructions outside of the native code module. Preserving data integrity involves ensuring that a native code module cannot perform wild reads or wild writes e.g. reads or writes outside of a specified data region associated with the native code module .

In some implementations the validator helps to achieve code control flow and data integrity for an x86 native code module in part by ensuring that a set of unsafe instructions from the x86 ISA instruction set architecture are not included in a native code module. For instance the validator may disallow the use of the following instructions and or features in a native code module 

Furthermore to provide effective code discovery and control integrity the system also restricts a set of control transfer instructions. Specifically unmodified indirect control flow instructions that can transfer execution to arbitrary locations in memory need to be modified to guarantee that all indirect control flow targets are in memory regions that are valid for the native code module. Some implementations can limit indirect control flow instructions by 1 not allowing return far call and far jump instructions 2 ensuring that call and jump imp instructions only use relative addressing and are encoded in a sequence of instructions such that the control flow remains within the native code module 3 ensuring that register indirect call and jump instructions are encoded in a sequence of instructions such that the control flow remains within the native code module and targets valid instruction addresses within the module and 4 not allowing other indirect calls and jumps.

Cluster hardware includes any hardware such as the facility used to create the cluster . A cluster operating system is the operating system and support systems that among other tasks facilitate communication between cluster level entities . The cluster level entities include the cluster level manager the task level manager the cluster cache the data distribution service and any other cluster entity that communicates relatively freely inside the cluster . It will be understood that communications between cluster level systems may be subject to a range of security restrictions encryption logging etc.

The workers by way of comparison execute in native clients and are subject to tight control on available input and output . The native clients are sandboxes created by the task level managers and provide execution space and limited communications functionality to the workers . The workers are instances of executing processes created by the binary code supplied by the customers of the system . In some implementations the native clients are light weight computational structures that require less resource overhead than for example virtual machines which also emulate processors random access memory and full network stacks.

The input and output channels available to the workers can be limited to basic file operations and socket functionality to allow the workers to access the input data and to write the output data . In some implementations the file access interface can be a subset of the UNIX file API and the socket API can be the UNIX socket API. The subset of the UNIX file API can be limited to only the OPEN READ and WRITE functions.

To the workers the input and output are presented as oriented communication channels that is input is only for receiving data and output is only for sending data that permit the transmission of structured serialized data. The structure required by the native clients can be specified in one or more frameworks that are required for compiling the input binary .

Input and output between the cluster operating system and thus any cluster level system and the native client pass through a secure remote procedure call secure RPC layer . The secure RPC layer can perform policy checking and other security functions to ensure that the workers only have access to read the input and write the output . For example any secure RPC read call specifying a memory value or name space not containing the input data associated with the worker 1 can be denied.

The native clients the secure RPC layer and the cluster operating system can all share the same file descriptors and namespace for the input data and the output data . The native client can provide the file descriptors to the worker upon request. As such the only source for valid file descriptors available to the worker is the native client . In some implementations the worker can request many input or output file descriptors when it begins processing a job append data to the end of the output files and then close the files before terminating. The use of native clients for sandboxing as opposed to for example virtual machines permits use of worker that have been designed and programmed using imperative algorithms. Once the file descriptors is provided to the worker the worker can actively request the file if and when it is needed it does not need to wait to request the file.

In some examples the worker 1 and the worker 2 may be created from binary code from two different clients. In such a case the worker 1 and the worker 2 are unable to access the same input data each is restricted to only the input data supplied by the same client for the same work order. In some other examples the worker 1 and the worker 2 may be associated with the same client and the same work order. In this case both the worker 1 and the worker 2 may be able to access at least some of the same input data .

In some implementations the policy checking that the secure RPC layer performs can be specified by or performed by a third party or a software system provided by a third party . For example a third party regulatory or trusted computing authority may be entrusted with creating or adding to the functionality of the secure RPC layer in order to provide extra assurance to customers or ensure compliance with legal requirements. Additionally or alternatively the customer that supplied the binary code used to create the worker may add to or specify the behavior of the secure RPC layer .

In some implementations of the system virtual machines may be used in place of the native clients . Some of the features of the virtual machine may be disabled for example to reduce computational requirements of the virtual machine and or to prevent access by the workers .

Three classes of SLAs may be used with the system in the examples discussed here. A high priority class SLA may have the most desirable features a low priority class SLA may have mid tier features and a best effort class SLA may have the least desirable features and may be used in contracts with the lowest payments.

An order completion range feature can describe a general timeframe for completion of a submitted work order. In general high priority class SLAs may be completed in hours and may be appropriate for same day needs. For example a banking institution may use a high priority class SLA for work order to be completed in the same day. A low priority class SLA may be completed in one or more days. The day long time frame may allow the system to take advantage of day cycle usage patterns to schedule processing of jobs during the night time when usage and power costs are low. For example a logistics firm may use a low priority SLA for traffic simulation to determine congestion caused by proposed road repairs. A best effort class SLA may be completed as so called best effort that is processed as system resources become available and are not is use with another higher priority work order. For example a researcher or hobbyist may use a best effort SLA for any project in which funding is limited but time to delivery is flexible.

A high priority class SLA may have the most desirable features and may be used in contracts with the highest payments. A low priority class SLA may have mid tier features and may be used in contracts with mid tier payments. A best effort class SLA may have the least desirable features and may be used in contracts with the lowest payments.

The global level manager can monitor the resources available to the system and adjust offered prices accordingly either in real time or on a fixed or variable schedule. For example the global level manager may increase or reduce price offers in real time for the high priority class SLAs according to the current availability of computational resources and short term usage predictions e.g. on the order of hours . For low priority class SLAs short term usage predictions e.g. on the order of a day or a week may also be factored to set the low priority class SLA prices. For best effort class SLAs long term usage predictions may be used to determine best effort SLA prices.

External and network factors may also be used to set price for SLAs. For example electrical power in one facility location may be cheaper than for the facility closest to the client or the farther facility may be projected to have more idle cycles. The price of electricity and the price of bandwidth may both be incorporated in the price offered for all levels of SLA.

Different service levels can have different processes for meeting assurance levels. For example high priority class SLA jobs may be assigned a higher priority value in the system and may kill lower priority jobs e.g. from low priority class and best effort class SLAs that are using resources that could be used for the high priority jobs. Additionally the system may include some dedicated computational resources to be used primarily or exclusively to fulfill high priority class SLA jobs. It will be noted however that other processes that use the facilities may have higher priority values than the high priority class SLA jobs.

Low priority class SLA job may be assigned a mid priority value in the system and may kill lower priority jobs e.g. from best effort class SLAs that are using resources that could be used for the mid priority jobs. The best effort class SLA jobs being best effort may not have any rate increasing techniques.

Killed jobs those killed by rate increasing techniques as well as those that die due to other factors such as hardware failure can be monitored by the task level managers . The task level managers can be configured to detect and report job death substantially immediately as opposed to for example waiting until a job times out and assuming the job was killed. In the case of a detected job death the task level manager restarts the job immediately or as soon as computational resources is available. Additionally or alternatively the cluster level manger or the global level manager may determine a different task level manager or cluster may be able to restart the killed job and may reassign to the available resource.

As the jobs progress the task level manager can monitor the job progress and report upward to the cluster level manager who in turn can report up to the global level manager . These reports can be organized and summarized by the global level manager for use by the system or client that submitted the work order. One feature of the report is an indication of remaining balance in a customer s account for work order that are billed per cycle or per process. As the customer s balance reduces the customer can be alerted for example to avoid a surprisingly large bill to the customer. This report can protect the customer against poorly designed implemented or configured code that requires more processing than the customer expected. This reporting can be done in real time or on a routine e.g. daily .

Another use of the reports is to enable monitoring of the rate of completion of jobs versus SLA described deadlines. If a job is being processed too slowly to meet the deadline the global level manager can use one or more rate increasing techniques to increase the process throughput of the job in order to meet the deadline.

work order parameters associated with a work order request are received . For example a client may supply the information about the input file binary code price request completion deadline or other factors to the global level manager . The global level manager may catalog and categorize the supplied data into standard format to describe the work order request. Network metrics that describe computational resource availability are collected . For example the global level manager may access or calculate resource availability and predictions that describe the current and future state of resources that may be used to process the work order.

A service level agreement is calculated to meet the work order parameters . For example the global level manager can calculate SLA features such as a deadline and class that meet the customer parameters given the current and projected state of computational resources. A service level price is calculated to meet the work order parameters . For example the global level manager can calculate based in part on the scarcity of computational resources and the class of the SLA a price to offer to the customer. In some implementations the price can be presented to the customer with the option to change one or more work order parameters in order to generate a new price.

The needed process throughput is then calculated . For example the global level manager can calculate a process throughput that defines the rate at which the customer s work order must be processed in order to meet the deadline. In some implementations the process throughput may be a constant rate. For example for a process with a deadline of twenty minutes the process throughput may be calculated as one twentieth per minute. In some implementations the process throughput may be variable. For example for a low priority class SLA the process throughput may vary based on time of day or week such that more processes are expected to be performed at night or on the weekend.

If the job is a best effort job the job is submitted for processing without throughput monitoring . For example the work order can be broken into jobs and distributed by the global level manager to the cluster level managers and then to the task level mangers for completion. Process throughput may not be monitored but if a job is assigned to a task level manger without progress over a specified time period the cluster level manger or the global level manager may reassign the job to a different task level manger .

If the job is not a best effort job the job is submitted for processing with throughput monitoring . For example the work order can be broken into jobs and distributed by the global level manager to the cluster level managers and then to the task level mangers for completion. The global level manager can monitor the rate of job completion as reported by the cluster level managers based on information from the task level managers .

If the process is proceeding at less than the calculated process throughput and the job is a low priority job a lower priority job is halted so that computational resources associated with the lower priority job become available for processing the job. For example task level manager may kill a worker associated with a best effort class SLA and generate a worker for the low priority job.

If the process is proceeding at less than the calculated process throughput and the jobs is a low priority job a series of operations may be undertaken to increase the process throughput. For example the task level manager may first kill best effort jobs and then low priority jobs to free up computational resources for the high priority job. If these actions do not free up enough computational resources the cluster level manager or the global level manager may reassign the work order to dedicated computational resources that are only used or primarily used for ensuring the system is able to meet high priority jobs.

If the process proceeds at the calculated process throughput or greater the job completes by the deadline . For example the task level managers can submit output data to the central storage . The completion is reported and output data is offered . For example an alert can be sent to the customer by the system in the form of an email text message API message or other format. The alert can include a link for downloading the output or for storing the output in another system

The memory stores information within the computing system . In some implementations the memory is a computer readable medium. In some implementations the memory is a volatile memory unit. In some implementations the memory is a non volatile memory unit.

The storage device is capable of providing mass storage for the computing system . In some implementations the storage device is a computer readable medium. In various different implementations the storage device may be a floppy disk device a hard disk device an optical disk device or a tape device.

The input output device provides input output operations for the computing system . In some implementations the input output device includes a keyboard and or pointing device. In some implementations the input output device includes a display unit for displaying graphical user interfaces.

Some features described can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The apparatus can be implemented in a computer program product tangibly embodied in an information carrier e.g. in a machine readable storage device for execution by a programmable processor and method steps can be performed by a programmable processor executing a program of instructions to perform functions of the described implementations by operating on input data and generating output. The described features can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that can be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer will also include or be operatively coupled to communicate with one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM erasable programmable read only memory EEPROM electrically erasable programmable read only memory and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM compact disc read only memory and DVD ROM digital versatile disc read only memory disks. The processor and the memory can be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with a user some features can be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user can provide input to the computer.

Some features can be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system can be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include e.g. a LAN local area network a WAN wide area network and the computers and networks forming the Internet.

The computer system can include clients and servers. A client and server are generally remote from each other and typically interact through a network such as the described one. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

Although a few implementations have been described in detail above other modifications are possible. For example while a client application is described as accessing the delegate s in other implementations the delegate s may be employed by other applications implemented by one or more processors such as an application executing on one or more servers. In addition the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other actions may be provided or actions may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other implementations are within the scope of the following claims.

