---

title: Devices, systems, and methods for monitoring and asserting trust level using persistent trust log
abstract: Devices, systems, and methods for monitoring and asserting a trust level of a computing device are disclosed. In one illustrative embodiment, a computing device may include a memory having stored therein a persistent trust log, the persistent trust log comprising data relating to historic events influencing a trust level of the computing device, and a security controller configured to detect an event that influences the trust level of the computing device and to write data relating to the event to the persistent trust log.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09177129&OS=09177129&RS=09177129
owner: Intel Corporation
number: 09177129
owner_city: Santa Clara
owner_country: US
publication_date: 20120627
---
The trust level of a computing device e.g. a personal computer a workstation a laptop computer a handheld computer a mobile internet device a cellular phone a personal data assistant a telephony device a network appliance a virtualization device a storage controller or other computer based device may be a decision criterion for allowing the computing device to participate in various activities and or transactions. By way of illustrative example the trust level of a computing device may be a factor in determining whether to allow the computing device to process and or store sensitive data e.g. corporate records or whether to allow the computing device to execute sensitive transactions e.g. financial transactions . It will be appreciated that the trust level of a computing device may be relevant to many other types of activities and or transactions.

Many events that a computing device participates in over its lifecycle may influence the trust level of the computing device. For instance a new smart phone that has just been unboxed will have a higher trust level than a three year old smart phone that has been jailbroken i.e. a process allowing a user access to system resources and or privileges not intended by the smart phone developer restored multiple times and had several applications from untrustworthy sources installed. Malicious software may attempt to hide events that negatively influence the trust level of a computing device e.g. jailbreaking and to misrepresent the trust level of the computing device as high.

While the concepts of the present disclosure are susceptible to various modifications and alternative forms specific embodiments thereof have been shown by way of example in the drawings and will herein be described in detail. It should be understood however that there is no intent to limit the concepts of the present disclosure to the particular forms disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives consistent with the present disclosure and the appended claims.

In the following description numerous specific details such as logic implementations opcodes means to specify operands resource partitioning sharing duplication implementations types and interrelationships of system components and logic partitioning integration choices are set forth in order to provide a more thorough understanding of the present disclosure. It will be appreciated by one skilled in the art however that embodiments of the disclosure may be practiced without such specific details. In other instances control structures gate level circuits and full software instruction sequences have not been shown in detail in order not to obscure the description of the concepts described herein. Those of ordinary skill in the art with the included descriptions will be able to implement appropriate functionality without undue experimentation.

References in the specification to one embodiment an embodiment an example embodiment etcetera indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may not necessarily include the particular feature structure or characteristic. Moreover such phrases are not necessarily referring to the same embodiment. Further when a particular feature structure or characteristic is described in connection with an embodiment it is submitted that it is within the knowledge of one skilled in the art to effect such feature structure or characteristic in connection with other embodiments whether or not explicitly described.

Embodiments of the concepts described herein may be implemented in hardware firmware software or any combination thereof. Embodiments implemented in a computing device may include one or more point to point or bus based interconnects between components. Embodiments of the concepts described herein may also be implemented as instructions carried by or stored on one or more machine readable or computer readable storage media which may be read and executed by one or more processors or controllers. A machine readable or computer readable storage medium may be embodied as any device mechanism or physical structure for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable or computer readable storage medium may be embodied as read only memory ROM device s random access memory RAM device s magnetic disk storage media optical storage media flash memory devices mini or micro SD cards memory sticks and others.

In the drawings specific arrangements or orderings of schematic elements such as those representing devices modules instruction blocks and data elements may be shown for ease of description. However it should be understood by those skilled in the art that the specific ordering or arrangement of the schematic elements in the drawings is not meant to imply that a particular order or sequence of processing or separation of processes is required. Further the inclusion of a schematic element in a drawing is not meant to imply that such element is required in all embodiments or that the features represented by such element may not be included in or combined with other elements in some embodiments.

In general schematic elements used to represent instruction blocks may be implemented using any suitable form of machine readable instruction such as software or firmware applications programs functions modules routines processes procedures plug ins applets widgets code fragments and or others and that each such instruction may be implemented using any suitable programming language library application programming interface API and or other software development tools. For example some embodiments may be implemented using Java C and or other programming languages. Similarly schematic elements used to represent data or information may be implemented using any suitable electronic arrangement or structure such as a register data store table record array index hash map tree list graph file of any file type folder directory database and or others.

Further in the drawings where connecting elements such as solid or dashed lines or arrows are used to illustrate a connection relationship or association between or among two or more other schematic elements the absence of any such connecting elements is not meant to imply that no connection relationship or association can exist. In other words some connections relationships or associations between elements may not be shown in the drawings so as not to obscure the disclosure. In addition for ease of illustration a single connecting element may be used to represent multiple connections relationships or associations between elements. For example where a connecting element represents a communication of signals data or instructions it should be understood by those skilled in the art that such element may represent one or multiple signal paths e.g. a bus as may be needed to effect the communication.

The present disclosure relates to devices systems and methods for monitoring and asserting a trust level of a computing device using a persistent trust log. As used herein the term persistent refers to data that is maintained even when a computing device is re imaged with a new software stack. The presently disclosed devices systems and methods utilize a security engine e.g. a security controller of a computing device to monitor the trust level of the computing device by storing data relating to events that influence the trust level in a persistent trust log. The use of the security engine and the persistent trust log advantageously provides a tamper resistant mechanism for monitoring the trust level of the computing device that may not be manipulated by low level malicious software e.g. kernel mode rootkits or software re imaging.

The presently disclosed devices systems and methods may also utilize the security engine and the persistent trust log to assert the trust level of the computing device when requested by an external service. By analyzing data stored in the persistent trust log the security engine may generate a trust assessment which may be used by the external service as a decision criterion for allowing the computing device to participate in various activities and or transactions. Advantageously the trust assessment generated by the security engine may be responsive to one or more criteria provided by the external service. Furthermore the trust assessment generated by the security engine may provide a secure mechanism for asserting the trust level of the computing device without revealing to an external service the events underlying the trust assessment i.e. the data stored in the persistent trust log which may be sensitive from a privacy and or security perspective.

Referring now to one illustrative embodiment of a system for monitoring and asserting a trust level of a computing device using a persistent trust log is shown as a simplified block diagram. The system includes the computing device one or more servers and a network communicatively coupling the computing device and the one or more servers . It is contemplated that the computing device may communicate with any number of servers as part of the system . In some embodiments the computing device and the one or more servers may be remote from one another e.g. located in different rooms buildings cities states or countries . The network may be embodied as any type of wired and or wireless network such as a local area network a wide area network a publicly available global network e.g. the Internet or other network. The network may include any number of additional devices to facilitate communications between the computing device and the one or more servers such as routers switches intervening computers and the like.

The computing device may be embodied as any type of electronic device capable of performing the functions described herein. By way of example the computing device may be embodied as a personal computer a workstation a laptop computer a handheld computer a mobile internet device a cellular phone a personal data assistant a telephony device a network appliance a virtualization device a storage controller or other computer based device. In the illustrative embodiment shown in the computing device includes a processor an input putput I O subsystem a system memory communications circuitry a security controller and a dedicated memory . As shown in phantom in the computing device may also optionally include one or more data storage devices and one or more peripheral devices . It will be appreciated that in some embodiments the computing device may not include all of the foregoing components. Furthermore it should be appreciated that the computing device may include other components sub components and devices commonly found in a computer and or computing device which are not illustrated in for clarity of the description.

The processor of the computing device may be any type of processor capable of executing software firmware such as a microprocessor digital signal processor microcontroller or the like. The processor functions as a primary processor or central processing unit of the computing device and is generally responsible for executing a software stack which may include a host operating system and various applications programs libraries and drivers resident on the computing device . As shown in the processor is illustratively embodied as a single core processor having a processor core . However in other embodiments the processor may be embodied as a multi core processor having multiple processor cores . Furthermore the computing device may include additional processors having one or more processor cores .

The processor is communicatively coupled to the I O subsystem via a number of signal paths. These signal paths and other signal paths illustrated in may be embodied as any type of signal paths capable of facilitating communication between the components of the computing device . For example the signal paths may be embodied as any number of wires cables light guides printed circuit board traces via bus intervening devices and or the like. The I O subsystem of the computing device may be embodied as circuitry and or components to facilitate input output operations with the processor and or other components of the computing device . In some embodiments the I O subsystem may be embodied as a memory controller hub MCH or northbridge an input output controller hub ICH or southbridge and a firmware device. In other embodiments I O subsystems having other configurations may be used. For example in some embodiments the I O subsystem may be embodied as a platform controller hub PCH . In such embodiments the memory controller hub MCH may be incorporated in or otherwise associated with the processor and the processor may communicate directly with the system memory as shown by the hashed line in . In still other embodiments the I O subsystem may form a portion of a system on a chip SoC and be incorporated along with the processor and other components of the computing device on a single integrated circuit chip.

The system memory of the computing device is also communicatively coupled to the I O subsystem via a number of signal paths. The system memory may be embodied as one or more memory devices or data storage locations including for example dynamic random access memory devices DRAM synchronous dynamic random access memory devices SDRAM double data rate synchronous dynamic random access memory device DDR SDRAM flash memory devices and or other volatile memory devices. Additionally although only a single system memory device is illustrated in in other embodiments the computing device may include additional system memory devices. In some embodiments the system memory may be utilized as a shared memory that is accessible to additional processors of the computing device such as the security controller by way of example .

The communications circuitry of computing device may be embodied as any number of devices and circuitry for enabling communications between the computing device and the network . The communications circuitry may include one or more wired and or wireless network interfaces to facilitate communications over the wired and or wireless portions of the network . The communications circuitry is communicatively coupled to the I O subsystem via a number of signal paths.

The computing device also includes a security controller which is distinct from and may operate independently of the processor . The security controller may be embodied as any type of processor capable of executing software firmware such as a microprocessor digital signal processor microcontroller or the like including one or more processors having one or more processor cores not shown . In the illustrative embodiment of the security controller is embodied as one or more separate integrated circuits that are communicatively coupled to the I O subsystem via a number of signal paths. In other embodiments the security controller may be integrated into the I O subsystem . The security controller may communicate with various components of the computing device via the I O subsystem . Additionally or alternatively the security controller may independently communicate with various components of the computing device e.g. the system memory and the communication circuitry via a number of signal paths as shown in phantom in . In the illustrative embodiment the security controller is also communicatively coupled to a dedicated memory that is accessible only to the security controller . In some embodiments the dedicated memory may be incorporated in the security controller .

The security controller may be configured for managing particular functions of the computing device irrespective of the operational state of the processor or of the host operating system of the computing device . To facilitate such independent operation the security controller may be provided with an independent connection to the power circuitry not shown of the computing device allowing the security controller to retain power even when other components of the computing device are powered down or turned off. Furthermore the security controller may be provided with one or more independent network interfaces via communication circuitry which is also provided with an independent connection to the power circuitry not shown allowing out of band communications over the network . In other words the security controller is able to communicate directly with devices on the network e.g. the one or more servers with or without the host operating system executing on the processor . In summary the security controller may operate intelligently based on incoming requests commands and communicate across the network whether the processor is turned off running on standby being initialized or in regular operation and whether the host operating system is booting running crashed or otherwise. In some illustrative embodiments the security controller may be implemented using an Intel Management Engine available from Intel Corporation of Santa Clara Calif. and or within chipsets sold by Intel Corporation.

In some embodiments the computing device may optionally include one or more data storage devices . The data storage device s may be embodied as any type of devices configured for the short term or long term storage of data such as for example memory devices and circuits memory cards hard disk drives solid state drives or other data storage devices. Each of the data storage device s may be communicatively coupled to the I O subsystem via a number of signal paths allowing the I O subsystem to receive inputs from and send outputs to the data storage device s .

The computing device may also optionally include one or more peripheral devices . The peripheral device s may illustratively include a display a touchpad a touchscreen a keyboard a mouse a microphone and or one or more external speakers among other peripheral devices. The particular number and type of devices included in the peripheral device s of the computing device may depend upon for example the intended use of the computing device e.g. as a desktop computing device or a mobile computing device . Each of the peripheral device s may be communicatively coupled to the I O subsystem via a number of signal paths allowing the I O subsystem to receive inputs from and send outputs to the peripheral device s .

Referring now to one illustrative embodiment of an environment of the system is shown as a simplified block diagram. As discussed above the system includes the computing device and one or more servers communicatively coupled to one another via a network . The computing device includes a host operating system executing on the processor a security engine and a persistent trust log . The one or more servers may include an external service utilized by the computing device a trust profile and in some embodiments a trust level database . The external service the trust profile and the trust level database may reside on the same server or on multiple servers including but not limited to the external service being executed on one server the trust profile being stored on another server and the trust level database being stored on yet another server .

The security engine of the computing device may be embodied as any number of hardware components firmware components and or software components. For instance in some illustrative embodiments such as that shown in the security engine may be embodied as a security controller e.g. a microprocessor a digital signal processor a microcontroller or the like of the computing device . In other illustrative embodiments the security engine may be embodied as one or more firmware and or software modules that are executed by the processor and or the I O subsystem of the computing device as a secure execution environment. As shown in the security engine of the computing device may communicate with the one or more servers over the network by sending and receiving data via the host operating system . In some embodiments the security engine may additionally or alternatively communicate with the one or more servers over the network using out of band communications as indicated in phantom in . As will be further described below with reference to the security engine may operate to monitor and or assert a trust level of the computing device .

The computing device further includes a persistent trust log which may be implemented using any suitable electronic data structure or arrangement such as a register data store table record array index hash map tree list graph file of any file type folder directory database or the like. In the illustrative embodiment the persistent trust log comprises data relating to historic events that influence the trust level of the computing device . By way of illustrative example the persistent trust log may include data relating to applications installed on the computing device networks to which the computing device was connected websites accessed by the computing device and other actions performed on or with the computing device e.g. jailbreaks . As will be further described below with reference to the security engine may write data relating to such events to the persistent trust log . In some embodiments the data stored in the persistent trust log may be modifiable only by the security engine . For instance the persistent trust log may be stored on a dedicated memory that is accessible only to the security engine . In other embodiments the persistent trust log may be stored on a portion of the system memory or a data storage device that may only be written to only by the security engine .

The host operating system of the computing device or an application running thereon may seek to interact with an external service executing on the one or more servers . By way of illustrative example the host operating system may request data e.g. corporate records from an enterprise rights management service . Before allowing access to any sensitive data the external service may desire to assess the trust level of the computing device . As will be further described below with reference to the external service may interact with the security engine to obtain a trust assessment representing the trust level of the computing device . In some embodiments the external service may provide a trust profile to the security engine that includes one or more criteria for generating the trust assessment e.g. whether the computing device has ever been jailbroken . The trust profile may include criteria specific to the external service requesting the trust assessment. In other embodiments the trust profile may include industry standard criteria for the type of external service e.g. a banking trust profile including one or more criteria relating to the trust level required of the computing device to participate in financial transactions . In some embodiments the one or more servers may also store a trust level database that may be accessed by the security engine over the network . The trust level database may include information regarding how one or more events might influence the trust level of the computing device e.g. the impact of installing a particular application on the trust level of the computing device .

Referring now to one illustrative embodiment of a method for monitoring the trust level of the computing device is shown as a simplified flow diagram. In the illustrative embodiment the method may be executed by the security engine of the computing device in conjunction with one or more other components of the computing device . The method is illustrated as a number of blocks in . Blocks may be optionally employed in some embodiments of the method and are therefore indicated in phantom in .

The method begins with block in which the security engine detects an event that influences the trust level of the computing device . By way of illustrative example the security engine may detect in block that a particular application has been installed on the computing device that the computing device has been connected to a particular network that the computing device has accessed a particular website or that some other action has been performed on or with the computing device e.g. a jailbreak . In some embodiments the security engine may actively monitor the other components of the computing device e.g. the host operating system the communications circuitry etc. and directly detect the event influencing the trust level of the computing device . It is also contemplated that the security engine may be informed of such an event by another component of the computing device in block .

After block the method proceeds to block in which the security engine writes data relating to the event detected in block to the persistent trust log . For instance the security engine may write data regarding the type of event Application X Installed Connected to Network Y Accessed Dangerous Site Z Jailbreak Detected etc. the date and time of the event and or other information relating to the event to the persistent trust log . Block may be performed each time an event that influences the trust level of the computing device is detected in block . As such the persistent trust log comprises a record of the historic events that influence the trust level of the computing device .

In some embodiments block of the method may involve block in which the security engine digitally signs the data written to the persistent trust log using a private key. This private key is known only to the security engine and thus block provides a mechanism for later confirming the authenticity of data stored in the persistent trust log i.e. a mechanism for later determining whether data stored in the persistent trust log was written to the persistent trust log by the security engine . In other embodiments block of the method may involve block in which the security engine encrypts the data written to the persistent trust log using the private key. Again this private key is known only to the security engine and thus block prevents other components of the computer device from being able to read the data stored in the persistent trust log .

After block the method may optionally proceed to block in which the security engine compresses the persistent trust log . This compression may allow the security engine to limit the amount of memory space needed for the persistent trust log over the lifecycle of the device. The security engine may compress the persistent trust log by replacing a portion of the data in the persistent trust log with a variable summarizing that portion of the data. In some embodiments this variable may be a quantitative value e.g. 1 10 representing the overall trust level of the summarized data. In other embodiments this variable may be a qualitative descriptor e.g. high medium low representing the overall trust level of the summarized data. By way of illustrative example the security engine may maintain the previous six months of data in full detail while summarizing all older data into an overall trust level variable. It will be appreciated that where employed block may be performed as frequently or infrequently as desired to limit the amount of memory space needed to store the persistent trust log .

Referring now to one illustrative embodiment of a method for asserting the trust level of the computing device is shown as a simplified flow diagram. In the illustrative embodiment the method may be executed by the security engine of the computing device in conjunction with one or more other components of the computing device . The method is illustrated as a number of blocks in . Blocks and blocks may be optionally employed in some embodiments of the method and are therefore indicated in phantom in .

The method begins with block in which the security engine receives a trust assessment request originating from an external service . As discussed above an external service may desire to assess the trust level of a computing device before allowing the computing device to perform some activity and or transaction with the external service . In such situations the external service may transmit a trust assessment request to the security engine either directly or via the host operating system . In some embodiments block may involve block in which the security engine receives a trust profile from the external service along with the trust assessment request. The trust profile may include one or more criteria to be used by the security engine when generating the trust assessment. In some embodiments block may also involve block in which the security engine receives an identity credential from the external service along with the trust assessment request. This identity credential may be used by the security engine to confirm the identity of the external service requesting the trust assessment.

After block the method may optionally proceed to block in which the security engine determines whether to respond to the trust assessment request received in block . In some embodiments of block the security engine may evaluate the identity credential received in block to determine whether to respond to the trust assessment request. For instance if the security engine does not trust the external service or does not otherwise wish to provide a trust assessment to the external service the method may be aborted in block . In other embodiments of block the security engine may evaluate whether providing the trust assessment to the external service would reveal the historic events influencing the trust level of the computing device in an undesirable manner . For instance if generating a trust assessment using the trust profile received in block would compromise the privacy or security of a user of the computing device the method may be aborted in block . It is contemplated that block may be optionally performed by the security engine at any time prior to transmitting the trust assessment to the external service i.e. block of the method including after generating the trust assessment in block .

After block or where employed after block the method proceeds to block in which the security engine generates a trust assessment by analyzing data stored in the persistent trust log . During block the security engine may map the data stored in the persistent trust log to the criteria defining the trust assessment. In the illustrative embodiment the security engine generates a trust assessment that represents the trust level of the computing device but does not reveal the particular historic events influencing the trust level of the computing device . For instance the trust assessment generated in block may be a quantitative value e.g. 1 10 representing the overall trust level of the computing device . In other embodiments the trust assessment generated in block may be a qualitative descriptor e.g. high medium low representing the overall trust level of the computing device . As described below the security engine may perform one or more of blocks when generating the trust assessment in block .

In some embodiments block of the method may involve block in which the security engine evaluates a digital signature to determine whether the data was written to the persistent trust log by the security engine . As discussed above when writing data to the persistent trust log in block of the method the security engine may digitally sign or encrypt the data using a private key. In block of the method the security engine may use this private key to evaluate the digital signature on the data stored in the persistent trust log . If the digital signature corresponds to the private key of the security engine after suitable processing the security engine may confirm that the data stored in the persistent trust log was in fact written to the persistent trust log by the security engine .

In other embodiments block of the method may involve block in which the security engine evaluates the data stored in the persistent trust log using one or more criteria included in a trust profile received from the external service originating the trust assessment request. As discussed above block may involve the security engine mapping data stored in the persistent trust log to criteria defining the trust assessment. Where a trust profile is received from the external service in block the one or more criteria included in the trust profile may be used as the criteria for analyzing the data stored in the persistent trust log in block . Block may allow an external service to specify what events should be considered important for a particular trust assessment request via the trust profile .

In still other embodiments block of the method may involve block in which the security engine retrieves information from an external database regarding how one or more of the historic events influence the trust level of the computing device . During block the security engine may set up a secure link with the trust level database to analyze how a particular event recorded in the persistent trust log should impact the trust assessment generated in block . For instance the trust level database may include up to date information on the trustworthiness of various applications networks and websites.

After block the method may optionally proceed to block in which the security engine digitally signs the trust assessment. In some embodiments the security engine may digitally sign the trust assessment with a timestamp in block to ensure that the trust assessment is not used to represent the trust level of the computing device at a later point in time at which point the trust assessment may not be accurate. In other embodiments the security engine may digitally sign the trust assessment with an anonymous attestation credential e.g. an Enhanced Privacy ID in block to prove that the trust assessment was generated by the security engine without revealing the identity of a user of the computing device .

After block or where employed after block the method proceeds to block in which the security engine transmits the trust assessment to the external service originating the trust assessment request. Where the trust assessment is digitally signed in block the external service may use this information to confirm the authenticity of the trust assessment. The external service may then use the trust assessment to determine whether to allow the computing device to perform some activity and or transaction with the external service .

Illustrative examples of the devices systems and methods disclosed herein are provided below. An embodiment of the devices systems and methods may include any one or more and any combination of the examples described below.

In one example a computing device having a trust level may comprise a memory having stored therein a persistent trust log the persistent trust log comprising data relating to historic events influencing the trust level of the computing device and a security controller configured to detect an event that influences the trust level of the computing device and to write data relating to the event to the persistent trust log.

In an example data stored in the persistent trust log may be modifiable only by the security controller. In an example the memory may be a dedicated memory device accessible only to the security controller. In an example the security controller may be further configured to digitally sign the data relating to the event using a private key when writing the data relating to the event to the persistent trust log. In an example the security controller may be further configured to encrypt the data relating to the event using a private key when writing the data relating to the event to the persistent trust log. In an example the security controller may be further configured to compress the persistent trust log by replacing a portion of the data relating to historic events influencing the trust level of the computing device with a variable summarizing the portion of the data.

In an example the security controller may be further configured to analyze data stored in the persistent trust log to generate a trust assessment in response to receiving a trust assessment request. In an example the trust assessment may not reveal the historic events influencing the trust level of the computing device. In an example the security controller may be configured to analyze data stored in the persistent trust log at least in part by evaluating a digital signature to determine whether the data stored in the persistent trust log was written to the persistent trust log by the security controller. In an example the security controller may be configured to analyze data stored in the persistent trust log at least in part by evaluating the data stored in the persistent trust log using one or more criteria included in a trust profile received with the trust assessment request. In an example the security controller may be configured to analyze data stored in the persistent trust log at least in part by retrieving information from an external database regarding how one or more of the historic events influence the trust level of the computing device.

In an example the security controller may be further configured to determine whether to respond to the trust assessment request by evaluating whether the trust assessment would reveal the historic events influencing the trust level of the computing device. In an example the security controller may be further configured to determine whether to respond to the trust assessment request by evaluating an identity credential received with the trust assessment request. In an example the security controller may be further configured to digitally sign the trust assessment with a timestamp prior to transmitting the trust assessment. In an example the security controller may be further configured to digitally sign the trust assessment with an anonymous attestation credential prior to transmitting the trust assessment.

In another example a method for asserting a trust level of a computing device may comprise receiving a trust assessment request originating from an external service generating a trust assessment using a security engine of the computing device by analyzing data stored in a persistent trust log and transmitting the trust assessment to the external service originating the trust assessment request.

In an example the data stored in the persistent trust log may be modifiable only by the security engine. In an example analyzing the data stored in the persistent trust log may comprise evaluating a digital signature to determine whether the data stored in the persistent trust log was written to the persistent trust log by the security engine. In an example analyzing the data stored in the persistent trust log may comprise evaluating the data stored in the persistent trust log using one or more criteria included in a trust profile received from the external service originating the trust assessment request.

In an example the data stored in the persistent trust log may relate to historic events influencing the trust level of the computing device. In an example analyzing the data stored in the persistent trust log may comprise retrieving information from an external database regarding how one or more of the historic events influence the trust level of the computing device. In an example generating the trust assessment using the security engine may comprise generating a trust assessment that does not reveal the historic events influencing the trust level of the computing device.

In an example the method may further comprise determining whether to respond to the trust assessment request prior to transmitting the trust assessment to the external service originating the trust assessment request by evaluating whether the trust assessment would reveal the historic events influencing the trust level of the computing device. In an example the method may further comprise determining whether to respond to the trust assessment request prior to transmitting the trust assessment to the external service originating the trust assessment request by evaluating an identity credential received from the external service originating the trust assessment request.

In an example generating the trust assessment using the security engine may comprise digitally signing the trust assessment with a timestamp prior to transmitting the trust assessment to the external service originating the trust assessment request. In an example generating the trust assessment using the security engine may comprise digitally signing the trust assessment with an anonymous attestation credential prior to transmitting the trust assessment to the external service originating the trust assessment request.

In yet another example a method for monitoring a trust level of a computing device may comprise detecting an event that influences the trust level of the computing device and writing data relating to the event to a persistent trust log using a security engine of the computing device.

In an example data stored in the persistent trust log may be modifiable only by the security engine. In an example writing the data relating to the event to the persistent trust log may comprise digitally signing the data relating to the event using a private key of the security engine. In an example writing the data relating to the event to the persistent trust log may comprise encrypting the data relating to the event using a private key of the security engine. In an example the persistent trust log may comprise data relating to historic events influencing the trust level of the computing device. In an example the method may further comprise compressing the persistent trust log by replacing a portion of the data relating to historic events influencing the trust level of the computing device with a variable summarizing the portion of the data. In an example the method may further comprise asserting the trust level of the computing device using the any of the methods described above.

In one example a computing device having a trust level may comprise a security engine and a memory having stored therein a plurality of instructions that when executed by the security engine cause the computing device to perform any of the methods described above.

In another example one or more machine readable storage media may comprise a plurality of instructions stored thereon that in response to being executed result in a computing device performing any of the methods described above.

While the concepts of the present disclosure have been illustrated and described in detail in the drawings and foregoing description such an illustration and description is to be considered as exemplary and not restrictive in character it being understood that only illustrative embodiments have been shown and described and that all changes and modifications consistent with the disclosure and recited claims are desired to be protected.

