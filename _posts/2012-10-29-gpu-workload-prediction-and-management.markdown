---

title: GPU workload prediction and management
abstract: The disclosed embodiments provide a system that configures a graphics-processing unit (GPU) in a computer system. During operation, the system predicts an incoming workload to the GPU. Next, the system identifies an operational floor for the GPU based on the incoming workload. Finally, the system uses the operational floor to configure the subsequent execution of the GPU, wherein the operational floor facilitates processing of the incoming workload by the GPU.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09196013&OS=09196013&RS=09196013
owner: Apple Inc.
number: 09196013
owner_city: Cupertino
owner_country: US
publication_date: 20121029
---
This application hereby claims priority under 35 U.S.C. 119 to U.S. Provisional Application No. 61 553 735 entitled GPU Workload Prediction and Management by Ian C. Hendry and Anthony G. Sumpter filed on 31 Oct. 2011.

The present embodiments relate to graphics processing units GPUs in computer systems. More specifically the present embodiments relate to techniques for predicting an incoming workload to a GPU and configuring the subsequent execution of the GPU based on the incoming workload.

Power management is critically important for many electronic devices. For example portable electronic devices such as laptop computers mobile phones and personal digital assistants PDAs need to conserve power to operate for any length of time on battery power. At the same time many of these portable electronic devices are beginning to incorporate high resolution high power graphics technology. Rapid developments in this area have led to significant advances in 2D and 3D graphics technology providing users with increasingly sophisticated visual experiences in domains ranging from graphical user interfaces to realistic gaming environments. Underlying many of these improvements is the development of dedicated graphics rendering devices or graphics processing units GPUs . A typical GPU includes a highly parallel structure that efficiently manipulates graphical objects by rapidly performing a series of primitive operations and displaying the resulting images on graphical displays.

To enable efficient graphics processing while reducing power consumption the operating level e.g. operating voltage and or frequency of the GPU may be adjusted based on the workload of the GPU. For example the workload of the GPU may be periodically and or continuously sampled. If the sampled workload is high the GPU s operating level may be increased making the GPU faster but less efficient. Conversely if the sampled workload is low the GPU s operating level may be decreased causing the GPU to execute more slowly but also more efficiently.

Such sampling based power management may cause the GPU s operating level to be adjusted based on the GPU s past workload instead of the GPU s current workload. In turn the delayed response to changes in the workload may reduce GPU performance and or efficiency during the processing of rapidly and or periodically fluctuating workloads. For example sampling of the GPU s workload may take up to 100 milliseconds while adjustment of the GPU s operating level may not be complete until several milliseconds after the GPU s workload has been sampled. As a result the GPU s operating level may be out of sync with workloads that fluctuate every 100 200 milliseconds with an increase in the operating level occurring as the workload decreases and a decrease in the operating level occurring as the workload increases.

Hence what is needed is a mechanism for improving the synchronization of GPU operating levels with GPU workloads.

The disclosed embodiments provide a system that configures a graphics processing unit GPU in a computer system. During operation the system predicts an incoming workload to the GPU. Next the system identifies an operational floor for the GPU based on the incoming workload. Finally the system uses the operational floor to configure the subsequent execution of the GPU wherein the operational floor facilitates processing of the incoming workload by the GPU.

In some embodiments the operational floor is associated with at least one of an operating voltage an operating frequency a memory bandwidth a latency a power gating configuration a cache configuration and a throughput.

In some embodiments using the operational floor to configure the subsequent execution of the GPU involves obtaining an operating level of the GPU and modifying the operating level of the GPU based on at least one of the operational floor an existing workload of the GPU a bottleneck in the GPU a minimum configuration of the GPU an operational ceiling for the GPU and a thermal limit for the GPU.

In some embodiments modifying the operating level of the GPU involves at least one of increasing the operating level based on the existing workload the minimum configuration or the operational floor and decreasing the operating level based on the bottleneck the operational ceiling or the thermal limit.

In some embodiments the operational ceiling and the thermal limit are associated with a higher priority than the existing workload and the operational floor.

In some embodiments the operational ceiling is based on at least one of the thermal limit and a battery runtime associated with the computer system.

The following description is presented to enable any person skilled in the art to make and use the embodiments and is provided in the context of a particular application and its requirements. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art and the general principles defined herein may be applied to other embodiments and applications without departing from the spirit and scope of the present disclosure. Thus the present invention is not limited to the embodiments shown but is to be accorded the widest scope consistent with the principles and features disclosed herein.

The data structures and code described in this detailed description are typically stored on a computer readable storage medium which may be any device or medium that can store code and or data for use by a computer system. The computer readable storage medium includes but is not limited to volatile memory non volatile memory magnetic and optical storage devices such as disk drives CDs compact discs DVDs digital versatile discs or digital video discs or other media capable of storing code and or data now known or later developed.

The methods and processes described in the detailed description section can be embodied as code and or data which can be stored in a computer readable storage medium as described above. When a computer system reads and executes the code and or data stored on the computer readable storage medium the computer system performs the methods and processes embodied as data structures and code and stored within the computer readable storage medium.

Furthermore methods and processes described herein can be included in hardware modules or apparatus. These modules or apparatus may include but are not limited to an application specific integrated circuit ASIC chip a field programmable gate array FPGA a dedicated or shared processor that executes a particular software module or a piece of code at a particular time and or other programmable logic devices now known or later developed. When the hardware modules or apparatus are activated they perform the methods and processes included within them.

The disclosed embodiments provide a method and system for configuring a graphics processing unit GPU in a computer system. The computer system may correspond to a portable electronic device laptop computer personal computer workstation media player and or another electronic device capable of driving a display. The GPU may be a high power discrete GPU that is connected to a motherboard in the computer system through an interface such as Peripheral Component Interconnect Express PCIe . Conversely the GPU may be a low power embedded GPU that is integrated into the motherboard of the computer system.

More specifically the disclosed embodiments provide a method and system for synchronizing the workload of the GPU with the operating level of the GPU. The workload may correspond to the amount of graphics processing to be done by the GPU while the operating level may include the operating voltage operating frequency memory bandwidth latency power gating configuration cache configuration and or throughput of the GPU.

First an incoming workload to the GPU may be predicted by analyzing command buffers graphics calls applications and or application programming interfaces APIs associated with the GPU. Next an operational floor for the GPU may be identified based on the incoming workload. The operational floor may correspond to a lower bound on the operating voltage operating frequency memory bandwidth latency and or throughput to be achieved by the GPU to process the incoming workload in a timely and or efficient manner.

Finally the operational floor is used to configure the subsequent execution of the GPU. In particular an operating level of the GPU may be obtained and adjusted based on a series of thermal performance and or efficiency bounds including the operational floor an existing workload of the GPU a bottleneck in the GPU a minimum configuration of the GPU an operational ceiling for the GPU and or a thermal limit for the GPU. Such configuration of the GPU s operating level may increase the GPU s responsiveness to rapidly fluctuating workloads while facilitating the safe efficient and effective execution of the GPU.

In addition processor may communicate with display using a display card . More specifically processor is coupled to display card through bridge chip . Display card includes a graphics processing unit GPU that performs various graphical processing operations to produce video frames in one or more framebuffers located in video memory . The video frames may then be used to produce video streams that drive display . For example the video streams may be transmitted over a standardized video interface such as Digital Visual Interface DVI or High Definition Multimedia Interface HDMI to drive an external display e.g. cathode ray tube CRT display liquid crystal display LCD plasma display organic light emitting diode OLED display surface conducting electron emitter display SED etc. connected to computer system .

Those skilled in the art will appreciate that the workload of GPU may fluctuate over time. For example the workload of GPU may be proportional to the number and or complexity of graphics calls made to GPU by applications on computer system . To facilitate workload processing by GPU the operating level e.g. operating voltage operating frequency etc. of GPU may be modified in response to changes in the workload of GPU . For example computer system may periodically and or continuously sample the workload of GPU during execution of GPU . If the sampled workload has increased computer system may increase the operating level of GPU . On the other hand if the sampled workload has decreased computer system may decrease the operating level of GPU .

However such sampling based power management of GPU may prevent computer system from responding to rapid fluctuations in the workload of GPU . For example computer system may sample GPU over a span of 100 milliseconds and finish modifying the operating level of GPU several milliseconds after the workload of GPU has been sampled. As a result adjustments to the operating level of GPU may be made over milliseconds after changes to the workload of GPU have occurred.

In turn the delay in the responsiveness of GPU to changes in workload may cause the GPU s operating voltage and or frequency to be out of sync with rapid and or frequent workload fluctuations. For example short bursty workloads that occur every 100 200 milliseconds may cause GPU to be at a low operating level when a workload is to be processed and at a high operating level when no workload is to be processed. Similarly the sampled workload of GPU may be based on the workload for one application and or process causing the operating level of GPU to be adjusted too low if multiple workloads are received at around the same time from multiple applications and or processes.

In one or more embodiments computer system facilitates the processing of workloads by GPU by predicting an incoming workload to GPU and configuring the subsequent execution of GPU based on the incoming workload. The incoming workload may be predicted based on command buffers graphics calls applications and or APIs associated with GPU . Furthermore the incoming workload may reflect the cumulative workload from multiple applications and or processes instead of the workload for a single application and or process. Next an operational floor for GPU may be identified based on the incoming workload. The operational floor may be associated with the operating voltage operating frequency memory bandwidth latency power gating configuration cache configuration and or throughput of GPU .

Finally the operational floor may be used to configure the subsequent execution of GPU . In particular an operating level of GPU may be obtained and modified based on a series of thermal performance and or efficiency bounds including the operational floor an existing workload of GPU a bottleneck in GPU a minimum configuration of GPU an operational ceiling for GPU and or a thermal limit for GPU . For example the existing workload minimum configuration and or operational floor may be used to increase the operating level of GPU while the bottleneck operational ceiling and or thermal limit may be used to decrease the operating level of GPU . Prediction based configuration of GPUs is discussed in further detail below with respect to .

As mentioned above the system of may facilitate workload processing in GPU including the processing of rapidly and or frequently fluctuating workloads. First analysis apparatus may predict an incoming workload to GPU . To predict the incoming workload analysis apparatus may monitor and or analyze the use of GPU on the computer system.

More specifically analysis apparatus may analyze applications that use GPU to perform graphics processing graphics calls made by applications to GPU APIs used by applications to make graphics calls and or command buffers to which graphics calls are written. For example analysis apparatus may assess the size of the incoming workload based on the launch of applications with dependencies on GPU and or the use of graphics libraries and or graphical APIs by applications . Analysis apparatus may also predict the incoming workload based on the queuing of graphics calls in command buffers the number of outstanding command buffers and or the referencing of resources on GPU by graphics calls . As a result analysis apparatus may be configured to assess both the individual workloads of applications as well as cumulative workloads arising from the submission of graphics calls by applications at around the same time.

Next analysis apparatus may identify an operational floor for GPU based on the incoming workload. Operational floor may correspond to a set of operating parameters that enables efficient processing of the incoming workload by GPU . For example operational floor may include an operating voltage operating frequency memory bandwidth latency power gating configuration e.g. configuration of power gates in GPU cache configuration e.g. configuration of the cache of GPU and or throughput to be achieved by GPU to efficiently process the incoming workload.

In particular operating floor may represent a configuration of GPU that allows GPU to perform a certain amount of work over a defined period rather than a specific operating voltage operating frequency memory bandwidth latency and or other hardware specific attribute of GPU . For example operating floor may be calculated as a percentage of the maximum throughput of GPU to be achieved over a particular amount of time e.g. in processing the incoming workload . Alternatively operating floor may include specific values for one or more hardware specific attributes of GPU . For example operating floor may include a specific operating voltage operating frequency memory bandwidth latency power gating configuration and or cache configuration for GPU .

Analysis apparatus may then provide operational floor to management apparatus and management apparatus may use operational floor to configure the subsequent execution of GPU . For example analysis apparatus may provide operational floor to management apparatus through a side channel and management apparatus may configure one or more operating parameters of GPU based on operational floor .

More specifically management apparatus may obtain an operating level of GPU that corresponds to the operating voltage operating frequency memory bandwidth latency and or throughput of GPU . Management apparatus may then modify the operating level of GPU based on operational floor an existing workload of GPU a bottleneck in GPU e.g. memory bandwidth limit a minimum configuration of GPU e.g. minimum memory bandwidth an operational ceiling for GPU and or a thermal limit for GPU .

For example management apparatus may increase the operating level of GPU based on the existing workload the minimum configuration and or operational floor and decrease the operating level based on the bottleneck the operational ceiling and or the thermal limit. Furthermore the operational ceiling and or thermal limit may be associated with a higher priority than the existing workload and or operational floor . In other words management apparatus may apply a series of upper and lower bounds associated with operational floor the existing workload the bottleneck the minimum configuration the operational ceiling and or the thermal limit to the operating level to obtain a new operating level for GPU . Modification of GPU operating levels is discussed in further detail below with respect to .

Finally management apparatus may facilitate processing of the incoming workload by GPU by applying the new operating level to GPU . For example management apparatus may modify the operating voltage operating frequency memory bandwidth latency cache configuration and or power gating configuration of GPU so that the execution of GPU conforms to the new operating level.

Furthermore management apparatus may apply the new operating level to GPU in a way that prepares GPU for handling the incoming workload. For example the new operating level e.g. based on operating floor may specify a power state containing a set of hardware specific attributes e.g. operating voltage operating frequency memory bandwidth etc. of GPU and a percentage of the throughput attainable at the power state to be completed by GPU over a period of five milliseconds. Management apparatus may then adjust the slow changing hardware specific attributes based on the new operating level but leave the fast changing hardware specific attributes at previous e.g. lower levels until the incoming workload arrives at GPU . For example fast changing hardware specific attributes may include graphics engine clock speeds and voltages while slow changing hardware specific attributes may include memory system clock speeds and memory system bus widths. Other attributes may be either fast changing or slow changing such as attributes associated with power gating and cache power. Note that by using the above described techniques management apparatus may selectively modify attributes of GPU in a way that optimizes both the processing of the incoming workload and power conservation in GPU .

By configuring the execution of GPU based on the incoming workload to GPU the system of may increase both the efficiency and performance of GPU . In particular analysis apparatus and management apparatus may synchronize changes to the operating level of GPU with changes in the workload of GPU allowing GPU to adapt to rapid fluctuations in the workload. Analysis apparatus and management apparatus may additionally facilitate the safe efficient and effective processing of workloads by GPU by adjusting the operating level of GPU based on a series of thermal performance and or efficiency bounds.

Those skilled in the art will appreciate that the system of may be implemented in a variety of ways. For example analysis apparatus may be implemented in software such as a device driver for GPU and or a software framework associated with GPU . Alternatively analysis apparatus may be provided by a microcontroller and or other hardware module on the computer system and or GPU . Furthermore analysis apparatus and management apparatus may be provided by a single component e.g. GPU or a combination of software and or hardware components.

Initially an incoming workload to the GPU is predicted operation . The incoming workload may be predicted by analyzing command buffers graphics calls applications and or APIs associated with the GPU. Next an operational floor for the GPU is identified based on the incoming workload operation . The operational floor may correspond to an operating voltage operating frequency memory bandwidth latency and or throughput to be achieved by GPU to process the incoming workload in a timely and or efficient manner.

Finally the operational floor is used to configure the subsequent execution of the GPU operation . To configure the subsequent execution of the GPU an operating level of the GPU is obtained and modified based on the operational floor an existing workload of the GPU a bottleneck in the GPU a minimum configuration of the GPU an operational ceiling for the GPU and or a thermal limit for the GPU. Modification of the operating level of the GPU is discussed in further detail below with respect to .

First the operating level may be set to the operational floor operation . However the operational floor may or may not be sufficient for the existing workload operation of the GPU. For example the operational floor may not be sufficient if the incoming workload to the GPU is smaller than the existing workload of the GPU. If the operational floor is not sufficient for the GPU s existing workload the operating level is increased to accommodate the existing workload operation .

The operation of the GPU may also be limited by a bottleneck operation . For example the memory bandwidth of the GPU may limit the rate at which the GPU processes graphics calls. If a bottleneck exists an increase in other parameters e.g. operating voltage operating frequency etc. associated with the operating level may not produce an increase in the performance of the GPU. As a result the operating level may be decreased based on the bottleneck operation . For example the operating voltage and or frequency of the GPU may be decreased so that the GPU executes at the highest possible rate permitted by the bottleneck.

Conversely the operating level may or may not meet a minimum configuration operation for the GPU. For example the minimum configuration may specify a minimum memory bandwidth required of the GPU to drive multiple displays. Along the same lines the minimum configuration may be provided by a user and or based on the type of power supplied to the GPU e.g. battery mains etc . If the operating level does not meet the minimum configuration the operating level is increased to meet the minimum configuration operation .

Furthermore the operating level may be higher than an operational ceiling and or thermal limit operation . The operational ceiling may correspond to a system based cap on the operating level of the GPU. For example the operational ceiling may limit the operating level of the GPU based on a maximum temperature e.g. thermal limit for the GPU and or a battery runtime of a computer system containing the GPU. The GPU may additionally include a chip based thermal limit that prevents the GPU from overheating if the system based operational ceiling does not account for extreme thermal events such as loss of a thermal interface layer between the GPU and a heat sink.

To prevent thermal damage to the GPU and or reduced runtime of a battery powering the computer system the operating level may be decreased based on the operational ceiling and or thermal limit operation . For example if the operating level exceeds the system based operational ceiling the operating level may be capped at the operational ceiling. If the capped operating level still exceeds the chip based thermal limit the operating level may be further reduced based on the thermal limit. Because the operational ceiling and or thermal limit are applied last the operational ceiling and or thermal limit may be associated with a higher priority than previously applied lower and or upper bounds including the operational floor existing workload bottleneck and or minimum configuration.

Finally the operating level is applied to the GPU operation . For example the operating level may be used to configure the operating voltage operating frequency memory bandwidth latency and or throughput of the GPU so that the GPU is capable of safely effectively and or efficiently processing the incoming workload once the incoming workload arrives at the GPU.

The foregoing descriptions of various embodiments have been presented only for purposes of illustration and description. They are not intended to be exhaustive or to limit the present invention to the forms disclosed. Accordingly many modifications and variations will be apparent to practitioners skilled in the art. Additionally the above disclosure is not intended to limit the present invention.

