---

title: Systems and methods for enabling write-back caching and replication at different abstraction layers
abstract: A computer-implemented method for enabling write-back caching and replication at different abstraction layers may include (1) identifying a cache abstraction layer that implements write-back caching to selectively cache at least one write to a backing store, (2) identifying a replication abstraction layer that replicates the backing store to a secondary storage system by replicating writes committed to the backing store to the secondary storage system, (3) receiving a request to create a point-in-time image of the backing store at the secondary storage system at a point at which the writes committed to the backing store are point-in-time consistent, (4) committing the cached write to the backing store to ensure that the writes committed to the backing store are point-in-time consistent, (5) marking the point at which the writes committed to the backing store are point-in-time consistent. Various other methods, systems, and computer-readable media are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09367457&OS=09367457&RS=09367457
owner: Veritas Technologies, LLC
number: 09367457
owner_city: Mountain View
owner_country: US
publication_date: 20121219
---
In the digital age organizations increasingly rely on digitally stored data. To protect against data loss organizations may use replication technologies to replicate data from a primary storage device to a secondary storage device from which the data may be backed up and later restored. To improve storage system performance organizations may use caching technologies to cache reads from and or writes to a relatively slow primary storage device in faster cache memory.

Unfortunately attempting to 1 protect against data loss and 2 improve storage system performance by combining common replication solutions with common caching solutions may be problematic because certain caching technologies may cause the data stored within a storage device to be point in time inconsistent. For example a typical caching solution may implement a write back policy to cache writes to a storage device. While implementing write back caching the caching solution may selectively store some of the writes destined for the storage device to cache memory instead of to the storage device. By selectively storing writes to cache memory instead of to the storage device the caching solution may cause the data within the storage device to be point in time inconsistent. If a replication solution then replicates this inconsistent data to a secondary storage device the data within the secondary storage device may also be point in time inconsistent. For this reason any backup of the storage device that is created from the data within the secondary storage device may also be point in time inconsistent and potentially unusable. Accordingly the instant disclosure addresses a need for additional and improved systems and methods for enabling write back caching and replication at different abstraction layers.

As will be described in greater detail below the instant disclosure generally relates to systems and methods for enabling write back caching and replication at different abstraction layers. In one example a computer implemented method for enabling write back caching and replication at different abstraction layers may include 1 identifying a cache abstraction layer that implements write back caching to selectively cache at least one write to a backing store 2 identifying a replication abstraction layer that replicates the backing store to a secondary storage system by replicating writes committed to the backing store to the secondary storage system 3 receiving a request to create a point in time image of the backing store at the secondary storage system at a point at which the writes committed to the backing store are point in time consistent 4 committing in response to the request the cached write to the backing store to ensure that the writes committed to the backing store are point in time consistent and 5 marking upon committing the cached write to the backing store the point at which the writes committed to the backing store are point in time consistent so that the point in time image of the backing store can be created at the point at which the writes committed to the backing store are point in time consistent.

In some embodiments the step of committing the cached write to the backing store may include 1 flushing the cached write to the backing store and 2 caching subsequent writes to the backing store at the cache abstraction layer while the cached write is flushed to the backing store. The cached subsequent writes may not be committed to the backing store until the cached write is flushed to the backing store.

In certain embodiments the step of committing the cached write to the backing store may include 1 flushing the cached write to the backing store and 2 implementing write through caching at the cache abstraction layer to cache subsequent writes to the backing store while the cached write is flushed to the backing store.

In at least one embodiment the step of marking the point at which the writes committed to the backing store are point in time consistent may include 1 writing a marker to the backing store at the point at which the writes committed to the backing store are point in time consistent and 2 replicating the marker to the secondary storage system.

In other embodiments the step of marking the point at which the writes committed to the backing store are point in time consistent may include 1 sending a message to the replication abstraction layer that indicates that the writes committed to the backing store are point in time consistent and 2 relaying the message to the secondary storage system.

In certain embodiments the method may further include 1 determining at the secondary storage system the point at which the writes committed to the backing store are point in time consistent and 2 creating the point in time image of the backing store based on the determination.

In various embodiments the cache abstraction layer may include a volume manager and or a file system manager and the replication abstraction layer may include an intelligent storage array and or a volume manager.

In one embodiment a system for implementing the above described method may include 1 an identification module programmed to identify a cache abstraction layer that implements write back caching to selectively cache at least one write to a backing store and a replication abstraction layer that replicates the backing store to a secondary storage system by replicating writes committed to the backing store to the secondary storage system 2 a receiving module programmed to receive a request to create a point in time image of the backing store at the secondary storage system at a point at which the writes committed to the backing store are point in time consistent 3 a committing module programmed to commit in response to the request the cached write to the backing store to ensure that the writes committed to the backing store are point in time consistent 4 a marking module programmed to mark upon committing the cached write to the backing store the point at which the writes committed to the backing store are point in time consistent so that the point in time image of the backing store can be created at the point at which the writes committed to the backing store are point in time consistent and 5 at least one processor configured to execute the identification module the receiving module the committing module and the marking module.

In some examples the above described method may be encoded as computer readable instructions on a computer readable storage medium. For example a computer readable storage medium may include one or more computer executable instructions that when executed by at least one processor of a computing device may cause the computing device to 1 identify a cache abstraction layer that implements write back caching to selectively cache at least one write to a backing store 2 identify a replication abstraction layer that replicates the backing store to a secondary storage system by replicating writes committed to the backing store to the secondary storage system 3 receive a request to create a point in time image of the backing store at the secondary storage system at a point at which the writes committed to the backing store are point in time consistent 4 commit in response to the request the cached write to the backing store to ensure that the writes committed to the backing store are point in time consistent and 5 mark upon committing the cached write to the backing store the point at which the writes committed to the backing store are point in time consistent so that the point in time image of the backing store can be created at the point at which the writes committed to the backing store are point in time consistent.

Features from any of the above mentioned embodiments may be used in combination with one another in accordance with the general principles described herein. These and other embodiments features and advantages will be more fully understood upon reading the following detailed description in conjunction with the accompanying drawings and claims.

Throughout the drawings identical reference characters and descriptions indicate similar but not necessarily identical elements. While the exemplary embodiments described herein are susceptible to various modifications and alternative forms specific embodiments have been shown by way of example in the drawings and will be described in detail herein. However the exemplary embodiments described herein are not intended to be limited to the particular forms disclosed. Rather the instant disclosure covers all modifications equivalents and alternatives falling within the scope of the appended claims.

The present disclosure is generally directed to systems and methods for enabling write back caching and replication at different abstraction layers. As will be explained in greater detail below by periodically flushing to a backing store writes destined for the backing store that have been cached by a cache abstraction layer that implements write back caching the systems and methods described herein may ensure that the data within the backing store is periodically point in time consistent. Furthermore in some examples by ensuring that the data within the backing store is periodically point in time consistent these systems and methods may ensure that when the data within the backing store is replicated to a secondary storage system by an independent replication abstraction layer the replicated data is also periodically point in time consistent.

Moreover by marking the point at which the data within the backing store is point in time consistent and replicating this marker to the secondary storage system these systems and methods may enable the creation of a point in time image of the backing store at the secondary storage system at a point at which the data within the backing store is point in time consistent.

The following will provide with reference to detailed descriptions of exemplary systems for enabling write back caching and replication at different abstraction layers. Detailed descriptions of corresponding computer implemented methods will also be provided in connection with . In addition detailed descriptions of an exemplary computing system and network architecture capable of implementing one or more of the embodiments described herein will be provided in connection with respectively.

In addition and as will be described in greater detail below exemplary system may include a committing module programmed to commit in response to the request the cached write to the backing store to ensure that the writes committed to the backing store are point in time consistent. Exemplary system may also include a marking module programmed to mark upon committing the cached write to the backing store the point at which the writes committed to the backing store are point in time consistent so that the point in time image of the backing store can be created at the point at which the writes committed to the backing store are point in time consistent. Exemplary system may further include a backup module programmed to create the point in time image of the backing store.

Although illustrated as separate elements one or more of modules in may represent portions of a single module or application. For example one or more of modules in may represent portions of a single module or application that is used to manage a system that includes a cache abstraction layer that implements write back caching to cache writes to a backing store and a replication abstraction layer that replicates the backing store to a secondary storage system. Additionally and or alternatively one or more of modules in may represent portions of a cache abstraction layer and or a replication abstraction layer. As part of the cache abstraction layer and or the replication abstraction layer one or more of modules in may enable the cache abstraction layer to coordinate with the replication abstraction layer so that a point in time image of a backing store may be created at a secondary storage system.

In certain embodiments one or more of modules in may represent one or more software applications or programs that when executed by a computing device may cause the computing device to perform one or more tasks. For example and as will be described in greater detail below one or more of modules may represent software modules stored and configured to run on one or more computing devices such as the devices illustrated in e.g. primary storage system and or secondary storage system computing system in and or portions of exemplary network architecture in . One or more of modules in may also represent all or portions of one or more special purpose computers configured to perform one or more tasks.

Exemplary system in may be implemented in a variety of ways. For example all or a portion of exemplary system may represent portions of exemplary system in . As shown in system may include a primary storage system in communication with a secondary storage system via a network . Primary storage system may be programmed with one or more of modules . Additionally or alternatively secondary storage system may be programmed with one or more of modules .

In one embodiment one or more of modules from may when executed by at least one processor of primary storage system and or secondary storage system facilitate primary storage system and or secondary storage system in enabling write back caching and replication at different abstraction layers. For example and as will be described in greater detail below one or more of modules may cause primary storage system and or secondary storage system to 1 identify a cache abstraction layer that implements write back caching to selectively cache e.g. to cache at least one write to a backing store 2 identify a replication abstraction layer that replicates backing store to secondary storage system by replicating writes committed to backing store to secondary store 3 receive a request to create a point in time image of backing store at secondary storage system at a point at which the writes committed to backing store are point in time consistent 4 commit in response to the request the cached write to backing store to ensure that the writes committed to backing store are point in time consistent and 5 mark the point at which the writes committed to backing store are point in time consistent so that the point in time image of backing store can be created.

Primary storage system and secondary storage system may include any type or form of computing device capable of reading computer executable instructions and storing data. Examples of primary storage system and secondary storage system include without limitation laptops tablets desktops servers cellular phones Personal Digital Assistants PDAs multimedia players embedded systems combinations of one or more of the same exemplary computing system in or any other suitable computing device.

As shown in primary storage system may include cache and backing store and secondary storage system may include secondary store . Cache backing store and secondary store may generally represent any type or form of volatile or non volatile storage device or medium capable of storing data. For example cache backing store and secondary store may represent one or more of the storage mediums and or storage devices illustrated in e.g. system memory storage device and or storage device and or one or more of the storage mediums and or storage devices illustrated in e.g. storage devices N storage devices N storage devices N and or intelligent storage array .

Network generally represents any medium or architecture capable of facilitating communication or data transfer. Examples of network include without limitation an intranet a Wide Area Network WAN a Local Area Network LAN a Personal Area Network PAN the Internet Power Line Communications PLC a cellular network e.g. a Global System for Mobile Communications GSM network exemplary network architecture in or the like. Network may facilitate communication or data transfer using wireless or wired connections. In one embodiment network may facilitate communication between primary storage system and secondary storage system .

As illustrated in at step one or more of the systems described herein may identify a cache abstraction layer that implements write back caching to selectively cache at least one write to a backing store. For example at step identification module may as part of primary storage system in identify cache abstraction layer . At step one or more of the systems described herein may also identify a replication abstraction layer that replicates the backing store to a secondary storage system by replicating writes committed to the backing store to the secondary storage system. For example at step identification module may as part of primary storage system in identify replication abstraction layer .

As used herein the term cache abstraction layer may generally refer to any system e.g. any combination of software and or hardware that is capable of caching data destined for a backing store. In some examples the term cache abstraction layer may refer to a system that implements caching for one or more applications without requiring the applications to be aware of and or handle any caching operations e.g. allowing the applications to perform I O operations normally as if no caching were implemented . Examples of cache abstraction layers may include without limitations file system managers e.g. VERITAS FILE SYSTEM and or volume managers e.g. VERITAS VOLUME MANAGER . The term backing store as used herein may generally refer to any type or form of storage device or medium capable of storing data. In some examples the term backing store may refer to a storage device or medium to which one or more applications may write data. In some examples the term backing store may refer to a storage device for which a caching system implements caching. Examples of backing stores may include without limitation file systems volumes and or storage arrays.

Cache abstraction layers may cache data destined for a backing store using various writing policies. For example cache abstraction layer may implement write back caching to cache writes destined for backing store . Using a write back policy cache abstraction layer may 1 receive from an application e.g. application a request to write data to backing store and 2 selectively store a portion of the data to cache but not to backing store . Later before overwriting data stored to cache cache abstraction layer may flush the data to backing store . By selectively storing data to cache but not to backing store cache abstraction layer may cause data within backing store to be at times point in time inconsistent.

Cache abstraction layer may continue to receive requests to write data to backing store . For example as shown in cache abstraction layer may receive a request to store an additional series of writes to backing store . Writes may include a series of ordered writes G H and I. In response to this request cache abstraction layer may again while implementing write back caching selectively store some of writes to cache but not to backing store and may store the rest of writes to backing store but not to cache . For example as shown in cache abstraction layer may store writes H and I to cache and write G to backing store . In this example cache abstraction layer may flush writes C and B from cache to backing store to make room for writes H and I. Because cache abstraction layer stored some of writes and to cache and others to backing store data within backing store may be point in time inconsistent.

Returning to the term replication abstraction layer may generally refer to any system e.g. any combination of software and or hardware that is capable of replicating data. Examples of replication abstraction layers may include without limitations volume managers and or intelligent storage arrays. In some examples a replication abstraction layer may be used to create a point in time image of a backing store at a secondary storage system e.g. for the purpose of backing up the data within the backing store .

Replication abstraction layers may replicate data using various methods. For example replication abstraction layer may implement synchronous or asynchronous block level replication to replicate backing store to secondary storage system . illustrate how replication abstraction layer may replicate backing store to secondary storage system . As shown in a series of writes may be written e.g. by cache abstraction layer to backing store . Writes may include a series of ordered writes A B C D E and F e.g. cache abstraction layer may have first committed write A to backing store followed by write B etc. . In one example replication abstraction layer may detect that writes have been committed to backing store as shown in and may replicate writes to secondary store either synchronously or asynchronously. For example as shown in replication abstraction layer may asynchronously transmit writes to secondary store via replication stream . At secondary storage system replication abstraction layer may commit each write within replication stream to secondary store in the order that the write was committed to backing store . By committing each write within replication stream to secondary store in the order that the write was committed to backing store replication abstraction layer may maintain a copy of the data within backing store at secondary storage system e.g. as shown in .

Returning to the systems described herein may perform steps and in any suitable manner. For example identification module may represent a portion of a system used to manage cache abstraction layers and replication abstraction layers. In one example identification module may identify cache abstraction layer and replication abstraction layer by detecting that cache abstraction layer caches writes destined for the same backing store that replication abstraction layer is replicating to secondary storage system . Additionally and or alternatively identification module may identify cache abstraction layer and replication abstraction layer by reading a configuration file identifying cache abstraction layer and replication abstraction layer .

In another example identification module may represent a portion of cache abstraction layer and may identify replication abstraction layer by determining that replication abstraction layer is configured to replicate backing store . In other examples identification module may represent a portion of replication abstraction layer and may identify cache abstraction layer by determining that cache abstraction layer is configured to cache writes destined for backing store .

At step one or more of the systems described herein may receive a request to create a point in time image of the backing store at the secondary storage system at a point at which the writes committed to the backing store are point in time consistent. For example at step receiving module may as part of primary storage system in receive a request to create a point in time image of backing store at secondary storage system at a point at which the writes committed to backing store are point in time consistent.

As used herein the term point in time image may refer to any point in time consistent copy of a backing store that is created at a point at which the writes committed to the backing store are point in time consistent. Writes committed to a backing store may be considered point in time consistent if all writes destined for the backing store prior to a specific point in time have been committed to the backing store. On the other hand writes committed to a backing store may be considered point in time inconsistent if all writes destined for the backing store prior to a specific point in time have not been committed to the backing store.

The systems described herein may perform step in any suitable manner. In one example replication abstraction layer may be configured to create point in time images of backing store at secondary storage system and receiving module may as part of replication abstraction layer receive the request to create the point in time image of backing store from a storage system administrator. In another example replication abstraction layer may prior to creating point in time images of backing store request that cache abstraction layer flush cached outstanding writes to backing store to ensure that the writes committed to backing store are point in time consistent and receiving module may as part of cache abstraction layer receive this request.

Replication abstraction layer may detect that writes B and C have been committed to backing store as shown in and may replicate these writes to secondary store . For example replication abstraction layer may asynchronously transmit writes B and C to secondary store via replication stream and may commit each write within replication stream to secondary store in the order that the write was committed to backing store . By committing each write within replication stream to secondary store in the order that the write was committed to backing store replication abstraction layer may maintain a copy of backing store on secondary store e.g. as shown in . But because the data stored to backing store is point in time inconsistent as a result of cache abstraction layer having stored some of writes to cache secondary store may also be point in time inconsistent. For this reason the portion of writes held in cache may need to be flushed to backing store and then replicated to secondary store before a point in time image of backing store may be created from the data within secondary store .

Returning to at step one or more of the systems described herein may commit the cached write to the backing store to ensure that the writes committed to the backing store are point in time consistent. For example at step committing module may as part of primary storage system in commit outstanding writes stored within cache to backing store to ensure that the writes committed to backing store are point in time consistent. At step one or more of the systems described herein may then mark the point at which the writes committed to the backing store are point in time consistent so that the point in time image of the backing store can be created at the point at which the writes committed to the backing store are point in time consistent. For example at step marking module may as part of primary storage system in mark the point at which the writes committed to backing store are point in time consistent so that a point in time image of backing store can be created.

The systems described herein may perform steps and in any suitable manner. In one example committing module may commit outstanding writes stored to cache to backing store in a way that ensures that the writes committed to backing store are point in time consistent by storing subsequent writes destined for backing store in cache until after the writes that were previously stored to cache have been flushed to backing store . After the previously cached writes are flushed to backing store but before any of the subsequent writes are allowed to be committed to backing store marking module may mark backing store as point in time consistent.

In addition to and or as an alternative to storing subsequent writes to cache committing module may commit outstanding writes stored to cache to backing store in a way that ensures that the writes committed to backing store are point in time consistent by causing cache abstraction layer to implement write through caching until after all outstanding writes have been flushed to backing store . While implementing write through caching cache abstraction layer may still store subsequent writes to cache but when cache abstraction layer stores a subsequent write to cache it may also commit the subsequent write to backing store . By storing subsequent writes to both cache and backing store cache abstraction layer may ensure that the data within backing store is point in time consistent at the moment when all outstanding writes have been flushed from cache to backing store . After the outstanding writes are flushed to backing store but before cache abstraction layer is allowed to again implement write back caching marking module may mark backing store as point in time consistent.

Marking module may mark backing store as point in time consistent in a variety of ways. In one example marking module may as part of cache abstraction layer write a marker e.g. a file marker to backing store at the point at which the writes committed to backing store are point in time consistent. For example marking module may write a marker to backing store immediately after committing module has flushed all previously outstanding writes from cache to backing store . In one example replication abstraction layer may be configured to interpret the marker as an indication of the point at which the writes committed to backing store are point in time consistent. In at least one example marking module may as part of replication abstraction layer replicate the marker to secondary storage system .

By replicating the marker to secondary storage system marking module may provide backup module with a point at which a point in time image of backing store may be created at secondary storage system . In at least one example backup module may create a point in time image of backing store at a point at which the writes committed to backing store are point in time consistent by 1 detecting when the replicated marker is received at secondary storage system and 2 creating the point in time image of backing store based on the replicated marker. The point in time image may be stored at secondary storage system at least until backup module has created an additional point in time image of backing store in response to detecting a subsequent marker. In one example backup module may maintain one or more point in time images of backing store at secondary storage system according to a predetermined recovery point objective. In another example backup module may delete an older point in time image of backing store once a newer point in time image of backing store is created.

Additionally and or alternatively marking module may mark the point at which the writes committed to backing store are point in time consistent by sending a message to replication abstraction layer that indicates that the writes committed to backing store are point in time consistent. In one example marking module may send a message that indicates the point at which the writes committed to backing store are point in time consistent to replication abstraction layer via a special application programming interface API . In at least one example marking module may as part of replication abstraction layer relay this message to secondary storage system .

By relaying this message to secondary storage system marking module may provide backup module with a point at which a point in time image of backing store may be created at secondary storage system . In at least one example backup module may create a point in time image of backing store at a point at which the writes committed to backing store are point in time consistent by 1 detecting when the message is received at secondary storage system and 2 creating the point in time image of backing store based on the received message. This point in time image may be stored at secondary storage system at least until after backup module has created an additional point in time image of backing store in response to detecting a subsequent message. In one example backup module may maintain one or more point in time images of backing store at secondary storage system according to a predetermined recovery point objective. In another example backup module may delete an older point in time image of backing store once a newer point in time image of backing store is created.

Point in time images of backing store may be used in a variety of ways. For example one or more of the systems described herein may use a point in time image of backing store as a secondary or backup source of the data within backing store . In one example backup module may enable an administrator to select a point in time image of backing store from which to restore data e.g. data that has been inadvertently deleted from backing store or data that has been corrupted to backing store . In another example backup module may enable an administrator to select a point in time image of backing store from which an application e.g. application may access the data within backing store in the event that backing store becomes unavailable. In some examples backup module may select a most recent point in time image of backing store from which to restore data. Upon completion of step exemplary method in may terminate.

Replication abstraction layer may detect that write A and marker have been committed to backing store and may replicate these writes to secondary store . For example as shown in replication abstraction layer may transmit write A and marker to secondary store via replication stream and may commit write A and file marker to secondary store in the order that each write was committed to backing store e.g. as shown in .

As shown in at the moment marker is committed to secondary store the data stored within secondary store may represent a copy of the data within backing store at a point at which the writes committed to backing store are point in time consistent. In at least one example backup module may detect that marker has been committed to secondary store and may in response to the detection create a point in time image of backing store using the replicated data within secondary store .

Replication abstraction layer may detect that writes write A and file marker have been committed to backing store and may replicate these writes to secondary store . For example as shown in marking module may transmit writes write A and file marker to secondary store via replication stream and may commit each write within replication stream to secondary store in the order that the write was committed to backing store

As shown in at the moment marker is committed to secondary store the data stored within secondary store may represent a copy of the data within backing store at a point at which the writes committed to backing store are point in time consistent. In at least one example backup module may detect that marker has been committed to secondary store and may in response to the detection create a point in time image of backing store using the replicated data within secondary store .

As explained above by periodically flushing to a backing store writes destined for the backing store that have been cached by a cache abstraction layer that implements write back caching the systems and methods described herein may ensure that the data within the backing store is periodically point in time consistent. Furthermore in some examples by ensuring that the data within the backing store is periodically point in time consistent these systems and methods may ensure that when the data within the backing store is replicated to a secondary storage system by an independent replication abstraction layer the replicated data is also periodically point in time consistent.

Moreover by marking the point at which the data within the backing store is point in time consistent and replicating this marker to the secondary storage system these systems and methods may enable the creation of a point in time image of the backing store at the secondary storage system at a point at which the data within the backing store is point in time consistent.

For example the systems and methods described herein may enable a replication solution to continuously replicate a backing store to a secondary storage system even as a caching solution implements write back caching to selectively cache writes destined for the backing store by 1 periodically committing writes cached by the caching solution to the backing store and 2 marking the backing store as point in time consistent after the writes have been committed. By marking the backing store as point in time consistent these systems and methods may also enable the replication solution to create a point in time image of the backing store at the secondary storage system.

Computing system broadly represents any single or multi processor computing device or system capable of executing computer readable instructions. Examples of computing system include without limitation workstations laptops client side terminals servers distributed computing systems handheld devices or any other computing system or device. In its most basic configuration computing system may include at least one processor and a system memory .

Processor generally represents any type or form of processing unit capable of processing data or interpreting and executing instructions. In certain embodiments processor may receive instructions from a software application or module. These instructions may cause processor to perform the functions of one or more of the exemplary embodiments described and or illustrated herein.

System memory generally represents any type or form of volatile or non volatile storage device or medium capable of storing data and or other computer readable instructions. Examples of system memory include without limitation Random Access Memory RAM Read Only Memory ROM flash memory or any other suitable memory device. Although not required in certain embodiments computing system may include both a volatile memory unit such as for example system memory and a non volatile storage device such as for example primary storage device as described in detail below . In one example one or more of modules from may be loaded into system memory .

In certain embodiments exemplary computing system may also include one or more components or elements in addition to processor and system memory . For example as illustrated in computing system may include a memory controller an Input Output I O controller and a communication interface each of which may be interconnected via a communication infrastructure . Communication infrastructure generally represents any type or form of infrastructure capable of facilitating communication between one or more components of a computing device. Examples of communication infrastructure include without limitation a communication bus such as an Industry Standard Architecture ISA Peripheral Component Interconnect PCI PCI Express PCIe or similar bus and a network.

Memory controller generally represents any type or form of device capable of handling memory or data or controlling communication between one or more components of computing system . For example in certain embodiments memory controller may control communication between processor system memory and I O controller via communication infrastructure .

I O controller generally represents any type or form of module capable of coordinating and or controlling the input and output functions of a computing device. For example in certain embodiments I O controller may control or facilitate transfer of data between one or more elements of computing system such as processor system memory communication interface display adapter input interface and storage interface .

Communication interface broadly represents any type or form of communication device or adapter capable of facilitating communication between exemplary computing system and one or more additional devices. For example in certain embodiments communication interface may facilitate communication between computing system and a private or public network including additional computing systems. Examples of communication interface include without limitation a wired network interface such as a network interface card a wireless network interface such as a wireless network interface card a modem and any other suitable interface. In at least one embodiment communication interface may provide a direct connection to a remote server via a direct link to a network such as the Internet. Communication interface may also indirectly provide such a connection through for example a local area network such as an Ethernet network a personal area network a telephone or cable network a cellular telephone connection a satellite data connection or any other suitable connection.

In certain embodiments communication interface may also represent a host adapter configured to facilitate communication between computing system and one or more additional network or storage devices via an external bus or communications channel. Examples of host adapters include without limitation Small Computer System Interface SCSI host adapters Universal Serial Bus USB host adapters Institute of Electrical and Electronics Engineers IEEE 1394 host adapters Advanced Technology Attachment ATA Parallel ATA PATA Serial ATA SATA and External SATA eSATA host adapters Fibre Channel interface adapters Ethernet adapters or the like. Communication interface may also allow computing system to engage in distributed or remote computing. For example communication interface may receive instructions from a remote device or send instructions to a remote device for execution.

As illustrated in computing system may also include at least one display device coupled to communication infrastructure via a display adapter . Display device generally represents any type or form of device capable of visually displaying information forwarded by display adapter . Similarly display adapter generally represents any type or form of device configured to forward graphics text and other data from communication infrastructure or from a frame buffer as known in the art for display on display device .

As illustrated in exemplary computing system may also include at least one input device coupled to communication infrastructure via an input interface . Input device generally represents any type or form of input device capable of providing input either computer or human generated to exemplary computing system . Examples of input device include without limitation a keyboard a pointing device a speech recognition device or any other input device.

As illustrated in exemplary computing system may also include a primary storage device and a backup storage device coupled to communication infrastructure via a storage interface . Storage devices and generally represent any type or form of storage device or medium capable of storing data and or other computer readable instructions. For example storage devices and may be a magnetic disk drive e.g. a so called hard drive a solid state drive a floppy disk drive a magnetic tape drive an optical disk drive a flash drive or the like. Storage interface generally represents any type or form of interface or device for transferring data between storage devices and and other components of computing system .

In certain embodiments storage devices and may be configured to read from and or write to a removable storage unit configured to store computer software data or other computer readable information. Examples of suitable removable storage units include without limitation a floppy disk a magnetic tape an optical disk a flash memory device or the like. Storage devices and may also include other similar structures or devices for allowing computer software data or other computer readable instructions to be loaded into computing system . For example storage devices and may be configured to read and write software data or other computer readable information. Storage devices and may also be a part of computing system or may be a separate device accessed through other interface systems.

Many other devices or subsystems may be connected to computing system . Conversely all of the components and devices illustrated in need not be present to practice the embodiments described and or illustrated herein. The devices and subsystems referenced above may also be interconnected in different ways from that shown in . Computing system may also employ any number of software firmware and or hardware configurations. For example one or more of the exemplary embodiments disclosed herein may be encoded as a computer program also referred to as computer software software applications computer readable instructions or computer control logic on a computer readable storage medium. The phrase computer readable storage medium generally refers to any form of device carrier or medium capable of storing or carrying computer readable instructions. Examples of computer readable storage media include without limitation transmission type media such as carrier waves and non transitory type media such as magnetic storage media e.g. hard disk drives and floppy disks optical storage media e.g. Compact Disks CDs or Digital Video Disks DVDs electronic storage media e.g. solid state drives and flash media and other distribution systems.

The computer readable storage medium containing the computer program may be loaded into computing system . All or a portion of the computer program stored on the computer readable storage medium may then be stored in system memory and or various portions of storage devices and . When executed by processor a computer program loaded into computing system may cause processor to perform and or be a means for performing the functions of one or more of the exemplary embodiments described and or illustrated herein. Additionally or alternatively one or more of the exemplary embodiments described and or illustrated herein may be implemented in firmware and or hardware. For example computing system may be configured as an Application Specific Integrated Circuit ASIC adapted to implement one or more of the exemplary embodiments disclosed herein.

Client systems and generally represent any type or form of computing device or system such as exemplary computing system in . Similarly servers and generally represent computing devices or systems such as application servers or database servers configured to provide various database services and or run certain software applications. Network generally represents any telecommunication or computer network including for example an intranet a WAN a LAN a PAN or the Internet. In one example client systems and or and or servers and or may include all or a portion of system from .

As illustrated in one or more storage devices N may be directly attached to server . Similarly one or more storage devices N may be directly attached to server . Storage devices N and storage devices N generally represent any type or form of storage device or medium capable of storing data and or other computer readable instructions. In certain embodiments storage devices N and storage devices N may represent Network Attached Storage NAS devices configured to communicate with servers and using various protocols such as Network File System NFS Server Message Block SMB or Common Internet File System CIFS .

Servers and may also be connected to a Storage Area Network SAN fabric . SAN fabric generally represents any type or form of computer network or architecture capable of facilitating communication between a plurality of storage devices. SAN fabric may facilitate communication between servers and and a plurality of storage devices N and or an intelligent storage array . SAN fabric may also facilitate via network and servers and communication between client systems and and storage devices N and or intelligent storage array in such a manner that devices N and array appear as locally attached devices to client systems and . As with storage devices N and storage devices N storage devices N and intelligent storage array generally represent any type or form of storage device or medium capable of storing data and or other computer readable instructions.

In certain embodiments and with reference to exemplary computing system of a communication interface such as communication interface in may be used to provide connectivity between each client system and and network . Client systems and may be able to access information on server or using for example a web browser or other client software. Such software may allow client systems and to access data hosted by server server storage devices N storage devices N storage devices N or intelligent storage array . Although depicts the use of a network such as the Internet for exchanging data the embodiments described and or illustrated herein are not limited to the Internet or any particular network based environment.

In at least one embodiment all or a portion of one or more of the exemplary embodiments disclosed herein may be encoded as a computer program and loaded onto and executed by server server storage devices N storage devices N storage devices N intelligent storage array or any combination thereof. All or a portion of one or more of the exemplary embodiments disclosed herein may also be encoded as a computer program stored in server run by server and distributed to client systems and over network .

As detailed above computing system and or one or more components of network architecture may perform and or be a means for performing either alone or in combination with other elements one or more steps of an exemplary method for enabling write back caching and replication at different abstraction layers.

While the foregoing disclosure sets forth various embodiments using specific block diagrams flowcharts and examples each block diagram component flowchart step operation and or component described and or illustrated herein may be implemented individually and or collectively using a wide range of hardware software or firmware or any combination thereof configurations. In addition any disclosure of components contained within other components should be considered exemplary in nature since many other architectures can be implemented to achieve the same functionality.

In some examples all or a portion of exemplary system in may represent portions of a cloud computing or network based environment. Cloud computing environments may provide various services and applications via the Internet. These cloud based services e.g. software as a service platform as a service infrastructure as a service etc. may be accessible through a web browser or other remote interface. Various functions described herein may be provided through a remote desktop environment or any other cloud based computing environment.

In various embodiments all or a portion of exemplary system in may facilitate multi tenancy within a cloud based computing environment. In other words the software modules described herein may configure a computing system e.g. a server to facilitate multi tenancy for one or more of the functions described herein. For example one or more of the software modules described herein may program a server to enable two or more clients e.g. customers to share an application that is running on the server. A server programmed in this manner may share an application operating system processing system and or storage system among multiple customers i.e. tenants . One or more of the modules described herein may also partition data and or configuration information of a multi tenant application for each customer such that one customer cannot access data and or configuration information of another customer.

According to various embodiments all or a portion of exemplary system in may be implemented within a virtual environment. For example modules and or data described herein may reside and or execute within a virtual machine. As used herein the phrase virtual machine generally refers to any operating system environment that is abstracted from computing hardware by a virtual machine manager e.g. a hypervisor . Additionally or alternatively the modules and or data described herein may reside and or execute within a virtualization layer. As used herein the phrase virtualization layer generally refers to any data layer and or application layer that overlays and or is abstracted from an operating system environment. A virtualization layer may be managed by a software virtualization solution e.g. a file system filter that presents the virtualization layer as though it were part of an underlying base operating system. For example a software virtualization solution may redirect calls that are initially directed to locations within a base file system and or registry to locations within a virtualization layer.

The process parameters and sequence of steps described and or illustrated herein are given by way of example only and can be varied as desired. For example while the steps illustrated and or described herein may be shown or discussed in a particular order these steps do not necessarily need to be performed in the order illustrated or discussed. The various exemplary methods described and or illustrated herein may also omit one or more of the steps described or illustrated herein or include additional steps in addition to those disclosed.

While various embodiments have been described and or illustrated herein in the context of fully functional computing systems one or more of these exemplary embodiments may be distributed as a program product in a variety of forms regardless of the particular type of computer readable storage media used to actually carry out the distribution. The embodiments disclosed herein may also be implemented using software modules that perform certain tasks. These software modules may include script batch or other executable files that may be stored on a computer readable storage medium or in a computing system. In some embodiments these software modules may configure a computing system to perform one or more of the exemplary embodiments disclosed herein.

In addition one or more of the modules described herein may transform data physical devices and or representations of physical devices from one form to another. For example one or more of the modules recited herein may identify point in time inconsistent data to be transformed e.g. data stored within a backing store that has been made by a cache abstraction layer point in time inconsistent transform the point in time inconsistent data into point in time consistent data e.g. by flushing to the backing store writes destined for the backing store that have been cached by the cache abstraction layer output a result of the transformation to a secondary storage system e.g. by replicating the backing store to a secondary storage system use the result of the transformation to create a point in time image of the backing store at the secondary storage system and store the result of the transformation to the secondary storage system. Additionally or alternatively one or more of the modules recited herein may transform a processor volatile memory non volatile memory and or any other portion of a physical computing device from one form to another by executing on the computing device storing data on the computing device and or otherwise interacting with the computing device.

The preceding description has been provided to enable others skilled in the art to best utilize various aspects of the exemplary embodiments disclosed herein. This exemplary description is not intended to be exhaustive or to be limited to any precise form disclosed. Many modifications and variations are possible without departing from the spirit and scope of the instant disclosure. The embodiments disclosed herein should be considered in all respects illustrative and not restrictive. Reference should be made to the appended claims and their equivalents in determining the scope of the instant disclosure.

Unless otherwise noted the terms a or an as used in the specification and claims are to be construed as meaning at least one of. In addition for ease of use the words including and having as used in the specification and claims are interchangeable with and have the same meaning as the word comprising. 

