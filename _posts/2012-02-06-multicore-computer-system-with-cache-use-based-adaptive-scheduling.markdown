---

title: Multicore computer system with cache use based adaptive scheduling
abstract: An example multicore environment generally described herein may be adapted to improve use of a shared cache by a plurality of processing cores in a multicore processor. For example, where a producer task associated with a first core of the multicore processor places data in a shared cache at a faster rate than a consumer task associated with a second core of the multicore processor, relative task execution rates can be adapted to prevent eventual increased cache misses by the consumer task.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09053029&OS=09053029&RS=09053029
owner: EMPIRE TECHNOLOGY DEVELOPMENT LLC
number: 09053029
owner_city: Wilmington
owner_country: US
publication_date: 20120206
---
The present application is a U.S. national stage application under 35 U.S.C. 371 of PCT Application No. PCT US12 23923 entitled MULTICORE COMPUTER SYSTEM WITH CACHE USE BASED ADAPTIVE SCHEDULING filed on Feb. 6 2012 which is incorporated herein by reference in its entirety.

Unless otherwise indicated herein the materials described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.

Multicore computing systems including for example dual and quad core computing systems are now commercially available. Multicore technologies are recognized as an important aspect of the future of computing. However a variety of significant multicore design challenges remain to be overcome. For example while small processor sizes powerful processing speeds and low manufacturing costs allow for inexpensively placing large total processing power on a single multicore chip challenges remain in harnessing such processing power through effective collaboration of the various cores.

The present disclosure describes a multicore computer system with cache use based adaptive scheduling and includes aspects such as a cache controller for a shared cache in such a multicore computer system a scheduler configured to optimize performance of tasks in a multicore computer system and methods and computer readable media optimizing shared cache use in a multicore computer system.

Some example multicore computer systems may include a first core and a second core and may further comprise a shared cache a counter configured to count just missed misses by the first core wherein the just missed misses include cache misses associated with data recently evicted from the shared cache and a scheduler configured to in response to an increase in the just missed misses counted by the counter adjust an execution rate of a task associated with the first core relative to an execution rate of a task associated with the second core.

Some example cache controllers for a shared cache that is operated with a multicore computer system may comprise a list of cache line addresses associated with data recently evicted from the shared cache and a plurality of counters. Each counter may be associated with one of the cores of the multicore computer system and each counter may be configured to count a just missed miss when an associated core requests the data recently evicted from the shared cache. Counter values of each of the plurality of counters may be retrievable from the cache controller and resettable by the cache controller upon request to the cache controller.

Some example schedulers may be configured to optimize performance of tasks in a multicore computer system including a first core and a second core each core associated with a task and each core configured to access a shared cache. A scheduler may comprise a cache controller interface configured to receive a count of just missed misses associated with the first core wherein the just missed misses include cache misses associated with data recently evicted from the shared cache. The scheduler may further comprise a prevention policy generator configured to in response to an increase in the count of just missed misses received at the cache controller interface adjust an execution rate of a first task associated with the first core relative to an execution rate of a second task associated with the second core.

Some example computer readable media may have computer executable instructions that when executed configure a scheduler to optimize performance of tasks in a multicore computer system wherein the multicore computer system includes a first core and a second core of a multicore processor each core associated with a task and each core accessing a shared cache. The computer executable instructions may comprise instructions for receiving a count of just missed misses associated with the first core wherein the just missed misses include cache misses associated with data recently evicted from the shared cache and instructions for generating a prevention policy in response to an increase in the count of just missed misses received at the cache controller interface wherein the that prevention policy adjusts an execution rate of a first task associated with the first core relative to an execution rate of a second task associated with the second core.

Some example methods for optimizing shared cache use in a multicore computer system including a first core and a second core may comprise accumulating by a plurality of counters counts of shared cache just missed misses by a plurality of cores in a multicore computer system. The just missed misses include cache misses associated with data recently evicted from the shared cache. A method may further comprise receiving by a scheduler one or more counts associated with a counter and also associated with the first core detecting by the scheduler an increase in just missed misses associated with the first core based at least in part on the one or more counts received by the scheduler and adjusting by the scheduler in response to the detecting an increase in just missed misses associated with the first core an execution rate of a task associated with the first core relative to an execution rate of a task associated with a second core.

Some example methods for optimizing use of a shared cache in a multicore computer system including a first core and a second core may comprise requesting a cache controller to count shared cache just missed misses associated with the first core wherein the just missed misses include cache misses associated with data recently evicted from the shared cache counting the shared cache just missed misses associated with the first core providing a count of shared cache just missed misses associated with the first core to a scheduler and adjusting an execution rate of a task associated with the first core relative to an execution rate of a task associated with a second core.

Some example methods for optimizing use of a shared cache in a multicore computer system including a first core and a second core may comprise monitoring a rate of shared cache just missed misses associated with the first core determining when the rate of just missed misses associated with the first core enters a predetermined range and when the rate of just missed misses is determined to enter the predetermined range adjusting an execution rate of a first task associated with the first core relative to an execution rate of a second task associated with the second core.

Some example computer readable media may have computer executable instructions for optimizing use of a shared cache in a multicore computer system comprising a first core and a second core. The computer executable instructions may comprise instructions for monitoring a rate of shared cache just missed misses associated with the first core instructions for determining when the monitored rate of shared cache just missed misses is in a predetermined range and instructions for adjusting an execution rate of a first task associated with the first core relative to an execution rate of a second task associated with the second core when the monitored rate is determined to be in the predetermined range.

The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects embodiments and features described above further aspects embodiments and features will become apparent by reference to the drawings and the following detailed description.

In the following detailed description reference is made to the accompanying drawings which form a part hereof. In the drawings similar symbols typically identify similar components unless context dictates otherwise. The illustrative embodiments described in the detailed description drawings and claims are not meant to be limiting. Other embodiments may be utilized and other changes may be made without departing from the spirit or scope of the subject matter presented here. It will be readily understood that the aspects of the present disclosure as generally described herein and illustrated in the Figures may be arranged substituted combined and designed in a wide variety of different configurations all of which are explicitly contemplated and made part of this disclosure.

The present disclosure is generally drawn inter alia to methods devices and or systems related to improved use of a shared cache by a plurality of processing cores in multicore environments. For example where a producer task associated with a first core places data in a shared cache at a faster rate than a consumer task associated with a second core relative task execution rates can be adapted to prevent eventual increased cache misses by the consumer task.

In the various couplings between components may be implemented via bus and interface connections as described in connection with . Scheduler and cache may be configured to exchange data and or commands comprising for example cache controller instructions counter values and or a prevention policy . Cache controller and shared cache may be configured to exchange data and or commands comprising for example cache read and or write data and instructions .

Cores may be configured to exchange cache read and or write data and instructions with the cache as shown by the example cache read and or write data and instructions exchanged between core and cache . Cache controller and shared cache may be configured to exchange cache read and or write data and instructions to read and or write data to shared cache per requests of the various cores . Core and producer task may for example be configured to request cache to perform cache write operations . An arrow pointing from core and producer task to cache indicates that cache write operations may comprise data that is written into the cache .

Core and consumer task may for example be configured to request cache to perform cache read operations . An arrow pointing from cache to consumer task and core N indicates that cache read operations may comprise data being read from the cache .

In multicore environments such as use of a shared cache may become less than optimal if a memory wall scenario develops. A memory wall may be understood as follows if the producer task races too far ahead of the consumer task shared cache may overflow. Shared cache overflow may be defined as data being evicted from shared cache by cache controller before the evicted data is read by consumer task . The evicted data may for example be moved to another more remote memory location such as a Random Access Memory RAM system memory not shown or a hard disk not shown . When consumer task attempts a cache read of the evicted data a cache miss may result and the consumer task may instead retrieve the evicted data from the more remote memory location. Retrieval from the more remote memory location may take more time than retrieval from shared cache and as a result the consumer task may fall further behind the producer task . Additional data written to the shared cache by producer task may be evicted prior to use by consumer task and the use of the shared cache in the multicore environment thereby becomes less than optimal. Locality of references via utilization of a shared cache affects the performance of a multi core environment because it is generally faster to retrieve desired data from a shared cache that it would be to retrieve desired data from other memory locations.

As will be described further in connection with the various other figures and description herein the multicore environment may be adapted to prevent the above described memory wall scenario. Adaptations of multicore environment may comprise inter alia modifications to the cache controller that can facilitate collection of cache utilization data and modifications to the scheduler that can facilitate collection analysis and response to the cache utilization data collected by the cache controller .

In some embodiments collected cache utilization data may comprise JMM data. JMM data may provide an indicator of how many cache misses associated with a particular core may be characterized as just missed . JMM data may comprise counts of cache misses corresponding to data that was recently evicted from the shared cache . Of course recently evicted for the purpose of determining JMM data may be defined in a variety of different ways. An example definition of a JMM data may comprise a cache miss on an n way set associative cache if and only if iff the requested data is among the last n 2 cache lines to be discarded from a line of the cache. Those of skill in the art will recognize with the benefit of this disclosure that there may be numerous other acceptable ways to define JMM data. Multicore environment may be configured to collect and utilize JMM data as described herein.

In the scheduler may be configured to provide cache controller instructions to the cache controller . Cache controller instructions may allow the scheduler to request counter values from the cache controller . Counter values may comprise JMM data associated with the various cores . Cache controller may in turn be configured to collect counter values as described further below.

The scheduler may be configured to detect based on retrieved counter values whether a preventable memory wall problem may occur. The scheduler may be further configured to generate and deploy a prevention policy to prevent a detected memory wall risk. A prevention policy may be configured to modify relative execution rates of the tasks thereby effecting the memory wall prevention. The prevention policy may comprise any of a variety of actions including for example context switches to provide the producer task with less execution time this is one approach for throttling producer task and or providing the consumer task with more execution time or other resources. The prevention policy may also comprise inter alia cache use policy modifications modifications of task priority settings and various techniques for throttling a producer task. The prevention policy may be implemented by direct interaction between the scheduler and the cores or may be implemented by communicating the prevention policy to the cache controller allowing the cache controller to enforce the prevention policy .

The cache controller may be configured to manage the shared cache in a traditional manner in some embodiments. In addition the cache controller may be configured to start increment and reset the counters . The cache controller may also be configured to provide counter values to the scheduler upon request by the scheduler and to enforce a prevention policy received from the scheduler .

In some embodiments the counters may be dedicated special function registers SFRs . Furthermore it should be emphasized that shared cache may comprise a shared cache of any level e.g. a level two L2 cache or a level three L3 cache. The shared cache may be implemented with a ring buffer or using any of the various available or future developed shared cache technologies.

Depending on the desired configuration processors may comprise two or more processor cores A B. Processor cores A B may comprise any processor types including but not limited to microprocessors P microcontrollers C digital signal processors DSP or any combination thereof. Processors may include one or more levels of caching such as level one caches A B and a level two shared cache controlled by a cache controller . In some embodiments cache controller may comprise a set of components discussed in connection with . Cache controller may further comprise aspects of a cache controller described in connection with . Cache and cache controller may also correspond to a shared any level cache such as for example a level three cache. Processors may also comprise registers A B. Each of the processor cores A B may include an arithmetic logic unit ALU a floating point unit FPU a digital signal processing core DSP Core or any combination thereof. A memory controller may also be used with the processors or in some implementations the memory controller may be an internal part of the processors .

Depending on the desired configuration the system memory may be of any type including but not limited to volatile memory such as RAM non volatile memory such as ROM flash memory etc. or any combination thereof. System memory typically includes an operating system one or more applications and program data . Operating system may include for example scheduler module s introduced in connection with which may comprise a set of components discussed in connection with . Scheduler module s may further comprise aspects of a scheduler described in connection with .

Computing device may have additional features or functionality and additional interfaces to facilitate communications between the basic configuration and any required devices and interfaces. For example a bus interface controller may be used to facilitate communications between the basic configuration and one or more data storage devices via a storage interface bus . The data storage devices may be removable storage devices non removable storage devices or a combination thereof. Examples of removable storage and non removable storage devices include magnetic disk devices such as flexible disk drives and hard disk drives HDD optical disk drives such as compact disk CD drives or digital versatile disk DVD drives solid state drives SSD and tape drives to name a few. Example computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data.

System memory removable storage and non removable storage are all examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that may be used to store the desired information and that may be accessed by computing device . Any such computer storage media may be part of device .

Computing device may also include an interface bus for facilitating communication from various interface devices e.g. output interfaces peripheral interfaces and communication interfaces to the basic configuration via the bus interface controller . Example output devices include a graphics processing unit and an audio processing unit which may be configured to communicate to various external devices such as a display or speakers via one or more AN ports . Example peripheral interfaces may include a serial interface controller or a parallel interface controller which may be configured to communicate through either wired or wireless connections with external devices such as input devices e.g. keyboard mouse pen voice input device touch input device etc. or other peripheral devices e.g. printer scanner etc. via one or more I O ports . Other conventional I O devices may be connected as well such as a mouse keyboard and so forth. An example communications device includes a network controller which may be arranged to facilitate communications with one or more other computing devices over a network communication via one or more communication ports .

The computer storage media may be one example of a communication media. Communication media may typically be embodied by computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media. A modulated data signal may be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media may include wired media such as a wired network or direct wired connection and wireless media such as acoustic radio frequency RF infrared IR and other wireless media.

Computing device may be implemented as a portion of a small form factor portable or mobile electronic device such as a cell phone a personal data assistant PDA a personal media player device a wireless web watch device a personal headset device an application specific device or a hybrid device that include any of the above functions. Computing device may also be implemented as a personal computer including both laptop computer and non laptop computer configurations.

In operation the scheduler may be configured to command the cache controller to start recording desired information namely the number s of JMM for one or more cores. The command may identify core s task s and or counter s and may include an instruction to reset the counter to zero initialize the counter to a predetermined count and or start the counter s . The command may be implemented in the scheduler for example via an Application Programming Interface API type command or for example via a machine instruction for the cache controller . In some embodiments the scheduler may be configured to send the command of operation in response to a detected performance change for a particular task or core e.g. a slow down of a consumer task. In some embodiments the scheduler may be configured to send the command of operation in response to another event such as detection of a context switch to a particular task e.g. a consumer task for which memory wall problems frequently arise. In some embodiments the command may identify when to stop counting and or return counter value s . For example an API that supports instructions relating to future actions e.g. actions at future times and or upon occurrence of specified events may be implemented in the scheduler and or cache controller. One example API is the WINDOWS EVENTING API however a variety of other technologies may also be used as will be appreciated. Operation may be followed by operation .

In operation the cache controller may be configured to set one or more counters such as example counter identified in the scheduler command of operation to an initial value. The initial value may be zero or may be non zero. Operation may be followed by operation .

In operation a counter may be configured to be incremented with each JMM by a core associated with the counter . The counter may be incremented by a variety of mechanisms including for example by a cache controller configured to implement a counter or by a discrete module of a cache controller as discussed in connection with . The counter may be configured to be incremented upwards or downwards in some embodiments. In various embodiments JMM detection may be performed for example using a JMM list maintained by the cache controller as will be discussed further herein. Operation may be followed by operation A.

In operations A and B the cache controller may be configured to poll the counter to obtain a JMM count number associated with the counter . In some embodiments the cache controller may be configured to poll the counter at a selected interval after the counter was started. The selected interval may correspond to a time interval or an interval based on volume of shared cache operations or an interval measured by any other relevant property. In some embodiments the cache controller may be configured to poll the counter in response to a command not shown from the scheduler or in accordance with the command of operation . In some embodiments the counter or a JMM manager as discussed herein may be configured provide a counter value to the cache controller without polling for example when a predetermined counter threshold value is reached. In some embodiments operations A and or B may be combined with operation discussed below and may comprise for example an interaction directly between the scheduler and the counter . In some embodiments interrupts may be generated at the counter e.g. in response to a count change. For example communications analogous to operation A may be eliminated as an interrupt need not include any request for information on the part of the controller . Instead an interrupt communication analogous to operation B may be performed. Operation B may be followed by operation .

In operation the cache controller may be configured to provide counter values to the scheduler . The scheduler may be configured to use provided counter values to detect and prevent memory wall problems with respect to the shared cache . In some embodiments the scheduler may be configured to perform memory wall detection based on comparing provided counter value s to one or more selected threshold values. For example a first threshold JMM count and a second threshold JMM count may be selected in the scheduler . If a provided counter value is between the first and second thresholds then the scheduler may be configured to deem a potential memory wall problem sufficiently likely to justify formulation and or deployment of a prevention policy by the scheduler .

In embodiments in which a counter is incremented upwards a threshold may be set at a selected counter value or may be set at a counter overflow e.g. a max counter count plus one which may in some embodiments be detected by a counter value sign change. In embodiments in which a counter is incremented downwards a threshold may also be set at a selected counter value or may be set at a counter underflow e.g. a count of zero minus one which may in some embodiments be detected by a counter value sign change. Operation may be followed by operation .

In operation the scheduler may be configured to provide a prevention policy to the cache controller . The prevention policy may comprise any policy for preventing a memory wall problem. In some embodiments the prevention policy can throttle a producer task cache data production rate and increase a consumer task cache data consumption rate using for example context switching in corresponding cores. The prevention policy may also comprise otherwise providing more or fewer resources to a producer or consumer task. In some embodiments the prevention policy may be based on cache use data such as the value of a JMM count or rate of change of a JMM count as compared to one or more previous JMM counts. For example prevention policy may vary depending on zone determinations made according to zone divisions as illustrated in as discussed further below. In some embodiments the prevention policy may bypass the controller and may instead be provided to one or more cores such as example core as discussed further in connection with . Operation may be followed by operation .

In operation the cache controller may be configured to enforce a prevention policy provided by the scheduler . In some embodiments the cache controller may be configured to forward prevention policy information to a core . In various embodiments the cache controller may be configured to modify cache use policies corresponding to particular cores or tasks to slow down or speed up execution of those tasks. In some embodiments the cache controller may increase or decrease priority of particular cores or tasks. In general the cache controller may take any action to modify the relevant execution rates of tasks involved in a potential memory wall scenario as may be identified in the prevention policy provided by the scheduler .

In zone the measured core experiences mostly cache hits. This corresponds to a desirable situation where desired data is stored in a cache prior to request for such data by the core. In some embodiments where a scheduler requests a JMM count from a cache controller and the cache controller provides a JMM count indicating total cache miss numbers JMM counts and or dm dt values indicating the measured core and or task falls in zone the scheduler may for example be configured not to deploy a prevention policy unnecessarily under these circumstances.

In zone the measured core experiences increasing JMM and or dm dt. This may correspond to a preventable memory wall scenario. The measured core is beginning to experience cache misses. In zone these cache misses may be identified as just missed because the cache misses have occurred recently and the pointers to this data may be still accessible. In some embodiments where a scheduler requests a JMM count from a cache controller and the cache controller provides a JMM count indicating total cache miss numbers JMM counts and or dm dt values indicating the measured core and or task falls in zone the scheduler may for example be configured to deploy a prevention policy to prevent a memory wall problem from occurring.

In zone the measured core experiences a high number of cache misses. This may correspond to a scenario in which transaction costs of retrieving cache misses may too great to be addressed through a prevention policy. In some embodiments where a scheduler requests a JMM count from a cache controller and the cache controller provides a JMM count indicating and or other data indicating total cache miss numbers JMM counts and or dm dt values indicating the measured core and or task falls in zone the scheduler may for example be configured not to deploy a prevention policy as any prevention policy may be futile when a zone scenario occurs.

In block and are illustrated as being performed sequentially with block first and block last. Furthermore within block blocks and are illustrated as being performed sequentially with block first and block last. It will be appreciated however that these blocks may be re ordered as convenient to suit particular embodiments and that these block or portions thereof may be performed concurrently in some embodiments. It will also be appreciated that in some examples various block may be eliminated divided into additional blocks and or combined with other blocks.

In a monitor block cores tasks and cache use data may be monitored for example by a scheduler in conjunction with a cache controller . In some embodiments a scheduler may be configured to monitor a shared cache cores and tasks to determine if circumstances indicating likely shared cache use problems suspicious conditions arise. For example a scheduler may be configured to monitor cores and tasks for introduction of certain task types such as decrypting and uncompressing large files which tasks may be prone to shared cache problems. Scheduler may also be configured to monitor cores for increased use of a main system memory or other non cache memory locations. Scheduler may also be configured to monitor a shared cache for balance between write and read operations. These and other suspicious conditions may be monitored by a scheduler in some embodiments to determine if further investigation is worthwhile.

In some embodiments block may further comprise a scheduler requesting a cache controller for JMM counts associated with particular cores in the multicore environment. In various embodiments requests for JMM counts may be done when a scheduler determines that suspicious conditions are present. In some embodiments requests for JMM counts may be routine and not subject to detection of suspicious conditions.

Blocks may be involved in retrieving JMM counts. In an adjust counters block a scheduler may command a cache controller to start one or more counters corresponding to one or more cores and the counter may optionally reset and start the requested counters by initiating incrementing or decrementing one or more counters in response to JMMs as appropriate for the embodiment. In a retrieve store counter value s block a scheduler may command a cache controller to provide counter values requested counter values may be provided to the scheduler and the scheduler may store retrieved counter values. The cache controller may automatically reset the counters once the counter values are provided to the scheduler or may allow the counters to continue counting without resetting in some embodiments. In a initialize counters block the scheduler may command the cache controller to reset or otherwise initialize to a predetermined count value counters associated with cores identified by the scheduler and the cache controller may reset counters accordingly. Block may be followed by block .

In a zone detection block a scheduler a component of a scheduler or another module in cooperation with a scheduler may be configured to detect whether shared cache use circumstances in a multicore environment are such that a prevention policy may be beneficially deployed to prevent a memory wall problem from arising. In some embodiments block may be configured to analyze stored JMM values corresponding to one or more cores. In some embodiments block may utilize core performance data beyond retrieved JMM counter values as discussed below in connection with . In some additional embodiments block may be configured to evaluate a number and or rate dm dt of JMM per unit of time and to compare the number and or rate of JMM to values from a zone graph such as to determine if JMM values indicate circumstances that may be characterized as in a particular zone such as zone in . In some embodiments block may compare retrieved JMM values to threshold JMM values described above in connection with . Block may be configured to use these and any other techniques to determine if deploying a prevention policy may be beneficial under any particular circumstances encountered by block . Block may be followed by block .

In a prevention policy deployment block a prevention policy may be deployed to adapt and improve the use of a shared cache in a multicore environment associated with device . A prevention policy may be any policy that adjusts relative execution rates of tasks accessing a shared cache. For example potential memory wall problems may be prevented by slowing an execution rate of one or more producer tasks by increasing an execution rate of one or more consumer tasks or both.

In some embodiments a prevention policy may be generated by a scheduler and initially deployed to a cache controller . In some additional embodiments the prevention policy may be deployed from scheduler directly to one or more cores in the multicore environment . These embodiments are examples only and it will be recognized that a prevention policy may be formulated by or with the assistance of any aspect of a multicore environment and may be deployed using a wide variety of components and techniques as desired to adjust relative execution rates of tasks using a shared cache. A prevention policy may for example use any of the techniques discussed herein including but not limited to context switches task throttling cache policy adjustments task priority adjustments and available task resource adjustments.

Scheduler and cache controller may be coupled via bus and or interface connections as described in connection with . Scheduler and cache controller may be configured to exchange data and or commands comprising for example cache controller instructions counter values and or prevention policy .

The scheduler may be configured with component . When scheduler executes the JMM instruction the multicore environment may respond by providing a counter value corresponding to core to the scheduler and resetting the counter for core . Scheduler may then utilize components and to detect a need for a prevention policy and to initiate deployment of a prevention policy respectively as described above.

The cache controller may be configured with component . Component may add 32 bit counters such as corresponding to each core in a multicore environment . The added counters may be configured to count JMM.

The cache controller may be configured with component . Component may comprise a just missed list of discarded cache line addresses. Component may be configured for use in determining by cache controller if a cache miss should be characterized as a JMM for the purpose of incrementing a counter. Component may also be used for other purposes for example component may comprise pointers to data recently evicted from a shared cache. Component may be used to revive pointers and the data they are pointing to such that when a measured task moves into zone the priority of a task may be increased and data referenced in modification may be used to restore recently evicted data back to the shared cache.

The cache controller may be configured with component . Component may comprise a look up table for the just missed list of component . Component may be configured for use in determining by cache controller if a cache miss should be characterized as a JMM for the purpose of incrementing a counter.

In the various couplings between components may be implemented via bus and interface connections as described in connection with . Monitor and cores may be configured to exchange data and or commands comprising for example performance data . Performance data may also be shared with zone detection . Monitor and cache controller interface may be configured to exchange data and or commands comprising for example start and stop data collection . Cache controller interface and zone detection may be configured to exchange data and or commands comprising for example counter values . Zone detection and prevention policy generator may be configured to exchange data and or commands comprising for example zone data . Prevention policy generator and cores may be configured to exchange data and or commands comprising for example prevention policy . Prevention policy generator and cache controller interface may be configured to exchange data and or commands comprising for example prevention policy . Cache controller interface and cache controller may be configured to exchange data and or commands comprising for example cache controller instructions counter values and or prevention policy . Cache controller and shared cache may be configured to exchange data and or commands comprising for example cache read and or write data and or commands . Cache controller and cores may be configured to exchange data and or commands comprising for example cache read and or write data and or commands and or prevention policy .

In cores may ordinarily be configured to perform cache read and or write operations by communicating with cache controller and the cache controller may in turn be configured to perform cache read and or write operations with shared cache . As cores may be using the cache controller and shared cache in this way monitor may be configured to detect suspicious conditions for example by evaluating performance data as discussed above in connection with .

Monitor may be configured to provide start and stop data collection commands to cache controller interface for example to start monitoring JMM data when suspicious conditions exist and to stop monitoring JMM data when suspicious conditions no longer exist.

Cache controller interface may be configured to perform data collection in response to commands . Cache controller interface may be configured to employ components and or to collect JMM cache use data corresponding to cores in a multicore environment which cores may be identified in commands . Thus in some embodiments all cores in a multicore environment need not be subject to JMM monitoring all of the time. Instead particular cores for which suspicious conditions exist may be monitored on an as needed basis. Cache controller interface may be configured to send cache controller instructions to the cache controller instructing the cache controller to count JMM for particular core s under investigation e.g. cores associated with particular producer and or consumer tasks. Cache controller interface may also be configured to receive and store requested counter values from the cache controller . Requested counter values may be stored in a table or other data structure allowing for comparing sorting averaging summing and or other operations as may be needed for analysis of the data.

Zone detection may be configured to access counter values and may be configured to use counter values to detect if conditions exist that warrant intervention via a prevention policy to preserve the effective use of the shared cache . Zone detection may for example be configured to compare JMM values to selected threshold values to calculate and analyze dm dt and to use other data such as overall cache hit miss data as discussed herein to determine if conditions exist that warrant a prevention policy. Moreover in some embodiments zone detection may be configured to collect data to help identify what types of prevention policy may be warranted. For example zone detection may be configured to analyze performance data as well as counter values . In some embodiments zone detection may be configured to detect whether mild medium or aggressive prevention policies are recommended. In some additional embodiments zone detection may be configured to detect which types of prevention measures such as producer task throttling increased execution rate of a consumer task or both may be recommended to alleviate risk of a shared cache memory wall.

Prevention policy generator may be configured to generate a prevention policy in response to a detection made by zone detection . A prevention policy may apply to cores and or tasks identified in the prevention policy . As discussed above a prevention policy may comprise any number of measures for adjusting relative execution rates of tasks using the shared cache . The prevention policy may also be tailored to make mild medium or aggressive execution rate adjustments to appropriately respond to particular cache use scenarios. For example a mild prevention policy may make small adjustments to priorities of tasks using the shared cache while an aggressive prevention policy may make large adjustments to priorities of tasks. A prevention policy may be communicated to cache controller interface for communication to the cache controller which may in turn communicate and or carry out the prevention policy with respect to the cores . Alternatively some or all aspects of a prevention policy may be carried out via direct interaction between the prevention policy generator and the cores .

In the various couplings between components may be implemented via bus and interface connections as described in connection with . Scheduler and scheduler counter interface may exchange data and or commands comprising for example cache controller instructions counter values and or prevention policy . Scheduler counter interface and JMM manager may be configured to exchange data and or commands comprising for example cache controller instructions and or counter values . JMM manager and counters may be configured to exchange data and or commands comprising for example cache controller instructions and or counter values . Counters and scheduler counter interface may also be configured to exchange data and or commands comprising for example counter values . JMM manager and just missed list may be configured to exchange data and or commands comprising for example just missed list data and or list lookups . JMM manager and cache interface may be configured to exchange data and or commands comprising for example just missed list data and or cache miss data . Cache interface and shared cache may be configured to exchange data and or commands comprising for example cache read and or write data and or commands . Scheduler counter interface and prevention policy enforcement may be configured to exchange data and or commands comprising for example prevention policy . Prevention policy enforcement core interface and cache interface may be configured to exchange data and or commands comprising for example prevention policy . Cache interface and cores may be configured to exchange data and or commands comprising for example cache read and or write data and or commands and or prevention policy .

In as with cores may ordinarily be configured to perform cache read and or write operations by communicating with cache controller and the cache controller may in turn be configured to perform cache read and or write operations with shared cache .

Scheduler counter interface may be configured to receive cache controller instructions instructing the cache controller to start counting JMM corresponding to a core identified in the instructions or to start counting JMM for all cores. Scheduler counter interface may be configured to provide instructions to JMM manager and to receive counter values either from JMM manager or from the various counters . Scheduler counter interface may be configured to provide counter values to scheduler either automatically or in response to a request from scheduler . Scheduler counter interface may also be configured to receive reset instruction s as a cache controller instruction from scheduler and to reset counters identified in such reset instruction s by providing the reset instruction s to JMM manager or by direct interaction with one or more of the counters .

JMM manager may be configured to receive cache controller instructions from interface and to provide the instructions to one or more of counters for example by starting stopping resetting initializing and or retrieving counter values from one or more of the counters .

JMM manager may also be configured to maintain the just missed list by placing just missed list data in the list . Just missed list data may comprise identifications of cache line addresses associated with data recently discarded from the shared cache . JMM manager may for example be configured to receive just missed list data from cache interface as data is discarded from the shared cache and JMM manager may be configured to place the data in the list . The just missed list as maintained by the JMM manager may for example comprise a LIFO list of the last n K discarded cache line addresses for an n way associative cache where K is a constant K 2.

JMM manager may also be configured to increment an appropriate counter from counters when a JMM is identified. In some embodiments JMM manager may receive cache miss data from cache interface upon occurrence of a cache miss. The cache miss data may identify a core and or task associated with a cache miss. JMM manager may be configured to respond to the receipt of cache miss data by determining if a cache line address associated with the cache miss is in the just missed list . If so a JMM may have occurred and a counter corresponding to the core associated with the cache miss may be incremented. If not no JMM may have occurred and no counter need be incremented.

JMM manager may also be configured to maintain an associative lookup table for the data identified by cache line addresses in the just missed list . This allows the cache controller to optionally use the list to reinstate recently discarded data in the shared cache . Cache controller may be configured to reinstate data in the shared cache for example in accordance with a received prevention policy which may comprise for example an increased priority level of a task associated with the recently discarded data.

Scheduler counter interface may be configured to receive a prevention policy and to provide the prevention policy to prevention policy enforcement module . Prevention policy enforcement module may be configured to enforce aspects of a prevention policy by communications with cores via core interface and may be configured to enforce aspects of a prevention policy by making adjustments at the cache interface .

There is little distinction left between hardware and software implementations of aspects of systems the use of hardware or software is generally but not always in that in certain contexts the choice between hardware and software may become significant a design choice representing cost vs. efficiency tradeoffs. There are various vehicles by which processes and or systems and or other technologies described herein may be effected e.g. hardware software and or firmware and that the preferred vehicle will vary with the context in which the processes and or systems and or other technologies are deployed. For example if an implementer determines that speed and accuracy are paramount the implementer may opt for a mainly hardware and or firmware vehicle if flexibility is paramount the implementer may opt for a mainly software implementation or yet again alternatively the implementer may opt for some combination of hardware software and or firmware.

The foregoing detailed description has set forth various embodiments of the devices and or processes via the use of block diagrams flowcharts and or examples. Insofar as such block diagrams flowcharts and or examples contain one or more functions and or operations it will be understood by those within the art that each function and or operation within such block diagrams flowcharts or examples may be implemented individually and or collectively by a wide range of hardware software firmware or virtually any combination thereof. In one embodiment several portions of the subject matter described herein may be implemented via Application Specific Integrated Circuits ASICs Field Programmable Gate Arrays FPGAs digital signal processors DSPs or other integrated formats. However those skilled in the art will recognize that some aspects of the embodiments disclosed herein in whole or in part may be equivalently implemented in integrated circuits as one or more computer programs running on one or more computers e.g. as one or more programs running on one or more computer systems as one or more programs running on one or more processors e.g. as one or more programs running on one or more microprocessors as firmware or as virtually any combination thereof and that designing the circuitry and or writing the code for the software and or firmware would be well within the skill of one of skill in the art in light of this disclosure. In addition those skilled in the art will appreciate that the mechanisms of the subject matter described herein are capable of being distributed as a program product in a variety of forms and that an illustrative embodiment of the subject matter described herein applies regardless of the particular type of signal bearing medium used to actually carry out the distribution. Examples of a signal bearing medium include but are not limited to the following a recordable type medium such as a floppy disk a hard disk drive a Compact Disc CD a Digital Video Disk DVD a digital tape a computer memory etc. and a transmission type medium such as a digital and or an analog communication medium e.g. a fiber optic cable a waveguide a wired communications link a wireless communication link etc. .

Those skilled in the art will recognize that it is common within the art to describe devices and or processes in the fashion set forth herein and thereafter use engineering practices to integrate such described devices and or processes into data processing systems. That is at least a portion of the devices and or processes described herein may be integrated into a data processing system via a reasonable amount of experimentation. Those having skill in the art will recognize that a typical data processing system generally includes one or more of a system unit housing a video display device a memory such as volatile and non volatile memory processors such as microprocessors and digital signal processors computational entities such as operating systems drivers graphical user interfaces and applications programs one or more interaction devices such as a touch pad or screen and or control systems including feedback loops and control motors e.g. feedback for sensing position and or velocity control motors for moving and or adjusting components and or quantities . A typical data processing system may be implemented utilizing any suitable commercially available components such as those typically found in data computing communication and or network computing communication systems. The herein described subject matter sometimes illustrates different components contained within or connected with different other components. It is to be understood that such depicted architectures are merely examples and that in fact many other architectures may be implemented which achieve the same functionality. In a conceptual sense any arrangement of components to achieve the same functionality is effectively associated such that the desired functionality is achieved. Hence any two components herein combined to achieve a particular functionality may be seen as associated with each other such that the desired functionality is achieved irrespective of architectures or intermediate components. Likewise any two components so associated may also be viewed as being operably connected or operably coupled to each other to achieve the desired functionality and any two components capable of being so associated may also be viewed as being operably couplable to each other to achieve the desired functionality. Specific examples of operably couplable include but are not limited to physically connectable and or physically interacting components and or wirelessly interactable and or wirelessly interacting components and or logically interacting and or logically interactable components.

With respect to the use of substantially any plural and or singular terms herein those having skill in the art may translate from the plural to the singular and or from the singular to the plural as is appropriate to the context and or application. The various singular plural permutations may be expressly set forth herein for sake of clarity.

It will be understood by those within the art that in general terms used herein and especially in the appended claims e.g. bodies of the appended claims are generally intended as open terms e.g. the term including should be interpreted as including but not limited to the term having should be interpreted as having at least the term includes should be interpreted as includes but is not limited to etc. . It will be further understood by those within the art that if a specific number of an introduced claim recitation is intended such an intent will be explicitly recited in the claim and in the absence of such recitation no such intent is present. For example as an aid to understanding the following appended claims may contain usage of the introductory phrases at least one and one or more to introduce claim recitations. However the use of such phrases should not be construed to imply that the introduction of a claim recitation by the indefinite articles a or an limits any particular claim containing such introduced claim recitation to inventions containing only one such recitation even when the same claim includes the introductory phrases one or more or at least one and indefinite articles such as a or an e.g. a and or an should typically be interpreted to mean at least one or one or more the same holds true for the use of definite articles used to introduce claim recitations. In addition even if a specific number of an introduced claim recitation is explicitly recited those skilled in the art will recognize that such recitation should typically be interpreted to mean at least the recited number e.g. the bare recitation of two recitations without other modifiers typically means at least two recitations or two or more recitations . Furthermore in those instances where a convention analogous to at least one of A B and C etc. is used in general such a construction is intended in the sense one having skill in the art would understand the convention e.g. a system having at least one of A B and C would include but not be limited to systems that have A alone B alone C alone A and B together A and C together B and C together and or A B and C together etc. . In those instances where a convention analogous to at least one of A B or C etc. is used in general such a construction is intended in the sense one having skill in the art would understand the convention e.g. a system having at least one of A B or C would include but not be limited to systems that have A alone B alone C alone A and B together A and C together B and C together and or A B and C together etc. . It will be further understood by those within the art that virtually any disjunctive word and or phrase presenting two or more alternative terms whether in the description claims or drawings should be understood to contemplate the possibilities of including one of the terms either of the terms or both terms. For example the phrase A or B will be understood to include the possibilities of A or B or A and B. 

While certain example techniques have been described and shown herein using various methods devices and systems it should be understood by those skilled in the art that various other modifications may be made and equivalents may be substituted without departing from claimed subject matter. Additionally many modifications may be made to adapt a particular situation to the teachings of claimed subject matter without departing from the central concept described herein. Therefore it is intended that claimed subject matter not be limited to the particular examples disclosed but that such claimed subject matter also may include all implementations falling within the scope of the appended claims and equivalents thereof.

