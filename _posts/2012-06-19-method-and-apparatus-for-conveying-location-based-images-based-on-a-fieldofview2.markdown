---

title: Method and apparatus for conveying location based images based on a field-of-view
abstract: An approach for enabling users to view an image of a location from different fields-of-view is described. A field-of-view generator causes a rendering of a user interface element representing a field-of-view. The field-of-view generator further processes one or more interactions with the user interface element to determine one or more parameters for specifying the field-of-view. The field-of-view generator further determines a portion of at least one panoramic image that is visible in the field-of-view based, at least in part, on the one or more parameters. Still further, the field-of-view generator causes a rendering of the portion of that at least one panoramic image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619138&OS=09619138&RS=09619138
owner: NOKIA CORPORATION
number: 09619138
owner_city: Espoo
owner_country: FI
publication_date: 20120619
---
Service providers and device manufacturers e.g. wireless cellular etc. are continually challenged to deliver value and convenience to consumers by for example providing compelling network services. One area of interest is providing device users with on demand access to routing information such as maps routes and points of interest data. Typically route options are shown either as lines on a map as a list of navigation directions or as a graphical depiction of streets highways etc. associated with a given location. Unfortunately there is currently no convenient means of enabling users to view an image of a location from different fields of view. In addition users are limited in their ability to view points of interest at a location from varying vantage points while accounting for various obstructions within the immediate proximity.

According to one embodiment a method comprises causing at least in part a rendering of a user interface element representing a field of view. The method further comprises processing and or facilitating a processing of one or more interactions with the user interface element to determine one or more parameters for specifying the field of view. The method further comprises determining a portion of at least one panoramic image that is visible in the field of view based at least in part on the one or more parameters. The method further comprises causing at least in part a rendering of the portion of that at least one panoramic image.

According to another embodiment an apparatus comprises at least one processor and at least one memory including computer program code for one or more computer programs the at least one memory and the computer program code configured to with the at least one processor cause at least in part the apparatus to cause at least in part a rendering of a user interface element representing a field of view. The apparatus is also caused to process and or facilitate a processing of one or more interactions with the user interface element to determine one or more parameters for specifying the field of view. The apparatus is also caused to determine a portion of at least one panoramic image that is visible in the field of view based at least in part on the one or more parameters. The apparatus is also further caused to cause at least in part a rendering of the portion of that at least one panoramic image.

According to another embodiment a computer readable storage medium carries one or more sequences of one or more instructions which when executed by one or more processors cause at least in part an apparatus to cause at least in part a rendering of a user interface element representing a field of view. The apparatus is also caused to process and or facilitate a processing of one or more interactions with the user interface element to determine one or more parameters for specifying the field of view. The apparatus is also caused to determine a portion of at least one panoramic image that is visible in the field of view based at least in part on the one or more parameters. The apparatus is further caused to cause at least in part a rendering of the portion of that at least one panoramic image.

According to another embodiment an apparatus comprises means for causing at least in part a rendering of a user interface element representing a field of view. The apparatus also comprises means for processing and or facilitating a processing of one or more interactions with the user interface element to determine one or more parameters for specifying the field of view. The apparatus also comprises means for determining a portion of at least one panoramic image that is visible in the field of view based at least in part on the one or more parameters. The apparatus further comprises means for causing at least in part a rendering of the portion of the at least one panoramic image.

In addition for various example embodiments of the invention the following is applicable a method comprising facilitating a processing of and or processing 1 data and or 2 information and or 3 at least one signal the 1 data and or 2 information and or 3 at least one signal based at least in part on or derived at least in part from any one or any combination of methods or processes disclosed in this application as relevant to any embodiment of the invention.

For various example embodiments of the invention the following is also applicable a method comprising facilitating access to at least one interface configured to allow access to at least one service the at least one service configured to perform any one or any combination of network or service provider methods or processes disclosed in this application.

For various example embodiments of the invention the following is also applicable a method comprising facilitating creating and or facilitating modifying 1 at least one device user interface element and or 2 at least one device user interface functionality the 1 at least one device user interface element and or 2 at least one device user interface functionality based at least in part on data and or information resulting from one or any combination of methods or processes disclosed in this application as relevant to any embodiment of the invention and or at least one signal resulting from one or any combination of methods or processes disclosed in this application as relevant to any embodiment of the invention.

For various example embodiments of the invention the following is also applicable a method comprising creating and or modifying 1 at least one device user interface element and or 2 at least one device user interface functionality the 1 at least one device user interface element and or 2 at least one device user interface functionality based at least in part on data and or information resulting from one or any combination of methods or processes disclosed in this application as relevant to any embodiment of the invention and or at least one signal resulting from one or any combination of methods or processes disclosed in this application as relevant to any embodiment of the invention.

In various example embodiments the methods or processes can be accomplished on the service provider side or on the mobile device side or in any shared way between service provider and mobile device with actions being performed on both sides.

For various example embodiments the following is applicable An apparatus comprising means for performing a method of any of the claims.

Still other aspects features and advantages of the invention are readily apparent from the following detailed description simply by illustrating a number of particular embodiments and implementations including the best mode contemplated for carrying out the invention. The invention is also capable of other and different embodiments and its several details can be modified in various obvious respects all without departing from the spirit and scope of the invention. Accordingly the drawings and description are to be regarded as illustrative in nature and not as restrictive.

Examples of a method apparatus and computer program for enabling users to view a location from different fields of view are disclosed. In the following description for the purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the embodiments of the invention. It is apparent however to one skilled in the art that the embodiments of the invention may be practiced without these specific details or with an equivalent arrangement. In other instances well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the embodiments of the invention.

Although various embodiments are described with respect to routes generated via a mapping application it is contemplated that the approach described herein may be used with any service for supporting user travel location finding and interaction within a given environment. This may include for example an event planning application a social media application a deal finder shopping application a sightseeing application a travel service or the like.

Unfortunately most routing applications and services are limited in their ability to enable users to view a location from multiple different directions and or perspectives e.g. fields of view . For example the user may be presented with a picture of the area corresponding to a given location based on a general direction of a compass e.g. North West . Because only fixed positions may be viewed however the range of perception of the view for the area is limited. Still further users are limited in their ability to view points of interest POI corresponding to a given location from different vantage points including in instances where various obstructions limit the ability to view the POI.

To address this problem a system of introduces the capability to generate panoramic images of locations rendered to a user interface i.e. via a mapping application or corresponding service . For the purpose of illustration the applications referred to herein collectively as applications may include a routing application mapping application travel planning application or the like. Likewise the services referred to herein collectively as services may include a routing service mapping service travel planning service social networking service or the like for interacting with the various applications . By way of example the system includes a field of view generator that generates a user interface element for displaying a panoramic image of the location and or various points of interest in connection with the application or service . The user interface element is presented in association with a map navigation route or other information generated by the mapping application or service for displaying the panoramic image as well as a corresponding field of view associated with said image. Of note the panoramic image and field of view are presented to the user relative to a specific location selection.

For the purpose of illustration the panoramic image depicts a perspective of the scenery from a selected location wherein the location serves as the focal point for perceiving and or depicting the surroundings at that location. The panoramic image as displayed via the user interface element may include one or more images that are tiled merged or stitched together. As such the panoramic image may be panned left or right via the user interface element for enabling a 360 degree view preview of the surroundings or a depiction thereof from the selected location. In addition the user interface element may be manipulated by the user via the display of UE to permit an expanded view of the panoramic image.

Alternatively the user interface element may be associated with an augmented reality application. As such the images presented may be real time images corresponding to a given location or those generated via one or more three dimensional object models. Under this scenario the user interface element may be caused to adapt the perspective e.g. the field of view of objects rendered in augmented reality mode in response to changes in user location. For example the field of view may be adapted accordingly as the user approaches a point of interest from a specific direction. For the purpose of illustration the images rendered by the field of view generator via the user interface element are described herein primarily from the perspective of panoramic images.

By way of example the user interface element may be displayed as a window or data bubble that is anchored to a corresponding location. The window may be juxtaposed against a map for depicting a panoramic image associated with the location relative to routing or location information. Alternatively the user interface element may be presented in a split screen view wherein a portion of the display features the user interface element while another presents the data provided by the mapping application and or service . In certain embodiments the user interface element may represent an interactive portion of the user interface as presented to the display of the UE . Hence the user may control the user interface element via one or more touch screen inputs or other input means including controlling a degree of rotation e.g. panning of the panoramic image or enabling an expanding of the panoramic image. Of note the field of view generator is configured to process various inputs for facilitating control of the user interface element via operation of the mapping application and or service .

In certain embodiments the field of view generator also presents a representation of a field of view in association with the panoramic image via the user interface element. By way of example the field of view corresponds to a finite range of perception of a user relative to the selected location. From the perspective of a panoramic image the field of view corresponds to a finite portion of the panoramic image available for view within the user interface element. The user may therefore increase the field of view and hence range of perception of the location area by expanding the dimensions of the user interface element accordingly. Also the user may adjust the field of view by adjusting a portion of the user interface element for controlling the field of view referred to herein as the field of view selector. As shown more fully in the field of view selector may be rendered to the display as a triangle for representing a view sector of the field of view.

Of note the field of view and hence the selector corresponds to a panning of the panoramic image via the user interface element. For example as the image is panned left or right about a center point corresponding to the selected location the field of view also rotates accordingly. Moreover when the user manipulates the user interface element to permit a greater amount of panoramic image to be viewed e.g. enhanced width the field of view selector may also be expanded to represent an increased view sector. This may include for example expanding the width of the triangle representing said field of view e.g. of . The field of view generator enables the user to pan the panoramic image at any degree of rotation. As such the user is able to view an image of the location from any perspective and corresponding field of view.

The panoramic image is retrieved by the field of view generator by way of a database maintained by the service . For example the images may include those maintained by a mapping service or social networking service. The panoramic images depict various POI corresponding to the location including for example buildings landmarks streets intersections and the like. Hence the image presented via the user interface element directly correlates to the determined or specified location of the user. The field of view generator may cause retrieval of the images in connection with the mapping service which may further execute the query based on data collected by the sensors of the UE . In the case of a mapping service for example the images may be captured using aircraft e.g. airplanes helicopters or car mounted cameras in conjunction with location information and laser range finder information. This two dimensional panoramic image data may then be further compiled into a three dimensional model representative of the environment corresponding to the location. As such the 3D models might also be acquired separately and the range finder information used only to align the models with the panoramic images.

In another embodiment the field of view generator operates in connection with the services or applications to permit the viewing of a select point of interest from multiple vantage points. By way of example the multiple vantage points correspond to different fixed positions and fields of view of the POI relative to or within proximity of the selected location. Under this scenario for example a building may be selected to be viewed from multiple different vantage points about its perimeter each vantage point corresponding to an image from said perspective. The field of view generator enables the user interface element to present the panoramic image of the POI for the selected vantage point as well as depict a field of view for said vantage point.

By way of example the user may select a specific POI and vantage point to view based on user provided input. This may include a touch screen input selection as rendered to the two dimensional map of the location. Based on this input the field of view generator causes the building to be highlighted within the map along with the presentment of various vantage point selection indicators. In certain embodiments the vantage point selection indicators are juxtaposed against the map rendered by the mapping application and or service . Hence in the case of a building the vantage point selection indicators are featured along the perimeter of the building based on a two dimensional aerial view or top to down view. Each vantage point selection indicator also depicts the corresponding field of view i.e. displays a triangle for representing a view sector.

Upon selection of a vantage point the panoramic image corresponding to the building is shown within a user interface element as the focal point of the image. The user interface element for presenting the image may be shown as anchored to the location of the building or featured in another portion of the user interface i.e. a corner of the display. The field of view generator causes the user interface element to display the associated panoramic image of the building from the vantage point e.g. back side front first entrance service door . In addition the user may select the POI shown within the image presented from said vantage point. For example in the case of a building as the focal point of the image an adjacent building may be selected. By way of this approach any POI within the field of view for a given panoramic image may be selected including those that or only partially visible offset from the current center of the image e.g. to the left or right of center etc.

In certain embodiments the user may provide further input for interacting with the field of view generator relative to a selected vantage point. For example the user may drag or flick their finger across the user interface element to traverse through the various images of the building from differing vantage points. Alternatively the client may automatically show each vantage point for a couple of seconds and then move on to the next available vantage point image of the building. Under this scenario the building stays centered within the panoramic image and may be shown in connection with the highlighted representation of the building along the map. In addition the panoramic images could also be displayed in connection with various tags for specifying details regarding the featured POI e.g. the name and description of a shop attached to the building . For this example the entrance to the shop may only be on one side of the building such that the shop is only shown from a single corresponding vantage point.

By way of example the field of view generator enables one or more of the following 1 process an input for specifying a field of view to associate with a location at least one point of interest associated with the location or a combination thereof via an interactive user interface element 2 determine a panoramic image to associate with the at least one location the at least one point of interest associated with the location or a combination thereof based at least in part on the field of view 3 cause at least in part a rendering of a panoramic image via the interactive user interface element for depicting the location the at least one point of interest associated with the location or a combination thereof to a display of a user device based at least in part on the input 4 enable selection of various points of interest from different vantage points 5 enable full rotation panning of the panoramic image relative to a selected location or expansion of the interactive user interface element for expanding the field of view. Of note the field of view generator enables a user to more readily access a view to points of interest within a city scene cityscape etc. from different available vantage points.

As shown in the system comprises user equipment UE having connectivity to the field of view generator via a communication network . By way of example the communication network of system includes one or more networks such as a data network a wireless network a telephony network or any combination thereof. It is contemplated that the data network may be any local area network LAN metropolitan area network MAN wide area network WAN a public data network e.g. the Internet short range wireless network or any other suitable packet switched network such as a commercially owned proprietary packet switched network e.g. a proprietary cable or fiber optic network and the like or any combination thereof. In addition the wireless network may be for example a cellular network and may employ various technologies including enhanced data rates for global evolution EDGE general packet radio service GPRS global system for mobile communications GSM Internet protocol multimedia subsystem IMS universal mobile telecommunications system UMTS etc. as well as any other suitable wireless medium e.g. worldwide interoperability for microwave access WiMAX Long Term Evolution LTE networks code division multiple access CDMA wideband code division multiple access WCDMA wireless fidelity WiFi wireless LAN WLAN Bluetooth Internet Protocol IP data casting satellite mobile ad hoc network MANET and the like or any combination thereof.

The UE is any type of mobile terminal fixed terminal or portable terminal including a mobile handset station unit device multimedia computer multimedia tablet Internet node communicator desktop computer laptop computer notebook computer netbook computer tablet computer personal communication system PCS device personal navigation device personal digital assistants PDAs audio video player digital camera camcorder positioning device television receiver radio broadcast receiver electronic book device game device or any combination thereof including the accessories and peripherals of these devices or any combination thereof. It is also contemplated that the UE can support any type of interface to the user such as wearable circuitry etc. .

By way of example the UE field of view generator applications and various services communicate with each other and other components of the communication network using well known new or still developing protocols. In this context a protocol includes a set of rules defining how the network nodes within the communication network interact with each other based on information sent over the communication links. The protocols are effective at different layers of operation within each node from generating and receiving physical signals of various types to selecting a link for transferring those signals to the format of information indicated by those signals to identifying which software application executing on a computer system sends or receives the information. The conceptually different layers of protocols for exchanging information over a network are described in the Open Systems Interconnection OSI Reference Model.

Communications between the network nodes are typically effected by exchanging discrete packets of data. Each packet typically comprises 1 header information associated with a particular protocol and 2 payload information that follows the header information and contains information that may be processed independently of that particular protocol. In some protocols the packet includes 3 trailer information following the payload and indicating the end of the payload information. The header includes information such as the source of the packet its destination the length of the payload and other properties used by the protocol. Often the data in the payload for the particular protocol includes a header and payload for a different protocol associated with a different higher layer of the OSI Reference Model. The header for a particular protocol typically indicates a type for the next protocol contained in its payload. The higher layer protocol is said to be encapsulated in the lower layer protocol. The headers included in a packet traversing multiple heterogeneous networks such as the Internet typically include a physical layer 1 header a data link layer 2 header an internetwork layer 3 header and a transport layer 4 header and various application layer 5 layer 6 and layer 7 headers as defined by the OSI Reference Model.

The aforementioned modules of the field of view generator may also access one or more databases and or performing various executions. This includes for example an optional image database for accessing various images for depicting the different panoramic images for a given location. The images may depict various points of interest POI such as buildings and landmarks. Also included is a profile database for maintaining profile information related to one or more users subscribed to and or associated with the field of view generator . It is noted that the image data may be maintained by the field of view generator or optionally access from a service e.g. mapping service .

In one embodiment an authentication module authenticates users and UE for interaction with the field of view generator . By way of example the authentication module receives a request to subscribe to the field of view generator for enabling generation of panoramic images in connection with a selected location. The subscription process may include for example establishing one or more services the user is affiliated with as well as their respective access credential information. Subscription may also entail selection of an opt in option wherein users of the field of view generator permits sharing of their context information e.g. location information position information and temporal information as collected via one or more sensors of UE . Preferences and settings information may be referenced to a specific user user device or combination thereof and maintained as profile data . It is further noted in certain embodiments that the subscription process may be coordinated with a subscription process of a given service accessed by a user. For example various input data required for a user to subscribe to a location based service or other service may be used for establishing profile data for the field of view generator .

The authentication process performed by the module may also include receiving and validating a login name and or user identification value as provided or established for a particular user during a subscription or registration process with the service provider. The login name and or user identification value may be received as input provided by the user from the user device or other device via a graphical user interface to the field of view generator e.g. as enabled by user interface module . Profile data pursuant to registration may be cross referenced as part of the login process. Alternatively the login process may be performed through automated association of profile settings maintained as profile data with an IP address a carrier detection signal of a user device mobile directory number MDN subscriber identity module SIM e.g. of a SIM card radio frequency identifier RFID tag or other identifier.

The authentication module may also be alerted of an input received via the user interface for indicating a user requested action. For example the request may be a type of touch input for indicating an expansion of a user interface element as generated via the user interface module . As another example the touch input may be a selection of a specific location and or point of interest for viewing of a specific vantage point related panoramic image. It is noted that the user interface module supports presentment of the user interface element for presenting such panoramic images e.g. via data while the authentication module interprets input provided to the user as they engage the field of view generator . The authentication module is therefore configured to receive requests for generation of a panoramic image via the service or application.

In one embodiment the context information processing module receives context information as gathered by the sensors of respective UE . Once received the context information processing module analyzes the context information to determine the relative location time position and other information useful for generating a panoramic image in association with a specified location. Based on this determination the context information processing module triggers execution of the view generation module which facilitates the querying retrieval associated panoramic image data from a database e.g. as maintained by a mapping service provider corresponding to the location.

In one embodiment the view generation module facilitates gathering of the various images corresponding to a location selected via a mapping application or service. In addition the view generation module determines and or retrieves the various images corresponding to a specified vantage point of a POI. By way of example in the case of a general view of a location the view generation module compiles the various images into a 360 degree panoramic image. In the case of a vantage point related view the view generation module correlates an image with a given vantage point.

It is noted in certain embodiments that the view generation module may facilitate various image rendering blending merging and other compilation techniques for producing a panoramic image. Of note information provided by the field of view module may also be used for generation of the panoramic image.

In one embodiment the field of view module operates in connection with the view generation module to determine an updated field of view to associate with a user interface element and associated location. The field of view is modified based on input detected by the authentication module . In addition the context information processing module may process current position information for the user and provide this information to the field of view module . Under this scenario the field of view module correlates the current position of the user to a specific field of view i.e. to support real time location and position tracking against a map. Still further this correlation enables the image retrieved by the view generation module to be that which best matches the current vantage point of the user.

The field of view module may also be configured to operate in connection with an augmented reality application. For example the field of view module may retrieve real time image data corresponding to the location such as from a live camera feed for supporting an augmented reality view. As in the case of a panoramic view the field of view module correlates the appropriate augmented reality view with the location. Under this scenario the user may select a particular POI to view at a given location e.g. a building while the resulting viewpoints would be a corresponding panoramic image. It is noted therefore that the image data retrieved for the augmented reality application would only be that required to select the desired building while the other image data is panoramic image data.

In one embodiment the user interface module enables presentment of a graphical user interface for presenting panoramic images in connection with a selected location. By way of example the user interface module generates the user interface element in response to detection of an input for selection of a location in a map. As another example the user interface module enables highlighting of a specific POI presented via the user interface. Of note the user interface module triggers execution of the various other modules including the authentication module field of view module and view generation module in response to user input.

The user interface module employs various application programming interfaces APIs or other function calls corresponding to the application of UE thus enabling the display of graphics primitives such as menus buttons data entry fields etc. for generating the user interface elements. Still further the user interface module may be configured to operate in connection with augmented reality AR processing techniques wherein various different applications graphic elements and features may interact within the same view at the UE . For example the user interface module may coordinate the presentment of augmented reality images in conjunction with various panoramic images for a given location or in response to a selected vantage point.

In one embodiment a communication module enables formation of a session over a network between the field of view generator and the services . By way of example the communication module executes various protocols and data sharing techniques for enabling collaborative execution between a subscriber s UE e.g. mobile devices laptops smartphones tablet computers desktop computers and the field of view generator over the network .

The above presented modules and components of the field of view generator can be implemented in hardware firmware software or a combination thereof. Though depicted as a separate entity in it is contemplated that the field of view generator may be implemented for direct operation by respective UE . As such the field of view generator may generate direct signal inputs by way of the operating system of the UE for interacting with the application . In another embodiment one or more of the modules may be implemented for operation by respective UEs as a field of view generator or combination thereof. Still further the field of view generator may be integrated for direct operation with a service such as in the form of a widget or applet in accordance with an information and or subscriber sharing arrangement. The various executions presented herein contemplate any and all arrangements and models.

In step of process the field of view generator causes a rendering of a user interface element representing a field of view. In step the field of view generator processes one or more interactions with the user interface element to determine one or more parameters for specifying the field of view. This may include for example input entered via the user interface element for indicating an extent of panning of a panoramic image or a degree or rotation of a triangular indicator for depicting the field of view. In another step the field of view generator determines a portion of at least one panoramic image that is visible in the field of view based on the one or more parameters. Per step the generator also a causes a rendering of the portion of that at least one panoramic image.

In step of process the field of view generator determines a location associated with the field of view. Per step the generator causes at least in part a rendering of the user interface element in a location based user interface an augmented reality user interface or a combination thereof based at least in part on the location. The location based interface may correspond to that provided by a mapping application and or corresponding mapping service . As noted previously any location based service may employ the various executions provided via the field of view generator . Furthermore the user interface element includes at least in part at least one representation of the field of view. The field of view may include at least in part a rendering of a triangle to represent a view sector of the field of view.

In step of process the field of view generator causes a rendering of another user interface element for presenting the rendering of the portion of the at least one panoramic image. In another step the generator processes and or facilitates a processing of one or more other interactions with the another user interface element to determine one or more updates to the one or more parameters. This updating corresponds to the provisioning of addition user input via the user interface as presented to the display of a UE . Per step the field of view generator causes an updating of the field of view the user interface element representing the field of view the another user interface element the portion of the at least one panoramic image or a combination thereof based at least in part on the one or more updates.

Per step of process the field of view generator determines an input for specifying at least one object depicted in the at least one panoramic image. In another step the generator determines one or more other panoramic images that depict one or more different view angles of the at least one object. As noted previously the object may include a specific point of interest including that which may be featured and or depicted via a given panoramic image. In step the field of view generator determines one or more vantage points associated with the at least one panoramic image and or the one or more other panoramic images. The generator also causes rendering of the one or more vantage points in relation to at least one representation of the at least one object corresponding to step . Of note the one or more vantage points are based at least in part on one or more respective locations one or more respective fields of view or a combination thereof associated with the one or more different view angles of the at least one object.

In step of processing the generator determines the one or more vantage points based on whether the at least one object fits with the one or more respective fields of view. The generator also determines one or more obstructions to viewing the at least one object from the one or more vantage points corresponding to step . Per step the generator determines to select the one or more vantage points based on the one or more obstructions. For example the field of view generator only enables the viewing of those vantage points that can be witnessed by the user from a specific field of view.

In step of process the field of view generator determines another input for specifying a rotation of the at least one object e.g. the point of interest . The field of view generator also causes a rendering of the at least one panoramic image and or the one or more other panoramic images to cause a presentation of the rotation. It is noted that the field of view generator overcomes limitations associated with traditional approaches to presenting mapping information and or associated images such as limited degrees of rotation user defined panoramic viewing of images associated with a select location and vantage point based viewing of select points of interest.

In the user is presented to display with mapping information via a mapping application and or service. The interface features various objects depicting streets roads buildings and other representations of elements corresponding to a map. By way of touch based input the user clicks on a specific location on the interface. In response the field of view generator renders a user interface element for presenting a panorama image corresponding to the selected location. The panoramic image features various points of interest associated with the selected location including one or more buildings a street view etc.

Also another user interface element is presented in connection with the first user interface element for depicting the selected location and current field of view associated with the panoramic image . The field of view is represented by way of example as a triangle for specifying a view sector of the user relative to the selection location. Of note the field of view may also correspond to a current position orientation of the user i.e. a direction the user is facing in instances where the map is associated with a real time location tracking service. The other user interface element is configured to receive an input for enabling user adaptation of the field of view. Hence the view direction can be changed by pivoting the triangle about the user interface element circularly in this case as depicted in by leftward directed line . Resultantly the panoramic image corresponding to the newly selected field of view is shown within the user interface element .

As shown in the view direction can be changed by flicking the panoramic image in a given horizontal direction as it is presented via the user interface element . By way of example when the user places their finger at a leftmost edge of the user interface element as shown in and gestures rightward towards the rightmost edge as shown in the panoramic image pans left to reveal an updated portion of said image. Resultantly the field of view at the corresponding location per is also updated thus reflecting a new position orientation of the triangle . Although not illustrated in expressly one or more vantage points could also be presented relative to user interface for enabling viewing of different perspectives of a given point of interest associated with the location.

As shown in the extent of viewing of the panoramic image can be adjusted by the user by widening the view sector as presented in connection with user interface element . By way of example in a first view sector e.g. triangle corresponding a first field of view may be adapted for example through two finger interaction as depicted in . Under this scenario the user places their fingers along opposing edges of the user interface element to and moves their fingers away outward . As a result a second view section e.g. triangle is generated corresponding to a second field of view. Of note widening of the view sector also widens the user interface element . This enables more of the panoramic image to be revealed.

In certain embodiments panning of the panoramic image as shown enables a user to more readily view and identify POI in the area at the location as associated with the facades of the buildings. Also the widened panoramic image per widened user interface element is achieved at the client device by the field of view generator based on server side stitching merging and other processing of images to render a 360 panoramic image.

In the user clicks on a two dimensional top to down map view as presented to the user interface . Each view presents a panoramic image corresponding to a location on the map. For example in the user interface element for presenting an image corresponding to a location on the map is shown as anchored to a corner of the map view. In a more expanded view is presented in relation to the location via user interface element . User element may correspond to a toggle view wherein the user toggles between the collapsed view and a full view to permit full viewing of the 2D map. Under this scenario a vantage point selector indicator with corresponding field of view indicator is presented as a user interface element for depicting a current vantage point associated with the image .

Having selected a location and rendered a corresponding user interface element for viewing the image the user may select a specific POI featured in the panoramic image to view from various vantage points. This is depicted by way of example in . Under this scenario the user provides an extended touch input to the interface for selecting a building featured within the image . Resultantly the building as depicted from a top down view is highlighted on the map as shown in . In addition all available vantage point selection indicators e.g. vantage point indicator selector for the building are shown.

The user selects a vantage point indicator selector to view a different panoramic image of the building from different angles and corresponding fields of view per . For example vantage point indicator selector corresponds to panoramic image vantage point indicator selector corresponds to panoramic image vantage point indicator selector corresponds to panoramic image and vantage point indicator selector corresponds to panoramic image . Alternatively the user may switch between the different panoramic images for each vantage point by swiping left or right on a given panoramic image as depicted by directional arrows and . As yet another alternative the field of view generator may be configured to automatically show each image for a limited period of time and then advance to the next available vantage point automatically.

The field of view generator may also support augmented reality applications as mentioned previously. For example building as depicted in could be an augmented reality view of said point of interest rather than a panoramic image i.e. corresponding to an augmented reality user interface and or mode of operation. As such selection of the building is from the augmented reality view. Under this scenario after selecting the building the field of view generator may cause the application subsequently present corresponding panoramic image and map data as in . Hence the field of view generator facilitates matching of the building presented in augmented reality mode view with the appropriate panorama image data for the respective location and vantage point indicated on the map.

The processes described herein for enabling a user to view a location from different fields of view may be advantageously implemented via software hardware firmware or a combination of software and or firmware and or hardware. For example the processes described herein may be advantageously implemented via processor s Digital Signal Processing DSP chip an Application Specific Integrated Circuit ASIC Field Programmable Gate Arrays FPGAs etc. Such exemplary hardware for performing the described functions is detailed below.

A bus includes one or more parallel conductors of information so that information is transferred quickly among devices coupled to the bus . One or more processors for processing information are coupled with the bus .

A processor or multiple processors performs a set of operations on information as specified by computer program code related to enable a user to view a location from different fields of view. The computer program code is a set of instructions or statements providing instructions for the operation of the processor and or the computer system to perform specified functions. The code for example may be written in a computer programming language that is compiled into a native instruction set of the processor. The code may also be written directly using the native instruction set e.g. machine language . The set of operations include bringing information in from the bus and placing information on the bus . The set of operations also typically include comparing two or more units of information shifting positions of units of information and combining two or more units of information such as by addition or multiplication or logical operations like OR exclusive OR XOR and AND. Each operation of the set of operations that can be performed by the processor is represented to the processor by information called instructions such as an operation code of one or more digits. A sequence of operations to be executed by the processor such as a sequence of operation codes constitute processor instructions also called computer system instructions or simply computer instructions. Processors may be implemented as mechanical electrical magnetic optical chemical or quantum components among others alone or in combination.

Computer system also includes a memory coupled to bus . The memory such as a random access memory RAM or any other dynamic storage device stores information including processor instructions for enabling a user to view a location from different fields of view. Dynamic memory allows information stored therein to be changed by the computer system . RAM allows a unit of information stored at a location called a memory address to be stored and retrieved independently of information at neighboring addresses. The memory is also used by the processor to store temporary values during execution of processor instructions. The computer system also includes a read only memory ROM or any other static storage device coupled to the bus for storing static information including instructions that is not changed by the computer system . Some memory is composed of volatile storage that loses the information stored thereon when power is lost. Also coupled to bus is a non volatile persistent storage device such as a magnetic disk optical disk or flash card for storing information including instructions that persists even when the computer system is turned off or otherwise loses power.

Information including instructions for enabling a user to view a location from different fields of view is provided to the bus for use by the processor from an external input device such as a keyboard containing alphanumeric keys operated by a human user a microphone an Infrared IR remote control a joystick a game pad a stylus pen a touch screen or a sensor. A sensor detects conditions in its vicinity and transforms those detections into physical expression compatible with the measurable phenomenon used to represent information in computer system . Other external devices coupled to bus used primarily for interacting with humans include a display device such as a cathode ray tube CRT a liquid crystal display LCD a light emitting diode LED display an organic LED OLED display a plasma screen or a printer for presenting text or images and a pointing device such as a mouse a trackball cursor direction keys or a motion sensor for controlling a position of a small cursor image presented on the display and issuing commands associated with graphical elements presented on the display . In some embodiments for example in embodiments in which the computer system performs all functions automatically without human input one or more of external input device display device and pointing device is omitted.

In the illustrated embodiment special purpose hardware such as an application specific integrated circuit ASIC is coupled to bus . The special purpose hardware is configured to perform operations not performed by processor quickly enough for special purposes. Examples of ASICs include graphics accelerator cards for generating images for display cryptographic boards for encrypting and decrypting messages sent over a network speech recognition and interfaces to special external devices such as robotic arms and medical scanning equipment that repeatedly perform some complex sequence of operations that are more efficiently implemented in hardware.

Computer system also includes one or more instances of a communications interface coupled to bus . Communication interface provides a one way or two way communication coupling to a variety of external devices that operate with their own processors such as printers scanners and external disks. In general the coupling is with a network link that is connected to a local network to which a variety of external devices with their own processors are connected. For example communication interface may be a parallel port or a serial port or a universal serial bus USB port on a personal computer. In some embodiments communications interface is an integrated services digital network ISDN card or a digital subscriber line DSL card or a telephone modem that provides an information communication connection to a corresponding type of telephone line. In some embodiments a communication interface is a cable modem that converts signals on bus into signals for a communication connection over a coaxial cable or into optical signals for a communication connection over a fiber optic cable. As another example communications interface may be a local area network LAN card to provide a data communication connection to a compatible LAN such as Ethernet. Wireless links may also be implemented. For wireless links the communications interface sends or receives or both sends and receives electrical acoustic or electromagnetic signals including infrared and optical signals that carry information streams such as digital data. For example in wireless handheld devices such as mobile telephones like cell phones the communications interface includes a radio band electromagnetic transmitter and receiver called a radio transceiver. In certain embodiments the communications interface enables connection to the communication network for enabling a user to view a location from different fields of view to the UE .

The term computer readable medium as used herein refers to any medium that participates in providing information to processor including instructions for execution. Such a medium may take many forms including but not limited to computer readable storage medium e.g. non volatile media volatile media and transmission media. Non transitory media such as non volatile media include for example optical or magnetic disks such as storage device . Volatile media include for example dynamic memory . Transmission media include for example twisted pair cables coaxial cables copper wire fiber optic cables and carrier waves that travel through space without wires or cables such as acoustic waves and electromagnetic waves including radio optical and infrared waves. Signals include man made transient variations in amplitude frequency phase polarization or other physical properties transmitted through the transmission media. Common forms of computer readable media include for example a floppy disk a flexible disk hard disk magnetic tape any other magnetic medium a CD ROM CDRW DVD any other optical medium punch cards paper tape optical mark sheets any other physical medium with patterns of holes or other optically recognizable indicia a RAM a PROM an EPROM a FLASH EPROM an EEPROM a flash memory any other memory chip or cartridge a carrier wave or any other medium from which a computer can read. The term computer readable storage medium is used herein to refer to any computer readable medium except transmission media.

Logic encoded in one or more tangible media includes one or both of processor instructions on a computer readable storage media and special purpose hardware such as ASIC .

Network link typically provides information communication using transmission media through one or more networks to other devices that use or process the information. For example network link may provide a connection through local network to a host computer or to equipment operated by an Internet Service Provider ISP . ISP equipment in turn provides data communication services through the public world wide packet switching communication network of networks now commonly referred to as the Internet .

A computer called a server host connected to the Internet hosts a process that provides a service in response to information received over the Internet. For example server host hosts a process that provides information representing video data for presentation at display . It is contemplated that the components of system can be deployed in various configurations within other computer systems e.g. host and server .

At least some embodiments of the invention are related to the use of computer system for implementing some or all of the techniques described herein. According to one embodiment of the invention those techniques are performed by computer system in response to processor executing one or more sequences of one or more processor instructions contained in memory . Such instructions also called computer instructions software and program code may be read into memory from another computer readable medium such as storage device or network link . Execution of the sequences of instructions contained in memory causes processor to perform one or more of the method steps described herein. In alternative embodiments hardware such as ASIC may be used in place of or in combination with software to implement the invention. Thus embodiments of the invention are not limited to any specific combination of hardware and software unless otherwise explicitly stated herein.

The signals transmitted over network link and other networks through communications interface carry information to and from computer system . Computer system can send and receive information including program code through the networks among others through network link and communications interface . In an example using the Internet a server host transmits program code for a particular application requested by a message sent from computer through Internet ISP equipment local network and communications interface . The received code may be executed by processor as it is received or may be stored in memory or in storage device or any other non volatile storage for later execution or both. In this manner computer system may obtain application program code in the form of signals on a carrier wave.

Various forms of computer readable media may be involved in carrying one or more sequence of instructions or data or both to processor for execution. For example instructions and data may initially be carried on a magnetic disk of a remote computer such as host . The remote computer loads the instructions and data into its dynamic memory and sends the instructions and data over a telephone line using a modem. A modem local to the computer system receives the instructions and data on a telephone line and uses an infra red transmitter to convert the instructions and data to a signal on an infra red carrier wave serving as the network link . An infrared detector serving as communications interface receives the instructions and data carried in the infrared signal and places information representing the instructions and data onto bus . Bus carries the information to memory from which processor retrieves and executes the instructions using some of the data sent with the instructions. The instructions and data received in memory may optionally be stored on storage device either before or after execution by the processor .

In one embodiment the chip set or chip includes a communication mechanism such as a bus for passing information among the components of the chip set . A processor has connectivity to the bus to execute instructions and process information stored in for example a memory . The processor may include one or more processing cores with each core configured to perform independently. A multi core processor enables multiprocessing within a single physical package. Examples of a multi core processor include two four eight or greater numbers of processing cores. Alternatively or in addition the processor may include one or more microprocessors configured in tandem via the bus to enable independent execution of instructions pipelining and multithreading. The processor may also be accompanied with one or more specialized components to perform certain processing functions and tasks such as one or more digital signal processors DSP or one or more application specific integrated circuits ASIC . A DSP typically is configured to process real world signals e.g. sound in real time independently of the processor . Similarly an ASIC can be configured to performed specialized functions not easily performed by a more general purpose processor. Other specialized components to aid in performing the inventive functions described herein may include one or more field programmable gate arrays FPGA one or more controllers or one or more other special purpose computer chips.

In one embodiment the chip set or chip includes merely one or more processors and some software and or firmware supporting and or relating to and or for the one or more processors.

The processor and accompanying components have connectivity to the memory via the bus . The memory includes both dynamic memory e.g. RAM magnetic disk writable optical disk etc. and static memory e.g. ROM CD ROM etc. for storing executable instructions that when executed perform the inventive steps described herein to enable a user to view a location from different fields of view. The memory also stores the data associated with or generated by the execution of the inventive steps.

Pertinent internal components of the telephone include a Main Control Unit MCU a Digital Signal Processor DSP and a receiver transmitter unit including a microphone gain control unit and a speaker gain control unit. A main display unit provides a display to the user in support of various applications and mobile terminal functions that perform or support the steps of enabling a user to view a location from different fields of view. The display includes display circuitry configured to display at least a portion of a user interface of the mobile terminal e.g. mobile telephone . Additionally the display and display circuitry are configured to facilitate user control of at least some functions of the mobile terminal. An audio function circuitry includes a microphone and microphone amplifier that amplifies the speech signal output from the microphone . The amplified speech signal output from the microphone is fed to a coder decoder CODEC .

A radio section amplifies power and converts frequency in order to communicate with a base station which is included in a mobile communication system via antenna . The power amplifier PA and the transmitter modulation circuitry are operationally responsive to the MCU with an output from the PA coupled to the duplexer or circulator or antenna switch as known in the art. The PA also couples to a battery interface and power control unit .

In use a user of mobile terminal speaks into the microphone and his or her voice along with any detected background noise is converted into an analog voltage. The analog voltage is then converted into a digital signal through the Analog to Digital Converter ADC . The control unit routes the digital signal into the DSP for processing therein such as speech encoding channel encoding encrypting and interleaving. In one embodiment the processed voice signals are encoded by units not separately shown using a cellular transmission protocol such as enhanced data rates for global evolution EDGE general packet radio service GPRS global system for mobile communications GSM Internet protocol multimedia subsystem IMS universal mobile telecommunications system UMTS etc. as well as any other suitable wireless medium e.g. microwave access WiMAX Long Term Evolution LTE networks code division multiple access CDMA wideband code division multiple access WCDMA wireless fidelity WiFi satellite and the like or any combination thereof.

The encoded signals are then routed to an equalizer for compensation of any frequency dependent impairments that occur during transmission though the air such as phase and amplitude distortion. After equalizing the bit stream the modulator combines the signal with a RF signal generated in the RF interface . The modulator generates a sine wave by way of frequency or phase modulation. In order to prepare the signal for transmission an up converter combines the sine wave output from the modulator with another sine wave generated by a synthesizer to achieve the desired frequency of transmission. The signal is then sent through a PA to increase the signal to an appropriate power level. In practical systems the PA acts as a variable gain amplifier whose gain is controlled by the DSP from information received from a network base station. The signal is then filtered within the duplexer and optionally sent to an antenna coupler to match impedances to provide maximum power transfer. Finally the signal is transmitted via antenna to a local base station. An automatic gain control AGC can be supplied to control the gain of the final stages of the receiver. The signals may be forwarded from there to a remote telephone which may be another cellular telephone any other mobile phone or a land line connected to a Public Switched Telephone Network PSTN or other telephony networks.

Voice signals transmitted to the mobile terminal are received via antenna and immediately amplified by a low noise amplifier LNA . A down converter lowers the carrier frequency while the demodulator strips away the RF leaving only a digital bit stream. The signal then goes through the equalizer and is processed by the DSP . A Digital to Analog Converter DAC converts the signal and the resulting output is transmitted to the user through the speaker all under control of a Main Control Unit MCU which can be implemented as a Central Processing Unit CPU .

The MCU receives various signals including input signals from the keyboard . The keyboard and or the MCU in combination with other user input components e.g. the microphone comprise a user interface circuitry for managing user input. The MCU runs a user interface software to facilitate user control of at least some functions of the mobile terminal to enable a user to view a location from different fields of view. The MCU also delivers a display command and a switch command to the display and to the speech output switching controller respectively. Further the MCU exchanges information with the DSP and can access an optionally incorporated SIM card and a memory . In addition the MCU executes various control functions required of the terminal. The DSP may depending upon the implementation perform any of a variety of conventional digital processing functions on the voice signals. Additionally DSP determines the background noise level of the local environment from the signals detected by microphone and sets the gain of microphone to a level selected to compensate for the natural tendency of the user of the mobile terminal .

The CODEC includes the ADC and DAC . The memory stores various data including call incoming tone data and is capable of storing other data including music data received via e.g. the global Internet. The software module could reside in RAM memory flash memory registers or any other form of writable storage medium known in the art. The memory device may be but not limited to a single memory CD DVD ROM RAM EEPROM optical storage magnetic disk storage flash memory storage or any other non volatile storage medium capable of storing digital data.

An optionally incorporated SIM card carries for instance important information such as the cellular phone number the carrier supplying service subscription details and security information. The SIM card serves primarily to identify the mobile terminal on a radio network. The card also contains a memory for storing a personal telephone number registry text messages and user specific mobile terminal settings.

While the invention has been described in connection with a number of embodiments and implementations the invention is not so limited but covers various obvious modifications and equivalent arrangements which fall within the purview of the appended claims. Although features of the invention are expressed in certain combinations among the claims it is contemplated that these features can be arranged in any combination and order.

