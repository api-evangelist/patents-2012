---

title: Apparatus and method for a hybrid latency-throughput processor
abstract: An apparatus and method are described for executing both latency-optimized execution logic and throughput-optimized execution logic on a processing device. For example, a processor according to one embodiment comprises: latency-optimized execution logic to execute a first type of program code; throughput-optimized execution logic to execute a second type of program code, wherein the first type of program code and the second type of program code are designed for the same instruction set architecture; logic to identify the first type of program code and the second type of program code within a process and to distribute the first type of program code for execution on the latency-optimized execution logic and the second type of program code for execution on the throughput-optimized execution logic.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09417873&OS=09417873&RS=09417873
owner: Intel Corporation
number: 09417873
owner_city: Santa Clara
owner_country: US
publication_date: 20121228
---
This invention relates generally to the field of computer processors. More particularly the invention relates to an apparatus and method for a hybrid latency throughput processor.

Invoking accelerators today requires going through a driver interface. In a system in which a hierarchical protection domain is used this means switching to ring 0 and copying data to a different address space which consumes significant time and processing resources. Due to the high latency such accelerator interfaces are also inherently asynchronous. Programmable accelerators require the accelerated code to be implemented in their own instruction set architecture ISA .

Some current processor architectures attempt to address some of these concerns but provide only a coarse grained asynchronous mechanism with a high latency between the accelerated task request and its execution. In addition current architectures use a non X86 ISA which requires a separate toolchain to generate and integrate the accelerated task with the main x86 program.

In addition current asynchronous hardware accelerators e.g. GPUs allow the accelerated task to execute unrelated to the application thread that triggered it. This allows the application thread to handle exceptions and or interrupts without affecting the accelerated task and even allow the application thread to migrate between cores without impacting the accelerated task location on the system.

Current synchronous hardware accelerators need to ensure that interrupts exceptions context switches and core migrations are still functionally correct and ensure forward progress. This is done either by 1 ensuring the accelerator is short enough and doesn t cause any exceptions so that any interrupts are deferred until the accelerator is done 2 maintaining the accelerator s forward progress in existing architectural registers e.g. REPMOV or 3 defining new architectural registers to hold the accelerator status and adding them to XSAVE XRESTORE.

In addition throughput program code is currently developed in specialized programming languages and instruction set architectures ISAs e.g. for DSPs and CPUs . As such throughout programs must be written in a different ISA and tool chain than latency programs. A single application which has both latency and throughput parts must be split into separate sub programs. Once separated each sub program runs on different hardware incurring significant overhead in control and data transfer between the two sub programs. Scheduling of the separate sub programs over the different hardware resources is done separately by different entities such as the operating system and driver or middleware.

In the following description for the purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the embodiments of the invention described below. It will be apparent however to one skilled in the art that the embodiments of the invention may be practiced without some of these specific details. In other instances well known structures and devices are shown in block diagram form to avoid obscuring the underlying principles of the embodiments of the invention.

In a processor pipeline includes a fetch stage a length decode stage a decode stage an allocation stage a renaming stage a scheduling also known as a dispatch or issue stage a register read memory read stage an execute stage a write back memory write stage an exception handling stage and a commit stage .

The front end unit includes a branch prediction unit coupled to an instruction cache unit which is coupled to an instruction translation lookaside buffer TLB which is coupled to an instruction fetch unit which is coupled to a decode unit . The decode unit or decoder may decode instructions and generate as an output one or more micro operations microcode entry points microinstructions other instructions or other control signals which are decoded from or which otherwise reflect or are derived from the original instructions. The decode unit may be implemented using various different mechanisms. Examples of suitable mechanisms include but are not limited to look up tables hardware implementations programmable logic arrays PLAs microcode read only memories ROMs etc. In one embodiment the core includes a microcode ROM or other medium that stores microcode for certain macroinstructions e.g. in decode unit or otherwise within the front end unit . The decode unit is coupled to a rename allocator unit in the execution engine unit .

The execution engine unit includes the rename allocator unit coupled to a retirement unit and a set of one or more scheduler unit s . The scheduler unit s represents any number of different schedulers including reservations stations central instruction window etc. The scheduler unit s is coupled to the physical register file s unit s . Each of the physical register file s units represents one or more physical register files different ones of which store one or more different data types such as scalar integer scalar floating point packed integer packed floating point vector integer vector floating point status e.g. an instruction pointer that is the address of the next instruction to be executed etc. In one embodiment the physical register file s unit comprises a vector registers unit a write mask registers unit and a scalar registers unit. These register units may provide architectural vector registers vector mask registers and general purpose registers. The physical register file s unit s is overlapped by the retirement unit to illustrate various ways in which register renaming and out of order execution may be implemented e.g. using a reorder buffer s and a retirement register file s using a future file s a history buffer s and a retirement register file s using a register maps and a pool of registers etc. . The retirement unit and the physical register file s unit s are coupled to the execution cluster s . The execution cluster s includes a set of one or more execution units and a set of one or more memory access units . The execution units may perform various operations e.g. shifts addition subtraction multiplication and on various types of data e.g. scalar floating point packed integer packed floating point vector integer vector floating point . While some embodiments may include a number of execution units dedicated to specific functions or sets of functions other embodiments may include only one execution unit or multiple execution units that all perform all functions. The scheduler unit s physical register file s unit s and execution cluster s are shown as being possibly plural because certain embodiments create separate pipelines for certain types of data operations e.g. a scalar integer pipeline a scalar floating point packed integer packed floating point vector integer vector floating point pipeline and or a memory access pipeline that each have their own scheduler unit physical register file s unit and or execution cluster and in the case of a separate memory access pipeline certain embodiments are implemented in which only the execution cluster of this pipeline has the memory access unit s . It should also be understood that where separate pipelines are used one or more of these pipelines may be out of order issue execution and the rest in order.

The set of memory access units is coupled to the memory unit which includes a data TLB unit coupled to a data cache unit coupled to a level 2 L2 cache unit . In one exemplary embodiment the memory access units may include a load unit a store address unit and a store data unit each of which is coupled to the data TLB unit in the memory unit . The instruction cache unit is further coupled to a level 2 L2 cache unit in the memory unit . The L2 cache unit is coupled to one or more other levels of cache and eventually to a main memory.

By way of example the exemplary register renaming out of order issue execution core architecture may implement the pipeline as follows 1 the instruction fetch performs the fetch and length decoding stages and 2 the decode unit performs the decode stage 3 the rename allocator unit performs the allocation stage and renaming stage 4 the scheduler unit s performs the schedule stage 5 the physical register file s unit s and the memory unit perform the register read memory read stage the execution cluster perform the execute stage 6 the memory unit and the physical register file s unit s perform the write back memory write stage 7 various units may be involved in the exception handling stage and 8 the retirement unit and the physical register file s unit s perform the commit stage .

The core may support one or more instructions sets e.g. the x86 instruction set with some extensions that have been added with newer versions the MIPS instruction set of MIPS Technologies of Sunnyvale Calif. the ARM instruction set with optional additional extensions such as NEON of ARM Holdings of Sunnyvale Calif. including the instruction s described herein. In one embodiment the core includes logic to support a packed data instruction set extension e.g. AVX1 AVX2 and or some form of the generic vector friendly instruction format U 0 and or U 1 described below thereby allowing the operations used by many multimedia applications to be performed using packed data.

It should be understood that the core may support multithreading executing two or more parallel sets of operations or threads and may do so in a variety of ways including time sliced multithreading simultaneous multithreading where a single physical core provides a logical core for each of the threads that physical core is simultaneously multithreading or a combination thereof e.g. time sliced fetching and decoding and simultaneous multithreading thereafter such as in the Intel Hyperthreading technology .

While register renaming is described in the context of out of order execution it should be understood that register renaming may be used in an in order architecture. While the illustrated embodiment of the processor also includes separate instruction and data cache units and a shared L2 cache unit alternative embodiments may have a single internal cache for both instructions and data such as for example a Level 1 L1 internal cache or multiple levels of internal cache. In some embodiments the system may include a combination of an internal cache and an external cache that is external to the core and or the processor. Alternatively all of the cache may be external to the core and or the processor.

Thus different implementations of the processor may include 1 a CPU with the special purpose logic being integrated graphics and or scientific throughput logic which may include one or more cores and the cores A N being one or more general purpose cores e.g. general purpose in order cores general purpose out of order cores a combination of the two 2 a coprocessor with the cores A N being a large number of special purpose cores intended primarily for graphics and or scientific throughput and 3 a coprocessor with the cores A N being a large number of general purpose in order cores. Thus the processor may be a general purpose processor coprocessor or special purpose processor such as for example a network or communication processor compression engine graphics processor GPGPU general purpose graphics processing unit a high throughput many integrated core MIC coprocessor including 30 or more cores embedded processor or the like. The processor may be implemented on one or more chips. The processor may be a part of and or may be implemented on one or more substrates using any of a number of process technologies such as for example BiCMOS CMOS or NMOS.

The memory hierarchy includes one or more levels of cache within the cores a set or one or more shared cache units and external memory not shown coupled to the set of integrated memory controller units . The set of shared cache units may include one or more mid level caches such as level 2 L2 level 3 L3 level 4 L4 or other levels of cache a last level cache LLC and or combinations thereof. While in one embodiment a ring based interconnect unit interconnects the integrated graphics logic the set of shared cache units and the system agent unit integrated memory controller unit s alternative embodiments may use any number of well known techniques for interconnecting such units. In one embodiment coherency is maintained between one or more cache units and cores A N.

In some embodiments one or more of the cores A N are capable of multi threading. The system agent includes those components coordinating and operating cores A N. The system agent unit may include for example a power control unit PCU and a display unit. The PCU may be or include logic and components needed for regulating the power state of the cores A N and the integrated graphics logic . The display unit is for driving one or more externally connected displays.

The cores A N may be homogenous or heterogeneous in terms of architecture instruction set that is two or more of the cores A N may be capable of execution the same instruction set while others may be capable of executing only a subset of that instruction set or a different instruction set.

Referring now to shown is a block diagram of a system in accordance with one embodiment of the present invention. The system may include one or more processors which are coupled to a controller hub . In one embodiment the controller hub includes a graphics memory controller hub GMCH and an Input Output Hub IOH which may be on separate chips the GMCH includes memory and graphics controllers to which are coupled memory and a coprocessor the IOH is couples input output I O devices to the GMCH . Alternatively one or both of the memory and graphics controllers are integrated within the processor as described herein the memory and the coprocessor are coupled directly to the processor and the controller hub in a single chip with the IOH .

The optional nature of additional processors is denoted in with broken lines. Each processor may include one or more of the processing cores described herein and may be some version of the processor .

The memory may be for example dynamic random access memory DRAM phase change memory PCM or a combination of the two. For at least one embodiment the controller hub communicates with the processor s via a multi drop bus such as a frontside bus FSB point to point interface such as QuickPath Interconnect QPI or similar connection .

In one embodiment the coprocessor is a special purpose processor such as for example a high throughput MIC processor a network or communication processor compression engine graphics processor GPGPU embedded processor or the like. In one embodiment controller hub may include an integrated graphics accelerator.

There can be a variety of differences between the physical resources in terms of a spectrum of metrics of merit including architectural microarchitectural thermal power consumption characteristics and the like.

In one embodiment the processor executes instructions that control data processing operations of a general type. Embedded within the instructions may be coprocessor instructions. The processor recognizes these coprocessor instructions as being of a type that should be executed by the attached coprocessor . Accordingly the processor issues these coprocessor instructions or control signals representing coprocessor instructions on a coprocessor bus or other interconnect to coprocessor . Coprocessor s accept and execute the received coprocessor instructions.

Referring now to shown is a block diagram of a first more specific exemplary system in accordance with an embodiment of the present invention. As shown in multiprocessor system is a point to point interconnect system and includes a first processor and a second processor coupled via a point to point interconnect . Each of processors and may be some version of the processor . In one embodiment of the invention processors and are respectively processors and while coprocessor is coprocessor . In another embodiment processors and are respectively processor coprocessor .

Processors and are shown including integrated memory controller IMC units and respectively. Processor also includes as part of its bus controller units point to point P P interfaces and similarly second processor includes P P interfaces and . Processors may exchange information via a point to point P P interface using P P interface circuits . As shown in IMCs and couple the processors to respective memories namely a memory and a memory which may be portions of main memory locally attached to the respective processors.

Processors may each exchange information with a chipset via individual P P interfaces using point to point interface circuits . Chipset may optionally exchange information with the coprocessor via a high performance interface . In one embodiment the coprocessor is a special purpose processor such as for example a high throughput MIC processor a network or communication processor compression engine graphics processor GPGPU embedded processor or the like.

A shared cache not shown may be included in either processor or outside of both processors yet connected with the processors via P P interconnect such that either or both processors local cache information may be stored in the shared cache if a processor is placed into a low power mode.

Chipset may be coupled to a first bus via an interface . In one embodiment first bus may be a Peripheral Component Interconnect PCI bus or a bus such as a PCI Express bus or another third generation I O interconnect bus although the scope of the present invention is not so limited.

As shown in various I O devices may be coupled to first bus along with a bus bridge which couples first bus to a second bus . In one embodiment one or more additional processor s such as coprocessors high throughput MIC processors GPGPU s accelerators such as e.g. graphics accelerators or digital signal processing DSP units field programmable gate arrays or any other processor are coupled to first bus . In one embodiment second bus may be a low pin count LPC bus. Various devices may be coupled to a second bus including for example a keyboard and or mouse communication devices and a storage unit such as a disk drive or other mass storage device which may include instructions code and data in one embodiment. Further an audio I O may be coupled to the second bus . Note that other architectures are possible. For example instead of the point to point architecture of a system may implement a multi drop bus or other such architecture.

Referring now to shown is a block diagram of a second more specific exemplary system in accordance with an embodiment of the present invention. Like elements in bear like reference numerals and certain aspects of have been omitted from in order to avoid obscuring other aspects of .

Referring now to shown is a block diagram of a SoC in accordance with an embodiment of the present invention. Similar elements in bear like reference numerals. Also dashed lined boxes are optional features on more advanced SoCs. In an interconnect unit s is coupled to an application processor which includes a set of one or more cores A N and shared cache unit s a system agent unit a bus controller unit s an integrated memory controller unit s a set or one or more coprocessors which may include integrated graphics logic an image processor an audio processor and a video processor an static random access memory SRAM unit a direct memory access DMA unit and a display unit for coupling to one or more external displays. In one embodiment the coprocessor s include a special purpose processor such as for example a network or communication processor compression engine GPGPU a high throughput MIC processor embedded processor or the like.

Embodiments of the mechanisms disclosed herein may be implemented in hardware software firmware or a combination of such implementation approaches. Embodiments of the invention may be implemented as computer programs or program code executing on programmable systems comprising at least one processor a storage system including volatile and non volatile memory and or storage elements at least one input device and at least one output device.

Program code such as code illustrated in may be applied to input instructions to perform the functions described herein and generate output information. The output information may be applied to one or more output devices in known fashion. For purposes of this application a processing system includes any system that has a processor such as for example a digital signal processor DSP a microcontroller an application specific integrated circuit ASIC or a microprocessor.

The program code may be implemented in a high level procedural or object oriented programming language to communicate with a processing system. The program code may also be implemented in assembly or machine language if desired. In fact the mechanisms described herein are not limited in scope to any particular programming language. In any case the language may be a compiled or interpreted language.

One or more aspects of at least one embodiment may be implemented by representative instructions stored on a machine readable medium which represents various logic within the processor which when read by a machine causes the machine to fabricate logic to perform the techniques described herein. Such representations known as IP cores may be stored on a tangible machine readable medium and supplied to various customers or manufacturing facilities to load into the fabrication machines that actually make the logic or processor.

Such machine readable storage media may include without limitation non transitory tangible arrangements of articles manufactured or formed by a machine or device including storage media such as hard disks any other type of disk including floppy disks optical disks compact disk read only memories CD ROMs compact disk rewritable s CD RWs and magneto optical disks semiconductor devices such as read only memories ROMs random access memories RAMs such as dynamic random access memories DRAMs static random access memories SRAMs erasable programmable read only memories EPROMs flash memories electrically erasable programmable read only memories EEPROMs phase change memory PCM magnetic or optical cards or any other type of media suitable for storing electronic instructions.

Accordingly embodiments of the invention also include non transitory tangible machine readable media containing instructions or containing design data such as Hardware Description Language HDL which defines structures circuits apparatuses processors and or system features described herein. Such embodiments may also be referred to as program products.

In some cases an instruction converter may be used to convert an instruction from a source instruction set to a target instruction set. For example the instruction converter may translate e.g. using static binary translation dynamic binary translation including dynamic compilation morph emulate or otherwise convert an instruction to one or more other instructions to be processed by the core. The instruction converter may be implemented in software hardware firmware or a combination thereof. The instruction converter may be on processor off processor or part on and part off processor.

One embodiment of the invention provides a generic extensible instruction for low latency invocation of synchronous e.g. fixed function or programmable accelerators e.g. co processors functional units referred to herein as an XCALL instruction. In one embodiment the instruction is an x86 instruction. However the underlying principles of the invention are not limited to any instruction set architecture ISA .

The instruction format according to one embodiment is XCALL result register command register param register which identifies a result register for storing results following executing of the instruction a command register for storing the specific command and associated information to be executed by an accelerator in response to the instruction and a parameter register for storing parameters associated with the invoked instruction respectively. The specific information stored in each register according to one embodiment of the invention is set forth below.

The processor clusters and accelerator clusters may be logical units within the same processor chip or core. Alternatively the processor clusters may be on one chip and the accelerator clusters may be on a different chip either in the same semiconductor package or on different packages and connected via a communication bus e.g. such as a PCI Express Direct Media Interface DMS or other type of communication bus . In yet another embodiment some of the accelerator clusters may be on the same chip or core as the processor clusters while other accelerator clusters may be on a different chip or core. The embodiments of the invention described herein are not limited to any particular chip packaging configuration and support implementations with multiple different types of accelerator clusters.

As illustrated in a set of registers are provided to enable communication of commands parameters and results between the general purpose processor clusters and the accelerator clusters as described herein. Specifically in one embodiment the register set includes the command registers result registers and parameter registers specified by the XCALL instruction. The register set may be general purpose registers GPRs which are used for the purposes specified below e.g. storing commands parameter data and result data in response to the execution of an XCALL instruction . In an alternate embodiment these are dedicated application specific registers.

In one embodiment the clusters execute program code including an XCALL instruction which may cause one or more accelerators to be invoked . In response control information specifying an operation to be performed is provided to the accelerator via a command register described below with respect to and or parameter register within the register set . In response the accelerator may use one or more fixed function units and or programmable function units to execute the command. Alternatively the accelerator cluster may respond with a busy indication exception or violation. The results are then provided to the processor clusters via a result register within the register set described below with respect to . If the command was successfully executed the resulting data may be stored in the result register. By contrast if the command was not successfully executed then data indicating the reason for the failure may stored in the result register and used for example to determine whether to re attempt to execute the command .

As indicated in one or more handlers may be executed on the processor clusters. In one embodiment interrupts generated by the handler may cause an invocation of the accelerator clusters as illustrated.

In one embodiment the id uniquely identifies the accelerator to invoke. For example as mentioned above multiple accelerators may be included within the accelerator cluster and each of these accelerators may be uniquely identified by an accelerator id code.

In one embodiment the private bit indicates whether the accelerator belongs to a particular group of known accelerators. For example if the private bit is set to 0 the id may identify one of a universal set of accelerators as defined by the assignee of the present patent application such that the same id refers to the same accelerator across all computer systems processors. If the private bit is set to 1 the id identifies a proprietary or stock keeping unit SKU specific accelerator. Thus with the private bit set to 1 the same id may refer to different accelerators in different systems.

In one embodiment the low 48 bits of the command register identified as field in and all of the parameter register not shown contain application specific data defined by the specific invoked accelerator.

In one embodiment when retired the XCALL instruction sets the Z bit in EFLAGS as follows. As is understood by those of skill in the art EFLAGS is a status register in an x86 implementations which contains the current state of the processor. The Z bit is set to 1 if the XCALL completed the execution of the requested accelerator. In this case if the tickle bit was set to 1 the result register is not modified and no actual work is done. If the tickle bit was set to 0 the result register is set to an accelerator specific value. The Z bit is set to 0 if the XCALL did not do any work. While the Z bit is used to indicate whether the XCALL instruction was successful in this embodiment a different bit may be set while still complying with the underlying principles of the invention.

In one embodiment the permanent bit is used to indicate whether a subsequent call to the same XCALL will succeed. For example the permanent bit being set to 0 indicates that a future call of the same XCALL may succeed e.g. if the accelerator was busy serving another HW thread . By contrast if there is no point in re trying the same XCALL e.g. if the specified accelerator does not exist in the current SKU or if the specific command and or parameter combination requested is not supported by the accelerator in this SKU then the permanent bit is set to 1.

In one embodiment the low 60 bits of the result register are set to provide additional data on the reason for the XCALL failure. In one embodiment the accelerator cluster provides the information needed to update the result register as described above.

In one embodiment if the private bit of the result register is set to 1 these details have an accelerator specific format. If the private bit is set to 0 these details are provided in a predetermined universal format e.g. such as a format specified by the assignee of the present patent application . Exemplary failure result codes employed in one embodiment of the invention include 

The flowchart set forth in illustrates the operations performed by one embodiment of the invention. At an XCALL instruction is decoded. As a result at data related to the command to be executed by an accelerator is sent to the command register and any necessary parameters are sent to the parameter register. At the private bit is set in the command register depending on whether the accelerator belongs to a known group of accelerators or a proprietary accelerator as described above . In addition at an ID code is updated in the command register to identify the specific accelerator which will execute the command.

At the identified accelerator receives the command specified by the XCALL instruction and determines whether it can be executed. For example the accelerator may currently be busy servicing another hardware thread and so may be unable to execute the current command. Additionally if the current command and or parameter combination requested is not supported by the accelerator then the accelerator will not be able to successfully execute the command. Alternatively the accelerator may successfully execute the command at .

If the command is successfully executed then the process moves to where at the EFLAGS Z bit is set equal to 0 to indicate successful execution of the command as discussed above . If the tickle bit of the command register was previously set to 1 e.g. at operation in determined at then at the result register is left unmodified. If the tickle bit was previously set to 0 then at the tickle bit is set to an accelerator specific value.

If the command specified by the XCALL instruction was not successfully executed by the accelerator determined at in then at in the Z bit of EFLAGS is set equal to 1 to indicate the failure to execute the command . If it is anticipated that a future attempt to execute the XCALL instruction will be successful determined at then at the permanent bit of the result register in is set to 0. Additional data specifying the reason for the failure may also be set in the failure details field of the result register.

If at it is anticipated that a future attempt to execute the XCALL instruction will be unsuccessful then at the permanent bit is set equal to 1 to indicate the permanence of the result and additional data related to the failure to execute the XCALL instruction is set in the details field of the result register. In either case above the data in the details field may be analyzed to determine the root cause of the failure and or to take steps to modify the instruction execution.

As mentioned above the control register and or the parameter register may be modified by the XCALL instruction. In addition just like a normal call an XCALL may consume stack area within the processor. In one embodiment which uses an x86 architecture during the XCALL e.g. when examined by an exception handler the 64 bit stack pointer register RSP is be updated to reflect the stack usage. On retirement the RSP register is restored to its original value to reflect releasing the used stack area. The amount of stack used depends on the specific accelerator in use.

The invoked accelerator may examine and or modify the value of additional registers and or memory locations during the sequences of operations described herein. While the specific semantics may be different for different accelerators the underlying principles of the invention remain the same.

 1 If interrupts and or exceptions are allowed during the XCALL then the continue bit is set to 1 and the XCALL is re issued once the handler completes and execution continues.

 3 Any state required by the accelerator to implement forward progress in the presence of interrupts and or exceptions may be updated in documented accelerator specific location s which can be in one or more of a the command and or parameter registers b other architectural registers c the stack area d additional memory locations. In all of the above cases such a state must survive save and restore operations such as from a context switch e.g. XSAVE context switch XRESTORE .

 4 An accelerator may choose to permanently reject an invocation if it is given an invalid command and or parameter registers e.g. unsupported features values that exceed hardware limitations . . . etc. . However if an accelerator has accepted an invocation it is responsible for completing the request and providing results.

 5 Programmable accelerators invoke user code which may be restricted in accelerator specific ways represented by programmable functions unit in . For example a sort accelerator may invoke the comparison function and a loop accelerator may invoke the loop body. If the user code does not obey the expected restrictions e.g. it tries to enter ring 0 when a ring based hierarchical protection domain is used then the accelerator will trigger an exception specifically UD after saving its state as usual.

 6 The exception handler may choose to a complete the partially evaluated accelerator in non accelerated software based on the saved state b emulate the unsupported instruction and re issue the XCALL requiring tweaking the saved state so the unsupported operation is not re tried or c terminate the execution. Simply trying to re issue the XCALL without any modifications will simply re trigger the exception as expected for UD .

The embodiments of the invention described herein provide a standard mechanism which may be incorporated into an instruction set architecture ISA such as an x86 ISA for invoking accelerators. In contrast to the techniques described in the background of the present patent application the accelerator invocation techniques described herein allow for fine grained low latency synchronous accelerators that naturally share as much or as little of the core s resources such as memory translation registers caches etc. Programmable XCALL accelerators allow the user to accelerate normal x86 code e.g. loops and sorting which is an integral part of the main x86 program and does not require a separate toolchain.

In addition current accelerator interfaces are designed for a specific accelerator while the embodiments of the invention described herein are extensible allowing the streamlined provision of specific accelerators for specific market segments as well as universal accelerators across all market segments. Accelerator invocation can be done at low latencies and without data copying overheads allowing the ecosystem of such accelerators to cover functionality that was impractical to provide previously. It also becomes possible to tailor SKUs with accelerators for specific markets embedded systems image processing HPC server etcs maintaining the tight integration with existing ISAs such as x86.

The XCALL interface described herein also opens up the ability to extend CPUs to cover functionality that was not previously accessible without stepping outside of the CPU ISA and toolchain the x86 ISA for processors designed by the assignee of the present patent application . For example using the techniques described herein programmable accelerators such as programmable loop accelerators SKMD and sort accelerators may be provided as well as fixed function accelerators such as those which perform Fast Fourier Transform FFT texture sampling and various other functions.

Currently failing instructions don t have a way to provide additional details about the failure except by way of dedicated flag bits and or dedicated registers typically for use in exception handlers. The embodiments of the invention described below provide a new fast failure behavior for instructions. In this new behavior an instruction may return a success fail indication e.g. inside a flags register such as EFLAGS or some other register . In addition in one embodiment the instruction writes additional failure details in a normal destination register upon detection of a failure. This allows the application code to test the instruction success failure and respond to certain failure modes without wasting processing resources and time which would result from the invocation of an exception handler or switching to a low level domain on a system which employs hierarchical protection domains e.g. ring 0 .

The proposed new trade off point for instruction failure handling is selected for a certain class of instructions which are both failure prone and have complex failure modes such as the XCALL instruction described above. However it is not suitable for other classes of operations such as division by zero DIV which are not prone to failure or for failure prone operations such as locks that have a simple failure mode.

For example every instance of an instruction which adds the values in two registers is expected to succeed. In one embodiment of the invention no failure handling is provided for instructions in this category.

For example an instruction which divides the values stored in two registers will normally succeed. It will only fail as the result of a divide by zero error. In one embodiment of the invention this class of instructions will trigger an exception handler on failure. The exception handler can then examine dedicated registers such as x86 control registers CR containing additional failure information to determine the correct course of action e.g. CR2 for page faults . The exception handler is separated from the normal application code keeping the application code clean and uncontaminated by the failure handling logic.

In one embodiment for these types of instructions bit s in flags and or destination register s are set to indicate failure but no details are provided. One example is an instruction which attempts to set locks data. For these simple failure modes the application code itself explicitly handles recovery without requiring an exception handler .

For this class of instructions processing systems currently need to resort to an exception handler to access dedicated registers for examining the failure details. For instructions that fail often and have complex failure modes the embodiments of the invention allows setting bit s in flags and or destination register s to indicate failure and also set additional bit s in destination register s to specify the details of the failure allowing the application code to take the correct actions without resorting to an exception handler.

This reduces the cost of failure to a minimum at the cost of having to test the result of each instruction . It also allows the application to trivially tailor its failure handling logic to the current context as opposed to using a hard to change universal exception handler at the cost of having to explicitly invoke this logic at any invocation point .

By way of example this behavior is described above for the XCALL instruction. In the example provided in the XCALL instruction specifies a command to be executed by a particular accelerator. In response the accelerator may execute the command and provide the results in the result register which as discussed may be a general purpose register . Alternatively the accelerator may fail to execute the command for a variety of reasons and update the result register with the reasons for the failure. For example the accelerator may currently be busy servicing another hardware thread and so may be unable to execute the current command. In this case the XCALL instruction may be successfully executed at a later time when the accelerator is no longer busy. As such in response to the failure indication the permanent bit is set to 0 in the result register to indicate that a second attempt may be made to execute the XCALL instruction.

In contrast if the current command and or parameter combination requested is not supported by the accelerator then the accelerator will never be able to successfully execute the command. As such in response to the failure indication the permanent bit is set to 1 in the result register to indicate that a second attempt will not result in successful execution of the XCALL instruction.

Subsequent program code may then read the result register to determine how to proceed. For example if the permanent bit is set to 0 it may again attempt to execute the XCALL instruction while if the permanent bit is set to 1 it may not attempt to execute the XCALL instruction.

If the first instruction was not successfully executed then at the second instruction also fails to execute. In contrast to prior implementations the complex failure details are examined at without invoking an exception handler so that a failure evaluation can be performed by the application program code. In particular a subsequent instruction may be executed to read the results from the result register and determine whether a new attempt should be made to execute the first instruction. If the results of the failure indicate that a second attempt would not work then the second attempt may be prevented saving time and processor resources. If the results indicate that a second attempt may be successful then a second attempt to execute the first instruction may be made. While these specific examples are provided for ease of explanation it should be noted that the underlying principles of the invention are not limited to these specific details.

Thus in the embodiments of the invention described herein an instruction s normal destination registers are used for a dual role they hold the result in the case of normal execution and failure details if the instruction fails. This is different from current implementations where there are dedicated registers for computation results and for failure results and or where an exception handler must be invoked. These techniques may be applied to all providers of programmable processors CPUs DSPs CPUs . . . .

The use of fast failure handling of complex instructions opens up the possibility of implementing instructions such as XCALL which would otherwise be difficult to define as an efficient instruction. Processors using such efficient instructions will realize improved performance and reduced development costs.

Synchronous hardware accelerators need to ensure forward progress in case of exceptions for this they need to save their state in a location that survives save and restore operations such as XSAVE XRESTORE in x86 architectures . One embodiment of the invention enables this operation by extending the save restore area in order to support new hardware accelerators such as those described above and illustrated in .

One embodiment of the invention uses the stack area in memory for storing the intermediate state of synchronous hardware accelerators to allow for a robust exception model including handling task switching and core migration without operating system OS enabling. In particular the embodiments of the invention allow accelerators such as synchronous hardware accelerators to save their state in the memory stack and safely restore their state following various types of processor events e.g. such as exceptions managed by an exception handler as described below .

In one embodiment the hardware accelerator invocation is treated as a CALL instruction in which the accelerator may consume an area on the user s stack to maintain its state. When an exception and or interrupt forces the accelerator to pause this state is automatically persistent and is available when the accelerator is resumed following the exception handler context switch and or core migration. In the latter case the hardware accelerator resuming the computation may be a different one associated with the new core . In such a case the new core may access the saved state within the stack e.g. from memory or a shared cache .

In one embodiment the synchronous accelerator is treated like a library function which is invoked uses the stack following invocation and then releases this portion of the stack when completed behaving like a function call . In one embodiment when the accelerator is invoked the stack pointer is moved to work with the invoked accelerator s local variables. When the invocation is complete the stack pointer is returned to the place that it originally was so that caller can start where it left off when the call occurred. In one embodiment in the even that an exception handler is invoked the program s stack pointer is adjusted to reflect the accelerator s stack usage thereby ensuring that the exception handler does not modify the accelerator s save area.

One embodiment of the invention is illustrated in which shows a hardware stack in memory an application hardware thread and an accelerator thread . The particular stack illustrated in includes a caller stack area for storing data associated with the execution of the application hardware thread an accelerator save area for storing data associated with the execution of the accelerator thread and an exception handler stack area for storing data associated with the execution of an exception handler .

In one embodiment during the execution of the application hardware thread an accelerator function is invoked. In response the stack pointer is adjusted to point to the top of the accelerator save area and the entries in the translation lookaside buffer TLB associated with the accelerator save area are locked at . One reason for doing so is that if an exception occurs and the accelerator saves its state be it on the stack or in a another designated memory area it is desirable to avoid an additional page fault which would convert the original exception into a double one. One way to avoid this is to lock the TLB page entry or entries for the accelerator save area when the accelerator begins work thereby ensuring that no such page fault will be generated. The OS can still mark the page as unavailable but it is forced to defer physically evicting it until the next context switch when the thread isn t running at all and the accelerator state is safely saved . On return from the context switch the accelerator re acquires the TLB page entries which may point at a different physical locations load the state and continue. A large accelerator save area may span multiple TLB pages in extreme cases dozens of 4 k pages . The number of TLB entries that need to be locked can be reduced by using large pages e.g. 64 k pages .

At the accelerator performs operations based on to the command which it is executing and at saves its current state to the accelerator save area within the stack . It then unlocks the TLB which had been locked at to avoid an additional page fault as described above . As illustrated an exception event is detected which is passed to an exception handler executed within the application hardware thread . During execution the execution handler may read write using a portion of the stack i.e. it uses the exception handler stack to store intermediate state information during the handling of the exception condition . Once the exception handler has completed its operations it allows the accelerator thread to resume.

At the accelerator again locks the TLB for the same reasons as stated above and at it loads the state which had previously been stored to the accelerator save area . Note that at this stage the accelerator thread may in fact be executed on different core or processor than the first portion of the accelerator thread operations . In such a case it may simply load the saved accelerator state from the accelerator save area which may be physically located in a shared memory or cache. It then completes it s thread of execution at unlocks the TLB at and completes at . Control is then transferred back to the application hardware thread which resets the stack pointer to the top of the accelerator save area i.e. where it left off when it began execution of the accelerator thread .

It will be appreciated that various modifications to the specific details provide above may be implemented while still complying with the underlying principles of the invention. For example in one embodiment a specific memory region may be designated for the accelerator to hold its state in rather than using the stack . In this case there is no need to modify the program s stack pointer for the exception handler.

In either embodiment the techniques described herein allow accelerators to work transparently when the invoking thread is migrated between symmetrical cores the accelerator on one core saves its state to memory and when the thread is scheduled on another core the accelerator there loads the data from memory e.g. via a shared common cache for efficiency . Thus the embodiments of the invention described herein allow an accelerator to transparently save its state and ensure forward progress in the presence of exceptions context switches and or core migrations without OS enabling e.g. without modifying XSAVE XRESTORE and or adding architectural registers . This in turn permits the use of accelerator forms that previously required the addition of new architectural registers and OS enabling via modified XSAVE. Processors using such accelerators realize improved performance and reduced development costs.

The embodiments of the invention below define a hybrid processor core architecture in which a single program can contain both latency and throughput components. In one embodiment of the invention the main application executes on the latency optimized clusters as is done today and the throughput parts are coded as a part of the main program i.e. using the same instruction set architecture ISA and executed on new throughput optimized hardware clusters. In one embodiment commands are invoked on the throughput optimized hardware by way of an instruction such as XCALL described above. However the underlying principles of the invention are not limited to this particular implementation.

The latency optimized hardware components and throughput optimized hardware components may be logical units within the same processor chip or core. Alternatively the latency optimized hardware components may be on one chip and the and throughput optimized hardware components may be on a different chip either in the same semiconductor package or on different packages and connected via a communication bus e.g. such as a PCI Express Direct Media Interface DMS or other type of communication bus . In yet another embodiment some of the throughput optimized hardware components may be on the same chip or core as the latency optimized hardware components while other throughput optimized hardware components may be on a different chip or core. The embodiments of the invention described herein are not limited to any particular chip packaging configuration and supports implementations with multiple different types of latency optimized hardware components and throughput optimized hardware components .

In one embodiment the transfer of control between the latency optimized hardware and the accelerated throughput oriented hardware is done under explicit application control. That is a specific instruction triggers the throughput optimized hardware which in turn invokes the application provided throughput code. The throughput optimized hardware of one embodiment is responsible for scheduling multiple concurrent instances of the throughput code in separate concurrent hardware micro architectural threads Threads .

In one embodiment from the point of view of the operating system the application is executing on a single thread regardless of whether it is running on the latency optimized hardware in multiple Threads or on the throughput optimized hardware maintaining the illusion that the program as a whole is one single thread to the operating system. Transfer of control between the latency and throughput hardware is transparent without context switches middleware intervention core migration etc.

As illustrated in in one embodiment the main program code is executed on a set of latency clusters i.e. latency oriented functional units such as x86 functional units . A primary instruction pointer identifies the current point of execution for the main instruction stream. As indicated in one embodiment the main instruction stream comprises x86 program code. However the underlying principles of the invention are not limited to an x86 implementation.

In one embodiment the throughput program code is included with the latency program code as illustrated. In response to detecting the need to execute the throughput code one embodiment of the invention triggers a front end unit of a set of throughput clusters which distributes the throughput code to be executed by a set of processor elements . By way of example and not limitation the XCALL instruction mentioned above may trigger the front end unit to retrieve a command from the command register and parameters from the parameter register and distribute the command for execution by one or more processor elements .

In the example shown in two processor elements are illustrated PE 1 and PE 2 . Processor element is concurrently executing two Threads Thread 1.1 and Thread 1.2 and processor element is concurrently executing two Threads Thread 2.1 and Thread 2.2 . Thus in this embodiment each of the processor elements are capable of simultaneous multithreading i.e. simultaneously executing multiple Threads . In one embodiment each of the Threads comprises a series of micro operations or ops and includes its own micro instruction pointer IP respectively used by each processor element to maintain the current point of Thread execution.

The processor elements may be homogeneous each capable of executing any one of the Threads or heterogeneous each designed to execute specific types of ops . For example one processor element may include functional units for executing sort or loop operations while another processor element may include functional units for executing graphics operations. Of course the underlying principles of the invention are not limited to any specific set of processor elements.

The hybrid processor core architecture illustrated in allows the use of the same instruction set architecture ISA to code the throughput portions of the application in contrast to current implementations where throughput program code is developed in specialized programming languages and ISAs such as for DSPs and CPUs . Consequently the same ISA and tool chain is used for both the latency and throughput parts and the complete application can be developed naturally as a single program.

Embodiments of the instruction s described herein may be embodied in different formats. Additionally exemplary systems architectures and pipelines are detailed below. Embodiments of the instruction s may be executed on such systems architectures and pipelines but are not limited to those detailed.

A vector friendly instruction format is an instruction format that is suited for vector instructions e.g. there are certain fields specific to vector operations . While embodiments are described in which both vector and scalar operations are supported through the vector friendly instruction format alternative embodiments use only vector operations the vector friendly instruction format.

While embodiments of the invention will be described in which the vector friendly instruction format supports the following a 64 byte vector operand length or size with 32 bit 4 byte or 64 bit 8 byte data element widths or sizes and thus a 64 byte vector consists of either 16 doubleword size elements or alternatively 8 quadword size elements a 64 byte vector operand length or size with 16 bit 2 byte or 8 bit 1 byte data element widths or sizes a 32 byte vector operand length or size with 32 bit 4 byte 64 bit 8 byte 16 bit 2 byte or 8 bit 1 byte data element widths or sizes and a 16 byte vector operand length or size with 32 bit 4 byte 64 bit 8 byte 16 bit 2 byte or 8 bit 1 byte data element widths or sizes alternative embodiments may support more less and or different vector operand sizes e.g. 256 byte vector operands with more less or different data element widths e.g. 128 bit 16 byte data element widths .

The class A instruction templates in include 1 within the no memory access instruction templates there is shown a no memory access full round control type operation instruction template and a no memory access data transform type operation instruction template and 2 within the memory access instruction templates there is shown a memory access temporal instruction template and a memory access non temporal instruction template. The class B instruction templates in include 1 within the no memory access instruction templates there is shown a no memory access write mask control partial round control type operation instruction template and a no memory access write mask control vsize type operation instruction template and 2 within the memory access instruction templates there is shown a memory access write mask control instruction template.

The generic vector friendly instruction format includes the following fields listed below in the order illustrated in .

Format field a specific value an instruction format identifier value in this field uniquely identifies the vector friendly instruction format and thus occurrences of instructions in the vector friendly instruction format in instruction streams. As such this field is optional in the sense that it is not needed for an instruction set that has only the generic vector friendly instruction format.

Register index field its content directly or through address generation specifies the locations of the source and destination operands be they in registers or in memory. These include a sufficient number of bits to select N registers from a P Q e.g. 32 512 16 128 32 1024 64 1024 register file. While in one embodiment N may be up to three sources and one destination register alternative embodiments may support more or less sources and destination registers e.g. may support up to two sources where one of these sources also acts as the destination may support up to three sources where one of these sources also acts as the destination may support up to two sources and one destination .

Modifier field its content distinguishes occurrences of instructions in the generic vector instruction format that specify memory access from those that do not that is between no memory access instruction templates and memory access instruction templates. Memory access operations read and or write to the memory hierarchy in some cases specifying the source and or destination addresses using values in registers while non memory access operations do not e.g. the source and destinations are registers . While in one embodiment this field also selects between three different ways to perform memory address calculations alternative embodiments may support more less or different ways to perform memory address calculations.

Augmentation operation field its content distinguishes which one of a variety of different operations to be performed in addition to the base operation. This field is context specific. In one embodiment of the invention this field is divided into a class field an alpha field and a beta field . The augmentation operation field allows common groups of operations to be performed in a single instruction rather than 2 3 or 4 instructions.

Scale field its content allows for the scaling of the index field s content for memory address generation e.g. for address generation that uses 2 index base .

Displacement Field A its content is used as part of memory address generation e.g. for address generation that uses 2 index base displacement .

Displacement Factor Field B note that the juxtaposition of displacement field A directly over displacement factor field B indicates one or the other is used its content is used as part of address generation it specifies a displacement factor that is to be scaled by the size of a memory access N where N is the number of bytes in the memory access e.g. for address generation that uses 2 index base scaled displacement . Redundant low order bits are ignored and hence the displacement factor field s content is multiplied by the memory operands total size N in order to generate the final displacement to be used in calculating an effective address. The value of N is determined by the processor hardware at runtime based on the full opcode field described herein and the data manipulation field C. The displacement field A and the displacement factor field B are optional in the sense that they are not used for the no memory access instruction templates and or different embodiments may implement only one or none of the two.

Data element width field its content distinguishes which one of a number of data element widths is to be used in some embodiments for all instructions in other embodiments for only some of the instructions . This field is optional in the sense that it is not needed if only one data element width is supported and or data element widths are supported using some aspect of the opcodes.

Write mask field its content controls on a per data element position basis whether that data element position in the destination vector operand reflects the result of the base operation and augmentation operation. Class A instruction templates support merging writemasking while class B instruction templates support both merging and zeroing writemasking. When merging vector masks allow any set of elements in the destination to be protected from updates during the execution of any operation specified by the base operation and the augmentation operation in other one embodiment preserving the old value of each element of the destination where the corresponding mask bit has a 0. In contrast when zeroing vector masks allow any set of elements in the destination to be zeroed during the execution of any operation specified by the base operation and the augmentation operation in one embodiment an element of the destination is set to 0 when the corresponding mask bit has a 0 value. A subset of this functionality is the ability to control the vector length of the operation being performed that is the span of elements being modified from the first to the last one however it is not necessary that the elements that are modified be consecutive. Thus the write mask field allows for partial vector operations including loads stores arithmetic logical etc. While embodiments of the invention are described in which the write mask field s content selects one of a number of write mask registers that contains the write mask to be used and thus the write mask field s content indirectly identifies that masking to be performed alternative embodiments instead or additional allow the mask write field s content to directly specify the masking to be performed.

Immediate field its content allows for the specification of an immediate. This field is optional in the sense that is it not present in an implementation of the generic vector friendly format that does not support immediate and it is not present in instructions that do not use an immediate.

Class field its content distinguishes between different classes of instructions. With reference to the contents of this field select between class A and class B instructions. In rounded corner squares are used to indicate a specific value is present in a field e.g. class A A and class B B for the class field respectively in .

In the case of the non memory access instruction templates of class A the alpha field is interpreted as an RS field A whose content distinguishes which one of the different augmentation operation types are to be performed e.g. round A. and data transform A. are respectively specified for the no memory access round type operation and the no memory access data transform type operation instruction templates while the beta field distinguishes which of the operations of the specified type is to be performed. In the no memory access instruction templates the scale field the displacement field A and the displacement scale field B are not present.

In the no memory access full round control type operation instruction template the beta field is interpreted as a round control field A whose content s provide static rounding. While in the described embodiments of the invention the round control field A includes a suppress all floating point exceptions SAE field and a round operation control field alternative embodiments may support may encode both these concepts into the same field or only have one or the other of these concepts fields e.g. may have only the round operation control field .

SAE field its content distinguishes whether or not to disable the exception event reporting when the SAE field s content indicates suppression is enabled a given instruction does not report any kind of floating point exception flag and does not raise any floating point exception handler.

Round operation control field its content distinguishes which one of a group of rounding operations to perform e.g. Round up Round down Round towards zero and Round to nearest . Thus the round operation control field allows for the changing of the rounding mode on a per instruction basis. In one embodiment of the invention where a processor includes a control register for specifying rounding modes the round operation control field s content overrides that register value.

In the no memory access data transform type operation instruction template the beta field is interpreted as a data transform field B whose content distinguishes which one of a number of data transforms is to be performed e.g. no data transform swizzle broadcast .

In the case of a memory access instruction template of class A the alpha field is interpreted as an eviction hint field B whose content distinguishes which one of the eviction hints is to be used in temporal B. and non temporal B. are respectively specified for the memory access temporal instruction template and the memory access non temporal instruction template while the beta field is interpreted as a data manipulation field C whose content distinguishes which one of a number of data manipulation operations also known as primitives is to be performed e.g. no manipulation broadcast up conversion of a source and down conversion of a destination . The memory access instruction templates include the scale field and optionally the displacement field A or the displacement scale field B.

Vector memory instructions perform vector loads from and vector stores to memory with conversion support. As with regular vector instructions vector memory instructions transfer data from to memory in a data element wise fashion with the elements that are actually transferred is dictated by the contents of the vector mask that is selected as the write mask.

Temporal data is data likely to be reused soon enough to benefit from caching. This is however a hint and different processors may implement it in different ways including ignoring the hint entirely.

Non temporal data is data unlikely to be reused soon enough to benefit from caching in the 1st level cache and should be given priority for eviction. This is however a hint and different processors may implement it in different ways including ignoring the hint entirely.

In the case of the instruction templates of class B the alpha field is interpreted as a write mask control Z field C whose content distinguishes whether the write masking controlled by the write mask field should be a merging or a zeroing.

In the case of the non memory access instruction templates of class B part of the beta field is interpreted as an RL field A whose content distinguishes which one of the different augmentation operation types are to be performed e.g. round A. and vector length VSIZE A. are respectively specified for the no memory access write mask control partial round control type operation instruction template and the no memory access write mask control VSIZE type operation instruction template while the rest of the beta field distinguishes which of the operations of the specified type is to be performed. In the no memory access instruction templates the scale field the displacement field A and the displacement scale filed B are not present.

In the no memory access write mask control partial round control type operation instruction template the rest of the beta field is interpreted as a round operation field A and exception event reporting is disabled a given instruction does not report any kind of floating point exception flag and does not raise any floating point exception handler .

Round operation control field A just as round operation control field its content distinguishes which one of a group of rounding operations to perform e.g. Round up Round down Round towards zero and Round to nearest . Thus the round operation control field A allows for the changing of the rounding mode on a per instruction basis. In one embodiment of the invention where a processor includes a control register for specifying rounding modes the round operation control field s content overrides that register value.

In the no memory access write mask control VSIZE type operation instruction template the rest of the beta field is interpreted as a vector length field B whose content distinguishes which one of a number of data vector lengths is to be performed on e.g. 128 256 or 512 byte .

In the case of a memory access instruction template of class B part of the beta field is interpreted as a broadcast field B whose content distinguishes whether or not the broadcast type data manipulation operation is to be performed while the rest of the beta field is interpreted the vector length field B. The memory access instruction templates include the scale field and optionally the displacement field A or the displacement scale field B.

With regard to the generic vector friendly instruction format a full opcode field is shown including the format field the base operation field and the data element width field . While one embodiment is shown where the full opcode field includes all of these fields the full opcode field includes less than all of these fields in embodiments that do not support all of them. The full opcode field provides the operation code opcode .

The augmentation operation field the data element width field and the write mask field allow these features to be specified on a per instruction basis in the generic vector friendly instruction format.

The combination of write mask field and data element width field create typed instructions in that they allow the mask to be applied based on different data element widths.

The various instruction templates found within class A and class B are beneficial in different situations. In some embodiments of the invention different processors or different cores within a processor may support only class A only class B or both classes. For instance a high performance general purpose out of order core intended for general purpose computing may support only class B a core intended primarily for graphics and or scientific throughput computing may support only class A and a core intended for both may support both of course a core that has some mix of templates and instructions from both classes but not all templates and instructions from both classes is within the purview of the invention . Also a single processor may include multiple cores all of which support the same class or in which different cores support different class. For instance in a processor with separate graphics and general purpose cores one of the graphics cores intended primarily for graphics and or scientific computing may support only class A while one or more of the general purpose cores may be high performance general purpose cores with out of order execution and register renaming intended for general purpose computing that support only class B. Another processor that does not have a separate graphics core may include one more general purpose in order or out of order cores that support both class A and class B. Of course features from one class may also be implement in the other class in different embodiments of the invention. Programs written in a high level language would be put e.g. just in time compiled or statically compiled into an variety of different executable forms including 1 a form having only instructions of the class es supported by the target processor for execution or 2 a form having alternative routines written using different combinations of the instructions of all classes and having control flow code that selects the routines to execute based on the instructions supported by the processor which is currently executing the code.

It should be understood that although embodiments of the invention are described with reference to the specific vector friendly instruction format in the context of the generic vector friendly instruction format for illustrative purposes the invention is not limited to the specific vector friendly instruction format except where claimed. For example the generic vector friendly instruction format contemplates a variety of possible sizes for the various fields while the specific vector friendly instruction format is shown as having fields of specific sizes. By way of specific example while the data element width field is illustrated as a one bit field in the specific vector friendly instruction format the invention is not so limited that is the generic vector friendly instruction format contemplates other sizes of the data element width field .

The generic vector friendly instruction format includes the following fields listed below in the order illustrated in .

Format Field EVEX Byte 0 bits 7 0 the first byte EVEX Byte 0 is the format field and it contains 0x62 the unique value used for distinguishing the vector friendly instruction format in one embodiment of the invention .

REX field EVEX Byte 1 bits 7 5 consists of a EVEX.R bit field EVEX Byte 1 bit 7 R EVEX.X bit field EVEX byte 1 bit 6 X and 1157BEX byte 1 bit 5 B . The EVEX.R EVEX.X and EVEX.B bit fields provide the same functionality as the corresponding VEX bit fields and are encoded using 1 s complement form i.e. ZMM0 is encoded as 1111B ZMM15 is encoded as 0000B. Other fields of the instructions encode the lower three bits of the register indexes as is known in the art rrr xxx and bbb so that Rrrr Xxxx and Bbbb may be formed by adding EVEX.R EVEX.X and EVEX.B.

REX field this is the first part of the REX field and is the EVEX.R bit field EVEX Byte 1 bit 4 R that is used to encode either the upper 16 or lower 16 of the extended 32 register set. In one embodiment of the invention this bit along with others as indicated below is stored in bit inverted format to distinguish in the well known x86 32 bit mode from the BOUND instruction whose real opcode byte is 62 but does not accept in the MOD R M field described below the value of 11 in the MOD field alternative embodiments of the invention do not store this and the other indicated bits below in the inverted format. A value of 1 is used to encode the lower 16 registers. In other words R Rrrr is formed by combining EVEX.R EVEX.R and the other RRR from other fields.

Opcode map field EVEX byte 1 bits 3 0 mmmm its content encodes an implied leading opcode byte 0F 0F 38 or 0F 3 .

Data element width field EVEX byte 2 bit 7 W is represented by the notation EVEX.W. EVEX.W is used to define the granularity size of the datatype either 32 bit data elements or 64 bit data elements .

EVEX.vvvv EVEX Byte 2 bits 6 3 vvvv the role of EVEX.vvvv may include the following 1 EVEX.vvvv encodes the first source register operand specified in inverted 1 s complement form and is valid for instructions with 2 or more source operands 2 EVEX.vvvv encodes the destination register operand specified in 1 s complement form for certain vector shifts or 3 EVEX.vvvv does not encode any operand the field is reserved and should contain 1111 b. Thus EVEX.vvvv field encodes the 4 low order bits of the first source register specifier stored in inverted 1 s complement form. Depending on the instruction an extra different EVEX bit field is used to extend the specifier size to 32 registers.

EVEX.U 1168 Class field EVEX byte 2 bit 2 U If EVEX.0 0 it indicates class A or EVEX.U0 if EVEX.U 1 it indicates class B or EVEX.U1.

Prefix encoding field EVEX byte 2 bits 1 0 pp provides additional bits for the base operation field. In addition to providing support for the legacy SSE instructions in the EVEX prefix format this also has the benefit of compacting the SIMD prefix rather than requiring a byte to express the SIMD prefix the EVEX prefix requires only 2 bits . In one embodiment to support legacy SSE instructions that use a SIMD prefix 66H F2H F3H in both the legacy format and in the EVEX prefix format these legacy SIMD prefixes are encoded into the SIMD prefix encoding field and at runtime are expanded into the legacy SIMD prefix prior to being provided to the decoder s PLA so the PLA can execute both the legacy and EVEX format of these legacy instructions without modification . Although newer instructions could use the EVEX prefix encoding field s content directly as an opcode extension certain embodiments expand in a similar fashion for consistency but allow for different meanings to be specified by these legacy SIMD prefixes. An alternative embodiment may redesign the PLA to support the 2 bit SIMD prefix encodings and thus not require the expansion.

Alpha field EVEX byte 3 bit 7 EH also known as EVEX.EH EVEX.rs EVEX.RL EVEX.write mask control and EVEX.N also illustrated with as previously described this field is context specific.

Beta field EVEX byte 3 bits 6 4 SSS also known as EVEX.s EVEX.r EVEX.rr1 EVEX.LL0 EVEX.LLB also illustrated with as previously described this field is context specific.

REX field this is the remainder of the REX field and is the EVEX.V bit field EVEX Byte 3 bit 3 V that may be used to encode either the upper 16 or lower 16 of the extended 32 register set. This bit is stored in bit inverted format. A value of 1 is used to encode the lower 16 registers. In other words V VVVV is formed by combining EVEX.V EVEX.vvvv.

Write mask field EVEX byte 3 bits 2 0 kkk its content specifies the index of a register in the write mask registers as previously described. In one embodiment of the invention the specific value EVEX.kkk 000 has a special behavior implying no write mask is used for the particular instruction this may be implemented in a variety of ways including the use of a write mask hardwired to all ones or hardware that bypasses the masking hardware .

Real Opcode Field Byte 4 is also known as the opcode byte. Part of the opcode is specified in this field.

MOD R M Field Byte 5 includes MOD field Reg field and R M field . As previously described the MOD field s content distinguishes between memory access and non memory access operations. The role of Reg field can be summarized to two situations encoding either the destination register operand or a source register operand or be treated as an opcode extension and not used to encode any instruction operand. The role of R M field may include the following encoding the instruction operand that references a memory address or encoding either the destination register operand or a source register operand.

Scale Index Base SIB Byte Byte 6 As previously described the scale field s content is used for memory address generation. SIB.xxx and SIB.bbb the contents of these fields have been previously referred to with regard to the register indexes Xxxx and Bbbb.

Displacement field A Bytes 7 10 when MOD field contains 10 bytes 7 10 are the displacement field A and it works the same as the legacy 32 bit displacement disp32 and works at byte granularity.

Displacement factor field B Byte 7 when MOD field contains 01 byte 7 is the displacement factor field B. The location of this field is that same as that of the legacy x86 instruction set 8 bit displacement disp8 which works at byte granularity. Since disp8 is sign extended it can only address between 128 and 127 bytes offsets in terms of 64 byte cache lines disp8 uses 8 bits that can be set to only four really useful values 128 64 0 and 64 since a greater range is often needed disp32 is used however disp32 requires 4 bytes. In contrast to disp8 and disp32 the displacement factor field B is a reinterpretation of disp8 when using displacement factor field B the actual displacement is determined by the content of the displacement factor field multiplied by the size of the memory operand access N . This type of displacement is referred to as disp8 N. This reduces the average instruction length a single byte of used for the displacement but with a much greater range . Such compressed displacement is based on the assumption that the effective displacement is multiple of the granularity of the memory access and hence the redundant low order bits of the address offset do not need to be encoded. In other words the displacement factor field B substitutes the legacy x86 instruction set 8 bit displacement. Thus the displacement factor field B is encoded the same way as an x86 instruction set 8 bit displacement so no changes in the ModRM SIB encoding rules with the only exception that disp8 is overloaded to disp8 N. In other words there are no changes in the encoding rules or encoding lengths but only in the interpretation of the displacement value by hardware which needs to scale the displacement by the size of the memory operand to obtain a byte wise address offset .

When U 1 the alpha field EVEX byte 3 bit 7 EH is interpreted as the write mask control Z field C. When U 1 and the MOD field contains 11 signifying a no memory access operation part of the beta field EVEX byte 3 bit 4 S is interpreted as the RL field A when it contains a 1 round A. the rest of the beta field EVEX byte 3 bit 6 5 S is interpreted as the round operation field A while when the RL field A contains a 0 VSIZE .A the rest of the beta field EVEX byte 3 bit 6 5 S is interpreted as the vector length field B EVEX byte 3 bit 6 5 L . When U 1 and the MOD field contains 00 01 or 10 signifying a memory access operation the beta field EVEX byte 3 bits 6 4 SSS is interpreted as the vector length field B EVEX byte 3 bit 6 5 L and the broadcast field B EVEX byte 3 bit 4 B .

In other words the vector length field B selects between a maximum length and one or more other shorter lengths where each such shorter length is half the length of the preceding length and instructions templates without the vector length field B operate on the maximum vector length. Further in one embodiment the class B instruction templates of the specific vector friendly instruction format operate on packed or scalar single double precision floating point data and packed or scalar integer data. Scalar operations are operations performed on the lowest order data element position in an zmm ymm xmm register the higher order data element positions are either left the same as they were prior to the instruction or zeroed depending on the embodiment.

Write mask registers in the embodiment illustrated there are 8 write mask registers k0 through k7 each 64 bits in size. In an alternate embodiment the write mask registers are 16 bits in size. As previously described in one embodiment of the invention the vector mask register k0 cannot be used as a write mask when the encoding that would normally indicate k0 is used for a write mask it selects a hardwired write mask of 0xFFFF effectively disabling write masking for that instruction.

General purpose registers in the embodiment illustrated there are sixteen 64 bit general purpose registers that are used along with the existing x86 addressing modes to address memory operands. These registers are referenced by the names RAX RBX RCX RDX RBP RSI RDI RSP and R8 through R15.

Scalar floating point stack register file x87 stack on which is aliased the MMX packed integer flat register file in the embodiment illustrated the x87 stack is an eight element stack used to perform scalar floating point operations on 32 64 80 bit floating point data using the x87 instruction set extension while the MMX registers are used to perform operations on 64 bit packed integer data as well as to hold operands for some operations performed between the MMX and XMM registers.

Alternative embodiments of the invention may use wider or narrower registers. Additionally alternative embodiments of the invention may use more less or different register files and registers.

As illustrated in the computer system which is a form of a data processing system includes the interconnect s bus es communicatively coupling the processor cluster s to the various other system components. The interconnects buses may include various levels of interconnection which may be connected to each other through various bridges controllers and or adapters as is well known in the art. By way of example the interconnect s may include a quick path interconnect QPI component a Peripheral Component Interconnect Express PCI Express component or other technologies for interconnecting the various components to the processor cluster s . The underlying principles of the invention are not limited to any particular interconnects or buses.

Although illustrated as a separate component in the accelerator s may be integrated within the processor cluster s . Alternatively some accelerator s may be integrated within the processor cluster s and some may be connected to the computer system via the interconnect s bus es . As described in detail above the accelerators are adapted to efficiently execute certain types of program code e.g. vector SIMD operations graphics operations sort and loop operations etc . By way of example the general purpose processor clusters may include execution logic within a processor core for executing general purpose instructions such as x86 instructions including instructions which invoke commands on the accelerator clusters . The underlying principles of the invention however are not limited to any particular type of general purpose clusters or accelerator clusters.

The embodiment illustrated in also includes a memory interface for coupling memory modules computer system. In one embodiment the memory modules are dual in line memory modules DIMMs such as random access memory RAM modules and the memory interface may generate the electrical signaling required to access the memory modules e.g. such as column address strobe CAS row address strobe RAS write enable WE and output enable OE signals .

In one embodiment the memory interface comprises logic and circuitry for interfacing with different types of memory modules including volatile memory modules such as RAM and non volatile memory modules such as Phase Change Memory PCM also sometimes referred to as phase change random access memory PRAM or PCRAM PCME Ovonic Unified Memory or Chalcogenide RAM C RAM . For example one embodiment of the computer system implements a two level 2L memory hierarchy comprising a near memory portion which may be a volatile memory such as RAM and a far memory portion which may be implemented as a Phase Change Memory PCM . In such a case the memory interface may include the logic and circuitry required to access both memory types.

The illustrated embodiment also includes one or more storage interfaces for interfacing with storage devices such as hard drives or other non volatile storage devices. In one embodiment the storage interface comprises a serial ATA storage interface and the hard drive comprises a solid state drive SSD or a magnetic storage device. In an embodiment of the invention which uses 2LM memory as discussed above a portion of the storage on the storage device may be used for far memory or a portion of far memory .

The illustrated embodiment also includes a graphics interface for interfacing with one or more graphics processing units . The GP Us may be embedded on a motherboard of the computer system or on a separate card inserted in the motherboard e.g. via a PCI express graphics interface or other high speed graphics interface . A video output interface such as a digital video interface DVI High Definition Multimedia Interface HDMI or DisplayPort video output interface outputs a video stream to a monitor which renders video for the end user. As mentioned the GPUs may be implemented as accelerator components for executing graphics program code using any of the embodiments described herein.

The illustrated embodiment also includes an audio input interface for receiving multiple digital and analog audio inputs. For example a microphone may be coupled to one of the audio input interfaces to capture the user s voice e.g. during Web chats phone calls or for recording audio . Additionally a digital audio input may be used such as a Toslink interface.

The illustrated embodiment also includes a sensor hub for collecting data from various different system sensors . By way of example and not limitation the sensors may include mechanical sensors motion sensors and location sensors to detect a position and orientation of the computer system . For example in one embodiment the sensors may include multi axis accelerometers for detecting acceleration values along the X Y and Z axes and reporting to the data to the sensor hub. The sensor hub may then perform calculations to determine a current orientation of the computer system . For example if the computer system is a notebook computer the sensor hub may detect a current position of the computer monitor. The sensors may also include inertial sensors for detecting displacements from a reference location and or proximity sensors for detecting proximity to a user or other device. In one embodiment the sensors include a global positioning system GPS sensor or other sensor for determining the current global position of the computer system. The sensors may also include a magnetometer for detecting the orientation of the Earth s electric field i.e. to determine a current position of the computing system relative to North . The sensors may also include a gyro for detecting changes in orientation and an ambient light sensor for detecting current lighting conditions e.g. so that the sensor hub or other system component may responsively adjust the brightness of the monitor .

All of the data collected from the various sensors may be used to determine a current mode of operation and responsively adjust operation of the computing device . For example in response to the signals from the sensors the computing device may enter into a first mode of operation in which in which the accelerator invocations described herein are enabled and a second mode of operation in which the accelerator invocations described herein are disabled.

The illustrated embodiment also includes a camera interface for coupling to a video camera usable to capture motion video and still pictures. For example in one embodiment the camera interface gathers motion video for video conferencing applications in which the accelerator invocation techniques described herein may be used. For example one accelerator may be configured to efficiently encode video streams into the H.264 MPEG 4 AVC format. It should be noted however that the underlying principles of the invention are not limited to any particular video compression format.

The illustrated embodiment also includes a serial bus interface for establishing serial data communication with connected devices e.g. mobile phones tablets printers external cameras MIDI devices etc . This embodiment further includes an Ethernet interface for establishing network connections over an Ethernet network and a cellular interface for establishing voice and data connections over a cellular network using cellular communication protocols. Various cellular technologies may be employed including but not limited to 3rd Generation Partnership Project technologies e.g. 3GPP2 code division multiple access technologies e.g. CDMA2000 technology using 1xRTT EVDO eHRPD Long Term Evolution LTE technology and or LTE Advanced LTE A technology and Universal Mobile Telecommunications System UMTS technology such as WCDMA TDSCDMA. In addition the embodiment shown also includes a WiFi and or Bluetooth interface for establishing communication over WiFi channels e.g. 802.11 channels and or Bluetooth channels respectively. Each of the Ethernet Cellular and WiFi communication interfaces include a transceiver and other circuitry for generating analog transmission signals using the appropriate technology. In one embodiment an accelerator may also be invoked to support the network communication process e.g. for performing network baseband functions such as data encoding .

The illustrated embodiment also includes a power management interface for detecting current conditions within the computer system e.g. thermal power usage battery life etc and responsively adjusting power usage to each of the different system components. For example under certain conditions the power management interface may turn off the accelerator functions described herein to conserve power e.g. when the battery drops below a threshold value .

The illustrated embodiment also includes a power management interface may also include various different types of Input Output devices such as a cursor control e.g. mouse touchscreen touchpad etc. a keyboard etc. for receiving user input.

It will be appreciated that additional components not shown in may also be a part of the data processing system in certain embodiments of the invention and in certain embodiments of the invention fewer components than shown in may be used. In addition it will be appreciated that one or more buses and or interconnects not shown in may be used to interconnect the various components as is well known in the art.

Embodiments of the invention may include various steps which have been described above. The steps may be embodied in machine executable instructions which may be used to cause a general purpose or special purpose processor to perform the steps. Alternatively these steps may be performed by specific hardware components that contain hardwired logic for performing the steps or by any combination of programmed computer components and custom hardware components.

As described herein instructions may refer to specific configurations of hardware such as application specific integrated circuits ASICs configured to perform certain operations or having a predetermined functionality or software instructions stored in memory embodied in a non transitory computer readable medium. Thus the techniques shown in the figures can be implemented using code and data stored and executed on one or more electronic devices e.g. an end station a network element etc. . Such electronic devices store and communicate internally and or with other electronic devices over a network code and data using computer machine readable media such as non transitory computer machine readable storage media e.g. magnetic disks optical disks random access memory read only memory flash memory devices phase change memory and transitory computer machine readable communication media e.g. electrical optical acoustical or other form of propagated signals such as carrier waves infrared signals digital signals etc. . In addition such electronic devices typically include a set of one or more processors coupled to one or more other components such as one or more storage devices non transitory machine readable storage media user input output devices e.g. a keyboard a touchscreen and or a display and network connections. The coupling of the set of processors and other components is typically through one or more busses and bridges also termed as bus controllers . The storage device and signals carrying the network traffic respectively represent one or more machine readable storage media and machine readable communication media. Thus the storage device of a given electronic device typically stores code and or data for execution on the set of one or more processors of that electronic device. Of course one or more parts of an embodiment of the invention may be implemented using different combinations of software firmware and or hardware. Throughout this detailed description for the purposes of explanation numerous specific details were set forth in order to provide a thorough understanding of the present invention. It will be apparent however to one skilled in the art that the invention may be practiced without some of these specific details. In certain instances well known structures and functions were not described in elaborate detail in order to avoid obscuring the subject matter of the present invention. Accordingly the scope and spirit of the invention should be judged in terms of the claims which follow.

