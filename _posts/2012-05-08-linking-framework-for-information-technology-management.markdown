---

title: Linking framework for information technology management
abstract: A data synchronization task is received at a console, wherein the data synchronization task is associated with information technology management. A configuration document is configured using the data synchronization task, wherein the configuration document defines data synchronization through declarations. A linking framework is configured based on the configuration document. Data is synchronized from a first and second source to a target as defined by the configuration document.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09286368&OS=09286368&RS=09286368
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09286368
owner_city: Redmond
owner_country: US
publication_date: 20120508
---
This Application is a continuation of and claims benefit from U.S. patent application Ser. No. 11 933 217 that was filed on Oct. 31 2007 and that is incorporated herein by reference in it entirety.

Many problem domains especially Information Technology IT management have to deal with synchronizing and linking data residing in multiple stores. In IT management a general solution has been to put IT management related data in a Data Warehouse DW and a Configuration Management Database CMDB . However the problem of integrating multiple data sources to a CMDB or a data warehouse has been typically left to the customer e.g. system administrators . Today s IT management solutions fail to provide a general purpose extensible mechanism for data integration.

The following presents a simplified summary of the disclosure in order to provide a basic understanding to the reader. This summary is not an extensive overview of the disclosure and it does not identify key critical elements of the invention or delineate the scope of the invention. Its sole purpose is to present some concepts disclosed herein in a simplified form as a prelude to the more detailed description that is presented later.

Embodiments of the invention are directed to a linking framework for data synchronization. Synchronization processes are created and managed using declarative documents such as objects instead of manual coding or scripting. Embodiments of the linking framework provide data transformation joining and automated conflict resolution for data synchronization tasks.

Many of the attendant features will be more readily appreciated as the same become better understood by reference to the following detailed description considered in connection with the accompanying drawings.

The detailed description provided below in connection with the appended drawings is intended as a description of the present examples and is not intended to represent the only forms in which the present examples may be constructed or utilized. The description sets forth the functions of the examples and the sequence of steps for constructing and operating the examples. However the same or equivalent functions and sequences may be accomplished by different examples.

Embodiments of linking framework may be uses in various data synchronization scenarios. Data may become isolated sometimes referred to as data islands and needs to be consolidated or federated with other data stores. There are situations where data needs to be synched into a CMDB or data warehouse. At the same time there are objects in the CMDB which are configured via people processes like policies that need to be synched out to the configuration and deployment systems. Also there are situations where objects between two foreign stores or instances of CMDBs need to be federated.

Service manager may be part of an organization s IT management system such as Microsoft System Center to enable an organization to manage its computing resources. Management systems may perform activities such as monitoring of deployed hardware and software automate processes such as software installation and updates logging reporting and error handling and diagnosis. Service manager provides a centralized point for service requests knowledge and workflow for processes such as incident reporting problem handling change requests and asset management.

Linking framework provides integration of data related to the management of computing resources. Linking framework provides functionality such as transformation conflict resolution joins and pre and post processing watermark tracking batching and concurrency across multiple servers for load balancing and performance. The behavior of linking framework is driven by configuration documents in one embodiment implemented as configuration objects . All a user has to do is manipulate the configuration documents to affect a change in the data integration tasks of the linking framework. The declarative nature of the configuration documents releases the user from the burden of coding or scripting all the various data integration activities.

A user may interact with service manager using a console to create and or modify a data synchronization task. In one embodiment a user may manipulate a form on console to generate or modify configuration documents for use with linking framework . A user such as a system administrator may enact data integration activities without having to perform actual coding. The administrator simply fills in a form on console that in turn is used to configure the associated configuration documents. Code to support the configuration documents may be pulled from a linking framework library store such as a Service Manager SM store and executed by linking framework .

Service manager may be connected to operations manager . Operations manager provides monitoring and management of an organization s computing environment such as error handling and reporting services. In one embodiment operations manager includes a Microsoft System Center Operations Manager.

Service manager may be connected to configuration manager . Configuration manager handles asset deployment hardware and or software and updating. Configuration manager may also provide configuration monitoring to ensure systems comply with desired configuration models and policies. Configuration manager may also generate reports showing what operating systems applications and software updates are installed on an organization s machines. In one embodiment configuration manager includes a Microsoft System Center Configuration Manager.

Service manager may interact with Configuration Management Database CMDB Data Warehouse DW and one or more external stores . CMDB stores information related to the organization s computing assets and the relationships between them. DW stores historical information about the tasks performed by service manager . DW may be used for reporting and analysis. External store also referred to as a foreign store stores data associated with other system management software products besides service manager operation manager and configuration manager . For example service manager may be part of Microsoft System Center while external store stores data associated with an SAP Corporation system management product.

Turning to an embodiment of a linking framework engine is shown. Linking framework engine is an instance of linking framework . One or more components of linking framework engine are configured by configuration document shown by a dotted line in . Configuration document is generated by a configuration workflow discussed below in response to user input at console . It will be appreciated that multiple linking framework engines may be working at the same time to integrate data between one or more sources and one or more targets.

Linking framework engine receives data from one or more sources. The embodiment of shows sources and . Data from sources is processed by linking framework engine and the resulting data is saved to target . Sources may include operations manager configuration manager and external store . Target may include CMDB and DW . While the embodiment in has three sources and one target it will be appreciated that other embodiments may have alternative number of sources and targets.

Linking framework engine may include import connectors that receive data from sources respectively. Each import connector includes a trigger triggers respectively that indicates when its connector is to pull data from its source. A trigger may initiate the requesting of data by its respective connector based on a time schedule an event or other factor. In one embodiment the import connectors use throttling when retrieving data to minimize impact on the sources.

Embodiments of the invention may initiate synchronization i.e. a trigger based on other factors besides a pre determined time schedule. Typically synchronizations occur on a schedule. However sometimes one needs to synch on demand or on an event indicating an opportunity. Also in some situations it is most efficient to synch on a data change rather than on either a schedule or an event.

In one embodiment location and globalization may be handled by connectors in linking framework . For example linking framework may treat all data as Unicode and simply pass it along between workflows connectors and other components.

Data obtained by import connectors is forwarded to export connector . In one embodiment import connectors drop off the data in a temporary storage e.g. staging database where export connector may pick up the data. In another embodiment staging database may be used to store data pulled from a source when all the sources for a data synchronization are not available at the same time. For example suppose source is never available at the same time as sources e.g. due to access policies at sources connectivity issues permission security issues source machine down etc. . In this case import connector may pull data when source is available and put the data in staging database . When sources are available the data for the synchronization may be retrieved and also put in staging database . Now all the data for the synch is ready for export connector to process.

Export connector may perform various processes e.g. join conflict resolution etc. on the data before storing the data to target . It will be appreciated that the embodiments of synchronization processing are not limited to the examples below all of the examples are not necessarily used in all synchronization processing and embodiments herein are not limited to the order of synchronization processing discussed below.

In the embodiment of export connector includes transform modules . A transform module transforms the data as needed for target . For example data may be transformed from one schema used at source to a different schema used at target .

Transform modules may handle issues such as misaligned schemas that exist across stores. For example as data is moved between external stores and a CMDB or data warehouse the data needs to conform to a common schema. Since the external stores may not conform to the common schema in the CMDB or the data warehouse transformations in the linking framework may be needed. In one embodiment of the invention the data is transformed into a Service Manager Model Library schema.

Linking framework may provide identity management of data. In some situations the primary key for the same real world object e.g. a computer is different in different stores. For example Microsoft System Center Operations Manager recognizes a computer by Fully Qualified Domain Name FQDN Hewlett Packard OpenView recognizes the same computer by Internet Protocol IP address and Microsoft System Center Configuration Manager SCCM recognizes the same computer by a unique system hash.

In one embodiment of linking framework the identity of each document may be embedded in the path instance Uniform Resource Identifier URI of the document. The properties of a particular type may correspond to a primary key and using those properties a composite key may be constructed and used as the instance URI of the document during the transformation phase. In one embodiment the same set of properties should be used for all the instances of a given type and if the composite key later gets changed then the previous instances should be properly disposed of and new ones created. Otherwise data could be duplicated and cause redundant operations in linking framework .

After the data passes through transform modules the data may be joined using join module . In some cases the representation of an object at target is a join of multiple sources i.e. multiplex . In another embodiment the object at target uses only a portion of a source object i.e. demultiplex . Embodiments of the invention enable the joining of a variety of data. In some situations properties of interest are expressed using different data types or ways that need table lookups or other data manipulations to arrive at the required shape. Sometimes the representation of an object in the destination is a join of multiple source objects or vice versa.

In module also supports cross service joins. In one embodiment in a cross service join two or more objects that need to be joined come from different stores that are in different non joinable forms and are available at different schedules. Join module may be configured to wait for source data from different stores on different schedules so that a join may be conducted correctly.

In another embodiment join may occur before a transformation. For example a line of data from a table in staging database may be read at once where the line of data includes data from multiple sources. The line of data is then transformed as defined in the configuration document.

Next at conflict module any conflicts between the data from sources are reconciled. Conflict module provides automated resolution as well as error handling for irresolvable conflicts. For example sometimes the same resulting object from two sources or picked up at two times from the same source is in conflict. If the source stores do not contain adequate information to accurately specify when a particular change has been done on entities since the retrieval times from these sources may be different predetermined intervals set by the configuration of the linking framework conflicts between multiple sources for the same instances would be impossible to reconcile accurately. Data times that conflict in such a way that no policy driven resolution can be applied may be parked in a file for later debugging such as at staging database while the linking framework continues with other items. Additionally if the resulting data saved at target does not make sense to a user the user may use the linking framework to trace the data back to the source of the data and debug the problem at the source.

After conflict module the data may be handled by cache module . The data is cached to local store such as staging database . In one embodiment the data is passed from cache module to target in a batch style. In one embodiment this batching may be conducted in a manner to minimize impact on target . For example the batching may be held until night when activity at target is minimal. In another example the passing of data to target is throttled by cache module to a level to prevent overwhelming target . Also data persisted in a batch style enables cache module to resume storing the data to target after an interruption e.g. network outage power failure at target etc. without having to restart the data storing from the beginning.

Turning to a flowchart shows operations of synchronizing data by a linking framework in accordance with an embodiment of the invention. In one embodiment at least a portion of flowchart may be implemented by computer readable instructions executable by one or more computing devices.

Starting with operation a user fills in a form e.g. a service request form at a console for a synchronization task. The user may be creating a new activity or changing an existing activity. For example to create a synchronization task a system administrator merely identifies the source s the trigger s for the source s e.g. a time schedule the target s the data types and the like. In one example the system administrator may want to initiate a synchronization task because the system administrator would like to install software on a set of assets e.g. clients which are not known to service manager e.g. saved to CMDB or DW yet. In another example the system administrator initiates a synchronization task because the analysts need information about certain assets that do not exist at service manager e.g. saved to CMDB or DW where the assets are involved in incidents the analysts are tracking.

Next in operation the synchronization task information in the form is used to configure a configuration document for the synchronization task. In another embodiment the configuration document is implemented as a configuration object stored in CMDB . In one embodiment code to implement the tasks defined in the configuration document is identified and referenced in the configuration document such as a reference to a code library.

For example the user does not have to code for an import connector or know how to connect to a source. The user declares the parameters of the import connector e.g. source data type trigger etc. and the proper code to implement the connector is provided by the linking framework such as from Service Manager SM store discussed below.

Next at operation the linking framework waits for a synchronization to be triggered e.g. by a scheduled time an event or other trigger as defined by the configuration document. Once a synchronization is triggered the logic continues to operation . It will be appreciated that multiple configuration documents may be active and have different synchronization triggers. A single configuration document is described in flowchart for the sake of clarity.

Proceeding to operation the linking framework is configured as defined by the configuration document. For example import export connectors are configured as described in the configuration document. Next in operation data is processed per the configuration document. For example data is obtained from a source by import connectors and transformed multiplexed demultiplexed and persisted to a target by export connectors as defined by the configuration document.

Continuing to operation the configuration document is optionally modified. In one embodiment the user may edit the configuration document using console . The user may edit various aspects including the source the target a trigger for an import connector and the like. After operation the logic returns to operation to wait for a synchronization to be triggered in accordance with the modified configuration document.

Turning to an embodiment of workflows for linking framework is shown. In general a workflow is a set of activities stored as a model that describes a real world process. Work passes through the workflow models from start to finish and work activities can be executed by system functions e.g. pulled from service manager store . A workflow provides a way of describing the order of execution and dependent relationships between pieces of work.

In a user creates a synchronization task at console . In one embodiment the user fills in a form indicating what activity the user wants done. The information entered by the user is received by configuration workflow . Configuration workflow generates a configuration document based on the user s inputs. In one embodiment code to implement the synchronization task defined in the configuration document is obtained from a code library such as service manager store .

The configuration document is passed from configuration workflow to scheduler workflow . Scheduler workflow periodically e.g. every 1 minute looks for configuration documents created by configuration workflow . Scheduler workflow determines whether the configuration document involves inbound workflows outbound workflows or both. Scheduler then places messages in a queue for inbound workflows and or outbound workflows . Scheduler workflow places the messages in queue when a trigger defined in the configuration document has been tripped to initiate the inbound outbound workflow as appropriate. As will be discussed below messages in queue may be associated with different configuration documents. Inbound outbound workflows and pull messages off the queue and handle data processing as defined by the configuration documents associated with the messages in queue .

Inbound workflow configures an import connector as defined by the configuration document associated with the message in queue . Import connector may collect data from various sources including but not limited to operations manager configuration manager and one or more external stores .

After the source data is collected by the inbound workflow import connector the data may temporarily stored in staging database . The data may then be picked up from staging database processed and persisted to the target by the outbound workflow export connector.

Outbound workflow configures an export connector as defined by the configuration document associated with message in queue . Export connector may send data to various targets such as but not limited to CMDB and DW .

In one embodiment linking framework may be extensible through a solution pack received at service manager . Solution pack includes resources to implement a particular aspect of information technology management. For example solution pack may include a new workflow including supporting code to be stored at service manager store and a group of forms for use with console that allow a user to interact with that new workflow. In one embodiment service manager is shipped as a product that includes solution packs for the workflows as shown in .

It will be appreciated that inbound workflow outbound workflow import connector and export connector are configured by configuration documents to generate linking framework engines such as described in connection with . One or more engines may be operation simultaneously as messages are handled by the inbound and outbound workflows. Messages may be associated with several different engines as the messages are processed by the inbound and outbound workflows. A linking framework engine is a logical construct of the linking framework at a point in time as the components of the linking framework are configured at that point in time.

Linking framework includes two types of connectors import connectors and export connectors. Connectors are components in linking framework which communicate with external sources and targets. In one embodiment connectors may be developed in any programming language as long as a Microsoft .NET wrapped entry point class is provided. In this embodiment connectors have no priority settings and all are treated the same.

Import connectors run under the application domain of inbound workflow . An inbound workflow loads the specified connector mentioned in the configuration document and calls the specified interface method.

Export connectors run under the application domain of outbound workflow . Export connectors are handed data from staging database via the outbound workflow and write the data into another system i.e. the target .

In one embodiment linking framework includes two types of export connectors a CMDB Connector and a DW Connector. In one embodiment a CMDB connector writes the data into CMDB after passing the data through an Extensible Stylesheet Language Transformations XSLT transformation. In one embodiment this connector uses an Upsert method in the Data Access Layer DAL for the CMDB SML runtime store and leaves the decision to Update or Insert a particular instance in the service manager runtime store. In one embodiment DAL provides a Merge method to be able to merge two documents rather than updating a document in its entirety.

A DW Connector writes the data into DW after passing the data through an XSLT transformation. In one embodiment the data is stored in relational tables.

In one embodiment export connectors differ from import connectors in that export connectors do not keep any state information nor persist any bookkeeping information. Export connectors work one batch of data at a time and therefore every time the outbound workflow loads an export connector the outbound workflow invokes a Configure method for the export workflow to program itself to be ready to process the upcoming batch.

Turning to an embodiment of a configuration document is shown. Configuration document is generated by configuration workflow and includes a link document a connector configuration document and a transformation Xform document . Configuration workflow creates configuration documents from templates in service manager store . In flowchart of configuration workflow checks the existence of DataSource and SyncSchedule documents operation . These documents are created and stored in service manager store when a user creates modifies a data synchronization configuration document at console . The DataSource document describes the endpoint address of the server from which the data transfer will be made from i.e. the source . It also contains information about how to connect to this server including the credentials to be used if necessary. The SyncSchedule document describes scheduling information for the data synchronization including the interval e.g. hourly daily weekly etc. .

When either the DataSource or SyncSchedule document are in the service manager store configuration workflow will be triggered to either add new linking framework configuration documents from preexisting template documents or update existing configuration documents operation . Template documents are configuration documents that do not have schedule information data source information collection information for example in the case of Microsoft System Management Services or other information used to synchronize data from source stores. This missing information is filled in with information from the DataSource and SyncSchedule documents.

Link document includes information about the source and target and processing to be conducted during the synchronization e.g. transformations joins conflict resolution policies and batch scheduling . The type information which connector configuration documents are involved in this synchronization dependencies and state information are tracked in a link document along with other bookkeeping data like the number of concurrent batches and the batch size i.e. amount of data in a single batch read write .

The link document can become Running or inactive once it s Active. Link documents in state Running can go back to being Active but an Inactive document cannot go into a Running state without being Active first. Similarly a linking document which is in a Running state has to go to an Active state before it can be set to Inactive.

A link document may be independent or be dependent on one or more other link documents. When the dependencies are specified in a link document then the synchronization will not start even though the synchronization time has come and passed unless the dependent link document s have completed their synchronization.

A link document may reference zero or more import connector and or zero or more export connector configuration documents such as connector configuration document . In one embodiment a link document includes either an import connector document reference the link document is then called an in Link or an export connector document reference the link document is then called an out Link or both an import and an export connector document references the link document is just called Link in this case . If a link document is an in link then there is an associated out link to write the data to a target.

A connector configuration document includes connector specific configuration information. The base type Connector contains enough sections for any connector to specify its configuration information however a particular connector may require a more structured way of declaring its configuration and can do that by deriving from the base Connector type.

Transformation document includes transformation related information. Transformation document may specify a source schema a target schema and the transformation mechanism such as XSLT for instances of the source schema to be transformed into the instances of the target schema.

Turning to a flowchart shows operations of scheduler workflow in accordance with an embodiment of the invention. In one embodiment at least a portion of flowchart may be implemented by computer readable instructions executable by one or more computing devices.

In one embodiment scheduler workflow is a timer based workflow where it is triggered periodically to watch for link document instances created by configuration workflow . In one embodiment the timer is set to watch for new link documents every one minute but this time period is configurable.

Duties of scheduler workflow may include the following query all Active link documents to check if they need to be synchronized maintain the state transitions of the link documents and maintain the dependencies of the link documents. As described below scheduler workflow places messages in queue to initiate synchronization activity by the inbound outbound workflows as defined in the configuration document.

Referring to flowchart scheduler workflow queries all Active link documents to determine if any are ready to be synchronized operation . If any Active link documents are ready to be synched then the logic starts to process a link document operation . In one embodiment a link document is ready to be synchronized if the next synchronization date of the link document is smaller than or equal to now and there are no dependencies to other link documents and the next synchronization date of the link document is smaller than or equal to now and all the dependent link documents have already been synchronized in this batch.

Scheduler workflow duties may include retrieving all the import and export connector assemblies specified in the link document in process. Connectors are configured using the connector configuration documents referenced in the link document. In one embodiment connector assembly information may be in the connector configuration documents.

If there s an import connector configuration document reference operation scheduler workflow will put an inbound workflow message into queue to trigger inbound workflow operation . If the concurrent batch count is more than one then scheduler workflow will put as many of the same inbound workflow message into queue as the concurrent batch count. Embodiments of operations of inbound workflow are discussed below in conjunction with .

The concurrent batch count indicates the number of inbound workflows associated with a data synchronization that may be executed at the same time. Each inbound workflow instance has an associated import connector instance. The concurrent batch count is defined for each data synchronization task by the configuration document. For example if the concurrent batch count is 3 then 3 messages are put into queue . Three inbound workflows and three import connectors may then import data as defined by the configuration document. The three inbound workflows may be executed in parallel using multiple processors multiple cores multiple servers etc. A concurrent batch count may be used in a similar fashion for outbound workflows.

If there s an export connector configuration document reference operation scheduler workflow puts an outbound workflow message into queue to trigger the outbound workflow operation . If the concurrent batch count is more than one then scheduler workflow puts as many of the same messages into the queue as the concurrent batch count. Embodiments of operations of an outbound workflow are discussed below in conjunction with .

If there are no import or export connector references in the link document then flowchart returns operation .

Once a message associated with the link document has been put in queue then scheduler workflow marks the link document as in a Running state operation . As described above a Running state indicates the link document is currently being processed by the linking framework.

Turning to a flowchart shows operations of inbound workflow in accordance with an embodiment of the invention. In one embodiment at least a portion of flowchart may be implemented by computer readable instructions executable by one or more computing devices.

An inbound workflow runs the specified connector referenced in the link document that caused scheduler workflow to initiate the inbound workflow . In one embodiment every time an inbound workflow is triggered the operations of flowchart are performed.

An inbound workflow message is popped from queue operation . Data referenced by the inbound workflow message is read from the defined source using an import connector and put in staging database operation . In one embodiment the import connector must have the appropriate credentials as provided in the DataSource document to access and read data from the source. In one embodiment one batch of data is read in a batch size as defined in the configuration document.

Next the logic determines if the session is complete operation . In one embodiment a session is complete when all the data associated with that link document has been read from the sources. If the session is not complete then a single message is put back into queue which is the same message that caused inbound workflow to be triggered operation . Inbound workflow is responsible for recycling its own messages until the session completes. It will be appreciated that messages associated with other configuration documents may already be queue . Queue may hold interspersed messages associated with multiple configuration documents and thus different synchronization activities .

If the session is complete then it is determined if an outbound workflow is specified in the link document operation . If outbound workflow is specified as many outbound workflow messages are put into the outbound workflow queue as specified in the concurrent batch count operation . If there is no export connector specified then the link document is marked as Active the link document had been marked as Running by the scheduler workflow and flowchart ends operation . An Active state indicates the link document is ready to be processed by the linking framework.

Turning to a flowchart shows operations of outbound workflow in accordance with an embodiment of the invention. In one embodiment at least a portion of flowchart may be implemented by computer readable instructions executable by one or more computing devices.

Outbound workflow runs the specified export connector referenced in the link document that caused scheduler workflow to initiate outbound workflow . In one embodiment every time outbound workflow gets triggered it performs the logic of flowchart .

Starting in operation an outbound workflow message is popped from queue . A batch of data batch size defined by configuration document associated with the message is retrieved from staging database operation and passed to export connector to process the data operation . Processing the data may include a transform join confliction resolution and the like. Next the batch of data is written to the target by the export connector operation . Next the logic determines if the session is complete i.e. all the data has been written to the target operation . If the session is complete then the link document is marked as Active and the workflow returns operation .

If the session is not complete a message is put back into queue which is the same message that caused outbound workflow to be triggered operation and the workflow returns. It will be appreciated that messages associated with other configuration documents may already be in queue . Each outbound workflow is responsible for recycling its own messages until the associated data in staging database is written to the target.

Turning to an example sequence of data synchronization operations using queue is shown. In queue has messages for a data synchronization task C and a data synchronization task D. Scheduler workflow adds three new messages to queue for data synchronization task A since data synchronization task A has a batch count of 3. Also in a message for data synchronization task C is being pulled from the queue and sent to inbound workflow for processing.

In a message for data synchronization task D is being popped from the queue and sent to outbound workflow for processing. From it will be appreciated that messages for both inbound and outbound workflows are placed in queue .

In a message for data synchronization task A is popped from queue and sent to inbound workflow for processing. Also inbound workflow from has placed the message for data synchronization task C back into queue . The session for data synchronization task C did not complete so the message is recycled.

In a message for data synchronization task B is put into queue by scheduler workflow . Also another message for data synchronization task A is pulled from queue for processing by inbound workflow . Thus at this point two inbound workflows are processing data for data synchronization task A. These inbound workflows may work concurrently i.e. in parallel if sufficient computing resources are available e.g. two servers .

Embodiments of the invention provide a declarative extensible linking framework for data synchronization for IT management. Embodiments of the invention allow a user to create and modify data synchronization processes through declarative expression instead of coding. A user such as a system administrator may easily make changes to processes through manipulating configuration documents implemented as configuration objects instead of coding or scripting. Administrators often wish to insert new logic during or before and after the linking activity per object per batch or per session without writing code. Also embodiments herein enable an administrator to make processes specific for a data type.

Linking activities can get very complex with many incoming and outgoing links each requiring its own configuration e.g. schedule batch size reconciliation policies transformations credential requirements etc. . Writing code or running scripts to set up and update data linking processes is not manageable. Embodiments herein provide an environment in which a user may implement various linking processes without the burden of drafting code. Also the declarative nature of linking framework provides consistency across linking processes and avoids the problems of multiple administrators each writing linking process code in their own style or creating bugs through copy paste of previous code.

Using declarative configuration documents also eases the authoring of data synchronization tasks for the user. Synchronizing data may require multiple actions that must occur in a proper order to avoid data conflict. Linking framework may automatically resolve conflicts for the user such as through conflict module .

Embodiments of linking framework are extensible. The declarative nature of linking framework enables a user to easily setup a synchronizing task for new data types and new ways of processing these data types without changing the linking framework. The user merely sets up a new configuration document. Linking framework also may be extended to new workflows using a solution pack.

Embodiments of the invention may provide system resiliency and hence data reliability. In some instances a process can run for a long period of time with the cooperation of many systems. Network outages temporary security glitches like expired credentials or system failures may occur. Sometimes the linking framework does not get access to all partner systems having sources and targets at the same time. Embodiments of the invention can work through all these issues without having to restart the processing from the beginning. Any system failure or transaction failure does not result in missing malformed or duplicate data. Data is gathered from the source and persisted to the target in such a way that an interrupted read from source write to target may be resumed from where the interruption occurred instead of restarting the process. In one embodiment a batch style of reading writing data from the source target stores provides this data resiliency and efficiency. Batching provides faster recovery on errors since interrupted reading writing does not have to be restarted parallel processing since different data groups may be read write at the same time grouping of data in keeping with available resources and minimization of the impact of data locks at sources and targets since only a portion of data i.e. a single batch is locked at a time.

Embodiments of the invention lessen impact on systems providing sources and targets. The partner systems themselves are operational systems which require most of their resources dedicated to their function monitoring deployment etc . Embodiments of the linking framework do not put undue burden on these source and target endpoints because the extraction and insertion of data may be throttled to accommodate the source and target stores at either end.

Linking framework provides reliability for recovering from an exception. Linking framework workflows may throw two types of exceptions Recoverable Exceptions and Non recoverable Exceptions. Linking Framework will retry running a particular workflow if a thrown exception is a Recoverable Exception. For a Non recoverable Exception corresponding entries are logged in an event viewer as well as Built In Diagnostic BID tracing when BID tracing is enabled.

In one embodiment the failure of a particular data synchronization will stop the execution of the synchronization until the problem is fixed e.g. network problems wrong XSLT etc. . During this down period every synchronization that depends on the failed synchronization will come to a halt as well to avoid wasting resources. Otherwise the linking framework may perform an erroneous or an unproductive synch operation since the data needed for the synch is not yet available.

In one embodiment scheduler workflow may determine how long a particular synchronization is in a bad state and place messages in an event log to notify a system administrator. In yet another embodiment an alert for the system administrator s attention is also produced.

In one embodiment if a computing device executing a workflow fails or if a workflow encounters an issue which requires manual intervention no data loss will happen since the data retrieval process is done by acknowledgement. When the workflows resume they may continue synchronizing data from where they left off. In other words an inbound workflow does not have to start a synchronization over from the beginning when the inbound workflow resumes. However if the source data is provided to the linking framework via streaming then the streamed content may be lost and the synchronization will have to restart from the beginning.

Linking framework provides various security mechanisms. For example workflows such as inbound outbound and configuration may access DataSource documents for credential information specific to a data source and connection details for a specific data source. Connectors will be run under the credentials specified in those DataSource documents. Since the connection details are specific to each connector connectors use this information to connect to a source.

Performance of linking framework may be impacted by a particular connector implementation data source system load and the batch size and concurrent batch count. Each workflow will be independently working on a separate batch of data if a concurrent batch count of more than one is specified. The batch size concurrent batch count and all performance related configuration data may be tweaked per source target system and per type in that source target system to enable the optimum performance throughout the linking framework.

There is no inherent limit on the number or size of the instances that are being retrieved or written from or to an external system. However throttling of synchronization so as to not overwhelm a source or target store may be used. A limit may be imposed by various factors including data source limits e.g. operations manager or configuration manager number of cascaded workflow hosts i.e. scale out scenario and or data target limits e.g. CMDB DW .

Other techniques may be used with embodiments of the invention to increase performance of linking framework . Watermarking of data e.g. based on last change time stamp a history table etc. may be used so that only changes in data are synched and thus decrease the impact on all resources. For example keeping track of the last record transferred allows the linking framework to resume from where the synch left off. This saves a lot of time as compared to constantly recognizing that the record that is about to be transferred from the source is already present at the target.

Caching may be used when obtaining data from a source so that the linking framework does not have to ask for the same data multiple times. For example sometimes the same data read from a source needs to be joined with multiple different pieces of data on one or more synchronization jobs again and again to create different output data. Fetching that common data every time from the source can be avoided by keeping a copy of the data at a linking framework cache such as staging database .

Parallelism may be used to affect data processing using multiple servers. Batches synchronized by different servers or different processes on the same server improves synch time and provides resiliency. For example if a server fails during data read write at a source target then the remaining servers may pick up the batches of the failed server.

Although not required embodiments of the invention are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement embodiments of the invention may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allow device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic radio frequency infrared Near Field Communication NFC and other wireless media.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

In the description and claims the term coupled and its derivatives may be used. Coupled may mean that two or more elements are in contact physically electrically magnetically optically etc. . Coupled may also mean two or more elements are not in contact with each other but still cooperate or interact with each other for example communicatively coupled .

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments of the invention. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device . Those skilled in the art will also realize that all or a portion of the computer readable instructions may be carried out by a dedicated circuit such as a Digital Signal Processor DSP programmable logic array and the like.

Various operations of embodiments of the present invention are described herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment of the invention.

The above description of embodiments of the invention including what is described in the Abstract is not intended to be exhaustive or to limit the embodiments to the precise forms disclosed. While specific embodiments and examples of the invention are described herein for illustrative purposes various equivalent modifications are possible as those skilled in the relevant art will recognize in light of the above detailed description. The terms used in the following claims should not be construed to limit the invention to the specific embodiments disclosed in the specification. Rather the following claims are to be construed in accordance with established doctrines of claim interpretation.

