---

title: Generating haptic effects for dynamic events
abstract: A system that generates a dynamic haptic effect for a dynamic event receives a first endpoint and a second endpoint for dynamic events. The first endpoint includes a first endpoint value and a corresponding first haptic effect, and the second endpoint includes a second endpoint value and a corresponding second haptic effect. The system receives a dynamic value for the dynamic event. The dynamic value is between the first endpoint value and the second endpoint value. The system then determines the dynamic haptic effect from the dynamic value by interpolating the dynamic haptic effect from the first haptic effect and the second haptic effect.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09030428&OS=09030428&RS=09030428
owner: Immersion Corporation
number: 09030428
owner_city: San Jose
owner_country: US
publication_date: 20120711
---
One embodiment is directed generally to haptic effects and in particular to generating haptic effects in response to a dynamic event.

Electronic device manufacturers strive to produce a rich interface for users. Conventional devices use visual and auditory cues to provide feedback to a user. In some interface devices kinesthetic feedback such as active and resistive force feedback and or tactile feedback such as vibration texture and heat is also provided to the user more generally known collectively as haptic feedback or haptic effects . Haptic feedback can provide cues that enhance and simplify the user interface. Specifically vibration effects or vibrotactile haptic effects may be useful in providing cues to users of electronic devices to alert the user to specific events or provide realistic feedback to create greater sensory immersion within a simulated or virtual environment.

Haptic feedback has also been increasingly incorporated in portable electronic devices referred to as handheld devices or portable devices such as cellular telephones personal digital assistants PDA s smartphones and portable gaming devices. For example some portable gaming applications are capable of vibrating in a manner similar to control devices e.g. joysticks etc. used with larger scale gaming systems that are configured to provide haptic feedback. Additionally devices such as cellular telephones and smartphones are capable of providing various alerts to users by way of vibrations. For example a cellular telephone can alert a user to an incoming telephone call by vibrating. Similarly a smartphone can alert a user to a scheduled calendar item or provide a user with a reminder for a to do list item or calendar appointment. Further haptic effects can be used to simulate real world dynamic events such as the feel of a bouncing ball in a video game.

One embodiment is a system that generates a dynamic haptic effect for a dynamic event. The system receives a first endpoint and a second endpoint for dynamic events. The first endpoint includes a first endpoint value and a corresponding first haptic effect and the second endpoint includes a second endpoint value and a corresponding second haptic effect. The system receives a dynamic value for the dynamic event. The dynamic value is between the first endpoint value and the second endpoint value. The system then determines the dynamic haptic effect from the dynamic value by interpolating the dynamic haptic effect from the first haptic effect and the second haptic effect.

One embodiment is a system that generates haptic effects for dynamic events such as a simulated bouncing ball. The system receives the desired haptic effects for the endpoints of the dynamic event such as the minimal and maximum force when the ball contacts a wall. The system then uses interpolation to automatically generate haptic effects for dynamic events that fall between the endpoints.

Devices that incorporate haptic effects generally are developed with the cooperation of both haptic effect designers who determine what the haptic effects should feel like and haptic effect programmers that develop software code to implement the designed haptic effects. In many systems an application programming interface API separates the work of the designer from the programmer so that a designer can call a desired haptic effect by name and the API retrieves the corresponding code or routine to implement the desired haptic effect. One example of an API for haptic effects is the VibeTonz API from Immersion Corp.

Haptic effects are frequently used to simulate dynamic real world events. For example a video game may feature a ball bouncing off of a wall. Depending on the speed force of the ball against the wall a haptic effect that simulates the collision of a bounce must to be varied to reflect the force that would have been generated by the collision in the real world. The haptic effect can be varied by changing parameters. As another example a smartphone may display a scrolling list of contacts. As the list scrolls a haptic effect may generate a tick haptic effect feel between contacts. As the speed of the scrolling increases the tick should get stronger to reflect the increased speed and vice versa. In one embodiment when a haptic effect is vibratory and is generated by an actuator the haptic effect can be varied to simulate dynamic haptic events by varying any combination of magnitude frequency and duration of the vibration parameters. Other examples of dynamic events that can generate corresponding haptic effects include the force of a boxing glove hitting a person the force of a bat hitting a ball the force of a car colliding with another object etc.

For many simulations the number of dynamic events for which a corresponding haptic effect is generated can be fairly large. For example for the ball bouncing against the wall a video game may specify ten or more different forces generated by the ball against the wall depending on the speed of the ball. Most designers in designing haptic effects for these forces will merely specify the parameters for the endpoints i.e. the smallest force and the largest force . The programmer then must program all parameters in between the endpoints using linear mapping or some other method. Depending on the number of intermediate points this may require a large effort on behalf of the programmer. In contrast embodiments of the present invention automatically generate intermediate stage haptic effects based on the endpoints using interpolation.

System includes a bus or other communication mechanism for communicating information and a processor coupled to bus for processing information. Processor may be any type of general or specific purpose processor. System further includes a memory for storing information and instructions to be executed by processor . Memory can be comprised of any combination of random access memory RAM read only memory ROM static storage such as a magnetic or optical disk or any other type of computer readable medium.

A computer readable medium may be any available medium that can be accessed by processor and may include both a volatile and nonvolatile medium a removable and non removable medium a communication medium and a storage medium. A communication medium may include computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and may include any other form of an information delivery medium known in the art. A storage medium may include RAM flash memory ROM erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM registers hard disk a removable disk a compact disk read only memory CD ROM or any other form of a storage medium known in the art.

In one embodiment memory stores software modules that provide functionality when executed by processor . The modules include an operating system that provides operating system functionality for system as well as the rest of a mobile device in one embodiment. The modules further include a haptic effects generation module that generates haptic effects using interpolation as disclosed in more detail below. System will typically include one or more additional application modules to include additional functionality such as smartphone related applications if system is a smartphone APIs a physics system etc. System may further be coupled to a database for storing data used by modules and .

System in embodiments that transmit and or receive data from remote sources further includes a communication device such as a network interface card to provide mobile wireless network communication such as infrared radio Wi Fi or cellular network communication. In other embodiments communication device provides a wired network connection such as an Ethernet connection or a modem.

Processor is further coupled via bus to a display such as a Liquid Crystal Display LCD for displaying a graphical representation or user interface to a user. The display may be a touch sensitive input device such as a touchscreen configured to send and receive signals from processor and may be a multi touch touch screen. Processor is further coupled to a keyboard or cursor control such as a mouse that allows a user to interact with system .

System in one embodiment further includes an actuator . Processor may transmit a haptic signal associated with a generated haptic effect to actuator which in turn outputs haptic effects such a vibrotactile haptic effects. Actuator includes an actuator drive circuit. Actuator may be for example an electric motor an electro magnetic actuator a voice coil a shape memory alloy an electro active polymer a solenoid an eccentric rotating mass motor ERM a linear resonant actuator LRA a piezoelectric actuator a high bandwidth actuator an electroactive polymer EAP actuator an electrostatic friction display or an ultrasonic vibration generator. In other embodiments a separate device from system includes an actuator that generates the haptic effects and system sends generated haptic effect signals to that device through communication device .

Programmer programs processor of so that the haptic effect signals are generated. Programmer specifies a range of force inputs e.g. minimum and maximum values Fmin and Fmax based on knowledge of the range of typical values from the physics system or simulation. The collision limits reflect the minimum and maximum force that would be generated by the ball hitting a wall.

In operation embodiments calculate the collision force of a particular dynamic event that may fall between the endpoints i.e. not the smallest force and not the largest force . The output to actuator is interpolated from the programmer s collision limits to the designer s vibration limits .

At the next dynamic event is detected. The functionality of is executed as a continuous loop so a dynamic event is always detected.

At it is determined if the dynamic event e.g. a collision of a ball into a wall happened. If No at the functionality continues at . If Yes at the physic systems provides a dynamic event value. In the example of the event is the collision and the dynamic event value is the collision force e.g. 8 on a scale of 1 10 . The dynamic event value is passed to a routine in one embodiment called playDynamicEffect. In one embodiment the dynamic event value is passed to the routine as follows 

playDynamicEffect collision force where collision is the name of the haptic event and the force is the value of the haptic event.

At the set of effect definitions closest to the dynamic event value are retrieved from the effects file. A linear interpolation in one embodiment requires at least two definitions. In the above example these effects are found by their common name collision and include collision 1 and collision 10 . More than two effects can be defined and retrieved from the effects files. For example the following three effects may be defined in an effects file 

At and a determination is made as to whether the dynamic event value falls between the two definition values. For example module determines that 8 is between the 1 and 10 encoded in the names of the definition values.

If the dynamic event value is greater than the lowest set definition value at in one embodiment no effect is played and the functionality continues to . This provides for a deadband where input forces are ignored. In another embodiment the smallest effect definition in the set may be used and the functionality then returns to .

If No at if the dynamic event value is less than the greatest set definition value at the highest effect definition in the set is used at e.g. 10 and the functionality returns to .

If Yes at at the haptic effect definition is determined by interpolation at and the functionality returns to .

In order to determine the haptic effect by interpolation at in one embodiment an interpolation variable t is determined using the following dynamic event value lowest value dynamic event highest value dynamic event lowest value dynamic event For the above example 

In a special case when the highest value dynamic event equals the lowest value dynamic event t 1 to avoid division by zero.

In one embodiment t is used in the following linear interpolation function 1 to calculate each interpolated haptic effect parameter where A is the parameter value for the lowest value dynamic event and B is the parameter value for the highest value dynamic event. For the above two effects example the parameters are determined as follows Duration 1 1050 41 ms Magnitude 1 010000 7778 Period 1 55 5 ms. Therefore after the interpolated haptic parameter values i.e. 41 ms duration 7778 magnitude 5 ms period are output to actuator of or another actuator either indirectly or directly to cause the haptic effect to be generated. The functionally then returns to to wait for another dynamic event to happen.

In another embodiment instead of two haptic effect definitions i.e. the two endpoints three haptic effect definitions are used as described above. In this embodiment the following quadratic equation is used for the interpolation 1 22 1 2 where C is the third definition.

As disclosed embodiments allow a haptic effect designer to more easily implement rich haptic effects by specifying the desired haptic effect endpoints. Embodiments then automatically generate intermediate stage haptic effects through interpolation.

Several embodiments are specifically illustrated and or described herein. However it will be appreciated that modifications and variations of the disclosed embodiments are covered by the above teachings and within the purview of the appended claims without departing from the spirit and intended scope of the invention.

