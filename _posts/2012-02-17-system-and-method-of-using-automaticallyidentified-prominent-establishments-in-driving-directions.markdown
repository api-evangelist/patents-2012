---

title: System and method of using automatically-identified prominent establishments in driving directions
abstract: A system and method provides turn-by-turn directions by identifying placemarks, such as businesses or other landmarks that appear along a traveled route. The system may determine whether signage is associated with each placemark along the route and whether the signage is visible from the route. The system may also determine how prominent the signage is from the route. The system selects the placemark by determining how easily the placemark may be identified from the route, based on the signage's visibility and prominence. The selected placemark may then be identified in connection with the turn-by-turn directions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08688377&OS=08688377&RS=08688377
owner: Google Inc.
number: 08688377
owner_city: Mountain View
owner_country: US
publication_date: 20120217
---
Various navigation systems provide users with turn by turn directions. These systems include handheld GPS devices mobile phones vehicle mounted devices or other computers with access to mapping websites. In such systems users input one or more locations and receive a route and turn by turn directions. The user may then follow the turn by turn directions to reach the one or more locations.

In navigation systems which include portable devices such as handheld or vehicle mounted devices the device may provide instructions visually and or audibly in order to assist the driver follow the route and turn by turn directions. These instructions may provide for example the name of the street or the route number onto which the driver is to turn or the distance to the next turn. However the user may not be familiar with the street names or route numbers provided by the navigation system and this information may not be readily visible to the user while driving.

An aspect of the invention provides for a method of generating turn by turn directions on a network. The method includes receiving by a server a request for turn by turn directions the request including a first location and a second location identifying a route between the first location and the second location identifying placemarks that are located along the route wherein the placemarks include signage that is associated with the placemark determining how identifiable the signage is from the route selecting a placemark based on the signage s identifiability generating a turn by turn direction that includes the selected placemark and transmitting the turn by turn directions to a client device.

In one example the signage s identifiability includes at least one of the following factors the signage s visibility from the route the signage s prominence from the route and the placemark s notoriety.

In another example the signage s visibility is determined by accessing an image corresponding to a location along the route identifying one or more text strings within the image and determining the extent to which the text string matches the name of a placemark located along the route.

In a further example the signage s prominence from the route is determined by accessing an image corresponding to a location along the route identifying a text string within the image that corresponds to the placemark and determining the viewing angle covered by the width of the text.

In still a further example the signage s prominence from the route is determined by accessing an image corresponding to a location along the route identifying a text string within the image that corresponds to the placemark accessing depth information to determine the distance of the text string from the image s location and multiplying the area of the text string with in the image by a depth factor in order to determine the physical size of the text string.

In yet another example the size of the text string relative to the size of the entire image is determined by comparing the width of the text string with the width of the entire image.

In another example the size of the text string relative to the size of the entire image is determined by comparing the area of the text string with the area of the entire image.

In a further example the placemark s notoriety is determined by whether the placemark corresponds to an entity having a plurality of locations throughout a predefined region.

In still a further example the placemark s notoriety is determined by whether the placemark is designated as being well known within a predefined region.

In still a further example the generated turn by turn direction includes a command to take an action relative to the position of the selected placemark.

In yet another example content is associated with the selected placemark and content is transmitted with the turn by turn direction to a client device. The content may be information associated with a business and may consist of an image coupon advertisement or website.

Another aspect of the invention provides for a device for generating turn by turn directions over a network. The device includes a processor and memory coupled to the processor the memory including a first part for storing the instructions and a second part for storing turn by turn directions and the processor being configured to receiving a request for turn by turn directions the request including a first location and a second location identifying a route between the first location and the second location identifying placemarks that are located along the route wherein the placemarks include signage that is associated with the placemark determining the signage s identifiability score along the route selecting a placemark based on the signage s identifiability score generating a turn by turn direction that includes the selected placemark and transmitting the turn by turn direction to a client device.

Another aspect of the invention provides for a device for displaying turn by turn directions. The device includes a processor a user input apparatus for providing data to the processor and a display for displaying data processed by the processor in accordance with instructions the processor being configured to transmit to a server on a network a request for turn by turn directions the request identifying a first location and a second location transmit to the server user information stored in the memory of the device receive from the server a route between the first location and the second location a turn by turn direction and a placemark selected from a plurality of placemarks wherein the placemark include signage that is associated with the placemark and wherein the placemark is selected based on the signage s identifiability from the route and display the turn by turn direction and the placemark on the electronic display.

In one example the device also includes a geographic location instrument and wherein the received placemark is associated with a geographic location proximate to a current location of the device and wherein the processor is further configured to determine the current location of the device based on the geographic location instrument and transmit the current location of the device to the server.

In one aspect the system and method provides turn by turn directions including placemarks that are easily identifiable by a user. Each placemark represents a geographically located object such as a business or landmark. A client device of the user may transmit an initial and a final location. Upon receipt of the locations a server may determine a route comprised of a plurality of route segments. For each route segment associated with a plurality of placemarks the server may determine whether signage is associated with each placemark and whether the signage is visible from the route. The server may also determine how prominent the signage is from the route. The server selects the placemark by determining how easily the placemark may be identified from the route based on the signage s visibility and prominence. The selected placemark is associated with the route segment and is used to generate a turn by turn direction for the route segment where information associated with the placemark is displayed on a client device.

As shown in a system in accordance with one aspect of the invention includes a computer containing a processor memory and other components typically present in general purpose computers.

The memory stores information accessible by processor including instructions and data that may be executed or otherwise used by the processor . The memory may be of any type capable of storing information accessible by the processor including a computer readable medium or other medium that stores data that may be read with the aid of an electronic device such as a hard drive memory card ROM RAM DVD or other optical disks as well as other write capable and read only memories. Systems and methods may include different combinations of the foregoing whereby different portions of the instructions and data are stored on different types of media.

The instructions may be any set of instructions to be executed directly such as machine code or indirectly such as scripts by the processor. For example the instructions may be stored as computer code on the computer readable medium. In that regard the terms instructions and programs may be used interchangeably herein. The instructions may be stored in object code format for direct processing by the processor or in any other computer language including scripts or collections of independent source code modules that are interpreted on demand or compiled in advance. Functions methods and routines of the instructions are explained in more detail below.

The data may be retrieved stored or modified by processor in accordance with the instructions . For instance although the system and method is not limited by any particular data structure the data may be stored in computer registers in a relational database as a table having a plurality of different fields and records XML documents or flat files. The data may also be formatted in any computer readable format. By further way of example only image data may be stored as bitmaps comprised of grids of pixels that are stored in accordance with formats that are compressed or uncompressed lossless e.g. BMP or lossy e.g. JPEG and bitmap or vector based e.g. SVG as well as computer instructions for drawing graphics. The data may comprise any information sufficient to identify the relevant information such as numbers descriptive text proprietary codes references to data stored in other areas of the same memory or different memories including other network locations or information that is used by a function to calculate the relevant data.

The processor may be any conventional processor such as processors from Intel Corporation or Advanced Micro Devices. Alternatively the processor may be a dedicated device such as an ASIC. Although functionally illustrates the processor and memory as being within the same block it will be understood by those of ordinary skill in the art that the processor and memory may actually comprise multiple processors and memories that may or may not be stored within the same physical housing. For example memory may be a hard drive or other storage media located in a server farm of a data center. Accordingly references to a processor computer or memory will be understood to include references to a collection of processors computers or memories that may or may not operate in parallel.

The computer may be at one node of a network and capable of directly and indirectly communicating with other nodes of the network. For example computer may comprise a web server that is capable of communicating with client devices and via network such that server uses network to transmit and display information to a user such as person or of on display of client device . Server may also comprise a plurality of computers that exchange information with different nodes of a network for the purpose of receiving processing and transmitting data to the client devices. In this instance the client devices will typically still be at different nodes of the network than any of the computers comprising server .

Network and intervening nodes between server and client devices may comprise various configurations and use various protocols including the Internet World Wide Web intranets virtual private networks local Ethernet networks private networks using communication protocols proprietary to one or more companies cellular and wireless networks e.g. WiFi instant messaging HTTP and SMTP and various combinations of the foregoing. Although only a few computers are depicted in it should be appreciated that a typical system can include a large number of connected computers.

Each client device may be configured similarly to the server with a processor memory and instructions . Each client device or may be a device intended for use by a person and have all of the components normally used in connection with a computer such as a central processing unit CPU memory e.g. RAM and internal hard drives storing data and instructions such as a web browser an electronic display e.g. a monitor having a screen a small LCD touch screen a projector a television a computer printer or any other electrical device that is operable to display information and user input e.g. a mouse keyboard touch screen and or microphone . The client device may also include a camera GPS receiver speakers a network interface device as well as all of the components used for connecting these elements to one another.

Although the client devices and may each comprise a full sized personal computer they may alternatively comprise mobile devices capable of wirelessly exchanging data with a server over a network such as the Internet. By way of example only client device may be a wireless enabled PDA a cellular phone tablet PC or notebook capable of obtaining information via the Internet. The user may input information using a small keyboard a keypad or a touch screen. Indeed client devices in accordance with the systems and methods described herein may comprise any device capable of processing instructions and transmitting data to and from humans and other computers including general purpose devices network computers lacking local storage capability and set top boxes for televisions.

The client devices may also include a geographic location instrument to determine the geographic location and orientation of the device. For example client device may include a GPS receiver to determine the device s latitude longitude and or altitude position. The geographic position component may also comprise software for determining the position of the device based on other signals received at the client device such as signals received at a cell phone s antenna from one or more cellular towers if the client device is a cell phone. It may also include an accelerometer gyroscope or other acceleration device to determine the direction in which the device is oriented. By way of example only the acceleration device may determine its pitch yaw or roll or changes thereto relative to the direction of gravity or a plane perpendicular thereto. In that regard it will be understood that a client device s provision of location and orientation data as set forth herein may be provided automatically to the user to the server or both. The client device may also be equipped with various privacy settings allowing the user to opt out of sending information about the device . For example before providing the device s location to a remote server the client device allows the user to select an option whereby such geographic location information is not to be sent.

Although certain advantages are obtained when information is transmitted or received as noted above aspects of the invention are not limited to any particular manner of transmission of information. For example in some aspects information may be sent via a medium such as an optical disk or portable drive. In other aspects the information may be transmitted in a non electronic format and manually entered into the system. Yet further although some functions are indicated as taking place on a server and others on a client various aspects of the system and method may be implemented by a single computer having a single processor.

The server may include direction data for generating turn by turn directions based on a plurality of route segments. Turn by turn directions may include text audio video images and maps. Each turn by turn direction and associated route segment may be further associated with one or more map tiles such that each turn by turn directions displayed with the one or more map tiles. It will be understood that turn by turn directions are not limited to instructions to make simple turns for example other directions may include continuing on a road taking a particular exit etc.

Server may store map related information at least a portion of which may be transmitted to a client device. For example and as shown in the server may store map tiles where each tile comprises a map image of a particular geographic area. A single tile may cover an entire region such as a state in relatively little detail and another tile may cover just a few streets in high detail. In that regard a single geographic point may be associated with multiple tiles and a tile may be selected for transmission based on the desired level of zoom. The map information is not limited to any particular format. For example the images may comprise street maps satellite images or a combination of these and may be stored as vectors particularly with respect to street maps bitmaps particularly with respect to satellite images or flat files.

The various map tiles are each associated with geographical locations such that the server and or client device are capable of selecting retrieving transmitting or displaying one or more tiles in response to receiving one or more geographical locations.

Data may also include route segments . Each route segment may be associated with one or more geographical locations. A given route between locations may comprise a plurality of route segments. By way of example only route segments may be based on stretches of road between intersections changes in road names or turn instructions for the particular determined route. For example if the route between location A and location C requires a turn at location B the route consists of two route segments namely the segment A B and the segment B C. Each segment may be associated with one or more turn by turn directions.

The system and method may process locations expressed in different ways such as latitude longitude positions street addresses street intersections an x y coordinate with respect to the edges of a map such as a pixel position when a user clicks on a map names of buildings and landmarks and other information in other reference systems that is capable of identifying a geographic locations e.g. lot and block numbers on survey maps . Moreover a location may define a range of the foregoing. Locations may be further translated from one reference system to another. For example the client may access a geocoder to convert a location identified in accordance with one reference system e.g. a street address such as 1600 Amphitheatre Parkway Mountain View Calif. into a location identified in accordance with another reference system e.g. a latitude longitude coordinate such as 37.423021 122.083939 . In that regard it will be understood that exchanging or processing locations expressed in one reference system such as street addresses may also be received or processed in other references systems as well.

The map database may also store data representing street level images . Street level images comprise images of objects at geographic locations captured by cameras in a direction generally parallel to the ground. Thus as shown in street level images and may represent various geographic objects such as buildings and sidewalks and and streets and respectively from a perspective of a few feet above the ground and looking down the street. It will be understood that while street level images and only show a few objects for ease of explanation a typical street level image will contain as many geographic objects street lights mountains trees bodies of water vehicles people etc. in as much detail as the camera was able to capture.

The street level image may be captured by a camera mounted on top of a vehicle at or below the legal limit for vehicle heights e.g. 7 14 feet from a camera angle pointing roughly parallel to the ground. Street level images may also be provided to the server via Internet listings or the client devices and . For example the images may be captured using an on device camera or a digital camera connected to the client device. Street level images are not limited to any particular height above the ground for example a street level image may be taken from the top of building. Panoramic street level images may be created by stitching together a plurality of photographs taken from different camera angles.

Each street level image may be represented as a set of pixels associated with color and brightness values. For example if the images are stored in JPEG format the image will be displayed as a set of pixels in rows and columns with each pixel being associated with a value that defines the color and brightness of the image at the pixel s location.

Street level image data further associates each street level image with a location or geo tag typically the latitude longitude position of the camera when the image was captured. In that regard the street level image data may associate the street level images and with latitude longitude positions and respectively. If the image data is provided to the server via a client device the location information may be provided by the client device using an on device GPS receiver .

In addition to being associated with geographic locations street level images are typically associated with information indicating the orientation of the image. For example if the street level image comprises a typical photograph orientation data and may store the camera angle as data representing an angle that is 90 east of true north and rises 2 from ground level shown as simply Looking East in the figures . If the street level images are panoramic images such as 360 panoramas centered at the geographic location associated with the image the orientation may indicate the portion of the image corresponding with looking due north from the camera position at an angle directly parallel to the ground.

Street level images may also be stored in the form of videos such as by displaying MPEG videos captured by an analog video camera or displaying in succession time sequenced photographs that were captured by a digital still camera.

The server may also access placemark information identifying local businesses clubs or other objects or features associated with particular geographic locations. For example a placemark may be associated with a name such as a company name or a description of the placemark such as fountain . Each placemark may also be associated with one or more route segments as well as content such as coupons advertisements user reviews photos or menus.

In addition each placemark may be associated with signage data that visually identifies the placemark from one or more locations along the route segments. Signage may include any text design or logo that appears at the placemarks location. For example as shown in the signs for Joe s Pizza and Fashion by Elizabeth are each forms of signage that may be associated with the placemarks for the businesses at that location.

Placemarks may refer to other geographically located objects in addition to or instead of businesses. For example they may also include points of interest POI individuals homes landmarks roads bodies of land or water items located in a store items that can be moved to different locations etc. Therefore while many of the examples below refer to businesses most aspects of the system and method are not limited to any particular type of placemark.

The server may include modules or instructions that allow for signage detection within the geo tagged image data . Specifically the server may detect potential text regions in an image such as regions and in . The server then performs a process for recognizing the text strings using optical character recognition OCR technology. The server may also search for known placemarks near the location of the geo tagged image and extract phrases from information related to the signage for the nearby placemarks e.g. name category phone number and other information that are expected to be found on places such as store fronts and signs . The server then compares the text strings recognized in the image with the phrases extracted from the data for nearby placemarks. If any placemark data matches a text string in the image the placemark may be associated with that particular geo tagged image. In addition all images that show at least part of the placemark s signage may be tagged as being associated with a particular placemark.

It should be appreciated that the server may be provided with an individual geo tagged image of placemarks also called the individual image scenario . Alternatively the server may have access to a large collection of images showing placemarks in a general area also called the image corpus scenario such as pictures taken by a camera car while touring around an area.

The image processing module processes received geo tagged images to detect text strings presented in the images. These text strings are often for signage that is related to a particular placemark. Accordingly the text strings recognized in an image are used by the image placemark detection module to identify placemarks in that image. Thus if more text strings are recognized in the image then there will be more matching results for the placemark identification to be based. In addition because of factors such as lighting angle shading and font text strings in images often are hard to locate and or recognize. Accordingly in one embodiment in order to achieve more informed placemark identification and accommodate factors affecting text recognition the image processing module adopts an over inclusive approach to recognize more text strings in the image even at the cost of a potential higher error rate. As shown the image processing module includes a text region detection module and an OCR module .

The text region detection module analyzes an image to detect the presence of a text string and identify a portion of the image e.g. a rectangular shaped bounding box that includes the text string. The identified portion of the image is called a text region. In one embodiment in order to be overly inclusive and detect more text strings in an image the text region detection module applies a variety of distinctive text character detection algorithms known in the related fields to identify text regions in the image. For example the text region detection module may consider visual features such as Histogram of oriented gradients edge contrast features transition run length densities geometrical properties and connected component based features in detecting text regions in the image.

The OCR module converts or translates text strings inside the detected text regions into editable text hereinafter called OCR ed text strings . The OCR module processes the text regions using computer algorithms and generates corresponding OCR ed text strings. In addition the OCR module calculates a confidence score that measures a quality of the OCR ed text strings. In one embodiment to be overly inclusive the OCR module applies a variety of OCR engines or algorithms and generates multiple alternative OCR ed text strings along with their corresponding confidence scores for a same text region. Examples of the OCR engines include Abbyy FineReader Nuance OmniPage and Open Source Tesseract. The resulting OCR ed text strings are collectively called a pool of texts. The pool of texts may include OCR ed text strings recognized in an individual image e.g. for the individual image scenario or multiple images e.g. for the image corpus scenario .

The placemark processing module generates a collection of phrases also called a pool of phrases for each known placemark near the geographical location indicated by the geo tag associated with an image also called the image location . By limiting the source of the pool of phrases to placemarks that are near the image location the placemark processing module effectively excludes irrelevant placemarks and thereby enhances computational efficiency and result quality. As shown the placemark processing module includes a nearby placemark identification module and a phrase generation module .

The nearby placemark identification module extracts the latitude and longitude coordinates of the image location from the geo tag and identifies placemarks located near the image location. For example the nearby placemark identification module searches for placemarks located within a radius around the image location in a placemark database and identifies the nearby placemarks in the search results. The radius may be defined by the accuracy of the image geo tag or predetermined e.g. 1 000 feet . In one embodiment the placemark database is a relational database and includes some or all of the following information for known placemarks in a geographic region 1 geographic locations e.g. latitude and longitude coordinates 2 names 3 categories e.g. RESTAURANT PIZZA BANK and INSURANCE and 4 phone numbers. The placemark database may include a mechanism for rapidly retrieving placemarks based on geographical information e.g. within a radius of a geographical location defined by latitude and longitude coordinates . The nearby placemark identification module retrieves information related to the nearby placemarks e.g. name category phone number from the placemark database.

The phrase generation module extracts or generates a set of n grams from the retrieved placemark information associated with the nearby placemarks. An n gram also called a phrase is a subsequence of n items e.g. characters words from a given sequence. The n grams extracted by the phrase generation module can be at the character level e.g. n consecutive characters in the text or at the word level e.g. n consecutive words in the text and can overlap in the original text. The phrase generation module adds all n grams generated for all nearby placemarks identified by the nearby placemark identification module into the pool of phrases. In one example the phrase generation module extracts word level n grams for the value of n ranging from 1 to 5. That is the pool of phrases includes any stretch of full words within the retrieved placemark information up to five words long.

The image placemark detection module compares the OCR ed text strings in the pool of texts with the n grams in the pool of phrases for matches and identifies placemarks in the images based on the matching results. As described earlier in one embodiment the image processing module adopts an over inclusive approach to recognizing text strings in an image. To accommodate the potential high OCR error rate the image placemark detection module performs the comparison in a manner that allows errors in the OCR ed text strings. As shown the image placemark detection module may include an approximate matching module and a scoring and placemark selection module .

The approximate matching module compares all n grams in the pool of phrases with all OCR ed text strings in the pool of texts to find any appearance of an n gram as a substring of any of the OCR ed text strings. In one embodiment in order to further enhance efficiency instead of comparing all n grams in the pool of phrases with all OCR ed text strings in the pool of texts the approximate matching module utilizes hashing and or filtering methods to limit the number of comparisons. In one embodiment to account for errors in the OCR ed text strings the approximate matching module allows some edit distances e.g. Levenshtein distance between the text strings and the n grams being compared and still considers them matching. For example a 75 or higher matching rate e.g. no more than 1 mismatching character in every four characters may be considered a match. A match between an OCR ed text string and an n gram is considered a piece of evidence towards the placemark associated with the n gram appearing or referenced in the image associated with the matching OCR ed text string.

The scoring and placemark selection module calculates scores for placemarks by combining evidence indicating that the placemark is found in an image. In one embodiment each match detected by the approximate matching module is assigned a weight based on factors such as the text field or type from which the matching n gram is extracted e.g. placemark name category phone number the length of the matching n gram i.e. the value of n the OCR confidence score associated with the matching OCR ed text string recognized in the image the edit distance of the match and the prevalence of the words terms in the matching n gram within the language e.g. RESTAURANT is weaker evidence than PARADISE or the local area e.g. NEW YORK is weaker evidence in the New York City area than Chrysler Building . For example a match for an n gram extracted from the placemark name may be giving a higher weight than a match for an n gram extracted from the category of the placemark. The score is generated based on factors such as the number of matches the weight of each match and the distance between the image location and the location of the placemark. The algorithm to calculate the weight for each match and or the score for each placemark can be generated using heuristics and or machine learning techniques. Some example heuristics include adjusting the confidence scores for the OCR ed text to be values between 0 and 1 with 1 indicating a high confidence in the accuracy of the OCR ed text and 0 indicating a low confidence and assigning higher weights for matches occurring in the placemark names than matches in the placemark categories.

For the individual image scenario the scoring and placemark selection module generates one score for each placemark near a target image and selects an placemark for the image based on the scores e.g. the placemark associated with the highest score as the placemark in the image. For the image corpus scenario the scoring and placemark selection module creates image placemark pairs by pairing each image in the image corpus with each placemark near the image location of that image and generates one score for each image placemark pair. The scoring and placemark selection module may select an image for each placemark based on the scores e.g. the image of the image placemark pair with the highest score for that placemark as the representative image for that placemark.

The data store stores data used by the image placemark detection module . Examples of such data include the placemark database the pool of texts the pool of phrases and the image itself.

Initially the server receives a geo tagged image Block . The server detects potential text regions in the image by applying a variety of distinct text detection algorithms Block and recognizes text strings in the detected regions using OCR technology Block . Separately the server detects nearby placemarks by searching in the placemark database for known placemarks located within a radius around the image location specified in the associated geo tag Block . The image server extracts phrases from the nearby placemarks by generating overlapping n grams from the information associated with the nearby placemarks Block . When repeated queries e.g. visual search queries are expected from the same or a nearby location the search results and or extracted phrases may be cached between the queries to further enhance efficiency.

The server compares the text strings recognized in the image with the n grams generated for the nearby placemarks for approximate matches Block and generates a score for each nearby placemark based on the matching n grams associated with that placemark and factors such as the distance between the image location and the location of the placemark Block . The server then associates a placemark as the known placemark appearing or referenced in the geo tagged image having the highest score Block . In addition the server associates the matching text region as being signage for that particular placemark. Alternatively the server may only associate a placemark with the geo tagged image if the score generated in Block is above a predefined threshold.

In one embodiment the server may process a large collection of images in a batch process e.g. for the image corpus scenario . For example the server will recognize OCR ed texts in the images generate the n grams for all placemarks in the general area of the collection of images and then analyze the images in a sequence based on their image locations such that the applicable pool of phrases are relatively stable between the adjacent images since the image locations are relatively close .

In another embodiment the server may identify placemarks in video streams or video frames. In yet another embodiment in order to identify known placemarks in an image in addition to matching OCR ed text recognized in the image the server also matches graphical components in the image e.g. logos to a database of known graphical marks associated with placemarks using image matching techniques matches the image against a database of real estate listings matches house numbers identified in the image to addresses of the placemarks and or takes into consideration manual placemark identification.

An image may contain more than one placemark having visible signage. For example as shown in the text strings found in text regions and each relate to the distinct placemarks of Joe s Pizza and Fashion by Elizabeth . Accordingly the separate placemarks of Joe s Pizza and Fashion by Elizabeth may each be associated with the image in provided that the score for each text region and is above any predefined threshold.

Once the geo tagged images have been associated with the placemarks visible within the image the data may be stored on the server as image data and may be used in connection with providing turn by turn navigation to the client devices and . For example illustrates a map that provides a route between a starting point on River Road and a destination on Main Street. The route is broken into two segments. Route segment includes a portion of River Road while route segment includes a portion of Main Street. Along the route there are several buildings and that could act as placemarks for providing a user with navigation. For example a user traveling from point to destination will be directed to take a right turn on to Main Street at either building or building . In addition if building is the building shown in the turn by turn could instruct the user to turn right at a specific placemark such as Joe s Pizza or alternatively at Fashion by Elizabeth . This would help assure that the user of a client device stays on the desired route and does not miss the required right turn. Preferably the placemark provided as part of the turn by turn directions will be easily identifiable and visible to a user as the user approaches Main Street from River Road. As set forth below the system is operable to select placemarks that are more easily identifiable along a desired route.

Turning to server may select a route segment as shown in block . Then at block the server may determine whether there are geo tagged images associated with any locations along the selected route segment. If there are such images at block the server will determine whether any of the images have placemark signage that is associated with it.

If images with placemark signage exist along the route segment the server will determine the identifiability scores for each placemark block as described below.

If there are additional route segments as shown in block the server will return to block and select the next route segment of the route. As provided in block if there are no additional route segments sever selects from the available placemarks based on their location and identifiability scores. Then as shown in block the server generates turn by turn directions that include the selected placemark s associated with the route. Returning to the turn by turn directions are transmitted to the client device as shown in block and are displayed by the client device as shown in block .

While the process in is shown in a certain order the steps may be performed in a different order and steps may be added or omitted. For example the determination of the identifiability scores for placemarks may be performed prior to the server receiving a request for turn by turn directions from the client device. In other words the server may use stored images to calculate the placemark identifiability scores for various locations and may select the best placemarks to use for these locations prior to determining the route that will be traveled by a particular user. Accordingly in some embodiments blocks and may be performed prior to blocks and .

Aspects of the invention will now be described in greater detail. As noted above a client device may transmit a request for turn by turn directions between two or more locations. As shown in a user may identify an initial location and a final location or in another example the user may identify a final location and the client device may determine the initial location for example GPS coordinates. As noted above locations may be provided in any number of forms including street addresses points of interest or GPS coordinates of the user device.

Using the process described in for the initial location and final location of the server will identify the route as including route segment and route segment . In addition the server will identify buildings and as being placemarks associated with the route. The association of placemarks with a particular route may be performed by the server accessing the placemarks geolocation data or by identifying placemarks that have street addresses corresponding to a portion of the route.

Once the server has identified the placemarks associated with the route the server may access the identifiability score for each of the placemarks along the route segment. It is the identifiability score that is used at least in part to determine which placemarks are displayed to a user in connection with the turn by turn directions. The identifiability score may include one or more factors relating to either the nature of the placemark or the image of the placemark along the route.

The identifiability score may be pre calculated by the server by determining whether any of the placemarks or have signage that is visible from the route segment prior to the server receiving a specific request for turn by turn directions from the client device . In order to make this determination the server accesses the information obtained from the geo tagged street level image data . As previously described the geo tagged image data contains information regarding the image s geographic location as well as the orientation or direction the camera was facing when the image was taken. Using this information the server may identify the subset of images that were taken along the selected route segment. In addition the server may limit the subset of images to those that have an orientation that is within a predefined angle in relation to the direction of travel along a route. For example if a route would require a user to travel due West the server may limit the images it considers as being associated with the route to those images that have an orientation within 90 degrees of due west. In this way the server will avoid relying on images that have an easterly orientation and which may not be visible to a user traveling along the route.

One of the factors for a placemark s identifiability along a route is the visibility score of the placemark s signage. Often times the signage for a placemark when viewed from the route might be unclear or may be wholly or partially blocked by objects such as trees or buildings. The visibility score accounts for this by providing greater weight to placemark signage that can be easily read from the route. In determining the visibility score of the placemark signage the server uses the OCR ed image data . As described above server creates text regions for the OCR ed image and may match the text within those text regions to data relating to the placemark. The visibility score for a placemark may be measured on a scale of 0 to 1 or some other range and based on the fraction of characters within the OCR ed text region that match the characters in the placemark s name. For example if a placemark has a name that is 10 characters long and the OCR ed text for the image of the placemark signage matches 9 of ten characters then the visibility score for the placemark in that image will be 0.9 i.e. 9 divided by 10 .

Another factor that may be used to determine a placemark s identifiability is the prominence score for the placemark s signage. The prominence of a placemark s signage is defined by the spatial angle covered by the signage within the image which may be determined using one of several alternative metrics. For example illustrates an image having bounding boxes and around the signage for Joe s Pizza and Fashion by Elizabeth respectively. The bounding boxes and represent the text regions identified by the server as part of the OCR process described above. The prominence score for each placemark may be calculated as the fraction of the image width that is covered by the bounding box. For example the bounding box for Fashion by Elizabeth has a width that is half of the width of the entire image while the bounding box for Joe s Pizza has a width that is the width of the entire image . Accordingly for image the prominence score of the Fashion by Elizabeth placemark is 0.5 while the prominence score for the Joe s Pizza placemark is 0.20. Alternatively the prominence score may be calculated based on the spatial angles that create the area of the bounding box for the placemark signage relative to the spatial angles that create the area of the entire image. As yet another alternative if information regarding the depth is collected as part of the street level image data the prominence score may be calculated by determining either the physical width or physical area of the signage. This would be performed by multiplying the spatial angle or angles of the signage s bounding box by a factor representing the distance of the placemark signage from the camera s location.

Yet another factor that may be used in determining the identifiability score of a placemark relates to the notoriety of the placemark in question. If the placemark in question is a business notoriety may include information regarding the size of the business such as the number of locations or offices the business has whether the business is located across the entire country. In addition notoriety may be based at least in part on the number of results that contain the placemark s name when a categorical search query is performed such as restaurants New York City . Notoriety could also include a metric for how well known the business is among the general public. For example in if Fashion by Elizabeth is a nationally known brand of clothing with retailers across the country and Joe s Pizza is a local restaurant with only a few locations then the server may increase the identifiability score of Fashion by Elizabeth relative to Joe s Pizza. For example in one possible embodiment nationally known placemarks may have their identifiability score multiplied by a factor of 2 while locally known placemarks will not have any multiplication factor applied. The server may store the information regarding the notoriety of a placemark as part of the placemark data . In addition the server may store as part of the placemark data a designation relating to whether the placemark is well known internationally nationally regionally or locally. The notoriety score as is also the case for the visibility and prominence scores may be normalized to a value between a particular range such as between the range of 0 and 1.

The identifiability score for a placemark along a route segment may include one or more of the factors discussed above in any number of ways. In one embodiment the identifiability score may comprise an array of several different values such as a visibility score a prominence score and a notoriety score. For example the identifiability score IDENT may be calculated using a linear combination of the visibility score VIS prominence score PROM and notoriety score NOTO . In addition each score contained in the linear combination may be weighted by a different value so as to provide the following equation IDENT w  VIS w  PROM w  NOTO . The weight values w  w  and w  may each be a fraction and their summation may equal 1. For example the weight values used may be w  4 13 w  8 13 and w  1 13.

In another embodiment the server may add a placemark s visibility score with the placemark s prominence score and then increase this combined score by the value based on the placemark s notoriety score. For example assuming that the placemark signage for Fashion by Elizabeth as illustrated in has a visibility score of 1 i.e. all characters in the text region matched the placemark name and a prominence score of 0.5 the width of the signage is half the width of the image as a whole then these scores could be added together so as to create a combined score of 1.5. If Fashion by Elizabeth is a nationally known brand the server could then multiply this combined score by a predetermined factor of 2 so as to create an identifiability score of 3. It should also be appreciated that the various factors making up the identifiability score may be weighted differently regardless of the combination used to create the score.

As provided in the server selects placemarks based on their location and identifiability scores block and then generates turn by turn directions that include the selected placemarks block . In selecting placemarks the server may first determine locations along the route that will require the user to act in some way such as by making a turn or changing lanes. These locations will often be associated with the user traveling from one route segment to another. For example as illustrated in as a user travels from point to point the user will have to make a right turn when proceeding from route segment to route segment . To help assure that the user makes the required right turn the server may select the most identifiable placemark that would be visible to a user who approaches route segment from route segment .

It should be appreciated that the server may select from potential placemarks irrespective of whether each of the placemarks has an associated image. Specifically some placemarks do not have associated signage that would allow for a visibility or prominence score but are well known places. For example the Eiffel Tower due to its notoriety may be used in provided turn by turn directions despite a lack of signage designating the Eiffel Tower.

In many instances the server will have access to numerous geo tagged images that represent different locations along a particular route segment. In addition the identifiability score of a particular placemark will change depending on the image s location and orientation. Accordingly it would be preferable for the identifiability score of a placemark to be based on an image that has a geographic location close to locations where the user would need to identify the placemark in order to make the desired action e.g. turning right on to route segment from route segment . To achieve this the server may determine the identifiability score for placemarks based on images and placemarks that have a geographic location that is within a predetermined distance from a particular location e.g. an intersection along the route. In one example this predetermined distance may be anywhere on the order of a foot to a mile or more. In addition the server may limit the identifiability scores to images having an orientation similar to the direction of travel such as by requiring that the image be within 90 degrees of the direction of travel. Alternatively the placemark s distance from the route could be included as a separate factor in the identifiability score.

For example in providing a placemark associated with the right turn from route segment to route segment of the server may be operable to select placemarks based on their identifiability scores in images that are located along route segment and that are predetermined distance such as 0.1 miles from the intersection of route segment and route segment . is an example of such an image. The server may then select between Fashion by Elizabeth and Joe s Pizza based on which of the two placemarks has the higher identifiability score.

In an alternative embodiment the server may access numerous images taken at several different locations along a route in order to determine the placemark having the highest identifiability score. In addition the server may access several different images and then average the identifiability score of a placemark. For example the server access the identifiability score for the placemarks contained in all of the images along a route that are within a quarter of a mile of an intersection and then use the placemarks average identifiability score to determine which placemark is to be selected for use in the turn by turn directions.

As described above in the server generates turn by turn directions that include selected placemarks block . Those turn by turn directions are then transmitted to and displayed or otherwise presented by a client device blocks and . illustrate examples of what may be displayed by a client device in accordance with the server generating a turn by turn direction based on the inclusion of the placemark for Fashion by Elizabeth. In alternative embodiments the turn by turn directions displayed on the client device may include an image of the placemark such as the image in Figure . In addition the placemark may include links to various URLs. For example as shown in the text Fashion by Elizabeth includes a hyperlink to a network location such as the website for Fashion by Elizabeth.

In one embodiment the server may incorporate additional content into the turn by turn direction for the route segment. For example as shown in the server may generate a turn by turn direction which includes a link to a coupon. In another example the turn by turn direction may display the actual coupon. In addition the turn by turn directions may be provided by the client device audibly. The client device may also present options that allow the user to select the manner in which the turn by turn directions are presented as well as the content included with the directions. For example the user may have the option of turning off audible directions or the option of having audible directions that include the name of selected placemarks. Although the example described above included placemarks located proximate to an intersection it will be understood that directions may also include placemarks located anywhere along a route. In particular turn by turn directions may include an intermediate direction that incorporates a placemark. For example for route segment in if building contains signage for the placemark Smith s Diner and has the highest identifiability score in a predefined area the associated turn by turn direction may include text or audio such as continue north along Main Street you will pass Smith s Diner on the right. 

In another embodiment the server may conduct an action based on the location of the client device. For example a client device may periodically send location information such as GPS coordinates to server as the client device moves along the route. As the user approaches a turn or the next route segment server may notify the user of a placemark based on the placemark s identifiability score as determined from nearby geo tagged images that have been stored on the server.

In another embodiment the server may provide a client device with all of the turn by turn directions at once. In this way if the client device is not a mobile device e.g. a desktop PC the user may send the directions to another device or print the directions prior to proceeding on the route.

In yet another embodiment the placemark signage used to determine the identifiability score may contain graphical components e.g. logos that are associated with a placemark. In this instance the same identifiability score factors may be used however instead of basing the visibility score on number of OCR ed characters that match the stored placemark name the sever may determine what percentage of the signage logo matches the stored placemark logo.

As these and other variations and combinations of the features discussed above can be utilized without departing from the invention as defined by the claims the foregoing description of exemplary embodiments should be taken by way of illustration rather than by way of limitation of the invention as defined by the claims. It will also be understood that the provision of examples of the invention as well as clauses phrased as such as e.g. including and the like should not be interpreted as limiting the invention to the specific examples rather the examples are intended to illustrate only some of many possible aspects.

