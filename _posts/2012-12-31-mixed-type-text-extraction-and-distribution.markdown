---

title: Mixed type text extraction and distribution
abstract: Systems, methods, and devices for extracting and distributing text of mixed types from displayed graphical data from a display of an electronic device are disclosed. The text types can include rendered text and text represented in rendered images. Displayed graphical data can be captured from data being displayed by an application on a display device. Text data can be extracted from the captured graphical data as text data at the rendering tree level, or by an optical character recognition process. In response to the extracted text data, a text selection tool with visual representations of selectable text can be applied to the displayed text data. Using the text selection tool, a user can select a subset of the text. In response to the user selection, one or more other applications can be determined and the selected text can be passed to at least one of the other applications for execution.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09170714&OS=09170714&RS=09170714
owner: Google Technology Holdings LLC
number: 09170714
owner_city: Mountain View
owner_country: US
publication_date: 20121231
---
Electronic devices typically run an operating system for controlling the base level functionality of the electronic device. To add additional or specialized functionality to the electronic device the operating system can execute one or more registered or unregistered applications. Registered applications typically comply with some predetermined application programming interface API to ensure efficient and easy interoperability with the operating system. Data such as text data can be sent back and forth between the registered applications and the operating system however the electronic device has no mechanism for sharing text data between the operating system and other unregistered applications. Unregistered applications often include integrated graphics engines and output data to the display without using the electronic device s graphics engine. In some instances of unregistered applications text is rendered as an image and underlying text data for rendering text is lost for sharing with the operating system and other applications.

To enable sharing of text data between various applications some conventional systems have implemented basic variations of copy and paste functionality. In such solutions a user selects text or images displayed on the graphical user interface of the electronic device initiates a copy or cut command opens another application selects a field and initiates a paste command. Whatever text or image that was copied will be inserted in the field selected by the user. However only information displayed by an active instance of the operating system or standalone application as rendered text can be selected and copied into active memory as text data. Any text that is rendered as an image with no underlying renderable text data is unavailable for copying and pasting between applications. In such scenarios a user may need to enter the text manually into another application.

Accordingly traditional cut and paste operations have various drawbacks and deficiencies with respect to sharing mixed type text data i.e. rendered text and rendered images with embedded text among multiple applications and the operating system. One specific issue with cut and paste operations involves the limited nature with which the text can be pasted into multiple applications simultaneously. To enter the copied text into multiple applications at the same time a user would need to launch each application and perform the pasting function into each of the desired text fields individually. Such manual processes are laborious and time consuming. Additionally traditional cut and paste operations are limited to the selection of rendered text and cannot select text presented on a graphical user interface that is rendered as an image i.e. a picture depicting words.

In the following description for purposes of explanation numerous examples and specific details are set forth in order to provide a thorough understanding of particular embodiments. Particular embodiments as defined by the claims may include some or all of the features in these examples alone or in combination with other features described below and may further include modifications and equivalents of the features and concepts described herein.

Described herein are techniques for capture and integration of text data associated with the dynamic state of applications on various types of electronic devices. One example method includes capturing graphical data from application data being output by a first application that is actively displaying a portion of the application data on a display device associated with the electronic device. Such methods further include extracting text data from the graphical data using a text extraction process and in response thereto displaying a text selection tool on the display device. The method can also include receiving a user input designating a subset of the text data through the text selection tool and executing another application. The subset of the text data can be available for use by the other application in response to receiving the user input designating the subset of the text data.

Related embodiments provide for the determination of text information from graphics output to a display device as well as determination of text intercepted from a rendering level from applications that use a general purpose graphics engine in the electronic device. Such text information can then be shared among the operating system and various other applications and services.

Various other embodiments of the present disclosure include methods that include extracting the text data by segmenting the application data into multiple zones associating each of the zones with a zone type designators and determining the text data from the plurality of zones based on the zone type designators. In such embodiments zone type designators can include a text field designator and an image field designator. Determining text data from the zones can include executing a text interception routine as the text extraction process on a zone associated with the text field designator at a rendering level of the electronic device.

Other embodiments of the present disclosure include a non transitory computer readable storage medium containing instructions that when executed control an electronic device to be configured to capture graphical data from application data being output by a first application that is actively displaying at least a portion of the application data on a display associated with the electronic device and to extract text data from the graphical data using a text extraction process. Such embodiments can also include instructions to display a text selection tool in response to extracting the text data and receive a user input designating at least a subset of the text data through the text selection tool. Such instructions can also include instructions to execute one or more second applications where the subset of the text data can be available for use by the applications in response to receiving the user input designating the subset of the text data.

Yet other embodiments include an apparatus having one or more computer processors a display device coupled to the one or more computer processors and a non transitory computer readable storage medium comprising instructions that when executed control the one or more computer processors to be configured to capture graphical data from application data being output by an application that is actively displaying a portion of the application data on the display device and extract text data from the graphical data using a text extraction process. When the text data is extracted the instructions also include instructions to display a text selection tool in response to extracting the text data receive a user input designating a subset of the text data through the text selection tool and execute other applications wherein the subset of the text data is available for use by other applications in response to the user input designating the subset of the text data.

As shown in electronic device can include a display device Display coupled to an operating system OS executed on a computer processor. In various embodiments operating system can include a text extractor Text Ext. . In the specific embodiment shown in the display device and multiple standalone or integrated applications and can be coupled to the text extractor . Such standalone or integrated applications and can be provided by the manufacturer of the electronic device or can be installed or downloaded according to user preferences to customize the functionality of the electronic device .

As many as N where N is a natural number applications can be running simultaneously limited only by the amount of processing power and memory of electronic device . At any given time one of the N applications can be running in the foreground. In some embodiments when an application is running in the foreground it is referred to as the active application and can cause a particular graphical user interface associated with the active application to be displayed on display device along with any standard or persistent graphical user interface components i.e. date time or battery level provided by the operating system .

As shown text extractor can be an integrated subroutine or sub process of the operating system . In such embodiments the text extractor can access data before and or after it is sent between internal components of the operating system and any of the applications and . Accordingly the text extractor can intercept text and graphical data before and after being sent to a graphics engine not shown of the operating system . For example text extractor extracts text from graphical data being displayed in an active application. The text extractor then allows the text to be available for use in another one of the applications. Similarly the text extractor can send and receive text data from each of the N applications as well as send and receive graphical data from each of the N applications. Although the text extractor is described as being part of operating system the text extractor may operate separately from operating system such as in an application running on the operating system .

Network interface can implement various wired and wireless communication protocols and capabilities. For example network interface can include Wi Fi Ethernet Worldwide Interoperability for Microwave Access WiMAX 3G 4G 4G Long Term Evolution LTE Edge and other wired and wireless functionality for communicating with a remote server computer through cloud network over connections and .

In such network enabled embodiments the operating system and or text extractor can communicate various types of data with remote server computer . For example operating system can communicate with server computer via a network interface to download and or remotely execute any of M where M is a natural number applications or resident on server computer .

Some variations of data flows for capturing text indicating selectable text selecting text and sharing the selected text amongst various components of the electronic device will now be discussed. First an example that includes extracting text from the operating system level rendering tree will be discussed then variations of similar systems will be discussed that require internal and standalone optical character recognition OCR processes routines or applications will be discussed.

The operating system can originate commands for sending graphical data to a user interface . Such commands can include sending graphical data to the graphics processor . Text extractor can intercept the graphical data at point . The graphical data generated by operating system can include data for rendering text and or images such as pictures photographs animation etc.

The text extractor can determine the portions of the graphical data that include text data for rendering of text. As used herein text data refers to any proprietary or open source encoding of letters words characters or symbols used by a computer computer processor or graphics engine for generating rendered and or selectable text on a computer output device such as computer display. For example text data can include ASCII hexadecimal binary and other systems or schemes for encoding text. Rendered text refers to any visual representation displayed on a computer display or other output device that represents the actual letters words characters or symbols without reference to the variations of the visual representation such as size font or other formatting variations.

From the graphical data text extractor can determine the text data and send it to text selector . In such embodiments the text data can include text rendering information such as size and location such that the text selector can accurately locate and determine where the text will be rendered in the display or user interface. In response to the text data text selector can send text selection tool data to the user interface to augment user interface generated by the operating system by a graphics processor . In some embodiments the text selection tool data can include instructions for changing the appearance of the rendered text displayed in user interface to provide a visual indication of which text is selectable. Changing the appearance of the rendered text displayed in the user interface can be performed by either the graphics processor or directly by text selector .

Changing the appearance of the rendered text displayed in the user interface can include changing the size shape format highlights color or other characteristic of text displayed or rendered in the user interface . For example text that would normally be rendered as black on a white background can be rendered as black on a transparent yellow background to indicate that that text is selectable. The text selection tool data can also include instructions for changing the appearance of selected text or providing some other visual indication of selected text in response to user input. In reference to the example in which selectable text is rendered as black text on a transparent yellow background when some portion of such text is selected by a user the appearance of the text can change such that it is displayed as red text on a transparent yellow background. While this specific example of visual indications of selectable and selected text can be effective one of ordinary skill in the art will recognize that various other types of visual indications of selectable and selected text can be used without deviating from the spirit or scope of the present disclosure.

Text selector can receive user input indicating user selected text through the user interface and or the text selection tool. The text selector can then send the text or text data representing the text to the application selector . Application selector can in response to receiving the text the text data representing the text and or a context meaning or definition associated with the text select one or more applications into which the text can be pasted or otherwise entered into. Application selector can send the selection of applications and the text or the text data to the operating system with instructions for invoking or initiating the selection of applications and entering of the selected text. Operating system can then invoke or initiate the selection of applications and insert the selected text into the appropriate text fields or inputs.

As shown optical character recognizer can be integrated with operating system . In such embodiments the optical character recognizer can directly or indirectly receive the separately rendered graphics from application . Optical character recognizer can then perform various types of OCR routines or processes on the graphics from application to recognize text data from the rendered graphics. In some embodiments performing the OCR routine can be in response to user input received through a control included in a window rendered on user interface . In such embodiments the control can include a button or other operable element rendered in a window on user interface . In other embodiments the control can included a keystroke or series combination of keystrokes on a user input device such as keyboard coupled to the electronic device.

In some embodiments the OCR routine can include a screen capture or screen shot operations. In other embodiments a separate application may perform such screen capture or screen shot operations and the separate application can send the resulting graphic or image to the optical character recognizer .

In all such embodiments the OCR operations can include recognizing images or graphics that are and or are not actively being displayed in user interface . For example an image rendered by application can be larger than the available display space on a user interface . The OCR operation may recognize portions of the image that off of or not displayed on the display space. In related embodiments operating system and or application can include zoom functions that results in only portions of the rendered image being displayed on user interface at a given time. In such scenarios a user can use various types of controls to scroll or scan around the image such that different portions of the image are viewable on user interface at a time. In such scenarios initiation of a screen capture operation can be configured to capture only the portion of the image viewable on user interface or configured to capture the entirety of the image based on the graphical data used to render the image.

In some embodiments it is advantageous that the screen capture operation be configured to only capture the portion of the image viewable on user interface so that only that portion of the image is sent to the optical character recognizer . As a result the text data from optical character recognizer can include both size and location of the text in the image or graphics from application or a screen capture operation as it is or will be displayed on user interface . The text selector can the accurately position visual indications of selectable and or selected text in the user interface based on the portion or zoom level of the image displayed on user interface .

Using the text data from the optical character recognizer text selector can provide various types of selection tools. In some embodiments the text selection tools can include visual indications of selectable text in the user interface . Through the text selection tools the text selector can receive an input that selects text from a user. The selected text can then be sent to application selector which selects one or more applications in which the selected text is available to these applications. Application selector may select the applications according to various contexts definitions and meanings associated with the selected text or various types of applications that might be useful to the user based on processes and routines beyond the scope of the present disclosure. In some embodiments application selector sends the application selection and text to the operating system along with value pairs that can include an application identifier and the text. Operating system can then invoke or initiate the applications associated with the various application identifiers and enter or insert the text where appropriate.

In response to the determination of the location of rendered text labeled controls and images the screen capture routine or the optical character recognizer can determine a number of zones. Each zone can be associated with the determined type of information within that zone i.e. images graphics rendered text controls and the rendered text labels. In the zones with images or graphics the optical character recognizer can perform an initial word detection process or routine to determine where the image or graphic might include embedded text. Such information can be provided to the text selector to use as a placeholder for the visual representation indicating selectable text. In parallel the optical character recognizer can continue to process and or recognize the text embedded in images or graphics. In such embodiments in the time it typically takes for a user to select some portion of the available text displayed in user interface the optical character recognizer can complete or continue to process the images or graphics. Such parallel processing of initial text detection and actual OCR processes improves the user experiences by limiting the delay between the time that a screen capture or text extraction mode is initiated and the time that the text selector can provide text selector tools or other visual indications of selectable text.

One example of a user interface that can include a combination of rendered text labeled buttons and images with embedded text is a web browser. Web browsers displayed in user interface can include an address field with rendered text labeled control buttons rendered text content and rendered image content. Upon the initiation of a screen capture process the optical character recognizer can perform the initial zone determination. During the initial zone determination optical character recognizer can detect zones within the captured the screen capture which include various types of images graphics rendered text controls and associated text labels. As discussed above for zones which include rendered text the operating system the optical character recognizer can intercept the text data from the graphical data before it is sent to the graphics processor . For example the address bar may contain a URL of rendered text that can be intercepted before an augmented or truncated version of the rendered text is displayed in text field of the address bar. Typically the text in the address bar is unformatted but includes much more text than can be readily displayed within the limited confines of the navigation bar in the graphical user interface. For such text the optical character recognizer can extract the entirety of the text in a URL before it is presented as an augmented or truncated form. In this way when the indication of selectable text is generated in the zone on or around the address field and designated as or associated with rendered text selection of the selectable text in the address field can select the entirety of the underlying text of the URL and not just the portion of the URL that is currently displayed.

Similarly for zones with buttons labeled with text the operating system or the optical character recognizer can intercept the text data for the label from the graphical data before it is sent to the graphics processor . For example a web browser can include various rendered operable control buttons that can be associated with a text label that may or may not be displayed in the user interface . Some operable buttons in graphical user interfaces can include a pop up text label when the cursor or other selector hovers above or near the button. For example a navigation button that can be used to go back one web page can be rendered as an arrow pointing to the left. However when a user hovers a cursor or a finger above the back button in the user interface the text label may be temporarily displayed to identify the name and or function of the button. In the specific example of the web browser if a user were to hover a cursor or finger above the back button the word back might be temporarily displayed. In such scenarios the optical character recognizer can intercept the text label associated with rendered operable button. In some embodiments the optical character recognizer can intercept the text label regardless of whether it is permanently temporarily or never displayed in the user interface . The optical character recognizer can then send such information to the text selector in order to apply a visual indication of selectable text in the zone on or around the operable button.

The rendered text in the content area of a web browser can also be intercepted by operating system or optical character recognizer which can detect determine and intercept the text data before the graphical data which can include the text data is sent to the graphics processor and or the user interface . The location size and other specifics of the rendered text within the displayed user interface can then be sent to the text selector so it can provide selector tools and or other visual indications of selectable text within user interface .

Finally rendered images or graphics in the content area of a web browser or other application user interface can also include embedded text. However in such scenarios since the text has been rendered into an image or graphic it is not associated with or connected to encoded text data or other data that can be used to render the text. In such scenarios the optical character recognizer can apply various types of optical character recognition processes or routines to detect and recognize the text embedded within the images. As discussed above the optical character recognizer can perform an initial word detection routine to provide location placeholders that text selector can use to generate visual indications of selectable text content area of the web browser displayed in user interface . With the placeholder visual indications of selectable text in the content area the optical character recognizer can continue to process or complete processing the image or graphical data into potential text data before user input indicating selected text is received.

Text selector can then receive the selected text and provide the selected text to the application selector . The application selector based on various factors and associated context and definitions can provide an application selection of one or more applications and the selected text to the operating system . Operating system can then generate a compilation of one or more locally or remotely available applications and the selected text with instructions for graphics processor to generate a visual representation in the user interface of the selected applications and the selected text.

In some embodiments the data extractor can include functionality for capturing the an initial screenshot or screen capture of any and all information or data displayed on a user interface or display of the electronic device at or at a time after the data extraction mode it initiated.

For example the user interface can include a computer display device such as a computer monitor or touch screen. The computer display device can display information from various operating system functions an application running in the foreground as well as information from one or more other applications or operating system functions running concurrently in the background. All such information can include rendered text rendered controls control labels associated with the rendered controls and images or graphics that may or may not include embedded text. Accordingly the screen capture can include displayed information from a number of processes and routines running in the foreground and the background.

In action the electronic device can extract the graphical data. In some embodiments extracting the graphical data can include performing a preliminary segmentation of the data and information displayed in the user interface into a plurality of zones. Since action in action the operating system or text extractor can determine the type of data that is included in each of the zones. If a zone includes image or graphical data then optical character recognition processor routine can be performed in action . If the zone includes rendered text then the text data associated with the rendered text can be intercepted directly from the operating system or the application generating the rendered text in action . Based on the determined type of data within each zone any available text can be determined using the optical character recognition process of action or the text interception process of action . Once all the text data is determined in actions or the resulting text data can be compiled in action . Compiling the resulting text data can include collecting the size and location on the user interface or display device associated with rendered text of the determined text data.

In response to the compilation of the resulting text data a visual indication or text selection tool can be generated and displayed in the user interface to indicate which zones are available as selectable text in action . In some embodiments the visual indication or text selection tool can include altering the appearance of the rendered text according to the size and location of the rendered text in the user interface. In action the electronic device can receive a selection of text through the user interface and the text selection tool. The selected text can then be output to an application selector in action .

In the embodiments shown in user interface or display device is depicted as displaying a graphical user interface that includes a base level or system level display area a web browser application. Reference to the web browser application is merely exemplary and is not intended to limit the scope of particular embodiments. Other types applications and their associated user interfaces can also be used.

The base level or system level display area can include information from the operating system including operating system level information such as time network signal strength and battery level etc. The web browser graphical user interface when displaying a website defined by computer executable code stored at the address defined in URL address field can include an augmented or truncated version of URL in address field rendered text content and an image with embedded text a placeholder window with a link to one or more other static or dynamic data sources rendered controls with text labels and . In some embodiments the user interface can include a text extraction mode control .

When the text extraction mode control is operated electronic device can initiate a text extraction mode according to various embodiments of the present disclosure. In one embodiment activation of the text extraction control causes the electronic device to execute one or more text extraction applications or subroutines. Such applications and subroutines can be executed at the operating system level or by standalone applications external to the operating system. In some embodiments a first text extraction application or routine can include identifying various zones of text within the displayed graphical user interface. In other embodiments the operating system in the electronic device can identify the various zones of the text within the displayed graphical user interface. In either such embodiments the graphical user interface may or may not show visual indications of the identified zones.

Each of the identified zones can be associated with a text type. For example the zones associated with the rendered text in address field rendered text in labeled button and the rendered text or can be identified as zones of text that can be intercepted from the graphical data or text data in the rendering tree before such data is sent to the graphics engine. In contrast zones associated with graphics or images and can be identified as having text that will need to be extracted using an optical character recognition program or subroutine.

For example as shown in selected text is shown as being selected in an double walled box. In some embodiments the electronic device can wait a predetermined amount of time after selected text is selected after which the selected text can be sent to the application selector for application selection based on meanings definitions or contexts associated with the selected text . In other embodiments electronic device only sends the selected text to the application selector after the user operates one or more physical or rendered controls to indicate completion of the text selection process. A user may operate text extraction mode control to indicate to electronic device that he or she has completed selecting text into initiate sending the selected text to the application selector.

Electronic device can also include features and components for mobile computing and mobile communication. For example shows a block diagram that illustrates internal components of a mobile device implementation of the electronic device according to present disclosure. Such embodiments can include wireless transceivers a processor e.g. a microprocessor microcomputer application specific integrated circuit etc. a memory portion one or more output devices and one or more input devices . In at least some embodiments a user interface is present that includes one or more output devices and one or more input devices . Such embodiments can include a graphical user interface that is displayed on a touch sensitive device e.g. a capacitive resistive or inductive touch screen device .

The internal components can further include a component interface to provide a direct connection to auxiliary components or accessories for additional or enhanced functionality. For example component interface can include a headphone jack or a peripheral data port. The internal components can also include a portable power supply such as a battery for providing power to the other internal components. All of the internal components can be coupled to one another and in communication with one another by way of one or more internal communication links e.g. an internal bus .

Each of the wireless transceivers utilizes a wireless technology for communication such as but not limited to cellular based communication technologies such as analog communications using advanced mobile phone system AMPS digital communications using code division multiple access CDMA time division multiple access TDMA global system for mobile communication GSM integrated digital enhanced network iDEN general packet radio service GPRS enhanced data rates for GSM evolution EDGE etc. and fourth generation communications using universal mobile telecommunications system UMTS code wide division multiple access WCDMA long term evolution LTE IEEE 802.16 etc. or variants thereof or peer to peer or ad hoc communication technologies such as HomeRF Bluetooth and IEEE 802.11 a b g or n or other wireless communication technologies such as infrared technology. In the present embodiment the wireless transceivers include both cellular transceivers and a wireless local area network WLAN transceiver although in other embodiments only one of these types of wireless transceivers and possibly neither of these types of wireless transceivers and or other types of wireless transceivers is present. Also the number of wireless transceivers can vary from zero to any positive number and in some embodiments only one wireless transceiver is present and further depending upon the embodiment each wireless transceiver can include both a receiver and a transmitter or only one or the other of those devices.

According to various embodiments the wireless transceivers can operate in conjunction with others of the internal components of the electronic device and can operate in various modes. For example one mode includes operation in which upon reception of wireless signals the internal components detect communication signals and the transceiver demodulates the communication signals to recover incoming information such as voice and or data transmitted by the wireless signals. After receiving the incoming information from the transceiver the processor formats the incoming information for the one or more output devices . Likewise for transmission of wireless signals the processor formats outgoing information which may or may not be activated by the input devices and conveys the outgoing information to one or more of the wireless transceivers for modulation to communication signals. The wireless transceiver s convey the modulated signals to a remote device such as a cell tower or a remote server not shown .

In related embodiments the input and output devices of the internal components can include a variety of visual audio and or mechanical outputs. For example the output device s can include a visual output device such as a liquid crystal display and light emitting diode LED indicator an audio output device such as a speaker alarm and or buzzer and or a mechanical output device such as a vibrating mechanism. The visual output devices among other things can include the display device of .

The input devices can include a visual input device such as an optical sensor for example a camera an audio input device such as a microphone and a mechanical input device such as a Hall effect sensor accelerometer keyboard keypad selection button touch pad touch screen capacitive sensor motion sensor and or switch. Actions that can actuate one or more input devices can include but need not be limited to opening the electronic device unlocking the device moving the device and operating the device.

Particular embodiments may be implemented in a non transitory computer readable storage medium for use by or in connection with the instruction execution system apparatus system or machine. The computer readable storage medium contains instructions for controlling a computer system to perform a method described by particular embodiments. The computer system may include one or more electronic devices. The instructions when executed by one or more computer processors may be operable to perform that which is described in particular embodiments.

As used in the description herein and throughout the claims that follow a an and the includes plural references unless the context clearly dictates otherwise. Also as used in the description herein and throughout the claims that follow the meaning of in includes in and on unless the context clearly dictates otherwise.

The above description illustrates various embodiments along with examples of how aspects of particular embodiments may be implemented. The above examples and embodiments should not be deemed to be the only embodiments and are presented to illustrate the flexibility and advantages of particular embodiments as defined by the following claims. Based on the above disclosure and the following claims other arrangements embodiments implementations and equivalents may be employed without departing from the scope hereof as defined by the claims.

