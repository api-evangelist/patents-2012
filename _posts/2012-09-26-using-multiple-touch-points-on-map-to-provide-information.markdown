---

title: Using multiple touch points on map to provide information
abstract: A device includes a touch sensitive surface for receiving touch input or gestures associated with two or more markers representing two or more locations defining a route on a map display. Based on the touch input or gesture, information associated with the route is provided to the user including, for example, the travel distance between the two or more locations and an estimated travel time. In some implementations, a gesture associated with two or more markers representing locations on a map display opens a user interface for providing travel directions for a route associated with the two or more locations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09494442&OS=09494442&RS=09494442
owner: Apple Inc.
number: 09494442
owner_city: Cupertino
owner_country: US
publication_date: 20120926
---
Modern devices e.g. smart phones electronic tablets often include a mapping application that allows a user of the device to track their location and the location of other users on a geographic map display. The mapping applications may include a search engine to allow users to enter a search query to search for a particular point of interest such as a business. The map display is usually generated from a map database that includes information for defining geographic boundaries for administrative areas e.g. counties cities towns based on geographic survey information. The mapping applications also allow users to generate a route and get turn by turn directions by entering departure and destination locations.

Modern devices include a touch sensitive surface for receiving input from a user. For example a smart phone or electronic tablet can include a touch sensitive display that is configured to receive touch input and gestures from a user to invoke various functions or applications on the device.

A device includes a touch sensitive surface for receiving touch input or gestures associated with two or more markers representing two or more locations defining a route on a map display. Based on the touch input or gesture information associated with the route is provided to the user including for example the travel distance between the two or more locations and an estimated travel time. In some implementations a gesture associated with two or more markers representing locations on a map display opens a user interface for providing travel directions for a route associated with the two or more locations. A first gesture provides directions from a first location represented by the first marker to a second location represented by the second marker. A second gesture provides directions from the second location represented by the second marker to the first location represented by the first marker.

Particular implementations disclosed herein provide one or more of the following advantages. A user can easily discover travel information by using simple touch input and gestures on a map display without opening another application dialogue or page.

The details of the disclosed implementations are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

The user interface can include map display and control bar . Control bar can include a toggle button that allows a user to open a search user interface or a directions user interface. In the example shown a search user interface is opened on touch sensitive display . The user has performed a search and two locations are represented by location markers e.g. pushpins on map display . Route is drawn on map display between markers . The user can touch markers to expose information about the location. Markers can be different colors to distinguish a current or departure location and a destination location. Route can be different colors to represent traffic conditions. Button can be used to determine the current location of device and to place a marker on map display representing the current location. In some implementations voice commands can be used to initiate a search which can result in markers being automatically dropped onto map display and route being drawn.

In conventional mapping applications travel information is often displayed at fixed location. Displaying travel information at a fixed location has several drawbacks. The text often is small font and therefore difficult to see on a small screen. In addition a portion of the user interface is dedicated to displaying the travel information even though a user may only occasionally want to see the travel information. This dedicated portion of the user interface can no longer be used to display other information which is undesirable on devices with small screens that need to maximize usable screen area. Another drawback is that the travel information can be displayed only for a single point to point route on the map display and not for point to multipoint or multipoint to multipoint routes as to do so would consume even more screen space and is therefore undesirable.

Markers define three routes and . Route was described in reference to . Route is between markers and and route is between markers and . In response to this touch input callouts are presented on map display . The user can receive information from all three callouts .

In some implementations the order of the touches can determine the travel information displayed. For example one marker can represent a current location of device and one or more markers can indicate the current locations of other devices such as devices carried by friends or family. In this scenario information can be provided for multiple routes where the current or departure and destination locations are determined by the order of the touches on the markers. The first marker touched becomes the current or departure location and the second marker touched becomes the destination location. For example the current location of device can be represented by marker and the location of a friend s device can be represented by marker . The user of device can expose information for the friend by touching marker then touching marker while still touching marker .

In some implementations a button or other user interface element can be presented to allow sharing of routes and travel information with other users. For example by touching button a sharing dialogue can be presented on display that allows the user of device to initiate sharing route or travel information displayed on map display with other users. In some implementations the sharing can be automatic to devices represented by markers on map display . In other implementations a dialogue can be presented allowing the user of device to select one or more users to share information.

In some implementations the order of touch input which marker is touched first and which marker is touched last in a sequence of touches can indicate the marker that represents a current or departure location and the marker that represents a destination location. Directions can be provided according to the order. For example the user touches marker first indicating that marker represents a current or departure location and then touches marker while still touching marker indicating that marker represents a destination location. For this order of touches travel directions are provided from a current or departure location represented by marker to a destination location represented by marker .

In some implementations process can begin by receiving simultaneous touch inputs at markers for two or more locations defining one or more routes on a map display . The map display can be provided by a client map application running on a device and or search engine and or mapping service as described in reference to . The markers can be displayed in response to a search query voice command or any other suitable source input.

Process can continue by providing information related to the one or more routes between two or more locations . The information can be provided for point to point routes point to multipoint routes and multipoint to multipoint routes. The type of information provided can be based on the order in which touches are made on markers as described in reference to . Information e.g. route and other travel information can be shared with other users through for example operating environment . Information can be any information related to a route between two markers such as travel distance and estimated travel time. The information can be presented to the user using any suitable user interface element. Information can also be provided as audio through headphones or a loudspeaker.

In some implementations process can begin by receiving a touch gesture starting from a first marker and moving towards a second marker on a map display . For example the touch gesture can be as described in reference to . In other implementations the order of the touches can indicate the marker that represents a current or departure location and the marker that represents a destination location and then produce travel directions according to the order. In some implementations other gestures can be used to invoke automatically travel directions.

Process can continue by providing travel directions from the first location to the second location based on the gesture . Travel directions can be for example turn by turn driving directions. In some implementations travel directions can be provided for a variety of transportation modes including pedestrian bike train mass transit etc.

In some implementations devices and can communicate over one or more wired or wireless networks . For example wireless network e.g. a cellular network can communicate with a wide area network WAN e.g. the Internet by use of gateway . Likewise access device e.g. IEEE 802.11g wireless access device can provide communication access to WAN . Devices can include but is not limited to portable computers smart phones and electronic tablets. In some implementations the devices do not have to be portable but can be a desktop computer television system kiosk system or the like.

In some implementations both voice and data communications can be established over wireless network and access device . For example device can place and receive phone calls e.g. using voice over Internet Protocol VoIP protocols send and receive e mail messages e.g. using SMPTP or Post Office Protocol 3 POP3 and retrieve electronic documents and or streams such as web pages photographs and videos over wireless network gateway and WAN e.g. using Transmission Control Protocol Internet Protocol TCP IP or User Datagram Protocol UDP . Likewise in some implementations device can place and receive phone calls send and receive e mail messages and retrieve electronic documents over access device and WAN . In some implementations device or can be physically connected to access device using one or more cables and access device can be a personal computer. In this configuration device or can be referred to as a tethered device.

Devices and can also establish communications by other means. For example wireless device can communicate with other wireless devices e.g. other devices or cell phones over the wireless network . Likewise devices and can establish peer to peer communications e.g. a personal area network by use of one or more communication subsystems such as the Bluetooth communication devices. Other communication protocols and topologies can also be implemented.

Devices or can communicate with service over the one or more wired and or wireless networks . For example service can be a search engine and or mapping application that performs one or more of the processes described in reference to .

Device or can also access other data and content over one or more wired and or wireless networks . For example content publishers such as news sites Really Simple Syndication RSS feeds Web sites and developer networks can be accessed by device or . Such access can be provided by invocation of a web browsing function or application e.g. a browser running on the device or

Devices and can exchange files over one or more wireless or wired networks either directly or through service .

Architecture can be implemented in any device for generating the features described in reference to including but not limited to portable or desktop computers smart phones and electronic tablets television systems game consoles kiosks and the like. Architecture can include memory interface data processor s image processor s or central processing unit s and peripherals interface . Memory interface processor s or peripherals interface can be separate components or can be integrated in one or more integrated circuits. The various components can be coupled by one or more communication buses or signal lines.

Sensors devices and subsystems can be coupled to peripherals interface to facilitate multiple functionalities. For example motion sensor light sensor and proximity sensor can be coupled to peripherals interface to facilitate orientation lighting and proximity functions of the device. For example in some implementations light sensor can be utilized to facilitate adjusting the brightness of touch surface . In some implementations motion sensor e.g. an accelerometer gyros can be utilized to detect movement and orientation of the device. Accordingly display objects or media can be presented according to a detected orientation e.g. portrait or landscape .

Other sensors can also be connected to peripherals interface such as a temperature sensor a biometric sensor or other sensing device to facilitate related functionalities.

Location processor e.g. GPS receiver can be connected to peripherals interface to provide geo positioning. Electronic magnetometer e.g. an integrated circuit chip can also be connected to peripherals interface to provide data that can be used to determine the direction of magnetic North. Thus electronic magnetometer can be used as an electronic compass.

Camera subsystem and an optical sensor e.g. a charged coupled device CCD or a complementary metal oxide semiconductor CMOS optical sensor can be utilized to facilitate camera functions such as recording photographs and video clips.

Communication functions can be facilitated through one or more communication subsystems . Communication subsystem s can include one or more wireless communication subsystems. Wireless communication subsystems can include radio frequency receivers and transmitters and or optical e.g. infrared receivers and transmitters. Wired communication system can include a port device e.g. a Universal Serial Bus USB port or some other wired port connection that can be used to establish a wired connection to other computing devices such as other communication devices network access devices a personal computer a printer a display screen or other processing devices capable of receiving or transmitting data. The specific design and implementation of the communication subsystem can depend on the communication network s or medium s over which the device is intended to operate. For example a device may include wireless communication subsystems designed to operate over a global system for mobile communications GSM network a GPRS network an enhanced data GSM environment EDGE network 802.x communication networks e.g. Wi Fi Wi Max code division multiple access CDMA networks and a Bluetooth network. Communication subsystems may include hosting protocols such that the device may be configured as a base station for other wireless devices. As another example the communication subsystems can allow the device to synchronize with a host device using one or more protocols such as for example the TCP IP protocol HTTP protocol UDP protocol and any other known protocol.

Audio subsystem can be coupled to a speaker and one or more microphones to facilitate voice enabled functions such as voice recognition voice replication digital recording and telephony functions.

I O subsystem can include touch controller and or other input controller s . Touch controller can be coupled to a touch surface . Touch surface and touch controller can for example detect contact and movement or break thereof using any of a number of touch sensitivity technologies including but not limited to capacitive resistive infrared and surface acoustic wave technologies as well as other proximity sensor arrays or other elements for determining one or more points of contact with touch surface . In one implementation touch surface can display virtual or soft buttons and a virtual keyboard which can be used as an input output device by the user.

Other input controller s can be coupled to other input control devices such as one or more buttons rocker switches thumb wheel infrared port USB port and or a pointer device such as a stylus. The one or more buttons not shown can include an up down button for volume control of speaker and or microphone .

In some implementations device can present recorded audio and or video files such as MP3 AAC and MPEG files. In some implementations device can include the functionality of an MP3 player and may include a pin connector for tethering to other devices. Other input output and control devices can be used.

Memory interface can be coupled to memory . Memory can include high speed random access memory or non volatile memory such as one or more magnetic disk storage devices one or more optical storage devices or flash memory e.g. NAND NOR . Memory can store operating system such as Darwin RTXC LINUX UNIX OS X WINDOWS or an embedded operating system such as VxWorks. Operating system may include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations operating system can include a kernel e.g. UNIX kernel .

Memory may also store communication instructions to facilitate communicating with one or more additional devices one or more computers or servers. Communication instructions can also be used to select an operational mode or communication medium for use by the device based on a geographic location obtained by the GPS Navigation instructions of the device. Memory may include graphical user interface instructions to facilitate graphic user interface processing including a touch model for interpreting the touch inputs and gestures described in reference to sensor processing instructions to facilitate sensor related processing and functions phone instructions to facilitate phone related processes and functions electronic messaging instructions to facilitate electronic messaging related processes and functions web browsing instructions to facilitate web browsing related processes and functions media processing instructions to facilitate media processing related processes and functions GPS Navigation instructions to facilitate GPS and navigation related processes camera instructions to facilitate camera related processes and functions and other instructions for facilitating other processes features and applications such as applications related to generating map displays and processing touch and gesture inputs as described in reference to .

Each of the above identified instructions and applications can correspond to a set of instructions for performing one or more functions described above. These instructions need not be implemented as separate software programs procedures or modules. Memory can include additional instructions or fewer instructions. Furthermore various functions of the device may be implemented in hardware and or in software including in one or more signal processing and or application specific integrated circuits.

The features described can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The features can be implemented in a computer program product tangibly embodied in an information carrier e.g. in a machine readable storage device for execution by a programmable processor and method steps can be performed by a programmable processor executing a program of instructions to perform functions of the described implementations by operating on input data and generating output.

The described features can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that can be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program can be written in any form of programming language e.g. Objective C Java including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors or cores of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer can communicate with mass storage devices for storing data files. These mass storage devices can include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with an author the features can be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the author and a keyboard and a pointing device such as a mouse or a trackball by which the author can provide input to the computer.

The features can be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system can be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include a LAN a WAN and the computers and networks forming the Internet.

The computer system can include clients and servers. A client and server are generally remote from each other and typically interact through a network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

One or more features or steps of the disclosed embodiments can be implemented using an Application Programming Interface API . An API can define on or more parameters that are passed between a calling application and other software code e.g. an operating system library routine function that provides a service that provides data or that performs an operation or a computation.

The API can be implemented as one or more calls in program code that send or receive one or more parameters through a parameter list or other structure based on a call convention defined in an API specification document. A parameter can be a constant a key a data structure an object an object class a variable a data type a pointer an array a list or another call. API calls and parameters can be implemented in any programming language. The programming language can define the vocabulary and calling convention that a programmer will employ to access functions supporting the API.

In some implementations an API call can report to an application the capabilities of a device running the application such as input capability output capability processing capability power capability communications capability etc.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made. The systems and techniques presented herein are also applicable to other electronic text such as electronic newspaper electronic magazine electronic documents etc. Elements of one or more implementations may be combined deleted modified or supplemented to form further implementations. As yet another example the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other implementations are within the scope of the following claims.

