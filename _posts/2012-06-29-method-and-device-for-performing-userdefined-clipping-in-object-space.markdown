---

title: Method and device for performing user-defined clipping in object space
abstract: A method and device for performing and processing user-defined clipping in object space to reduce the number of computations needed for the clipping operation. The method and device also combine the modelview transformation of the vertex coordinates with projection transform. The user-defined clipping in object space provides a higher performance and less power consumption by avoiding generation of eye coordinates if there is no lighting. The device includes a driver for the user-defined clipping in the object space to perform dual mode user-defined clipping in object space when a lighting function is disabled and in eye space when the lighting function is enabled.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09024969&OS=09024969&RS=09024969
owner: QUALCOMM Incorporated
number: 09024969
owner_city: San Diego
owner_country: US
publication_date: 20120629
---
This application is a continuation of U.S. application Ser. No. 11 531 205 filed Sep. 12 2006 the entire content of which is incorporated herein by reference.

In general three dimensional 3D graphics applications display 3D objects in a two dimensional 2D space e.g. a display screen . The pixels in a 2 dimensional graphic have the properties of position color and brightness. On the other hand a 3D pixel adds a depth property that indicates where the point lies on an imaginary Z axis. Texture is created as 3D pixels are combined each with its own depth value.

Converting information about 3D objects into a bit map that can be displayed is known as rendering and requires considerable memory and processing power. In the past 3D graphics was available only on powerful workstations but now 3D graphics accelerators are commonly found in personal computers PC . The graphics accelerator contains memory and a specialized microprocessor to handle many of the 3D rendering operations. Open GL Open Graphics Library for desktops defines an application programming interface API for writing applications that produce 3D and 2D computer graphics. The API includes hundreds of functions for drawing complex three dimensional scenes from primitives.

User defined clip planes permit for efficient early culling of non visible polygons increasing performance and saving power. The user defined clipping is usually done in hardware in the PC graphics systems. It is relatively a new feature in handheld devices. OpenGL ES is a subset of the desktop OpenGL which creates an interface between software and graphics. Furthermore user defined clipping is either done in software or in hardware in mobile phones. If user defined clipping is done in software user defined clipping is usually done in eye coordinates. Vertices vertex coordinates are first transformed from object space into eye space. The transformed vertices are tested against the user defined clipping planes in eye space. Vertices are assembled into primitives. If a primitive partially lies in the half space of a clipping plane the primitive will be clipped by the clipping plane. However numerous computations are needed to transform the numerous vertices from the object space to the eye space.

For example in 3D graphics applications such as OpenGL ES or OpenGL a user can specify multiple clipping planes. A clipping plane is an arbitrary plane in 3D space. Each plane defines a half space. Any object or any portion of the object will be clipped if it does not lie in the half space. Any object in the scene will be tested against all the clipping planes. This process is called user defined clipping. Another type of clipping is called frustum clipping that clips objects against the eye frustum. Frustum clipping will not be described herein.

A current challenge is to implement the user defined clipping using a 3D software engine found in a hand held 3D imaging device without poor performance. The hand held 3D imaging devices have limited battery power and processing capability. A significant number of computations are needed to transform a lot of vertices from the object space to the eye space these computations reduce the performance of the 3D imaging device.

In a conventional user defined clipping process in eye space shown in such as provided by the OpenGL ES engine the vertex object coordinates denoted as V obj of step S are transformed using a modelview transformation process at step S. At step S the vertex object coordinates V obj are converted into eye space to form vertex eye coordinates denoted as V eye where the vertex object coordinates V obj are multiplied by the modelview matrix M for the coordinates. The vertex eye coordinates V eye are subjected to primitive assembling at one of steps S if a polygon S if a line segment and S if a point . The primitive assembling for a polygon at step S and for a line segment at step S are further subjected to a flat shading process at step S. If the shade model is flat shading then the color of each vertex will be replaced with the color of the last vertex of the triangle or line. The output from the flat shading process of step S or the point assemble process of step S are subjected to the user defined clipping process in eye space at step S if enabled. Enabling the clipping process at step S will be described in detail later.

The primitives can be a polygon a line segment or point and can be clipped using a conventional user defined clipping process shown in . These primitives can be clipped against a user clip plane at step S. In clip coordinates the view volume of step S is defined by where x yand zare clip coordinates.

The view volume can be further restricted by as many as n user defined clip planes to generate the clip volume wherein n is an implementation dependent. Each user defined plane specifies a half space. The clip volume is the intersection of all such half spaces with the view volume Step S . It should be noted that in ordinary OpenGL user clipping can be done in either eye space or in the projection space. However step S assumes that it is done in projection space. However if no user defined clip planes are enabled at step S the clip volume is the view volume at step S. Hence the output from the Flat shading process S if the primitive is a polygon or a line segment or the point assemble process of step S are subjected to a projection transform at step S without the user defined clipping process of step S.

A user defined clip plane is specified at step S with the function ClipPlane plane eqn 4 where the value of the first argument plane is a symbolic constant CLIP PLANEi where i is an integer between 0 and n 1 indicating one of n user defined clip planes and eqn 4 is an array of four single precision floating point values. OpenGL requires double precision floating points. The four single precision floating point values are the coefficients of a plane equation P of step S in object coordinates denoted as p p p and p. The current modelview matrix denoted as Mc is stored for the clip plane P at step S. The inverse of the current modelview matrix Mc for the clip plane P is obtained or calculated at step S via an inverse matrix process. The resultant inverse matrix is denoted as Inv Mc. The Inv Mc is applied to these coefficients via multiplication at the time they are specified at step S yielding P eye as follows  eye where Mc is the current modelview matrix Mcis the Inv Mc the resulting plane equation is undefined if Mc is singular and may be inaccurate if Mc is poorly conditioned and P eye is the plane equation coefficients in eye coordinates at step S which is followed by step S. At step S all points with eye coordinates xyzw that satisfy  eye eye 0 or 0 lie in the half space defined by the plane points that do not satisfy this condition do not lie in the half space where T is a transpose and denotes multiplication of a matrix or vector.

At step S the user defined clip planes are enabled with an Enable command. Alternately the clipping could be disabled with the Disable command. At step S a determination is made whether the user defined clip planes are enabled or disabled. If the determination is YES meaning enabled the output from the flat shading process S if a polygon or line segment assemble of step S or S or the point assemble process S is subject to clipping at step S in eye space. The value of the argument to either command is CLIP PLANEi where i is an integer between 0 and n specifying a value of i enables or disables the plane equation with index i. The constants obey ClipPlane I ClipPlane i.

Regarding step S if the primitive under consideration is a point then clipping passes the primitive unchanged if the primitive lies within the clip volume otherwise the primitive is discarded. If the primitive is a line segment at step S then clipping does nothing to the primitive if the primitive lies entirely within the clip volume and discards the primitive if it lies entirely outside the volume. If part of the line segment lies in the volume and part lies outside then the line segment is clipped and new vertex coordinates are computed for one or both vertices. A clipped line segment endpoint lies on both the original line segment and the boundary of the clip volume.

The clipping process at step S yields a value 0 t 1 for each clipped vertex. If the coordinates of a clipped vertex are D and the original vertices coordinates are Dand D then t is given by 1 where the value of t is used in color and texture coordinate clipping.

If the primitive is a polygon at step S then the primitive is passed if every one of its edges lies entirely inside the clip volume and is either clipped or discarded otherwise. Polygon clipping may cause polygon edges to be clipped but because polygon connectivity must be maintained these clipped edges are connected by new edges that lie along the clip volume s boundary. Thus clipping may require the introduction of new vertices into a polygon. Edge flags are associated with these vertices so that edges introduced by clipping are flagged as boundaries edge flag TRUE and so that original edges of the polygon that become cut off at these vertices retain their original flags.

If it happens that a polygon intersects an edge of the clip volume s boundary then the clipped polygon must include a point on this boundary edge. This point must lie in the intersection of the boundary edge and the convex hull of the vertices of the original polygon.

A line segment or polygon whose vertices have wvalues of differing signs may generate multiple connected components after clipping. Some implementations are not required to handle this situation. That is only the portion of the primitive that lies in the region of w 0 need be produced by clipping.

Primitives rendered with clip planes must satisfy a complementarily criterion. Suppose a single clip plane with coefficients p p p p or a number of similarly specified clip planes is enabled and a series of primitives are drawn. Next suppose that the original clip plane is re specified with coefficients p p p p and correspondingly for any other clip planes and the primitives are drawn again. In this case primitives must not be missing any pixels nor may any pixels be drawn twice in regions where those primitives are cut by the clip planes.

Clipping requires plane equations each consisting of four single precision floating point coefficients and corresponding bits indicating which of these user defined plane equations are enabled. In the initial state all user defined plane equation coefficients are zero and all planes are disabled.

In view of the above description of the user defined clipping process in eye space there is a need to reduce the computations for user defined clipping in 3D imaging devices having a 3D graphics software and or hardware engine.

There is also a need to perform the user defined clipping in the object space to avoid transforming vertices from the object space into the eye space. Most cases in 3D gaming content processing require less computation to transform a few user defined clip planes from the eye space to the object space than to transform a lot of vertices from the object space to the eye space.

In view of the above it is an object of the present invention to provide for user defined clipping in object space which consumes less power in a mobile or hand held communication or computing device with limited power capability.

A further object of the present invention is to provide the user defined clipping in the object space to avoid transforming vertices from the object space into the eye space to reduce the number of computations ordinarily required by user defined clipping in the eye space.

A further object of the present invention is to provide in most of the cases in 3D gaming contents less computations to transform a few user defined clip planes from the eye space to the object space than required to transform a lot of vertices from the object space to the eye space.

The foregoing and other objects of the present invention are carried out by an object space user defined clipping driver comprising a primitive assembling module operable to primitive assemble vertex coordinates in object space and a user defined clipping module operable to create clipped vertex coordinates in the object space using clip planes P obj in the object space and the primitive assembled vertex coordinates in the object space.

The clipped and non clipped vertex coordinates in the object space are transformed from the object space directly into projection space by one vector to matrix multiplication. When lighting is disabled and user defined clipping is disabled or enabled the two transforms modelview and projection can be combined into one 4 4 matrix rather than into two 4 4 matrices.

Alternatively the clipped vertex coordinates in the object space are not transformed from the object space to the eye space until immediately before projection transformation.

A further aspect of the present invention is to provide a program code executable by a processor and having program instructions which upon execution are operable to primitive assemble vertex coordinates in object space. The code is also operable to perform user defined clipping to create clipped vertex coordinates in the object space using clip planes P obj in the object space and the primitive assembled vertex coordinates in the object space.

A further aspect of the present invention is to provide a 3D graphics engine comprising an object space user defined clipping driver operable to perform user defined clipping of vertex coordinates in object space when a lighting function is disabled in the 3D graphics engine. The 3D graphics engine also includes a graphics core for transforming the clipped vertex coordinates in the object space into projection space.

A still further aspect of the present invention is to provide a program code having program instructions executable by a processor wherein upon execution the program instructions are operable to perform vertex coordinate processing of vertex coordinates in eye space when lighting is enabled and perform vertex coordinate processing of vertex coordinates in object space when lighting is disabled.

The program instructions operable to perform the vertex processing in the object space is operable to perform primitive assembling in the object space using the vertex coordinates in the object space and user defined clipping in object space.

The program instructions operable to perform the vertex processing in the eye space is operable to perform primitive assembling in the eye space using the vertex coordinates in the eye space and user defined clipping in eye space.

A still further aspect of the present invention is to provide a 3D imaging device comprising determining means for determining whether a lighting function is enabled or disabled eye space processing means for processing vertex coordinates in eye space when the lighting function is enabled and object space processing means for processing vertex coordinates in object space when the lighting function is disabled.

The object space processing means performs primitive assembling in the object space using the vertex coordinates in the object space and user defined clipping in the object space.

The eye space processing means performs primitive assembling in the eye space using the vertex coordinates in the eye space and user defined clipping in the eye space.

The object space processing means includes means for transforming into projection space clipped and non clipped vertex coordinates in the object space directly by one vector to matrix multiplication. When lighting is disabled and user defined clipping is disabled or enabled the two transforms modelview and projection can be combined into one matrix rather than into two matrices.

A further aspect of the present is a method for processing object space user defined clipping comprising the steps of converting clip planes P eye in eye space to clip planes P obj in object space and performing user defined clipping to create clipped vertex coordinates in the object space using the clip planes P obj in the object space and the vertex coordinates in the object space.

A still further aspect of the present invention is a method for dual mode processing user defined clipping comprising the steps of determining whether a lighting function is enabled or disabled performing object space vertex coordinate processing with object space user defined clipping to create clipped vertex coordinates in object space when the lighting function is disabled and performing eye space vertex coordinate processing with eye space user defined clipping to create clipped vertex coordinates in eye space when the lighting function is enabled 

The method for dual mode processing user defined clipping further comprises the step of transforming the clipped vertex coordinates in the object space and non clipped vertex coordinates in the object space directly into projection space.

An advantage of the present invention is higher performance and less power consumption by avoiding generation of eye coordinates if lighting is disabled.

While this invention is susceptible of embodiments in many different forms this specification and the accompanying drawings disclose only some forms as examples of the use of the invention. The invention is not intended to be limited to the embodiments so described and the scope of the invention will be pointed out in the appended claims.

The preferred embodiment of the 3D imaging device according to the present invention is described below with a specific application to a method for user defined clipping in object space. The 3D imaging device may be a personal computer PC 3D graphics system a handheld computing device such as a personal digital assistant PDA or a mobile phone which employs a 3D graphics application. However it will be appreciated by those of ordinary skill in the art that the present invention is also well adapted for other types of computing devices with 3D graphics applications such for Game applications simulator graphics and virtual reality graphics. The present invention implementation is suited for a user defined clipping process in a 3D software engine.

Referring now to the drawings in detail wherein like numerals are used to indicate like elements throughout there is shown in an embodiment of a method for user defined clipping in object space generally designated at according to the present invention.

As best shown in the method for user defined clipping in object space includes a vertex process pipeline with user defined clipping in object space when lighting is disabled. The method identifies data for vertex object coordinates denoted as V obj at step S. Thereafter the vertex object coordinates V obj are subjected to primitive assembling at one of steps S if a polygon S if a line segment and S if a point . The primitive assembling for a polygon at step S and for a line segment at step S are subjected to a flat shading process at step S. If the shade model is flat shading then the color of each vertex will be replaced with the color of the last vertex of the triangle or line. The output from the flat shading process of step S or the point assemble process of step S is subjected to the user defined clipping process if enabled by step S.

The view volume may be further limited by as many as n user defined clip planes to generate the clip half space in the clipping process S wherein n is implementation dependent. Each user defined plane specifies a half space. The clip volume is the intersection of all such half spaces with the view volume Step S . However if no user defined clip planes are enabled at step S the clip volume is the view volume at step S subject to combined modelview and projection transformation .

Clipping requires plane equations each consisting of four single precision floating point coefficients and corresponding bits indicating which of these user defined plane equations are enabled. In the initial state all user defined plane equation coefficients are zero and all planes are disabled.

Step S is followed by step S if the clip plane is disabled. At step S the output from the Flat shading process S if the primitive is a polygon or a line segment or the point assemble process of step S are subjected to both Modelview and projection transform at step S without the user clipping of step S. Step S is followed by step S where a view volume clipping process takes place defined by where x yand zare clip coordinates. Step S ends the method .

Referring now to in the conventional vertex process pipeline with user defined clipping in eye space the pipeline includes vertex object coordinates of step S which is followed by step S. At step S a modelview transformation process takes place where the vertex object coordinates in object space are converted to eye space. Thereafter step S is followed by primitive assembling process S which includes in general steps S S S and S. The primitive assembling process S is followed by the user clipping process S assuming clipping is enabled which in turn is followed by a projection transformation process at step S. Step S is followed by step S where a process for view volume clipping can take place. Step S ends the pipeline .

On the other hand the vertex process pipeline with user defined clipping in object space is split as best seen in wherein the driver A performs the primitive assembling in object space at step S followed by a user defined clipping process in object space at step S assuming that an enable command has been received . Step S includes steps S S S and S and step S includes steps S S S S S S S S S and S. A 3D graphics engine may be implemented as a software graphic engine or a hardware graphics engine and provides the Graphics Core. The 3D graphics engine A is shown separate from the program instructions A but would include suitable program instructions not shown . In the embodiment shown in and the driver A is generally implemented as software. In the 3D graphics engine A the vertex object coordinates of step S are still in object space but are clipped vertex object coordinates denoted as CV obj and need to be transformed to projection space vertex coordinates using a combined modelview and projection transformation process of step S as will be described in more detail later using a single matrix such as a single 4 4 matrix. Some vertex coordinates V obj passing through the user clipping step S are not clipped as the result of a plane being disabled Step S to S or if the condition in step S is not met. These vertex coordinates are non clipped vertex coordinates V obj in the object space. Thus the vertex coordinates of step S may provide data that is both CV obj and V obj to step S

Alternately the combined modelview and projection transformation process S may include a two step process denoted at steps SA shown in phantom which uses the same equation as step S of . The modelview transform of step SA is the same as the modelview transformation at step S. Step SA converts the clipped vertex object coordinates into eye space immediately before the projection transformation process of step SB shown in phantom . This two step process requires two 2 separate matrices. Step S or SB is followed by the view volume clipping process of step S.

Referring now to the combined modelview and projection transformation process of step S assume the following  eye  obj MVT matrix where MVT matrix is the modelview transform matrix. Since V eye for user clipping is not used MVT matrix and Projection matrix are combined into one matrix MVTPRJ matrix. Projection coordinates can be calculated as  prj  obj MVTPRJ matrix or  prj  obj MVTPRJ matrix where CV obj is the clipped vertex coordinates in the object space and V obj are non clipped vertex coordinates in object space V prj is the all vertex coordinates in projection space and MVTPRJ matrix is the combined MVT matrix and Projection matrix.

The pipeline performs the user defined clipping in the object space to avoid transforming vertices from the object space into the eye space. In most of the cases in 3D gaming contents pipeline requires less computation to transform a few user defined clip planes from the eye space to the object space than to transform a lot of vertices from the object space to the eye space.

Moreover in the pipeline the modelview transform can be combined with the projection transform denoted at step S. In this case after the user defined clipping process of step S clipped vertex coordinates are transformed from the object space directly into the projection space by one vector to matrix multiplication rather than two. In ordinary OpenGL two transformations may be combined when both lighting and user defined clipping are disabled. In the exemplary embodiment the two transformations can be combined as long as lighting is disabled. Thus user defined clipping can be either disabled or enabled. As can be appreciated using a single matrix reduces the computations to achieve the clipped vertex coordinates into projection space.

Referring again to the user can specify multiple clipping planes at step S. A clipping plane is an arbitrary plane in 3D space. Each plane defines a half space. In the user defined clipping any object or any portion of the object will be clipped if it does not lie in the half space. Any object in the scene will be tested against all the clipping planes.

At step S a user defined clip plane is specified by calling a function with ClipPlane plane eqn 4 where the value of the first argument plane is a symbolic constant CLIP PLANEi where i is an integer between 0 and n 1 indicating one of n user defined clip planes and eqn 4 is an array of four floating point values. The four floating point values are the coefficients of a plane equation P of step S in object coordinates denoted as p p pand p. The current modelview matrix denoted as Mc is stored for a clip plane at step S. The inverse of the current modelview matrix Mc for a clip plane is obtained or calculated at step S via an inverse matrix process. The inverse matrix is denoted as Inv Mc. The Inv Mc is applied to these coefficients via multiplication at the time they are specified at step S yielding P eye defined by  eye where Mc is the current modelview matrix Mcis the inverse of the matrix Mc denoted as Inv Mc the resulting plane equation is undefined if Mc is singular and may be inaccurate if Mc is poorly conditioned and P eye is the plane equation coefficients in eye coordinates.

The plane equation coefficients in eye space P eye of the step S are converted to object space at step S using modelview matrix coordinates M. The modelview matrix coordinates M of step S is the same as the matrix coordinates of step S. Furthermore with regard to step SA the modelview transformation can be the same as step S. The conversion of the plane equation coefficients in eye space to object space is defined by  obj or  obj  eye where P obj is the plane equation coefficients in object space T represents the transpose of the matrix or vector and represents matrix multiplication.

Step S is followed by step S where all points with vertex object coordinates V obj xyzw that satisfy  obj obj 0 lie in the half space defined by the plane points that do not satisfy this condition do not lie in the half space.

At step S the user defined clip planes are enabled with an Enable command. Alternately the user could disable clip planes with the Disable command. At step S a determination is made whether the user defined clip planes are enabled or disabled. If the determination is YES meaning enabled the output from the flat shading process S if a polygon or line segment assemble of step S or S or the point assemble process S is subject to clipping at step S in object space. The value of the argument to either command is CLIP PLANEi where i is an integer between 0 and n specifying a value of i enables or disables the plane equation with index i. The constants obey ClipPlane i ClipPlane i.

Referring now to step S the user defined clipping process is applied in the object space rather than in the eye space. Instead of transforming all vertex coordinates from object space to eye space for clipping the user defined clip planes specified at step S are transformed from eye space to object space and clipping is applied thereto. In this way the computations required in transforming of the multiple vertex coordinates is replaced by less computations to transform the clip planes at step S to object space. In the most of the cases the amount of vertex coordinates is much larger than amount of user defined clip planes specified. By moving user defined clipping to the object space many computation cycles are saved and thus power consumption in mobile or hand held devices with 3D imaging capability were reduced.

Conventional user clipping in eye space is determined by P eye V eye. According to following transformation 

Since the vertex based lighting process is based on vertices in the eye space the method to perform clipping in object space will not be applicable to save computation when lighting is enabled. Instead the conventional method should be used if lighting is enabled. In OpenGL and OpenGL ES have an application programming interface API to enable and disable lighting such as using glEnable GLenum array .

Referring now to the dual mode user defined clipping method is shown for use in 3D imaging device A or B of or B respectively and begins with step S where a determination is made whether lighting has been disabled. If the determination at step S is YES the step S is followed by step S where the vertex processing with user defined clipping takes place in object space in accordance with the flowcharts of or . On the other hand if the determination at step S is NO then step S is followed by step S where the vertex processing with user defined clipping takes place in eye space as disclosed in . Thus the driver A or B only needs to be operational when lighting is disabled.

Vertex based processing of is in inner loop of per vertex operation in a graphics pipeline. By removing modelview transform per vertex the system will process vertex data faster. Vertex based processing processes the data per vertex. After the view volume clipping of step S and viewport on the screen the processing is on a per pixel level. Based on the data in each of the vertices of a polygon all pixels within the polygon will be drawn filled. The saved computation can be translated directly into power reduction.

Since the user clipping is done earlier i.e. it is done in the object space rather than in the eye space it is possible to apply the user defined clipping process as a pre processing in software before sending vertex coordinates into a digital signal processor DSP or a hardware based graphics core as best seen in . By doing so the complexity of the graphics pipeline in the DSP or hardware graphics core is reduced and it is possible to enable the user clipping feature in a pre developed graphics system. Vertex coordinates are assembled in S and clipped by user defined clip planes in S. Clipped vertex coordinates in object are sent into the 3D graphics engine A for further processing at step S for transformation into projection space.

Referring now the primitive assembling of Step S if the primitive is a point the Vertex object coordinates in object space S are V obj. The vertex coordinates in eye space are V eye then  eye  obj

Any input clip plane in object space at S is P. ModelView transformation matrix for the clip plane in S is Mc. Then the clip plane in eye space P eye is  eye Inv

Transform the plane P from eye space to the point s object space at step S by the ModelView transformation matrix for the point M. The clip plane in the point s object space P obj is  obj P eye Then perform clipping in the point s object space according to step S or S. As a proof set forth below P obj V obj 0 if and only if P eye V eye 0. The Proof is defined by

If the primitive is a line the line can be described by two vertices at the ends. In object space they are V obj and V obj. To transform the line into eye space by ModelView transformation matrix M  eye1 obj1 and  eye2 obj2. Any input clip plane in object space at S is P. ModelView transformation matrix for the clip plane in S is Mc. Then the clip plane in eye space P eye is defined by  eye Inv

Transform the plane P from eye space to the line s object space at step S by the ModelView transformation matrix for the line M. The clip plane in the line s object space P obj is defined by  obj  eye Then perform the clipping in the line s object space according to step S or S.

It is obvious that the line segment lies entirely in or out of the clip volume in object space if and only if it lies entirely in or out of the clip volume in eye space. The proof to prove that the clip point computed in eye space is the same one transformed from the clip point computed in object space is set forth below.

To proof the clip points are the same in both object space and eye space define the clip point in object space as C obj and the clip point in eye space as C eye. Assume t is a ratio of the clip point in the line clipped into the plane. In object space then  obj P obj obj2  obj obj2 obj obj2 and in eye space  eye P eye eye2  eye eye2 eye eye2 .

If t eye t obj the clip point in eye space should be the clip point in object space transformed by the line s ModelView transformation matrix M. The Proof for C eye is defined by

Since each edge of the polygon is handled as a line segment as described above if it is true for line it is true for polygon.

In view of the foregoing there are three major differences between the conventional approach and the present invention. First in the present invention the vertex coordinates are not transformed from the object space to the eye space until just before projection transformation at step SB or converted directly into projection space. Second in the present invention the user defined clip planes are transformed from the eye space to the object space. Third in the present invention clipping is determined by IF P obj V obj 0 instead of IF P eye V eye 0.

Referring again to the three dimensional 3D imaging device A will now be described in detail. The device A may be a mobile phone or other hand held computing device with communication equipment now shown for permitting two way wired or wireless communications such as a personal digital assistant PDA and a mobile cellular or satellite telephone with video capability. The device A may be a PC laptop or other wireless computing devices. The device A includes a processor and display for displaying the 2 D bitmap on the screen. The storage unit provides the necessary storage for the vertex object coordinates clipped vertex coordinates in object space CV obj clip planes and modelview matrix for the planes and coordinates the projection transformation matrix and MVTPRJ matrix . The storage unit also includes the volume clipping . The storage unit includes one or more suitable computer readable storage medium for use in the type of device A.

The device A further includes program instructions A with the object space user defined clipping driver A or pre processing stage and a 3D graphics application module such as without limitation having game content for playing games simulators CAD virtual reality graphics. The eye space user defined clipping module is software for the vertex processing with user defined clipping in eye space shown in is integrated into the program instructions A for use in the dual mode user defined clipping method . Nevertheless for dual mode operation the eye space user defined clipping module may also be hardware based and would be removed from the program instructions of B.

Referring now to the three dimensional 3D imaging device B depicts a hardware implementation of the object space user defined clipping driver B. The device B like device A may be a mobile phone or other hand held computing device with communication equipment now shown for permitting two way wired or wireless communications such as a personal digital assistant PDA and a mobile cellular or satellite telephone with video capability. The device B may be a PC or laptop. The device B includes a processor and display for displaying the 2 D bitmap on the screen and a storage unit .

The device B further includes program instructions B with a 3D graphics application module shown in phantom such as without limitation having game content for playing games simulators CAD virtual reality graphics. The eye space user defined clipping module is software for the vertex processing with user defined clipping in eye space shown in is integrated into the program instructions B for use in the dual mode user defined clipping method .

In the hardware implementation the 3D graphics engine B integrates or interfaces with the hardware based object space user defined clipping driver B. Nevertheless for dual mode operation the eye space user defined clipping module may also be hardware based and would be removed from the program instructions of B.

With specific reference to the user clipping is done earlier as a pre processing stage or driver A in software before sending vertex coordinates into a DSP or a hardware graphics core of the 3D graphics engine A. The software based object space user defined clipping driver A includes vertex object coordinates in object space shown in phantom . The driver A further includes a primitive assembling module A and an object space user defined clipping module A. The primitive assembling module A includes a polygon assemble sub module AA a line segment assemble sub module AB a point assemble sub module AC and a flat shading sub module AD. The primitive assembling module A includes the program instructions for carrying out the processes of steps of S S S and S. The driver A also includes a 3D graphics engine software interface A to interface the driver A with the 3D graphics engine A.

With specific reference to the user clipping is done as a pre processing stage or driver B in hardware before sending vertex coordinates into a DSP or a hardware graphics core of the 3D graphics engine B. The hardware based object space user defined clipping driver B includes vertex object coordinates in object space shown in phantom . The driver B further includes a primitive assembling module B and an object space user defined clipping module B. The primitive assembling module B includes a polygon assemble sub module BA a line segment assemble sub module BB a point assemble sub module BC and a flat shading sub module BD. The primitive assembling module B carries out the processes of steps of S S S and S. The driver B also includes a 3D graphics engine hardware interface B to interface the driver B with the 3D graphics engine B.

It will be appreciated by those of ordinary skill in the art that the method and device for performing user defined clipping in object space according to the present invention has higher performance and requires less power consumption by avoiding generation of eye coordinates if there is no lighting.

The foregoing description of the embodiments of the invention has been presented for purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed and modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. The embodiments were chosen and described in order to explain the principles of the invention and its practical application to enable one skilled in the art to utilize the invention in various embodiments and with various modifications as are suited to the particular use contemplated. It is intended that the scope of the invention be defined by the claims appended hereto and their equivalents.

