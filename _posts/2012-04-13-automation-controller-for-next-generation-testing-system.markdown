---

title: Automation controller for next generation testing system
abstract: An automation controller for next generation testing system includes a database including a plurality of scripts and modules, a business layer component, and an automation component. The automation component includes an automation agent and an automation worker. The business layer component is operable to determine a next script from the plurality of scripts and modules and send the next script to the automation component in response to a get next script request sent by the automation component. The automation agent is operable to send the get next script request to the business layer, receive the next script from the business layer, and send the next script to the automation worker for execution. The automation worker is operable to execute the next script or section thereof, obtain a result, send status updates, send proof of life notifications and the result of execution to the automation agent.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09183124&OS=09183124&RS=09183124
owner: Accenture Global Services Limited
number: 09183124
owner_city: Dublin
owner_country: IR
publication_date: 20120413
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 61 476 623 filed Apr. 18 2011 which is incorporated by reference in its entirety herein.

This disclosure relates to software testing and in particular this disclosure relates to an automation controller for an integrated platform for developing debugging and executing tests to insure the integrity and functionality of software systems.

The development of computer software involves a rigorous testing process to insure that the software functions as intended. During the testing process testers write various test scripts or software test modules for performing different types of tests necessary to ensure that the computer software is functioning as designed. The testers also set up and run the test scripts while tracking the results and report the test result to appropriate personnel. This process is inefficient and time consuming and requires significant tester involvement.

Further as businesses continue to rely on computer software and complex software packages an increasing number of highly complex computer software has been developed to meet business demands. Due to the increased complexity and scale such software programs require a large scale testing process involving far more testers and test scripts than were required previously. Such increases are related to organizations centralizing their testing and moving to an outsourced testing model. Traditionally testing was embedded into the systems development life cycle SDLC for each project but now central discrete testing functions exist within organizations which test across multiple projects and releases.

Testing tools have been developed to assist the testers in performing the various steps of the testing process. However existing testing tools are not able to provide the required functionality and efficiency to overcome the challenges posed by the large scale testing process.

Testing of various products and or software products has increased in complexity and scope. In the past relatively small groups of designers and developers perhaps 10 to 30 in number developed various tests for testing and verifying the function of software modules or code segments. Such small groups of individuals have been manageable. However as the number of individuals contributing to the project becomes large redundancy and complexity increase which contributes to increased cost and an increase in the number of errors. Therefore a need exists to address the above.

An automation controller for next generation testing system includes a database including a plurality of scripts and modules a business layer component and an automation component. The automation component includes an automation agent and an automation worker. The business layer component is operable to determine a next script from the plurality of scripts and modules and send the next script to the automation component in response to a get next script request sent by the automation component. The automation agent is operable to send the get next script request to the business layer receive the next script from the business layer and send the next script to the automation worker for execution. The automation worker is operable to execute the next script or section thereof obtain a result and send status updates proof of life notifications and the result of execution to the automation agent.

Other embodiments of systems methods features and their corresponding advantages will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems methods features and advantages be included within this description be within the scope of the invention and be protected by the following claims.

As shown in a system for next generation testing NGT system using automation controller provides a platform allowing increased efficiency and functionality for testing computer software. The system may be embodied as a system cooperating with computer hardware components and or as a computer implemented method.

The NGT system may include a unified desktop which includes a test planning tool a modular script designer an execution tool bar and a defect management component . The NGT system may also include a prioritization and assignment manager an automation controller a data supply chain controller an integration layer and a reporting portal . The integration layer may link to an existing testing tool such as Hewlett Packard s HP Quality Center an existing test management and quality management tool such as IBM Rational Quality Manager and a database or server such as a Microsoft SQL Server with SQL Integration Services and SQL Analysis Services. The NGT system may also include virtual machines which may interface with the automation controller . The virtual machines may run a functional test automation tool such as Hewlett Packard s HP QuickTest Professional QTP which is commercially available functional and regression test software. The automation controller automation worker and automation agents may reside within virtual machines VMs . The virtual machines may run a functional test automation tool such as functional and regression test software such as Hewlett Packard s HP QuickTest Professional QTP . Other types of testing tools may also be used.

The NGT system provides a suite of wrapper tools for a testing process. The NGT system may include of a set of tools that integrate with existing test tools and extend their functionality. The NGT system allows functional testing at a larger scale by delivering tools to reduce the effort and increase the quality of testing. The NGT system may reduce testing effort. Further the NGT system may be extendible for use across clients and may be built as an internal set of assets for use across clients and may be designed to allow client specific functionality to be handled through configuration and extension.

The NGT system may be embodied as a system cooperating with computer hardware components and or as computer implemented methods. The NGT system may include a plurality of software components or subsystems. The components or subsystems such as the modular script designer and the automation controller may be implemented in hardware software firmware or any combination of hardware software and firmware and may or may not reside within a single physical or logical space. For example the modules or subsystems referred to in this document and which may or may not be shown in the drawings may be remotely located from each other and may be coupled by a communication network.

The memory subsystem may include any suitable storage components such as RAM EPROM electrically programmable ROM flash memory dynamic memory static memory FIFO first in first out memory LIFO last in first out memory circular memory semiconductor memory bubble memory buffer memory disk memory optical memory cache memory and the like. Any suitable form of memory may be used whether fixed storage on a magnetic medium storage in a semiconductor device or remote storage accessible through a communication link. A user or system interface may be coupled to the computer and may include various input devices such as switches selectable by the system manager and or a keyboard. The user interface also may include suitable output devices such as an LCD display a CRT various LED indicators a printer and or a speech output device as is known in the art.

To facilitate communication between the computer and external sources a communication interface may be operatively coupled to the computer system. The communication interface may be for example a local area network such as an Ethernet network intranet Internet or other suitable network . The communication interface may also be connected to a public switched telephone network PSTN or POTS plain old telephone system which may facilitate communication via the Internet . Any suitable commercially available communication device or network may be used.

Description of the modular script designer follows. Modular script designer combines a simple or facilitating script creation using a modular approach along with an approvals framework. Modularization is the process of grouping test steps into small modules that describe a piece of functionality. These modules combine together to form test scripts or cases. The MSD provides intelligent module suggestions for developing test scripts. Test scripts may include one or more modules. When a module is added to a script a list of likely next modules is displayed to the user. Therefore the modular script designer may improve knowledge management and decrease duplicated efforts in creating modules. Users can also search for modules with an in line search function.

The modular script designer also allows for meta tagging and indicating parameters in the modules. Metadata is added to modules so that the system can understand how and where the module is used. Input and output parameters are specified to enable re use of the modules and data driven approaches. The modular script designer also allows the specification of skills and pre requisites associated with a module. Skills are assigned to the tests so that the system knows who will be able or qualified to execute the script. Pre requisites including data are specified to track the readiness of a test for execution. The modular script designer also provides automated approvals workflow. A centralized workflow system is used to enable modules to be approved or rejected. After a module is created or modified the approver is notified. The approver may choose to approve the module to be used in all scripts for a subset of scripts or for a single script.

Description of the test execution toolbar follows. The test execution toolbar may be a unified toolbar incorporating all of the tools that a tester requires. The test execution toolbar may provide in line test execution. Test scripts can be opened directly within the toolbar which saves room on a tester s desktop and avoids certain keystrokes such as ALT Tabbing between screens. Defect raising and screen capture may be part of the process. The text execution toolbar may also provide an embedded approvals lists. All module script approvals may be shown in the toolbar and an approver can quickly open the relevant script module for approval. The test execution toolbar also allows quick access to all NGT tools. A quick launch bar may be provided to enable the tester to quickly access all of the NGT tools. The toolbar may also handle login management for NGT. A user profile section is available to change user information. The test execution toolbar is also dockable with an auto hide function. The test execution toolbar may be docked to the left hand side of the screen and it can be selected to be visible or auto hide. An extendable framework allows additional panels to be added to the toolbar.

Description of the prioritization and assignment manager PAM follows. The PAM provides a centralized automated prioritization of test scripts with real time assignment logic. The PAM provides configurable prioritization factors. test scripts are prioritized based on a centralized set of factors and the factors can be configured centrally to influence the entire test operation for example to improve performance against contractual key performance indicators KPIs . The PAM further provides a skill based assignment it provides a pull rather than push approach. Testers may click Get Next via a user interface to get assigned the next script to execute. The best script is chosen in real time based on weighted assignment factors. Managers may control the skills as compared against the skills of their team members. The PAM may also provide manager overrides. Managers are given a view of the scripts planned for execution by their team. They are able to change the factors of specific scripts for example business priority to re prioritize the queue and force scripts to be assigned to specific individuals. The PAM may also provide a pluggable framework for new factors. New decision factors can be added by defining a new factor class. The factor may be presented through the user interface and can be weighted in the decision logic. This could be used to enable advanced Applied Statistic decision models.

Description of the automation controller follows. The automation controller may be an automation framework for resilient off line automation on a virtual farm such as a computing machine in a cloud environment. The automation controller facilitates remote execution of test scripts. An automation controller agent may run on virtual machines VM s to manage the execution of test scripts. A logging framework is used to support the execution. The automation controller also may communicate with the PAM to get the next script. This allows the centralized factors to apply to both manual and automated execution.

The automation controller provides intelligent selection of test modules to maximize the return on investment or ROI associated with each test script that is run automatically. The automation controller selects for automation the test scripts that provide the greatest ROI collectively. The choice whether to automate a particular test script using the automation controller may be based on the ROI associated with the test script. For example a particular test script may be a test script that handles initial login by a user. Because a test script that handles initial login by user may be used by hundreds of different test scripts without variation this testing script provides a high ROI and as such may be a good candidate for automation. The ROI is a measure of increased efficiency attained by automation of the test script. A prioritization workflow aids the automation team in assessing the next module to be automated. The user interface allows the automation team to check in and upgrade automated modules.

The automation controller further provides modular design and partial automation in certain embodiments. Automation scripts may be developed as modules and each automation module may have one or more manual modules mapped against it. Partial automation enables rapid execution of automated parts of scripts. The automation controller is used where applicable to automate the execution of test scripts.

Description of the reporting portal follows. The reporting portal provides an automated reporting capability accessible through a central on line portal. The reporting portal may include a full Microsoft Business Intelligence BI suite. The solution makes use of SQL Server Integration Services SQL Server Analysis Services and SQL Server Reporting Services which are available from Microsoft Corporation. A custom SQL Server Integration Services SSIS component directly communicates with external testing tools such as an HP Quality Center which is available from Hewlett Packard Corporation.

The reporting portal also includes an off line data warehouse to avoid testing tool degradation. An off line data warehouse may be maintained to avoid queries directly on the external testing tool. A dimension based data model is used for simplified reporting. Further data is pre aggregated in a multidimensional online analytical processing MOLAP database to provide quick analysis.

The reporting portal further provides cube based metrics and KPIs key process indicators . Using SS Analysis Services measures and targets may have been pre defined which can be included into reports. PowerPivot a spreadsheet add in available from Microsoft Corporation allows data to be quickly analyzed in spreadsheet programs such as Microsoft Excel for ad hoc reports. Further the reporting portal provides integration with solutions such as Microsoft SharePoint . Where data from systems other than the HP Quality Center is required for example financial production data the solution can receive data from solutions such as Microsoft SharePoint . The SSIS component allows the solution to be easily extended to direct data sources where required.

Description of the defect management tool follows. The defect management tool may simplify the process for raising tracking and updating defects. The defect management tool may provide a defect watch list. Toolbar based list of defects with real time Red Amber or Green RAG status indicators may be provided. Red status indicates high risk or serious project issues amber status indicates medium risk and green status indicates low risk. The defect management tool may allow quick access to full information of the defects to see the latest status. The defect management tool may also provide in line defect raising with test history. While executing a test through the toolbar screenshots and test steps may be captured. When a defect is raised this information is pre populated in the defect. Screenshots and other attachments can be uploaded directly. The defect management tool also reduces alt tab operations. By including core defect management in the toolbar the defect management tool is able to reduce the need to alt tab into an external testing system such as the HP Quality Center . The defect management tool also enables automated un blocking of scripts to further avoid time spent in the external testing system. The defect management tool further provides team based views. Managers have a team view to enable them to see the defects currently impacting their team with the relevant size and status.

Description of the test planning tool follows. The test planning tool provides an intelligent interface for estimating planning selecting regression and assigning prep work. The test planning tool provides assisted estimation. A three stage process is used to provide estimation at increasing levels of accuracy. Information is used from previous testing releases to improve estimates. Pluggable architecture for client specific calculations may be used. The test planning tool also provides deconstruction of requirements into tests. The test planning tool assists the user in breaking down requirements into a manageable number of tests. Collaborative working capabilities allow a divide and conquer approach. The test planning tool further provides resource forecasting by skill. Early foresight of skills required to support the testing activities is made possible and graphical display of availability versus demand may be presented on the user interface. The test planning tool further helps to shape the test organization by promoting cross skilling. The test planning tool also provides regression pack suggestions. Using a meta data driven approach the system will suggest an appropriate regression pack. Risk based testing scores can be used to size the pack accordingly.

Description of the test data supply chain follows. The test data supply chain automates the demand management and supply of test data. The test data supply chain may provide a data catalogue. Data types are modeled and stored in a database. The test data team can check data in and out of the catalogue. Also rules can be specified to enable basic data mining. The test data supply chain also provides mapping data to test scripts. During preparation the data type required is selected against the script. Also using the modular script designer data parameters can be mapped directly to script parameters to allow automated assignment at run time. The test data supply chain further provides monitoring of stock levels and re ordering. The test data supply chain can monitor demand versus capacity for all types of data and as data gets used by test scripts the levels are updated. The test data supply chain can order additional data from the data team or via an automated provision. The test data supply chain may also be integrated with the PAM . The stock levels can be used during prioritization to avoid running scripts that do not have available test data or where stock levels are low.

For example if fifty specific test scripts require input data type A and twenty seven specific test scripts require input data type B the test data supply chain organizes the required data types for each script and provides the data to the test script in a just in time manner to avoid redundancy and reduce complexity. Further such test data may change throughout the lifecycle of the testing process based on the results of a particular test. Accordingly the test data supply chain tracks the required changes and updates the data sets required for the corresponding test scripts so that as the test scripts are being executed up to date test data is available to the test script.

The automation controller may include two components an automation agent and an automation worker . The automation agent may be developed using Windows Workflow Foundation 4.0. The automation agent may enable the PAM to manage and host the Workflow run time control manage and report on running instances of automation workers . The automation agent may communicate with NGT application database or server to get the next script for execution by calling an NGT Get Next Service. The NGT Get Next service cleans PC state gets an automation script path gets automation data and transfers work to the automation worker. The automation agent may also communicate with the NGT application database or server to monitor instance states including complete idle suspended and running states. Other states may also be monitored.

The automation agent may monitor instance states by monitoring logs output by the functional test automation tool in the file system containing execution status and traces. The automation agent may also parse the log file to determine the next block or module to be executed. The automation agent may send a delaying instruction and persist the delaying instruction into the automation queue stored on the NGT database . The delaying instruction may be a message that instructs the automation controller to pause execution of a test script store information about the block at which execution paused forward the test script back to the prioritization and assignment manager for a predetermined period of time delay and after the time delay expires allow continued execution of the test script from the block at which execution paused. While execution of the test script is paused another test script may be executed. The parsing process may occur throughout execution of an automation script or at the completion of execution of the automation script by the automation worker and the functional test automation tool . The automation agent may also manage persistence and bookmarks and update the NGT database status log by persisting or storing or maintaining relevant contents of the log files into the NGT database . Additionally the automation agent may raise alerts for example by sending an alert message to the automation support staff via the NGT application service when exceptions are captured via the automation worker log or in the run time environment itself.

The automation worker may have multiple roles including waiting for instructions from the automation agent . For example then the automation worker receives execution instructions and details from the automation agent the automation worker may launch the functional test automation tool open a script via the functional test automation tool from the test management tool add data to the functional test automation tool and add elsewhere when mentioned if accurate data table and run scripts and choose the results path. The automation worker may also capture exceptions and inform the automation agent when exceptions occur. The automation worker may also inform the automation agent when execution of a script is completed faulted cancelled or another status by raising internal events which helps the automation agent decide when to perform the next Get Next action.

Operational support of the automation controller may include deployment and rebooting of virtual machines. The automation controller may be deployed manually on virtual machines using a .msi file generated using Microsoft s Visual Studio Team System 2010 which is a commercially available computer application. This option for deployment may require no additional configuration but updates may require increased support. The automation controller may also be deployed using Microsoft s ClickOnce which is another commercially available computer application. This option for deployment reduces the support requirement by enabling automatic updates after the first installation. Clients may need to allow automatic update which may require a user to login as an administrative user.

Rebooting of virtual machines may involve a virtual network computing VNC based configuration operated at a client to maximize the hardware usage. For example each virtual machine may be allocated to three administrative users with separate logins. When the virtual machines are rebooted because of operational or maintenance needs the automation controller may instantiate or create a real instance of the automation agent at the start of the console session during the reboot remotely log into two additional sessions at the start up and start an instance of the automation agent at the startup on remote machines.

Components in the automation controller may communicate using a functional test automation tool to automation agent workflow which may be a predefined flat file format for passing information between a functional test automation tool session and workflow. The file format may include information such as the next section to run and the delay time till next execution.

Test automation provided by the automation controller may take place on the Virtual Machines VMs . Each VM may have an instance of functional test automation tool installed along with a small service based application to poll for the next task to execute. The service will call the PAM to get the next test to be executed load that test in the functional test automation tool run the test record the results and then ask for the next test. The automation controller may include four types of features Get Next Script Script Generation Script Execution and Resilience . The Get Next Script feature allows a service to be deployed to the VMs and calls a central Web Service to get the next script which returns a set of input variables and a list of modules to be executed. The Script Generation feature creates a script to be loaded into the functional test automation tool for execution. The Script Execution feature runs the script in the functional test automation tool and records the results. The resilience feature allows the service to be resilient to errors occurring during execution e.g. the functional test automation tool freezing etc. and recover from these situations automatically.

The automation controller may automate script design at a modular level with a one to one mapping between manual modules and automated modules. For example a test script X may include one or more modules. When the script X has modules that are all automatable the NGT system sends the script to the automation controller for testing. The automation controller may then distribute the scripts to VMs to run the scripts unattended.

The NGT system may include UIs which may provide in line automation of modules in a toolbar. For example when a script has a combination of manual modules and automated modules the NGT system may assign the script to a tester. The automation controller may include in a toolbar an icon to indicate that a module is an automated module. The tester may click on the icon to automate that module on the tester s desktop.

The automation controller may provide a feature to get scripts that will produce the highest return on investment RoI when automated. The NGT system may determine how a high RoI may be achieved by analyzing the modules in the system. For example the system may look for modules which are included in the most scripts or look for scripts which include the highest number of automated modules. Based on these and other factors the system may determine which scripts or modules when automated and run by the automation controller will return the highest RoI.

The integration layer provides backend agnostic access to the upstream layers business components layer and presentation layer and enables plug ability via a common interface to one or more backend systems such as QC Rational and Team Foundation Server. Integration layer implements the following design pattern an abstract base class inherits from ProvideBase which is a class available in Microsoft s .NET each concrete implementer in turn inherits from the abstract class above Appropriated Provider is loaded based on type definition in a .config file. The integration layer also includes the integration fa ade. Integration fa ade exposes a simplified interface to the business components layer and reads data from a combination of data transfer objects from one or more backend repository or cache R2 and merges them to a common super data transfer object to return to the business components layer . Integration layer also includes NGT components which interface between the integration fa ade and the data layer and may provide mapping functionality for the integration layer if required. The integration layer also includes caching components and testing tool components . Testing tool components are providers servicing requests for data read write from a Testing Tool .

The data layer includes data access components which centralize the logic necessary to access underlying NGT data store exposing methods to allow easier and transparent access to the database. It also includes data helper utilities which are used to centralizing generic data access functionality such as managing database connections. The data layer also includes service agents which provide Windows Communication Foundation services proxy for talking to application server services. The data layer may be an Enterprise Library Data Access Application Block or a custom designed data layer. Alternatively object relational mapping tools such as Entity Spaces available from EntitySpaces LLP Genome available from TechTalk GmbH LINQ to SQL available from Microsoft Corporation Entity Framework also available from Microsoft Corporation or LLBLGen Pro available from Solutions Design may be used to generate the data layer components.

Cross cutting functions in the NGT may include for example security exceptions handling locking and communication. The NGT may also include a local cache . Outputs from the NGT may include for example email functionality or other information communication functionality. Emails may include notifications to testers regarding script rejection or approval notifications to approvers regarding scripts that are ready for review and notifications regarding security concerns system exceptions and auditing. The NGT may also communicate information to testing tool and an NGT database .

The logic circuitry and processing described above may be encoded in a computer readable medium such as a CDROM disk flash memory RAM or ROM an electromagnetic signal or other machine readable medium as instructions for execution by a processor. Alternatively or additionally the logic may be implemented as analog or digital logic using hardware such as one or more integrated circuits or one or more processors executing instructions or in software in an application programming interface API or in a Dynamic Link Library DLL functions available in a shared memory or defined as local or remote procedure calls or as a combination of hardware and software.

The logic may be represented in e.g. stored on or in a computer readable medium machine readable medium propagated signal medium and or signal bearing medium. The media may comprise any device that contains stores communicates propagates or transports executable instructions for use by or in connection with an instruction executable system apparatus or device. The machine readable medium may selectively be but is not limited to an electronic magnetic optical electromagnetic or infrared signal or a semiconductor system apparatus device or propagation medium. A non exhaustive list of examples of a machine readable medium includes a magnetic or optical disk a volatile memory such as a Random Access Memory RAM a Read Only Memory ROM an Erasable Programmable Read Only Memory i.e. EPROM or Flash memory or an optical fiber. A machine readable medium may also include a tangible medium upon which executable instructions are printed as the logic may be electronically stored as an image or in another format e.g. through an optical scan and then compiled and or interpreted or otherwise processed. The processed medium may then be stored in a computer and or machine memory.

The systems may include additional or different logic and may be implemented in many different ways. A controller may be implemented as a microprocessor microcontroller application specific integrated circuit ASIC discrete logic or a combination of other types of circuits or logic. Similarly memories may be DRAM SRAM Flash or other types of memory. Parameters e.g. conditions and thresholds and other data structures may be separately stored and managed may be incorporated into a single memory or database or may be logically and physically organized in many different ways. Programs and instruction sets may be parts of a single program separate programs or distributed across several memories and processors.

While various embodiments of the invention have been described it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the invention. Accordingly the invention is not to be restricted except in light of the attached claims and their equivalents.

