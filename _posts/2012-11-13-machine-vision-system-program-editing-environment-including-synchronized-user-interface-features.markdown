---

title: Machine vision system program editing environment including synchronized user interface features
abstract: A machine vision system program editing environment including synchronized selection and/or identification of related features in a plurality of different user interface windows is provided. In particular, one of the windows is an editing window where a part program representation is displayed for editing by a user. In one embodiment, a user may select data or another feature of interest in a window that is not the editing window (e.g., a results window, or graphical workpiece inspection feature display window) and the associated part program instruction representation is automatically highlighted and/or selected in the editing window. Conversely, a part program instruction representation may be selected by a user in the editing window and the associated results or feature in another window is automatically highlighted and/or selected. User interface navigation, rapid program quality assessment, and overall part program creation and editing efficiency are significantly enhanced in such an editing environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09013574&OS=09013574&RS=09013574
owner: Mitutoyo Corporation
number: 09013574
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20121113
---
This application claims the benefit of and priority from U.S. Provisional Patent Application No. 61 560 278 filed Nov. 15 2011 and U.S. patent application Ser. No. 13 297 232 filed Nov. 15 2011.

The invention relates generally to machine vision inspection systems and more particularly to methods for creating and editing part programs in such systems.

Precision machine vision inspection systems or vision systems for short can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer a camera and optical system and a precision stage that is movable in multiple directions so as to allow the camera to scan the features of a workpiece that is being inspected. One exemplary prior art system that is commercially available is the QUICK VISION series of PC based vision systems and QVPAK software available from Mitutoyo America Corporation MAC located in Aurora Ill. The features and operation of the QUICK VISION series of vision systems and the QVPAK software are generally described for example in the 3 published January 2003 and the 3 published September 1996 each of which is hereby incorporated by reference in their entirety. This product as exemplified by the QV 302 Pro model for example is able to use a microscope type optical system to provide images of a workpiece at various magnifications and move the stage as necessary to traverse the workpiece surface beyond the limits of any single video image. A single video image typically encompasses only a portion of the workpiece being observed or inspected given the desired magnification measurement resolution and physical size limitations of such systems.

Machine vision inspection systems generally utilize automated video inspection. U.S. Pat. No. 6 542 180 teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the 180 patent automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text based programming for example or through a recording mode which progressively learns the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user with the aid of a graphical user interface or through a combination of both methods. Such a recording mode is often referred to as learn mode or training mode. Once the inspection event sequence is defined in learn mode such a sequence can then be used to automatically acquire and additionally analyze or inspect images of a workpiece during run mode. 

Video tools or tools for short and other graphical user interface features may be used manually to accomplish manual inspection and or machine control operations in manual mode . Their set up parameters and operation can also be recorded during learn mode in order to create automatic inspection programs or part programs. Video tools may include for example edge boundary detection tools autofocus tools shape or pattern matching tools dimension measuring tools and the like. Other graphical user interface features may include dialog boxes related to data analysis step and repeat loop programming and the like. For example such tools are routinely used in a variety of commercially available machine vision inspection systems such as the QUICK VISION series of vision systems and the associated QVPAK software discussed above.

The machine control instructions including the specific inspection event sequence i.e. how to acquire each image and how to analyze inspect each acquired image are generally stored as a part program or workpiece program that is specific to the particular workpiece configuration. For example a part program defines how to acquire each image such as how to position the camera relative to the workpiece at what lighting level at what magnification level etc. Further the part program defines how to analyze inspect an acquired image for example by using one or more video tools such as edge boundary detection video tools.

Editing a part program for a machine vision inspection system is a more complex task than editing a program for a machine tool or assembly robot or the like. For example part programs for machine vision inspection systems include later portions that control operations and or provide image dependent measurement results that depend at least partially on the results determined by the execution of a previous portion of the program and or on the particular instance of a workpiece that is being used to provide the images that are essential to the inspection operations. Furthermore the learn mode user interface for such systems used for part program creation and editing may be particularly complex requiring simultaneous display of a real time image window a video tool bar display a part program representation window a results output window a results window for short an inspection feature graphical display window a position window a lighting window and a measurement tool display in order for the user to properly assess the causes and effects of their programming actions in order to create high quality part programs. In such an editing environment simply recognizing the location of all of the effects associated with a part program instruction may be difficult. If a user saves a partially completed part program and recalls the part program at a later time to alter or finish the programming it may be even more difficult for them to recognize the proper association between part program instructions and their associated effects reflected in various windows. A need exists for an editing environment that can enhance user interface navigation rapid program quality assessment and overall part program creation and editing efficiency for machine vision inspection systems.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

In order to address the considerations outlined above it would be desirable for a machine vision inspection system to provide an editing environment including features that can enhance user interface navigation rapid program quality assessment and overall part program creation and editing efficiency for machine vision inspection systems by indicating the relationships between part program instructions represented in an editing window and the related operating context and or results displayed in other windows of the user interface. In such an editing environment the user may more easily recognize the cause and effect relationships between various part program instructions in the results and even navigate to desired parts of the user interface and or desired specific part program instructions in the editing window by selecting a result that is of interest to them and that is displayed in a different window. This is particularly important when the part program is created and edited by recording actual control operations input by a user of the machine vision inspection system in that the user is intuitively selecting assessing and or approving the details of their control operations and or part program instructions based on the resulting state of the machine vision inspection system and or the measurement results associated with those control operations and or part program instructions.

Frequently the indication of a problem or lack of robustness in the part programming instructions will be indicated by an unexpected or out of tolerance result in a results window or a misplaced measurement feature in a graphical display window or the like and not in the part program instructions themselves. However it is only in the editing window that the deficient part programming instructions can be viewed such that they can be understood and reliably edited or supplemented. Furthermore frequently deficient part programming instructions associated with such a displayed result may not be visible in the editing window because the editing window has a limited size in a crowded user interface and a part program may have a very large number of instructions and or corresponding instruction representations. Heretofore no general purpose machine vision inspection system and particularly no system which records actual user controlled operations in order to create a part program e.g. as opposed to simple graphical object or text based programming systems have provided an editing environment which reliably robustly and conveniently indicates the relationships between part program instruction representations in an editing window and the related operating context and or results displayed in other windows of a user interface during editing operations.

In order to support this desirable editing environment a machine vision system program editing environment including a method that provides synchronized selection and or identification of related features in a plurality of different user interface windows is disclosed herein. In particular one of the windows is a part program representation window also called an editing window where part program instruction representations are displayed for editing by a user. In one embodiment a user may select data or another feature of interest in a window that is not the editing window e.g. a results window or graphical workpiece inspection feature display window and the associated part program instruction representation is automatically displayed and or highlighted and or selected in the editing window such that editing commands may be conveniently implemented at the automatically highlighted or selected part program instruction representation. Conversely in some embodiments a part program instruction representation may be selected by a user in the editing window and the associated results or feature in another window may be automatically highlighted and or selected for evaluation.

Related editing features and functions which may be used in combination with the features disclosed herein are also described in patent applications entitled Machine Vision System Program Editing Environment Including Real Time Context Generation Features U.S. patent application Ser. No. 13 297 232 filed Nov. 15 2011 hereafter the 232 application System and Method Utilizing An Editing Initialization Block In A Part Program Editing Environment In A Machine Vision System U.S. patent application Ser. No. 13 297 182 filed Nov. 15 2011 hereafter the 182 application and Machine Vision System Editing Environment For A Part Program In Which A Continuous Stream Of Image Acquisition Operations Are Performed During A Run Mode U.S. patent application Ser. No. 13 297 220 filed Nov. 15 2011 hereafter the 220 application each of which is hereby incorporated by reference in its entirety. The features disclosed herein are particularly useful when used in combination with the context generation features disclosed in the 232 application. This is because if a user edits an arbitrary location in a part program which is reached by the methods disclosed herein the machine configuration or context at that time may be unknown that is it may be unknown if certain types of changes have occurred e.g. the part being moved on the stage etc. relative to the machine configuration which would be expected if the part program was executed from the beginning up to that arbitrary location in the part program. Continuing edits to the part program at that arbitrary location without establishing the expected operating context for that location e.g. the machine configuration etc. may produce unpredictable results and or even machine damage. Due to such concerns it has been a standard practice for some such systems to actually execute all of the instructions of a part program from the beginning up to and including any potential additional modifications or additions to the part program instructions in order to verify that the modifications and or additions are being programmed based on a realistic set of conditions that is the expected context for their operation. However the execution of all of the instructions of a part program to provide a realistic operating condition for modifications or additions to the instructions is impractical for large part programs e.g. those including a large number of image acquisitions and or feature inspections which are particularly common for machine vision inspection systems that provide microscopic inspection e.g. micron resolution measurements on macroscopic objects e.g. objects spanning tens or hundreds of millimeters . For this reason jumping to an arbitrary location in a part program e.g. by the methods disclosed herein has not been a strongly felt need because it was not particularly useful in prior art machine vision inspection systems. However the 232 application discloses methods for providing an editing environment which reliably and robustly provides a valid part programming editing context in near real time at an arbitrary location in a part program during editing operations which significantly increases the utility and time savings associated with the methods disclosed herein.

Thus in some embodiments of the present invention as further described below and in the 232 application a machine vision inspection system further comprises a run mode a learn mode and an editing portion. The run mode is operable to execute a previously created part program using a run mode of execution. The learn mode sometimes referred to as record mode is operable to receive user input to control operations of the machine vision inspection system and record part program instructions corresponding to the controlled operations in order to create a part program. The learn mode also includes an editing user interface comprising the editing window which includes comprising an editable part program representation of part program instructions wherein the part program representation comprises instruction representations. The editing portion is operable to edit a part program and includes an editing execution portion operable to execute previously recorded part program instructions according to an edit mode of execution that is different than the run mode of execution.

In various embodiments the learn mode is configured such that it is further operable to automatically record respective surrogate data which is associated with a respective set of recorded part program instructions wherein at least some of the surrogate data includes data which results from actual control operations corresponding to the associated set of recorded instructions. In addition the edit mode of execution includes a surrogate execution mode. During the surrogate execution mode for at least one set of part program instructions if respective surrogate data has been previously recorded in association with that set of part program instructions then at least some members of that set of part program instructions are not executed. In other words the corresponding associated actual control operations are not executed and the respective surrogate data is used in the subsequent operation of the surrogate execution mode as a substitute for data that would otherwise result from those actual control operations which are not executed.

In various embodiments the learn mode may be configured to record in a respective set of recorded part program instructions an indication of whether respective surrogate data has been previously recorded in association with that respective set of part program instructions. In one embodiment the indication is included in an initial instruction of the respective set of recorded part program instructions. In one embodiment the respective set of recorded part program instructions may comprise instructions written in a mark up language e.g. XML or a derivative thereof . In various embodiments the respective set of recorded part program instructions may comprise at least one of an element a parent element a container element and a child element written in the mark up language. In at least one embodiment the indication may comprise the presence of respective surrogate data included within that respective set of recorded part program instructions. In at least one embodiment the indication may comprise a respective identifier included within that respective set of recorded part program instructions the respective identifier usable to locate the corresponding respective surrogate data in a surrogate data memory portion of the machine vision inspection system.

In various embodiments the editing portion comprises editing commands usable to edit a part program and the editing execution portion is configured such that when the user uses the editing user interface to input an editing command to edit the program at a target location indicated in the editing window and or the part program representation e.g. an arbitrary part program location reached by the methods disclosed herein then the edit mode of execution begins at a valid context starting location in the part program prior to the target location and uses the surrogate execution mode for executing at least a portion of the part program instructions in order to establish a valid context for editing the part program at the target location.

Additional features associated with providing and using the systems and methods disclosed herein and briefly outlined above will be understood by one of ordinary skill in the art based upon the various drawings descriptions and claims disclosed in this application especially when taken in conjunction with the incorporated references wherein similarly depicted described and or referenced elements may be further understood by cross referencing.

The vision measuring machine includes a moveable workpiece stage and an optical imaging system which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system is generally comparable to the QUICK VISION series of vision systems and the QVPAK software discussed above and similar state of the art commercially available precision machine vision inspection systems. Suitable machine vision inspection system are also described in commonly assigned U.S. Pat. Nos. 7 454 053 7 324 682 8 111 938 and 8 111 905 which are each incorporated herein by reference in their entireties.

A workpiece or a tray or fixture holding a plurality of workpieces which is to be imaged using the machine vision inspection system is placed on the workpiece stage . The workpiece stage may be controlled to move relative to the optical assembly portion such that the interchangeable objective lens moves between locations on a workpiece and or among a plurality of workpieces . One or more of a stage light a coaxial light and a surface light may emit source light or respectively to illuminate the workpiece or workpieces . The source light is reflected or transmitted as workpiece light which passes through the interchangeable objective lens and the turret lens assembly and is gathered by the camera system . The image of the workpiece s captured by the camera system is output on a signal line to the control system portion . The light sources and may be connected to the control system portion through signal lines or busses and respectively. To alter the image magnification the control system portion may rotate the turret lens assembly along axis to select a turret lens through a signal line or bus .

In various exemplary embodiments the optical assembly portion is movable in the vertical Z axis direction relative to the workpiece stage using a controllable motor that drives an actuator a connecting cable or the like to move the optical assembly portion along the Z axis to change the focus of the image of the workpiece captured by the camera system . The term Z axis as used herein refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor when used is connected to the input output interface via a signal line .

As shown in in various exemplary embodiments the control system portion includes a controller a power supply portion the input output interface a memory a workpiece program generator and executor a recorder translator and a learn mode portion a run mode portion and editing portion a surrogate data manager a program status manager a node manager an inter window auto scroll portion and a results window portion . Each of these components as well as the additional components described below may be interconnected by one or more data control buses and or application programming interfaces or by direct connections between the various elements.

The input output interface includes an imaging control interface a motion control interface a lighting control interface and a lens control interface . The motion control interface may include a position control element and a speed acceleration control element although such elements may be merged and or indistinguishable. The lighting control interface controls for example the selection power on off switch and strobe pulse timing if applicable for the various corresponding light sources of the machine vision inspection system .

The memory includes an image file memory portion a workpiece program memory portion that may include one or more part programs PP or the like and a video tool portion . The video tool portion includes video tool portion and other video tool portions which determine the GUI image processing operation etc. for each of the corresponding video tools. Many known video tools are included in commercially available machine vision inspection systems such as the QUICK VISION series of vision systems and the associated QVPAK software discussed above. The video tool portion also includes a region of interest ROI generator that supports automatic semi automatic and or manual operations that define various ROIs that are operable in various video tools included in the video tool portion .

In general the memory portion stores data usable to operate the vision system components portion to capture or acquire an image of the workpiece such that the acquired image of the workpiece has desired image characteristics. The memory portion may also store inspection result data may further store data usable to operate the machine vision inspection system to perform various inspection and measurement operations on the acquired images e.g. implemented in part as video tools either manually or automatically and to output the results through the input output interface . The memory portion may also contain data defining a user interface operable through the input output interface . As will be described in more detail below with reference to in one embodiment when editing a part program rather than being required to execute all of the steps of the part program in order to generate the needed context for continuing edits certain context can be simulated using previously saved data as surrogate data. The memory portion may also store such surrogate data.

The signal lines or busses and of the stage light the coaxial light and the surface light respectively are all connected to the input output interface . The signal line from the camera system and the signal line from the controllable motor are connected to the input output interface . In addition to carrying image data the signal line may carry a signal from the controller that initiates image acquisition.

One or more display devices e.g. the display of and one or more input devices e.g. the joystick keyboard and mouse of can also be connected to the input output interface . The display devices and input devices can be used to display a user interface which may include various user interface features that are usable to perform inspection operations and or to create and or modify part programs to view the images captured by the camera system and or to directly control the vision system components portion . In particular according to various exemplary embodiments of the present invention the display devices and input devices are used to present various user interface features usable to allow rapid efficient intuitive and flexible editing of part programs on the machine vision inspection system .

The workpiece program generator and executor recorder translator learn mode portion run mode portion editing portion surrogate data manager program status manager node manager and an inter window auto scroll portion may in one embodiment all be considered to be part of a general machine controller block MC that is linked to the controller . Additionally a client window portion may be linked to the controller . A client window may be considered to be outside of but communicating to inter operate with the control system portion in some embodiments. The workpiece program generator and executor is responsible for creating and executing part programs. It will be appreciated that the terms workpiece program and part program may be used interchangeably herein.

In accordance with the operations of the workpiece program generator and executor in various exemplary embodiments when a user utilizes the machine vision inspection system to create a part program for the workpiece the user generates part program instructions either by explicitly coding the instructions automatically semi automatically or manually using a workpiece programming language and or by generating the instructions by operating the machine vision inspection system in a learn mode e.g. as controlled by the learn mode portion to provide a desired image acquisition training sequence. For example a training sequence may comprise positioning a workpiece feature in the field of view FOV setting light levels focusing or autofocusing acquiring an image and providing an inspection training sequence applied to the image e.g. using video tools . The learn mode operates such that the sequence s are captured or recorded and converted to corresponding part program steps i.e. instructions . These part program steps when the part program is executed in a run mode e.g. as controlled by the run mode portion will cause the machine vision inspection system to reproduce the trained image acquisition and inspection operations to automatically inspect a workpiece or workpieces matching the workpiece used when creating the part program.

The recorder translator is utilized for translating machine operations into part program code. In other words if a user performs an action e.g. such as altering a video tool that is used to measure a feature on a workpiece an instruction is generated that is translated into a machine readable language and a reverse translation may also be performed. As will be described in more detail below in certain embodiments disclosed herein certain instructions in a part program may also be translated into instruction representations in a user interface. In some embodiments the part program instructions may be written in a mark up type language code. In one specific example embodiment the mark up language code may be MIML code. The editing portion provides or activates various operations and user interface features related to editing a part program within an editing user interface portion which may include a part program representation window as described in greater detail below.

The surrogate data manager need not be present to practice all embodiments of the present invention. However the surrogate data manager may be used in combination with the present invention in some embodiments. Briefly the surrogate data manager links to surrogate data which in accordance with the present invention may be recorded in a part program. In certain implementations the surrogate data manager is responsible for obtaining the surrogate data from an output where it would normally be generated and providing the surrogate data to be written into the part program. The surrogate data manager is described in greater detail below.

The program status manager in one embodiment manages whether programs are protected or unprotected. In one implementation an unprotected part program may include stored surrogate data while a protected part program has had any surrogate data removed. In one example embodiment protected programs are programs for which the editing process has been completed such as may be utilized in a factory in a run mode. In one embodiment a user may select a part program that is to be protected at which point the program status manager automatically removes all of the surrogate data so that the part program is not burdened with extra execution steps at run time. The program status manager is also responsible for when a program is unprotected such that the surrogate data remains recorded in the part program and when a part program is recalled by the editing portion the surrogate data is indicated as being available.

In one embodiment the node manager is responsible for managing node numbers that are assigned to nodes in a part program. In one implementation within a representation of a part program each of the instruction representations is assigned a node number. In certain implementations an organizational tree structure may be utilized wherein there are parent nodes and child nodes. In certain implementations every line of a part program representation that is generated by the recorder translator is assigned a node number or a guaranteed unique identifier of the like by the node manager . As described in greater detail below in some embodiments the inter window auto scroll portion may utilize the node numbers assigned by the node manager to display related elements of associated part program elements and corresponding editing functions in different windows at the same time. In other words if a user wishes to see which measurements of a workpiece are related to which instruction representations and coded instructions in a part program the inter window auto scroll portion will automatically scroll in the respective windows to the relevant lines in the part program representation and or coded instructions that correspond to the relevant node number.

The results window portion provides or activates various operations and user interface features related to editing a part program including displaying results of measurements performed by machine vision system inspection operations within a results window user interface . However more generally the results window portion and or results window user interface may comprise the various features and attributes described elsewhere in this disclosure as well as extensions and are alternatives which will be apparent to one of ordinary skill in the art based on inter window auto scroll portion features or attributes depicted described and or referenced in this disclosure.

The client window portion provides or activates various operations and user interface features related to editing a part program including displaying features related to measurements performed by machine vision system inspection operations within a client window user interface . However more generally the client window portion and or client window user interface may comprise the various features and attributes described elsewhere in this disclosure as well as extensions and or alternatives which will be apparent to one of ordinary skill in the art based on inter window auto scroll portion features or attributes depicted described and or referenced in this disclosure. A client window need not be present in some embodiments of the present invention. A client window may be associated with a program or routine which is not essential to the basic operation of the machine vision inspection system but which may provide enhanced functionality or ease of use. The graphic view window portion represented by the graphic view window shown in is one example of a client window portion . As shown in a client window may have inter window auto scroll user interface features and attributes that are substantially similar to those disclosed herein for a results window.

Further regarding many features of may be understood based on the descriptions of their analogous or substantially similar counterparts which are similarly depicted described and or referenced elements in the co pending applications previously incorporated herein by reference. The editing portion and or the editing UI portion described in greater detail below may have numerous features similar or identical to analogous features described in the incorporated references. The inter window auto scroll portion may comprise the various features and attributes disclosed herein as well as extensions and alternatives which will be apparent to one of ordinary skill in the art based on inter window auto scroll portion features or attributes depicted described and or referenced in this disclosure. In addition the inter window auto scroll portion may alternatively be referred to as an auto scroll manager and may have some features similar to features described in relation to the auto scroll manager described in the incorporated references.

It will be understood that the editing portion the inter window auto scroll portion the node manager and in some embodiments the surrogate data manager cooperate with one another to provide the various features disclosed herein for enhancing the part program editing environment of a machine vision inspection system. In some embodiments these various portions may alternatively be configured such that they are part of one another or otherwise combined and or indistinguishable. Thus it will be appreciated that the configuration of these portions shown in is exemplary only and not limiting.

In the embodiment shown in the inter window auto scroll portion interacts with the program representation window portion through a program representation window selection event notification SE and a program representation window auto scroll notification AS. The inter window auto scroll portion interacts with the client window portion through a result window selection event notification SE and a result window auto scroll notification AS. The inter window auto scroll portion interacts with the client window portion through a client window selection event notification SE and a client window auto scroll notification AS. The various selection event notifications SE are triggered independently. That is any window that is the host of selection of an element that is of a type that may have an associated element in another window may issue a selection event notification SE in response to that selection based on a routine or operations of that window that are triggered by the selection event.

For example a selection event may be the user selecting an instruction representation in the program representation window or selecting a result in the result window or selecting a graphical element in a client window. Selection may be accomplished by using a user interface input device and a known element selection method such as a mouse click on the element in a user interface or the like. In contrast in various embodiments the auto scroll notifications AS to each applicable window are triggered in response to any selection event notification and are generally sent to all applicable windows however it is not necessary to send an auto scroll notification to the window that created the current selection event notification .

The auto scroll notifications AS are based on a routine or operations of the Inter Auto Scroll Portion that are triggered by a selection event notification SE. In response to receiving an auto scroll notification AS a window displays and or highlights a feature or element in that window that is associated with the particular element that was selected in the window that issued the triggering selection event notification SE as described in greater detail below. One aspect of the novelty of the systems and methods disclosed herein lies in the combination of various attributes and features disclosed herein in relation to providing a machine vision system part programming and editing environment. Such a combination has not been previously contemplated or achieved in relation to the particular operating and programming complexity of a machine vision inspection system in order to provide the related part programming user interface features disclosed herein.

In one embodiment may be implemented using known publisher subscriber methods which are sometimes implemented using XML like languages e.g. as used for notifications between web pages . In various embodiments a publisher subscriber method may be implemented by adapting methods such as a list based method or a broadcast based method or a content based method to support the features disclosed herein. In a machine vision inspection system the publishers and subscribers are generally located in the same processing space and it is possible for the identity of the subscriber windows to be known by the publisher. Applicable to such cases U.S. Pat. No. 8 028 085 the 085 patent which is hereby incorporated herein by reference in its entirety describes low latency methods which may be adapted to support the features disclosed herein.

In various embodiments associated or corresponding features in the various windows may be established as part program instructions are created and or recorded during learn mode. For example in one embodiment each of the corresponding features may be assigned or labeled with the same identifier in each window portion as a means of establishing and recording their association. In such an embodiment the selection event notification SE may include the identifier of the selected element which may be passed through the auto scroll notification AS such that the receiving window may auto scroll e.g. display and or highlight the associated feature or element based on that identifier as described in greater detail below.

The user interface also includes a toolbar a toolbar a stage position display and a field of view display . The toolbar comprises various user tools e.g. measurement video tools arranged horizontally in the upper portion of the user interface . The toolbar comprises user tools e.g. alignment and magnification tools arranged vertically on the right hand portion of the user interface. The stage position display displays X Y and Z coordinates indicating a position of the stage . The field of view display displays a field of view of the machine vision inspection system as imaged by the camera and for reference schematically displays in dashed outline the location where a box tool region of interest corresponding to the box tool instruction representation A would appear as it is defined and recorded by a user.

The part program instruction representations depicted in the part program representation window include parent node instruction representations and . The parent node instruction representation includes children node instruction representations A and B. The parent node instruction representation indicates that a box tool will be opened for measuring the line feature represented as LINE wherein the instruction representation A indicates that the user utilizes the box tool to determine edge points of LINE which are then utilized as indicated by the instruction representation B to define LINE . The parent node instruction representation includes children node instruction representations A and B. The parent node instruction representation indicates that a box tool will be opened for measuring the line feature represented as LINE wherein the instruction representation A indicates that the user utilizes the box tool to determine edge points of LINE which are then utilized as indicated by the instruction representation B to define LINE . The instruction representation indicates that a distance represented as DIST is determined between LINE and LINE . The results window displays measurement results and which correspond to the instruction representations and respectively.

The method s depicted and described with reference to may be used to provide the necessary notifications between windows and each window may include routines or operations that provide the corresponding highlighting and or marking. This provides the benefits outlined above. In one embodiment a selection of an element in the results window or the client window results in a transfer of control to the part program representation window and or selection of the corresponding part program instruction representation in that window once it receives the associated selection event notification e.g. as described with reference to such that editing operations are immediately facilitated.

It should be appreciated that with regard to any window may include elements that are out of view at the time of a selection event notification e.g. in the case of a large part program or workpiece CAD image or the like . The user may scroll the contents of any window individually prior to selection and the contents of other windows need not be adjusted at that time. Then in various embodiments upon a selection event notification if the corresponding element in any window is not currently in the display area a routine or operations of that window will automatically cause its contents to jump or scroll to the element corresponding to the selection event notification. That is if an element in one window related to a user selected element in another window is not visible in its respective window then the learn mode user interface may be configured to automatically scroll the display in its respective window until the element related to the user selected element is visible its respective window. It should also be appreciated that although the word scroll or auto scroll may be used herein these words are used for convenience only and are not limiting. More generally the element corresponding to the selected element may be made visible in its respective window by any convenient and or known method including simply regenerating the window with the desired contents or the like.

As shown in a point associated with an end of LINE is illustrated as part of data . In one embodiment a node ID may be used by the inter window auto scroll portion to be assigned to associated part program instructions and their corresponding instructions representations displayed in the part program representation window and or the results generated results window and or a client window based on the execution of those instructions. Thus related features in various windows become associated in the inter window auto scroll portion.

Alternatively the results window and or the client window and or the part program representation window that is the editing window may generate their own element identifiers at the time that they generate their displayed elements and pass this information to the inter window auto scroll portion which may form an association between the various identifiers in a stored identifier association table or the like. It should be appreciated that in some embodiments the part program instructions in the part program instruction representations may be handled within a single application or subroutine of the machine vision inspection system control software such that a part program instruction or its corresponding part program instruction representation may be represented by a single identifier which is usable by the inter window auto scroll portion in relation to either of these elements.

As shown in at a block a machine vision inspection system learn mode is provided which is configured such that it is operable to receive user input to control operations of the machine vision inspection system and record associated part program instructions corresponding to the controlled operations in order to create a part program the learn mode including a learn mode user interface comprising an editing user interface portion comprising an editable part program representation of part program instructions in an editing window the part program representation comprising instruction representations and a results window which receives and displays respective results which comprise results provided by controlled operations of the machine vision inspection system.

At a block the learn mode is configured such that when user input is received that provides a first respective set of controlled operations of the machine vision inspection system that include operations that determine and display a first respective set of results in the results window then the learn mode is operable to automatically provide operations comprising 

In at least one embodiment or implementation the routine continues either to a routine portion described in block or in another embodiment or implementation to an alternative block A corresponding to a routine portion which is described in .

As shown in the implementation at the block the learn mode is configured to provide user interface operations that operate the results window and the part program representation window the editing window according to a set of inter window auto scroll operations wherein when the user selects a member of the first respective set of results in the results window an inter window auto scroll operation is initiated comprising adjusting the instruction representations in the editing window such that at least one instruction representation of the first respective set of instruction representations is visible in the part program representation window and at least one instruction representation of the first respective set of instruction representations is marked in the editing window by an indicator to indicate at least one instruction representation in the editing window that corresponds to the first respective results selected by the user in the results window.

The corresponding member is associated with part program instructions that generate the first respective set of results in the results window when executed as outlined previously. Then at a block the learn mode is configured to provide user interface operations that operate the results window and the editing window according to a set of inter window auto scroll operations based on the inter window auto scroll association wherein when the user selects a member of the first respective set of results in the results window an inter window auto scroll operation is initiated comprising adjusting the instruction representations in the editing window such that at least one instruction representation of the first respective set of instruction representations is visible in the part program representation window and at least one instruction representation of the first respective set of instruction representations is marked in the editing window by an indicator to indicate at least one instruction representation in the editing window that corresponds to the first respective results selected by the user in the results window. The inter window auto scroll operation is based on the inter window auto scroll association. The inter window auto scroll association may be established as outlined previously and or as described below.

At a block A at least a first respective results identifier is automatically defined and recorded in association with at least one member of the first respective set of results in the results window wherein the first respective results identifier is unique to the at least one member of the first respective set of results.

 a at least a first respective part program instruction identifier in association with at least one member of the first respective set of recorded part program instructions wherein the at least a first respective part program instruction identifier is unique to that at least one member and

 b at least a first respective instruction representation identifier in association with at least one member of the first respective set of part program instruction representations in the editing window wherein the at least a first respective instruction representation identifier is unique to that at least one member.

At a block C an association between the at least a first respective results identifier and at least one of the following is automatically defined and recorded 

In other words following principles previously outlined with reference to block in the association that is defined and recorded is between the identifier of a particular set of results in the results window and the identifier of a corresponding set of part program instructions that generate the first respective set of results in the results window when executed. In one embodiment the identifier s may be implemented as outlined above with reference to .

As previously indicated the results window and or the client window and or the part program representation window that is the editing window may generate their own element identifiers at the time that they generate their displayed elements and pass this information to the inter window auto scroll portion which may form an association between the various identifiers in a stored identifier association table or the like. It should be appreciated that in some embodiments the part program instructions in the part program instruction representations may be handled within a single application or subroutine of the machine vision inspection system control software such that a part program instruction or its corresponding part program instruction representation may be represented by a single identifier which is usable by the inter window auto scroll portion in relation to either of these elements. Thus in some embodiments the identifier associated with the results and the identifier associated with the corresponding part program instructions may be the same identifier and the association operation outlined above with reference to block C is accomplished by simply using the same identifier to identify corresponding elements in various windows.

At a decision block a decision is made as to whether a respective result is selected in the result window e.g. by a user selecting the result through the user interface . If a respective result is not selected in the result window the routine continues to a block where the result window is monitored for selection events and the routine returns to the decision block . If a respective result is selected in the result window the routine continues to a block .

At the block the corresponding respective result identifier associated with the selected respective result is identified.

At a block the respective part program instruction PPI and or the respective PPI identifier associated with the respective result identifier is identified. In one embodiment this may be accomplished through the intermediate step of identifying a respective part program instruction representation identifier associated with the respective result identifier and then identifying the part program instruction s PPI underlying that respective part program instruction representation.

At a decision block a determination is made whether the instruction representation corresponding to the respective PPI and or PPI identifier associated with the respective result identifier is visible in the part program representation window. If the instruction representation corresponding to the respective PPI and or PPI identifier associated with the respective result identifier is visible in the part program representation window the routine continues to a block . If the instruction representation corresponding to the respective PPI and or PPI identifier associated with the respective result identifier is not visible in the part program representation window the routine continues to a block .

At a block the instruction representations in the part program representation window are adjusted such that at least one instruction representation corresponding to the respective PPI and or PPI identifier associated with the respective result identifier is visible in the part program representation window.

At a block that instruction representation corresponding to the respective PPI and or PPI identifier is marked with an indicator in the user interface to indicate at least one instruction representation in the editing window that corresponds to the respective result selected by the user in the results window.

At a decision block a decision is made as to whether a part program instruction PPI representation is selected in the part program representation window. If a PPI representation is selected in the part program representation window the routine continues to a block where the part program representation window is monitored for selection events and the routine returns to the decision block . If a PPI representation is selected in the editing window the routine continues to a block .

At a block the respective part program instruction and or the respective PPI identifier associated with the respective selected PPI representation is identified.

At the block the corresponding respective result identifier associated with the respective PPI and or the respective PPI identifier is identified.

At a decision block a determination is made whether the result identified by the corresponding respective result identifier is visible in the results window. If the result identified by the corresponding respective result identifier is visible in the results window the routine continues to a block . If the result identified by the corresponding respective result identifier is not visible in the results window the routine continues to a block .

At a block the results in the results window are adjusted such that the result identified by the corresponding respective result identifier is visible in the results window.

At a block that result is marked with an indicator in the user interface to indicate at least one result in the result window that corresponds to the respective PPI representation selected by the user in the part program representation window.

In some embodiments the displayed image may be a saved image that is recalled. The previously incorporated 232 application discloses editing portion operations wherein surrogate data is saved after the execution of part program instructions in learn mode. Such surrogate data may comprise a workpiece image that is saved so that it may be displayed in the field of view display when a corresponding part program instruction representation e.g. a box tool instruction representation is chosen in the editing window that is when the workpiece feature in that image was used to initially define that instruction . Alternatively the surrogate data may provide the means of determining the physical location lens configuration and lighting etc. to speed up actual duplication of the image acquisition conditions and image used when initially defining the instruction. As described in the 232 application this procedure may save considerable time and avoid collision risk in contrast to requiring adjustment of the actual vision machine components to acquire a new image of that workpiece feature. More generally the editing portion operations described in the 232 application may advantageously be used in combination with various embodiments disclosed herein to provide the proper program editing context either by surrogate mode execution or actual mode execution or a combination of both when appropriate after an auto scroll operation described herein is executed. Therefore portions of the 232 application are included below with for easy reference and understanding. Further understanding may be gained from the 232 application and other incorporated references.

The edit execution portion is responsible for various execution modes during an editing process and includes a surrogate mode portion an actual mode portion and an edit execution user interface features portion . The surrogate mode portion includes a node analyzer which includes surrogate data operations A and machine operations B. As will be described in more detail below when the surrogate mode portion operates a surrogate execution mode in accordance with the present invention surrogate data is utilized for generating context for the continuing editing operations. The node analyzer in one implementation determines whether the part program execution has reached the target node e.g. where a modification is to be made in the part program . The node analyzer determines whether the surrogate data operations A or actual machine operations B will be performed in accordance with the type of node that is involved. In general once the target node is reached then actual machine operations are performed wherein for part program instructions prior to the target node surrogate data operations may be utilized for generating at least some of the context that is needed for the continuing editing operations. If surrogate data is missing a user may be prompted to allow perform actual machine operations to generate the needed context. In one implementation each node is analyzed to determine if surrogate data operations are applicable including whether surrogate data exists if it is the right type of node for surrogate data operations alternatively whether actual machine operations need to be utilized etc.

The actual mode portion includes operations that are more traditionally performed by prior machine vision systems. It will be appreciated that the actual mode portion may also be called by the surrogate mode portion for performing the machine operations B when appropriate. The actual mode portion includes machine operations A and data operations B. The machine operations A perform actual machine operations e.g. moving the stage as part of a video tool operation while the data operations B generally output data. The edit execution user interface features provide user interface features for the execution of the editing functions e.g. indications as to the status of various execution operations such as color codes indicating what portions of a part program have utilized surrogate data or have been run through an actual execution etc. .

The editor commands includes a run segment portion A a modify portion B and an insert append portion C described in detail in the 232 application. In general the run segment portion A performs an actual run of a selected segment of the part program. It will be appreciated that in order to run a selected segment of a part program the proper context up to the selected segment must be established. As will be described in more detail below in accordance with the present invention the proper context may be established by utilizing surrogate data. If surrogate data does not exist for a certain portion of a part program then a segment may be run so as to generate the needed surrogate data. It will be appreciated that in prior machine vision systems it has been difficult to run an isolated segment of a part program without running all of the preceding portions of the part program due to the need for the proper context leading up to the selected segment. For example if the segment required the stage to be lowered but the system was unaware of the present X Y Z location of the stage then lowering the stage to an unknown position could be inadvisable. Thus in prior implementations the technique typically utilized was to run the entire part program from the beginning in order to be able to run a segment in the middle for which all of the preceding operations could require a significant amount of time to perform. In contrast in accordance with the present invention surrogate data may be utilized to establish the proper context for making edits to or running a segment of a part program without requiring the running of the entire part program from the beginning.

The modify portion B has certain similarities to the operation of the run segment portion A. In general when an instruction representation in a part program is selected to be modified then the surrogate mode may be utilized for the portions of the part program that precede the instruction that is to be modified. In one embodiment when the modify command is selected for an instruction representation in a part program the node for the instruction representation is designated as the target node. Once the target node is reached the editor switches out of the surrogate mode and switches into the actual execution mode e.g. as controlled by the actual mode portion and executes the first relevant part program instruction of the node. In one embodiment if the instruction that is selected for modification corresponds to a child node then the actual execution may be designated to begin at the parent node. In one specific example embodiment if a child node related to a box tool is to be modified the parent node which involves setting up the image acquisition for the box tool may be the node at which the actual execution is set to begin. With regard to the insert append component C if the insert is in between child nodes then the parent node may also need to be executed in order to perform the desired insertion. It will be appreciated that in certain implementations an append operation may generally be considered to be a special case of an insert operation which occurs at the end of an existing part program.

The following description will make reference to both the initial part program instruction representations of and the corresponding features on the workpiece of . In one embodiment each of the instruction representations is associated with a node and is assigned a node number or identifier. In certain implementations a tree structure is utilized wherein some of the instruction representations are associated with parent nodes and some are associated with children nodes. For example the children node instruction representations A D A C A B A C and A B are associated with parent node instruction representations and respectively. It will also be appreciated that in one embodiment the instruction representations as displayed in the editing interface comprise icons and labels derived from the mark up language instructions of the part program. In one embodiment the mark up language of the part program may comprise XML like code. The instruction representations thus point to associated code instructions that are executed as will be described in more detail below with respect to .

As shown in the part program representation begins with the instruction representations and which indicate that the user manually selects a location on the workpiece to act as a rough origin point ROP not shown and then aligns the origin to the rough origin point ROP. More specifically the instruction representations A B C and D indicate that the user sets up and utilizes a manual tool to define the rough origin point ROP and the instruction representation aligns the origin with the rough origin point ROP. The instruction representation then indicates that a box tool will be opened for measuring the line XLINE. More specifically the instruction representations A and B indicate that the user sets up e.g. including moving the stage to a designated location and acquiring a corresponding image and utilizes the box tool to determine the edge points PTX. The functions and operations of box tools and other edge detection video tools are known in the art and are described in more detail in the previously incorporated references. The edge points PTX that are determined by the box tool are then utilized by the instruction representation C to define the line XLINE. Similarly the instruction representation indicates that a box tool will be opened for measuring the line YLINE wherein the instruction representation A indicates that the user utilizes the box tool to determine the edge points PTY which are then utilized as indicated by the instruction representation B to define the line YLINE.

The instruction representation then indicates that an intersection point XYORIGIN is determined at the intersection of the lines XLINE and YLINE. The instruction representation then indicates that the machine vision system is commanded to align the origin to the point XYORIGIN. The instruction representation then indicates that the machine vision system is commanded to align the X axis for the workpiece to the line XLINE. As will be described in more detail below with respect to and as indicated by the comment line the operations of the instruction representations establish the correct location and orientation of the workpiece for performing additional measurements.

The instruction representation then indicates that a box tool will be opened for measuring the line L. More specifically the instruction representations A and B indicate that the user sets up e.g. including moving the stage to a designated location and acquiring a corresponding image and utilizes the box tool to determine the edge points PT which are then utilized as indicated by the instruction representation C to define the line L. As will be described in more detail below the box tool utilized for measuring the line L i.e. illustrated as box tool in and the associated instruction representations and A C are utilized as examples in for illustrating how surrogate data is generated stored and modified.

Returning to the instruction representation indicates that a box tool will be opened for measuring the line L wherein the instruction representation A indicates that the user utilizes a box tool to determine the edge points PT which are then utilized as indicated by the instruction representation B to define the line L. The instruction representation indicates that the user defines a selected position tolerance and the instruction representation indicates that an intersection point is determined where the previously determined lines L and L intersect.

After the part program corresponding to the representation is stored and exited when the part program is recalled for editing prior implementations have required that the entire part program be executed from the beginning in order to produce valid context for continuing edits to the part program. While prior implementations have produced accurate results and part programs by executing all of the instructions each time a part program is recalled for editing the execution of all of the instructions may take a significant amount of time particularly those instructions that require certain time consuming processes such as hardware interactions etc. . As will be described in more detail below in accordance with the present invention rather than executing the entire part program from the beginning previously saved data may be used as surrogate data for simulating valid context for continuing edits to the part program.

In other words in one embodiment when continuing edits are being made to the part program for making measurements on the workpiece it is useful to know certain parameters. For example in order to know the correct thresholds size and location for a video tool it is necessary to have the right video image including information such as the correct stage position light levels magnification etc. In one embodiment such information may be considered as part of the hardware context. In addition in order to know if a sequence is correct for continuing edits to the part program it is useful to know what has been done already including what features have been measured what part coordinate system is being utilized etc. In one embodiment this information may be considered as part of the software context. In one embodiment the context is generally considered as establishing the user interface of the machine vision inspection system in a state such that all of the native interface control elements are ready for modifying the part program. As noted above accurate context is provided at the time the part program is initially recorded and also later at runtime in that all of the part program instructions e.g. corresponding to the representations are generally executed in order. As noted above this provides a valid context for continuing edits to the part program including indicating any measurements and results already produced by the part program e.g. the indications of the lines XLINE YLINE L L and intersection points XYORIGIN and I as illustrated with respect to the workpiece in the user interface .

As will be described in more detail below when editing a part program rather than being required to execute all of the instruction representations of the part program in order to generate the needed context certain context can be simulated by using previously saved data as surrogate data. Briefly during the recording or runtime execution of a part program the data that is needed to determine context is stored with the part program. Then at a later time certain results may be simulated utilizing the saved data as surrogate data in order to produce the desired context. Thus by avoiding the execution of certain time consuming operations e.g. those requiring hardware interaction such as the moving of the stage edge detection focusing lighting changes pattern matching etc. significant time savings may be achieved. The saving of data that may be later utilized as surrogate data will be described in more detail below with respect to .

As shown in the XML like code instructions include node I.D. numbers A B and C which in one embodiment may correspond to the instruction representations A B and C of . The XML like code instructions also include certain position information for the image position and certain box tool position information for the box tool such as may be displayed in the areas and of the user interface of . As shown in data is stored with the part program that may be utilized at a later time as surrogate data for simulating context. More specifically when the instruction representation B of indicates that the box tool of is run to determine the set of edge points PT the positions of the set edge points PT relative to the part coordinate system for the workpiece are stored in the XML like code instructions as the data . Modifications may be made to the part program which may result in modifications to the surrogate data .

As shown in from the point A the routine continues to a block . At the block the learn mode is configured such that it is further operable to automatically record respective surrogate data which is associated with a respective set of recorded part program instructions. In addition at least some respective surrogate data comprises data which results from actual execution of controlled operations corresponding to the associated respective set of recorded part program instructions.

At a block the edit mode of execution is configured such that it comprises a surrogate execution mode wherein during surrogate execution mode of part program instructions represented in the editable part program representation for at least one set of part program instructions if respective surrogate data has been previously recorded in association with that set of part program instructions then at least some members of that set of part program instructions are not executed such that their associated controlled operations are not actually executed. In addition the respective surrogate data is used in subsequent operation of the surrogate execution mode as a substitute for data that would otherwise result from their associated controlled operations which are not executed.

At a block the routine continues to the next node as a current node. At a decision block a determination is made as to whether the current node is the target node of an editing command. If the current node is the target node of an editing command then the routine continues to a block where an actual execution mode is begun at the current node after which the routine continues to a decision block as will be described in more detail below. However in one implementation the target node may be considered to be the parent node associated with an instruction representation and the actual execution mode may start at the parent node such that the physical set up for measurement corresponding to an instruction representation is performed to provide the correct physical context for editing at the instruction representation.

If at the decision block it is determined that the current node is not the target node of an editing command then the routine continues to a decision block where a determination is made as to whether the current node unconditionally requires physical system changes. For example if the node moves the stage to image a new portion of the workpiece e.g. a via a simple move command or the like then in some embodiments this may unconditionally requires physical system changes. Similarly certain magnification changes are unconditional physical system changes and so on. However it will be appreciated that in some embodiments if such changes are embedded within a parent node that already has associated surrogate data and a subsequent node again requires a similar physical change e.g. a move or magnification change respectively then it may not be unconditionally required since it will eventually be superseded by the similar subsequent instruction. Various methods of analyzing whether a current node unconditionally requires physical system changes may be determined by one skilled in the art based on the teachings of this disclosure. In any case if the current node does unconditionally require physical system changes then the routine continues to the block . If the current node does not unconditionally require physical system changes then the routine continues to a decision block .

At the decision block a determination is made as to whether the current node provides results data. If the current node does provide results data then the routine continues to a decision block as will be described in more detail below. If the current node does not provide results data then the routine continues to a block where the node is executed in surrogate execution mode after which the routine continues to the block as will be described in more detail below.

At the decision block a determination is made as to whether surrogate data exists for the current node. If surrogate data does exist for the current node then the routine continues to a block as will be described in more detail below. If surrogate data does not exist for the current node then the routine continues to the block .

At the block the node is executed in surrogate execution mode. For the surrogate execution mode surrogate data is used as a substitute for data that would otherwise result from the execution of control operations associated with at least some members of a set of part program instructions corresponding to the current node and those members of the set of part program instructions are skipped such that the associated control operations are not actually executed.

The routine then continues to the decision block where a determination is made as to whether there is another node to execute in the surrogate execution mode. If there is another node to execute in the surrogate execution mode then the routine returns to the block and if not then the routine ends. For example if execution has arrived at decision block by reaching a target node and executing blocks and then in some instances there will not be another node to execute in surrogate execution mode because the context may already be established for editing at or within the target node.

While various preferred and exemplary embodiments of the invention have been illustrated and described it will be appreciated that various changes can be made therein without departing from the spirit and scope of the invention.

