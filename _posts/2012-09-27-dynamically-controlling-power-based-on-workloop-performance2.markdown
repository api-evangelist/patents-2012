---

title: Dynamically controlling power based on work-loop performance
abstract: The present embodiments provide a system that dynamically controls power consumption in a computing device. During operation, the system measures the performance of the computing device while executing a work-loop. Next, the system determines a derived completion time for the work-loop based on the measured performance. (For example, the derived completion time can be an expected completion time, a maximum completion time, or more generally a completion time distribution.) The system then determines a deadline-proximity for the work-loop based on a comparison between the derived completion time and a deadline for the work-loop. (For example, the deadline-proximity can be an expected deadline-proximity, a minimum deadline-proximity, or more generally a deadline-proximity distribution.) Finally, the system controls the power consumption of the computing device based on the determined deadline-proximity for the work-loop.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09632566&OS=09632566&RS=09632566
owner: Apple Inc.
number: 09632566
owner_city: Cupertino
owner_country: US
publication_date: 20120927
---
The disclosed embodiments generally relate to power management techniques for computing devices. More specifically the disclosed embodiments relate to a technique for dynamically controlling power in a computing device based on empirically determined work loop deadlines.

In order to optimize battery life a portable computing system often reduces power consumption when the system is idle. This is typically done by powering down system modules or reducing clock frequencies and voltage levels when the system detects an idle period. When the system subsequently detects an increase in workload it is desirable for the system to rapidly power up the system modules and increase the clock frequencies and voltage levels to their normal operating levels.

While performing these power management operations it is desirable to avoid large latencies or overreactions to the current state of the system. In order to accomplish this a critical piece of information that must be determined is an estimate of how busy the system will be in the future.

Traditionally real time operating systems were designed to make predictions about metrics of running tasks such as future workloads periodicity of tasks or upcoming deadlines. In harmonic or other perfectly periodic real time systems optimizing power is straightforward. Such systems have an easily calculated periodic workload and one simply adjusts the power to accommodate this workload. In the class of real time systems earliest deadline first EDF scheduling is one of the most effective techniques for real time scheduling. It optimizes throughput yet does not require fixed workloads and does not require a periodic relationship between running tasks. Most portable computing systems do not operate in a perfectly periodic environment which makes EDF an optimal real time scheduling choice in terms of throughput but restricts the ability to estimate the power required to meet the deadline of each running task.

Hence what is needed is a technique for optimizing power management for a portable computing device in an environment with less predictable workloads.

The present embodiments provide a system that dynamically controls power consumption in a computing device. During operation the system measures the performance of the computing device while executing a work loop. Next the system determines a derived completion time for the work loop based on the measured performance. For example the derived completion time can be an expected completion time a maximum completion time or more generally a completion time distribution. The system then determines a deadline proximity for the work loop based on a comparison between the derived completion time and a deadline for the work loop. For example the deadline proximity can be an expected deadline proximity a minimum deadline proximity or more generally a deadline proximity distribution. Finally the system controls the power consumption of the computing device based on the determined deadline proximity for the work loop.

In some embodiments controlling the power consumption of the computing device involves considering deadline proximities for multiple work loops executing on the computing device.

In some embodiments the system determines the deadline for the work loop by obtaining the deadline from an application associated with the work loop.

In some embodiments the system determines the deadline for the work loop based on measurements of a frequency at which the work loop is started.

In some embodiments measuring the performance involves making calls to performance measurement functions through an application programming interface API while executing the work loop. These performance measurement functions signal a start of the work loop and an end of the work loop.

In some embodiments measuring the performance involves performing multiple measurements of a completion time for the work loop.

In some embodiments multiple measurements of work loop completion times and deadline proximity values are obtained to determine a statistical distribution for completion times and deadline proximities for the work loop. The system then uses the determined statistical distribution to determine a power performance setting for the computing device that has a probability p of causing a missed deadline for the work loop where p is typically set to be very small if not zero.

In some embodiments controlling the power consumption involves controlling a power performance state P state of a processor in the computing device wherein the P state determines a clock speed and or an operating voltage of the processor.

In some embodiments controlling the power consumption involves controlling a CPU power state C state for a processor in the computing device wherein the C state determines whether the processor is in an operating state a halted state or a sleep state.

In some embodiments controlling the power consumption involves scheduling threads to run on one or more processor cores in the computing device based on power consumption considerations and the one or more work loop deadlines.

In some embodiments scheduling the threads involves scheduling the threads to run in parallel on the same core scheduling the threads to run serially on the same core or scheduling the threads to run in parallel on different cores.

The following description is presented to enable any person skilled in the art to make and use the present embodiments and is provided in the context of a particular application and its requirements. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art and the general principles defined herein may be applied to other embodiments and applications without departing from the spirit and scope of the present embodiments. Thus the present embodiments are not limited to the embodiments shown but are to be accorded the widest scope consistent with the principles and features disclosed herein.

The data structures and code described in this detailed description are typically stored on a computer readable storage medium which may be any device or medium that can store code and or data for use by a computer system. The computer readable storage medium includes but is not limited to volatile memory non volatile memory solid state storage devices magnetic and optical storage devices such as disk drives magnetic tape CDs compact discs DVDs digital versatile discs or digital video discs or other media capable of storing computer readable media now known or later developed.

The methods and processes described in the detailed description section can be embodied as code and or data which can be stored in a computer readable storage medium as described above. When a computer system reads and executes the code and or data stored on the computer readable storage medium the computer system performs the methods and processes embodied as data structures and code and stored within the computer readable storage medium. Furthermore the methods and processes described below can be included in hardware modules. For example the hardware modules can include but are not limited to application specific integrated circuit ASIC chips field programmable gate arrays FPGAs and other programmable logic devices now known or later developed. When the hardware modules are activated the hardware modules perform the methods and processes included within the hardware modules.

The disclosed embodiments can effectively optimize battery life in a complex N device system with a highly variable workload. In the EDF spirit the system operates using upcoming deadlines. However the system includes a number of additions to the conventional EDF scheduling technique. First the system abandons the classic notion of an EDF thread or process rather the system operates based on work loops W. These are loops that can span multiple threads or multiple devices but like a classic EDF thread or process represent a body of work W that the system desires to accomplish in time T. A key metric for these work loops is their upcoming deadline or a variant thereof represented by T. Unlike existing systems the disclosed embodiments keep track of how long it takes to complete a task independently of where the task is executed. For example the task can be executed on N different devices. Moreover note that the disclosed embodiments gather statistics and then adjust power based on this live data as opposed to other systems that perform adjustments based on predetermined measurements.

During operation the system statistically measures the proximity of each work loop W to its upcoming deadline or alternatively its duty cycle over an appropriate amount of time T where T T. In doing so the system identifies boundary cases where this determined deadline must be adjusted. Next based on these statistical measurements and adjustments the power management system performs adjustments to limit in the statistical sense excursions into the power deficit space where power has been lowered too much and we miss one or more deadlines and also to limit excursions into the power surplus space where power has been raised too much and we burn excessive power completing W.

Note that if every critical global work loop is measured the system has enough information to make a reasonable power adjustment. These power adjustments should ideally take into account how loaded the system is. If the system is highly loaded and is operating at a maximum power level the probability that the system will miss a deadline if the power is adjusted downward is great. On the other hand if the system is less loaded e.g. is operating at of a maximum possible load the power level can be adjusted downward with less risk of missing a deadline.

To avoid missing deadlines the system can initially operate at a maximum power level and the system can monitor its workload for a practically significant amount of time to enable the system to take action based on the measurements. For example assume we measure a work loop for an audio buffer 3000 times. Based on this large number of measurements we can determine statistically that we have a certain amount of headroom and variance. We can then dial the power down based on this variance for example to come within 7 standard deviations of a deadline which is close to a zero probability of missing the deadline. Moreover if something dramatic happens with the system we detect a change we can return to the full power mode so we do not miss any deadlines and can take additional measurements before lowering the power again.

Note that in some applications such as real time video streaming the penalty for missing a deadline is only a video glitch which is acceptable if it does not happen often. In these applications we can dial down the power to achieve whatever error rate we feel comfortable with.

Also the tasks that we are concerned with include work that needs to be completed by a certain deadline. However there exist other background tasks that do not have to be completed by a specific deadline such as a chron process. We can consider such background processes to have a deadline of infinity.

We describe how the system operates in more detail below but first we describe a computing device upon which the system operates.

Results from performance measurement mechanism feed into control mechanism which uses the results to control a power consumption level for computing device . This can be accomplished by feeding various control signals into processor chip which includes multiple processor cores . These control signals can generally include any type of control signal that can be used to adjust the power performance of computing device . For example in one possible implementation that uses an INTEL chipset these control signals can include a P state signal that determines a clock speed and or operating voltage of the processor. The control signals can also include a C state signal that determines whether the processor is in an operating state a halted state or a sleep state.

Controller also communicates with a scheduler which schedules various processes to run on processor cores within processor chip . As mentioned above this can involve scheduling the threads to run 1 in parallel on the same core 2 serially on the same core or 3 in parallel on different cores.

Next the system uses the measurements to determine a statistical distribution for completion times for the work loop step and then uses the determined statistical distribution to determine a derived completion time for the work loop step . In one embodiment the system determines the derived completion time based on the worst performer of all measurements. However we can push the derived completion time closer to the average completion time based on an empirically derived distribution to achieve more power savings at the cost at a small increase in the risk of missing a future deadline. The system then determines a deadline proximity or deadline proximity distribution for the work loop based on a comparison between the completion time distribution or derived completion time for the work loop and a deadline for the work loop step . For example the deadline proximity can be determined by subtracting the derived completion time from the deadline for the work loop.

Finally the system controls the power consumption of the computing device based the determined deadline proximity for the work loop and the granularity flexibility of the power control for the system step . Note that this step can involve taking into account deadline proximities for multiple work loops. As mentioned above for an INTEL chip set specific implementation controlling the power consumption can involve controlling a power performance state P state of a processor in the computing device wherein the P state determines a clock speed and or an operating voltage of the processor. In addition controlling the power consumption can involve controlling a CPU power state C state for a processor in the computing device wherein the C state determines whether the processor is in an operating state a halted state or a sleep state of various levels of power savings and exit latency.

In other embodiments controlling the power consumption can involve scheduling threads to run on one or more processor cores in the computing device based on power consumption considerations and the one or more work loop deadlines. For example the system can schedule threads to 1 run in parallel on the same core using hyper threading or similar techniques when available 2 run serially on the same core or 3 run in parallel on different cores. Note that computer systems typically try not to schedule two threads to run on the same core. However note that it is possible to save power by scheduling two threads on the same core which eliminates the need to expend power to open up an additional core. We can alternatively hold off on running a thread on a core because the thread has a lot of headroom before its deadline. This enables another thread to finish executing on the core so the system does not have to open another core. Without this knowledge about deadlines and headroom the system must spawn the thread onto another core.

Note that the work loop deadline can be determined in a number of ways. In some cases we can determine the deadline from the application itself. In other words the application can tell us in advance what the upcoming deadline will be. In other embodiments we can determine the deadline automatically by measuring the frequency at which a specific work loop Wis started and comparing its completion time against this frequency. For example in an ideally created graphics rendering work loop doing animations at the screen refresh rate we know when the next vertical blank will occur and we can set the next vertical blank time as the next deadline that we can measure against. If that time is Td and the completion time for that deadline frame is Tw then the distribution of each sample for all i of Td Tw is what we measure ourselves against.

Alternatively we can relax the requirement of having a specific deadline and instead look at relative completion times. For example imagine the same graphics rendering work loop which looks at when it started its rendering work and sets the future deadline to 16 ms in the future the same as 60 frames per second . In this case we are trusting that the system is in phase and that we are called at the right time to render a frame. We then assume the next deadline is Td current time 16 ms and we can measure Twas usual.

Note that Tdis only needed to place a hard boundary that we do not want to cross which occurs in a number of important media realtime scenarios. However there may be scenarios where the metric might be different. For example we can refuse to let the distribution of Twchange by more than a factor of K due to power performance changes which does not require us to determine deadlines Td just expected completion times Tw.

Note that it is possible for work loops to span multiple hardware devices. Moreover the above described work loop system is thread independent. This facilitates managing power globally across the entire system not just within the CPU cores themselves.

Moreover in a system where more than one device can change power e.g. a GPU and a CPU the system can adjust the power of the device that maps best to these one or more of the following criteria 1 the finest smallest performance steps this facilitates making small performance adjustments in situations where headroom is tight 2 the largest headroom as measured by deadline proximity i.e. the device that is the most idle and 3 the largest power savings for a given amount of step i.e. the device give us the best power savings for a given amount of performance loss .

The foregoing descriptions of embodiments have been presented for purposes of illustration and description only. They are not intended to be exhaustive or to limit the present description to the forms disclosed. Accordingly many modifications and variations will be apparent to practitioners skilled in the art. Additionally the above disclosure is not intended to limit the present description. The scope of the present description is defined by the appended claims.

