---

title: Dynamic database memory management according to swap rates
abstract: Memory of a database management system (DBMS) that is running in a virtual or physical machine is managed using techniques that that reduce the effect of memory swaps on the performance of the physical or virtual machine. One such technique includes the steps of determining a swap rate while the database application is in an executing state, and decreasing the size of memory space available to the database application if the swap rate is above a threshold.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09086921&OS=09086921&RS=09086921
owner: VMware, Inc.
number: 09086921
owner_city: Palo Alto
owner_country: US
publication_date: 20120430
---
This application is related to U.S. patent application Ser. No. 12 946 940 filed Nov. 16 2010 and entitled Method and System for Integrating Database Memory Management In Virtual Machines issued on Jan. 13 2015 as U.S. Pat. No. 8 935 456 and U.S. patent application Ser. No. 12 946 971 filed Nov. 16 2010 and entitled Relieving Memory Pressure in a Host Using Database Memory Management issued on Jan. 27 2015 as U.S. Pat. No. 8 943 259.

Due to the specialized ways that database management systems DBMS utilize memory to access data a DBMS typically implements its own memory management techniques rather than relying on more general memory management techniques that are provided by the underlying operating system on which the DBMS runs. For example a DBMS may expressly request that the operating system allocate to it a portion of memory so that it can manage such memory on its own thereby avoiding triggering of memory management techniques disk swaps LRU page replacement algorithms etc. that the underlying operating system may typically use to over commit its available physical memory in an effort to provide running applications a larger virtual memory space in which to execute. That is although the operating system may provide the DBMS a virtual memory space that is larger than the portion of physical memory allocated to the DBMS application the DBMS application can using its own memory management techniques ensure that it utilizes its virtual memory space within the bounds of its allocated physical memory and therefore avoid any operating system level memory management activities that would otherwise adversely affect performance of the DBMS e.g. untimely writes to swap disk etc. .

Tuning the DBMS memory has been at the forefront of database research. Recently autonomic techniques for tuning the memory of DBMS at runtime have been developed for some commercial relational databases. One such technique employs memory pools each employing specialized paging policies apart from the paging policies of the operating system. Tuning parameters in this technique include the amount of memory to be allocated to these pools and how that memory is to be divided among the various memory pools.

The largest of the memory pools is the buffer pool which contains the memory pages of database tables that are actively involved in transaction processing. As a transaction modifies rows in database tables the pages containing these rows are brought into the buffer pool from disk and are modified in place. When the transaction is eventually committed by the DBMS these dirty pages are flushed to disk under the control of the DBMS for example by atomically writing a record relating to committed transaction into a write ahead transaction log on disk to ensure that the transaction s changes are never lost. It should be noted that the DBMS not the operating system determines when dirty pages of the buffer pool are written to disk.

In addition the DBMS implementing its own memory management typically maintains its own free list of memory pages and memory page descriptor data structures that are separate and different from any memory management based free memory page lists and data structures maintained by the operating system. Indeed a memory page that the DBMS may regard as free e.g. because it has recently completed a database query transaction relating to the data in the memory page may actually appear to the operating system to be a more important memory page because the DBMS has recently accessed the memory page. As an additional example memory page descriptor data structures maintained by the DBMS may indicate which memory pages are clean and which ones are not. Clean memory pages are those that contain data that matches the corresponding data stored in the database on disk. Because the operating system has no knowledge that the DBMS utilizes portions of its allocated memory as an in memory cache of the data it stores in the database on disk e.g. for faster access and query response times it is not able to similarly characterize the memory pages used by the DBMS.

The DBMS s own memory management techniques referenced above work well when the DBMS is the only application running on a host computer and is able to ensure its own allocation of physical memory. However when a DBMS is run in a virtual machine that is hosted on a computer with other virtual machines or the DBMS is run in a physical machine alongside other workloads the DBMS as initially tuned may be forced to run with insufficient physical memory resulting in performance degradations e.g. due to disk swaps.

One or more embodiments of the present invention provide techniques for managing memory of a database application running on an operating system in a virtual or physical machine that reduces the effect of disk swaps on the performance of the physical or virtual machine. A method according to an embodiment of the present invention includes the steps of determining a swap rate by the operating system while the database application is in an executing state and decreasing the size of memory space available to the database application if the swap rate is above a threshold.

Further embodiments of the present invention include without limitation a non transitory computer readable storage medium that includes instructions that enable a processing unit to implement one or more aspects of the above methods as well as a computer system configured to implement one or more aspects of the above method.

In the embodiments of the present invention described herein a database management system DBMS is running on guest OS and includes various memory management modules. It should be recognized that one or more other applications APPS may be running alongside DMBS on guest OS and compete for virtual hardware resources provided by virtual hardware platform . As will be further described below in conjunction with the memory management modules of DMBS communicate with a balloon driver and a swap monitor of guest OS to carry out memory management. Balloon driver is responsive to memory management commands from hypervisor in particular a resource scheduler module and operates as a balloon driver that is described in U.S. Pat. No. 7 433 951 entitled System and Method for Controlling Resource Revocation in a Multi Guest Computer System the entire contents of which are incorporated by reference herein. Swap monitor is a kernel module inside guest OS that in one embodiment computes the rate of guest physical memory pages that are swapped in from virtual HD . As will be described in further detail below this swap rate is used as an indicator of when the guest e.g. VM is experiencing memory pressure. Moving weighted averages of several time intervals are used to filter out noise with more recent samples getting a higher weight. In this embodiment swap out activity is ignored because cold pages i.e. guest memory pages that have not been accessed recently may be swapped out to virtual HD and such swap activity may not be indicative of the guest coming under memory pressure. However in some embodiments swap monitor may consider both the swap in and swap out activities in computing the swap rate.

It should be recognized that the various terms layers and categorizations used to describe the virtualization components in may be referred to differently without departing from their functionality or the spirit or scope of the invention. For example virtual hardware platforms may be considered to be part of virtual machine monitors VMM which implement the virtual system support needed to coordinate operations between hypervisor and their respective VMs. Alternatively virtual hardware platforms may also be considered to be separate e.g. as a component of its corresponding virtual machine since such platforms include the hardware emulation components for the virtual machine from VMMs and VMMs may be considered to be separate from hypervisor . One example of hypervisor that may be used is included as a component of VMware s vSphere product which is commercially available from VMware Inc. of Palo Alto Calif. VMware . It should further be recognized that other virtualized computer systems are contemplated such as hosted virtual machine systems where the hypervisor is implemented in conjunction with a host operating system.

DBMS includes a balloon controller which queries resource scheduler on a periodic basis e.g. once per second. In one embodiment in order to perform such querying balloon controller leverages an application programming interface API to access special runtime components e.g. dynamically loaded libraries shared memory objects etc. that have been installed in guest OS that provide backdoor access to hypervisor to obtain data about the state and performance of the virtual machine in which the application is running e.g. such data that may be only known by hypervisor . One example of such an API is VMware s vSphere Guest API that interacts with the vSphere Guest SDK runtime components that are part of the VMware Tools product. It should be recognized that other techniques such as utilizing hypercalls and other similar backdoor means for an application to communicate with hypervisor may be utilized in other embodiments. Balloon controller via API queries resource scheduler for a variety of runtime information including the balloon target and corresponding inflate or deflate request and the host physical memory currently available e.g. actually allocated to VM . In another embodiment balloon controller may register itself with balloon driver to receive the balloon target and corresponding inflate or deflate request directly from balloon driver and balloon driver may accordingly be configured to notify or respond to balloon controller . It should be recognized that the host physical memory available to VM may vary over time depending on the amount of host physical memory used by all VMs running in host computer system .

In one embodiment in addition to assisting with inflate or deflate commands from resource scheduler balloon controller during normal operations of DBMS continually manages and resizes the sizes of memory pools of DBMS that have been initially tuned for optimal memory management with the VM e.g. when DMBS is the only application running in VM and VM is the only virtual machine running on hypervisor . The memory pools shown in include buffer pool sequential scan pool and temporary table pool . In one embodiment memory pools are executing components of DBMS that have the responsibility of managing certain portions of the memory allocated to DBMS e.g. each such portion a pool for example by implementing policies that allocate or deallocate memory pages to the pool in a manner tailored to the particular usage of the pool by DBMS . It should be recognized however that memory pools may also refer to the allocated portion of memory itself rather than the executing component as the context requires. It should be also recognized that the three memory pools shown in are for illustration and any number and type of memory pools may be provided in the embodiments of the present invention. In response to an inflate or deflate command originating from resource scheduler or due to changes in available host memory to VM during the normal course of execution of DBMS balloon controller may issue requests to any one or all of the memory pools to evict or allocate memory pages according to the memory pool s own memory management policies.

In one embodiment each of the memory pools maintains a page descriptor data structure. The page descriptor data structure distinguishes between free and used guest memory pages and marks used guest memory pages as dirty or not dirty clean i.e. identical to an on disk image. In accordance with the memory pool s own memory management policies the free memory pages may for example be preferentially used before evicting clean memory pages to avoid an extra disk read if the evicted clean page is accessed later and clean memory pages may be preferentially evicted before dirty memory pages because the evictions would not require a corresponding write to a backing store which would be a virtual hard drive in this embodiment. When there are not enough free or clean memory pages dirty memory pages will need to be selected for eviction and these will require a corresponding write to the backing store.

It should be recognized that some memory pools of DBMS not shown in do not maintain page descriptor data. One example is a private memory pool that is often used by sort operators. The private memory pool is not tracked on a per page basis. Instead DBMS maintains other statistics on the usefulness of private memory usage e.g. how much sort memory is actively used the rate of sort or hashing operators etc.

The memory portion managed by buffer pool operates as a large cache for accessing the actual data of the database that is stored on disk. For example database tables and indexes may be cached by buffer pool so that query transactions can be serviced by DBMS in memory without accessing the slow database disk. Buffer pool may implement any policy for evicting and allocating memory pages. In one embodiment memory pages from buffer pool are evicted in the context of a process or thread of balloon controller . In an alternative embodiment balloon controller parallelizes this task by distributing its parts across multiple backend threads or processes.

DBMS may also use a sequential scan pool for example to manage memory to facilitate operations that would perform large sequential scans of the data stored on the database disk. For example a database query that cannot use a previously created database index might scan an entire database table on disk. Sequential scan pool is used in such instances to prevent such operations from polluting buffer pool with cached pages of data from the database that are not likely to be accessed in the near future. In a typical implementation sequential scan pool employs a special fixed size ring data structure and an allocation or eviction request from balloon controller causes a resizing of this ring data structure.

Temporary table pool manages memory for temporary tables that have a lifetime that may be limited to either a session or a transaction generally do not generate write ahead log records and cannot be recovered in the event of a crash. Temporary table pool can thus be resized independently of buffer pool in response an allocation or eviction request from balloon controller .

Balloon controller also registers with a swap monitor to obtain the rate of guest physical memory pages that are swapped in from virtual HD hereinafter referred to as the guest swap rate which is computed by swap monitor as a moving weighted average. The guest swap rate provides an indication of when the guest e.g. VM is under memory pressure. The guest may experience memory pressure for a variety of reasons. First host computer system may be under memory pressure and take memory away from the guest via the ballooning mechanism discussed above. Second other workloads running in the guest such as APPS may increase or the workload of DMBS itself changes. Third the guest may have been configured with too little memory for the workloads that it is servicing.

When the guest swap rate is below a threshold memory of DBMS is managed in the manner described below in conjunction with . When the guest swap rate increases above a certain threshold memory of DBMS is further managed in the manner described below in conjunction with .

At step resource scheduler issues inflate commands to balloon drivers running in VMs including balloon driver of VM . The inflate command to balloon driver includes a balloon target. At step balloon controller determines this balloon target and the inflate command for example by querying resource scheduler via its periodic polling through the aforementioned API or receiving it directly from balloon driver . At step balloon controller issues an eviction request to each of the memory pools in response to which the memory pools each evict memory pages according to the policies implemented in them step . It should be recognized that in alternative embodiments balloon controller may only request certain memory pools to evict memory pages. Similarly in alternative embodiments balloon controller may specifically request a number of memory pages or amount of memory for eviction depending upon the value of the balloon target. At step balloon controller releases the memory pages evicted by the memory pools at step to guest OS . In one embodiment where guest OS is Linux this is accomplished by madvise MADV REMOVE which frees a range of guest memory pages and associated backing store. Afterwards guest OS is free to reuse these guest memory pages for any tasks including pinning such memory pages e.g. so that they are not subsequently paged out to disk during performance of memory management by guest OS and allocating them to balloon driver in response to an inflate command from resource scheduler which occurs at step . At step after the memory pages evicted from the memory pools have been pinned and allocated to balloon driver and balloon driver has notified hypervisor thereof hypervisor re allocates these pinned memory pages to another VM according to conventional ballooning techniques. The number of memory pages freed by DMBS while carrying out steps through may satisfy all or part of the balloon target. If it is less than the balloon target the rest is satisfied by balloon driver according to the standard ballooning techniques such as those described in U.S. Pat. No. 7 433 951.

In one embodiment balloon controller implements a proportional allocation policy to preserve over the course of the execution of DBMS the relative memory pool sizes with respect to each other and to the total amount of host physical memory currently available e.g. currently allocated to VM as this amount may change in response to other VM activity on host computer system . For example as previously discussed balloon controller periodically queries resource scheduler for the available host physical memory to VM in order to implement this policy. This policy relies on results from an initial DBMS tuning performed with VM running as the stand alone virtual machine so that there is no competition for resources with other virtual machines running on top of hypervisor . Any technically feasible method for DBMS tuning on a host computer system may be carried out to obtain the initial memory pool sizes. From each of the initial memory pools sizes a ratio reflecting the memory pool size to the total amount of host physical memory available to VM in the absence other VMs competing for host physical memory. The computed ratios represent the target ratios for the memory pools while DBMS is executing. During execution balloon controller periodically e.g. as regular intervals re computes the actual ratios using the current pool memory sizes and the total amount of host physical memory available to VM at the time of recomputation Any deviations from the target ratios trigger resizing of the affected memory pools via memory pool specific allocation and eviction operations.

At step balloon controller determines the host physical memory currently available to VM by for example querying resource scheduler as previously discussed. At step balloon controller computes the ratios for each of the memory pools based on its current size and the host physical memory available to VM determined in step . At step balloon controller determines if the computed ratio of any memory pool is greater than the target ratio for that memory pool. If yes the method proceeds to step where balloon controller issues an eviction request to the memory pool whose computed ratio is greater than its target ratio requesting that the memory pool evict an appropriate amount of memory pages so that the computed ratio matches or more closely matches the target ratio and then to step . If no step is carried out. At step balloon controller determines if the computed runtime ratio of any memory pool is less than the target ratio for that memory pool. If yes the method proceeds to step where balloon controller issues a allocation request to the memory pool whose computed runtime ratio is less than its target ratio requesting that the memory pool allocate for itself more memory pages so that the computed ration matches or more closes matches the target ratio. The method then ends. If no the method skips step directly to the end. At step balloon controller releases to guest OS the memory pages evicted by the memory pools pursuant to any eviction requests. As described above in one embodiment where guest OS is Linux this is accomplished by madvise MADV REMOVE which frees a range of guest memory pages and associated backing store. It should be recognized that the method of may further be used by balloon controller in the context namely steps to determine which memory pools and how many memory pages in such memory pools should be requested to proportionally evict memory pages to assist with inflate commands originating from resource scheduler or conversely proportionally re allocate memory pages to memory pools to take advantage of a deflate command originating from resource scheduler . The method ends after step .

When the balloon target changes at a fast rate maintaining the requested eviction rate may be challenging for balloon controller if a substantial number of pages are dirty. For example when memory pools are backed by conventional hard disk storage the rate of eviction of dirty pages is limited by the storage I O bandwidth. Rotating disks are especially unforgiving for random accesses and online transaction processing OLTP loads generally result in buffer pool populated in random order. Several possible optimizations to the techniques described above may be applied.

In one embodiment if changes to the eviction order are tolerable the eviction policy might be adjusted in favor of evicting clean memory pages over dirty ones. Since evicting clean memory pages does not require writes to the backing store this increases the speed of memory page eviction.

In another embodiment the policy of the preferential clean memory page eviction may be modified such that only a fraction of all clean memory pages are evicted preferentially with the rest of the balloon target satisfied from dirty memory pages to limit the damage to the DBMS working set.

In some embodiments it may be possible for DBMS to identify a sufficient number of eviction candidates before writing any dirty memory pages to the backing store. If it is possible the dirty memory pages to be evicted are sorted by their position on disk disk block numbers and the writes are performed according to the sorted order and merged where possible.

In a further embodiment to avoid a sharp drop in transaction throughput balloon controller may employ a technique of writing out dirty memory pages in bulk to temporary files in a sequential fashion while maintaining indexing data structures pointing to their temporary locations. These memory pages can then be lazily paged in from the temporary locations over a longer time period.

The method illustrated in is carried out by balloon controller to adjust the balloon size with respect to the balloon target received from resource scheduler to account for situations where the guest swap rate increases above a certain threshold which may be tuned according to the expected workload of DBMS . In one implementation the threshold for the guest swap rate is 10 pages second.

Balloon controller periodically checks the guest swap rate computed by swap monitor e.g. once per second steps and . If it determines at step that the guest swap rate exceeds the threshold balloon controller enters a swap inflate state and increases the balloon size with respect to the balloon target i.e. the current balloon target that it previously obtained via API or from balloon driver at step . In one embodiment the rate of increase is made proportional to the guest swap rate. In one embodiment the rate of increasing the size of memory space available to the database application is an exponentially increasing rate. After this increase the flow returns to step where balloon controller waits another second before checking the guest swap rate again.

If at step balloon controller determines that the guest swap rate does not exceed the threshold it enters a swap balance state and proceeds to step . During the swap balance state balloon controller periodically checks the guest swap rate computed by swap monitor e.g. once per second steps and . If it determines at step that the guest swap rate exceeds the threshold balloon controller enters the swap inflate state once again and increases the balloon size above the balloon target at step . On the other hand if it determines at step that the guest swap rate does not exceed the threshold step is executed where balloon controller checks e.g. via API to see if the balloon target has been increased. If the balloon target has been increased the flow returns to step of . If the balloon target has not been increased balloon controller checks a timer to see if it has spent a minimum required amount of time in the swap balance state. In one embodiment the minimum required amount of time is set in the timer as 10 seconds and the timer counts down. The swap balance state is implemented to reduce oscillations between the swap inflate state and a swap deflate which is described below. When the timer expires as determined at step balloon controller enters the swap deflate state. If the timer has not expired the flow returns to step .

While in the swap deflate state balloon controller continuously decreases the balloon size at step until it determines that one of the conditions judged at steps and is satisfied. At step balloon controller judges whether or not guest swap rate exceeds the threshold. If the guest swap rate exceeds the threshold balloon controller enters the swap inflate state once again and increases the balloon size at step . If the guest swap rate does not exceed the threshold balloon controller executes the decision block at step where it checks e.g. via API to see if the balloon target has been increased or if the balloon size is equal to the balloon target i.e. the balloon has been deflated to the current balloon target that it previously obtained via API or from balloon driver via step . If either of these conditions is satisfied the flow returns to step of . If not balloon controller continues to decrease the balloon size at step .

The technique described above in conjunction with can be extended in several ways. First the technique can be applied during normal operation in the absence of memory over commit e.g. balloon target is at zero . The occurrence of guest swap in such situations suggest that the guest may have been configured with less memory than required by the workloads running therein or that the DBMS load profile and or query composition have changed over time. Second the technique can be applied to a DBMS executing natively on hardware. This configuration is described below in conjunction with . Third it should be recognized that the technique can be applied in the embedded database cases where the same VM is shared between DBMS and other workloads. Load spikes in the other workloads might trigger guest swap even in the absence of host memory over commit. Since the database is normally tuned in isolation without adjustments for load changes in other processes external workload spikes might lead to guest swap. Fourth the technique may be adapted to cause balloon controller to eliminate guest swap but let the rest of the balloon target be drawn from guest kernel data structures and other user level processes while still maintaining swap free operation. Fifth instead of waiting for guest swap in activity the technique may be guided by scanning rates of various guest kernel caches and use these scan rates as inputs in lieu of guest swap in rates.

The benefits of the techniques described above in conjunction with and have been observed in a VM configured with 8 GB of RAM and a database buffer pool configured at 5.5 GB. In the experiment reflected in the VM memory limit was lowered from 8 GB to 4 GB after 5 minutes 300 seconds of execution. After a transitional period the number of transactions executed in a VM that employs the inventive technique was observed to be about three times greater than the number of transactions executed in a VM that does not employ the inventive technique.

In the embodiments described above balloon controller is implemented as a module within DBMS . It should be recognized that in other embodiments balloon controller may be a standalone process dedicated to managing the memory pools of DBMS . In another embodiment balloon controller may reside in hypervisor so that balloon controller may be shared among two or more DBMS running in the same virtual machine or different virtual machines. Such sharing of balloon controller permits the different instances of DBMS to reclaim memory on behalf of hypervisor but in a DBMS specific fashion.

Furthermore in alternative embodiments of the present invention guest memory freed by DBMS may be released directly by a user level thread or process running in DBMS without calling into a kernel driver of guest OS . This can be achieved for example by extending hypervisor with a hyper call a special existing instruction or any trapping instruction which the user level thread or process running in DBMS can execute to trap into hypervisor and release memory directly.

The various embodiments described herein may employ various computer implemented operations involving data stored in computer systems. For example these operations may require physical manipulation of physical quantities usually though not necessarily these quantities may take the form of electrical or magnetic signals where they representations of them are capable of being stored transferred combined compared or otherwise manipulated. Further such manipulations are often referred to in terms such as producing identifying determining or comparing. Any operations described herein that form part of one or more embodiments of the invention may be useful machine operations. In addition one or more embodiments of the invention also relate to a device or an apparatus for performing these operations. The apparatus may be specially constructed for specific required purposes or it may be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines may be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The various embodiments described herein may be practiced with other computer system configurations including hand held devices microprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like.

One or more embodiments of the present invention may be implemented as one or more computer programs or as one or more computer program modules embodied in one or more computer readable media. The term computer readable medium refers to any data storage device that can store data which can thereafter be input to a computer system computer readable media may be based on any existing or subsequently developed technology for embodying computer programs in a manner that enables them to be read by a computer. Examples of a computer readable medium include a hard drive network attached storage NAS read only memory random access memory e.g. a flash memory device a CD Compact Discs CD ROM a CD R or a CD RW a DVD Digital Versatile Disc a magnetic tape and other optical and non optical data storage devices. The computer readable medium can also be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.

Although one or more embodiments of the present invention have been described in some detail for clarity of understanding it will be apparent that certain changes and modifications may be made within the scope of the claims. Accordingly the described embodiments are to be considered as illustrative and not restrictive and the scope of the claims is not to be limited to details given herein but may be modified within the scope and equivalents of the claims. In the claims elements and or steps do not imply any particular order of operation unless explicitly stated in the claims.

Plural instances may be provided for components operations or structures described herein as a single instance. Finally boundaries between various components operations and data stores are somewhat arbitrary and particular operations are illustrated in the context of specific illustrative configurations. Other allocations of functionality are envisioned and may fall within the scope of the invention s . In general structures and functionality presented as separate components in exemplary configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements may fall within the scope of the appended claims s .

