---

title: Digital makeup
abstract: A system for processing an image of a human face, the system including a data processing and analyzing utility including a high-pass filtering module outputting a high-pass signal indicative of edges or contours of the face in the input image data; at least one band-pass filtering module outputting a bandpass signal indicative of low-contrast slowly-varying qualitative features of the face; a low-pass filtering module outputting a low-pass signal in which low-contrast regions are smoothed and high-contrast regions are preserved; a feature computation module calculating a localized feature of the image for a plurality of pixels of the image; a strength computation module determining a localized operand using the localized feature to determine a strength of filters to be used in the high-pass, band-pass, and low-pass filtering modules at the pixels, and transmitting the localized operand to the filtering modules; at least one transformation module altering a portion of the high-pass, the bandpass, or the low-pass signals; and an addition module adding the various signals together, thus yielding an output signal indicative of a characteristic of an altered image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09495582&OS=09495582&RS=09495582
owner: DIGITAL MAKEUP LTD.
number: 09495582
owner_city: Tel Aviv
owner_country: IL
publication_date: 20121204
---
The present invention is in the field of image processing and more particularly in the field of processing images of human faces.

Many techniques have been developed for altering an image of a human face in order to improve the face s appearance.

In U.S. Pat. No. 8 107 672 a makeup simulation system is disclosed. The simulation system applies makeup to a video having an image of the face of a user captured thereon and is characterized by image capturing means for capturing the image of the face of the user and outputting the video control means for receiving the video output from the image capturing means performing image processing on the video and outputting the video and display means for displaying the video output from the control means wherein the control means includes face recognition means for recognizing the face of the user from the video based on predetermined tracking points and makeup processing means for applying a predetermined makeup on the face of the user included in the video based on the tracking points and outputting the video to the display means.

U.S. Pat. No. 6 502 583 discloses a method which includes determining a requested face which is requested by the person who wants the photograph to be corrected or wants to be made up and creating an image of the face corrected or made up by executing image processing such as contour combining of the original face image or the face of the person based on the requested face.

There is a need in the art for a novel technique for improving an image of a face without a need to recognize specific regions of the face and without requiring extensive processing power.

The above mentioned U.S. Pat. No. 8 107 672 and U.S. Pat. No. 6 502 583 describe face recognition techniques to recognize local features tracking points of the face and process the image based on the recognized local features.

Some other known image processing techniques described in U.S. Pat. No. 5 442 462 and U.S. Pat. No. 5 799 111 utilize adaptive smoothing filters applied to the images. Adaptive one directional and two directional processing are used to extract on a pixel by pixel basis a criterion which determines a smoothing procedure suitable for the pixel signal and noise behavior. More specifically a parameter e.g. strength of the filter to be applied to a given pixel is dependent on local characteristics of the image. For example in order to determine the strength of the filter for a given pixel of the image a difference is calculated between a value of the given pixel and a value of an adjacently preceding value in the first sequence. The strength of the filter is calculated according to this difference. Because a parameter of the adaptive filter is calculated locally for each direction the techniques of U.S. Pat. No. 5 442 462 and U.S. Pat. No. 5 799 111 may involve intensive processing and their execution may be time consuming. This may make it difficult to alter the image in real time or near real time and thus might not be useful for digital makeup applications.

The perceived appearance of human facial beauty is known to comprise multiple underlying factors including the following a facial features acuity and vitality b facial skin luster clarity and tone and c facial morphology structure and alignment. Such factors are typically improved by cosmetic makeup techniques utilizing various substances e.g. colored and transparent liquids oils powders and tools e.g. brushes spunges liners air brushes etc .

In professional makeup terms a vitality is typically achieved with eye liners and lip liners e.g. often pencil and liquid liners b skin luster clarity and tone is improved by applying a foundation concealer blush and powder and c improved morphology and structure is attained by applying respective highlights and shadows in specific facial locations.

The present invention is based on the inventor s understanding of the main steps of a makeup process which Foundation Concealer Liner Morphology Blush and Powder. More specifically 

Foundation comprises a step of evening out skin texture by applying a transparent foundation substance on the entire face thereby creating a canvas namely a flat homogeneous whitish surface of the entire face area on which all subsequent steps are applied onto. This is somewhat similar to a painter starting a work of art from a flat white canvas.

Concealer comprises a step of applying locally a skin color matched concealing substance that covers local skin imperfections and irregularities such as pimples acne inflammations areas of redness or discoloration pores birthmarks blemishes freckles wrinkles creases spider veins dark circles under the eye green blue areas surrounding the lips etc. Each of these irregularities may require a different covering action such as the spreading of the concealer in directions that best blend the concealed effect with neighboring regular skin areas. For example dark circles under the eye are typically concealed by applying concealer on the general area and then spreading the material in multiple directions to the sides and downwards but not upwards onto the eyes followed by spreading the concealer in opposite directions until evening out and achieving a desired blend.

Liners accentuate contours and edges of important facial locations such as lips and eyes thereby increasing the facial vitality.

Morphology comprises a step of restructuring the face if needed by applying shading and highlighting to specific areas of the face. Dark colors shaders shade and make areas recede such as for example hollows of the cheek temples under chin and sides of nose. Light colors highlighters make things come forward for example apple of the cheek under the eye browbone and middle of the chin.

Blush comprises a step of adding color and vitality to the face either over local areas or over the entire face.

Powder comprises a step of adding a matte powder over the entire face or over specific areas of the face or head that generate increased shining that often depends on the illumination conditions and angles.

The present invention relates to a digital image processing technique for altering the image of a human face namely Digital Makeup DM . This technique is based on the inventors realization that many of the above makeup artist actions may be closely imitated by specifically designed algorithms. In accordance with the present invention the DM processing is applied to an entire image that includes a human face without specifically requiring any knowledge of location of the face in the image facial structure facial feature locations or facial skin geometries and borders. The DM processing simulates some of the above main steps of the makeup process by the following algorithms the application of a foundation is simulated by smoothing facial pixels the application of a concealer is simulated by detecting local facial variations and smoothing these variations into the surrounding skin tone the actions of a liner is simulated by extracting facial edges and contours and retaining or enhancing them the application of powder is simulated by identifying extreme highlights and further smoothing such variations using image transformations thereby imitating actions of a sponge or brush. Optionally the application of blush may be imitated by sensing image areas of slight color variations and enhancing them and or implementing a global non linear color histogram transformation operation applied to color image components thereby enhancing the image color saturation that affects mostly the facial areas.

The above is achieved in the present invention by combining different kinds of digital filters which will be defined below to construct an improved facial image representation. In the present invention the facial image data is decomposed into different component signals indicative of the face s qualitative features e.g. details and different kinds of imperfections by respective differencing between outputs of the filters where the input of a filter is either a signal indicative of the original facial image or an output of a previous filter which received the signal indicative of the original facial image as an input . The differencing results in a high pass signal at least one bandpass signal and one low pass signal. Respective transformations and or filters are applied to at least one of the component signals to increase or decrease the strength of desired facial qualitative features for example in order to achieve improved digital makeup effects such as foundation concealer liner blush and powder . Finally the transformed filtered component signals are summed together to form an output signal which can be converted into an output image. It should be noted that after the different facial qualitative features are separated into their corresponding component signals via the multiple filtering and differencing techniques of the present invention some qualitative features may be strengthened and others may be smoothed out or attenuated. For example the technique of the present invention may improve the appearance of a face by attenuating the undesirable qualitative features e.g. skin texture wrinkles puffiness acne scars blemishes and strengthening the desirable qualitative features face s details such as contours and edges . However digital makeup may be used in the same way in order to provide an output image in which the face s appearance is deteriorated e.g. aging instead of anti aging by strengthening the undesirable qualitative features and or attenuating the desirable ones.

Optionally the technique of the present invention may be further modified for improving the facial morphology. This is achieved by typically applying highlights and shadows to specific facial locations. For this a facial feature detection and or facial skin detection segmentation operation is required as such highlights and shadows are to be placed in specific positions with respect to such facial features e.g. eyes brows lips nose chin cheeks cheek bones forehead etc . Such face detection and skin segmentation is required in cases the DM process is to be applied solely and selectively to facial regions and not to any background regions. The present invention does not require such face detection and skin segmentation for its operation although it may use such segmentation for further improvements in some imaging applications.

Therefore an aspect of some embodiments of the present invention relates to a system for processing an image of a human face the system comprising a data processing and analyzing utility comprising a high pass filtering module configured for receiving an input image data indicative of a characteristic of the image and outputting a high pass signal indicative of at least one of edges and contours of the face in the input image data at least one band pass filtering module configured for receiving data indicative of the input image data and outputting a bandpass signal indicative of low contrast slowly varying qualitative features of the face a low pass filtering module configured for receiving data indicative of the input image data and outputting a low pass signal in which low contrast regions are smoothed and high contrast regions are preserved a feature computation module configured for receiving the input image data and calculating a localized feature of the image for a plurality of pixels of the image a strength computation module configured for receiving said localized feature from the feature computation module using the localized feature for determining a localized operand to determine a strength of filters to be used in each of the high pass filtering module band pass filtering module low pass filtering module at said plurality of the pixels and transmitting the localized operand to each of said filtering modules at least one transformation module configured for receiving and altering at least a portion of at least one of the high pass signal the bandpass signal and the low pass signal and an addition module configured for receiving the high pass signal the bandpass signal and the low pass signal after said at least portion thereof has been altered and for adding the received signals together thus yielding an output signal indicative of a characteristic of an altered image.

In a variant the high pass filtering module comprises a first filtering utility configured for receiving the input image data applying a first smoothing filter thereto and outputting a first smoothed signal and a first subtracting utility for subtracting the first smoothed signal from the input image data thus yielding the high pass signal.

Optionally the at least one bandpass filtering device comprises a second filtering utility configured for receiving the input image data applying a second smoothing filter thereto and outputting a second smoothed signal and a second subtracting utility for subtracting the second smoothed signal from the first smoothed signal thus yielding the at least one bandpass signal.

Optionally the low pass filtering module comprises the second filtering utility the second smoothed signal being the low pass signal.

In another variant the at least one bandpass filtering module comprises a second filtering utility configured for receiving the first smoothed signal applying a second smoothing filter to the first smoothed signal and outputting a second smoothed signal and a second subtracting utility for subtracting the second smoothed signal from the first smoothed signal thus yielding the at least one bandpass signal.

Optionally the low pass filtering module comprises the second filtering unit the second smoothed signal being the low pass signal.

In a variant the strength computation module is configured for determining the localized operand to determine a strength of the smoothing filters at the plurality of the pixels and transmitting the localized operand to the filtering utilities.

In another variant at least one of the filtering utilities is configured for receiving an individual global parameter and using the global parameter and the localized operand to calculate the strength of the respective smoothing filter.

In yet another variant the strength computation module is configured for determining a plurality of localized operands each localized operand corresponding to a respective filtering utility and being indicative of the strength of the respective smoothing filter and each filtering utility is configured for using the respective localized operand for determining the strength of the respective smoothing filter.

In a further variant at least one of the filtering utilities is configured for applying a multi dimensional adaptive smoothing filter to a respective received signal.

In yet another variant at least one of the filtering utilities is configured for applying a linear smoothing filter to a respective received signal. Optionally the first filtering utility is configured for applying the linear smoothing filter.

According to some embodiments of the present invention the above defined system comprises an array of the bandpass filtering modules wherein each bandpass filtering module comprises a respective filtering utility configured for receiving said data indicative of the input image data and applying a respective smoothing filter thereto and outputting a respective smoothed signal and a respective subtracting utility for subtracting the respective smoothed signal from a previously smoothed signal output by a preceding filtering utility comprised in a preceding filtering module thus yielding a respective bandpass signal.

Optionally the low pass filtering module comprises a filtering utility being a part of a last bandpass filtering module in said array of the bandpass filtering modules to generate a last smoothed signal being the low pass signal.

According to some embodiments of the present invention there is provided a system comprising a first high pass filtering module configured for receiving an input image data indicative of a characteristic of the image and outputting a first high pass signal indicative of at least edges and or contours of the face in the image a decimating module configured for receiving the input image data and processing the received image data for reducing a size of the input image to produce a first decimated image and outputting a decimated signal indicative of the first decimated image a filtering system as described above configured for receiving and processing the first decimated signal and outputting a first output signal indicative of a first output image an interpolation module configured for receiving the first output signal and interpolating the first output signal to output an interpolated signal indicative of an image having a size equal to the size of the input image and a first addition module configured for receiving the interpolated signal and the first output signal and adding the interpolated signal and the first output signal together thus yielding a second output signal indicative of a characteristic of an altered image.

Optionally the system comprises a first transformation module configured for altering at least a portion of the first high pass signal to output a first transformed signal the first addition module being configured for receiving the interpolated signal and the first transformed signal and adding them together thus yielding a second output signal indicative of a characteristic of an altered image

In a variant the first high pass filtering module comprises a second interpolation module configured for receiving the decimated signal and interpolating the decimated signal to output a second interpolated signal the first high pass filtering module being configured for receiving the input image data and the second interpolated signal and a first subtracting unit configured for subtracting the second interpolated signal from the input image data thus yielding the first high pass signal.

In another variant the system comprises a second decimating module configured for performing a second decimation on the first decimated signal to output a second decimated signal which is received and processed by said filtering system to output the first output signal.

Another aspect of some embodiments of the present invention relates to a method for processing an input signal indicative of a characteristic of an image of a human face the method being implemented by a data processing and analyzing utility and comprising 

 i processing input image data to calculate a localized feature of the image for a plurality of pixels of the image 

 iii applying a high pass filter at least one bandpass filter and a low pass filter to data indicative of the input image data thus generating a high pass component signal at least one bandpass component signal and a low pass component signal such that a strength of each filter is dependent on the localized operand 

 iv applying at least one transformation to at least one of the high pass component signal bandpass component signal and low pass component signal for altering at least a portion of at least one of the component signals 

 v adding the component signals after at least one of them component has been altered thus yielding an output signal indicative of a characteristic of an altered image.

According to some embodiments of the present invention there is provided a method for processing an input signal indicative of indicative of a characteristic of an image of a human face the method comprising 

applying a first high pass filter to input image data to generate a first high pass signal indicative of at least edges and or contours of the face in the image 

decimating the input image data to output a decimated signal indicative of an image of reduced size with respect to the input image 

interpolating the first output signal to output an interpolated signal indicative of an image having a size equal to the size of the input image 

adding the first output signal to the interpolated signal thus yielding a second output signal indicative of a characteristic of an altered image.

A further aspect of some embodiments of the present invention relates to a non transitory computer readable medium that is useful in conjunction with a computer and on which is stored a data processing and analyzing utility configured to cause the computer to respond to input image data to carry out the following 

processing input image data to calculate a localized feature of the image for a plurality of pixels of the image 

applying a high pass filter at least one bandpass filter and a low pass filter to data indicative of the input image data thus generating a high pass component signal at least one bandpass component signal and a low pass component signal such that a strength of each filter is dependent on the localized operand 

applying at least one transformation to at least one of the high pass component signal bandpass component signal and low pass component signal for altering at least a portion of at least one of the component signals 

adding the component signals after at least one of them component has been altered thus yielding an output signal indicative of a characteristic of an altered image.

In image processing a smoothing filter is a processing function which is applied to an input image data in order to produce an output image data in which the difference in a characteristic of adjacent pixels is reduced as compared to that of the input image data. Typically a parameter characterizing a smoothing filter is the strength of the filter. The stronger coarser the filter the less difference there is between the characteristics of adjacent pixels. A weaker finer filter alters the pixels of the input image in a lesser degree and accordingly the difference between the characteristics of adjacent pixels in the output image is closer to that of the input image data.

An adaptive smoothing filter is a smoothing filter that self adjusts its parameter s such as strength according to an optimization algorithm driven by a difference in a characteristic of adjacent pixels. In the present invention the characteristic of the pixels may generally be represented by an intensity of one or more light components e.g. one or more colors of the pixel. For example an adaptive smoothing filter may adjust its strength according to a difference between the intensities of two adjacent pixels.

A bandpass filter is a filter which attenuates signals having a characteristic outside a desired band while signals having the characteristic within the desired band are substantially unchanged. In the above mentioned U.S. Pat. No. 5 442 462 and U.S. Pat. No. 5 799 111 it is shown that a difference between smoothing filters of different strengths is a bandpass filter. In another known technique described in US Patent Application 2010 0158330 it is shown that a bandpass filter can be determined as a difference between adaptive smoothing filters applied on the same input or as a difference between a first adaptive smoothing filter applied on the input and a second adaptive smoothing filter applied on the output of the first smoothing filter. For the purpose of this invention the characteristic may be value or luminance.

A finite impulse response filter FIR is a filter that uses one or more characteristics of the input signal in order to produce an output. An infinite impulse response filter IIR is a filter that uses one or more characteristics of the input signal as well as one or more characteristics of a signal which is the output of a filtering of the input signal through the same filter.

An adaptive IIR filter may be defined as a directional adaptive filter. This means that in order to alter a given pixel having a certain coordinate r c a difference in the pixel characteristic is calculated between the given pixel and a previously filtered pixel. The process is repeated again for the next pixel which lies on a line defined by the first and second pixel. An illustration of one directional adaptive filters ODAFs can be seen in . For example a top to bottom adaptive filter TTBAF uses the difference between the characteristic of the input pixel I r c and the characteristic of an output O r 1 c of the same filter at an adjacent pixel above the input pixel. In the same figure a bottom to top adaptive filter BTTAF is illustrated. The BTTAF uses the difference between the characteristic of the input pixel I r c and the characteristic of an output O r 1 c of the same filter at an adjacent pixel located below the input pixel.

A multi directional adaptive filter MDAF is a filter which alters a given pixel of an input image by considering the difference between a characteristic of the given pixel and the characteristics of a plurality of pixels adjacent to the given pixel. The multi directional adaptive filter may be implemented in many different manners. In one example the output characteristic of the given pixel may be determined according to an average of the differences between the characteristic of the input pixel and the characteristics of the surrounding filtered pixels.

In another non limiting example illustrated in an IIR MDAF is illustrated. In order to calculate an output characteristic of a pixel r c having a given input characteristic I r c an intermediate characteristic of the given pixel denoted as P r c is calculated by weighting the three ODAFs from a previously processed row ODAF1 ODAF2 ODAF3 eq. 1 1 eq. 2

ODAF1 r c is denoted by the numeral ODAF2 r c is denoted by the numeral ODAF3 r c is denoted by the numeral . A given ODAF is a function of the difference between the given pixel s input characteristic and the characteristic of an adjacent pixel which was previously filtered. ODAF function 11 eq. 3 ODAF function 1 eq. 4 ODAF function 11 eq. 5

O r 1 c 1 is the characteristic of a previously filtered pixel located at r 1 c 1 . O r 1 c is the characteristic of a previously filtered pixel located at r 1 c . O r 1 c 1 is the characteristic of a previously filtered pixel located at r 1 c 1 . Thus ODAFis a function of the difference I r c O r 1 c 1 . Optionally O r 1 c 1 TTBAF r 1 c 1 O r 1 c TTBAF r 1 c and O r 1 c 1 TTBAF r 1 c 1 .

The intermediate characteristic P r c is further filtered from the side pixels r c 1 and r c 1 in the same manner as before. Since the average direction of the filtering from the pixels at r 1 c 1 r 1 c r 1 c 1 r c 1 and r c 1 is downward the result of the filtering from five directions can be considered to be a TTBAF. TTBAF ODAF ODAF eq. 6 1 eq. 7

ODAF4 r c is denoted by the numeral ODAF5 r c is denoted by the numeral . ODAF function 1 eq. 8 ODAF function 1 eq. 9 Optionally ODAF function ODAF 1 eq. 10 ODAF function ODAF 1 eq. 11

The same preparatory filtering process is performed with one directional filters and and the result is filtered via side filters and in order to obtain a BTTAF r c .

Finally weighting the TTBAF and BTTAF achieves the output of a multi directional and multi dimensional adaptive filter MDAF MDAF TTBAF BTTAF eq. 12 1 eq. 13

It can be seen that filtering just one pixel via an MDAF requires a plurality of operations. Namely for each direction a strength of the filter is to be calculated and the filter is to be applied to the desired pixel in order to calculate the characteristic of the pixel. This process may therefore require high processing power and or may be performed slowly and might not be preferable for digital makeup application especially when real time digital makeup is to be performed.

Another kind of MDAF is an MDAF that is constructed as an FIR filter as depicted in . In the art this kind of filter is called a bilateral filter. In this non limiting example the corresponding MDAF at each pixel depends on an adaptive weighting function of neighboring pixels whereby the output OP r c of the MDAF at pixel r c is given by 

In the art there is also another known FIR bilateral filter based technique also known as smart blur technique. In the latter technique the differences between the characteristic of a given pixel and the characteristics of the neighboring pixels are thresholded and their respective weights e.g. Gaussian weights are used only for those neighboring pixels having respective differences exceeding a predefined threshold. Since not all Gaussian weights may be used in each pixel a re normalization is required to maintain the sum of said weights equaling unity.

Reference is now made to illustrating an image processing system of the present invention configured and operable for altering facial features in input image data to perform digital makeup. In the system a plurality of filters is used which operate together to decompose an input data representative of an input image into a plurality of output signals and the output signals are transformed and added to produce together a final output data output image where the filters are configured such that their strengths are dependent on a localized feature of the input image calculated on a pixel by pixel basis. The localized feature may be determined pixel by pixel or for different groups of adjacent pixels. In the latter case the group of pixels may form a shape which is oriented according to a desired structure of the image e.g. it may be oriented along an edge or contour . The group of pixels may be chosen according to the luminescence and or the chrominance of the image. The localized feature may have high resolution the same feature is common to a low number of adjacent pixels a low resolution the same feature is common to a low number of adjacent pixels or a medium resolution therebetween.

The system of is used to alter the original facial image input image data . The alterations in some examples of the present invention generally relate to improving the face in the image. However the system may be used to deteriorate the image or to alter it in other manners e.g. aging simulating facepaint or creating a cartoon like image as will be shown below in the examples.

As shown in the system is generally a computer system including inter alia such utilities as data input and output utilities and memory utility which are not specifically shown and a data processing and analyzing utility software and or hardware . The latter includes a high pass filtering module at least one band pass filtering module a low pass filtering module a feature computation module f a strength computation module FI x at least one transformation module five such modules being shown in the present not limiting example T1 T5 and an addition unit 5. The high pass filtering module is configured for receiving an input signal I x indicative of a characteristic of the original image and outputting a high pass signal indicative of at least edges and or contours of the face in the image. The band pass filtering module is configured for receiving data indicative of the input signal i.e. the input signal I x itself or any functional thereof resulting from filtering the input signal by one or more intermediate filters and outputting a bandpass signal indicative of low contrast slowly varying qualitative features of the face. The low pass filtering module is configured for receiving data indicative of the input signal i.e. the input signal I x itself or any functional thereof resulting from filtering the input signal by one or more intermediate filters and outputting a low pass signal in which low contrast regions are smoothed while high contrast regions are preserved. The feature computation module is configured for receiving the input signal I x and calculating a localized feature of the image for a plurality of pixels of the image. The strength computation module is configured for receiving the localized feature resulting from the feature computation module using the localized feature for determining a localized operand to determine a strength of the filtering modules at the plurality of the pixels and transmitting the localized operand to the filtering modules. The transformation module is configured for altering at least a portion of at least one of the following signals high pass signal at least one bandpass signal and low pass signal. The addition module is configured for receiving the high pass signal the at least one bandpass signal and the low pass signal after at least a portion of at least one of these signals has been altered by the at least one transformation module and for adding the received signals together thus yielding an output signal image data indicative of a characteristic of an altered image.

Thus system receives an input signal I x which is to be processed and which is indicative of an image including at least a part of a human face. The system operates to filter the input image data aimed at altering e.g. improving the face s image. The input signal I x is actually in the form of image data presented by a matrix of pixels and is thus indicative of a characteristic of the image at each pixel. As mentioned above the characteristic may be intensity or value.

Initially the input signal is analyzed by the feature computation module f which calculates for each pixel of the image having position defined by a row r and a column c a localized feature f r c of the image. In a non limiting example the localized feature may be a gradient of the characteristic of the image or a local maximum of local gradients. If the characteristic is the intensity then the gradient of the intensity is larger in the regions in which the contrast is higher. The localized feature f r c is then fed into the strength computation module FI x which uses the localized feature and an adaptive operand a for the filtering operation to compute a localized operand F r c which controls the strength of the smoothing on each pixel. In general the localized operand F r c is such that regions with high contrast are finely smoothed while regions in which the contrast is lower are more coarsely smoothed. As mentioned above regions of the image in which the contrast is higher are the regions of contours and edges which generally contribute to the vitality and acuity of the face s image.

The localized operand F r c is fed into the high pass filtering module one or more bandpass filtering modules and the low pass filtering module. In each filtering module the localized operand F r c is used to calculate a parameter of each of these filters that the respective filtering module will apply on the input image. The filtering modules decompose the input signal into component signals S to S . In the example of S is a high pass signal S S and S are the bandpass signals and S is the low pass signal. The signal S is a signal which retains the fine detail of the image i.e. the signal S is indicative of an image where high contrast regions are retained while other regions are attenuated. The output of each bandpass filtering module is a signal indicative of an image in which certain imperfections of the face are retained while others are smoothed out. Finally S is the low pass pedestal signal which retains the low frequency base signal of the image but where all the details are blurred.

At least one of the computed signal component S . . . S is received by a respective transformation module T1 . . . T5 . Each transformation module may alter the respective component signal via an offset bias function a gain stretching function and or a thresholding function. Optionally these functions are constant gain functions provided by predetermined operators. Alternatively these functions are dependent on the signal component and may be determined via histogram analysis mean standard deviation thresholded levels such as for example tail outlier values linear and non linear mappings etc of the signal components S . . . S . Finally the transformed component signals are added together by the addition module 5 to provide an output signal O x .

In some embodiments of the present invention the transformation module T1 acting on the high pass signal S increases the weight of the signal S relative to the other signals. In this manner the output image is characterized by higher vitality while the facial imperfections are attenuated.

Finally the low pass filter of corresponds to the last filtering utility of which is the filtering utility of the last band pass filtering module. In the non limiting examples of these figures the module Low Pass corresponds to the filtering utility Fil 4.

In the localized operand F r c is fed into filtering utilities Fil1 Fil 2 Fil 3 and Fil 4. Each filtering utility is associated with a corresponding individual global parameter k1 k2 k3 and k4 each being indicative of the strength of the smoothing filter function applied by each of the filtering utilities and modifying the localized operand F r c to determine the strength of each smoothing filter at each pixel. In other words all the filtering utilities apply coarser smoothing filters in low contrast regions and finer smoothing filters in high contrast regions because of the localized operand F r c . However the actual strengths of the different filters at a given pixel may be different from each other since for each filter the localized operand is individually modified in a different manner by the respective global parameters k1 k2 k3 and k4 .

As will be shown below the global parameters when applied to the operand F r c in each pixel are of lower complexity as compared to the local operands F r c . Thus using the global parameter to vary a local operand which is calculated once for each pixel requires less processing than calculating the local operand for each filter for each pixel. In this manner the computational process for determining the strengths of the multiple filters at each pixel is accelerated.

In some embodiments of the present invention the signal I x is received by each of the filtering utilities and filtered. In some embodiments of the present invention the filtering utilities use respective MDAFs and optionally different combinations of non adaptive finite impulse response NAFIR filters and or adaptive finite impulse response AFIR filters and or IIR MDAF depending on the type of operation or facial image effect desired to separate and process. Because the filters are calculated simultaneously this embodiment of the present invention enables parallel processing by all filtering utilities thereby enabling more effective real time implementations with minimum latency in multi processors or multi core processors. Optionally at least some of the MDAF are IIR MDAF s and the calculation of the pixel characteristic at each is performed as described above with reference to

In another non limiting example in each filtering utility the MDAF at each pixel depends on a localized feature that applies to all respective directions at that pixel. Thus it is not necessary to calculate the filtering strength of each ODAF of the MDAF for a plurality of directions. Rather the localized feature determines a single strength for all the ODAFs which form a specific MDAF at any given pixel.

In one such case the localized feature f r c is determined by identifying the local maximum of such characteristic of the image within a local region of N pixels size in the vicinity of said pixel r c e.g. the maximum in the absolute differences between the intensity at the pixel r c and the intensity of each of the surrounding pixels . In this manner the localized feature f r c is computed once for all directions of a given pixel and requires in turn fewer operations and becomes less processor intensive and thus faster.

In some embodiments of the present invention successive filtering utilities provide increasingly smoothing stronger filters. For example k1

One or more of the computed signal component S . . . S is received by a respective transformation modules T1 . . . T5. The transformation module may alter the respective component signal via an offset bias function a gain stretching function and or a thresholding function. Optionally these functions are constant gain functions provided by predetermined operators. Alternatively these functions are dependent on the signal component and may be determined via histogram analysis mean standard deviation thresholded levels such as for example tail outlier values linear and non linear mappings etc of the signal components S . . . S signals. Finally the transformed component signals are added together by the addition module 5 to provide an output signal O x .

In some embodiments of the present invention the transformation module T1 acting on the high pass signal S increases the weight of the signal S relative to the other signals. In this manner the output image is characterized by higher vitality while the facial imperfections are attenuated.

In a non limiting example of the present invention for each ODAF of the MDAFs the output signal ODAF r c can be expressed as follows ODAF 1 eq. 25 The i and j indexes denote the direction of the ODAF in the image while r c is the operand that reflects the strength of the specific filter and depends on the local abruptness or edge structure of the pixel r c .

As mentioned above in abrupt pixel change locations high contrast regions the ODAF will attempt to smooth less while in smooth image regions the ODAF will attempt to smooth more.

In a non limiting example the adaptive operand x can be expressed as follows exp eq. 26 where ranges between 02 eq. 27

F r c is the feature computed in each image pixel where a the adaptive operand input into the strength computation unit FI x is a constant value indicative of a noise level or signal level depending whether one seeks to overcome noise by adaptive smoothing or seeks to separate local signal amplitude variation components that represent clutter image texture of interest etc F r c k is a function of F r c and k and max abs 11 abs 1 abs 11 abs 1 abs 1 abs 11 abs 1 abs 11 eq. 28 over a neighborhood of eight pixels.

While in this example f r c is calculated in a window composed by nine pixels forming a square larger and or differently designed local windows may be used. A non limiting example of a window is a window oriented in various directions such as vertical horizontal and 45 degrees and 45 degrees orientations whereby gradients are summed separately for each orientation and the orientation which generates the maximum value is selected for f r c for that pixel in best estimating the edge feature.

The computed f r c value and the a value are used in determining the exponential function F r c exp f r c a . This function is typically computationally expensive and may be performed once for all possible values of f r c a which are then optionally loaded onto a lookup table LUT . Next for each of the filters in Fil1 Fil12 Fil13 Fil14 the respective F1 r c F2 r c F3 r c F4 r c and thus the respective 1 r c 2 r c 3 r c 4 r c values are determined using a preferred piecewise linear transformation that requires far less complexity than recalculating the exponential function for each pixel and each filter. For a certain 1 r c this transformation is computed as follows and similarly for the other filters as well 

Thus when k is below 1 the adaptive filter acts as a finer filter which tracks the incoming signal edges more rapidly and smoothes them less. If k is above 1 the adaptive filter functions as a coarser filter which tracks the incoming signal edges less rapidly and smoothes more. Thus for all filters and all pixels the adaptive smoothing operands 1 r c 2 r c 3 r c 4 r c are determined and used in determining the respective ODAFs and respective MDAFs ODAF1 1 1 1 eq. 33 ODAF2 2 1 2 eq. 34 ODAF3 3 1 3 eq. 35 ODAF4 4 1 4 eq. 36

In another embodiment of the present invention the localized feature F r c is designed such that at pixels with abs f r c a the r c will be higher thereby filtering less strongly thereby providing a more abrupt adaptation of the r c parameter depending on whether f r c values are well below a or above a. An example of such feature is as follows abs abs 1 abs eq. 37 eq. 38 where a and f r c are as provided above and m is a slope factor of said function within the range between 0 and a. The advantage of this function in the context of facial image improvement is that it will smooth more strongly the subtle facial imperfections while retaining more effectively the sharpness of stronger detail. For this embodiment each of the filters receives increasing a factors thus shifting the smooth transition range of the respective filter to higher values of f r c than the preceding one hence making the respective filter to smooth stronger.

In another non limiting example well known gradient operators and edge detection filters may be used to score pixels in terms of their edginess e.g. a Sobel filter which is often used in edge detection and use this measure to control x . Image segmentation techniques may also be used to segment local image regions thereby determining the transition pixels between such adjoining areas and avoiding their smoothing.

Referring now to another example of the system of the present invention is illustrated in which the filtering units are in series. In the system of the filtering modules are arranged in series. Thus except for the last filtering module the output of any filtering module is filtered by a successive filtering module. The bandpass filters and the low pass filter are implemented by applying a subsequent filter to the output of the preceding filter and thereafter differencing them. Like the example of the adaptive high pass component signal is S I x MDAF x . The adaptive bandpass surface component signals differ from those of . For example 2 MDAF MDAF MDAF eq. 39 The low pass base component signal exiting the filtering unit Fil14 is 5 MDAF MDAF MDAF MDAF 4 eq. 40

The configuration exemplified in enables pipeline processing of all MDAF filters enabling effective real time implementations with multi processors or multi core processors. This configuration however may be riddled by some latency. Nonetheless an advantage of the embodiment of lies in the fact that the k values may be selected according to need and application and need not be ordered in increasing values.

Referring now to another example of the system of the present invention is illustrated in which each filter of the filtering modules depends on a respective localized feature. The localized features F1 r c F2 r c F3 r c F4 r c are computed individually for each filter according to desired signal characteristics that are to be extracted using the respective differenced signal components S S S and S . In such cases both the F r c function as well as the factoring function F r c k may be tailored per S x signal component and are calculated outside the filtering utilities Fil1 Fil14.

It should be noted that while in the examples of four filtering utilities are present the scope of the invention is not limited to this example as well as any other number of filtering utilities and generally two or more filtering utilities may be used. Moreover the filtering utilities of the above examples applied at least one MDAF to the received signals. This might not be the case. In fact in some embodiments the filters implemented by the filtering utilities may include MDAFs and or MDAIIRs and or NAFIRs AFIRs etc depending on the type of operation or image effect desired to separate and process. For example the filter MDAFapplied by the filtering utility Fil1 may be replaced by a linear filter such as a Gaussian or a box filter such that the S signal is a linear high pass component signal.

As indicated above the elements modules utilities of the system may be implemented as hardware and or software elements of a data processing and analyzing utility running respective algorithms on a processor.

In both cases when all T transformations are unity i.e. transparent the result is O x I x . Thus the transformation of at least one of the component signals is necessary in order to alter the input image.

In order to better understand the operation of the system reference is made to which illustrate examples of the manner in which an input signal is processed by the different modules utilities of the system of the present invention. In the example of these figures a system with two smoothing filtering utilities is considered.

A general mathematical notation of the above hybrid i.e. combined filtered FIR and IIR image representation is as follows 3221211 eq. 43 where O is the output signal and T3 T2 and T1 are the gain or look up table LUT transformations applied to the low pass pedestal signal component I and the signal difference components I I and I I respectively.

By applying appropriate transformations to the component signals the output signal can be adjusted according to the user s need. In the output signal O indicative of an output image is illustrated and compared to the input signal I. It can be seen that the addition of the transformed component signals yields an output signal in which the noise is smoothed out in regions A and F the facial imperfections are smoothed out in regions C to E while the high contrast region B possibly indicative of a contour or edge of the face or of a face s feature is retained and even enhanced.

Additional smoothing filters and respective differencing operations may be applied on the output of the first filtering utility if additional skin effects need to be extracted and further processed. For example when adding another smoothing filter the notation is as follows 4332321211 eq. 44

In 1 is calculated according to equations 29 32 above. 1 r c is plotted against f r c a for a 30 and three values of k namely k 0.4 1 and 1.6. For the same value of f r c the value of 1 r c decreases as k increases. Thus the respective filter characteristic as a function of f r c becomes steeper and generally assumes higher values finer filtering more sensitive to abrupt transition contours for low values of k and becomes less steep and generally assumes lower values coarser filtering more sensitive to non abrupt smoother subtle transitions between adjoining regions for high values of k.

 2 r c is plotted against f r c a for the values of m 4 and values a 30 50 70. Note that in the 2 r c embodiment the respective filtering strengths of the filters is a function of the respective values a1 . . . a4 while in the 1 r c embodiment the respective filtering strengths of the filters is a function of the respective values k1 . . . k4 and requires the additional per pixel per filter computations related to said k piecewise transformation.

An additional advantage of 2 r c compared to 1 r c is illustrated in . It can be seen that 2 r c is higher than 1 r c at high values of f r c corresponding to high values of contrast and thus retains details in the edge and contour transition locations. On the other hand 2 r c is lower than 1 r c at lower values of f r c corresponding to smoother lower contrast and more subtle values of contrast and thus smoothes such regions more strongly.

Referring now to block diagrams illustrate some examples of a system for processing an image of a human face according to another embodiment of the invention. In the system the input image is processed along two different paths and the outputs of the two processing paths are combined to yield an output image. The first path generally includes a linear filter while the second path includes the above described system .

In the signal I x indicative of the input image is received by a decimating unit which reduces the size of the image and thus removes a portion of the data contained in the signal I x to output the decimated signal ID x indicative of a decimated image. The decimated signal is then processed in two different threads routes.

In the first thread an interpolation unit is used to increase decimated image to the input image original size by interpolation. Thus the signal DI x outputted by the interpolation unit is indicative of an interpolated image having the size of the input image. In the interpolated image the characteristic value or intensity of the pixels where the missing data was previously located is interpolated according to the characteristic of the surrounding pixels. Thus the decimation and interpolation of the input image results in a smoothed image. The interpolated signal DI x and the input signal I x are received by a subtracting module 0 where DI x is subtracted from I x to produce a difference signal Sd x . Optionally the difference signal passes through the transformation module T0 which applies a transformation thereon similar to the transformation modules described above and outputs as the transformed difference signal SdT x .

In the second thread the decimated signal ID x is processed by the system described above with reference to any one of producing a resulting signal IDE x which corresponds to the signal O x . The signal IDE x is then interpolated by a second interpolating module thus yielding the interpolated signal Rt indicative of an image having the same size as the input image. Optionally the signal Sdt x from the first thread is summed with the signal Rt from the second thread by an addition module 6 resulting in the output signal O which can be converted into an output image. Alternatively the signal Sdt x may be further processed by a filtering utility Fil0 such as a MDAIIR thereby further reducing residual noise in the detail signal component and the signal Rt is yielded. In the latter case the signal Rt is summed with the signal Rt by the addition module 6 resulting in the output signal O .

The decimation down sampling and interpolation up sampling by the decimating modules and the interpolating modules and may be bilinear or of a higher order.

In the system the first thread produces the signal SdT x or Rt which is generally indicative of the details contours edges of the face while attenuating the rest of the image. This is because the signal Sd x from which the signals SdT x and Rt derive is a difference between data indicative of the input image and data indicative of a smoothed image thus being a high pass signal. Thus the first thread is a high pass filter. In the second thread the facial information to be retouched is processed. Thus in the system detail information is processed differently from the facial information to be retouched and the output signal therefore retains the acuity that may be otherwise lost in the retouching process of the second thread.

The system may provide processing acceleration as a the intensive processing of the system is applied to a smaller image and b image resizing operations e.g. decimators and interpolators are implemented in advanced processors e.g. multi core digital signal processors DSPs in real time accelerated e.g. dedicated hardware configurations thereby enabling more complex operations to be handled by software based DSP cores of said processors. At the same time the details of the image are still maintained and may even be accentuated via the transformation module T0 thanks to the processing along the first thread.

The signal component Sd x that contains image detail may also be extracted effectively in another embodiment using a simple high pass NAFIR filter module as provided in without decimating and interpolating in the first thread. Yet another embodiment of the present invention is exemplified in wherein a simple low pass NAFIR filter module is used for both a generating the high pass detail filter by the differencing operation in the first thread and b for achieving said decimation operation by an additional sub sampling unit in the second thread.

Referring now to a block diagram illustrates yet another example of the configuration and operation of the system in which the input image undergoes two decimations. The system of is configured similar to that of the example of . In fact the first thread of is the same as the first thread of in which the image signal is decimated by a factor M and is then interpolated by the same factor M. However the second thread of the system in the example of includes an additional decimating module which further decimates the signal ID x by a factor N to produce the decimated signal IDD x . The signal IDD x is processed by the thread path including the above described system to produce the signal IDDE x and an second interpolation module which interpolates the signal IDDE by a factor M N to produce the signal Rt which is to be summed to SdT x or Rt to yield O .

An advantage of this example of is in that the decimation factors M and N may be determined according to the specific application or situation. The M factor determines the detail e.g. edge and contour information that is preserved and further processed in the first route. Facial image detail and acuity to be preserved is typically characterized by higher contrast and abrupt transitions i.e. narrow transition regions . This can be extracted by a small decimation interpolation DECINT factor M ranging typically between 1.1

Because facial image acuity and detail is retained in the first thread the processing strength of the second thread can be increased with reduced potential loss of image acuity as a function of the actual facial imperfections of the particular subject illumination conditions etc. The decimation factor N may typically vary between 2

Another consideration that may impact the selection of the decimation and interpolation factors or the highpass NAFIR alternative of the first route is the input image resolution as compared to the resolution of the display. Often in video transmission applications e.g. video calling video conferencing bandwidth limitations constrain the amount of compressed image data that may be transmitted in which cases the compression codecs may dynamically reduce the transmitted image resolution before reducing the video frame rates. Three image formats that are typically used in video calling applications include 640 480 pixels 320 240 pixels and 160 120 pixels. Assuming for example a display resolution at the receiving end of 1280 960 typically the received imagery is resized dynamically to fit the display screen such that the size of the displayed subject and displayed scene in such video calling applications remains constant regardless of the dynamically selected transmitted image resolution.

In any such case where an image is enlarged for display e.g. via interpolation respective image pixels are enlarged and aliasing the effect in which different signals become indistinguishable may be observed. In the embodiments of utilizing the first route detail and the second route concealing processing the retained detail signal component from the first route when enlarged for display may accentuate such aliasing effects in the vicinity of edges and contours. This effect may be amplified as the display enlargement increases. Therefore for example for a transmitted image of size 640 480 pixels and a display of size 1280 960 pixels the enlargement factor is small 2 2 and the processing may use a higher decimation and interpolation factor such as 4 referring to . This also alleviates the processing resources of the filtering system. As the transmitted image size is reduced to 320 240 pixels the enlargement factor increases 4 4 and the processing should use a lower decimation and interpolation factor such as a factor of 2 referring to thereby avoiding excessive accentuation of display aliasing and building on the reduced processing resources required for the filtering system due to the smaller image size. As the transmitted image size is further reduced to 160 120 pixels the enlargement factor increases 8 8 and the processing should use no resizing at all thereby avoiding excessive accentuation of display aliasing and building on the further reduced processing resources required for the filtering system due to the further reduced image size. Therefore in some embodiments of the present invention there is provided a logic control utility for controlling such decimation and interpolation factors as a function of transmitted image size display size and computing resources. The logic utility may be part of the decimating module or of the interpolation module or the logic utility software may be distributed between the decimating module and interpolation modules.

The embodiment in which decimation is performed in two stages using factors M and N referring to may be particularly useful in situations of high resolution imagery whereby the first route decimation and interpolation factor M is selected such that sufficient image detail is preserved while sufficient facial skin effects are retained in the second route for further processing and concealing. Because the retaining of image detail requires relatively small NAFIR filters the first route factor M can be chosen to be substantially low. On the other hand the second route includes more complex processing. Thus the factor N of the second route is selected according to available processing resources. In this manner the first route s processes are optimized separately from the second route s processes such that each route affects a different aspect of the displayed facial image namely the first route affects detail while the second route affects skin effects . This embodiment can also be implemented with two NAFIR low pass filters and a sub sampling function as in whereby a small NAFIR is used for the first route and an additional larger NAFIR is used before or after said sub sampling function in second route. Thus in some examples the system includes the logic utility as provided above for controlling such decimation and interpolation factors as a function of transmitted image size display size and computing resources.

It should be noted that the above imaging processing systems may operate in various color representations for example RGB YCbCr Lab etc. Thus the technique of the present invention can be applied to imaging systems which capture and display color video in RGB color representation and to other imaging systems which capture and display color video in YCbCr with varying color resolutions e.g. 4 2 2 4 2 0 .

In the context of DM the operation of the system of the present invention e.g. systems and as provided in the above figures is designed to imitate the way makeup artists work. Generally a makeup process comprises five main steps Foundation Concealer Liner Blush and Powder.

In DM Foundation includes evening out skin texture by applying a transparent foundation substance on the entire face thereby creating a canvas namely a flat homogeneous whitish surface of the entire face area on which all subsequent steps are applied. This is somewhat similar to a painter starting a work of art from a flat white canvas. The component signal S in any of replaces the Foundation step in DM as the signal S is indicative of an image of a smooth relatively homogeneous surface that generally retains its average color values.

In DM Concealer includes local application of a skin color matched concealing substance that covers local skin imperfections and irregularities such as pimples acne inflammations areas of redness or discoloration pores birthmarks blemishes freckles wrinkles creases spider veins dark circles under the eye green blue areas surrounding the lips etc. Each of these irregularities may require a different covering action such as the spreading of the concealer in directions that best blend the concealed effect with neighboring regular skin areas. For example dark circles under the eye are typically concealed by applying concealer on the general area and then spreading the material in multiple directions to the sides and downwards but not upwards onto the eyes followed by spreading the concealer in opposite directions until evening out and achieving a desired blend. The transformation of the signal components S . . . S in replaces the Concealer elements application in DM as different regions in the image may be applied with different concealers.

In DM Liner includes accentuating contours and edges of such facial features as lips and eyes thereby increasing the facial vitality. A liner seeks facial edges and contours and further enhances them. According to the present invention such edges and contours are retained and further accentuated by signal component S in and the first route in 

In DM Blush includes adding color and vitality to the face either over local areas or over the entire face or the entire image. Locally adding blush is achieved by sensing image areas of slight color variations and enhancing them and or implementing a global non linear color histogram transformation operation applied to color image components thereby enhancing the image color saturation that affects mostly the facial areas. For example in an embodiments of with three filtering utilities implementing MDAFs the S and or S component signals may represent respective colors differences of the input image e.g. Cb and Cr being the blue difference and red difference components respectively in a YCbCr color space . The transforming modules T2 and or T3 amplify the specific color components in the respective signals according to the desired effect to be achieved on the output image. The transformations may be dependent on the Luminance Y and chrominance of the S and or S image components. For example the filtering utilities may operate to decrease luminance and increase chrominance thus adding color to the input facial image.

In DM Powder application step includes adding a matte powder over the entire face or over specific areas of the face or head that generate increased shining that often depends on the illumination conditions and angles. The embodiments of may provide a shining area detection for example with three filtering utilities implementing MDAFs where the S signal representing the luminance component e.g. Y in a YCbCr color space would be thresholded by undergoing transformation by module T3. The luminance pedestal component S is thresholded at its saturation level by transformation module T4 and the thresholded regions of the signal S are correlated with the thresholded regions of S . The regions in which saturation occurs in the thresholded S signal and the saturation threshold is exceeded in the signal S are designated as highlighted regions and their highlighting may be reduced by attenuation via the transformation module T3 and or the transformation module T4.

In DM Morphology includes restructuring the face if needed by applying shading and highlighting to specific areas of the face. Dark colors shaders shade and make areas recede such as for example hollows of the cheek temples under chin and sides of nose. Light colors highlighters make things come forward for example apple of the cheek under the eye browbone and middle of the chin. Improved facial morphology and construction using makeup is achieved by typically applying highlights and shadows to specific facial locations. For this a facial feature detection and or facial skin detection segmentation operation is required as such highlights and shadows are to be placed in specific positions with respect to such facial features e.g. eyes brows lips nose chin cheeks cheek bones forehead etc . Such face detection and skin segmentation is required in cases the DM process is to be applied solely to facial regions and not to any background regions. The present invention does not require such face detection and skin segmentation for its operation although it may use such segmentation for further improvements in some imaging cases.

The facial skin segmentation into component signals provided above may also be used in conjunction with various facial image detection and tracking in imagery as well as facial morphology analysis for improved shading and highlighting facial skin tone analysis and respective image display optimization based on such analysis.

Reference is made to which depict specific regions of the face and head that often need shading and highlighting. illustrates specific placement of such shading and highlighting by a professional makeup artist which then blends the substance with surrounding skin. The result of blending in digital makeup according to the present invention is illustrated in . According to some embodiments of the present invention automated face and head analysis is performed in order to determine the regions which need shading and highlighting for improved morphology and facial structuring and the DM techniques described above are performed for each specific region separately. The application of the DM techniques described above will thus depend on whether the region is to be shaded or highlighted.

Referring to there are provided examples of the present invention in which the DM processing described above is performed via video compression utilizing various codecs and video transmission utilizing various networks and platforms such as desktop and mobile video calling applications over the internet Wi Fi and cellular networks Video codecs e.g. H264 VP8 MPEG2 MPEG4 used in video communications are often equipped with pre processors for noise reduction and post processors for compression artifact removal.

In the block diagrams illustrate such pre and post processors in conjunction with encoders and decoders. A more specific video calling configuration is illustrated in

For example in video calling and video conferencing the DM technique as described above in may be utilized as a pre processor for facial image retouching after which the imagery is compressed and transmitted. In high bandwidth applications image detail and motion generally underlie the quality of the displayed image on the receiving side while in low bandwidth applications image detail is often lost and displayed image quality is dominated by the compression artifacts e.g. quantization noise block noise mosquito noise .

In a communication system is exemplified in which a standard encoder decoder with a pre processing and or and post processing implementation is provided. A sending device includes a camera for capturing a facial image on line mode or a storage device in which the image data previously captured by camera is stored off line mode a pre processor for reducing noise in the image and an encoder for encoding the image for transmission. A receiving device includes a decoder to decode the incoming transmission and a post processor for reducing noise in the image before the image is displayed on a screen. According to some embodiments of the present invention facial imperfection reduction and image improvement may be implemented in the pre processor on the sending device or in the post processor on the receiving device or the modules and utilities of the system of the present invention are distributed between the pre processor and the post processor.

In the pre processing and encoding functions are performed by an enhanced encoder on the sending device . The DM processing may be implemented by the enhanced encoder on the sending device whereby the post processor on the receiving device assesses decoded image quality and noise artifacts and transmits back to the enhanced encoder what level of pre processing it should apply to achieve improved image quality in a specific transmission circumstance of available bandwidth data loss e.g. packets etc. Optionally such decoded image quality criteria can be additionally applied by said post processor on the receiving device .

In the DM process replaces the existing deblocking filter in the motion compensation loop of H.264 encoding and decoding processes. Such motion compensation loop is inherent to the widely used video compression standards whereby current deblocking filter in H.264 codec is a processing feature implemented in both the encoding and decoding motion compensation loops. If the DM process is used instead in such motion compensation loops then such encoder and decoder are considered part of the system of the present invention. The main advantage in using the DM in this manner is an improvement of the reduction of blocking noise and compression artifacts and therefore improvement of the compression capability of the codec due to reduction in signal redundancy.

The existing deblocking filters can modify between 1 3 samples on either side of a given block edge. In the current invention the DM process may be used in a similar manner only its effect is significantly stronger as its MDAF implementations affect many more pixels in the vicinity of block artifacted edges. This is due to the fact that the DM MDAF approach provides for recursively processing the image data thereby achieving an extensive size of equivalent spatial integration of pixels.

Moreover when a video stream is encoded a deblocking filter strength may require adaptation to a computed image error due to quantization step size and or motion compensation errors. Pixel based dynamic control of deblocking is easily achieved by the DM.

In the system of a DM processing may be performed by the pre processor for adaptive facial alteration and also by the post processor for compression artifact reduction. Because the DM process reduces facial signal variability the data included in a facial image output by the digital makeup technique of the present invention is decreased as it is more highly correlated spatially and a 5 10 bandwidth reduction may be achieved. This actual bandwidth saving may also depend on the size of the head face relative to the image size. A more significant bandwidth saving of 10 100 may be achieved when transmitting a downscaled image after applying DM thereby avoiding the display of excessive facial artifacts when upscaling back for display at the receiver end. The result is a displayed facial image that is more pleasing and becoming to the user yet requiring significantly less bandwidth.

Referring now to there are illustrated detailed implementations of the DM processing in known hardware software packages.

The DM process can also be applied to digital TV broadcast and filming applications in studio settings e.g. talk shows interviews news casting . The DM may be implemented into the studio TV cameras or as an external standalone post processor. The DM process may also be implemented in firmware of camcorders webcams codecs and displays.

In a similar manner as applied to video streams the DM process may also be applied to still photographs either before the image compression stage e.g. JPEG or after its decoding and before display or printing. The DM process in this invention may be applied to the entire image or alternatively more selectively in face or skin regions of the image similarly to the approach taken for the DM morphology function above.

It should be understood that the system of the present invention i.e. its data processing and analyzing utility utilizing the above described filtering modules may actually be embedded in any electronic device having an imager camera or any electronic device capable of receiving image data from an external imager. Also the data processing and analyzing utility of the present invention may be implemented as a pure software product which may be downloaded into an electronic device such as a phone device tablet PC etc. e.g. via a network such as the Internet in the form of an API.

In an embodiment of this invention image regions that contain faces and skin may be manually designated. This is preferably achieved by a single localized single tap one touch on a touch screen such as those used in smart phones and tablets. A continuous localized touch may activate a localized face or skin segmentation that can present to the user the intermediate segmentation result such that the user stops the continuous touch once the process seems to have segmented the desired face skin region after which the DM process is applied. Alternatively the DM process can be applied in batch mode on multiple images. The DM may also be used in conjunction with automatic gain control AGC and dynamic rage compression DRC of cameras.

Various embodiments and aspects of the present invention as delineated hereinabove and as claimed in the claims section below find experimental support in the following examples.

Reference is now made to the following examples which together with the above descriptions illustrate some embodiments of the invention in a non limiting fashion.

It is therefore indicated that by using MDAF filters different facial imperfections and facial effects can be extracted in the bandpass signals. Thus using the respective T1 T8 transformations each different imperfection can be dealt separately in a suitable manner. At the same time applying a Gaussian filter produces a high pass component image in which the face s contours and edges are well preserved. Thus it is advantageous to combine a Gaussian filter with a series of MDAF filters in order to process the skin imperfections while keeping the face s edges and contours. As explained above one manner of implementing this hybrid filtering process the filtering unit Fil1 of may apply a linear Gaussian filter while the other filtering units may apply MDAFs. Another solution for separately processing skin effects and facial details may performed by the system of in which the input signal goes through two different paths. The first path includes a linear filter and produces a high pass signal in which the details of the face are preserved. The second path may include a plurality of MDAF s in series or in parallel which processes the skin effects.

Referring now to there is illustrated a foundation effect achieved by the of the technique present invention. depicts an input image in which the forehead skin is textured. illustrates an output image yielded by any one of the systems or of . The texture in the output image is refined smoothed out while edges are preserved and no discontinuities are perceived between such adjacent regions.

Referring now to there is illustrated a wrinkle reducing effect achieved by the technique of the present invention. By processing the input image via the DM technique of the present invention an output image is achieved in which wrinkles are reduced while edges are preserved and no discontinuities are perceived between such adjacent regions.

Referring now to an example of acne concealing using the DM processing technique of the present invention is illustrated. is the input image in which a subject with an acute case of acne is shown. is a photograph of the same subject after a clinical medication based treatment. is an output image given the input image of yielded by the DM processing technique of the present invention. In the present example respective S signals of the Cr color image component are thresholded by a low threshold and a higher threshold and whereby pixels exceeding the higher threshold are filtered by a higher k value while pixels exceeding a lower threshold are a lower value of k resulting in pixels that have a higher probability of having acne or skin irregularities being filtered more strongly relating to the embodiment described in . A feathering operation may be used to refine the transition areas between such adjoining regions.

Referring now to there is illustrated an implementation of the technique of the present invention in which an input image of a face is processed to increase the skin s imperfections e.g. wrinkles in order to yield an output image in which the face appears to have aged.

This processing is performed by selecting one or more transformations which highlight the skin s imperfections rather than attenuating the skin s imperfections.

The following figures illustrate a comparison between the technique of the present invention and different noise attenuation techniques in the art.

In these figures i is input image p is the processed image C is the contrast 1 represents the upper surface near boundary 2 represents the lower surface near boundary stands for mean is the standard deviation and RSS represents the root sum of squares.

A measure of the image s cleanliness is the Contrast to Noise Ratio CNR which is calculated for the input and processed images as follows CNR C RSS 12 eq. 45 CNR C RSS 12 eq. 46

CNR Improvement Ratio CNRIR measures the image improvement noise attenuation between the processed image and the input images. CNRIR CNR CNR CNR eq. 47

Referring now to there is shown a comparison between the speckled noise of an input image and the speckled noise of images output by different processings of the input image. Generally speckled noise texture represents facial skin imperfections e.g. large pores wrinkles acne etc . In the noise standard deviation is 2.86. In the image processed by bilateral filtering results in a noise standard deviation of 1.16. In the image processed by the DM technique of the present invention results in a noise standard deviation of 0.73. Thus the speckled noise texture is better removed by the DM technique of the present invention compared to the bilateral filter both in reduced 60 and in less perceived speckled morphology of the residual noise texture while retaining image sharpness at transition regions.

Referring now to there are illustrated implementations of the technique of the present invention on various platforms common in today s market.

