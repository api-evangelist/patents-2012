---

title: Electronic charge sharing CMOS-memristor neural circuit
abstract: CMOS-memristor circuit is constructed to behave as a trainable artificial synapse for neuromorphic hardware systems. The invention relies on the memristance of a memristor at the input side of the device to act as a reconfigurable weight that is adjusted to realize a desired function. The invention relies on charge sharing at the output to enable the summation of signals from multiple synapses at the input node of a neuron circuit, implemented using a CMOS amplifier circuit. The combination of several memristive synapses and a neuron circuit constitute a neuromorphic circuit capable of learning and implementing a multitude of possible functionalities.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08832009&OS=08832009&RS=08832009
owner: The United States of America as represented by the Secretary of the Air Force
number: 08832009
owner_city: Washington
owner_country: US
publication_date: 20120515
---
The invention described herein may be manufactured and used by or for the Government for governmental purposes without the payment of any royalty thereon.

The memristor or memory resistor was first theorized by Leon Chua at the University of California Berkeley in 1971 1 . Only theoretical for more than 30 years researchers at Hewlett Packard recently announced the discovery of memristors fabricated in their lab 2 3 . In terms of its behavior a memristor is a device whose resistance changes under given toggle conditions e.g. exceeding some voltage and then holds that resistance until another toggle condition is met. In this way memristors can be thought of as reconfigurable resistors with memory. However given the nature at which Chua arrived at this particular switching property relating charge q and flux linkage the memristor is a new fundamental electronic device in the same way resistors capacitors and inductors are fundamental.

Memristors are promising devices for a wide range of potential applications from digital memory logic and analog circuits and even some bio medical applications. Of particular interest for the invention described here memristors can also be applied in the development of neural networks. More specifically memristor behavior is very similar to that of the synapses found in biological neural networks.

Treating nanoscale memristors as artificial synapses it becomes feasible to construct neuromorphic circuits dense enough to realize many applications such as image and voice recognition in hardware. The present invention uses memristors as artificial synapses in conjunction with a CMOS based neuron circuit that can be used in the construction of hybrid CMOS memristor neuromorphic systems.

It is therefore an object of the present invention to provide an apparatus that behaves as a trainable neuromorphic circuit.

It is a further object of the present invention to provide an apparatus that weights and sums the outputs of a plurality of memristor based artificial synapses into the input of a neuron.

It is yet a further object of the present invention to provide an apparatus that trains a neuromorphic circuit through the application of externally supplied signals.

It is yet still an object of the present invention to detect whether the output of a neuromorphic circuit matches an expected output and to train said neuromorphic circuit to accomplish the same.

It is yet a further object of the present invention to provide a neuromorphic circuit that functions as a logic gate.

Briefly stated the present invention provides an apparatus comprising a CMOS memristor circuit which is constructed to behave as a trainable artificial synapse for neuromorphic hardware systems. The invention relies on the memristance of a memristor at the input side of the device to act as a reconfigurable weight that is adjusted to realize a desired function. The invention relies on charge sharing at the output to enable the summation of signals from multiple synapses at the input node of a neuron circuit implemented using a CMOS amplifier circuit. The combination of several memristive synapses and a neuron circuit constitute a neuromorphic circuit capable of learning and implementing a multitude of possible functionalities.

The present invention an artificial neural circuit is constructed where memristors determine the weights of synapses that feed the CMOS based neural circuit.

Referring to a CMOS memristor neural circuit a voltage divider circuit that acts as the memristive synapse. The value for the load resistance R can also be accomplished with a pass transistor must be properly chosen such that 1 the maximum voltage drop across the memristor never exceeds a toggle or threshold voltage at which the memristor M will begin changing states and 2 the output voltage swing is maximized for the maximum possible change in memristance R R where Rand Rare the maximum and minimum resistance values for the memristor respectively. In other words it is desired that the output to be very sensitive to the memristance without unintentionally changing the value of the memristance itself.

Still referring to consider a chalcogenide material based memristor where the device memristance swings roughly between 200 and 1 k and the threshold for the device to change memristance states is approximately 0.2V. For a small input voltage V the maximum drop across the memristor will not approach or exceed 0.2V so the first criterion is satisfied. This small input voltage can be guaranteed for sub threshold operation where the supply voltage V is held below the threshold voltage of the transistors. Furthermore if a sub threshold voltage is used for the supply then the load resistance R that maximizes the voltage swing can be determined by R square root over R R .

The CMOS circuitry within the overall neural circuits must perform two major tasks 1 amplify the voltage swing at voltage node V V and 2 provide an output that can be summed together with the outputs of other synapses. The synaptic circuit shown in achieves the above mentioned tasks through charge sharing.

Again referring to the summation circuit functions by allowing the pull up PMOS transistor WP to charge up the node V between the two transistors when the input is 0V. Once charged V is held high until the input goes high which also produces a voltage at V based on the memristance value and turns on the driving NMOS transistor WN . A high input voltage V will also turn off the pull up PMOS transistor WP . The charge is then allowed to pass through the driving NMOS transistor WN to increase the voltage V across the summation capacitance . When V is less than the threshold voltage of the driving NMOS transistor WN high threshold variety the transistor never turns on very strongly. Normally the two floating capacitors at each internal node will charge to a common voltage. However as V is charged it approaches the gate voltage V which causes the gate to source voltage of the driving NMOS transistor WN to quickly approach zero. If the transistors are sized properly then the driving NMOS transistor WN will turn off before charging is completed. Thus the amount of charge and the associated voltage V is weighted according to the total memristance values M at all inputs.

Still with reference to the value of the resistance R could be set to 477 The next design parameter is the voltage supply V which is set to help maximize V. For the earlier example V can be set to 250 mV for 45 nm CMOS which also forces the circuit into sub threshold operation. This leaves the sizing of the driving NMOS WN and pull up PMOS WP transistors in the synapse circuit. The size of the pull up PMOS transistor WP should be tuned to 1 react quickly to changes at the input V and 2 provide enough internal capacitance at its drain to match the summation capacitance at V and promote charge sharing. Assuming the drain capacitance of a transistor is approximately equal to the gate capacitance the transistor width sizing of WP should be equal to the total size of all input gates of the neuronal buffer or amplifier circuit .

Turning to the buffering side of the circuit it is important that the amplifier be sensitive to changes at V. Furthermore the output of buffer or amplifier circuit should be pulled strongly to either V or ground depending on the input. Several options are possible for the buffer or amplifier circuit including a chain of CMOS inverters or a CMOS operational amplifier.

The final design parameter for the synaptic circuit is the width of the driving NMOS transistor WN in .

Referring to considering the earlier example and the case where two synaptic circuits drive a common summation capacitance shows a plot of voltage V see versus the weighted sum of the inputs and for a variety of width values for the driving NMOS transistor WN. see To clarify the weighted sum is determined by multiplying the logic value at each input e.g. 1 for 250 mV and 0 for 0V by the corresponding memristance value M see . The results in were taken for a two input neural circuit i.e. two synapses driving a single buffering circuit at node V such that the weighted sum is the sum of the memristors driven by a high voltage. For example if both inputs were 250 mV logic 1 and M 1000 while M 200 then the weighted sum would be 1200 . This being the case the desired response is for V to be linear as a function of weighted sum of the inputs such that V reflects that summation. A further desire would be to have the V response centered around 125 mV or half V to help reduce the required size of the first amplification stage.

Referring to provides an example of how multiple synaptic circuits can be connected and then buffered to produce an amplified version of the weighted sum of the inputs. As can be seen in the circuit consists of n synaptic inputs all driving node V. For example considering how the inputs are weighed the total logically weighted sum would range from 0 to n 1000 if the memristance value for Rwere 1000 .

Referring to shows simulation results for three 3 input CMOS memristor neural circuits configured to implement a majority logic full adder described. Specifically the majority function Maj A B C of all three inputs A B and Cis equivalent to the carry out Cterm of a full adder. Furthermore the sum can also be determined from a majority function as Maj Maj Maj A B C such that only three 3 input CMOS memristor neural circuits are required to implement a full adder. As can be seen from the circuit as configured functions as desired.

Considering all transistors to be fabricated using 45 nm CMOS and of the high threshold variety with V see set to 250 mV the energy consumption of the circuit is very low on the order of femtojoules fj or 10joules according to SPICE simulation results utilizing the 45 nm predictive design kit FreePDK from Oklahoma State University 4 and memristor models developed at the Air Force Research Laboratory 5 6 . The delay of the circuit is around 500 us.

Referring to shows the performance of a single 3 input CMOS memristor neural circuit mapped to implement several Boolean logic functions such as OR and AND functions. In addition to showing the performance also illustrates the ability to configure the CMOS memristor neural circuit to implement a variety of logic functions. While such speeds may be on the order of what is observed for biological neurons robust and even high performance operation will require massive parallelism.

Referring to shows the delay and energy of the circuit depicted iii as a function of the weighted sum of the four synaptic inputs.

Referring to shows as an example of training an implementation of the CMOS memristor neural circuit from but with additional circuitry that can be used for learning. The learning circuit used to train the memristors is designed such that circuit behavior eventually matches a given input signal expectation V. Note that learning is made possible with two circuits the global trainer and the local trainer. The global trainer exists for each neuron such that only one global trainer is required for several memristive synapse circuits. The purpose of the global trainer is to detect whether or not the output of the circuit matches some expectation. If the circuit does not produce the expected result then the global trainer will send a signal Sel to all memristive synapses connecting to that neuron indicating training must occur. A local trainer is implemented for each synapse which takes the Selsignal from the global trainer and if both Seland the respective input voltage Vare high then a high voltage training pulse is delivered across the memristor. During training several clock cycles may be required to test the output and train the memristors to implement a particular function. So long as the memristors can be trained i.e. they re not stuck on some particular state as a result of device failure the circuit will eventually be trained to match the expected function regardless of what memristance states are actually used.

Still referring to also allows training in both directions by controlling the polarity of the voltage drop across the memristor during the training phase. As can be seen in the figure the memristor device is positioned between two voltages Vand V while training occurs. If Vis high and Vis low then the memristor is trained toward R. On the other hand if Vis low and Vis high then the drop across the memristor is negative and it is trained toward R the off state. It should also be noted that the signal Vcan be set normally to a low value and acts as the ground rail during normal operation.

Referring to and as an example of the learning process a two input neural circuit is trained to function first as a Boolean AND logic gate and then as an OR logic gate is shown. This particular simulation is an example of an exhaustive supervised training session meaning the circuit is trained repetitively with every possible input output combination until the output learns the desired expectation. As can be seen from the figure the AND gate is implemented after two training cycles while the logical OR function requires three training cycles.

Having described preferred embodiments of the invention with reference to the accompanying drawings it is to be understood that the invention is not limited to those precise embodiments and that various changes and modifications may be effected therein by one skilled in the art without departing from the scope or spirit of the invention as defined in the appended claims.

