---

title: Reputation-based in-network filtering of client event information
abstract: A policy management system is described herein which generates rules based, at least in part, on reputation information provided by at least one reputation source and client event information forwarded by filtering logic. The policy management system then deploys the rules to the filtering logic. The filtering logic, which resides in-network between clients and at least one service, uses the rules to process client event information sent by the clients to the service(s). In one illustrative environment, the service corresponds to an ad hosting service, which uses the policy management system and filtering logic to help prevent malicious client traffic from reaching the ad host service, or otherwise negatively affecting the ad hosting service.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09171151&OS=09171151&RS=09171151
owner: Microsoft Technology Licensing, LLC
number: 09171151
owner_city: Redmond
owner_country: US
publication_date: 20121116
---
Online services are subject to various threats. For example a malicious entity may orchestrate a click fraud campaign by using a collection of software agents commonly referred to as BOTs to automatically click on advertisements. In another case a malicious entity may perform a distributed denial of service DDOS attack by sending a large amount of bogus traffic to a service. In another case a malicious entity may attempt to steal information from a service by repetitively attempting to exploit vulnerabilities in the service. In another case a malicious entity may direct fake traffic to its own site for the purpose of elevating its ranking score in a search engine. These examples are cited by way of illustrative not limitation many other types of malicious activity are prevalent in today s network environments.

In some cases an administrator of a service can manually correct or ameliorate the damage caused by an attack that has already occurred once discovered. This approach however is neither efficient nor fully effective in all situations.

According to one illustrative implementation a policy management system is described herein which generates rules based at least in part on at least one of a on reputation information provided by at least one reputation source and b client event information CEI forwarded by filtering logic. The policy management system then deploys the rules to the filtering logic. The filtering logic resides anywhere between a collection of clients and one or more services with which the clients may interact for this reason the filtering logic may be regarded as an in network mechanism.

According to another illustrative aspect the filtering logic uses the rules to process CEI sent by clients to at least one service. Upon discovering an instance of CEI that matches a rule the filtering logic can take one or more prescribed actions. For instance the filtering logic can block tag and or reroute the instance of the CEI that matches a rule or simply pass the instance of the CEI to the target service without modification.

In one illustrative environment the service corresponds to an ad hosting service. In this context some clients correspond to legitimate users who are interacting with ads provided by the ad hosting service. Other clients correspond to malicious devices which are taking part in a click fraud campaign. The in network filtering logic and policy management system help prevent malicious CEI from reaching the ad hosting service or otherwise negatively affecting the ad hosting service. In other words the filtering logic and policy management system proactively address the threats posed by malicious clients rather than or in addition to relying on the ad hosting service to perform post correction to address already processed fraudulent CEI. According to another illustrative characteristic the filtering logic and policy management system may help simplify the processing performed by the ad hosting service and the network infrastructure leading to the ad hosting service.

Alternatively or in addition the policy management system can generate rules that attempt to identify CEI having other potentially non malicious characteristics. In other words in this type of environment the policy management system can generate rules which are not aimed at detecting and eliminating threats but rather serve some other policy objective or objectives.

The above approach can be manifested in various types of systems components methods computer readable storage media data structures articles of manufacture and so on.

This Summary is provided to introduce a selection of concepts in a simplified form these concepts are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

The same numbers are used throughout the disclosure and figures to reference like components and features. Series 100 numbers refer to features originally found in series 200 numbers refer to features originally found in series 300 numbers refer to features originally found in and so on.

This disclosure is organized as follows. Section A describes illustrative functionality for generating rules for deployment to in network filtering logic. Section A also describes the construction and operation of the filtering logic. Section B describes illustrative methods which explain the operation of the functionality of Section A. Section C describes illustrative computing functionality that can be used to implement any aspect of the features described in Sections A and B.

As a preliminary matter some of the figures describe concepts in the context of one or more structural components variously referred to as functionality modules features elements etc. The various components shown in the figures can be implemented in any manner by any physical and tangible mechanisms for instance by software hardware e.g. chip implemented logic functionality firmware etc. and or any combination thereof. In one case the illustrated separation of various components in the figures into distinct units may reflect the use of corresponding distinct physical and tangible components in an actual implementation. Alternatively or in addition any single component illustrated in the figures may be implemented by plural actual physical components. Alternatively or in addition the depiction of any two or more separate components in the figures may reflect different functions performed by a single actual physical component. to be described in turn provides additional details regarding one illustrative physical implementation of the functions shown in the figures.

Other figures describe the concepts in flowchart form. In this form certain operations are described as constituting distinct blocks performed in a certain order. Such implementations are illustrative and non limiting. Certain blocks described herein can be grouped together and performed in a single operation certain blocks can be broken apart into plural component blocks and certain blocks can be performed in an order that differs from that which is illustrated herein including a parallel manner of performing the blocks . The blocks shown in the flowcharts can be implemented in any manner by any physical and tangible mechanisms for instance by software hardware e.g. chip implemented logic functionality firmware etc. and or any combination thereof.

As to terminology the phrase configured to encompasses any way that any kind of physical and tangible functionality can be constructed to perform an identified operation. The functionality can be configured to perform an operation using for instance software hardware e.g. chip implemented logic functionality firmware etc. and or any combination thereof.

The term logic encompasses any physical and tangible functionality for performing a task. For instance each operation illustrated in the flowcharts corresponds to a logic component for performing that operation. An operation can be performed using for instance software hardware e.g. chip implemented logic functionality firmware etc. and or any combination thereof. When implemented by a computing system a logic component represents an electrical component that is a physical part of the computing system however implemented.

The phrase means for in the claims if used is intended to invoke the provisions of 35 U.S.C. 112 sixth paragraph. No other language other than this specific phrase is intended to invoke the provisions of that portion of the statute.

The following explanation may identify one or more features as optional. This type of statement is not to be interpreted as an exhaustive indication of features that may be considered optional that is other features can be considered as optional although not expressly identified in the text. Finally the terms exemplary or illustrative refer to one implementation among potentially many implementations

From a high level perspective the operations performed by the processing system satisfy one or more policy objectives. In one case the clients may include any number of non malicious clients such as representative non malicious client and any number of malicious clients such a representative malicious client . The non malicious client represents any agent that is attempting to perform a legitimate normal non malicious transaction with the service . The malicious client represents any agent that is attempting to perform an action that is deemed undesirable by the service for any reason defined by the service hence that action may be regarded as malicious. In this context the processing system performs actions on the CEI sent by the clients with the intent of thwarting the actions by the malicious client but not the non malicious client .

The filtering logic resides anywhere between the clients and the service and for this reason may be regarded as an in network filtering mechanism. By virtue of this configuration the processing system attempts to take action on the CEI before at least some of the CEI sent by the malicious client reaches the service . This has the effect reducing the risk that the service will act on malicious CEI sent by the malicious client . This in turn eliminates or reduces the amount of post processing that the service is compelled to perform after having already processed CEI sent by the malicious client . As a further benefit the processing system may reduce congestion in the filtering infrastructure which connects the clients to the service and may potentially simplify the processing performed by the service itself. These potential benefits are cited by way of illustration not limitation other implementations of the processing system may provide additional advantages.

In other cases the processing system serves some other policy objective that does not involve discriminating between non malicious clients and malicious clients. For example the processing system can classify the CEI into different categories of non malicious traffic and take different actions on the traffic depending on its assigned classification. Hence while many of the examples presented in this disclosure pertain to the management of online threats the reader should keep in mind that the processing system can be tailored to satisfy any policy objective or objectives.

This subsection presents an overview of the environment as a whole. Later subsections present further details on selected components in the environment . Namely Subsection A.2 presents further illustrative details regarding the filtering logic . Subsection A.3 presents further illustrative details regarding the policy management system . And subsection A.4 presents further illustrative details regarding the service .

Starting at the top of and working down each client may correspond to any type of computing device which operates in a network environment of any type. For example at least some of the clients may correspond to any of personal computer devices laptop computer devices tablet type computer devices mobile telephone devices including smartphone devices electronic book reader devices personal digital assistant devices game console devices portable game playing devices set top boxes intelligent appliances and so on. Alternatively or in addition some of the clients may correspond to software agents within more encompassing applications or devices.

The network environment may correspond to a wide area network of any type such as the Internet a local area network a point to point connection or combination thereof. The network environment may operate based on any protocol or combination of protocols. shows that the network environment encompasses only the clients for convenience of illustration but any other component in may be considered as part of the network environment . For example the service may represent functionality that is accessible to the clients via the Internet available at a specified IP address.

In some cases the representative non malicious client may represent any computer device under the direction of a human user that performs an action assessed by the service as being legitimate. For example if the service is a shopping related service the non malicious client may represent a computer device that performs a normal shopping transaction under the direction of the human user.

In contrast the malicious client may include a BOT that performs a malicious action directed at the service in automated fashion. The BOT represents any kind of malicious software and or hardware that the malicious client acquires in any manner. In the most common cases the malicious client may acquire the BOT by becoming infected with a virus e.g. when the user interacts with an infected website downloads an infected file etc. More precisely a malicious client that is infected with a BOT is often infected with multiple BOTs. Indeed it is often the case that a first installed BOT may accommodate the introduction of additional BOTs. In other cases the representative malicious client may represent any non infected computer device that is nevertheless being operated by a malicious user for any malicious objective.

The malicious client can perform any type of malicious activity. In the prominent example set forth herein the service is an ad hosting service. In this kind of business environment an advertiser submits an ad to the ad hosting service. The ad hosting service then presents the ad on any number of publication sites maintained by respective publishing entities. In a non malicious mode of operation a user may click on the ad when viewing a publication site or otherwise interact with the ad such as by mousing over the ad with a mouse device etc. . This prompts the non malicious client to send an instance of CEI to the service . Here the instance of CEI conveys the ad consumption action taken by the user such as a click made may the user. In many business models the user s action is also a revenue generating event for the publishing site and the ad hosting service. That is as a result of the user s click the advertiser is obligated to pay a prescribed fee to the publication site on which the ad is displayed further the advertiser is often obligated to pay a typically smaller fee to the ad hosting service itself. In a malicious mode of operation the BOT of the malicious client may automatically click on the ad posted by a publication site. Although there is no real user behind these actions the advertiser may still incur the various costs described above unless the ad hosting service recognizes the BOT s clicks as fraudulent.

Different motivations may underlie a click fraud campaign. In some cases a malicious entity may be affiliated with one or more publication sites. The malicious entity can instruct its army of BOTs to click on these publication sites to generate ad revenue for these sites. In other cases a malicious entity may be a competitor of a particular advertiser. The malicious entity may instruct its BOTs to click on the advertisements of its competitor wherever they may appear. This has the effect of depleting the advertising budget of the advertiser without otherwise directing meaningful customer traffic to the advertiser s ad campaign. In other cases a malicious entity may orchestrate a click fraud campaign as a form of political or social protest and so on.

Many other types of malicious attacks are possible. For example in a distributed denial of service DDOS attack the BOTs send a large number of requests to a service . This has the effect of swamping the service with fake traffic which in turn prevents the service from handling legitimate traffic in an efficient manner. In a statistical guessing attack the BOTs repeatedly attempt to guess the passwords of users of a service or otherwise attempt to gain unauthorized access to the service. In a traffic boosting campaign the BOTs may direct fake traffic to a site for the purpose of boosting the relevance score of the site in a search engine s ranking. These few cases are mentioned by way of example not limitation. Further as explained above in other environments the processing system may attempt to discriminate between different kinds of non malicious traffic rather than separate non malicious traffic from malicious traffic.

The representative service can perform any activity. In the prominent example set forth herein the service is an ad hosting service which interacts with one or more advertiser systems and publication sites . In other cases the service may correspond to a shopping related site a financial services site a news related site a social network site and so on. In terms of physical implementation the service may be implemented as one or more server computers and associated data stores.

As mentioned above the processing system includes filtering logic and policy management system . As the name suggests the filtering logic filters CEI that is sent by the clients to the service . In addition in some implementations the filtering logic can also filter traffic in the opposite direction that is from the service to the clients . The filtering logic performs this role by comparing each instance of CEI with the rules in a rule set. Each rule in the rule set is associated with at least one client of interest. For example a rule may identify one or more malicious clients of interest. Through this process the filtering logic can identify whether an instance of CEI that it has received originates from a client that is deemed a threat or potentially a threat.

Upon classifying the instance of CEI the filtering logic then takes one or more actions on the CEI. For example the filtering logic can block the instance of the CEI which prevents the instance of the CEI from reaching any target destination. Alternatively the filtering logic can reroute the instance of the CEI to a destination which differs from its original destination. In this case the filtering logic can send the instance of CEI to just the new destination or can send the instance of CEI to both the original and new destinations. Alternatively or in addition the filtering logic can add information to the instance of CEI which has the effect of tagging or marking the CEI. Any downstream consumer of the instance of CEI can read the tagging information and process the instance accordingly. The filtering logic can perform yet additional operations.

The policy management system generates the rules used by the filtering logic . The policy management system then deploys the rules in the filtering logic . More specifically an analysis system generates the rules based on at least two sources of information a reputation information received from a reputation management system and b CEI received from the filtering logic and forwarded to the analysis system . Each instance of reputation information describes at least one client of interest that has recently exhibited activity within the network environment . In contrast the forwarded CEI describes CEI that the filtering logic has recently received from at least one client. More specifically in some cases the forwarded CEI may correspond to original raw CEI that has not been modified by the filtering logic . Alternatively or in addition the forwarded CEI may correspond to already processed CEI that includes supplemental information added thereto compared to the original CEI. For example the forwarded CEI may include tagging information added by the filtering logic .

By virtue of the above summarized mode of operation the analysis system will attempt to fashion a rule that targets a malicious client identified in the reputation information providing that the forwarded CEI also indicates that this same malicious client is also currently attempting to perform a transaction with the service being protected. To be more concrete the reputation information may indicate that the BOT which operates on malicious client has recently attempted to contact its command and control C C site for reasons explained in greater detail below . The analysis system determines whether any of the CEI received from the filtering logic indicates that the malicious client is also attempting to click on an ad from the ad hosting service. If so the analysis system may attempt to fashion a rule that has the intent of blocking this particular malicious client optionally together with other malicious clients which may be associated with the malicious client .

More specifically each instance of CEI is associated with a network connection which may also be regarded as a transaction or a flow. For example assume that the malicious client attempts to click on an ad. This action causes the malicious client and service to exchange a series of packets e.g. in the Transmission Control Protocol TCP or some other protocol or combination of protocols. The packets for instance may include one or more introductory packets that mark the beginning of the connection e.g. a SYN packet one or more packets that send payload data interspersed with acknowledgement packets and one or more closing packets that mark the close of the connection e.g. a FIN packet . Each connection of this nature has a duration extending from the first first transmitted packet to the last transmitted packet. The duration may correspond to just a fraction of second in some cases e.g. 300 ms . In other cases the duration is longer e.g. potentially several seconds or minutes etc. .

In some cases the analysis system is capable of catching a first discovered malicious client in the act of performing a malicious connection. In this case the analysis system may be able to formulate a rule that targets the malicious client and deploy that rule onto the filtering logic before the connection has terminated. This may enable the filtering logic to stymie the malicious transaction as whole. This in turn prevents the service from acting on the transaction.

Yet in other cases the connection is too short to stop the transaction in real time. That is the analysis system requires a certain amount of time to detect a threat formulate a rule and then pass that rule to the filtering logic . The filtering logic then takes a certain amount of time to load the new rule in its data store. This latency means that the filtering logic may be unable to act on the new rule while the current client connection is in progress.

To address this latency issue the analysis system also attempts to predict malicious clients that are likely to interact with the service in the near future and pushes those rules to the filtering logic on a proactive basis. The manner in which the analysis system performs this task is described in greater detail below. As an overview the analysis system can first identify a malicious client that is currently active in the network environment . Then the analysis system can determine whether the behavior of any other clients is similar to this identified client. Alternatively or in addition the analysis system can determine whether the identified client is a member of subnet of clients where that subnet as a whole has a significant number of malicious clients. In response to either of these determinations the analysis system can formulate one or more rules which target the complete group of potentially malicious clients. This operation is based on the assumption that any of the related clients may perform malicious transactions in the near future.

In addition the analysis system can attempt to predict whether an identified client will likely engage in malicious activity based on a host of factors such as the frequency at which the client has performed malicious activity in the past the most recent attempt by the client to perform malicious activity the durational and inter event characteristics of connections made by the client and so on.

The reputation management system operates by collecting reputation information from different reputation systems . The reputation management system then formulates the reputation information into a standardized record referred to here as a reputation data set. As described above an instance of reputation information identifies at least one client that has exhibited malicious activity in the network environment .

Consider for example the merely representative reputation system shown in . In some implementations a malicious client may include a BOT which is programmed to contact an original command and control C C site . For example the BOT may contact the original C C site on a periodic basis and or on an event triggered basis and or on a random or partially random basis etc. The original C C site may respond to the inquiry from the BOT by providing it with attack instructions. For example the original C C site may instruct the BOT to participate in a click fraud campaign that targets a particular website and or a particular advertisement and or a particular ad hosting service and so on. The C C site can re provision its army of BOTs in this dynamic manner to carry out any malicious objectives.

Further suppose that an entity associated with the reputation system has legally hijacked the domain associated with the original C C site. This means that the BOT will be directed by a DNS service to a new C C site rather than the original C C site . This action may effectively disarm the BOT from causing any damage to the service . However as explained above a client that includes a single BOT often includes plural BOTs. Hence the malicious client may still pose a threat to the service by virtue of the existence of other BOTs that may reside on the malicious client .

To address the continued risk posed by the malicious client the reputation system includes a site monitoring module that monitors episodes in which any malicious client attempts to contact the new C C site . The reputation system formulates an instance of reputation information in response to this event. A feed formulation module can then forward this instance of reputation information to the reputation management system of . The reputation management system can then add the received instance of reputation information to its reputation data set.

Each instance of reputation information can include various information items such as a the identity of the malicious client in question b temporal information that indicates when the client last performed a suspicious action c temporal information that indicates when the client first performed a suspicious action d the reputation system from which the instance of reputation information originates and so on.

Other implementations can employ other types of reputations systems besides or in addition to the reputation system shown in . For example another reputation system may correspond to a SPAM detector provided by an Email system not shown . Another reputation system may correspond to a malicious activity module provided by a search engine and so on. These reputation systems leverage the principle described above if a client exhibits one type of malicious behavior the client may be infected with multiple bad actors and is therefore considered a potentially active threat. In yet other cases one or more reputation systems can provide information regarding activity exhibited by non malicious clients.

Returning to this figure also indicates that the service can send service reputation information to the policy management system . For example the service may include independent threat analysis functionality. That functionality may conclude that a particular client is a malicious actor. The service can communicate this conclusion to the policy management system as reputation information. Upon receipt the policy management system can optionally treat this reputation information in the same manner as any other instance of reputation information received from any other reputation system. Alternatively the policy management system can act on the reputation information provided by the service in a different manner than other instances of reputation information. For example the policy management system can automatically generate a rule which excludes the malicious client identified by the service rather than weighing the appropriateness of excluding this client in the manner described in detail below.

The service may also issue other control instructions to the policy management system . For example the service may disable and enable the filtering performed by the filtering logic as it pertains to the service . In one situation the service may wish to suspend the protection afforded by the processing system so as to collect statistical data for testing purposes. In this mode the service may wish to receive both non malicious and malicious traffic for a limited time span so as to inform itself of threats in the network environment and its ability to handle these threats. After this testing period ends the service may instruct the policy management system to turn on its protective services. In a similar manner the service can send any other configuration instructions to the processing system which affects its operation in any manner.

In terms of physical implementation the filtering logic can be implemented by any number of filtering devices. Subsection A.2 provides additional details on this topic. In one implementation the analysis system the reputation management system and each reputation system can each be implemented by one or more server computers and associated data stores. Any component shown in or any combination of components can be implemented at a single site or distributed over plural sites in any manner.

Further the components shown in can be administered by different collections of entities in accordance with different business paradigms. In one case a single entity can administer both the filtering logic and the policy management system for the purpose of protecting the service . In that case the service may be administered by the same entity which operates the policy management system or may be administered by a different entity. In this mode different services may employ their own local version of the policy management system . This enables each local version of the policy management system to address the particular needs of the service it is protecting.

In another case various aspects of the components shown in can be provided as a common resource that is available to plural services. For example a single entity can implement a global reputation management system on behalf of one more services and associated local analysis systems. In this case a local entity which administers a local version of the analysis system can subscribe to the services of the global reputation management system . This will enable the local analysis system to receive updated reputation information from the global reputation management system on a periodic episodic and or any other basis using a push and or pull model to receive the reputation information. Still other allocations of functions are possible. For example features of the filtering logic and analysis system that are common to plural services can be shared among those services as a common resource. for instance shows an example of filtering logic that serves multiple services where is described below .

In another business model a software developer can produce a software product that may interact with an existing online service or that may operate as an online service in its own right. In either case the software developer can design the product such that it integrates with and leverages the protective services of the processing system .

In yet another business model a service can offer the protection of the processing system to its proven non malicious consumers as an optional feature to be turned on and off upon the instruction of those consumers. The service can charge a fee for such protection or offer such protection for free.

The CEEM can also extract any other selected information items from the CEI and compare this selected information with corresponding information expressed in the rules. For example the CEEM can optionally extract a destination identifier associated with the destination of each packet which may identify the service to the packet is directed. The CEEM can determine that an instance of CEI matches a particular rule if the extracted source identifier and destination identifier match a client of interest and a service specified in a rule respectively.

An action taking module performs one or more actions based on the results of the extracting and matching performed by the CEEM . As described above without limitation possible actions include a blocking further propagation of an instance of CEI that matches a rule b rerouting an instance of CEI that matches a rule c tagging an instance of CEI that matches a rule and so on. If the instance of CEI does not match any rule the action taking module can optionally pass it to its intended destination without modification. In addition the action taking module can add tagging information to such an instance of CEI.

More specifically in some implementations the CEEM or the action taking module can categorize an instance of CEI as white gray or black. A white instance of CEI corresponds to CEI that has been judged to be non malicious. A black instance of CEI is CEI that has been judged to be malicious. A gray instance of CEI is CEI that has been judged to be potentially malicious but not with the same certainty as the black classification. The action taking module can then optionally add tag information to each instance of CEI which conveys the white gray black classification. In addition the action taking module can route white gray and black traffic to respective destinations. This implementation is merely one example other implementations can adopt other classificatory breakdowns of potential client traffic and or can perform other actions upon classifying instances of CEI.

In addition to white gray black tagging the action taking module can add other information to instances of CEI. For example the action taking module can embed information into an instance of CEI which indicates the reputation source which has identified the client in question as malicious.

The filtering logic interacts with the policy management system via an interface such as an application programming interface API . In one interaction the analysis system sends one or more rules to the filtering logic for storage in the data store . In another interaction the filtering logic sends CEI to the analysis system . As will be described in detail below the analysis system uses this forwarded CEI together with the reputation information provided by the reputation management system to produce new rules.

As described in Subsection A.1 the filtering logic can send raw original CEI to the analysis system . The filtering logic can produce this raw original CEI by forking off a stream of the CEI which it has received from the clients . In addition or alternatively the filtering logic can send CEI that has already been processed by the action taking module to the analysis system . For example the processed CEI that is forwarded may include tag information added by the action taking module .

In other cases the analysis system can consume different types of CEI over the course of its operation. For example when the analysis system starts up it may have no information regarding threats in the network environment . Correspondingly the filtering logic may store no rules. In this case the analysis system may initially ask the filtering logic to send a forked off copy of the received event stream without tagging information applied thereto. In short order the filtering logic will acquire rules and begin processing CEI based on those rules. In view thereof at some stage the analysis system may ask for and receive CEI from the filtering logic that contains tagging information in addition to the raw untagged CEI or instead of the raw untagged CEI. Still other environment specific implementations of this feedback mechanism are possible.

In some implementations the filtering logic represents equipment that resides on the edge of a processing domain that contains the service . For example the service may be implemented by a data center an enterprise environment or the like. In this context the filtering logic intercepts CEI that is destined for the service and checks it to determine whether it is malicious in nature.

More specifically shows a first implementation of logical functions of the filtering logic shown in . In this implementation the filtering logic is implemented as one or more discrete filtering units that are dedicated to performing only the functions shown in . This implementation adds the filtering unit s to existing network infrastructure which may perform other network operations on the CEI that may be unrelated to the operations shown in . For example the existing network infrastructure may comprise any of load balancers firewalls core switches top of rack TOR switches aggregate switches virtual switches and so on.

More specifically the filtering unit s may sit between upstream existing network infrastructure if any and downstream existing network infrastructure if any . In this configuration the filtering unit s may process the output of upstream existing network infrastructure if any. In addition or alternatively the filtering unit s may send its output to any downstream existing network infrastructure .

In yet other cases the implementations of can be combined into a single implementation. That is this combined implementation would include one or more discrete single purpose filtering units as in with the kind of dual purpose functionality shown in . Still other implementations are possible.

In general the filtering unit A determines whether an instance of CEI meets a prescribed test as governed by rule set A if so the filtering unit A can forward the CEI to destination X and or perform some other action s on the instance of CEI. If the instance of CEI does not satisfy the test imposed by filtering unit A the filtering unit A may classify it as belonging to one of two cases case a or case b. If the instance CEI is assigned the first class the filtering unit A forwards it to filtering unit B . If the instance of CEI is assigned to the second class the filtering unit A forwards it to the filtering unit C . The filtering unit B can then perform its own local test as guided by rule set B to determine whether to forward the CEI to destination Y and or perform some other action s on the instance of the CEI. The filtering unit C likewise can perform its own local test as guided by rule set C to determine whether to forward the CEI to destination Z and or perform some other action s on the instance of the CEI. The destinations and may be associated with any of services analysis sites sink hole sites in which the CEI is essentially discarded and so on.

In one case the hierarchical structure of can be used to protect plural services within a data center or other environment. A top level filtering unit e.g. filtering unit A can determine whether an instance of CEI originates from a client that is deemed malicious with respect to all services hosted by the environment. If so the filtering unit A can block the instance of CEI or send it to an analysis site associated with destination X . Filtering unit B can then perform filtering that is locally appropriate to a service which it protects associated with destination Y and filtering unit C can perform filtering that is locally appropriate to the service which it protects associated with destination Z and so on.

In another case all three of the filtering units shown in protect a single service. The top level filtering unit A can perform relatively coarse level filtering on behalf of the single service. The other filtering units can perform finer grade filtering for the service. For example filtering unit A can be assigned the task of classifying an instance of CEI as white gray or black. Filtering unit B and or filtering unit C can be assigned the more refined task of analyzing traffic classified as gray. This architecture is also a way to increase the number of rules that the filtering logic can accommodate compared to the use of a single filtering unit having a fixed memory capacity. To repeat these examples are presented by way of illustration not limitation still other applications of hierarchical filtering structures are possible.

The reputation management system includes an interface such as an application programming interface API for receiving reputation information from the reputations systems . Each reputation system can interact with the reputation management system via the interface to perform various operations. For example each reputation system can register itself as a reputation feed. Each reputation system is thereafter associated with an identifier which it provides to the reputation management system . Each reputation system can then send instances of reputation information to the reputation management system each time it detects predefined suspicious behavior in the network environment such as a client checking into a captured C C site . More specifically the reputation management system can collect the reputation information from each reputation system on a push basis a pull basis and or any other basis. Each reputation system can identify the client of interest by IP address ASN and or any other designator. Each reputation system can also identify an entire subnet by specifying an identified mask such as by specifying the prefix associated with the subnet to be described in greater detail below .

A reputation set builder module compiles a reputation data set based on the instances of reputation information that it receives from different reputation systems . The reputation set builder module stores the reputation data set in a data store . More specifically the reputation set builder module can store the reputation data set as a file in any format such as SQL . The reputation set builder module can also maintain a version of the reputation data set in memory to facilitate quick lookup. The reputation set builder module can structure the reputation data set as a hash table or in some other data structure.

The analysis system includes an interface such as an API for interacting with various other entities. For example the interface receives reputation information from the reputation management system forwarded CEI from the filtering logic service reputation information from the service etc. This information may be received on a push basis a pull basis and or any other basis. A rule generation module operates on the received information to produce rules using any mechanism. In one case the rule generation module uses an algorithm that employs a cost function as will be set forth in greater detail below. In another case the rule generation module employs artificial intelligence engine such as a machine learning engine a neural network engine etc.

A rule deployment module sends the rules generated by the rule generation module to the filtering logic . The rule deployment module can perform this task using different levels of functionality . For example a lowest level of the functionality can correspond to one or more drivers. The drivers perform discovery to identify the filtering units that are operational in the filtering logic at any given time. The drivers also convert the rules to be pushed to the filtering logic to a format that is compatible with each recipient filtering unit. The connection manager determines the manner in which the rules are parsed out to the different filtering units in the filtering logic . The top level management layer maintains information regarding the expected topology of the filtering logic . The top level management layer also maintains policies which determine how rules are disseminated to the different filtering units. The top level management layer can also define a course of action to be taken when at least some of the filtering units that are expected to be present in the filtering logic are not found by the drivers. Other implementations of the rule deployment module can adopt other device control architectures and paradigms.

The rule generation module includes a packet sniffer module for examining packets associated with the forwarded CEI provided by filtering logic . As explained above the forwarded CEI may or may not include additional information added by the filtering logic such as tagging information. The packet sniffer module operates by extracting selected information from predefined fields of packets and storing the selected information in a data store . In one implementation the selected information may identify the client which has sent each packet the service to which the packet is directed and the source and destination ports associated with the client and service respectively.

A client of interest assessment module compares the extracted selected information with the reputation information. In one case this comparison may involve for each instance of CEI comparing a client identifier that has been extracted from the CEI with the known malicious clients identified in the reputation information. If there is a match the client of interest assessment module can store information regarding a potentially malicious client in a data store . This is a client that a has been identified as malicious by at least one reputation system and b has recently attempted to perform a transaction with the service . Each client that is identified in the data store is referred to herein as an identified client.

A correlation assessment module and a subnet assessment module attempt to find clients that are related to each identified client in the data store . More specifically the correlation assessment module compares the behavior of each identified client with the behavior of other clients. As a result of this comparison the correlation assessment module may find that one or more other clients perform a similar pattern of clicks as an identified client under consideration. Different factors may explain this similarity. In some cases a BOT may embody logic which produces similar behavior in different clients which are infected with this same BOT. Alternatively or in addition a client that is infected with the BOT may be associated with a group of IP addresses the clients that are associated with these IP addresses therefore may produce the same pattern of behavior.

The subnet assessment module determines the subnet to which each identified client belongs where the concept of a subnet is clarified below . If the subnet is populated with a significant number of other malicious clients the subnet assessment module can store the prefix of that subnet. The subnet assessment module can also determine a subnet for each correlated client identified by the correlation assessment module .

Both the correlation assess module and the subset assessment module promote one of the overriding goals of the analysis system which is to predict malicious clients which are likely to be active in the network environment in the near future. This is useful because as explained above the processing system may have insufficient time to devise and deploy a rule so as to thwart a malicious client that is currently performing a malicious transaction.

Next a candidate rule production module produces rules which attempt to target the respective identified clients in the data store . In addition the rule generation module can also produce rules which attempt to target the related clients if any identified by the correlation assessment module and or the subnet assessment module . For instance the candidate rule production module can target a whole subnet of clients by adopting a rule which specifies a mask that mask identifies the subnet.

As a result of its operation the candidate rule production module can store a set of N candidate rules in a data store . The candidate rule production module can structure the rules in any manner. Further each rule can include various information items such as but not limited to a the identity of the targeted client in question such as by providing an IP address ASN etc. of the targeted client b a mask which identifies a group of other malicious clients with which the targeted client is associated c hard time out information which indicates the amount of time for which the rule will be active d idle time out information which indicates the amount of time for which the rule will be active if no specified event occurs such as no further reputation information is received for the targeted client in question and or no CEI is received from this client etc. e a priority level associated with the rule f a description of the reputation source that is responsible for judging the targeted client as being malicious g the action or actions to be performed when an incoming instance of CEI is determined to match the rule h a measure which defines an extent to which an action specified by the rule is to be performed e.g. by specifying that X percent of traffic matching the rule is to be permitted through the filtering logic and so on.

More specifically a first type of rule attempts to target a single malicious client. In one standard and protocol such a rule identifies the client using a 32 match where 32 indicates the number of bits in the IP prefix . A second type of rule attempts to target a grouping of clients by specifying a mask. For example in one case such a rule can identify a subnet having 255 potential clients using a 24 match where 24 indicates the number of bits in the IP prefix .

The candidate rule production module can also receive other instructions from any other source. These instructions may play a part in its formulation of rules. For example the service may instruct the candidate rule production module to ban one or more malicious clients which it has independently assessed as being undesirable. Or a service may instruct the candidate rule production module to change any parameter of an existing rule such as the priority level of a rule and or the throughput percentage associated with the rule and so on. More generally any entity including an administrator can manually load any rules into the data store delete any rules modify any existing rules retrieve any rules for analysis perform any algorithmic overrides and so on.

In addition or alternatively the rule generation module can record hit counts which reflect a number of times that one or more reputation systems have identified each client as being malicious e.g. based on the number of times that each client has checked into its C C domain within a prescribed period and or based on the number of times that a service has notified the policy management system that each client is malicious etc. The candidate rule production module can then boost the priority levels of rules that target clients with relatively high hit counts.

In addition the rule generation module can detect whether the CEI exhibits potentially malicious behavior when considered by itself that is without consideration of the reputation information. The rule generation module can then generate rules when that behavior is detected. For instance the rule generation module can generate a rule that targets a client when the CEI that is sent by that client exceeds a prescribed threshold irrespective of whether the reputation information identifies the client as being potentially malicious. This behavior may indicate that the client is participating in a distributed denial of service attack. The rule generation module can generate other rules upon detecting other types of telltale patterns in the CEI.

A rule selection module sorts the rules in the data store . More specifically in some implementations the filtering logic may have a limited capacity to store a maximum of M entries. Recall that the candidate rule production module produces N candidate rules in the data store . If M

Section B provides illustrative details regarding one manner of operation of the rule selection module . By way of overview the rule selection module can employ at least one cost function to sort the N rules in the data store .

The middle panel indicates the manner by which the correlation assessment module can compare two CEI steams of CEI. Namely the correlation assessment module can compute and store the delay between each instance of CEI in a first CEI stream with each instance of CEI in a second CEI stream.

As indicated in the third panel the correlation assessment module can then sort the computed delays into the temporal bins of a histogram where each bin corresponds to a specified delay period. The correlation assessment module can then perform processing to remove noise from the signal represented by the histogram. The manner in which this processing can be performed is described in Section B. After such processing the correlation assessment module can determine if there are any spikes in the processed signal. Spikes having a significant magnitude indicate that the two CEI streams under consideration are correlated.

In one manner of operation the subnet assessment module identifies the subnet or subnets to which an identified client belongs. The subnet assessment module then determines the number of infected clients in this group relative to the total number of clients in this group. The subnet assessment module then makes a determination based on this ratio whether it is appropriate to fashion a rule which targets the entire subnet. A subnet having a percentage of bad agents that exceeds a prescribed threshold is an appropriate candidate to target as a whole.

Consider for example the IP prefix 128 10 12 with a 24 subnet. The destination 24 means that the IP prefix has 24 bits. The subnet can accommodate a total of 255 clients meaning that the last 8 bits of the address can accommodate 255 permutations. If 20 clients in this subnet happen to be malicious then the score for this subnet is 20 255.

The added functionality if included may include a client event interpretation module . The client event interpretation module can read the tagging information contained in a received instance of CEI if any. An action taking module can then perform any appropriate action based on the tagging information and or other factors. In one such action the action taking module can route white traffic to any service specific functionality such as ad processing functionality in the case of an ad hosting service. The action taking module can send gray traffic to a module which performs further analysis. The action taking module can block black traffic if in fact this traffic is not already blocked by the filtering logic . In other cases the operations performed by the client event interpretation module and the action taking module are incorporated in the filtering logic .

An independent threat assessment module performs any independent analysis on the CEI to detect malicious clients. The independent threat assessment module can then notify the policy management system of its findings. The policy management system can act on this notification in different ways described above. To review the policy management system can treat the input from the service as another instance of reputation information to be processed in the same manner as other reputation information from other reputation sources. Alternatively or in addition the policy management system can give priority to the conclusions of the service e.g. by blocking clients identified as being malicious by the service independent of the processing set forth in connection with .

A service instruction module can provide any control instructions to the policy management system which affect the operation of the policy management system in any manner. In one case the service instruction module can send an instruction which enables and disables the operation of the policy management system as it affects the service . In another case the service instruction module can send an instruction that modifies any parameter of an existing rule.

A client instruction module can optionally forward instructions and other information to the clients . For example upon determining the existence of a malicious client based on the service s own analysis or based on the conclusions reached by the policy management system the client instruction module can forward a message to the client in question to inform it that it is potentially infected with a BOT. For example shows a page of content provided by a publishing site having a slot in which the ad hosting service would normally display an advertisement. If the client that displays this page has been determined to be infected with a BOT the client instruction module can display the BOT notification message in the slot reading for example Notice You may be infected with a malicious agent. Please click here for more information. 

Starting with this figure shows a procedure which conveys illustrative configuration related behavior of the policy management system of . In the sole block the policy management system receives control instructions from various sources. For example the policy management system can receive instructions which serve to configure the reputation management system or the analysis system or individual rules in the analysis system . The policy management system can also receive instructions which enable or disable the policy management system as a whole. In one case a service that is the beneficiary of the policy management system may supply these control instructions.

Advancing to in block the analysis system determines whether each identified client exhibits behavior that is similar to one or more other clients. If so the analysis system can store the identities of these additional correlated clients. In block the analysis system determines whether each identified client and each correlated client belongs to a subnet having a percentage of malicious clients that satisfies a prescribed threshold. If so the analysis system stores the identity of this subnet. In block the analysis system produces a set of candidate rules based on the conclusions reached in blocks and . The analysis system can also take into consideration other factors and instructions when generating the candidate rules. For example a service may independently identify malicious clients and ask the analysis system to insert rules which block them and or perform some other action on the identified malicious clients. In another case the analysis system can generate rules based solely on the CEI e.g. independent of the reputation information . In general the set of candidate rules can be said to identify a list of candidate clients.

In block the analysis system determines whether it is time to push a new set of rules to the filtering logic . For example in one case the analysis system updates the rules in the filtering logic at periodic intervals e.g. every x minutes. Alternatively or in addition the analysis system can update the rules on an event driven basis such as the accumulation of a prescribed number of new candidate rules in the data store . If the update time has arrived in block the analysis system sorts the candidate rules based on a cost function. This operation is described in greater detail below.

In block the analysis system pushes the M top ranked rules to the filter logic . That is assume that there are N candidate rules in data store further assume that there are M available slots for storing rules in the filtering logic . If M N then the analysis system will forward the M top ranked rules to the filtering logic and ignore the remaining N M rules for the time being. In another case assume that M N. In this case the analysis system can push all M rules to the filtering logic as well as M N random rules. Each random rule targets a malicious client identified by the reputation information but that malicious client has not yet been detected in recent CEI. In other words such a random rule targets a client that is known to be malicious but that client has not yet been observed to be actively attacking the service.

In other cases each instance of reputation information may have severity scores associated therewith. For example the reputation information associated with a particular client may have a hit count associated therewith. The hit count indicates the number of times that one or more reputation systems have flagged this client as being malicious. If this kind of severity information exists the analysis system can choose rules that target the clients having the highest severity scores. This strategy can be used instead of choosing random rules based on reputation information or in addition to choosing random rules.

Further note that when the analysis system starts up it may not have received any CEI from the filtering logic . But assume that the analysis system does receive the reputation information from the reputation management system at start up. In this case the analysis system can push a set of rules to the filtering logic that is wholly or mostly determined based on the reputation information. As time progresses the analysis system can push increasingly more rules based on a combination of reputation information and CEI.

After block the procedure repeats its operation e.g. by identifying additional malicious clients and fashioning rules based on these clients. Subsequent iterations of the procedure may have the effect of removing a subset of rules in the filtering logic and substituting in their place new rules. In this manner the analysis system dynamically maintains a set of rules in the filtering logic which address client that are a known to be malicious based on reputation information and b currently posing a threat to the service or are expected to pose a threat to the service in the near future. And as noted above in some circumstances the analysis system can propose rules based on factor a alone or factor b alone.

The analysis system performs the sorting in block based on one or more cost functions. Different cost functions can be formulated each of which assigns a score to each candidate rule in the collection of N candidate rules in the data store . The analysis system then picks the top M candidate rules based on the scores assigned by the cost function. That is consider two malicious candidate clients having cost values cand c respectively. The analysis system will be more apt to adopt a rule rfor the first client rather than a rule rfor a second client if c c although it is possible to define cost in the opposite manner too such that the analysis system will be more apt to adopt a rule for the first client rather than the second client if c

In one case the cost function comprises a factor based function expressed as Cost f x factor where 1. In one implementation there are two factors that is K 2 including a recentness factor that is factor recentness and a frequency factor that is factor frequency . The recentness factor is computed by first measuring a separation in time between a current point in time and the end of a last received instance of CEI for a particular client under consideration where the end of the last received instance is reflected in timestamp information associated with that instance . This measurement is referred to as the age of that client denoted as age. The frequency factor is computed by first measuring how many instances of CEI have been received for a client under consideration since it has been added into the candidate rule set or in some other identified timeframe . This value is referred to as count denoted as count. When a client is first added to the candidate rule set the countfor that client is set to zero.

In one implementation the analysis system measures agein some type of time based units e.g. seconds and measures countin some type of count based units. Further the ageis measured using a different scale compared to count. To address this discrepancy the analysis system can compute a unit less Cost value based on normalized versions of recentness and frequency.

More specifically the normalized value of recentness may be computed as recentness 1 age age age age . The symbol agerefers to the largest agevalue exhibited by any client in the candidate list. Similarly the symbol agerefers to the smallest agevalue of any client in the candidate list. These largest and smallest age values may be assessed at the time at which it is desired to push a set of rules to the filtering logic e.g. at the time that block is performed. Note that the recentnessvalue varies between 0 and 1. Further a client having a more recent CEI instance that is a lower agevalue has a higher recentnessvalue.

The normalized value of frequency may be computed as frequency count count count count . The symbol countrefers to the largest countvalue exhibited by any client in the candidate list. Similarly the symbol countrefers to the smallest countvalue that is exhibited by any client in the candidate list. Again the frequencyvalue varies between 0 and 1. Further a client having more CEI instances that is a higher countvalue has a higher frequencyvalue.

With the two factors described above the cost function becomes Cost recentness frequency. If 1 and 0 the rule selection algorithm manifests a Least Recently Used LRU rule eviction policy. On the other hand if 0 and 1 then the rule selection algorithm manifests a Least Frequency Used LFU rule eviction policy. The analysis system can adopt a combination of LRU and LFU by choosing different combinations of and .

In another case the cost function comprises a function based function expressed as Cost f x f pattern where 1. In one implementation there are two patterns that is L 2 including a flow duration fd pattern that is pattern fd and a flow inter arrival fiat pattern that is pattern fiat .

For an open connection a current measurement of fdis defined as the separation in time from the beginning of a CEI communication e.g. a SYN packet of a TCP connection to the current time for a client under consideration. For a closed connection fd is not computed. From a high level perspective as the fd of an open flow increases the chance of receiving more traffic for this flow decreases.

More specifically in one formulation f fd 1 fd where fdcorresponds to fd fd fd fd . Here the fdvalue is the largest fdvalue exhibited within a group of clients over an extended period of time e.g. several hours or longer in one case. Similarly the fdvalue is the smallest fdvalue exhibited within the group of clients over the extended period of time. In contrast to the factor based computations described above the group of clients that is considered when computing the fdand fdvalues may be more encompassing compared to the set of clients identified by the candidate list. More generally the intent of this fd related analysis is to use data patterns learned from historical data to predict the behavior of the current flow duration. The analysis system clamps negative values to 0. Further if a flow from a client is closed the cost function associated with that client does not take into consideration the fd value that is 1 and 0 .

A current measurement of fiat fiat measures the amount time current between the current time and the time at which the previous flow has ended for a particular client under consideration. The end of the last flow may correspond to the receipt of a FIN packet for a TCP based communication. From a high level perspective as the fiat value that is measured with respect to a last received flow increases the probability of receiving this flow again for this particular client decreases. Note that the concept of flow inter arrival time is related to the recentness measurement. But the pattern information that is used to compute the fiat value is gleaned from a larger amount of historical data compared to the recentness factor.

More specifically in one formulation f fiat 1 fiat with negative values clamped to zero. Here fiat fiat fiat fiat fiat . The fiatand fiatvalues are the largest and smallest respectively fiatvalues exhibited within a group of clients over an extended period of time with respect to the relatively large group of clients described above that is not limited to the clients in the candidate list . More generally this formulation uses historical fiat values to predict the behavior of the incoming instances of CEI. Note that when flow is open e.g. when a SYN packet has been observed but not a FIN packet the value of fiat is not used and therefore 0 and 1.

The above two types of cost functions are described by way of illustration not limitation. Additional types of cost functions can be developed to suit the characteristics of particular environments.

The cost functions can also be modified to take into consideration other factors such as priority levels associated with the candidate rules. For example some rules may have elevated priority levels because they target clients that have been repeatedly identified by reputation systems as being malicious. In other words these clients have high hit counts associated therewith. The cost function can also take into consideration whether each rule attempts to target a single IP address or multiple IP addresses e.g. by favoring the latter rule over the former in one case.

In other implementations the ranking of clients using a cost function can precede the generation of rules in block rather than following block . In this implementation the candidate rule production module would produce M rules to be sent to the filtering logic rather than N rules.

As a final point recall that the analysis system can add a first set of rules to the set of candidate rules that target specific clients that are detected by the client of interest assessment module . These clients may be regarded as original clients. The analysis system can add a second set of rules which target clients that are related to the original clients e.g. as identified by the correlation assessment module . These clients may be regarded as correlated clients. The cost function analysis was described above for application to individual original clients. It can also be applied to the correlated clients. In one approach for example each of a set of correlated clients is considered to possess the same characteristics as the original client to which it relates. For example a correlated client is given the same timestamp as its original counterpart client. Further the count of a correlated client is set to zero at the same time as the original client s count is set to zero. According to one interpretation a correlated client is considered to be engaging in an open transaction. The flow duration of a correlated client is based on the time duration between the time that this client was added to the candidate list and the current point in time.

As a related point note that the ranking has been described above in the context in which each rule targets a client under consideration. But any rule may be associated with a subnet. This kind of rule targets plural clients. In one implementation the analysis system can assign a score to a rule associated with a subnet by treating the entire subnet as akin to a single client entity under consideration. And hence the phrase client under consideration is to be broadly construed herein as any entity targeted by a rule which may refer to one machine or plural machines . For example the analysis system can compute the frequency factor for a rule associated with a subnet by counting how many instances of CEI were received from this subnet since the rule was added to the candidate list. In general however note that the above described manner of interpreting behavior associated with clients is presented by way of example not limitation as stated above other implementations can use other scoring techniques.

The computing functionality can include volatile and non volatile memory such as RAM and ROM as well as one or more processing devices e.g. one or more CPUs and or one or more GPUs etc. . The computing functionality also optionally includes various media devices such as a hard disk module an optical disk module and so forth. The computing functionality can perform various operations identified above when the processing device s executes instructions that are maintained by memory e.g. RAM ROM or elsewhere .

More generally instructions and other information can be stored on any computer readable medium including but not limited to static memory storage devices magnetic storage devices optical storage devices and so on. The term computer readable medium also encompasses plural storage devices. The term computer readable medium also encompasses propagated signals e.g. transmitted or received via physical conduit and or air etc. However the specific terms computer readable storage medium and computer readable storage medium device expressly exclude propagated signals per se while including all other forms of computer readable media.

The computing functionality also includes an input output module for receiving various inputs via input modules and for providing various outputs via output modules . Illustrative input modules include a keyboard device a mouse input device a touchscreen input device a gesture input device a voice recognition mechanism and so on. One particular output mechanism may include a presentation module and an associated graphical user interface GUI . The computing functionality can also include one or more network interfaces for exchanging data with other devices via one or more communication conduits . One or more communication buses communicatively couple the above described components together.

The communication conduit s can be implemented in any manner e.g. by a local area network a wide area network e.g. the Internet etc. or any combination thereof. The communication conduit s can include any combination of hardwired links wireless links routers gateway functionality name servers etc. governed by any protocol or combination of protocols.

Alternatively or in addition any of the functions described in the preceding sections can be performed at least in part by one or more hardware logic components. For example without limitation the computing functionality can be implemented using one or more of Field programmable Gate Arrays FPGAs Application specific Integrated Circuits ASICs Application specific Standard Products ASSPs System on a chip systems SOCs Complex Programmable Logic Devices CPLDs etc.

In closing the description may have described various concepts in the context of illustrative challenges or problems. This manner of explanation does not constitute an admission that others have appreciated and or articulated the challenges or problems in the manner specified herein. Further the claimed subject matter is not limited to implementations that solve any or all of the noted challenges problems.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

