---

title: Compiler driven mechanism for registration and deregistration of memory pages
abstract: A method, system and article of manufacture are disclosed for registering and deregistering memory pages in a computer system. The method comprises the steps of hoisting register and deregister calls in a given routine where temporal locality is present to overlap computation and communication; using software pipelined registration and deregistration where spatial locality is observed; and using intra-procedural and inter-procedural analysis by a compiler of the computer system to deregister dynamically allocated buffers. The preferred embodiment of the invention is based on an optimizing compiler. The compiler is used to extract information such as addresses of buffers which are being reused repeatedly (temporal locality), preferably in a loop. The compiler may also find information about spatial locality, such as arrays whose indexes are used in a well-defined manner in a series of messages, for example, array pages being accessed in a pre-defined pattern in a loop.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08612953&OS=08612953&RS=08612953
owner: International Business Machines Corporation
number: 08612953
owner_city: Armonk
owner_country: US
publication_date: 20120913
---
The present application is a continuation nonprovisional application claiming the priority of the filing date of the co pending and commonly assigned U.S. patent application Ser. No. 12 111 991 entitled A compiler driven mechanism for registration and deregistration of memory pages filed on Apr. 30 2008.

This invention generally relates to memory management in computer systems and more specifically to methods and systems for registration and deregistration of memory pages. The preferred embodiment of the invention relates to such methods and systems for use in multi node distributed computer systems that employ remote direct memory access to transfer data between the nodes.

An important factor in the performance of a computer or a network of computers is the ease or difficulty with which data is accessed when needed during processing. To this end direct memory access DMA was developed early on to avoid a central processing unit CPU of a computer from having to manage transfers of data between long term memory such as magnetic or optical memory and short term memory such as dynamic random access memory DRAM static random access memory SRAM or cache of the computer. Accordingly memory controllers such as DMA controllers cache controllers hard disk controllers and optical disc controllers were developed to manage the transfer of data between such memory units to allow the CPU to spend more time processing the accessed data. Such memory controllers manage the movement of data between the aforementioned memory units in a manner that is either independent from or semi independent from the operation of the CPU through commands and responses to commands that are exchanged between the CPU and the respective memory controller by way of one or more lower protocol layers of an operating system that operate in background and take up little resources time memory of the CPU.

However in the case of networked computers access to data located on other computers referred to as nodes has traditionally required management by an upper communication protocol layer running on the CPU of a node on the network. The lower layers of traditional asynchronous packet mode protocols e.g. User Datagram Protocol UDP and Transport Control Protocol Internet Protocol TCP IP which run on a network adapter element of each node today do not have sufficient capabilities to independently without host side engagement in the movement of data manage direct transfers of stored data between nodes of a network referred to as remote DMA or RDMA operations. In addition characteristics with respect to the transport of packets through a network were considered too unreliable to permit RDMA operations in such types of networks. In most asynchronous networks packets that are inserted into a network in one order of transmission are subject to being received in a different order than the order in which they are transmitted. This occurs chiefly because networks almost always provide multiple paths between nodes and some paths involve a greater number of hops between intermediate nodes e.g. bridges routers etc. than other paths and some paths may be more congested than others.

To support RDMA in pinning based networks for example Infiniband see Infiniband Architecture Specification Infiniband Trade Association 2004 Myrinet see Myricom Inc Myrinet http www.myrinet.com pages that need to be transferred from the sender to the receiver must have the source destination buffers pinned registered to physical memory for the duration of RDMA. Unpinning involves deregistering the memory at some later point of time after the transfer has completed mainly because of the fact that only a fraction of the actual physical memory can be pinned. But pinning unpinning registration deregistration pages in memory is a costly operation adding to the overhead of message passing interfaces like MPI see MPI A Message Passing Interface Standard MPI forum . As used herein the terms registration or pinning and deregistration or unpinning are used synonymously.

To address this overhead of pinning unpinning and enable better computation communication overlap in MPI based code various MPI implementations or layers underneath which are entrusted with the task of registering or deregistering pages may employ one of several solutions.

One approach is to restrict RDMA operations to a static memory region. This helps to register the memory region once and amortize this cost over a possibly large number of RDMA operations. But this approach restricts the application to a static memory region. For many applications this is inappropriate and forces the user to copy to from the registered memory. For larger messages copy costs quickly become a bottleneck. However this policy may still be applied to eager messages See High Performance RDMA based MPI implementation over Infiniband ICS 2003 J. Liu J. Wu S. Kini P. Wyckoff et al. .

Another approach is to register memory on the fly. The source and destination buffers are registered before the RDMA operation and then deregistered upon completion of transfer. This approach unfortunately has a high cost of registering the memory prior to each RDMA operation. A third approach is to maintain some sort of a cache. In OpenMPI implementation this is called a Rcache registration cache see Infiniband Scalability in Open MPI IPDPS 2006 Galen M. Shipman Tim S. Woodall Rich L. Graham Arthur B. Maccabe and Patrick G. Bridges . Once a new unregistered address is encountered and is entered in the cache subsequent accesses can avoid the overhead of registration. For applications which regularly reuse target and destination buffers exhibit temporal locality for RDMA operations the cost of the initial registration is effectively amortized over later RDMA operations. This approach was first available in MPICH GM.

The first two solutions are not generic or effective enough. Regarding the cache based solution in many instances even with a cache present registration deregistration overhead becomes unavoidable due to absence of temporal locality of the pages accessed in a message. For example when adjacent pages of an array are accessed in a loop this kind of situation may arise. OpenMPI has tried to overcome this problem partially for large messages by trying to pipeline the RDMA registering process see High Performance RDMA Protocols in HPC Euro PVM MPI Conf. 2006 Tim S. Woodall Galen M. Shipman George Bosilca and Arthur B. Maccabe . It breaks up a large message into several units and registers future chunks that will be sent as well as RDMAing the current chunks all at the same time. But shorter messages cannot be handled by this mechanism. Results reported see High Performance RDMA Protocols in HPC Euro PVM MPI Conf. 2006 Tim S. Woodall Galen M. Shipman George Bosilca and Arthur B. Maccabe show that the pipelined strategy works well for message sizes of 100K bytes or more. Also current registration deregistration implementations are synchronous resulting in more delay.

On the deregistration side the cache based strategy suffers from the usual cache eviction problem of when and what to deregister. In addition for dynamically allocated pages deregistration must happen before the pages are deallocated. This is difficult to do at run time because a program can deallocate either non registered or registered pages. The usual strategy is to rewrite allocation libraries like free etc. for deregistration so that during a free operation registration cache is checked to see whether the freed pages are present in the registration cache. This results in undue overhead and complications see Infiniband Scalability in Open MPI IPDPS 2006 Galen M. Shipman Tim S. Woodall Rich L. Graham Arthur B. Maccabe and Patrick G. Bridges . In Wyckoff et al. work has been done to address the deregistration issue for arbitrary allocation deallocation by providing for special register deregister functions dreg register dreg deregister that call a kernel module dreg. The register deregister functions are available in user space and the dreg module in the kernel keeps track of VM virtual memory allocations and deallocations. By setting up a polling signaling mechanism between the dreg module and the register deregister function the registration cache can be maintained consistently.

The major drawback of all the current strategies used to reduce the overhead of pinning unpinning is due to the implementation of the pinning unpinning by layers like MPI or ones below it. These layers do not have a view of the locality of the message pages accessed as can be observed at the higher abstraction level of a program.

An object of this invention is to provide a computer based strategy for registration deregistration of memory pages in a computer system.

A further object of the present invention is to provide a mechanism for registration deregistration of memory pages in a computer system based on analyzing message passing interface code at a high level.

Yet a further object of the invention is to register deregister memory pages in a computer system in a way that overlaps computation with the overhead of pinning and that also avoids re writing allocation libraries for deregistration.

These and other objectives are attained with a method system and article of manufacture for registering and deregistering memory pages in a computer system. The system comprises the steps of hoisting register and deregister calls in a given routine where temporal locality is present to overlap computation and communication using software pipelined registration and deregistration where spatial locality is observed and using intra procedural and inter procedural analysis by a compiler of the computer system to deregister dynamically allocated buffers.

The preferred embodiment of the invention is based on an optimizing compiler. The compiler is used to extract information such as addresses of buffers which are being reused repeatedly temporal locality preferably in a loop. The compiler may also find information about spatial locality such as arrays whose indexes are used in a well defined manner in a series of messages for example array pages being accessed in a pre defined pattern in a loop.

The preferred embodiment of the invention described in detail below effectively addresses a number of problems. For instance this embodiment of the invention helps to find out at a program level which pages are to be registered and deregistered well in advance of the actual usage. This has several advantages. First registration deregistration can now happen in an asynchronous thread helping in the overlap of computation and communication totally. Second this helps in measuring the amount of pages that need to be registered deregistered using compiler based profiling mechanisms which can be done easily when compared to library instrumentation . Such profiling can help in fine tuning the placement of registration deregistration calls.

Also with the preferred embodiment of the present invention deregistration for dynamically allocated pages becomes easier to handle. There is no need to change and trap free delete calls to find out whether certain pages need to be deregistered before they are freed. Also kernel changes are not required. Even programs that do not demonstrate temporal locality of accessed pages can be effectively registered deregistered using a compiler based approach which is similar to software prefetching. This is not possible using any of the current methods adopted.

Further benefits and advantages of this invention will become apparent from a consideration of the following detailed description given with reference to the accompanying drawings which specify and show preferred embodiments of the invention.

The network including nodes and switching network need not have a reliable connection or reliable datagram transport mechanism. Rather in the embodiments of the invention described herein RDMA can be performed in a network having an unreliable connection or unreliable datagram transport mechanism i.e. one in which packets of a communication between nodes e.g. a message are received out of the order in which they are transmitted. When the switching network includes a plurality of paths for communication between nodes and and the packets of that communication are transmitted over different paths it is likely that the packets will be received out of transmission order at least some of the time.

The nodes each include a processor not shown and memory not shown both of which are utilized for execution of processes which may also be referred to as tasks . As further shown in one or more tasks processes and are executing on nodes and respectively. Typically many tasks execute concurrently on each node. For simplicity the following description will refer only to one task per node. Task has access to the memory of the node on which it runs in terms of an address space assigned to the task. Similarly task has access to the memory of node on which it runs in terms of an address space assigned to that task.

Using RDMA represented at task running on node is able to read from and write to the address space of task in a manner similar to reading from and writing to its own address space . Similarly utilizing RDMA task running on node is able to read from and write to the address space of task also in a manner similar to reading from and writing to its own address space . For RDMA enabled processing each of the tasks and is a cooperating process such that for each task e.g. task at least some portion of its address space e.g. address space is accessible by another cooperating process. illustrates a two task example. However the number of cooperating processes is not limited for RDMA operations. Thus the number of cooperating processes can be any number from two processes to very many.

In master task on node is shown initiating an RDMA write operation to read data from the address space of task on node into its own address space labeled . The RDMA transport protocol enables this data transfer to occur without the active engagement of the slave task i.e. without requiring the an upper protocol layer operating on node to be actively engaged to support the RDMA data transfer to slave task .

The LAPI layer e.g. layer of protocol stack and layer of protocol stack provides a reliable transport layer for point to point communications. LAPI maintains state for messages and packets in transit between the respective node and another node of the network and re drives any packets and messages when the receiving node does not acknowledge them within an expected time interval. In operation the LAPI layer packetizes non RDMA messages into an output staging buffer of the node such buffer being illustratively a send first in first out herein SFIFO buffer maintained by the HAL hardware abstraction layer of the protocol stack . Typically HAL maintains one SFIFO and one receive FIFO herein RFIFO an input staging buffer for receiving incoming packets for each task that runs on the node. Non RDMA packets arriving at the receiving node from another node are first put into a RFIFO. Thereafter the data from the buffered packets are moved into a target user buffer e.g. address space used by a task e.g. task running on that node.

On the other hand for RDMA messages the LAPI layer uses HAL and a device driver to set up message buffers for incoming and outgoing RDMA messages by pinning the pages of the message buffers and translating the messages. The state for re driving messages is maintained in the LAPI layer unlike other RDMA capable networks such as the above described reliable connection or reliable datagram networks in which such state is maintained in the HAL adapter or switch layer. Maintenance of state by the LAPI layer rather than a lower layer of the stack such as HAL or the adapter layer enables RDMA to be conducted reliably over an unreliable datagram service.

The HAL layer e.g. layer of protocol stack on node and layer of stack on another node is the layer that provides hardware abstraction to an upper layer protocol ULP such ULP including one or more of the protocol layers LAPI and MPI for example. The HAL layer is stateless with respect to the ULP. The only state HAL maintains is that which is necessary for the ULP to interface with the network adapter on the particular node. The HAL layer is used to exchange RDMA control messages between the ULP and the adapter microcode. The control messages include commands to initiate transfers to signal the completion of operations and to cancel RDMA operations that are in progress.

The adapter microcode operating on a network adapter of a node is used to interface with the HAL layer for RDMA commands and to exchange information regarding completed operations as well as cancelled operations. In addition the adapter microcode is responsible to fragment and reassemble RDMA messages to copy data out of one user buffer for a task running on the node to adapter memory for transport to network and to move incoming data received from the network into a user buffer for the receiving task.

As mentioned above to support RDMA in pinning based networks memory pages that need to be transferred from the sender to the receiver must have the source destination buffers pinned registered to physical memory for the duration of RDMA. Unpinning involves deregistering the memory at some later point of time after the transfer has completed mainly because of the fact that only a fraction of the actual physical memory can be pinned. But pinning unpinning registration deregistration pages in memory is a costly operation adding to the overhead of message passing interfaces.

The present invention effectively addresses this overhead. Generally by analyzing message passing interface based code at a high level the present invention not only does a better job of registering pages early and thus completely overlaps computation with the overhead of pinning but also avoids re writing of allocation libraries for deregistration. This is done with the help of the knowledge of which pages are being deallocated and whether they have been registered earlier.

The preferred embodiment of the invention is based on an optimizing compiler. The compiler is used to extract information like addresses of buffers which are being reused repeatedly temporal locality preferably in a loop. It may also find information about spatial locality like arrays whose indexes are used in a well defined manner in a series of messages for example array pages being accessed in a pre defined pattern in a loop. The invention can be categorized into three sub areas a Hoisting Sinking of register deregister calls where temporal locality is present to overlap computation and communication b Using prefetching techniques for registration deregistration where spatial locality is observed once again for computation communication overlap and c Using intra inter procedural compiler analyses to effectively deregister dynamically allocated buffers. Each of these sub areas is discussed in detail below.

The case of temporal locality or the same buffer address being used a number of times in a loop is a prime target for registration hoisting. We can carry out the registration of such addresses only once outside the loop and deregister the addresses if required once the loop exits. To support this a user level mechanism is provided for registration or deregistration of pages that is visible to a tool like the compiler. These compiler visible functions are referred to herein as REGISTER and DEREGISTER respectively. Currently strict structures are not imposed on these functions. The only requirement is that these functions accept a variable argument list of memory pages that can be registered deregistered. Many vendors who support message passing interfaces will be able to supply these two functions without much difficulty.

The advantages of the preferred compiler based registration deregistration mechanism are several. First if the REGISTER DEREGISTER functions are invoked asynchronously then the registration deregistration overhead can be easily overlapped with other computation. This is not possible with any runtime mechanism as some amount of startup overhead is always realized on first time registration even if messages used pipelined registration technique . Second the preferred embodiments can register deregister memory pages that do not exhibit temporal locality but exhibit spatial locality using a form similar to software pipelining. Third deregistration for allocated buffers become easier as noted earlier.

The following example discussed with reference to is from BT which is a benchmark in the NAS Parallel Benchmark Suite NPB . The file involved is x solve.f. Similar code can be found in y solve.f and z solve.f.

In the subroutine x solve mpi irecv isends are invoked via calls to the routines x send receive  solve info and x send receive  backsub info. In each of these cases either a in buffer out buffer is used and the same address continues to be used in the entire do loop both for the first do loop as well as the second loop. Hence the registration deregistration of these buffers can be hoisted out of the respective do loops. This is denoted by the REGISTER DEREGISTER functions which may be special user level calls that can be invoked by the compiler and inserted at places of interest. Here the places or labels of interest are denoted by numbers 1 to 8 in . However it can be observed that the DEREGISTER functions at labels 3 and 4 can be moved before 7 and 8 because delayed deregistration is better while the REGISTER functions at labels 5 and 6 can be moved after the labels 1 and 2 as early registration works better for computation communication overlap. This will allow the four REGISTER functions at the top to be merged to two based on the in buffer and out buffer.

Similarly the DEREGISTER functions at the end can be merged to create two functions one for the in buffer and the other for the out buffer Label 1 and Label 2 in . The approximate signature of a REGISTER DEREGISTER function accepts a series of in buffer addresses as input for registration deregistration. However this is not mandatory. In such a case the eight calls can remain as separate standalone calls at the top four of them and at the bottom four of them for the x solve subroutine.

The register deregister functions can be hoisted higher if possible. Since x solve y solve and z solve all exhibit similar characteristics each of them creates two REGISTER and two DEREGISTER calls each by applying the same logic as above see . These calls have been hoisted out of the respective x solve y solve and z solve into the subroutine adi which invoke them as shown in . After merging all the REGISTER DEREGISTER calls can be moved to the start end of the subroutine adi as shown. The subroutine adi is invoked in a loop in the main program and the calls can be hoisted outside of this loop too.

It can be seen that by hoisting sinking the registration deregistration enough window is created for subsequent overlap of these calls by invoking these calls in a synchronous manner. The only issue that can arise with aggressive hoisting sinking is the creation of extra pinning pressure due to a limit on the number of pages that can be pinned simultaneously. This can be taken care of in the compiler using a profile driven approach whereby profiles of how many pages get registered deregistered can be tracked for each call. Hoisting sinking can be controlled based on this profile.

This algorithm and the subsequent ones discussed below assumes the existence of a standard optimizing compiler like IBM s XL which has the infrastructure for some of the analyses employed here. The algorithm also assumes that as noted earlier two user level functions called REGISTER . . . and DEREGISTER . . . are made available for example by vendors implementing message passing interfaces for pinning based networks.

This technique software pipelined registration is derived from software prefetching carried out in the compilers so that data that will be accessed in the future can arrive ahead of use. Software prefetching can have an arbitrary spatial window as opposed to hardware centric techniques and perform well for regular spatial accesses like arrays. Software based prefetching using helper threads for dynamic code has also been carried out with good results.

Consider a case in MG mg.f from the NAS Parallel Benchmark Suite . The code snippet involves a call to mpi allreduce. In this case the buffer is not constant because jg 0 i 1 is used in each call to mpi allreduce. For such cases we can derive what buffer addresses will be used in future iterations and these buffers can be registered early using a different thread preferably . The current techniques employed by various MPI implementations of caching registered pages will not be able to exploit such cases as the same address is not used in successive iterations. Even pipelining techniques proposed in OpenMPI for registering pages for large messages will not be able to utilize the regular page access patterns as noted here in .

The central idea of software pipelined registration is to register ahead a page or a set of pages of the buffer to be used in a future iteration or a set of iterations . This can help in overlapping computation of a current iteration with the communication overhead of a future iteration if the registration deregistration can be carried out asynchronously.

Dynamically allocated pages pose a difficult problem for deregistration. In accordance with the preferred embodiment of the invention the compiler is used to track allocated pages that need to be de registered. Before they are deallocated de registration function is called that cleans up the registration cache or anything similar in an appropriate manner. This also avoids changing any kind of library routines to trap for de registration as suggested above or use any modification in the kernel.

Consider a simple case where a buffer is used and subsequently deallocated see . In this case before the deallocation is activated via the free call we can actually deregister the relevant pages using a list of start addresses and lengths respectively. This information of which parts of the buffer have been registered earlier can be captured in triplets of the form noted above by the compiler using inter intra procedural analyses. If they had been executed under conditional code that information can also be carried. This information is passed inter procedurally in this case from bar and car to foo and is used before the relevant free call for de registration. For non trivial cases we will also need the alias points to set of the buf to find out its aliases and capture all the registration triples correctly.

The preferred embodiment of the invention provides a number of important advantages. For example a compiler based registration deregistration strategy may allow greater flexibility in overlapping computation and communication as the registration overhead incurred as part of communication in RDMA based networks can be effectively overlapped. This is possible if registration can be hoisted or issued early in an asynchronous manner. Techniques like software prefetching can be employed for early registration in cases where the accesses demonstrate spatial locality instead of temporal locality. Complexities involved in tracking memory related calls for deregistration may also be avoided by following a compiler based procedure that deregisters the relevant pages by utilizing intra and inter procedural knowledge.

As will be readily apparent to those skilled in the art the present invention can be realized in hardware software or a combination of hardware and software. Any kind of computer server system s or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software could be a general purpose computer system with a computer program that when loaded and executed carries out the respective methods described herein. Alternatively a specific use computer containing specialized hardware for carrying out one or more of the functional tasks of the invention could be utilized.

The present invention or aspects of the invention can also be embodied in a computer program product which comprises all the respective features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program software program program or software in the present context mean any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation and or b reproduction in a different material form.

While it is apparent that the invention herein disclosed is well calculated to fulfill the objects stated above it will be appreciated that numerous modifications and embodiments may be devised by those skilled n the art and it is intended that the appended claims cover all such modifications and embodiments as fall within the true spirit and scope of the present invention.

