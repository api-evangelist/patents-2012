---

title: Zone based presence determination via voiceprint location awareness
abstract: A speech from a speaker proximate to one or more microphones within an environment can be received. The microphones can be a directional microphone or an omni-directional microphone. The speech can be processed to produce an utterance to determine the identity of the speaker. The identity of the speaker can be associated with a voiceprint. The identity can be associated with a user's credentials of a computing system. The credentials can uniquely identify the user within the computing system. The utterance can be analyzed to establish a zone in which the speaker is present. The zone can be a bounded region within the environment. The zone can be mapped within the environment to determine a location of the speaker. The location can be a relative or an absolute location.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09401058&OS=09401058&RS=09401058
owner: International Business Machines Corporation
number: 09401058
owner_city: Armonk
owner_country: US
publication_date: 20120130
---
The present invention relates to the field of presence determination and more particularly to zone based presence determination via voiceprint location awareness.

Locating personnel within large facilities e.g. workplaces is becoming increasingly important to daily business operations. Operations can often include organizing meetings securing resources and coordinating personnel activities. For example high rise office buildings e.g. multi story offices often house many company divisions within a single building which can include hundreds of personnel distributed over many floors. Frequently managing business operations within these large facilities can be daunting. That is as ubiquitous computing e.g. mobile computers allows the personnel to move freely within these large facilities determining the location e.g. presence can be time consuming and difficult. Facilities which lack presence solutions often resort to manual coordinating efforts such as contacting personnel directly to determine the personnel location. These manual efforts can reduce productivity and frequently result in frustration of personnel attempting to conduct business operations.

Alternatively facilities can be outfitted with traditional presence solutions. Traditional presence solutions frequently rely on Radio Frequency Identification RFID Ultrasound Wireless Fidelity WiFi Global Positioning System GPS and other technologies to determine personnel location. These solutions typically involve using a uniquely identified tag which must be worn by personnel e.g. authorized persons visitors residents etc. for presence systems to recognize and identify the personnel s location. Drawbacks of this system often include inaccurate association of tags to individuals cost of acquiring tags for individuals within a facility limited battery life of tags lost tags replacement expenses of lost tags and inconsistent usage of tags. These drawbacks can quickly create significant hurdles to adopting invaluable presence technologies within these large facilities.

One aspect of the present invention can include a system an apparatus a computer program product and a method for zone based presence determination via voiceprint location awareness. A speech from a speaker proximate to one or more microphones within an environment can be received. The microphones can be a directional microphone or an omni directional microphone. The speaker can be a person. The speech can be processed to produce an utterance to determine the identity of the speaker. The identity of the speaker can be associated with a voiceprint. The identity can be associated with user credentials of a computing system. The credentials can uniquely identify the user within the computing system. The utterance can be analyzed to establish a zone in which the speaker is present. The zone can be a bounded region within the environment. The zone can be mapped within the environment to determine a location of the speaker. The location can be a relative or an absolute location.

Another aspect of the present invention can include a method an apparatus a computer program product and a system for zone based presence determination via voiceprint location awareness. A speech engine can be configured to determine the location of a speaker within an environment based on a received speech utterance. The utterance can be received from one or more microphones proximate to the speaker. The location can be one or more zones within the environment. The utterance can be matched to a voiceprint. The voiceprint can be associated to a speaker identity. A data store can be able to persist one or more voiceprints associated with a speaker identity and a mapping. The speaker identity can be associated with a user credential of a computing system. The mapping can associate one or more zones with the environment.

The present disclosure is a solution for zone based presence determination via voiceprint location awareness. In the solution an array of microphones distributed throughout an environment e.g. facility can be utilized to establish a speaker e.g. personnel presence within the facility. In one embodiment a microphone can be placed into each room of the facility where each microphone location can be mapped to a zone of the facility. In the embodiment when the microphone detects speech from a speaker a voiceprint associated with the speaker can be utilized to uniquely identify and locate the speaker within a zone. The disclosure can perform voiceprint creation speaker identification speaker verification presence determination and the like. In one embodiment the disclosure can be a current Real Time Location Service RTLS lacking tracking devices. In one configuration of the embodiment the RTLS can be capable of automatically reacting to speech from personnel even when personnel voiceprints have not been registered with the service.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction processing system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction processing system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing. Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions.

These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

As used herein environment can be a built environment providing the setting for personnel e.g. speaker activity. Environment can include but is not limited to a building a neighborhood a city a geographically bounded region and the like. For example environment can be a college campus. In one embodiment environment can be divided into one or more zones e.g. Zone A . A zone can logically and or physically separate portions of environment .

Room can be a distinguishable space within an environment . Room can include but is not limited to a room e.g. room a passageway a public area and the like. Room can include microphone which can be a fixed or movable microphone. Microphone can include but is not limited to a single microphone multiple communicatively linked microphones multiple independent microphones and the like.

In one instance microphone can be a component of an audio video device. For example microphone can be a microphone associated with a security camera. Microphone can detect speech from a proximate speaker . Speaker can be an individual proximate to microphone producing speech . Speech is a vocalized form of communication which can be received by microphone . Speech can include traditional language constructs including but not limited to sentences words syllables and the like. That is speech can include isolated words connected words and continuous speech. Speech can include but is not limited to one or more languages. It should be appreciated that speech can be directed at microphone and or indirect e.g. ambient noise . For example speech can include a speaker within room communicating with another person within the room.

Microphone can convey speech to speech engine . Engine can process speech into one or more utterances . Utterance can be a complete unit of speech in spoken language. Utterance can be associated with one or more attributes including but not limited to pitch style loudness and the like. That is utterance can be an artifact of a speech recognition process. Combining speaker identity with utterance engine can produce voiceprint .

Voiceprint can be a unique data set associating a speech e.g. utterance with a speaker identity e.g. user credentials . In one embodiment voiceprint can be a time varying spectral representation of a speech signal. In the embodiment the signal can be utilized to uniquely identify a speaker. For example voiceprint can be a speech behavioral biometric utilized within a computing security system. Voiceprint can include but is not limited to utterance spectrogram user credentials and the like. Voiceprint can include a single unique voiceprint multiple voiceprints and the like. Voiceprint can include but is not limited to a template a speech model e.g. Hidden Markov Model and the like. It should be appreciated that utterance stored within voiceprint can include utterance attributes e.g. speaker dependent characteristics . In one embodiment user credentials associated with voiceprint and can be utilized to determine a speaker identity.

In speaker verification a previously established voiceprint can be utilized to verify the identity of a speaker . In speaker verification a verification action can be performed on speech and voiceprint . Verification can include decoding speech matching speech to a voiceprint and the like. In one instance engine can compare utterance attributes of speech with utterance attributes associated with voiceprint . It should be appreciated that verification can be arbitrarily complex and can utilize one or more rulesets settings and the like. That is verification can be a robust and extensible allowing the disclosure to be adapted to a wide variety of implementations.

When a speech matches a voiceprint the speaker identity can be determined through use of user credentials associated with voiceprint . When a speech does not match a voiceprint the speaker identity can be set to a guest identity. In one instance the guest identity can be manually assigned to a registered user of a system e.g. system when credentials are manually provided. In another instance the guest identity can be automatically assigned to a registered user of a system e.g. system when the speaker interacts with devices which automatically provide credentials to the system.

In presence determination mapping can enable zone based presence determination of speaker . Mapping can associate a microphone e.g. microphone A with a location e.g. Zone A . Speech from speaker can be received by microphone and can be communicated to engine . Engine can utilize mapping to identify the microphone which received speech and determine speaker location. For example microphone A can be identified via unique device identifier which can be associated with a Zone A.

Engine can generate presence information which can be data associated with a speaker location. Presence information can include but is not limited to location map and the like. In one instance information can include a status indicator conveying the availability of speaker . Location can be an absolute location and or a relative location. For example when a speaker is proximate to microphone e.g. microphone A but is not within room e.g. Zone A a relative location e.g. near Zone A can be established. Map can be a graphical element conveying the location of speaker within environment . For example map can be a floorplan of a building indicating speaker is in Zone A e.g. room . Map can show one or more speakers and appropriate locations which can be tracked by the disclosure. In one instance map can show historic locations of a speaker permitting visual tracking capabilities.

In one embodiment the disclosure can enable zone based presence determination of multiple speakers simultaneously. In another embodiment the disclosure can facilitate presence tracking of one or more speakers. It should be appreciated that the environment configuration described within scenario can be an exemplary setup. The disclosure can support multiple microphones within a single zone multiple zones each equipped with multiple microphones and the like.

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. It should be understood that stages can be optional providing that the disclosure functionality is maintained. It should be appreciated that speaker identity can be manually provided to engine . In one instance speaker interacting with a computing system login process can manually input identity . In the instance user credentials can be validated and a speaker identity can be determined. It should be understood that although scenario describes a zone based presence determination capability the disclosure is not limited in this regard. Further the disclosure can be extended to provide presence determination capabilities for multiple environments . It should be appreciated that the engine can be a text independent speech processor but can support text dependent implementations.

In step a speech can be received from one or more microphones within an environment. For example a conference room can be equipped with an array of microphones which can be utilized to obtain speech from a speaker. In step the speech can be analyzed to determine an appropriate utterance. Analysis can include but is not limited to signal processing speech decoding normalization and the like. The analysis can produce an utterance which can include phenomes words and the like. The utterance can be a data model such as a vocabulary. In step a voiceprint can be selected. In step the utterance can be matched against the selected voiceprint and a matching score can be generated. The matching score can be a numerical value a fuzzy logic value and the like. For example score can be a numerical value such as a percentage. In one embodiment matching score can be a confidence value indicating the likelihood a positive validation has occurred.

In step score can be evaluated against a threshold value. The threshold value can be manually and or automatically established. Threshold value can be a numeric value a fuzzy logic value and the like. In one instance the threshold value can be a ruleset which can permit programmatic actions to be triggered from the evaluation. In the instance the ruleset can permit sophisticated logic to be established based on the result of the evaluation. For example when the score is lower than the threshold value a notification can be conveyed to an administrator indicating the detection of a guest within the environment. When the evaluation results in failure the method can continue to step else proceed to step . In step if there are more voiceprints to match the method can return to step . It should be appreciated that the method can support multiple voiceprints for a speaker. In one embodiment when step is repeated an alternative voiceprint associated with a speaker identity can be selected and steps can be performed. In the embodiment the steps can be run until all voiceprints are exhausted or a match occurs.

In step a guest voiceprint can be generated from the utterance and guest credentials can be assigned. A guest voiceprint can be generated using similar processes described within voiceprint creation of scenario . Guest credentials can be assigned manually and or automatically. In step user credentials can be determined. Credentials can be determined based on one or more rulesets settings and the like. In one instance credentials can be automatically obtained from an authentication system. In step speaker location can be established utilizing an environment mapping. In step resource privilege assessment can be optionally performed based on speaker location. In one instance the method can be a process of a presence based security system. In the instance when speaker location is determined a security action e.g. granting access to a resource can be enacted. For example when a speaker is proximate to a locked door associated with a secure area the method can be utilized to automatically unlock the door. In step the method can end.

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention in any regard. Method can be performed in real time or near real time. Steps within method can performed in serial and or in parallel. One or more steps can be optional permitting method functionality is retained.

In one embodiment system can be a drop in solution for presence determination within an existing computing infrastructure. For example engine can be a plug in component of a presence server application. In another embodiment system can be configured to be integrated with an existing presence system to enhance and or extend presence system functionality.

Presence server can be a hardware software element able to accept store and or distribute presence information e.g. presence information . Server can include but is not limited to speech engine mapping voiceprint data store interface and the like. Server can communicate with presentities watchers services and the like. In one embodiment server can be a component of a unified communications system. In the embodiment server can be an IBM LOTUS SAMETIME server.

Speech engine can be a hardware software entity able to receive speech identify speaker validate speaker and or determine speaker location. Engine can include but is not limited to utterance processor verification engine locator settings and the like. Engine can be a networked computing element distributed computing element and the like. In one instance engine functionality can be a portion of a Web service. In another instance engine functionality can be a capability of an Application Programming Interface API .

Utterance processor can be a hardware software component configured to process speech . Processor functionality can include but is not limited to voice recognition speech recognition speech coding speech recording speech playback normalization e.g. cepstral normalization and the like. Processor can include one or more statistically based speech recognition algorithms. For example processor can utilize acoustic modeling and or language modeling to process speech . It should be appreciated that processor can include traditional and or proprietary speech recognition technologies. In one instance processor can be utilized to create voiceprint . In the instance processor can utilize traditional and or proprietary technologies to process and or store voiceprint . Technologies can include but is not limited to frequency estimation Hidden Markov Models HMM Gaussian mixture models pattern matching algorithms neural networks matrix representation Vector Quantization decision trees and the like. It should be appreciated that processor can utilize anti speaker techniques including but not limited to cohort models world models and the like.

Verification engine can be a hardware software element for identifying and or verifying speaker . Engine functionality can include directory service communication credential verification speaker recognition and the like. Engine can perform verification actions including but not limited to template matching ruleset evaluation and the like. Verification engine can perform directory service assisted actions including but not limited to directory creation e.g. guest directory credential creation e.g. enrollment and the like.

Locator can be a hardware software component configured to perform presence determination of speaker based on speech . Locator functionality can include but is not limited to presence determination presence tracking presence information distribution and the like. Locator can be utilized to create and or manage table . Locator can update table in response to determining that speaker s location has changed. In one instance locator can be an optional component of speech engine . In the instance locator can be an external presence component e.g. unified communications presence engine communicatively linked to engine .

Settings can be one or more configuration options for establishing the behavior of system and or server . Setting can include but is not limited to utterance processor options identity engine settings locator options and the like. Settings can be manually and or automatically configured. In one instance settings can be heuristically determined from communicatively linked presence systems. In one instance settings can be presented within interface . In the instance settings can be managed and or configured utilizing traditional and or proprietary interface mechanisms.

Mapping can be a data set linking sensor e.g. microphone to a zone within environment . Mapping can be manually and or automatically established. Mapping can be dynamically updated when changes to environment zone and or sensor occurs. In one instance mapping can be managed via one or more user interfaces.

Voiceprint can be stored within server engine data store and the like. In one embodiment voiceprint can enable multiple language support. In the embodiment voiceprint can include multiple language voiceprints for a single speaker. It should be appreciated that voiceprint can be associated with one or more security mechanisms. Voiceprint can be associated with speaker characteristics.

Data store can be a hardware software component able to persist tracking table mapping voiceprint map and the like. Data store can be a Storage Area Network SAN Network Attached Storage NAS and the like. Data store can conform to a relational database management system RDBMS object oriented database management system OODBMS and the like. Data store can be communicatively linked to server in one or more traditional and or proprietary mechanisms. In one instance data store can be a component of Structured Query Language SQL complaint database. In another instance data store can be a portion of a speech database.

Tracking table can be a data set for enabling presence accounting for one or more speakers . Table can include but is not limited to presence information voiceprint information credentials and the like. In one instance system can enable presence tracking via tracking table which can include presence information about one or more speakers . In another instance tracking table can employ historic locations of speaker to forecast subsequent speaker location. It should be appreciated that table is presented for exemplary purposes only and should not be construed to limit the invention in any regard.

Presence information can include location information timing information e.g. date time an environment map and the like. Presence information can be communicated to one or more components within system . In one instance information can be conveyed to components of a unified communications system. In the instance information can be delivered to presence aware applications e.g. Instant Messenger conferencing application etc .

Interface can be a user interactive component permitting interaction and or presentation of map . Interface can be present within the context of a Web browser application a desktop application and the like. In one embodiment interface can be a screen of an IBM LOTUS SAMETIME application. Interface capabilities can include a graphical user interface GUI voice user interface VUI mixed mode interface and the like. In one instance interface can be communicatively linked to computing device e.g. client device .

Map can be a data set for presenting speaker presence information. In one instance map can be dynamically generated on request. In another instance map can be persistent and can be continually updated during system runtime. In one embodiment map can be a graphically interactive map permitting interaction with presence information associated with a speaker.

Directory server can be a hardware software component for storing organizing and providing access to information within user directory . Server can include traditional and or proprietary implementations. In one instance server can be an IBM LOTUS DOMINO server. Server can include but is not limited to user directory server settings and the like. User directory can be a data set utilized for authenticating and authorizing of users e.g. speaker . Directory can include but is not limited to credentials access permissions and the like. Credentials can be associated with a user profile user data and the like.

Sensor can be a device able to detect proximate speech from speaker . For example sensor can be an acoustic to electric transducer. Sensor can be a dynamic microphone piezoeletric microphone fiber optic microphone and the like. It should be appreciated that sensor can be a wired device and or wireless device. Sensor can include but is not limited to a fixed sensor a movable sensor and the like.

Network can be an electrical and or computer network connecting one or more system components. Network can include but is not limited to twisted pair cabling optical fiber coaxial cable and the like. Network can include any combination of wired and or wireless components. Network topologies can include but is not limited to bus star mesh and the like. Network types can include but is not limited to Local Area Network LAN Wide Area Network WAN VPN and the like. Network can include but is not limited to an Internet intranet extranet and the like.

In one embodiment system can adapt voiceprints e.g. speaker models after each successful verification to capture long term changes in the voice of a speaker. For example a speaker s voice can change due to ageing which can affect speech .

Drawings presented herein are for illustrative purposes only and should not be construed to limit the invention any regard. System can employ traditional and or proprietary technologies. System can utilize traditional and or proprietary protocols. Protocols can include but is not limited to Hypertext Transport Protocol HTTP Transport Control Protocol TCP Internet Protocol IP Lightweight Directory Access Protocol LDAP Real time Transport Protocol RTP Extensible Messaging and Presence Protocol XMPP and the like. System can conform to a networked computing environment distributed computing environment cloud computing environment and the like. In one instance system architecture can be a Service Oriented Architecture.

It should be appreciated that system implementation details can vary based on deployment requirements and or limitations. For example system can be utilized for state and or national public safety security associated correctional facilities automated attendance monitoring assisting investigations e.g. confirming alibis law enforcement activities e.g. locating perpetrators and the like.

The flowchart and block diagrams in the illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be run substantially concurrently or the blocks may sometimes be run in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

