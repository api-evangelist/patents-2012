---

title: Capture and transmission of media files and associated metadata
abstract: A method and a system of associating correlating metadata with data assets, such as video and audio files, so that the files are rendered as a combination presentation are described herein. The system includes a client a media capture device that provides on board storage, network connectivity, preprocessing, preview buffering, file management, and an eventing system. The method includes capturing the media, associating the media with other media via an identifier, and supports associating correlating metadata prior to time of media capture and during media capture on the capture device itself, and after media capture either on a local machine or on an on-line group. When the combination presentation is presented, additional associated advertising and annotations may be provided upon rendering.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09214191&OS=09214191&RS=09214191
owner: WHP Workflow Solutions, LLC
number: 09214191
owner_city: North Charleston
owner_country: US
publication_date: 20121006
---
This patent application is a continuation application of U.S. Pat. No. 8 311 983 entitled Correlated Media for Distributed Sources issued on Nov. 13 2012 which claims priority to U.S. provisional patent application Ser. No. 61 173 459 filed on Apr. 28 2009 both of which are incorporated by reference herein.

This subject matter of the present application relates to aggregating and correlating distributed media.

Media data comes in many forms including but not limited to video audio still images and text. Presently media data is captured that is recorded and stored on a storage media that is dependent on the form of media data. For example video is captured by video cameras audio is captured via microphone and recorders and still images are captured by cameras.

Currently video cameras and digital recorders are used for a wide range of applications. While the use of video cameras and digital recorders is typically associated with personal events. There are many applications of the use such devices for commercial purposes including security and surveillance. For example police car video cameras are used to record stop encounters.

As described above more than one form of media may be used to capture an event. For example a security camera and a digital audio recorder may capture both video and audio data respectively from a crime scene. Afterwards a police officer or security supervisor may add text captions to the video using computer based software or on camera functions. Combining different forms of media for presentation is termed multimedia and accordingly there may be multimedia capture of security events and crime scenes.

Presently captured media is most commonly stored as digital data thereby becoming a data asset. Digital data assets may be streamed to users or consuming devices in real time or may be captured and later transported as a file for streaming.

The consumer electronics revolution has made digital video cameras digital still cameras and digital recorders ubiquitous. Accordingly commoditized video cameras and digital recorders have become available for security applications. Digitization and miniaturization has led to the production of video cameras that can fit in a mobile phone with ever improving resolution. Further the advent of commoditized compact memory has enabled large amounts of video data to be stored in such devices in a cost effective manner. As of this writing 16 gigabytes GB of storage space can store 40 hours of video data with average resolution. Accordingly large amounts of digital data assets may be captured from many different sources and in many different media. Furthermore the individuals that capture a security event or crime scene with a camera or recorder need not necessarily be related. For example at a crime scene there may be surveillance cameras that were stationed in the area long before the scene there may be police officers with mobile cameras and recorders and another police officer taking still shots with a digital camera.

With the Internet digital data assets may be shared in both in edited and non edited form. In the past files were shared simply by transferring peer to peer such as e mailing files or uploading to a LAN based server. Later digital data assets were posted and distributed via web pages via internet protocols. Currently police officers and security personnel can post and distribute digital data assets to a centralized location via web services with facilities to search and tag on posted assets. In this way different recordings of the same crime scene might be aggregated to help solve a crime case regardless of who originally captured or uploaded the digital asset.

In general there is presently a critical mass of digital data assets that can be correlated and combined together. For example panoramic software can stitch together different still photos taken at the same time of the same event and result into a single photo. Different video and audio feeds may be mixed together to make a composite rendering. However such efforts are typically manual in nature and use relatively short media clips.

At present automating the correlation and combination of multimedia of relatively large long data assets such as those hundreds or thousands of hours in length is not done. Moreover recording metadata to aid in correlating the data assets with other data assets is not presently done. Finally using such correlating metadata to automate correlations of data assets into a combination presentation is not presently done.

The embodiments described herein relate to a comprehensive system to store data assets associate correlating metadata share data assets in either a peer to peer manner or via a web service or equivalent retrieve data assets and present data assets either singularly or in various combinations.

Method embodiments described herein may include associating an identifier along with correlating metadata such as date timestamp and location. The identifier may then used to associate data assets that are related to a particular incident. The identifier may be used as a group identifier on a web service or equivalent to promote sharing of related data assets. Additional metadata may be provided along with commentary and annotations. The data assets may be further edited and post processed. The data assets may be then presented either singularly or in various combinations either locally or in a custom application. A custom application may be hosted at a network operation center as well with capabilities of directing collection of data assets.

System embodiments described herein may include a mobile client that is based on a modified cell phone. The mobile client may include video cameras and other media recording capabilities location service functionality such as global positioning system GPS functionality and full networking capabilities. The mobile client may also support a preview mode by which the video camera captures not only an incident at the time of recording starting but also several seconds of video preceding the event as stored in a preview buffer. The mobile client may further include a custom charger in the form of inductance coils and a file manager that provides file system capabilities specific to a mobile device. Even further the mobile client may include a tamper proof chassis and optional features for physical secure storage.

The mobile client hardware may be exposed to application software via an eventing system that allows programmers to add event handlers for custom software events. The system as disclosed may also include end to end applications covering use of external advertising and annotations and tools.

The embodiments described herein pertain to methods systems and apparatuses for capturing digital media as data assets associating correlating metadata with those assets and retrieving and correlating data assets at least partially based on the correlating metadata. In this way the task of correlating disparate data assets into a coherent combination may be automated.

There are many different types of combinations of data assets. Such combinations may be of similar media as in making a panoramic composite photo by stitching together different digital photos. Further such combinations may be of different media such as adding a custom audio track to a video. Such combinations may even be of the same context such as providing different views of the same police fire and or security incident. In extreme situations different contexts may be combined such as with a mashup. Such combinations need not be composites and may be presented as various different correlated media assets displayed side by side or as combined into an integrated whole.

To support automating such a varied range of combination presentations the embodiments described herein allow a rich range of correlating metadata to be associated with a data asset. When two or more data assets are to be combined as a composite or otherwise the metadata may provide a referent by which each data asset may be correlated. Common metadata may includes but is not limited to date time stamp and location metadata.

For example a video clip may have date time information stored for each frame and an audio clip may have date time information stored for each track segment. The video clip and the audio clip may be combined into a multimedia presentation by correlating the date time stamps of the two files. In this case the correlation is a synchronizing of the two files and the presentation is a composite of the two files. Of course the number of such files that may be so combined is not limited to just two.

Correlation can be based on multiple metadata values. For example multiple still photos might be stored not only with date time stamp metadata but also with location metadata possibly from a global positioning satellite GPS stamp. A software tool that collects all stored still photos taken within a window of time for example during a security or police response to a crime incident and close to the scene of a crime may combine the photos of the incident into a sequence of pictures with which for investigation purposes. Here the correlation is both by time and location and the presentation is a non composite simultaneous display of different data assets.

Correlating metadata can be based on a set of custom fields. For example a set of video clips may be tagged with an incident name. Consider three field police officers each in a different city and in a different time zone recording videos and taking pictures at exactly at midnight on New Year s Day 2013. Each officer might tag their videos and their still photos with New Year s Day 2013 Security Watch . A software tool may collect all stored videos with that tag and may further provide a presentation rotating between the videos and photos for the event. Here the correlation is made using a custom tag is not specific either to time or location and is a non composite display of different data assets.

This degree of flexibility means that correlations can be both by absolute referent and by relative referent. Most incidents occur at an absolute time and location and incidents may occur at different locations such as a bank robbery occurring at a bank and a breaking and entering at a power main to shut off the power to enable the robbery . Another example would be the security of an event over multiple locations such as the election or Olympics which are held at different venues in a city or different cities. In other situations incidents such as a high speed chase may span multiple counties. The above is a correlating example of synchronizing video and audio by means of a relative referent whereby the time stamp need not be of absolute time but could potentially be synchronized to the beginning of the data clips. The above example of the New Year s Day event is an extreme example of correlating by a relative referent. The New Year s Day 2013 Security tag is arbitrary and correlates data assets without regard to traditionally absolute referents of date time and location. This example is also known as date time shifting and location shifting.

In this exemplary platform event is to be captured by recording devices each of which is to capture some part of event as represented by scopes respectively. The data captured by the respective scopes may be uploaded in the form of files to a web service by users with accounts that can transfer files from their respective devices . The web service groups users into groups e.g. users with accounts belong to group . Note that device can be associated with multiple user accounts and . Note that the user with account does not have a device but can still participate in a group. The users thus organized can store the data assets into a central storage . The user with account which does not belong to group may potentially belong to any number of other groups on the web service or alternatively may join group . The user with account may have devices not shown and upload to the central storage . Users and with accounts and respectively may log on later to tag comment annotate or otherwise associate metadata with the uploaded files. The following discussion describes this configuration in more detail.

Event may represent the capture of any set of media data. Usually an event consists of a discrete real world event such as a crime incident. However some users may wish to combine different events in different locales and time zones. These different events may not even have any context in common save for a user s preferences. For example a police supervisor may be looking for patterns of assaults in a jurisdiction. Each individual assault was perpetrated independently but studying the aggregate data the police supervisor may detect areas of high risk.

An event can be captured by one of many commonly available devices . Exemplary devices include but are not limited to video cameras digital audio recorders or digital still cameras. Another example of a recording device might be a laptop that stores GPS samples or other location service samples to track location. Devices may record data in analog format but then convert the data to digital format later for sharing. Devices may further have the capability of capturing different types of media at the same time. For example a video recorder usually captures video and audio at the same time. Alternatively many digital cameras support both video and still modes of capture. Notwithstanding the many features of present day devices usually a single device at best can only capture a subset of an event as represented by scopes . Each scope only covers a subset but a combination of the scopes may provide a more complete capture of the event.

Devices may generally store captured media either as files or stream the captured media to a remote device that will persist the data. Eventually the captured media may be stored as a digital data asset usually as a file. In the alternative data may be persisted on analog tape.

Devices may have the ability to associate metadata either before capture or at time of capture. For example the respective devices may provide for a user to provide a default tag for all files such as camera identifier ID . During capture the respective devices may store data time stamp information or location service tracking location data such as GPS with the file.

An example of a default tag associated before time of capture is an Event ID also called a Pounce ID that may be used to indicate which files are candidates for correlating for an event. Generally an Event ID corresponds to a unique event. The end to end process is discussed in the context of . Metadata association is discussed in more detail below in the context of .

In the exemplary platform in each device belongs to at least one user not shown and each user has an account . In the case where data is being shared peer to peer accounts may not be necessary since devices may access each other without the need for intermediate storage and because the user is operating only one device. However in the exemplary platform note that the user associated with account is operating both devices and . Further note that devices need not have been operated at the same time. For example a user might record video in a police car on a device for an incident and on a separate device record video and or audio that may or may not begin or end at the same time.

Accounts may be aggregated on web service as as a group . As a default a group may be identified to include all users with data files with the same Event ID. A group may also be either a predefined or a self selecting group for example a set belonging to a security agency or a set of all police officers belonging to the homicide division or even a set of officers seeking to share data regardless if they bellowing to an organized or unorganized group. A group may also be related to some other grouping external from the web service e.g. a law enforcement Case ID seeking all data assets that might have captured an event such as a crime in progress.

In this exemplary platform users with accounts associated with devices then may upload files to central storage . Users may belong to zero one or more groups. An example of where a user belongs to zero groups is includes a user having initially established an account although an alternative embodiment may include a user creating a default group. An example of a user belonging to multiple groups includes a video file belonging both to a group to capture a security event and to a group showing what other security personnel were doing on a given day.

Users with accounts in a group may also have the ability to add metadata after capture of the media data. As illustrated by users and adding metadata may include but is not limited to commenting on files by manually adding meta data or by automation such as tagging which may be performed via software tools and by scripting.

Users with accounts are not limited to associating data assets with metadata. Users with accounts in a group also have the ability to edit the data assets directly. For example a still photo may be uploaded and later cropped using a digital photo editor. The editor may be provided as on line tool as part of the web service or alternatively may be provided as desktop software by which the user may download the file edit and re upload the edited file.

User account pertains to a user who is not associated with a device. In general user accounts may be associated with zero one or more devices. Because users can add metadata after capture a user may still participate in a group without being responsible for providing data assets to the group. This is a common scenario for master editors as well as mixers who use data assets as samples.

In this exemplary platform embodiment the result is a central store of data assets that have been associated with correlating metadata from before during and after time of capture. At least some subset of the metadata may be used for correlation.

The correlation and presentation tool is represented as a single entity. However correlation and presentation may be implemented in different modules for example as different dynamic link libraries DLLs within a single application or as separate plug ins from a browser. The correlation and presentation tool may have a query tool not shown that provides for simple queries e.g. retrieve all data assets relating to New Year s Day 2013 Security Watch. Alternatively the tool may provide the back end infrastructure for a domain specific application such as a law enforcement dispatch tool. Several such applications including applications for law enforcement and for transportation are discussed below.

The correlation and presentation tool may invoke search module in the form of a query. The query may be a SQL query that retrieves data assets according to a series of where clauses. For example in the following SQL pseudo code 

In addition to filtering and correlating via predefined fields the embodiments described herein may support filtering on custom metadata. One option to support custom metadata is to support a number of custom fields within a relational database. In this way a simple text comparison may return all data assets when a custom tag equals e.g. New Year s Day 2013 Security Watch. In the alternative some relational databases may support stored procedures that can invoke binaries. For example MICROSOFT SQL SERVER allows invocation of COM object and ORACLE 10G allows invocation of JAVA objects.

In the above examples the actual binary to execute the queries is the search module . The search module may not only invoke data assets in the central store but also zero one or more external databases via the external correlation module . Example external databases may store as examples only mapping data advertising data assets domain data such as public Securities and Exchange Commission SEC filing data or integration with other applications such as law enforcement case management databases. At this stage correlations may occur in the form of join statements in SQL or binary equivalents.

The external correlation module may be responsible for returning data assets from the external database along with correlation metadata. The data assets may be returned with at least an Event ID to allow general correlation with the other data assets returned from the central store . Any metadata that was captured before or during recording may be converted to a format correlatable with the data assets on the central store . For example if a date time stamp is in a different format the external correlation module may convert the date time stamp to the central store format.

The external correlation module may have access to multiple databases so it may use one external database for data assets and another database for metadata. One example is a Joint Photographic Experts Group JPEG file that has GPS information which is correlated with a geolocation advertising database that links ads specific to the JPEG s location.

When the search module retrieves data assets and associated metadata it may return the data to the correlation and presentation tool optimally as a rowset. Specifically it may return a binary enumerable set of rows in which each data row contains a data asset ID an Event ID related metadata and at least an accessible reference to the data asset so that the correlation and presentation tool may actually retrieve the data asset. In the alternative when a high bandwidth dedicated connection is available the data assets may be served as a binary large object BLOB . In the alternative to a rowset the search module may return the data asset id event id metadata and data asset reference as an eXtensible Markup Language XML file.

Once at the correlation and presentation tool the data assets may be further correlated for presentation. For example once the data assets are local to the correlation and presentation tool further filtering may be performed resulting in changing correlations. For example when the rowset returns all data assets focusing on a particular crime incident it may be possible to retrieve only the data assets focusing only on a particular person under surveillance. Because of the extent of possibilities correlations may be driven by a custom rules engine.

The correlation and presentation tool may further support displaying the data assets both simultaneously and as composite. One example of such displaying would be to have multiple synchronized videos of a security incident playing on small screens and providing a control to view images from a selected one of the small screens on a large screen. Another example would be to stitch together individual still images into a single composite. Yet another example would be to display a first video followed immediately by a second correlated video.

Composite presentations may require editing capabilities on the subject data assets. For example in stitching the different JPEGs taken from different cameras and different locations will vary in shading color filtering and the like. Software post processing modules may be resident in the correlation and presentation tool to apply digital photo processing to correct and homogenize the JPEGs to be stitched.

As a result of the correlation and presentation functions being integrated into the same tool the correlation engine itself may be used to determine which data assets are to be post processed. For example the correlation function may identify which JPEGs have an average darkness beyond a predetermined threshold. In the alternative the correlation engine might calculate an average darkness and homogenize the images to that average.

After post processing the correlation and presentation tool may be used to present the final presentation to the user . The user may apply other processing as desired.

The user has the option of storing the final presentation as a single multimedia file or in the alternative as a single distribution of multiple files. The single file or distribution may be stored on an intermediate data store where other users may view or access.

The intermediate data store may be a networked share drive or a file server accessible via the web. In the alternative it may be portable media such as a memory stick or DVD ROM. Access to the data on the intermediate data store may be encrypted or password protected.

In this exemplary platform embodiment the result is a single multimedia file or single distribution that combines multiple data assets that have been correlated for consumption by a user.

Event may be captured by mobile clients and both configured in accordance with the embodiments described herein. Mobile client may then capture a portion of event via video recording . Mobile client may similarly capture a portion of event via video recording .

During the recording both mobile clients and may store metadata identifying the date timestamp and location of the recording. Potentially each client may also store data assets with different date timestamps and locations.

After the event is over mobile client and mobile client may attempt to establish a peer to peer mesh LAN or WLAN connection over the Infrared Data Association IRDA protocol. Specifically if mobile client initiates the mobile client may first generate an Event ID based on the mobile client s device number. The user of the mobile client may add additional metadata e.g. the name of the event. Mobile client may then send this metadata over to mobile client via IRDA. When mobile client sends an acknowledgement a link may be established. Henceforth any data assets transferred over the link may be tagged with the Event ID and associated metadata.

Because this is a peer to peer collection mobile clients and can enumerate each other s data assets. Mobile client may enumerate all data assets on mobile client taken near the GPS location of one of his video recordings taken at the event and around the times of the event. Then mobile client may retrieve all those data assets. When the data assets are transferred the data assets may be tagged with the Event ID and associated metadata. Mobile client may similarly perform such an action to mobile client .

In step an Event ID also called a Pounce ID may be obtained. This Event ID is provided as the minimal amount of metadata to correlate the resulting data asset with other data assets. Data assets with the same Event ID may be retrieved together. A data asset may eventually have more than one Event ID.

In step correlation metadata prior to capturing the data asset may be applied. Correlation metadata may include but is not limited to the Event ID. Other correlation metadata may include the identity of the person capturing the data and a location stamp.

In step data capture commences. During capture correlating metadata may be captured along with the media. For example GPS samples may track location during a mobile video recording in progress.

Once recording is complete at decision block a decision is made if the resulting data asset is to be shared in place via a peer to peer connection or uploaded to a web service.

If the data asset is to be uploaded to a web service a group corresponding to the Event ID may have to be joined and then uploaded to a central store via the web service. Alternatively if the data asset is to be shared in place there is no need to upload the data.

In step the data asset may be modified multiple times. In additional metadata correlating or otherwise may be applied.

In step the data asset may be post processed. For example if the uploaded data is a still JPEG it may be cropped. Another example includes correlating the data asset with other data assets and integrating them together.

If the final data asset is to be shared in step the data asset may be stored in a memory different than central storage such as a memory stick or a DVD ROM and the data asset may then be ready for distribution. Otherwise the data asset remains in storage for further retrieval and other actions. The following discussion describes this process in more detail.

In step the Event ID may be created in many different ways provided that the Event ID is sufficiently unique to identify one or more sets of data assets covering at least a portion of an event. Again while an event may correspond to an actual real world event for purposes of the embodiments described herein an event may be a set of recordings that are to be collected together for any reason real world artistic or otherwise. For clients enabled with consumer software to create an Event ID e.g. Pounce software the Event ID may be a globally unique identifier GUID generated by software such as guidgen.exe from MICROSOFT . Alternatively the Device ID of the capturing device may be used. On a cell phone if the transport is short message service SMS the SMS ID may be used as an Event ID. For yet another example for Twitter based distribution the PID plus additional supporting text may be used for an Event ID.

In step pre capture metadata is to be applied to the one or more sets of data assets. The metadata may include the Event ID as well as any metadata globally applicable to the one or more sets of data assets such as but not limited to name of the person capturing the event date time stamp location and device type. The pre capture metadata preferentially is stored within a data asset persisted as a file. For example the MICROSOFT advanced systems format ASF supports the placing of support metadata within the file format itself. Alternatively the metadata may be stored separately and distributed as a companion file for the one or more sets of data assets.

In step media is captures which may include capturing an event and metadata at the same time. Examples include but are not limited to location markers timestamp and telemetry. As in step the metadata may be stored along with the data in the asset as a file but could alternatively be stored separately in a companion file.

In scenarios where there are a small number of users with a small number of files the files may be retrieved or edited in place in a peer to peer network. In such situations a web service may not be necessary and per step may bypass joining a group and participating in a web service.

However in peer to peer connections the larger the number of users the more cross connections and communication overhead is required. For N users there are N N 1 2. Thus for example three users would require six cross connections and four users would require ten cross connections. Since the overhead to maintain connections would become prohibitive for a large number of users a web service may be preferable. Per step a non peer to peer scenario may involve a web service by which a group may be joined corresponding to the Event ID and the data asset being uploaded to a central storage. For example when uploading a videofile to a web based video repository a user may upload an associated text field which in turn may contain an Event ID. As part of the upload the user may also upload license data not shown . As an alternative to a web service a service on a corporate LAN might be employed as well.

In step once the data asset has been captured a decision to modify the data asset may be made. The modification may include but not be limited to one or more of adding metadata applying post processing including combining data assets via correlation metadata or persisting the data asset for distribution in steps and .

In step metadata is applied after the data is captured. In fact the Event ID may be edited or changed or an additional Event ID may even be added. Further custom metadata may be added or if custom fields of metadata are redefined old metadata may be made consistent with a new format. In the case of external data assets being added as described in reference to items and metadata may be converted to match metadata of other data assets. In step data assets are post processed. Such post processing may include editing the data asset e.g. cropping photos changing color distribution providing other special effects or combining data assets. For example combining and correlating an audio track and a video track may be considered to be post processing or perhaps are just combine virtually for during the process. An example is a police video from a car in the form of a file and audio overlaid from the device that recorded audio while outside of the car.

In step if the decision is to share the data asset separate from the platform as disclosed the data asset may be stored on a separate portable media such as a memory stick or DVD ROM. Alternatively it may be stored on a network drive. The sharing may be in the form of a single file or alternatively in a distribution of one or more data and one or several metadata files.

In this exemplary method embodiment the result is a single multimedia file or single distribution that combines multiple data assets that have been correlated for consumption by a user.

The platform implemented by the various embodiments described herein may be based on commodity hardware. In the alternative custom hardware may be applied to implement the platform for improved speed or efficiency. The server hardware may be based on a standard personal computer PC architecture or may be based on cloud computing as will be described later. The client may be a PC client with the ability to capture media or a custom mobile client as described in .

Both servers and clients for the platform implemented by the various embodiments described herein may be based on a PC architecture. Specifically there may be a processing unit comprised of one or more central processing units CPUs that each has one or more cores. There may be an on board read only memory ROM e.g. a basic input output system BIOS which manages boot up. For working memory there may be random access memory RAM for storage including virtual swap space there may be one or more hard drives. There may further be an input output interface to support both serial and parallel operations. The input output interface may contain support for a mouse and keyboard or the PC may have a separate interface. All these parts may be connected on a bus to multiplex data and instruction connectivity. There may be a fast bus for CPU communications to RAM and a slow bus for input output operations. Connectivity between the two buses may be handled by a northbridge.

The input output interface may include connectivity to a number of peripherals. Expansion cards or on motherboard functionality may be directly connected to the bus. Further there may be a video graphics card which in turn may provide connectivity to a video monitor. If the PC is to be networked there may be a modem or network interface card NIC . NICs may support a wide range of protocols. The PC may even have a cellular modem. Audio functions such as microphone and speaker support may be supported by an audio card. Interface for optical storage such as CD ROM DVD ROM and BluRay disks may be handled through the input output interface. Other portable storage such as memory sticks thumb drives and legacy floppy drives may also be handled through the input output interface.

In the case of clients for media capture cards supporting fast input output such as Universal Serial Bus USB 2.0 and Institute of Electrical and Electronics Engineers standard no. 1394 IEEE 1394 also known as FireWire interfaces can be supported by a PC e.g. high resolution microphones and video cameras. However fast input output can be any sort of data acquisition including but not limited to location sampling telemetry or other streaming data feeds.

In the case of servers large arrays of storage such as Redundant Array of Inexpensive Disks RAID arrays are common. Multiple CPU and multiple core configurations with relatively large amounts of RAM provide support for large numbers of users.

Mobile client is powered by power functions . Information is entered via buttons and potentially via a screen if it is a touch screen. Visual output is provided through screen . Media can be captured through media input functions including video and still cameras and microphones . Metadata including correlating metadata may be entered via metadata collector functions . These functions are described in detail as follows.

Client may receive a signal via the antenna not shown and then signal may then be sent to the receiving function of the transceiver . After the transceiver there may be a function to determine what type of signal is being received not shown to distinguish between background noise and actual voice input. After the signal type has been determined the signal may be sent to codec in the coding functions . The decoded signal may then be forwarded to filters and error corrector both of which may improve the quality of the decoded signal. Finally the signal may be forwarded to an appropriate rendering mechanism. For example if the signal is a voice signal then it may be sent to a transducer such as a speaker not shown if the signal is SMS or web browsing data or other software data it may be sent to an appropriate software application and then displayed on screen .

A signal may be then generated in response be it through voice from a transducer such as a voice microphone not shown through buttons or other inputs such as a stylus not shown or screen if it supports touch screen functions. Regardless if the input is voice or software or a combination of the two the signal is then forwarded to the appropriate codec for coding and then for transmission in the transmission function of the transceiver and then to the antenna not shown .

Client has the ability to capture media. Contemporary cell phones also support on board media input for video and still data via a camera and via a microphone . While these are known forms of input further media input may be through data connections such as pod casts and other streams not shown .

Client further includes the ability to respond to triggering events. For example a Radio Frequency ID RFID reader not shown can provide a software notification that an RFID card has been read an acknowledged. In turn the camera may be turned on for recording. Another example is a vehicle collision detector creating a software event to turn on recording.

In additional to capturing media and triggering events client includes metadata collection functions . For example samples of location metadata may be collected by location service receiver . Geolocation metadata may include Global Positioning System GPS metadata. However because GPS is prone to error from GPS signals bouncing off of buildings in urban settings geolocation metadata may alternatively be determined by triangulating signal strength or weakness from different cell towers with known locations. For relatively immobile clients receiver may collect geolocation metadata via internet protocol IP address.

Another form of metadata is date time data. Obtaining date time metadata for client may be accomplished using an onboard clock not shown . Alternatively date time metadata may be obtained from a signal from a cell phone tower.

Yet another form of metadata is text generally entered by a user pushing buttons . Client may utilize a software application by which the user enters metadata values via the 10 key pads or via a touch screen . Such traditional button entry would be handled via button entry function .

Alternatively custom functions for hotkeys may be employed. Specifically hotkeys may be used to enter common tags. For example a user may enter the key to indicate the use of a metadata tag key. Further the user may enter a number for example 2 if the number was not already defined and text in the value for a metatag such as Jane. Thus the next time the user wanted to tag a photo with the name Jane the user would press to trigger metadata mode and then press 2 and then Jane would then be associated with the photo. If no photo or media file was available upon triggering the hotkey the user may be prompted to delete or edit the hotkey for different use. This would ease the otherwise cumbersome task of associating metadata with a restricted user interface.

Other metadata input output functions may include but not be limited to USB and FireWire. Input output functions on client may include but are not limited to 1 providing other sources of media capture 2 providing sources of detectors of triggering events and 3 providing sources of metadata capture. Accordingly in alternative to where all of these functions are on board the mobile client these functions could be accomplished via peripheral hardware.

Not shown are custom chips to aid in functions typically enabled via software. These include but are not limited to data compression chips and encryption algorithms.

Power functions provide power to the all of client . Typically this is in the form of a battery . But a charger AC input typically recharges the battery or provides direct power.

An alternative form of charging may be performed using inductance coils. In situations such as law enforcement remembering to charge a client device may not always be present in a user s mind. By implementing the charger as an inductance system including a program to manage the charging. Specifically the program may determine when the system is being charged how much power to convert and when the system is to be disconnected. The on board mobile client processor not shown or a separate processor may alternatively be used as may the on board mobile client RAM not shown or separate memory be used. The mobile client may also have an inductance coil to receive energy and then to the power functions and there to the battery.

An off board charger may be configured as an inductance coil that connects to an electrical power source and may further include a processor and memory to indicate when to charge and how much to charge the client device. The off board charger may even further include an indicator having a charge status indicator in the form of colored light emitting diodes LEDs or alternatively an LED array.

Alternative charging configurations may include placing the mobile client s charger off of the device and elsewhere on the person of the user. For example coils may be placed in the sole of a user s shoe in or on the seat of the user s pants in the user s belt or in the web gear of the user. The corresponding charger may further be disposed on the gas pedal of the user s car or even on a car seat which could then charge the client device whenever the coils are proximate.

In order to support vehicle mounting the mobile client may be placed within a chassis of aluminum or other material with an extendable arm that connects to the windshield of a car much like a rear view mirror. The chassis may have tamperproof qualities and may include one or more security locks that prevent theft or unauthorized modification of the mobile client.

The mobile client components may be divided into two portions to support a secure recorder configuration 1 the data gathering portion including cameras and microphones and 2 the storage portion which contains the stored data. This latter storage portion may be secured in a hidden and hardened portion of the vehicle to prevent theft or unauthorized modification. The data gathering portion should be in public view therefore in order to best capture the surrounding events the ability to conceal this portion is limited. However if a malicious actor steals the camera the actor steals only the device but not the data which then may be later used for its intended purpose or even to help determine who stole the camera. The hidden portion may also be hardened such that in the event of an accident the data storage may be recovered or still functional to upload data.

Several alternatives may be exercised to prevent stealing the data gathering portion. One alternative is to integrally mount the data gathering portion into the vehicle s dashboard such that removal requires removing the dashboard and unbolting the device. This alternative would lengthen the amount of time to remove the data gathering portion to greatly increase the chances that a would be thief would be caught. For scenarios where an officer wants an option to move the camera the camera may be removed from the vehicle when not in operation and stored securely in a separate location. In either alternative a would be thief is deterred or prevented from stealing the data gathering portion.

Embodiments of the platform support data connectivity. Data connectivity from a PC architecture client is primarily from a network interface card for example an Ethernet card or in the alternate from a dial up modem. Data connectivity from a mobile client most commonly would be via a cellular connection. Clients are not limited to just one form of connectivity and may have multiple data connections. For example a PC client may have both a modem and a network interface card or a mobile client may have both a cellular and Wi Fi connection.

Connectivity support is not limited to data connectivity. Connectivity support may also be for voice data as with ordinary cellular connectivity. Support for device communication e.g. Bluetooth support may also be available.

Various embodiments of the client may support a full network stack. At the data link layer client support may include but is not limited to Ethernet support for PC clients and Wi Fi support for both PC clients and mobile clients. For Network Session Transport layer protocols support may include transmission control protocol internet protocol TCP IP user datagram protocol UDP and other protocols. For application layer protocols file transfer protocol FTP support for uploading large media files may be available hypertext transfer protocol HTTP may be available for web access and simple mail transfer protocol SMTP may be available for email access.

Embodiments of the platform may support peer to peer connectivity by which client devices may create an ad hoc network to access and trade files. In the alternative embodiments of the platform as disclosed may also support dedicated networks. For example one remote client may videotape an event and another client may record the audio of an event. The remote clients may support infrared data association IRDA standards and may be able to transfer files to each other. Since IRDA is slower than Wi Fi the remote clients may support Wi Fi and set up a private ad hoc network between the two. Finally the remote clients may participate in a dedicated network along with PC clients.

Since multimedia files are large even with compression embodiments of the platform may create large amounts of data. Accordingly the data may be stored on cloud computing centers. By integrating with cloud computing the embodiments described herein may make available large amounts of storage and further provide access to compute intensive applications available on cloud computing platforms. However integration may result in degraded performance and over reliance on a third party.

There are a number of compute intensive applications that may be hosted alone on large computer clusters. Face recognition is one such application. However when such applications and databases are hosted on a cloud computing node in addition to having higher availability of a larger number of compute resources the application is not inherently networked. One application of the various embodiments described herein includes a client camera capturing a video frame or still image extracting out a subject s face using standard algorithms and then calling a cloud computing database.

An embodiment of the uploading implementation may be described with respect to remote client which has a still camera and PC client which has a number of still photos stored as files. PC client with may store a number of still photos with the name of the person stored with the file as correlation metadata in the form of a tag. The PC client may upload the photos to the application host via a web service. The application host may then store the photos to central storage in cloud where is the photos may be available for retrieval via search and correlation. In the alternative PC client may upload the untagged photos and then tag them with metadata after the uploading.

An embodiment of the download process may be described with respect to remote client which takes real time still photos at an event. The context may be in law enforcement surveillance or in photojournalism. Regardless the user of remote client may automatically tag the photo with the names of individuals on the photos. Remote client may upload the photos to application host via a web service which may then store the photos on a central store in cloud . Once on the web service the remote client may request the photos to be automatically tagged. The application host may then invoke a face recognition application running on the cloud to retrieve all photos that are similar to the faces in the photo uploaded from remote client . Where the retrieved photos do not have sufficient similarity to the photo uploaded from remote client third party databases may be invoked. Based on the tags provided from PC client as well as all other clients that stored photos in the database the relevant tags may then be applied to the photo uploaded by remote client .

Because the correlation and presentation are integrated together item custom features such as autotagging are available. More importantly because the embodiments as disclosed integrates with external data item and provides for metadata correlation item it can integrate with third party databases such as facial databases including integration with cloud computing applications.

This integration with cloud computing applications provides for faster responses. Accordingly remote client might receive the names of the individuals just taken in a photo immediately. Additionally the remote client might receive additional information such as company name or other professional information. On a variation of the above scenario the user could have taken a picture of a product in a store used object recognition software in the cloud and similarly retrieved product information. The foregoing is exemplary and not intended to be a limiting or exhaustive list of possible applications of extending the present platform to include cloud computing.

The integration of the described herein may not only provide feedback regarding the accuracy of the facial recognition but may also work to improve matches. For example if clients and are organized into a group the likelihood of retrieving false matches from a general database is removed by limiting the face recognition database only to members of the group. Furthermore by adding autotagged photos to the general database especially after post capture corrections provides an ever improving sample of photos to determine facial matches. Facial recognition capabilities may be augmented by taking changes over time such as hair style and the growth of mustaches and beards and could return name information but also time period information.

One problem with cloud computing integration is that data may be widely distributed geographically thus creating wide variances in network latency and performance. For example in cloud may be located in or near Seattle Wash. but cloud may be located in or near Washington D.C. Thus a user located in Seattle would likely experience slow data retrieval if the data were based in cloud but better performance of data based in cloud .

Accordingly the application host may manage offline edge and nearline data by 1 caching data on application host itself and 2 invoking server affinity which guarantees that a particular server or at least a particular cloud is to serve data to a particular user. Data that is known to be needed commonly may be placed on the application host that is nearline. Data that is known to be needed by users geographically local to the cloud but is not commonly used may be pinned to a local server or a local cloud via server affinity. Placing data redundantly on different edge points of the cloud may not be cost or storage prohibitive because cloud computing provides large amounts of storage. Further data that is not time sensitive may be stored offline or arbitrarily on the cloud.

Another problem with cloud computing is over reliance on a single cloud computing provider. For example where the central storage is hosted on a cloud for a production system such as for law enforcement cloud failure means data storage is lost. If the law enforcement force was in a major city such as New York with 1 000 policemen on duty down time of a cloud for 1 hour would be a loss of almost a man year of data. Cloud computing is a relatively new technology cloud computing brownouts and blackouts are possible. Additionally much data in particular in law enforcement scenarios must be made secure.

The application host may integrate storage across clouds and from different cloud computing providers and mirror. Alternatively the application host may implement a RAID scheme which may subdivide data across three clouds all from different providers. Security which may include auto encryption may be enhanced since no single cloud provider is likely to have all the data. In both cases storage availability is improved.

For custom functionality the exemplary platform may include custom libraries mostly exposing programmatic support for the software eventing model and to custom hardware as exposed by the custom drivers . Finally applications may be built on top of the libraries . The following discussion will cover each of these areas in more detail.

Standard drivers may include drivers for stock cell phone hardware including but not limited to buttons screen and memory . There may be other stock hardware including e.g. a GPS receiver not shown .

Custom drivers may include drivers to support non stock hardware for a cell phone. Custom drivers may be included in various embodiments by which a mobile client comprises a cell phone with additional hardware functionality.

One example of a custom driver is a custom network stack to compensate for the presence of a partial network stack as in various cell phone embodiments. However full implementations are to support functions typically not on a cell phone including Wi Fi connectivity FTP to name a few.

Other examples of custom driver include a custom USB implementation and a custom Plug n Play PnP implementation . Not all cell phones support PnP which is the automatic installation of hardware drivers and automatic configuration and provisioning thereof. However some cell phones may have additional hardware added for telemetry and metadata purposes. A full USB stack and support for PnP may provide such functionality in various embodiments. As USB is not the only serial interface stack it optionally may be replaced with some other serial data interchange stack.

Standard drivers and custom drivers may serve to forward communications to the operating system . Generally there will be an event queue and a series of modifiable event handlers not shown . Modification of the event handlers may include a recompilation of the operating system . An alternative is to create extensions to the operating system to isolate any necessary custom functionality. This includes a custom software eventing model .

Software events are different from the physical events that may be captured via media and multimedia in accordance with the various embodiments described herein. Other terms for software events include triggers and notifications. A software event may include a message that software sends when some occurrence discernable by software occurs. An example includes a hardware button being pushed a driver triggering a software event that sends a message to all applications subscribing to the event for which a button has been pushed. If an application has an event handler that event handler will contain functionality as to what the application should do when a button is pushed.

A software eventing model may support software events for custom hardware. For example if a custom driver provides an interface for an RFID trigger the custom driver may send a notification to the operating system extension s internal event queue. The internal event queue may then forward the notifications through custom libraries to application . The application may then handle the event of the RFID trigger by turning storing the camera s preview buffer and starting the record function of the camera. Alternatively software events may be processed via a modification of the operating system s event queue. Additionally event notifications from applications may be disseminated via the software eventing system .

The standard drivers preferably are not modified or are modified as little as possible and custom drivers should be isolated from the operating system as much as possible. To enable custom eventing in some cases the communications may be intercepted or hooked by module A for the standard drivers and B for the custom drivers. For example if a particular button sequence is to bypass the operating system and perform a custom function such as a triggering a hotkey mode it may be necessary to intercept the button pushes and redirect execution to a hotkey executable. Further by way of example if a combination of the default operation and a custom option is required the button pushes can be simply hooked thus passing through the push notifications to the operating system at the same time triggering a custom button push software event handler.

The operating system and the operating system extensions generally will expose their functionality via an application programming interface API . Standard libraries generally provide function calls or object models to aid programming applications. Standard libraries generally are distributed along with the operating system. Library extensions that is custom libraries provide function calls or objects models to support custom hardware operating system extensions or to provide new additional functionality on top of the original operating system .

There is a wide range of applications now enabled by this extended platform as will be described as follows.

Patch manager is an application that handles updates for the drivers and installed software. There are two ways of patching. The first optimizes saving memory the second optimizes versioning. For both versions the flash memory contains a lookup table mapping locations in memory for functions. When an application calls a function it goes to a lookup table that was populated by the table mapping from flash. In this way the function can proceed to the location of the function and properly execute.

The first example of patching stores the lookup table values in a well known location. It then stores drivers the operating system applications and any other binaries in other locations of the memory. Each binary is allocated more memory than it currently needs in order to account for future patches. When the patch manager receives notice which includes all new binaries and a new lookup table perhaps over the network or via an SMS message the patch manager triggers a software event. The software event shuts down all software except for those necessary for patch functions. The patch manager first overwrites the lookup table and then overwrites all binaries with the new binaries. The patch manager then forces a reboot. The reboot then restarts the mobile client populates the software lookup table with the lookup table in flash. When an application calls a function it then will go to the new location and to the new binary.

While the first example conserves memory it does not provide provision for falling back in the event bad patches are installed or patches were improperly installed. In a second example of a patch manager the same triggers and events are used as in the first example. However additionally the location of the current lookup table is stored. At a well known location several bytes of empty storage store each new location of lookup table. The original lookup table address is in the first location. The lookup table of the first patch is in the second location and so on. Whenever a patch is installed lookup table and all binaries are stored contiguously. Upon reboot the operating system looks for the last lookup table and then installs the lookup table into software from that location. In the event a patch has to be backed out the patch manager can decrement the list of addresses of lookup table versions reload the older lookup table and in doing so revert back to the older software.

File manager is an application that provides advanced file management for on board removable storage. Typically when removable storage such as memory sticks are in a cell phone the assumption is that the user will remove the memory stick and place it in a PC to remove and otherwise manage files. However for scenarios such as security cameras where removing the memory stick may take long periods of time an ability to manage files as not to run out of memory is required. To address these requirements the file manager contains four main functions 1 deleting files upon upload 2 round robin deletion 3 metadata tagging upon upload or download and 4 enumeration of data assets.

For the first function as files are written to media eventually a notification perhaps from SMS will trigger uploading all files not currently open. Where a file is open optionally the trigger will force a closing of a file and a reopening for example with the onboard video camera is currently recording.

For the second function where uploading is sporadic or non existent the file manager may maintain a queue of files and implement a first stored first out memory management approach. Specifically when memory is no longer available the oldest files will be deleted and that space allocated for a new file. The file manager may implement packing and compression algorithms as well.

For the third function upon upload or download the file manager checks the Event ID of the data asset. If it is null it populates the metadata field with the current Event ID on the mobile client. Where the Event ID is associated with other metadata for example the name of the event that field is populated if null. In the alternative it may prevent upload or download.

For the fourth function the file manager provides not only for enumeration of data assets but simple search via metadata. The file manager maintains a table of data assets on the machine and maintains a list of metadata fields and offsets. When request for example from SMS or alternatively via a network requires a list of data assets matching metadata criteria it sequentially iterates through all the data assets in the data asset table and retrieves the file name if the data asset matches. It then writes the file name into a text file. The text file is then returned over the data connection. The text file may be formatted with XML or with a proprietary format to aid enumeration and presentation on the receiver of the file.

A QoS Failover application manages multiple media inputs for example a video camera and a microphone. Consider the case where the mobile client is in a police car and the police officer is wearing a wireless video camera and a wireless microphone configured for the platform as disclosed. Further consider the case such that the video wireless connection has a lower range than the microphone wireless connection. While the police officer is near the car both video and microphone are streaming data. When the officer exceeds the distance for the video connection but not the microphone the QoS Failover application can cut out storage only for microphone. When the officer then exceeds the distance for microphone the QoS Failover application can then place a marker in the file indicating no receipt. When the police officer returns to the car the microphone and video can recommence recording according to range.

Consider the case where data assets from multiple mobile clients are to be correlated. The Client Sync application provides the client side support to aid consistency and reliability of media and metadata across the clients hence the term sync. Upon activation the Client Sync registers the mobile client with a web service or equivalent. The web service provides an Event ID and in turn the mobile client via the Client Sync uploads data assets to the web service. The data assets are tagged with the Event ID. The Client Sync also provides location samples to the web service as to allow for tracking of the mobile client. When data assets are uploaded the Client Sync also appends to the data asset a checksum. Upon upload the web service can validate the authenticity of the uploaded data asset. The checksum also called a heartbeat can also contain additional metadata. For its part the web service can also provide additional metadata. For example consider a law enforcement scenario with multiple officers. Each of the officers has a mobile client and already is associated with an Event ID. When a particular incident occurs the web service can provide an Incident ID that gets associated with the officers proximate to the event. This Incident ID gets associated with all data assets uploaded until the web service rescinds the Incident ID. In this way later the data assets associated with the Incident ID may be easily identified.

Identifying relevant mobile clients to send the Incident ID relies on knowing the location of the mobile clients. If an officer indicates that an incident has occurred either through a hotkey or a message the web service attempts to identify which other mobile clients with the same Event ID are proximate. Usually this may be done via GPS. However as described in the hardware section above GPS is prone to error from GPS signals bouncing off of buildings location may alternatively be determined by triangulating signal strength or weakness from different cell towers with known locations. For relatively immobile clients such as surveillance tower cameras geolocation via IP address may be employed.

The remote control application takes advantage of the full network stack on the mobile client. Consider the case where the mobile client has an IP address and is fully participating on a network. The remote control application contains a proxy to intercept remote instructions either through SMS or from a direct IP connection to a remote site. Accordingly a remote user can fully control the client either for maintenance such as patching and upload of data assets.

The preview application is not an application to preview data. Rather it is an application to guarantee that media captured in the preview buffer of a video camera is recorded along with the rest of the event. On video cameras with preview a memory buffer stores the first few seconds of data. This buffer could store an arbitrary amount of time. Upon recording the video begins recording at the time of triggering in other words at the start of the event to be recorded. However for security cameras and other applications it may be preferable to store the previous few seconds in the preview buffer as well to ensure complete recording. Accordingly a RFID triggered security camera function in a mobile client configured with the platform as disclosed would store not only the event upon triggering the camera but also the first 10 seconds. In this way the video would store not only the event but the precursor events that led to the event.

Mobile devices such as the mobile client as disclosed require constant recharging. A custom charger application determines how much charge is left in the battery and provides alerts when charge is low. Furthermore in cases of inductance charging the custom charger can store information about how much power is needed to recharge the battery. It could also store rules on detecting when charging coils were sufficient proximate and stable to trigger charging functions.

The ability to receive short message system SMS messages and trigger software events provides a general mechanism to remotely control a phone. Specifically a mobile client that has an SMS capable transceiver may monitor SMS calls and perform software routines in responses. Specifically one of the custom drivers could be an SMS driver to allow the ability to monitor SMS calls for custom commands. Calls to and from the SMS driver could be intercepted and hooked. When a predefined SMS message to a predefined location is received it could trigger an event in event model which in turn could be utilized in an application .

An alternative embodiment is to have a daemon application without the driver or event model to directly monitor SMS messages such that when a predefined SMS message to a predefined location is received it would perform a particular prespecified task.

An example application for monitoring SMS messages relates to law enforcement. A stealth recording feature may be implemented where a mobile client receives a SMS message which includes a phone number the SMS message instructs the mobile client to start recording its environment and transmit the audio and or video over the received phone number. Another SMS message could instruct the mobile client to stop recording and transmitting. Variations on this scenario where an SMS message instructs the mobile client to initiate a phone call but does not record as to the type of media to transmit and whether to use the calling number as the destination to transmit recorded media will be appreciated by one of ordinary skill in the art.

In particular Table A as follows provides an exemplary mapping of events to SMS Messages to be interpreted a control instructions operative to control a mobile client s stealth recording function 

The mobile client may optionally send a response SMS message to the sender to confirm receipt of messages proper operation of the client or error messages. The SMS messages could be used as a protocol including but not limited to triggering software events by the receiver. For example an SMS acknowledgement for starting a call could trigger a software server to start receiving streaming media. Another example would be to receive an error SMS stating that a connection could not be established and displaying the error message as part of a computer application.

The mobile client could receive SMS messages from any SMS source. These include but are not limited to other mobile devices and computer applications with a cell that could transmit SMS. Accordingly protocols could be established over SMS between two mobile devices or with a custom computer application with capable of transmitting and receiving messages compliant with the SMS protocol.

Although the SMS messages above are merely exemplary a sample session may be as follows. The mobile client receives an SMS message 27 1 555 555 1234. In response the mobile client starts a phone call with 1 555 555 1234 and immediately sends an SMS acknowledgement. The mobile client then receives an SMS message of 77. The mobile client immediate starts recording video and audio. If the recording cannot be performed the mobile client would send back an SMS error message to 1 555 555 1234. Periodically the mobile client will upload files to an FTP server or other host. Alternatively the calling number 1 555 555 1234 could provide a connection to an FTP server or equivalent. In another alternative the server to which 1 555 555 1234 provides connectivity could trigger a streaming receipt upon receiving the acknowledgement SMS from the mobile client. The mobile client upon receiving 74 and send an acknowledgement SMS and would halt recording. A new recording could be established the mobile client receiving 77 and again halted by the mobile client receiving 74. Similarly upon receiving 24 the mobile client would stop the call and send an acknowledgement.

The above applications are not intended to be an exhaustive list of applications available. General utilities such as profile management not shown are available. A profile manager could store user information such as name to be used as default metadata. It could also store results about memory usage bit rate and resolution of stored media.

Commercial utilities can also be implemented on this platform. For example in the case of law enforcement the mobile client might have a hot key for a police officer to indicate the officer has been attacked or shot. The video would trigger to store the preview buffer as well as the current events and a central station could call for backup asking other police to converge on the attacked officer s GPS location.

Another law enforcement example is the alternative log on password utility for undercover policemen. The alternative log on password utility accepts two passwords. One password activates all the law enforcement functionality on the mobile client and displays a user interface specific to the law enforcement functionality. A second password simply displays an ordinary user interface expected on an ordinary cell phone and additionally may activate a call for backup to the central station. Specifically when an undercover policeman begins to be suspected to be a cop by those he or she is investigating the policeman might be searched. Ordinarily if the policeman is searched and the mobile client is found an inspection of the mobile client might arouse suspicions that the undercover policeman is a cop. The undercover policeman could enter a the second password into the alternative log on password utility while would show the ordinary cell phone user interface and may help convince others that the undercover policeman is not a cop. In the meantime the backup call to the central station would allow other policemen nearby to rescue the undercover cop.

Commercial utilities are not limited to law enforcement. The mobile client may support applications not specific to its video or networking capabilities. An example of a commercial utility not specific to law enforcement is where the client could store an audit function not shown that indicates that an unauthorized person has attempted to open the tamperproof chassis. An example of using the SMS based mobile client control feature such as used by the Stealth feature described above is the case of a lost mobile client. The mobile client may host an application that upon receiving a message such as an SMS text message may un mute a mobile client with its ringer turned off or alternatively may activate a mobile client that is in sleep mode and then ring the device. In this way a mobile client that has been misplaced in a room where the ringer has been turned off or cannot otherwise be located simply by dialing the mobile client s number.

Once the data assets are tagged and available on a central store they may be searched correlated tagged edited and presented either collectively via a web service or to a closed set of users via a standalone application. The platform as disclosed gives rise to both types of applications.

Regarding a web service groups may correspond to a group. The data reviewed by the groups the content of the tags and comments made by the group may be queried for possible advertising. Because the group is self selecting the fit of ad selection will improve a selection algorithm based strictly on scanning media content and metadata. In the external data store as provided with correlating metadata in could be the correlation of advertising.

The NOC provides the capability of viewing individual videos. In video feed a video or potentially another form of multimedia will be rendered. Annotation tools provide allow a user select one or more frames of running video superimpose text links or other content perhaps associating to a single object such that the annotations render upon playback. Many tools presently exist for annotation of video and multimedia in general. Running commentary box provides a control with which to view commentary and commentary edit box provides a place to add additional commentary. Commentary text is persisted to a database and is associated with the multimedia file being rendered. Commentary is distinct from annotation in that the text is visible at all times in the running commentary box during rendering whereas annotation only appears for specific frames and is superimposed over video as rendered in the video feed . Associated videos stills text or other multimedia may render at the same time in browser . For example links from the annotation may render in browser . Map may also display the location of the video. For example if the video is by a police car in hot pursuit the map may show a point rendering geolocation of the path of the pursuit itself.

The NOC has a supervisor mode shown in where data feeds including video and audio are coming from police officers proximate to an incident. Specifically a police officer encounters an incident and presses a hot key telling the NOC that an incident is under way. The NOC can start an incident record and the police officer s feed appears in Car Feed 1 item . Because it is the first feed it also appears in the main video feed . The map then centers on the location of that particular officer. The incident ID may be used as an Event ID.

On the map the user can view other officers near to the incident and can either manually select other officers individually by clicking on the officers or by dragging and dropping a bounding rectangle over the location. In the alternative the application can use a predefined distance and automatically join other officers. Each joined officer s feed then shows in feeds and so on.

When an officer is joined the officers feed is associated with the Event ID and defines a group. Thus joining officers within a predefined distance and unjoining officers that go out of that predefined distance is an autogrouping feature.

The main video feed may display which of the feeds or to concentrate on. Alternatively the main video feed may automatically switch between which officer is closest to the incident. Note that the video feed is not a composite view but rather is an example of multiple videos being shown side by side based on correlation metadata.

If the data is being viewed after the fact browser can bring up data from the law enforcement s case database. All media files with the Event ID may then be automatically tagged with the Case ID from the case database. In this way data from the case database may be provided in an integrated view along with the media.

Law enforcement mobile clients have redundant local storage that is eventually uploaded for archiving. The application can provide a scanner function not shown that can manage uploading from the mobile clients can tag the file as archived thus preventing redundant storage. In the alternative the scanner function could seek similar clips based on Event ID and location and timestamp information and delete redundant clips. Because of the redundant storage the NOC can provide security functions. Specifically the scanner function could also detect files tampered with by noting files with the matching data with different checksums. Additionally the NOC can check checksums on uploaded files to detect files intended to spoof the NOC.

The embodiments as disclosed may be used for both personal and commercial vertical applications. Advantages include but are not limited to 1 reducing the price of camera monitoring via use of commoditized ever miniaturizing hardware and ever cheaper storage 2 guaranteed full capture of an event by implementing preview buffers 3 custom eventing where a camera may be triggered on an arbitrary event 4 integration with other media via correlating metadata and 5 integration with third party data via correlating metadata. The following sections will describe an exemplary application for personal use an exemplary application for law enforcement an exemplary application for security cameras and will more generally enumerate other exemplary commercial scenarios.

The NOC application may be accessible via a web page on a notebook computer or other web enabled mobile device. Accordingly all or portions of the NOC application may be viewed while in the field by a law enforcement officer.

An example application would be allowing a junior officer to patrol an area and to view indicia of incidents that occurred within a time frame in the present locale. In this way the officer could more quickly learn the crime history of his location even though he had never been in the area before.

One embodiment would be to let an officer travel through a neighborhood. The officer would enter a time range of data to browse for the area for example over the past year. The NOC application would pick up geolocation information of the roaming officer such as GPS location and display a map in the NOC would show pushpins indicating incidents within the specified time frame. The pushpins could be color coded or have size or shape changes indicating the severity or recentness of the incidents. The officer could click on the event and view the video or associated media to learn more. In this way the officer could familiarize himself as to the crime history of an area in near real time.

The mobile NOC need not be in real time. An officer could be in an area and if he wished to learn more about the crime history of his location he could open the NOC application and specify his current location and search for crimes within a time area and various search criteria. In this way upon entering a crime scene the officer might find related crimes not readily discernable from the crime scene itself. For example if there was an assault at a crime scene the officer could quickly identify other assaults nearby and consider suspects from those crimes as well as leads from the present crime scene.

Video cameras digital cameras and digital recorders are to be ubiquitous among law enforcement officers. It is not uncommon for several policemen each with their own camera or recorder to be proximate to a crime in progress. The embodiments as disclosed enable sharing and the automatic correlating of the resulting data assets.

Because mobile clients and are enabled per the disclosure they are able to perform a peer to peer connection. Per the embodiment as disclosed the initiating client identifies its device id and enters a tag called Robbery 1 and sends both to to use as an Event ID and as extra metadata. Mobile client sends an acknowledgement back to thus fully establishing data link . Mobile client then downloads via IRDA all photos time stamped during a time frame corresponding to that of the crime from and mobile client similarly downloads all photos form . Both clients automatically tag the photos moved through the data link .

Standard camera is not configured per the present disclosure and cannot perform peer to peer transfer as mobile clients and . Instead the users of mobile clients and establish a group not shown on web service using mobile client s Device ID as an Event ID. The user of standard camera then joins the group and when standard camera uploads chosen photos to the web service over data link the photos are automatically tagged with the Event ID and the meta tag Robbery 1. 

A user such as a police supervisor back at headquarters who is a member of the group not shown subsequently may access the web service via a PC over a data link . The user may further upload related photos such as getaway scenes of the robbery crime scene of persons of interest driving away and again via the data link the photos are automatically tagged with the Event ID and the meta tag Robbery 1. The user may also query edit tag and combine photos on the PC.

It is to be emphasized that in the above scenario media is not limited to photos. Video or audio could have been uploaded as well. The web service could have been a standalone application running on a network. Most importantly the event here exemplified by a crime scene need not have been at the same time or place. An Event ID could tie together any media regardless if they previously were related at all.

Host receives data assets from mobile clients and both in synchronous and via asynchronous upload. A web service can remotely configure a mobile client by checking the existing profile sending an updated profile via client application . In general client application functionality includes providing network connectivity to the host. The profile includes and is not limited to frequency of receiving an IP signal to poll the status of the mobile client. This signal is also called a heartbeat. Upon configuration web service will send out a heartbeat according to that frequency for example every 15 seconds. Client application will receive the heartbeat and return geolocation information such as GPS coordinates. In the event of connectivity error website would be able to indicate which mobile clients and have failed to connect or have not transmitted a heartbeat.

Because a mobile client and in the field broadcast geolocation information a network operating center NOC can get mobile location information from the host and know in real time the location of mobile units. This enables map applications. For example a NOC application may display selected units on a computerized view of a map perhaps accessible via a web site . Alternatively particular mobile clients may be searched by geolocation. By way of another example the NOC can have the location of a crime scene and the current location of a mobile unit and automatically map the optimal route for the mobile unit to get to the crime scene. This feature is also known as a Get Me There feature.

As client application captures media it stores the corresponding data assets on storage . Via synchronizing application the mobile client may either push the stored media via file transfer protocol FTP to the file transfer server or the synchronizing application may be remotely triggered for example via an SMS command to affirmatively upload the stored media as data assets.

Once the data assets are uploaded to file transfer server a crawler application periodically scans the uploaded data assets. The data assets are placed into a folder queue and optionally associated with metadata for example in the form of metadata tags corresponding to incident or case. Transcoder converts the file formats of the data assets into a standard format for example one based on H.264. Once transcoding is completed if the transcoding is successful crawler application archives the original file and stores the transcoded video to store and a reference to the transcoded video to database . In the event of error the uploaded data asset is placed into another directory for later review.

One error that may occur in particular with data assets stored as H.264 compliant files is the loss of the file index. A file might be partially uploaded but because the file index is stored at the end of the file none of the partial uploaded file is usable. Prior to transmission synchronization application might store the H.264 index in a separate file and redundantly upload the index. Because the index is much smaller than the media data in the H.264 file corruption is less likely. In the event the uploaded H.264 file is truncated the complete index uploaded separately may be used to decode the portion of the H.264 file that arrived. If the H.264 file arrived intact then the redundant index may be discarded.

Once data assets have been stored in the database and store they are accessible via a website . The website may include functionality to search and view videos including external data such as case data. For example it may enable computer aided dispatch where an officer is dispatched to a crime scene incident information is entered by the dispatch via website and uploaded to database data assets are uploaded from mobile client or tagged with metadata corresponding to the incident and the searched and viewed in composite afterwards.

Website may also provide various ways to quickly review video files. For example website might provide thumbnail or videocap views of videos to aid visual search. In some cases a scroll bar might be displayed to allow the user to scan through individual frames in the video rather than merely viewing a default frame.

Website may also integrate with external websites. For example a supervisor may access website and upload a video to a public social networking site as part of a public alert such as missing child alert Amber alert .

Website may also provide visibility to monitor the status of uploaded data assets and provide for bandwidth management and prioritization. For example website may show what data assets have been uploaded transcoded or what percentage of the process is complete. It may also show which data assets have errors or are otherwise corrupt. Specifically the website may review the contents of the file transfer server directories which store uploaded data assets archived data assets and corrupt data assets. It may further receive notifications from crawler application as to what percentage of an operation such as transcoding is complete. If a data file is to be prioritized for upload or transcoding the website might provide a control to configure the crawler application accordingly.

Mobile client shows an alternative architecture for a client. Here car service combines the functionality of client application and synchronizing application . Additionally it provides network connectivity to a supervisor application . Supervisor application provides the ability to provide remote control over client and to view configuration status and stored data assets on client . On mobile client the mobile configuration and the captured data assets are stored in the same store . Data assets are captured and reviewed locally by application .

The following describes features and advantages enabled by the platform as disclosed for law enforcement.

Police and security video may be used in evidence at trial. However in order to be admissible the evidence must be stored such that an unbroken chain of custody can be made ensuring that the evidence was not tampered with. With the embodiments as disclosed a metadata tag to store an Officer ID and a metadata tag to store a timestamp and action may be made. When the police video is stored the tag stored the Officer ID of the owner of the mobile client. When the officer uploads for storage the officer authorizes the upload which again tags the police video with Officer ID timestamp and action. When the data is received and archived the archival officer may again tag the police video with his Officer ID timestamp and action. Thus at all stages the chain of custody of the video may be verified. For further security the metadata may be encrypted. Alternatively checksums may be archived in a database to detect later tampering.

Because all video is uploaded and archived citizens who have been stopped may request an identifier for the video clip capturing their stop and a limited access account. The citizen may then go to the law enforcement agency s web site log on and then view the footage of their stop. This will provide an incentive for officers to avoid excessive force and can provide evidence for and against any culpability.

When suspects in custody are interrogated by police officers typically there is a camera to memorialize the event. However a determined police officer can disable a typical security camera. If a mobile client enabled with RFID and preview is in the room it will be difficult to tamper with the camera. Specifically an officer with an RFID badge enters the interrogation room. The RFID badge not only triggers video recording it also makes use of preview mode to capture the first 10 seconds prior to entry. Therefore even if the officer were to tamper with the camera the camera would have captured the first few seconds and would detect the tampering.

Often officers enter hazardous situations. When an officer is assaulted the officer may hit a hotkey on the mobile device that acts as a panic button. The mobile client sends a notification that includes the officer identity and the officer s location which then goes to the NOC. The supervisor mode of the NOC includes map showing nearby officers which are also broadcasting their locations via GPS or other location services. The officer at the NOC may then quickly dispatch the proximate officers to the location.

Police videos are often used as evidence in trial. The embodiments as disclosed support post process editing of videos. Because it may be desirable to black out portions of video as unfairly prejudicial both district attorneys and defense lawyers may edit out or black out portions of the video to be left out of the trial record. One way to do this is via professional post processing tools. A less expensive alternative would be to use an overly tool a block of non color over top of the video to place overlays blocks over the portions of the video to be blocked out. In this way not only could portions of frames be provided rather than full blackout faster turnaround of editing could occur.

A variation of mobile officers carrying mobile clients is to have a mesh of security towers covering a geographic area. This would enable close circuit surveillance over an arbitrary area with minimal installation costs. Examples of locations where these may be applicable include but are not limited to be college campuses airports prisons and high crime areas. It is to be noted that a mesh of camera towers need not be limited to law enforcement scenarios. For example a mesh of camera towers at a sporting event or an entertainment event would provide improved media coverage of the event. Each of the towers would have a mobile client configured with a full network stack to allow remote control over IP and Wi Fi and a file manager to manage file upload and file deletion. Both the network stack and the file manager are discussed in and the supporting text.

Each camera is network enabled and is independent in that it is a self contained recording and storage device that adds metadata such as time and location. Because the cameras house these on board capabilities all that is needed locally is power. No communication cabling would be required.

Each camera could be configured to host a synchronizing application that was able to detect proximate cameras. An embodiment would be to refer to a web service that tracked the location of each installed camera and from knowledge of its local location could select proximate cameras.

To aid in backwards compatibility where a camera did not have the necessary hardware initially a hardware block with the missing hardware e.g. to enable network connectivity could be attached and the necessary software components installed. Accordingly previously purchased hardware could be made to be compatible for mesh applications.

However collectively the cameras act together as a mesh of cameras that give a law enforcement agency a comprehensive view of what happened at the same location or close by locations at the same time. A NOC s supervisor mode could quickly search for all uploaded data assets from the camera at a particular time and location and then view and edit them together.

Note that the cameras all networked peer to peer devices. Accordingly an officer cold come to a location where there were several devices present such as the scene of a crime or other event and could determine on his laptop or cell phone the locations of all the cameras. The officer could then choose cameras to download video to his laptop or cell phone or by default download all videos from the surrounding cameras.

A camera need not start out as part of a mesh. A camera may operate independently until another camera is added to the network to establish a mesh. Thus a single camera perhaps mounted on a pole could provide ad hoc surveillance in a relatively short period of time. As time went on other cameras could be incrementally added to establish a mesh. Cameras could also be removed as necessary.

A non law enforcement scenario for using mesh is to replay sports games. Professional and other sports team s videotape games and practices to better assess points of weakness and to identify ways to improve the team and individual player s performance. An ability to view a play or action from multiple angles would provide a comprehensive way to assess the action.

By providing a mesh of multiple cameras incorporating the disclosures herein multiple cameras may synchronize to the same clock. If four surrounding cameras were configured to view a play and were synchronized the configuration would provide a quad view. Alternatively cameras in the mesh could provide a mix of different views for example a coach s view views from two different players and perhaps two sideline shots.

Per editing software using the metadata features disclosed herein metadata specific to game analysis indicating for example the particular play the context of the game and players involved could be added. For example for a football game metadata indicating that a particular segment of media represented a first down a running play where Jones was the runner could be added. In addition to providing context upon playback it also provides metadata enabling searching and filtering on kinds of plays players and other elements of interest in analyzing the game.

The game analysis metadata need not be rendered but could also be used for statistical analysis of the game. One could determine likelihood of how a team or player reacted according to different situations. For example in football one could determine that a team was significantly more likely to do a long pass on a first down than other teams.

Cameras using the present embodiment have a sharable format thus different teams could agree to share media with each other. Because the camera s clocks could be synced to a global source e.g. a web accessible value of global time the different media could be synchronized with each other even though they had been recorded separately by different parties. Accordingly different views designed from different perspectives may be correlated together.

Commercial embodiments are not limited to law enforcement. The following are some other commercial scenarios supported by the platform.

The embodiments as disclosed can replace a taxicab s meter box and camera with a single device. Currently most taxicabs install a meter box to show the fare charge. Some taxicabs also install a camera to show the face of the driver to the passenger. However meter boxes only show charges not distance route or other information that may be of interest to the passenger.

A taxicab hosted client as disclosed with a video camera and a GPS or other geolocation tracker integrated with a map database and an external charge database may perform the roles of the meter box and camera for a lower price and with greater functionality including but not limited to a a view for the passenger with start and end points on the map with the specified route as calculated by software also shown so the passenger could proactively request a different route b the passenger view displaying progress on the route by showing the taxicab s GPS tracking samples as the trip progresses c the passenger view additionally showing not just taxicab fare information but also time and distance information traffic alerts predictions of arrival time d a log of the trip could be stored and uploaded via the mobile connection or in the alternative could update via Wi Fi upon parking in order to provide an audit trail to a central office e the passenger view could provide average trip times and other aggregated information from the audit information f the client integrated with a printer could give a receipt with the information from the view upon request of the passenger and g uploaded audit information could be used in training new taxicab drivers.

The present embodiments could monitor pickup and drop off of children. Currently typical school buses do not have onboard cameras. Accordingly determining whether a child was dropped off at the correct location on the way home or in the alternative determining if a child was correctly picked up relies on the bus driver s memory. In the case of a missing child the camera could provide objective evidence as to whether the child was on the bus or not.

A school bus hosted client of the present embodiments with an eventing system for door opening and closing a video camera with preview and a geolocation tracker integrated with a map database includes but is not limited to the following advantages a when the school bus door opens or closes the custom eventing system could trigger recording of the video camera b the video camera would have several seconds of preview buffer so would record a those several seconds along with the actual event of a child entering or exiting the school bus c the custom eventing system could trigger turning off the video camera d the geolocation tracker could trigger upon turning on the camera as well and along with a map database indicate where the pickup or drop off occurred e the information could be archived to a central office via cellular upload or Wi Fi and f the archived information could be aggregated for statistics and in where no errors of pickup or drop off occurred the information could be deleted to save storage.

The present embodiments could monitor accidents for bulk transportation such as semi rig trucks. Currently semi rigs do not have onboard cameras. Accordingly disproving the liability of a semi rig in the event of an accident is difficult.

A truck hosted client of the present embodiments with an eventing system triggered by a vehicle crash detector such as disclosed in U.S. Pat. No. 4 161 228 which triggers airbags a video camera with preview a geolocation tracker integrated with a map database includes but is not limited to the following advantages a when the vehicle crash detector detects a crash the custom eventing system could trigger recording of the video camera b the video camera would have several seconds of preview buffer so would record a those several seconds along with the actual event of the crash and c the geolocation tracker could trigger upon turning on the camera as well and along with a map database indicate where the accident occurred and upon upload could notify a central office as to dispatch a response team. Additional advantages may be realized by further integration with a telematics system which provides additional digital telemetry about the state of the truck. For areas that did not have cell phone coverage alternative data transport such as packet radio could be implemented.

As a hybrid of the previous School Bus and Trucking scenarios an embodiment of the present disclosure could monitor accidents on school buses as well. Currently school buses do not have onboard cameras. Accordingly determining causality and harm to children on the bus is difficult to prove.

A set of school bus hosted clients as described by the present disclosure specifically with one or more cameras recording events outside of the bus and one or more cameras recording events within the bus with an eventing system for crash detection a video camera with preview and a geolocation tracker integrated with a map database includes but is not limited to the following advantages a comprehensive monitoring for how events outside of the bus impact events inside the bus including but not limited to bus collisions b the video camera would trigger from a collision and would have several seconds of preview buffer enabling it to record several seconds prior to the collision c the crash detector event could also trigger a collision message to a central location along with geolocation data indicating where the collision occurred d the information could be archived to a central office via cellular upload or Wi Fi and e the central office could collect media from cameras not on the bus to provide different angles of the accident.

The descriptions of the above scenarios are not intended to be an exhaustive list of uses of the present embodiments and are only some of the many possible applications made possible.

In compliance with the statute the subject matter of this application has been described in a language more or less specific as to structure and method features. It is to be understood however that the embodiments are not limited to the specific features described since the disclosure herein comprise exemplary forms of putting the present embodiments into effect. The present embodiments are therefore claimed in any of its forms or modifications within the proper scope of the appended claims appropriately interpreted in accordance with the doctrine of equivalents and other applicable judicial doctrines.

