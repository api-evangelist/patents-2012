---

title: Graphics power control with efficient power usage during stop
abstract: In an embodiment, a processor that includes multiple cores may implement a power/performance-efficient stop mechanism for power gating. One or more first cores of the multiple cores may have a higher latency stop than one or more second cores of the multiple cores. The power control mechanism may permit continued dispatching of work to the second cores until the first cores have stopped. The power control mechanism may prevent dispatch of additional work once the first cores have stopped, and may power gate the processing in response to the stopping of the second cores. Stopping a core may include one or more of: requesting a context switch from the core or preventing additional work from being dispatched to the core and permitting current work to complete normally. In an embodiment, the processor may be a graphics processing unit (GPU).
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09035956&OS=09035956&RS=09035956
owner: Apple Inc.
number: 09035956
owner_city: Cupertino
owner_country: US
publication_date: 20120508
---
This invention is related to power management in integrated circuits and systems employing integrated circuits.

As the number of transistors included on an integrated circuit chip continues to increase power management in the integrated circuits continues to increase in importance. Power management can be critical to integrated circuits that are included in mobile devices such as personal digital assistants PDAs cell phones smart phones laptop computers net top computers etc. These mobile devices often rely on battery power and reducing power consumption in the integrated circuits can increase the life of the battery. Additionally reducing power consumption can reduce the heat generated by the integrated circuit which can reduce cooling requirements in the device that includes the integrated circuit whether or not it is relying on battery power .

Clock gating is often used to reduce dynamic power consumption in an integrated circuit disabling the clock to idle circuitry and thus preventing switching in the idle circuitry. Additionally some integrated circuits have implemented power gating to reduce static power consumption e.g. consumption due to leakage currents . With power gating the power to ground path of the idle circuitry is interrupted reducing the leakage current to near zero.

Power gating can be an effective power conservation mechanism. On the other hand power gating reduces performance because the power gated circuitry cannot be used until power is restored and the circuitry is initialized for use. The tradeoff between performance especially perceived performance from the user perspective and power conservation is complex and difficult to manage. In particular the process of stopping a block in order to power gate the block consumes power but does not improve performance.

In an embodiment a processor that includes multiple cores may implement a power performance efficient stop mechanism for power gating. One or more first cores of the multiple cores may have a higher latency stop than one or more second cores of the multiple cores. The power control mechanism may permit continued dispatching of work to the second cores until the first cores have stopped. The power control mechanism may prevent dispatch of additional work once the first cores have stopped and may power gate the processing in response to the stopping of the second cores. In one embodiment stopping a core may include requesting a context switch from the core. Alternatively stopping a core may include preventing additional work from being dispatched to the core and permitting current work to complete normally. In an embodiment one stopping mechanism may be used for the first cores and another stopping mechanism may be used for the second cores. In an embodiment the processor may be a graphics processing unit GPU .

While the invention is susceptible to various modifications and alternative forms specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood however that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

Various units circuits or other components may be described as configured to perform a task or tasks. In such contexts configured to is a broad recitation of structure generally meaning having circuitry that performs the task or tasks during operation. As such the unit circuit component can be configured to perform the task even when the unit circuit component is not currently on. In general the circuitry that forms the structure corresponding to configured to may include hardware circuits and or memory storing program instructions executable to implement the operation. The memory can include volatile memory such as static or dynamic random access memory and or nonvolatile memory such as optical or magnetic disk storage flash memory programmable read only memories etc. Similarly various units circuits components may be described as performing a task or tasks for convenience in the description. Such descriptions should be interpreted as including the phrase configured to. Reciting a unit circuit component that is configured to perform one or more tasks is expressly intended not to invoke 35 U.S.C. 112 paragraph six interpretation for that unit circuit component.

Turning to a block diagram of one embodiment of a GPU is shown. In the illustrated embodiment the GPU includes a fabric interface unit a processor a GPU firmware computer accessible storage medium and a set of GPU execution engines A N. The GPU execution engines A N and the processor are coupled to the fabric interface unit . The processor is also coupled to the GPU firmware computer accessible storage medium . The fabric interface unit is coupled to a fabric interface arrow to communicate with other portions of an integrated circuit IC see e.g. such as a central processing unit CPU an IC PMU etc. Together the processor and the GPU firmware computer accessible storage medium form a power management controller in this embodiment. Other embodiments may include hardware circuitry that implements a portion or all of the power management controller . Any combination of hardware and processor executable software may be used.

The GPU cores A N may be execution hardware configured to perform various graphics processing operations. For example the execution cores A N may include one or more 3 dimensional 3D cores configured to perform 3D graphics rendering and one or more 2D cores configured to render 2D images. Alternatively or in addition the GPU cores A N may include unified shaders vertex and pixel pixel shaders vertex shaders texture processing units rasterizers etc. There also may be various caches not shown in . Cores may be processors execution engines and or processing units in various embodiments.

As highlighted above the GPU cores A N may not be symmetrical. Each core A N may have varying attributes including a latency for stopping execution during use. That is some cores A N may stop with a lower latency than other cores A N. Stopping a core may be implemented in a variety of fashions in various embodiments. For example as mentioned previously additional work may not be assigned to a core if it is to be stopped and the core may be permitted to run its current work to completion. Another previously mentioned example is the use of a context switch function to stop a core A N. This example is illustrated in with the context switch CS interface to each core A N. An interrupt may also be used to stop a core in some embodiments causing the core to exit a task to an interrupt service routine .

The latency for stopping various cores may vary. For example in the case that a current task is permitted to run to completion but additional work is not assigned to the stopping core the latency may vary from core to core. Tasks performed by one core may be more complex than those performed by another core and thus may incur more latency to complete on average. Similarly GPU cores may vary in context switch latency. Generally a context switch may include saving of GPU core state so that the task being switched from may be continued upon a return to the context. Context switches may be used to stop one task to permit another task to be performed on the same GPU core. In this case the context switch may be used to stop a task for power down. The context switch latency may depend on the amount of state to be saved the efficiency of the context switch implementation etc. Similarly the latency to recognize an interrupt save state of the current task not necessarily the same amount of state as a context switch often less and initiating fetch at the interrupt service routine address may vary. In one embodiment a halt instruction that causes the core to stop may be stored at the interrupt service routine address to complete the halt for embodiments that implement the interrupt mechanism.

The power management controller may be configured to determine that the GPU is to be powered down. In some embodiments the determination may be responsive to a message received by the power management controller requesting the power down. The message may be transmitted e.g. by a driver executed on a CPU in a system including the GPU . Alternatively the power management controller may be configured to determine that the GPU is to be powered down via monitoring of the activity in the GPU the power consumed in the GPU as compared to a limit etc. In response to the determination that the GPU is to be powered down the power management controller may be configured to cause the longer latency GPU cores A N to stop. The stop may be a request e.g. requesting a context switch or may occur due to completion of a current task while additional tasks are inhibited from being scheduled to the cores.

In one embodiment the power management controller may permit additional work to be issued to one or more GPU cores A N that have shorter stop latencies while waiting for one more GPU cores A N that have longer stop latencies to stop. In an embodiment that implements context switching to stop a GPU core A N the power management controller may request a context switch from the higher latency GPU core s and may permit continued issuance of work to remaining GPU cores. In some embodiments the power management controller may also be configured to issue the additional work e.g. other routines in the GPU firmware storage may issue work to cores such as providing a descriptor pointer to the core where the descriptor pointer points to a memory descriptor that specifies the work . In other embodiments the GPU work may be issued by other hardware and or software but may be permitted or not permitted by the power management controller . By permitting additional work to be issued the lower latency cores may continue to perform useful work when they would otherwise be powered up but idle and awaiting the longer latency cores to complete their stop.

The fabric interface unit is configured to receive transactions from the fabric interface for the GPU . The transactions may include commands from the CPU . The transactions may also include responses to read requests transmitted by the GPU to read work descriptors from memory and or to read data to be operated upon by the GPU . The fabric interface unit may also be configured to transmit the read requests as well as write requests to write results generated by the GPU to memory.

The processor may be configured to execute the firmware from the GPU firmware computer accessible storage medium . The computer accessible storage medium may be any type of storage medium including the types described below with respect to . Particularly in an embodiment the computer accessible storage medium may be any type of non volatile memory including Flash memory various programmable read only memories etc. Volatile memory e.g. random access memory may also be used if the firmware is loaded into the memory at the time the system is booted and the memory is powered during power down events.

In an embodiment the processor may be a microcontroller. A microcontroller may be a processor that also includes specific interfaces to more easily embed within a device such as the GPU . For example in the embodiment of the microcontroller may include a non volatile memory interface e.g. a Flash memory interface and an interface to the fabric interface unit . Additionally the microcontroller may include context switch interfaces to each of the GPU cores A N. The context switch interfaces may have a variety of forms. For example the context switch interface may include a request transmitted by the processor and an acknowledgement completion indication from the GPU core A N. The request may be a signal e.g. asserted to indicate a context switch request and deasserted to indicate no request. Similarly the acknowledgement completion indication may be a signal asserted to indicate acknowledgement completion or deasserted to indicate no acknowledgement in progress. CPUs by way of contrast typically include a general bus interface rather than specific interfaces for a specific implementation.

Turning now to a state machine illustrating exemplary states which may be implemented in the power management controller for one embodiment is shown. In the illustrated embodiment there is a normal state a power down preparation state and a power down state .

In the normal state the GPU may be operating at full power or may be power managed among various operating points e.g. voltage clock frequency combinations by components external to the GPU such as by a GPU driver executed on a CPU . The power management controller may generate a power down request responsive to measuring various activity in the GPU or may receive a power down request from an external source such as the GPU driver. For example in one embodiment the power management controller may be configured to manage a duty cycle within each frame time associated with the GPU . The frame time may be the amount of time that a frame is displayed for a user in a video sequence and thus may be a bound on the amount of time that the GPU has to render the next frame. The duty cycle may be a limit to the amount of time that the GPU may be on during the frame time e.g. to met a power consumption target thermal limit etc. . When the duty cycle ends the GPU power management controller may generate the power down request. Alternatively the duty cycle determination may be made by the GPU driver or the GPU driver may implement other power management schemes and may generate power down requests.

The power down request may cause a transition to the power down preparation state . In the power down preparation state the power management controller may stop the GPU cores A N so that the power down may occur. Once the GPU cores A N are halted the state machine may transition to the power down state and the GPU may be powered down. The power management controller may control the powering down power gating sending a request to a power management unit in the system to power gate the GPU . In response to a power up request the GPU may be powered up again and the power management controller may return to the normal state .

Turning now to a flowchart is shown illustrating operation of one embodiment of the power management controller in the power down preparation state . While the blocks are shown in a particular order for ease of understanding other orders may be used. In embodiments that implement a portion or all of the power management controller in hardware blocks may be performed in parallel in combinatorial logic in the hardware. Blocks may be implemented as instructions stored in the GPU firmware storage and executed by the processor . The embodiment of implements a context switch for stopping the long latency GPU cores A N. Similar operation may be implemented for use of an interrupt to stop the long latency GPU cores A N.

The power management controller may be configured to request a context switch from the long latency cores block and may be configured to begin monitoring for the context switch to complete decision block . The context switch request from the power management controller and response from the cores acknowledgement completion may be transmitted over the context switch interfaces shown in . If the context switch is not complete decision block no leg and there is additional work available to transmit to the short latency cores decision block yes leg the power management controller may be configured to dispatch the next task to the short latency cores block . Alternatively the power management controller may permit a separate task scheduler to dispatch the next task rather than controlling the dispatch itself. The next task may be dispatched in response to a given short latency core completing its current task. The power management controller may continue monitoring the long latency cores for completion of the context switch decision block .

In response to completion of the context switch in the long latency cores decision block yes leg the power management controller may request a context switch from the short latency cores block . The power management controller may monitor for completion of the context switch in the short latency cores decision block . Once the context switch is complete decision block yes leg the power down preparation is complete all cores are halted and the transition to the power down state may be performed.

It is noted that the detection of context switch completion may be with respect to each of the long latency cores decision block and each of the short latency cores decision block . Thus if there is more than one long latency core the decision block may complete successfully once each long latency core has completed its context switch. Similarly if there is more than one short latency core the decision block may complete successfully once each short latency core has completed its context switch. It is further noted that completion of the context switch may indicate that the corresponding core is idle.

Turning next to a flowchart is shown illustrating operation of another embodiment of the power management controller in the power down preparation state . While the blocks are shown in a particular order for ease of understanding other orders may be used. In embodiments that implement a portion or all of the power management controller in hardware blocks may be performed in parallel in combinatorial logic in the hardware. Blocks may be implemented as instructions stored in the GPU firmware storage and executed by the processor . The embodiment of implements run to completion of current tasks for stopping the long latency GPU cores A N.

The power management controller may begin inhibiting the dispatch of additional work to the long latency cores block . If the current in progress tasks have not yet completed in the long latency cores decision block no leg and there is additional work available to transmit to the short latency cores decision block yes leg the power management controller may be configured to dispatch the next task to the short latency cores block . Alternatively the power management controller may permit a separate task scheduler to dispatch the next task rather than controlling the dispatch itself. The next task may be dispatched in response to a given short latency core completing its current task. The power management controller may continue monitoring the long latency cores for completion of the current tasks decision block .

In response to completion of the current tasks in the long latency cores decision block yes leg the power management controller may request a context switch from the short latency cores block . The power management controller may monitor for completion of the context switch in the short latency cores decision block . Once the context switch is complete decision block yes leg the power down preparation is complete all cores are halted and the transition to the power down state may be performed.

It is noted that the detection of current task completion may be with respect to each of the long latency cores decision block . Thus if there is more than one long latency core the decision block may complete successfully once each long latency core has completed its current task. Similarly detection of the completion of the context switch for the short latency cores may be with respect to each short latency core. Thus if there is more than one short latency core the decision block may complete successfully once each short latency core has completed its context switch. It is further noted that completion of the current task or the context switch may indicate that the corresponding core is idle.

Some of the embodiments herein use a GPU as an example of the processor for which the power management techniques are used. However other embodiments may implement the techniques with any processor e.g. a central processing unit CPU other special purpose processors such as input output processors IOPs digital signal processors DSPs embedded processors microcontrollers etc. . Still further other embodiments may implement the power management to control fixed function circuitry.

The PMU is configured to generate voltage requests to the power supply which is configured to supply the requested voltages on one or more voltage inputs to the IC . More particularly the PMU may be configured to transmit a request for a desired voltage magnitude including a magnitude of zero when the corresponding circuitry is to be powered down in some embodiments . The number of independent voltage inputs supported by the IC may vary in various embodiments. In the illustrated embodiment the Vinput is supported for the GPU along with a Vinput for the CPU and a Vinput for the rest of the integrated circuit . Each voltage input may be provided to multiple input pins on the integrated circuit to support enough current flow and power supply voltage stability to the supplied circuitry. Other embodiments may power the CPU with a separate supply but the GPU may receive the Vsupply. Still other embodiments may include other non CPU voltage supplies besides the Vand Vinputs.

The supply voltage to power gated circuits such as the GPU may be controlled via voltage requests from the PMU but may also be controlled via power gate controls issued internally by the PMU e.g. the Power Gate control signals shown in . Gating the power internally may be performed more quickly than issuing voltage requests to the power supply and powering up may be performed more quickly as well . Accordingly voltage requests to the power supply may be used to vary the magnitude of the supply voltage to adjust an operating point of the GPU and the power gating during times that the GPU is sleeping or off may be controlled internal to the IC .

The power measurement circuit may e.g. be configured to measure the current flow on the Vsupply. Based on the requested voltage the power consumed in the GPU may be determined either by the power measurement circuit or the PMU . The power measurement circuit may e.g. be readable by software to determine the current power measurement or may supply the current power measurement on an input to the IC .

The clock generator may supply clocks to the CPU CPU Clk in the GPU GPU Clk in the PMU and any other circuitry in the IC . The clock generator may include any clock generation circuitry e.g. one or more phase lock loops PLLs digital delay lock loops DLLs clock dividers etc. . The clock generator may be programmed by the PMU to set the desired clock frequencies for the CPU clock the GPU clock and other clocks.

Together the supply voltage and clock frequency of a circuit in the IC may be referred to as an operating point for the circuit. The operating point may directly affect the power consumed in the circuit since the dynamic power is proportional to the frequency and to the square of the voltage. Accordingly the reduced power consumption in the circuit when both the frequency and the voltage are reduced may be a cubic effect. However operating point adjustments which change only the frequency or only the voltage may be made also as long as the circuitry operates correctly at the selected frequency with the selected voltage .

The CPU may be any type of processor and may implement an instruction set architecture. Particularly the CPU may implement any general purpose instruction set architecture. The CPU may have any microarchitecture including in order or out of order speculative or non speculative scalar or superscalar pipelined multithreaded etc.

The GPU may implement any graphics application programming interface API architecture. The graphics API architecture may define an abstract interface that is specially purposed to accelerate graphics operations. The GPU may further support various languages for general purpose computation e.g. OpenCL etc.

The temperature sensors A B may be any type of temperature sensing circuitry. When more than one temperature sensor is implemented the temperature sensors may be physically distributed over the surface of the IC . In a discrete implementation the temperature sensors may be physically distributed over a circuit board to which the discrete components are attached. In some embodiments a combination of integrated sensors within the IC and external discrete sensors may be used.

It is noted that while the illustrated embodiment includes components integrated onto an IC other embodiments may include two or more ICs and any level of integration or discrete components.

Turning next to a block diagram illustrating communication between a GPU driver executed by the CPU and GPU firmware executed by the processor is shown for one embodiment. The GPU driver may generate one or more GPU work descriptors . The work descriptors may be data structures in memory and may describe the tasks to be performed by the GPU . For example the data structures may include pointers to objects in memory that are to be rendered into a frame buffer for display on a display screen. The GPU driver may complete one or more work descriptors and may generate a kick command to the GPU to indicate that the work descriptors are available. In response to the kick command the GPU firmware may read the GPU work descriptors from memory and may cause the GPU to perform the desired processing. In some embodiments the kick command may include the address of the work descriptors . In other embodiments the work descriptors may be stored at a predefined address that the GPU firmware may read.

The work descriptors may also include graphics commands to be performed or pointers to lists of commands to be performed. The commands may be defined for the GPU and may be the interface for other parts of the system to the GPU . The commands may be effectively an instruction set implemented by the GPU . Generally each item of work may be a task or tasks to be performed by the GPU .

The memory storing the GPU work descriptors and the GPU driver may be internal or external to the IC in various embodiments. In one implementation the memory may be external to the IC e.g. one or more dynamic random access memories DRAMs and there may be an memory controller internal or external to the IC to communicate with the external memory on behalf of the GPU the CPU and any other devices components included in the IC that use memory. The GPU firmware may be a portion of the firmware stored in the GPU firmware storage for example.

Turning now to a block diagram of a computer accessible storage medium is shown. Generally speaking a computer accessible storage medium may include any storage media accessible by a computer during use to provide instructions and or data to the computer. For example a computer accessible storage medium may include storage media such as magnetic or optical media e.g. disk fixed or removable tape CD ROM DVD ROM CD R CD RW DVD R DVD RW or Blu Ray. Storage media may further include volatile or non volatile memory media such as RAM e.g. synchronous dynamic RAM SDRAM Rambus DRAM RDRAM static RAM SRAM etc. ROM or Flash memory. Storage media may also include non volatile memory e.g. Flash memory accessible via a peripheral interface such as the Universal Serial Bus USB interface a flash memory interface FMI a serial peripheral interface SPI etc. Storage media may include microelectromechanical systems MEMS as well as storage media accessible via a communication medium such as a network and or a wireless link.

The computer accessible storage medium in may store an operating system OS the GPU driver and the GPU firmware . Each of the operating system the GPU driver and the GPU firmware may include instructions which when executed in the system may implement the operation described above. In an embodiment the OS and the GPU driver may be executed on the CPU and the GPU firmware may be executed on the GPU e.g. on the processor . A carrier medium may include computer accessible storage media as well as transmission media such as wired or wireless transmission.

Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.

