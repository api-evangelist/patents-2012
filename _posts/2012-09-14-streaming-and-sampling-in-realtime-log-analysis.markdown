---

title: Streaming and sampling in real-time log analysis
abstract: Technologies are described herein for incorporating streaming and/or sampling in real-time log analysis. Representative samples of log data are extracted from the log files on a number of monitored hosts and streamed in real-time to log processors for processing. The log processors accumulate and process the representative samples of log data, and track a data completeness value representing an indication of a proportion of total log data represented by the representative samples received. The representative samples of log data are merged and collated. Estimated metrics are calculated from the merged and collated representative samples and the data completeness, and the estimated metrics are published to consumers in near real-time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08850263&OS=08850263&RS=08850263
owner: Amazon Technologies, Inc.
number: 08850263
owner_city: Reno
owner_country: US
publication_date: 20120914
---
Real time Log Analysis RTLA may allow an organization to monitor the service and error logs of a number of host computers and devices in near real time in order to spot trends in service performance or customer demand as well as to troubleshoot potential problems. An RTLA system may collect log data from the host computers and devices process and collate the collected data and analyze the collated data to generate service metrics. These metrics may then be published to host management systems alarming and alerting services reporting and graphing services and support services. The generated metrics may include fatal error counts rates page views service availability host access rates hardware performance measures and the like. Management and support personnel may utilize the published metrics and processed and collated log data to be alerted to potential problems or failures troubleshoot host or service problems determine additional resources that need to be made available to meet growing demand spot trends in service or product demand and the like.

In an RTLA system that monitors a large number of services and or hosts the high volume of log data collected processed and analyzed may result in an unacceptable latency between the logging of events errors and publishing of the related metrics. For example in a system comprising tens of thousands of host computers the RTLA system may collect and process multiple terabytes of log data daily and may incur a latency between the logging of events errors and the generation and publishing of the related metrics on the order of several minutes such as 8 to 10 minutes. In addition a sudden increase in log volume due to external events such as a denial of service DoS attack or deployment of bad code may further increase the latency in the RTLA system delaying investigation and analysis of potential problems. Such a delay in investigation and resolution of problems may result in prolonged service unavailability leading to significant loss of revenue violation of service level agreements and the like.

The following detailed description is directed to technologies for incorporating streaming and or sampling in real time log analysis. Utilizing the technologies described herein an organization may augment or replace an RTLA system with smart sampling of log data as well as streaming of log data in real time to make estimated metrics and representative log data available to consumers with reduced latency. Smart sampling of the log data may reduce the volume of log messages that must be processed while retaining the data of interest to the consumers from the logs. Furthermore coupling smart sampling with streaming of the sampled log data from the monitored hosts to the back end services for processing may reduce the latency between the logging of events errors at the hosts and the publishing of estimated metrics and representative data to the consumers to near real time i.e. to seconds instead of minutes for example. This may allow consumers of the estimated metrics to immediately identify trends or patterns in the metrics that may require immediate response such as an indication of a pending failure or problem a spike in demand requiring quick provisioning of additional resources to reduce service unavailability an indication of a security breach or DoS attack and the like.

It should be appreciated that the subject matter presented herein may be implemented as a computer process a computer controlled apparatus a computing system or an article of manufacture such as a computer readable storage medium. These and various other features and embodiments will become apparent from a reading of the following disclosure and a review of the associated drawings.

While the subject matter described herein is presented in the general context of program modules that execute on one or more computing devices those skilled in the art will recognize that other implementations may be performed in combination with other types of program modules. Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that the subject matter described herein may be practiced on or in conjunction with other computer system configurations beyond those described below including multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers handheld computers personal digital assistants cellular telephone devices electronic book readers special purposed hardware devices network appliances and the like. The embodiments described herein may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

In the following detailed description references are made to the accompanying drawings that form a part hereof and that show by way of illustration specific embodiments or examples. The drawings herein are not drawn to scale. Like numerals represent like elements throughout the several figures.

Each host may execute an RTLA agent . The RTLA agent may be implemented as software hardware or any combination of the two. According to embodiments the RTLA agent may scan service and error logs on the host for particular types of log messages generated by the executing services and applications or the host hardware. For example the RTLA agent may be configured to scan the service and error logs to identify fatal errors such as HTTP 500 errors from a Web service or internal application failures from an application executing on the host. The RTLA agent may further periodically collect the identified log messages also referred to herein as log data from the various service and error logs and transmit the log data to a number of log processors executing on one or more log processing server s . In some embodiments the RTLA agent may be further configured to identify and filter data from the log messages that may be more interesting to consumers of the RTLA data. For example the RTLA agent may be configured to report log messages having the same signature fatal error only once or in the case of a series of fatal errors only extract the stack trace from the associated log message s for example.

The log processing server s may represent conventional server computers virtual machines executing on a host hardware platform network appliances or any combination of these and other computing devices. The log processing server s may be connected to the host computers by one or more networks not shown for example. The log processors may represent one or more software or hardware modules executing on the log processing server s and or other computing platforms. The RTLA agent may transmit the log data collected on the host to particular log processor s or log processing server s based on local configuration parameters for example. In some embodiments the RTLA agent may select the log processor s to which to transmit the log data based on the particular service or error log from which the log data was extracted and or the like. According to some embodiments the RTLA agents may collect the log data from the service and error logs at a configured interval such as every minute and transmit the log data to the log processors in one minute log data chunks . It will be appreciated that other intervals beyond one minute may be configured and that the interval may affect the latency of making representative data and metrics available to consumers from the service and error logs of the hosts in the RTLA system.

The log processors may receive the log data chunks and split the log data into one or more databases or log data files such as data tables indexes and the like. The log processors may further provide the processed log data in data cubes . The dimensions in the data cubes may include host ID host type host session page ID page type request ID request type customer ID source log and or other categories of the logged messages. The log data may be accumulated in log data files and the data cubes over the configured interval of each log data chunk producing one minute data cubes for example. In further embodiments the log processors may summarize dimensions over total log data and not just the identified fatal error log messages for example.

The processed log data in the log data files and data cubes for the configured interval may then be made available to other services for consumption as will be described below. For example the log processing server s may provide an application programming interface API for the consumption of the log data files and the data cubes . Additionally or alternatively the log processing server s may push the processed log data in the log data files and or the data cubes to other services for consumption such as a long term storage service not shown that may store the received log data chunks and or the processed log data in the log data files and data cubes for future analysis.

The environment may further include one or more data accumulation server s . The data accumulation server s may represent conventional server computers virtual machines executing on a host hardware platform network appliances or any combination of these and other computing devices. The data accumulation server s may be connected to the log processing server s by one or more networks not shown . A number of data accumulation tasks may execute on the data accumulation server s . The data accumulation tasks may represent one or more software or hardware modules executing on the log processing server s and or other computing platforms.

The data accumulation tasks may pull the data cubes and associated log data files from the log processing server s and generate merged cubes . The merged cubes may comprise log data from multiple log processing servers s or log processors merged across hosts across multiple configured intervals and the like. In addition the data accumulation tasks may collate the log data in the merged cubes across one or more dimensions. For example a single request identified by a request ID may result in fatal error messages logged in multiple service and error logs or across multiple hosts such as in the case where the request is received by a Web service and then issues multiple requests to other services to collect content to satisfy the original request. The data accumulation tasks may collate the multiple log messages from across the hosts and or service and error logs by request ID in order to eliminate redundant fatal errors for a single request.

The data accumulation tasks may then utilize the merged cubes to generate a number of configured metrics and other accumulated log data for the monitored hosts . Such metrics may include fatal error rates over time error rates by function or module request counts and latency hardware errors security metrics CPU utilization free memory and available storage space and any other metrics that may be determined from the log data. The data accumulation tasks may further be configured to utilize consumer configured log messages generated by services and applications executing on the monitored hosts to calculate customizable metrics such as access rates by webpage views by product access by region or location access by user demographic inventory usage or spoilage and or any other measure that may be important to business or operational performance of the services and applications on the monitored hosts .

The generated metrics and other accumulated log data may then be published to consumers of the RTLA data as discussed above. Consumers of the RTLA data may include monitoring alerting service s that may be configured to alert administrative or support personnel when one or more metrics are out of bounds or when a trend in the metric is noticed host management service s that may include the ability to provision and initiate additional hosts services and or other resources in response to the metrics or trends in the metrics reporting service s that provide administrative or support personnel insight into the operations of the hosts and allow investigation of failures or other problems long term storage so that the metrics and other accumulated log data may be stored over longer periods for future analysis and any other consumers of the RTLA data that may be imagined by one skilled in the art.

In some embodiments the data accumulation tasks may wait a configured period of time such as 3 or 5 minutes before retrieving the log data from the log data files and or data cubes from the log processing server s in order to allow the log data chunks from the various hosts to arrive at the log processing server s data and to be processed by the log processors . The configured period of time may further add to the latency of the metrics and other log data being made available to consumers. In addition depending on the destination the publishing of the metrics and other accumulated log data may further add to the latency of the data before consumption.

Each host may execute a sampling agent . The sampling agent may be implemented as software hardware or any combination of the two. The sampling agent may be implemented as a component of the RTLA agent or execute in parallel to the RTLA agent for example. According to embodiments the sampling agent samples the service and error logs on the host to extract a portion of the log messages for further processing. In some embodiments the sampling agent may extract a representative sample of log messages from the service and error logs for processing such as a random 10 of the log messages or every tenth logged message for example. In other embodiments the sampling agent may apply more complex statistical sampling methods and heuristics to extract the representative sample.

According to some embodiments the sampling agent may utilize a hashing algorithm to sample the log messages from the service and error logs. For example a hash may be computed from a value present in every sampled log message such as a request ID or a timestamp and a tag added to the log message with the hashed value. The sampling agent may then sample those log messages containing a particular hash value or range of hash values for the representative sample. For example the sampling agent may apply a MOD 10 operation to the hash value tag and select those log messages that result in 0 for extraction. The use of the hashing algorithm to sample the log messages may have the added advantage that log messages from different service and error logs and or different hosts generated from the same request i.e. having the same request ID will all be included in the extracted representative sample. These log messages can then be combined collated by the accumulation tasks across the hosts and or service and error logs by the request ID in order to eliminate redundant fatal errors for a single request as described above in regard to .

In further embodiments the sampling agent may additionally or alternatively utilize sampling rules to apply smart sampling logic to the log messages of the service and error logs in addition to or as an alternative to the heuristics and statistical sampling described above. The sampling rules may comprise regular expressions regex query language statements code statements XML statements and or the like that allow patterns in the service and error logs to be matched in order to sample or extract data from targeted log messages that has been identified as being of particular interest. The sampling rules may further comprise rules that indicate data or patterns in log messages that are not to be included in the extracted representative sample or that are to be sampled with less frequency than other log messages.

In some embodiments the sampling rules may contain patterns that correspond to particular metrics defined for generation by the data accumulation tasks . For example if a rising trend in accesses from a certain geographical region has been determined to be an accurate indicator of a DoS attack then a metric for access by geographical region may be configured in the data accumulation tasks and a sampling rule comprising a pattern to match logged access messages and extract the geographical region or to match the identified offending region may be pushed to the hosts for use by the sampling agents in sampling the service and error logs . The sampling rules may be dynamic allowing new rules to be pushed to the hosts on a real time basis to change or tweak the types of log messages targeted the data to be extracted from the targeted log messages the percentage of log messages being sampled by the sampling agents and the like. In further embodiments the smart sampling logic may be combined with the identification and filtering logic of the RTLA agents described above to further filter the data sampled from the log messages.

The sampling agents may further stream the sampled log data in log data samples A N also referred to herein as log data samples to one or more sample processors . The sample processors may represent one or more software or hardware modules executing on the log processing server s and or other computing platforms. The sample processors may be a component of the log processors described above in regard to or the sample processors may execute in parallel to the log processors on the log processing server s for example. Each log data sample may contain a small amount of data comprising one or more sampled log messages or portions thereof and the sampling agent may stream the log data samples in real time using any number of multicast and or streaming protocols known in the art. It will be appreciated that the latency incurred by the periodic collection and transmission of the log data chunks described above may be reduced or eliminated by streaming the log data samples to the log processing server s in real time.

In some embodiments specific sample processors may subscribe to receive log data samples from specific sampling agents or hosts . In other embodiments the sample processors may listen for log data samples in the stream containing specific hash value tag s generated by the sampling agents as described above. This may allow the processing of the log data samples to be load balanced across multiple sample processors and or log processing server s . It will be appreciated that other methods for delivering the log data samples to the sample processor for processing may be imagined such as the selection of the target sample processor by the sampling agent based on configuration parameters and or the hash value tag computed for each log message and delivery of the log data samples to the target sample processor. It is intended that all such methods for delivering the log data samples to the sample processor be included in the scope of this application.

As in the case of the log processors the sample processors may split the sampled log data in the log data samples into a number of files and or databases such as the log data files and the data cubes described above in regard to . In some embodiments the sampled log data may be accumulated in the log data files and data cubes over the same or similar configured interval as in the RTLA system described above such as one minute. However the sampled log data in the log data files and the data cubes may be made available to the data accumulation tasks right away for collation and loading into the merged cubes . This may eliminate the latency added by the configured period of time that the data accumulation tasks wait to allow the log data chunks from the various hosts to arrive at the log processing server s data and to be processed by the log processors as further described above in regard to .

The sample processors may further maintain a measure of data completeness that indicates the proportion or percentage of total log data represented by the sampled log data received from the sampling agents and loaded into the log data files and the data cubes . The data completeness may be calculated from information received from the sampling agents regarding the sampling rate or the size of the samples for example. The data completeness may be utilized by the data accumulation tasks and other consumers of the processed log data to calculate estimated metrics over the configured interval from the portion or percentage of sampled log data processed by the sample processors and loaded into the merged cubes . The data accumulation tasks may then publish the estimated metrics to consumers that subscribe to the estimated metrics. This may include the monitoring alerting service s the host management service s the reporting services the long term storage and other consumers that have interest in estimates of the metrics being made available with a latency on the order of seconds instead of the 8 to 10 minutes described above.

In some embodiments the data accumulation tasks may be further configured to determine patterns or trends in the sampled log data such as the occurrence of a particular error and generate new or updated sampling rules which may then be fed back to the sampling agents as further shown in . This may allow for a feedback loop to be implemented that allows the data accumulation tasks to recognize patterns that indicate a pending event or events such as a pending failure and adjust the sampling process to generate more pertinent data for the event s . Alternatively or additionally the sample processors may also be configured to recognize the patterns or trends and generate the new or updated sampling rules . For example upon detecting a commonly occurring error the sampling rules may be updated such that the log entries resulting from the common error are not extracted by the sampling agents as frequently as other errors to avoid potential masking of the less common errors in the representative samples.

It will be appreciated that the estimated metrics generated from the sampled log data may allow the consumers to react more quickly to trends and patterns in the metrics that may indicate an impending failure or condition in the operation of the hosts . In addition complete correct metrics may be made available by the data accumulation tasks for the full log data processed by the log processors at a later time such as the 8 to 10 minute latency described above allowing administrative and support personnel to verify the failure or condition while having the forewarning provided by the estimated metrics derived from the sampled log data.

Turning now to additional details will be provided regarding the embodiments presented herein for incorporating streaming and or sampling in real time log analysis. It should be appreciated that the logical operations described herein are implemented 1 as a sequence of computer implemented acts or program modules running on a computing system and or 2 as interconnected machine logic circuits or circuit modules within the computing system. The implementation is a matter of choice dependent on the performance and other requirements of the computing system. Accordingly the logical operations described herein are referred to variously as operations structural devices acts or modules. These operations structural devices acts and modules may be implemented in software in firmware in special purpose digital logic and any combination thereof. It should also be appreciated that more or fewer operations may be performed than shown in the figures and described herein. These operations may also be performed in parallel or in a different order than those described herein.

From operation the routine proceeds to operation where the sampling agents stream the sampled log data to the sample processors . The sampling agents may stream the log data samples containing the sampled data to the sample processors using a multicast protocol for example. It will be appreciated that while some log data samples may be lost in the stream due to the nature of the multicast protocols the amount of data lost is usually very low and will likely not affect the accuracy of the estimated metrics calculated from the sampled log data. In addition the sampling agents may hash a value present in every sampled log message such as a request ID or timestamp and include the hash value in each log data sample . This may allow the sample processors to listen for log data samples in the stream containing specific hash value s so that processing of the log data samples may be load balanced across multiple sample processors and or log processing server s .

The routine proceeds from operation to operation where the sample processors process the sampled log data in the log data samples . For example the sample processors may split the sampled log data in the log data samples into log data files and data cubes as described above in regard to . In some embodiments the sampled log data may be accumulated in the log data files and data cubes over a configured interval such as one minute. However the sampled log data in the log data files and data cubes may be made available to the data accumulation tasks right away for collation and loading into the merged cubes eliminating the latency added by the configured period of time that the data accumulation tasks wait to allow the log data chunks from the various hosts to arrive at the log processing server s data and to be processed by the log processors as described above in regard to .

From operation the routine proceeds to operation where the sample processors determine the data completeness of the sampled log data processed as a percentage or proportion of the total log data for the configured interval. The data completeness may be determined based on the percentage of log messages sampled the number of data log samples received in the interval and the like. These values may be computed by the sample processors and or provided by the sampling agents for example. In addition the sampling rules currently being used by the sampling agents may additionally or alternatively be used to determine the data completeness or to determine separate data completeness values for different metrics. For example if log messages related to a particular error have a smaller inclusion rate than other log messages based on the applicable sampling rules currently in effect then the data completeness value determined with respect to any metric calculated for the particular error may be adjusted accordingly.

The routine proceeds from operation to operation where the data accumulation tasks utilize the sampled log data loaded into the merged cubes and the data completeness to calculate the estimated metrics . Next at operation the data accumulation tasks may publish the estimated metrics to consumers that subscribe to the estimated metrics. This may include the monitoring alerting service s the host management service s the reporting services the long term storage and other consumers as described above in regard to . It will be appreciated that while the estimated metrics may represent an estimate of the value of the metrics based on the sampled log data and the data completeness the estimated metrics may be available to consumers with a latency on the order of seconds instead of the 8 to 10 minutes described above in regard to the RTLA system shown in .

From operation the routine proceeds to operation where the sample processors and or the data accumulation tasks may determine patterns or trends in the sampled log data and generate new or updated sampling rules which may then be fed back to the sampling agents as discussed above in regard to . This may allow for a feedback loop to be implemented that allows the data accumulation tasks to recognize patterns in the log data that indicate a pending event or events such as a pending failure and adjust the sampling process to generate more pertinent data for the event s . From operation the routine ends.

While embodiments are described herein for sampling service and error logs on monitored hosts to calculate estimated metrics regarding the condition or operation of the services on the hosts it will be appreciated that the embodiments described herein may be utilized to obtain samples and recognize patterns in any data stream and to calculate associated estimated metrics in real time with very little latency especially when the exact value of the metric is not as important to trends in the metric that can be predictors of certain situations or events. For example specific sampling rules could be pushed to the monitored hosts that match a specific fatal signature and an estimated metric calculated for the rate of the fatal signature in real time. This may allow for alerting on patterns or trends in the rate of the fatal signature that foretell a pending failure. In another example an RTLA system could report estimated metrics such as the top ten viewed or purchased products at an e commerce site the top ten articles moving up the list in popularity on a news site and the like in real time.

In other embodiments smart sampling may be utilized to identify and collect specific information regarding the monitored hosts . For example consumers of an RTLA system monitoring GPS enabled mobile hosts may push a sampling rule to the hosts that will collect and transmit sampled log data indicating that the host is located at a particular location such as a particular business. The RTLA system may then alert the consumer through a monitoring alerting service for example causing the consumer to automatically issue a coupon to the user of the mobile host located in that particular location in real time. In further embodiments the sampling and streaming methods for RTLA described herein may be utilized to sample location logs for GPS enabled mobile hosts and identify or predict traffic problems at certain locations in real time to sample the logs of security devices in order to detect an attack or break in in real time and the like.

The computer includes a baseboard or motherboard which is a printed circuit board to which a multitude of components or devices may be connected by way of a system bus or other electrical communication paths. In one illustrative embodiment one or more central processing units CPUs operate in conjunction with a chipset . The CPUs are standard programmable processors that perform arithmetic and logical operations necessary for the operation of the computer .

The CPUs perform the necessary operations by transitioning from one discrete physical state to the next through the manipulation of switching elements that differentiate between and change these states. Switching elements may generally include electronic circuits that maintain one of two binary states such as flip flops and electronic circuits that provide an output state based on the logical combination of the states of one or more other switching elements such as logic gates. These basic switching elements may be combined to create more complex logic circuits including registers adders subtractors arithmetic logic units floating point units or the like.

The chipset provides an interface between the CPUs and the remainder of the components and devices on the baseboard. The chipset may provide an interface to a random access memory RAM used as the main memory in the computer . The chipset may further provide an interface to a computer readable storage medium such as a read only memory ROM or non volatile RAM NVRAM for storing basic routines that help to startup the computer and to transfer information between the various components and devices. The ROM or NVRAM may also store other software components necessary for the operation of the computer in accordance with the embodiments described herein.

According to various embodiments the computer may operate in a networked environment using logical connections to remote computing devices and computer systems through one or more networks such as a local area network LAN a wide area network WAN the Internet or any other networking topology known in the art that connects the computer to remote computers. The chipset includes functionality for providing network connectivity through a network interface controller NIC such as a gigabit Ethernet adapter. For example the NIC may be capable of connecting the computer to other computing devices over the network s such as the hosts the log processing server s or the data accumulation server s described above in regard to . It should be appreciated that any number of NICs may be present in the computer connecting the computer to other types of networks and remote computer systems.

The computer may be connected to a mass storage device that provides non volatile storage for the computer. The mass storage device may store system programs application programs other program modules and data which are described in greater detail herein. The mass storage device may be connected to the computer through a storage controller connected to the chipset . The mass storage device may consist of one or more physical storage units. The storage controller may interface with the physical storage units through a serial attached SCSI SAS interface a serial advanced technology attachment SATA interface a fiber channel FC interface or other standard interface for physically connecting and transferring data between computers and physical storage devices.

The computer may store data on the mass storage device by transforming the physical state of the physical storage units to reflect the information being stored. The specific transformation of physical state may depend on various factors in different implementations of this description. Examples of such factors may include but are not limited to the technology used to implement the physical storage units whether the mass storage device is characterized as primary or secondary storage or the like. For example the computer may store information to the mass storage device by issuing instructions through the storage controller to alter the magnetic characteristics of a particular location within a magnetic disk drive unit the reflective or refractive characteristics of a particular location in an optical storage unit or the electrical characteristics of a particular capacitor transistor or other discrete component in a solid state storage unit. Other transformations of physical media are possible without departing from the scope and spirit of the present description with the foregoing examples provided only to facilitate this description. The computer may further read information from the mass storage device by detecting the physical states or characteristics of one or more particular locations within the physical storage units.

In addition to the mass storage device described above the computer may have access to other computer readable medium to store and retrieve information such as program modules data structures or other data. It should be appreciated by those skilled in the art that computer readable media can be any available media that may be accessed by the computer including computer readable storage media and communications media. Communications media includes transitory signals. Computer readable storage media includes volatile and non volatile removable and non removable storage media implemented in any method or technology for the non transitory storage of information. For example computer readable storage media includes but is not limited to RAM ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM flash memory or other solid state memory technology compact disc ROM CD ROM digital versatile disk DVD high definition DVD HD DVD BLU RAY or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices and the like.

The mass storage device may store an operating system utilized to control the operation of the computer . According to one embodiment the operating system comprises the LINUX operating system. According to another embodiment the operating system comprises the WINDOWS SERVER operating system from MICROSOFT Corporation of Redmond Wash. According to further embodiments the operating system may comprise the UNIX or SOLARIS operating systems. It should be appreciated that other operating systems may also be utilized.

The mass storage device may store other system or application programs and data utilized by the computer such as the RTLA agent the sampling agent the log processor the sample processor or the data accumulation task each of which was described above in regard to . In one embodiment the mass storage device or other computer readable storage media may be encoded with computer executable instructions that when loaded into the computer may transform the computer from a general purpose computing system into a special purpose computer capable of implementing the embodiments described herein. These computer executable instructions transform the computer by specifying how the CPUs transition between states as described above. According to one embodiment the computer may have access to computer readable storage media storing computer executable instructions that when executed by the computer perform the routine for incorporating streaming and or sampling in real time log analysis as described above in regard to .

The computer may also include an input output controller for receiving and processing input from a number of input devices such as a keyboard a mouse a touchpad a touch screen an electronic stylus or other type of input device. Similarly the input output controller may provide output to a display device such as a computer monitor a flat panel display a digital projector a printer a plotter or other type of output device. It will be appreciated that the computer may not include all of the components shown in may include other components that are not explicitly shown in or may utilize an architecture completely different than that shown in .

Based on the foregoing it should be appreciated that technologies for incorporating streaming and or sampling in real time log analysis are presented herein. Although the subject matter presented herein has been described in language specific to computer structural features methodological acts and computer readable media it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features acts or media described herein. Rather the specific features acts and mediums are disclosed as example forms of implementing the claims.

The subject matter described above is provided by way of illustration only and should not be construed as limiting. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure. Various modifications and changes may be made to the subject matter described herein without following the example embodiments and applications illustrated and described and without departing from the true spirit and scope of the present invention which is set forth in the following claims.

