---

title: Using near-duplicate video frames to analyze, classify, track, and visualize evolution and fitness of videos
abstract: A system and method for analyzing video include segmenting video stored in computer readable storage media into keyframes. Near-duplicate keyframes are represented as a sequence of indices. The near-duplicate keyframes are rendered in a graphical representation to determine relationships between video content.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08798402&OS=08798402&RS=08798402
owner: International Business Machines Corporation
number: 08798402
owner_city: Armonk
owner_country: US
publication_date: 20120830
---
This application is a Continuation application of co pending U.S. patent application Ser. No. 12 909 094 filed on Oct. 21 2010 incorporated herein by reference in its entirety.

This application is related to commonly assigned co pending U.S. patent application Ser. No. 12 909 137 filed on Oct. 21 2010 and incorporated herein by reference in its entirety.

The present invention relates to video processing and more particularly to systems and methods for dealing with a large video corpus to analyze track classify and visualize videos or portions thereof.

Video data differs from purely textual data in several important ways. Video is often easier to generate but it is harder to manipulate compare and query over. Consequently social repositories of video data such as YouTube depend on verbal title tags and descriptions for searching even though each of these textual records can bear little relation to the actual video content. Sometimes this inaccuracy is deliberate for spamming purposes but often it is due to the honest polysemy of words.

It is difficult to find a precision answer to a query with video. Retrieval of video content may be complicated by a server s heuristic attempts at query expansion such as including videos whose supposed relevance to the query comes mainly from their popularity or from their collocation within ill formed playlists where other videos are in fact legitimate responses.

There are very many videos that are digitally accessible but current search engines do not look at the videos they simply describe the videos in words. Finding videos that are related to each other is difficult and little progress has been made in this area especially on large depositories like YouTube .

A system and method for analyzing video include segmenting video stored in computer readable storage media into keyframes. Near duplicate keyframes are represented as indices and videos are represented as a sequence of indices. The near duplicate keyframes are rendered in a graphical representation to determine relationships between video content.

A system in accordance with the present principles includes a processor and a memory coupled to the processor and configured to store a module for analyzing video. The module is configured to segment video stored in computer readable storage media into keyframes represent near duplicate keyframes as indices and render the near duplicate keyframes in a graphical representation to determine relationships between video content.

These and other features and advantages will become apparent from the following detailed description of illustrative embodiments thereof which is to be read in connection with the accompanying drawings.

In accordance with the present principles systems and methods for tracking analyzing classifying videos are provided. In one embodiment videos within a depository compete for view counts like organisms within an ecology compete for survival. Video genes are composed of near duplicate keyframes which are those frames within the entire corpus of videos that are very similar in physical appearance colors sizes shapes visual composition of objects etc. and that appear in several different videos. These near duplicate keyframes or near dups include very useful information in their temporal sequence or evolution within the video and across long stretches of time as the videos evolve . Criteria for determining near dups may be set as desired. These sequences of near dups permit easy handling of problems in classifying annotating retrieving comparing and ranking videos.

These videos are utilized to clean up responses given by current video retrieval engines to locate those videos that are most typical or which best summarize a given topic of interest to compare at high speed two videos for similarity or for copying to classify videos as news monologue dialogue slideshow etc.

Another feature teaches how to visualize relationships among videos in terms of both their relevance to the topic and their relationship over time to other videos that are similar. This feature shows in a way similar to a family tree how important parts of a video are inherited from predecessor videos. One of the advantages includes that a much larger group of videos can be understood at a glance than has previously been possible. In a single display videos that are most relevant to a topic e.g. which best summarize a topic and a form that the video takes newscast debate etc. can be located. The processing time for these analyses and displays is much faster and the comprehensiveness of coverage is much greater than prior art systems.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing. Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

In accordance with the present principles an analogy between videos and genetics is employed for classifying analyzing displaying videos. In Table 1 a concept mapping between an ecosystem and a social video depository is provided to suggest useful representations and powerful tools that can be employed. Table 1 indicates a plurality of commonalities together with an estimate of the relative sizes and frequencies between the two domains. For example most ecologies are more massive in numbers than video depositories see the relative size column for such an indication . On the other hand many more videos are usually found together in playlists than there are organisms found living together in symbiosis.

Some of the parallels are straightforward. Videos follow grammar rules of good formation genotypes and have immediately observable differences by genre phenotypes . The sequences within and across short clips tend to be preserved except for editorial inclusions introns and superfluous beginnings and endings telomeres . Their relationships to each other can be traced by their reuse of near duplicate shots phylogenetics discoverable through time flexible matching algorithms e.g. Smith Waterman and Clustal . Near dups are sometimes dropped or interrupted genetic gaps but their basic patterns of repetition are indicative of structure which can be displayed graphically electrophoresis . Competition for views can be enhanced by coexistence on playlists with related videos symbiosis or by copying asexual reproduction or by mashups sexual reproduction leading to evolution of content genetic drift .

Nevertheless we note that there are some differences in the orders of magnitude that distinguish the two domains. As noted in Table 1 compared to the genes that make up the DNA of an organism near duplicate keyframes of a video are made from a much larger alphabet and each video encodes a much shorter sequence of them. Although this simplifies video analysis it impairs the use of many genetic visualization techniques such as the simple false coloring of base pairs or amino acids in displays of lineage or similarity.

On the other hand videos come with timestamp information so their inheritance and evolution are much easier to know with certainty. One of the most important parallels however is that genetics encodes information within grammatical sequences unlike bag of X approaches sequential temporal information both intra and inter video encodes and yields critical information about genre and ancestry.

By employing this analogy classification and analysis of videos can be performed. In this way solutions for exploring very large corpora of videos are provided to 1 Improve precision and eliminate off topic videos 2 Locate hot clips and hot videos 3 Trace history and locate summary videos if present 4 Compare videos quickly based on content 5 Determine origin and changes of videos 6 Classify videos into genres. The present embodiments may be developed and employed in any edited video domain.

Referring now to the drawings in which like numerals represent the same or similar elements and initially to a block flow diagram for a system method for processing videos is shown in accordance with one illustrative embodiment. In block a corpora of videos is captured collected and or stored on a topic. The corpora may include a video website a video library etc. In block the videos are segmented into keyframes. Segmentation may be performed based upon any criteria e.g. spatial temporal color sequence etc. In block keyframes are represented by descriptors. The descriptors may include an indexing or encoding scheme to represent the keyframes. In block equivalence classes of keyframes are created. In block the videos are represented as sequences of equivalence class indices. In block for each equivalence class videos are sorted by time of creation and linked. In block the video is painted with false color showing popularity of keyframes. In block videos are displayed on a timeline showing multiple inheritances.

In accordance with the present principles videos are considered organisms and near duplicate keyframes near dups are considered genes. Near dups are comparable to clips but simpler to detect cluster track compare and display. Data collection may be performed via spidering or other techniques block . Video datasets are usually very imbalanced. For example most popular videos may not be on topic and very unequal view distributions may occur.

For a case study 5.4K videos were analyzed including 210K keyframes segmented from the videos block . A same extraction method was employed for the keyframes which included size normalization color correlogram cross feature extraction FLANN Fast Library for Approximate Nearest Neighbors lookup and equivalence class clustering etc.

Color correlogram data are only an approximation of content and may oversegment videos during camera movements. Some object recognition may be helpful in this instance. The distribution of near dups across an ecology in the data set analyzed in this example seemed to follow a Zipf like power law but with an exponent of about that is with a longer and more diverse tail than Zipf expects.

Just as amino acids are grouped into families with common functional roles near dups most likely occur in families that have common semantic meanings e.g. commentator crowd outdoors establishing shot etc. . Inheritance may be defined as occurring due to multiple inheritances within a temporal window rather than through a single near dup transmission although a single near dup transmission may be employed.

For some topics a video summary may already exist within the ecology. As a topic drifts it may become necessary to construct a video summary instead e.g. through a disciplined automatic mashup algorithm.

In accordance with one embodiment visualization of the videos in the case study may be provided as follows. First near dups genes were tracked. This included finding all videos with a given near dup block sorting by temporal order of first posting date and time block and linking immediate temporal neighbors only block . This provides a transitive reduction the opposite of transitive closure of the temporal relationships and induces a simple path through the videos.

The present embodiments may be employed in video repository domains e.g. YouTube or any other edited video domains including news applications commercial or corporate libraries blogs social networking sites etc.

With continued reference to a case study of YouTube that was performed will be described. In block 200K videos were collected and their metadata from YouTube on 22 different topics. One topic includes the Iran dataset for which a spider repeatedly made about a dozen queries through the YouTube application programming interface API each of the form Iran election Iran president Iran controversy etc. These queries retrieved about 5.4K unique videos eventually being segmented and yielding about 210K keyframes in block . A second topic Housing provided ground truth for tuning the present methods. About 15K near dup pairs and 25K non near dup pairs from this dataset were hand annotated and verified.

To compare keyframes they were first normalized spatially and through histogram equalization then the four corners of each image were masked away to reduce interference by added text and graphics then features were extracted from the remaining cross shaped region based on hue saturation value HSV color correlograms. In block each keyframe s resulting 332 component descriptor was then indexed for k nearest neighbor lookup with respect to the Ldistance metric. Other methods for describing keyframes are well known in the art for example methods based on local or global color texture optic flow similarity to known models etc. and give similar descriptors.

The Fast Library for Approximate Nearest Neighbor FLANN package was used to establish classes of similar keyframes. Other methods well known in the art may also be employed. For performance we set a heuristic limit on number of neighbors searched equal to square root over N where N is the size of the keyframe set. Only those neighbors were kept which were within an adaptive threshold that was sensitive to descriptor complexity. In block equivalence classes of near duplicates resulted from an efficient union find variant for the transitive closure of these neighbor relations. On this dataset this method created about 2.5K near dup classes over all datasets precision was 98 recall was 80 and the F1 composite measure of retrieval was 88 at a total cost of O N square root over N per dataset.

By examining these near dup classes it was not hard to discover that YouTube appears to answer queries using a proprietary query expansion algorithm to enhance recall but often at the cost of lowered precision. It appears to select very popular but off topic videos if they happen to share a playlist with other videos that directly satisfy the query and it appears to weight this selection proportionately by view count. Since many playlists are off topic and ill specified e.g. My Favorite Videos contamination of the response set results. In the case study dataset the 4 most popular videos were so off topic that they shared no near dup keyframes with any other videos at all. This was also the case for 7 of the top 10 most popular videos. For videos in the top 10 of popularity which gathered almost all the total views the likelihood of having a near dup was below the average of the dataset as a whole which was about 0.58. However noting their lack of near dups these off topic invasive species are easily detected and they in fact do not interbreed with other near dups.

In general this particular topic domain like many others is characterized by a very unequal distribution of views as measured by the Gini coefficient used in biodiversity studies. Gini computes a state of pure equity as a value of 0. Applied here it would mean each video has exactly the same number of views. A Gini coefficient of 1 indicates that all resources are possessed by a single entity. Here one video would have all the views. The Gini coefficient of the case study dataset is 0.94 whether one looks only at those videos with near duplicates or includes those without. This value far exceeds the Gini coefficient of inequality for the distribution of monetary wealth in any country which has its maximum at about 0.7 for Namibia.

Additionally we have noted that the member keyframes of a near duplicate class tend to be temporally collocated preferentially with members of only very few other near duplicate classes. Further the temporal order of these pairings tends to be preserved across videos. This can be seen by examining bigram statistics which record the frequency of adjacent pairs of near dups within a video.

If B is a matrix that counts at B i j the number of times in the video ecology that a near dup from class i is followed by a near dup from class j then B is shown to be heavily asymmetric. A standard definition of asymmetry represents B as the sum of a purely symmetric matrix S B B 2 and a purely anti symmetric matrix K B B 2 and defines the amount of asymmetry as 0 a K B 1 where the norm can be chosen as appropriate. The extreme values of a occur exactly where expected. For some norms our case study dataset has a 0.6 and if the diagonal of matrix B which encodes the self succession of near dups is omitted a 0.7. Observation confirmed the severe non Markovian property of near dups with many identical long chains of near dup classes repeating within and across videos. One conclusion is that the unit of video virality is more properly that of the keyframe sequence that is a clip here we use individual near dups as an efficient proxy.

The genetic inheritance of videos may be defined via the simplest possible approximation as an unweighted directed link between a pair of videos that share a single near dup but restricted to only those pairs which are immediately temporally adjacent. This is a case of transitive reduction that is the inverse to transitive closure where each near dup induces its own single time based simple path through the video ecology.

Referring to a machine generated graph presents in greatly reduced and symbolic form the inheritances of near dups within the case study dataset on Iran. At a glance although there are many isolated components videos tend to generate and interbreed in synchrony with important events news events or other occurrences . We also note that initial videos about an event tend to acquire more views than later ones and they also tend to be subject to more evolution. In arcs represent re occurrence of one or more near dup frames.

When completed for all near dups a family tree or a directed acyclic graph DAG may be generated. The graph may be displayed against a time grid as depicted in .

Time scale shows temporal events. Depending on the scenario logarithmic or other relationships may be employed to scale the graph to provide a reasonable display or permit a reasonable interpretation of the data e.g. width may be proportional to the logarithm of the number of views or postings. Graphical tools may be employed to generate the visualizations in accordance with the present principles.

Because keyframes are clustered or classed according to near dup similarity in block and these classes are then sorted and numbered according to their cardinality or other method in block we can use either this near dup class number or the cardinality itself as a rough indicator of near dup virality or popularity. In block this can be visualized using a hot false color scheme which is based on blackbody radiation black red orange yellow white in that order see . A virally hot keyframe shows up as white and an infrequently used one as black.

Referring to the visualization uses a fixed size box for each video and shows within the box as vertical stripes all of the near dup keyframes detected in temporal order within those videos. In this example only keyframes with at least 15K views are visualized. Each box has a kind of cytogenic banding pattern. An inset image shows a magnified view of the videos so that cytogenic patterns are more visible. Even though this encoding is many to one 2.5K near dup classes into e.g. 64 false colors a video with many viral near dups should show up as a box that is close to all white.

This visualization suggests three features. First any news summary videos already present in the ecology show up immediately as white boxes. Secondly mashups show up as a confluence of inheritance arrows onto a box with a pronounced striped pattern reflecting the video s alternation of many hot near dups with cold unpopular interjected title slides and editorializing frames. Third many extended near dup sequences have been transmitted essentially in their entirety.

Cardinality of a near dup equivalence class may be employed to designate hotness popularity of the near dup. Encoding may include false color hotness using a blackbody radiation scale e.g. black dark red red orange yellow pale yellow white white being the hottest similar to cytogenic bands as shown in . Other visualization methods that include different encodings of the near dups or genes are also contemplated

Similarity between videos may be determined by matching videos using genes. Genetics tools such as the Smith Waterman algorithm of genetics may be employed to match videos.

Full Video Similarity via Smith Waterman Since a full video is represented by a sequence of near dup class numbers two videos can be compared using an extension of the Smith Waterman algorithm of genetics which is a simplified and discretized form of dynamic time warping DTW that assigns penalties to component mismatches and to sequence gaps. Because the algorithm works on a derived sequence of integers and not on features images or clips it is fast. An example of its use in aligning two videos is shown in which includes before and after alignments of a pair of clips and where the near dup classes have been assigned false colors for bands arbitrarily for illustration purposes. Gaps and mismatches are perceived instantly. Since many long videos are reposted with only a few added editorializations at their beginning or trimmed credits from their ending they are especially informative. Any gaps within matched pairs of the video tend to indicate a failure of the keyframe detector and any mismatches tend to indicate an overgranularity of keyframe clustering. A similar observation can be made about the internal self matching of talkshow and slideshow videos . These inaccuracies can provide very useful non manual ground truth feedback for tuning the sensitivities of the earlier algorithms that detect and cluster the near duplicates.

As a bonus the Smith Waterman match induces a true distance metric on the videos. The total number of gaps necessary to form a minimal cost match between a pair of sequences is in fact positive definite symmetric and subadditive. We can therefore create an induced distance matrix of a video ecology to study the sparsity of its interconnectivity. Both visualization and direct computation indicate that in our case study dataset interrelationships are on the order of only 1 . This may be illustrated using the heuristic Reverse Cuthill McKee algorithm to permute the interconnection matrix to dramatize its sparsity. This means that in general despite much inheritance any two specific videos retrieved using a query are unlikely to be related to each other simply given the large number of videos in the total collection.

Genre via Motifs We have noted that by observing the patterns of near dup repetitions within a video it is often easy to tell the video genre regardless of near dup content by using what geneticists call motifs. We illustrate this with an example that is very roughly the equivalent of gel electrophoresis in genetics. A video is represented as a sequence of near dup class numbers which are integers. By applying a degenerate form of Lempel Ziv encoding to this sequence we can capture the periodicity of the content. For example if the video is of the form ABAABABBA where A and B are two large positive near dup class numbers this sequence can be compressed losslessly into 002132213 where each small non negative code integer captures the LZ distance of each original integer to its most recent previous occurrence. Ignoring any of the 0s which indicate new content this LZ code can now be histogrammed to find peaks which will correspond to length of the periods of repetition of content. In the example this histogram would be 232 corresponding to 2 instances of the code of 1 3 of the code of 2 and 2 of the code of 3.

Except for some expected blurring videos having a single static frame or of a monologue which is almost the same thing have LZ code histograms with modes at 1 dialogues such as host plus guest talk shows have histogram modes at 2 as in the example above . Slideshows accompanying music or spoken text have modes at P where P is the number of independent slides that are cycled through and news programs and mashups have no discernible period at all since their codes are mostly 0s. These patterns also easily show up of course in false color displays as shown in . Viral near dups tend not to come from videos with periodicity they tend to originate from news.

News in has no histogram LZ is nearly all 0s . A monologue and or music only is shown in and peaks near 1. Talk shows dialogue in peak near 2. Talkshows have regular biphasic rhythms equal time . Slideshows in peak at a value near their period. High virality rarely comes from videos with a peak.

Multiple sequence alignment is provably NP hard with V videos of length L taking O 2L time. So various heuristic approaches like the Clustal family of algorithms in genetics may be employed to find and verify all near duplicate videos.

Basing a taxonomy of genres solely on period may be improved upon by employing better grammar based methods derived from constraints on how a story is told etc. Such methods may employ a kind of compiler to parse near dups into their functional roles and sequences of them into a composite meaning. The amount of genetic drift topic drift probably varies from genre to genre but it may be near constant within one genre.

Referring to a system method for handling video content in a video corpus or other collection of videos is illustratively shown. In block video stored in computer readable storage media is segmented into keyframes. The criteria for segmentation may include any subject video content feature scene changes color changes tags information metadata etc.

In block near duplicate keyframes are represented as a sequence of indices. In one embodiment near dups may be classified into groups or classes. All members of a class may be represented by a value color or other index or encoding. In block the representation of the near duplicate keyframes may include indexes in accordance with popularity of the near duplicate keyframes or employ other criteria. The popularity of the keyframes may be rendered according to a false color scheme. The sequence of indices may include integers colors or other descriptors wherein an index value represents a class of near duplicate keyframes.

In block the near duplicate keyframes are rendered in a graphical representation to determine relationships between video content. In block a similarity between two videos may be determined by aligning and comparing respective key frame sequences. A Smith Waterman method may be employed to re align the videos to provide a band and gap representation of the near dup keyframes. In this way a side by side comparison provides an immediate visual result.

In block a graph may be generated to temporally show a history or to show inheritance features of one or more near duplicate keyframes. A family tree or directed acyclic graph may be provided to show the inheritance or multiple inheritances of each video. The relationships between video content may include one or more of non relevant videos videos whose parts have been incorporated into other videos summary videos within a corpus of videos and mashup videos within a corpus of videos.

In block the genre of a video may be determined based upon a visual rendering of the sequence of near duplicate keyframes. The genres may include one or more of news videos videos collecting images from other videos monologue videos or videos with a single image talkshow videos slideshow videos etc. In block videos with determined relationships are graphically rendered tracked classified analyzed etc. as needed.

Referring to a system for evaluating video content is illustratively shown. System includes one or more processors . System includes a memory coupled to the processor . The memory includes a video handling module configured to segment video stored in computer readable storage media into keyframes represent near duplicate keyframes as indices and render the near duplicate keyframes in a graphical representation to determine relationships between video content. The system includes a display . Indexed near duplicate keyframes are displayed on display e.g. in accordance with popularity in a false color scheme.

The module is configured to generate a graph to temporally show a history or inheritance of one or more near duplicate keyframes. The module may also be configured to determine a similarity between two videos by aligning and comparing respective key frame sequences and determine a genre of a video based upon a visual rendering of the sequence of near duplicate keyframes. For example the indices of the keyframes are determined in accordance with near dup classes based on similarity and then the popularity of the class is measured e.g. number of occurrences etc. and possibly displayed. In one embodiment the Smith Waterman or other method may be stored in memory and executed to perform re aligning and comparing of the key frames.

The system may operate with input from a user through user interface . The user may adjust the graphically rendered output to analyze and draw conclusions about videos rendered using module . The system may include or be included in a computer a telephone a software application or other computing device. The system may connected to a network wireless connection wired connection or any other known connection type or channel to enable communication with a content library a web site or other storage device with a corpus of videos.

Having described preferred embodiments of a systems and methods for using near duplicate video frames to analyze classify track and visualize evolution and fitness of videos which are intended to be illustrative and not limiting it is noted that modifications and variations can be made by persons skilled in the art in light of the above teachings. It is therefore to be understood that changes may be made in the particular embodiments disclosed which are within the scope of the invention as outlined by the appended claims. Having thus described aspects of the invention with the details and particularity required by the patent laws what is claimed and desired protected by Letters Patent is set forth in the appended claims.

