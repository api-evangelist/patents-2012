---

title: Messaging system with distributed filtering modules which register interests, remove any messages that do not match the registered interest, and forward any matched messages for delivery
abstract: In a message delivery system, messages are carried over a network in packets. Server hosts support applications for originating and receiving messages and network interfaces. Switches interconnect the server hosts and form the packet network. Some of the switches are linked to the local server hosts. Distributed filtering/matching modules associated with the local server hosts register interests for applications on the associated local server hosts, inspect packets received over the network or from a local server host to match messages with registered interests and remove any unmatched packets from the packets. The matched messages are forwarded to the local server host for delivery to the applications. This system offers the ability to use special purpose hardware for the filtering/matching function without requiring connections to a common message broker.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09319362&OS=09319362&RS=09319362
owner: Solace Systems, Inc.
number: 09319362
owner_city: Ottawa, ON
owner_country: CA
publication_date: 20120125
---
This invention relates to data communication networks and in particular to a method of message delivery with distributed hardware message filtering.

In the prior art many message delivery systems exist which offer message delivery between endpoints such as between different applications. The message delivery systems may implement different message delivery semantics such as point to point or publish subscribe and different service types such as assured also know as guaranteed or persistent and reliable also known as best effort .

Such messaging systems provide for loosely coupled message delivery between the message source and the receiving application for one to one delivery or receiving applications for one to many delivery . A messaging system is comprised of many components some of which are standard and some of which are specific to the particular messaging system. These components include server hosts applications network interface cards network switches message brokers software libraries etc. a particular instance of a messaging system may include some or all of these components. There may also be other sub functions not mentioned in the previous list that may be featured in a particular implementation. The way in which these components are assembled to create a messaging system is one way messaging system implementations are differentiated. A particular implementation of a messaging system may have advantages over other implementations depending on the requirements of the applications using the messaging system and the characteristics of the message flows between these applications.

The mechanism by which the messaging system determines how to route a particular message to its destination endpoint s is another form of differentiation between messaging systems know in the art. Prior art messaging systems use topics metadata tags added by the message source or inspection of the message content itself to determine which endpoint s to deliver a particular message to. The endpoints may be different applications or a queue that could be shared by multiple applications or a combination of applications and queues. The criteria used by the message delivery system to determine which messages to deliver to which endpoint s may be configured by the administrator of the system or the endpoint s themselves can indicate their own interests in the form of subscription requests.

Broadly speaking there are two messaging system architectures and many variants of each . The two architectures are broker and brokerless as they are known in the art. In the broker based systems there is an intermediate system the broker in between sending and receiving systems. One advantage of the broker based system is that the broker may be implemented in a separate machine from the applications and therefore contain hardware designed specifically to offload systems hosting the applications from specific processing tasks associated with a messaging system. A disadvantage of the broker based system is that all message flow must pass through the broker and this can add latency to the system especially when message flows are one to many. Under these usage patterns the finite egress bandwidth of the broker and associated serialization latency are at issue.

Brokerless systems have the advantage that there is no intermediate system through which all message flows must pass. Often brokerless systems rely on networking technologies that employ multicast. The networking devices that implement the underlying network can replicate data with high efficiency and have fewer restrictions in terms of egress bandwidth. The use of multicast in the underlying network has the effect of reducing latency associated with the broker and its finite egress bandwidth but at the cost of pushing other functionality implemented in the broker off to the systems hosting the applications. For example the machines hosting applications that are receiving message data are typically required to inspect all messages received over a particular multicast channel and discard messages that the application is not interested in processing in a broker based system the broker would perform this function.

For many applications a messaging system that features the advantages of both broker and brokerless topologies is desirable. Specifically a messaging system that features the latency characteristics of brokerless systems particularly with message flows that are one to many while offloading messaging system processing from the systems hosting the applications as is typical of broker based systems.

According to the present invention there is provided a message delivery system for delivering messages over a network wherein the messages are carried over the network in packets comprising a plurality of server hosts supporting applications for originating and receiving messages a plurality of switches interconnecting said server hosts and forming the packet network wherein at least some of said switches on the edge of the network serving as ingress egress switches are linked to network interfaces of the server hosts and distributed filtering matching modules associated with the server hosts and wherein the filtering matching modules are configured to a register interests associated with applications on the server hosts b inspect packets received over the network for a local server host or received from the local server host to match messages carried by the packets with the registered interests c remove any unmatched messages from the packets and d forward packets carrying any matched messages to the local server host for delivery to the applications.

In such a packet network the messages intended for the destination hosts are carried in packets. Typically each packet will carry a number of messages although in some cases a large message can be carried by one or more packets. The packets are typically IP packets which have a header and payload. The messages are carried in the packet payload.

The packets are delivered through the network based on a multicast IP address. Embodiments of the invention examine the packets at the egress switches to filter the messages intended for applications on destination server hosts. In one embodiment the filter modules at the egress switches inspect the packet payloads and filter the messages from packets arriving over the network or from local hosts and forward the messages of interest to groups of applications on the destination servers using a multicast address. In this case not all the messages carried by the packets are necessarily of interest to each of the destination applications in the multicast group. In this embodiment it is left to the individual applications to discard the messages that are not of interest to that particular application. This embodiment saves bandwidth on the link from the egress switch to the host but requires more processing by the host applications since some residual filtering is left to the host applications.

In an alternative embodiment the filter modules at the egress switches filter the messages from packets arriving over the network and forward the messages of interest to specific applications on the destination servers over a point to point connection using a unicast address. In this case only the messages of interest to each application are sent to that application. This embodiment requires more bandwidth on the link from the egress switch to the host but relieves the host applications of any filtering responsibility.

Embodiments of the invention thus provide a novel system that offers some of the benefits of both a brokerless system and a brokered system. The distributed filtering matching modules on the edge of the network can be implemented in special purpose hardware optimized for the filtering matching function. In one embodiment they may be associated with enhance ports in the switches at the edge of the network.

According to another aspect the invention provides a method of delivering messages over a network having a plurality of switches including ingress egress switches attached to local server hosts and wherein the messages are carried over the network in packets comprising receiving messages originating in supporting applications on the local server hosts forwarding packets carrying the messages to ingress egress switches attached to the destination server hosts inspecting the packets in distributed filtering matching modules to match messages received over the network or from a local server host with the registered interests removing any unmatched messages from the packets forwarding packets carrying the matched messages to the local server host for delivery to the applications.

In yet another aspect the invention provides a filtering matching module for association with local server hosts supporting applications for originating messages in a message delivery system for delivering messages over a network wherein the messages are carried over the network in packets which is configured to register interests for applications on the associated local server hosts inspect the packets received over the network or from a local server host to match messages carried by the packets with registered interests so as to identify destination applications on the local server host remove any unmatched messages from the packets and deliver packets carrying any matched messages to the local server host for delivery to the applications.

Depending on the implementation of the message delivery system a particular functional layer may do more or less processing. The primary purpose of the client is to host applications that wish to make use of the services provided by the message delivery system. A single client may host one or many such applications. The application s access the services of the message delivery system via the messaging layer which is software code that provides an application programming interface or API also known as a library . An application may make use of the message delivery system to send messages receive messages or send and receive messages. In the messaging layer is shown as a single entity but depending on the implementation each application may have a unique instance of the API embedded within it or in an alternate implementation the messaging layer may contain its own process or daemon as it is known in the art that all applications communicate with and share. The networking stack is generally part of the operating system its function is to perform any additional framing or formatting required for transmission over a network. Some networking technologies optionally use techniques such as remote direct memory access RDMA or kernel bypass to reduce latency in these cases the networking stack is implemented such that the messaging layer can interact with the network interface without involving the operating system. The network interface is a hardware device that has a connection to a network the connection also known as a link may be optical cable copper cable or wireless. The combination of the network interface and network stack provides an abstract interface that the messaging layer can use for communicating with other network attached systems.

The following example describes the path a message takes through the broker based message delivery system . The message is generated by an application residing on one of the server hosts . In the example of the message is generated by an application residing in server host . The application sends the message to the messaging system by making a call to the API of the messaging layer . In the example of in the sending direction the messaging layer on server host is responsible for receiving a message generated by one of the applications and formatting or framing it in such a way that it can be extracted by the messaging layer of another receiving application . Formatting and or framing may include adding a topic string or number to the message if the message delivery system uses topics to determine which systems are to receive a particular message or if the message delivery system is implementing point to point messaging then the messaging layer must add the address of the destination system. Similarly if the content of the message is used by the message delivery system to determine the destination systems then the messaging layer must only ensure that the message is framed in such a way that destination systems can extract the content of the message . It is important to note that there may be other optional control information added to the message by the messaging layer that is used by the message delivery system to enable more advanced features an example would be the addition of a sequence number to ensure that messages are delivered to a receiving application in the same order in which they were sent and without loss.

Once the messaging layer has finished framing and formatting the message it is sent on to the networking stack and network interface for transmission over the network to the message broker . The network consists of one or more devices commonly known in the art as switches. The switches implement standard networking protocols such as Ethernet IP Infiniband or the like.

The message broker may be a software application running on a general purpose computing device similar to the server hosts or a hardware device tailored to the tasks that a messaging system is required to perform. These tasks include networking parsing data received from the network filtering messages matching messages received from sending applications to interests from receiving applications storing messages transforming messages and other tasks related to the implementation of a message delivery system. An example message broker is also described in U.S. Pat. No. 7 716 525. Upon receiving the message message broker must parse it and extract the control information as well as any data needed to determine the destination s the destination s for the message may include applications or queues. In order to determine the destination s for the message the message broker will take data associated with the message and compare it to interests or subscriptions that the message broker has collected from all the destinations participating in the broker based message delivery system . The interests collected from the destinations may be in the form of topic strings or hierarchical topic strings either of which may or may not contain wild cards or other forms of what is known in the art as regular expressions. Alternately the topics could be in the form of numbers or in some implementations of a message delivery system the interests describe characteristics of the message content. The collection of interests that the message broker has received from all of its destinations are stored internal to the message broker in a data structure know in the art as a forwarding table. The data extracted from the message by the message broker is compared to all of the interests collected in the forwarding table. For each entry in the forwarding table that produces a match to the extracted data a copy of the message will be sent by the message broker to the destination corresponding to that particular entry. These destinations may be applications residing on server hosts connected via the network or queues that exist within the message broker . A server host may be host to more than one destination application for which a matching interest is detected.

In a broker based messaging system the network is typically implemented using a connection based networking technology such as TCP. The use of a connection based protocol allows the message broker to have a unique connection to the messaging layer for each application even though they connect to the network via a common network interface . The message broker may use these connection s to send a unique copy of the message for each application for which a match was detected in the previous step. Note that applications that do not have a subscription matching message do not receive message and thus pay no bandwidth or processing cost associated with filtering message this is performed by the broker on behalf of the subscribing applications. Also of note is that there may be application s running on server host aside from the one that generated message that have registered a matching interest the broker based message delivery system allows for two possible implementations in this scenario. The first implementation is one in which the broker sends a copy of the message back to the server host that generated it on the connection dedicated to the application that registered the matching interest. This implementation is favored because the computationally intensive task of matching messages to interests is performed centrally by the broker . The second implementation is one in which the messaging layer maintains a local forwarding table and compares the message to the interests of local applications and sends a copy to any that match. The second implementation maybe useful in situations where the bulk of the message flow is between applications residing on the same client this application is also known in the art as inter process communication or IPC.

Previously the basic function of a broker based messaging system was described. There are many additional optional features that an implementation of a broker based messaging system may include such as storage of the message message caching broker redundancy etc. none of which affect the present invention. The distinguishing feature of the broker based messaging system is that the matching of messages to destinations is performed centrally this function is computationally intensive especially when the complexity of the interests and the number of interests increases. One of the primary advantages of the broker based messaging system is that the matching function can be performed by specialized hardware contained in the message broker . The application of specialized hardware to this task allows it to be performed efficiently and without consuming resources on the server hosts . Stated another way the messaging layer and applications residing on the server hosts are offloaded of the task of inspecting every message and filtering from the stream any messages which it is not interested in receiving. In the broker based messaging system the server hosts receive only messages that the resident applications have registered an interest with the message broker in receiving. This reduces CPU load on the server hosts and facilitates the implementation of a computationally intensive task in specialized hardware where it can be performed with maximum efficiency. The primary disadvantage of the broker based messaging system is that a message must traverse the network twice in order get to a destination once from sending server host to the message broker and once from the message broker to the destination server host . The additional latency added by the message broker and the additional network transfer is undesirable in some applications.

The following example will describe the path a message takes through the brokerless message delivery system with emphasis on the differences between the broker based system of the previous example. The message is generated by an application residing on server host . Similar to the broker based message delivery system of there is a series of process steps that take place in the server host as shown in . The application of which a single server host may contain one or many sends the message to the messaging system by making an API call to messaging layer . The messaging layer on server host is responsible for receiving a message generated by an application and formatting or framing it such a way that it can be transmitted over the network and extracted by a receiving system. This processing is similar to the processing performed in the broker based message delivery system of but may be different due to differences in the underlying network transport mechanisms employed by the two systems.

Once the messaging layer has finished framing and formatting the message it is sent on to the networking stack . It is at this step that the differences between the broker based message delivery system and the brokerless message delivery system begin to become apparent. As previously described broker based message delivery systems typically make use of point to point or connection based networking technologies such as TCP. Brokerless message delivery systems typically make use of multicast network technologies which are typically connectionless. Widely available networking technologies such as Ethernet Infiniband and IP support both methods of communication. Networking technologies that optionally use techniques such as remote direct memory access RDMA or kernel bypass to reduce latency are equally applicable to brokerless message delivery systems as they are to broker based message delivery systems . The networking stack receives the message formatted by the messaging layer adds any additional framing or formatting required by the network and passes the message to the network interface for transmission. Note that if there are other applications on the sending system then the network stack will replicate the message and send back to the messaging layer as if it had been received over the network this is a feature of multicast networking that is supported by the network stack of most operating systems.

The network of the brokerless message delivery system is very similar to the network of the broker based message delivery system . Many brokerless message delivery systems including systems relevant to the present invention make use of multicast networking protocols as it relates to the present discussion the network is assumed to be multicast capable. Historically some data networking systems relied on a shared wire or bus between systems participating in the network. The Ethernet 10Base2 standard is an example of such a system. In a 10Base2 network all of the connected systems are joined by a single co axial cable. A consequence of such a network topology is that all systems connected to the cable can receive any data generated by any other connected system naturally providing a multicast delivery. Modern networks such as or are implemented using point to point links rather than a shared wire or bus. In this type of network server hosts are connected by point to point cables either electrical or optical to networking devices known as switches. The switches have multiple interfaces and may connect to many hosts or other switches to create larger networks. The switches are capable of receiving data on one interface replicating it and retransmitting it out of multiple interfaces. By employing these techniques the switches can mimic the multicast behaviors of the bus topology. Modern network switches are capable of providing multicast network service with remarkable efficiency as a result of years of design innovation and refinement. Of note is that with modern broadcast network technologies like Ethernet the reality is that every host gets a unique copy of the data.

In the brokerless message delivery system an application residing on server host wishes to send message to a subset of applications residing on the other server hosts or another application residing on the same server host . The messaging layer on server host after formatting message sends it to the network stack . After adding additional framing the network stack will send the message to any local applications that are listening to the multicast group on which the message is to be sent with the exception of the sending application and via the network interface and the network to all the other server hosts that have application s that are listening to the multicast group. The switches that make up the network will replicate the packet s that contain message and send a copy to the other server hosts . The packet s will be received by the network interface of the server hosts and will be passed up to the messaging layer via the network stack . Upon the reception of a message it is the function of the messaging layer to determine which if any of the applications have an interest in receiving such a message. This is a fundamental difference between the broker based message delivery system and the brokerless message delivery system . In the broker based message delivery system this filtering function is performed by the message broker in the brokerless message delivery system this function is performed by the messaging layer on all participating server hosts in the message delivery system. In the art there are two prevalent implementations of the messaging layer . In the first implementation a separate process known as a daemon does the messaging layer processing for all applications hosted on the system. In the second implementation a separate instance of the messaging layer is embedded in each application and the network stack delivers a copy of the message to each instance of the API that is listening to the multicast group. Note that in the daemon implementation on the sending server host it is the daemon process that filters replicates and distributes the message to other local applications if they have registered an interest in receiving such a message and not the network stack as previously described.

The messaging layer of a particular server host having received the message from the network stack must parse the message and extract any data needed to determine the destination s . In the daemon implementation the daemon process will do this processing for all applications hosted on a given server host in the daemonless implementation the messaging layer instance in each application performs this processing. The data extracted from the message may be a topic a metadata tag text string or number as previously described added by the messaging layer in the sending server host or some portion of the message content. In order to determine which if any of the applications are interested in receiving the message the messaging layer must take the extracted data and compare it to interests that it has collected from the application s that it is hosting. The interests collected from the application s may be in the form of topic strings or hierarchical topic strings either of which may or may not contain wild cards or other forms of regular expressions to be matched to the topic sent with the message . Alternately the topics could be in the form of numbers and the interests could be in the form of a range or an exact match or in some implementations of a message delivery system the interests may describe a substring or pattern contained within the message content. For any of the interests that are deemed to be a match by the chosen algorithm to the current message a copy of that message is sent to the application that registered the matching interest. It is important to note that this processing must be carried out in all of the server hosts and possibly every application depending on whether or not daemon or daemonless implementation is used. Depending on the size of the topic space and the complexity of the rules used to match interests to messages this processing can be onerous. If a host cannot keep up processing the messages as they arrive then message loss can occur which decreases the efficiency of the system and its applications. In the broker based message delivery system the message broker performs this processing in a central location offloading this processing from the destination server hosts and applications .

A possible enhancement to the brokerless message delivery system is to distribute the topic space across multiple multicast groups. Some multicast networking technologies such as IP multicast allow multiple multicast groups to be established such that not all of the server hosts need to receive all of the multicast data. By assigning a subset of the topics to a particular multicast group the burden of filtering off unwanted messages at the destination server hosts in the previous example can be reduced. The destination server hosts will not receive data sent to multicast groups that carry no topics of interest. In some cases these and similar techniques can be used to reduce the cost of filtering off unwanted messages at the destination server hosts . That said another management problem is created in terms of how to distribute topics to multicast groups in such a manner that applications can take advantage of the network filtering by not needing to join all multicast groups. Typically the number of topics in use is far more e.g. 10 or more the number of multicast groups supported by modern switches so having one topic per multicast group is not technically feasible.

The present invention is a method of combining the advantages of both of the previously described message delivery systems and . A method is presented that provides the reduced latency of the brokerless message delivery system while offloading the server hosts of the onerous task of matching message topics or messages to the interests of hosted applications as in the broker based message delivery system .

The present invention involves adding additional functionality to the switches that make up the network . The new functional blocks implement the matching filtering function . Of note is the fact that the matching filtering function only needs to be deployed on the links connecting to participating server hosts the network has been drawn in three sections to show this. The first network block is built with enhanced switches that are enabled with the matching filtering function on the links that connect to server hosts that are participating in the hybrid message delivery system . Network block is built with standard switches that are not enabled with the matching filtering function . Link connects network block to note that it does not have a matching filtering function on either end and furthermore one is not required on either end because link is not connected to any of the server hosts that are a part of the hybrid message delivery system . Network block is similar to and link is similar to the important point is that the network of the hybrid message delivery system can be built from a combination of standard and enhanced switches provided that enhanced switches are deployed with the matching filtering functions on the ports that connect to the server hosts .

The preferred embodiments of the present invention will be presented in the following description of a path taken by a message as it traverses the hybrid message delivery system and later by a detailed description of the devices and protocols employed. As in the two previously described message delivery systems and an application residing on server host generates a message for transport over the hybrid message delivery system to destination applications residing on one or more of the other participating server hosts . The sending application passes the message to the messaging layer via an API call. As in the previous two example message delivery systems and the messaging layer is software code that provides an API by which an application can send and or receive messages. In the example of the messaging layer on server host is responsible for receiving a message generated by an application and formatting or framing it in such a way that it can be transmitted over the network and extracted by a receiving system. This may include adding a topic to the message that may have been passed to the messaging layer via the API. As in the previously described message delivery systems and the topic could be a string a string with hierarchical sub fields a number a programming language object or there could be no topic and characteristics of the message itself could be used to determine the destinations or if the message delivery system is implementing point to point messaging then the messaging layer must add the address of the destination system. Similarly if the content of the message is used by the message delivery system to determine the destination systems then the messaging layer must only ensure that the message is framed in such a way that destination systems can extract the message . It is important to note that as in the previous examples there may be other optional control information added to the message by the messaging layer that is used by the message delivery system to enable more advanced features.

The processing performed on the sending server host in the present example of is very similar to that on the sending server host in the example brokerless message delivery system . Once the messaging layer has finished framing and formatting the message it is sent on to the networking stack for transmission on a predetermined multicast group. The network as in the previous example message delivery systems and consists of one or more devices commonly known in the art as switches. Also as described in previous examples is the network interface a hardware device that has a connection to the network switch es that make up the network . The connection between the network interface and the network may be optical cable copper cable or wireless.

The hybrid message delivery system makes use of multicast networking technologies in a similar manor to the brokerless message delivery system . The network stack and network interface will address the message to all of the destination server hosts making use of the multicast addressing facilities provided by the network . The hybrid message delivery system may optionally associate a subset of the topics or message types with a particular multicast group or address in order to segregate network traffic if this is the case then it is the responsibility of the messaging layer to instruct the network stack to address the message to the correct multicast group.

The network is responsible for replicating the packet s that contain message and delivering it to the matching filtering function corresponding to the subset of the destination server hosts that have joined the multicast group on which message was sent.

The applications will have previously communicated their interests in terms of what types of messages they wish to receive to the matching filtering function via a control connection similar to the way in which they communicated their interests to the message broker in the example broker based message delivery system previously described. The control connection is preferably a TCP connection to a control plane application associated with the matching filtering function but maybe made by any reliable means of communication. Alternately another controlling entity could configure the interests in the matching filtering function on behalf of the receiving application s . The interests of the applications similar to the two previously described message delivery systems and are in the form of topic strings or hierarchical topic strings either of which may or may not contain wild cards or other forms of regular expressions. The topics could also be in the form of numbers and the interests in the form of matching numbers or ranges of numbers or in some implementations the interests describe characteristics of the message content. Alternately the interests may be in the form of topics or topics including regular expressions for which the application is not interested in receiving in this case a negative interest may be referred to as a filter. All forms of matching messages to the interests of applications or removing unwanted messages from a message stream for a specific application are covered within the scope of the invention.

Upon receiving a message the matching filtering function will compare the topic of the message or the message content to the interests that it has collected from the applications hosted by the server host that it is connected to. It is preferable for performance reasons that the matching filtering logic to be implemented using hardware devices such as ASICs FPGAs or network processors as they are known in the art it may also be implemented in software on a general purpose processor. The network switches are multi ported devices as such it may be more cost effective to implement the matching filtering function for multiple ports of the same switch in the same physical hardware to provide economies of scale techniques for logically partitioning the hardware for each switch port are well known to those skilled in the art. If a match is detected by the by the matching filtering function then the packet containing the message for which the match was detected will be transformed and forwarded to the application that registered the matching interest. Note that depending on the implementation of the hybrid message delivery system there may be multiple applications on the same server host which may have registered a matching interest for the same message in this case the matching filtering function must send a copy of the message to each of the applications that registered a matching interest. Techniques for handling these specific cases will be detailed in subsequent sections. Some implementations of the two previously described message delivery systems and may allow multiple messages and to be transported in a single network packet in the hybrid message delivery system one of the design goals is not to burden the destinations with messages that they are not interested in receiving these unwanted messages should be removed from the message stream. Techniques for removing unwanted messages will also be detailed in subsequent sections.

The messages for which the matching filtering function detected a matching interest are forwarded to the destination application s via the corresponding server host for which the matching interest s were detected. The network interface and networking stack will forward the message up to the messaging layer where it will be distributed to the application with the matching interest. Of note is that unlike the brokerless message delivery system the messaging layer does not need to inspect the message or the message topic and compare it to the interests it has collected from the applications it is hosting. Also of note that unlike the broker based message delivery system there is no intermediate broker that must receive and process the message before forwarding it on to its destination s .

The hybrid message delivery system can optionally provide acceleration to the previously described IPC use case as follows. As in the previous example server host generates and sends message to the network . If the matching filtering function corresponding to server host has collected an interest from one of the applications aside from the one that generated message in receiving messages of the same type as then after forwarding message on to other network the matching filtering function will retain a copy of the message and process it as would any other message received from the network . For any interests collected from applications that are found to be a match to the current message a copy of the message can be forwarded back to sending server host and addressed to the application that registered the matching interest. By employing these techniques the hybrid message delivery system can provide the benefit of offloading the task of matching interests to messages from the applications in the IPC case as well as the normal case. Modern server hosts have multiple processing cores and applications that are extremely latency sensitive are often purposely co located. In these cases the benefits of offloading the task of matching interests to messages may be outweighed by the latency incurred by sending the message to an off box matching filtering function .

The ports are typical of a standard network switch where the switch core connects logically if not physically directly to the ports . In the case of the enhanced ports there is a new functional block inserted into the path implementing the matching filtering logic in this is shown as four discreet blocks but could be implemented in the same physical device to reduce cost. Conversely the control logic is drawn in as a central block but could be implemented as a number of discreet elements co located with the matching filtering logic . The matching filtering logic is intended to operate in a flow through mode of operation where normal network traffic not associated with the hybrid message delivery system passes through unimpeded and traffic associated with the hybrid message delivery system is operated on as will be described in subsequent sections. The matching filtering logic is most efficiently implemented in a hardware device such as an FPGA or ASIC as they are known to those skilled in the art but may also be implemented with software running on a network processor or general purpose processor although with less efficiency. The control logic as shown in has a connection to the switch core and is reachable as a network host this is not required but provides an efficient way for the server hosts to communicate information such as interests etc. with the control logic . This communication could take place over a TCP connection between the control logic and the applications or some other form of reliable network communication. The dashed lines are a channel physical or logical used by the control logic to configure the matching filtering logic . As previously stated it is not required for the control logic to be centrally located and connected to the network via a dedicated link it could equivalently be co located or embedded within the matching filtering logic .

As previously stated the matching filtering logic could be implemented in one or more physical devices stated another way the matching filtering logic for multiple ports could be implemented in the same device. There is another possible design for the enhanced network switch where the matching filtering logic is combined with the control logic as it is shown in . In this implementation the traffic associated with the hybrid message delivery system is routed from the ports through the switch core to the matching filtering logic that is co located with the control logic or separate but similarly connected by a dedicated switch port via an internal link similar to . After processing by the matching filtering logic the message traffic is forwarded to the correct egress port. This implementation has the disadvantage that the message traffic must pass through the switch core twice adding latency and is not the preferred implementation however is still covered within the scope of the present invention.

The IP header contains its own source and destination addresses similar to the Ethernet header however the IP addresses are globally routable the Ethernet addresses are only significant within the local network. Global routability is not required however IP networking is ubiquitous supports multicast and the UDP layer offers a method of sending network data to a particular application on a host making IP UDP a good choice as a transport layer for the hybrid message delivery system . Infiniband and other network protocols have equivalent protocol stacks and could also be used. The hybrid message delivery system uses the multicast addressing feature of IP. IP multicast addresses are not generally routable over the public internet and must be assigned by a local network administrator. If multiple IP multicast groups are to be used in the implementation of the hybrid message delivery system then the system administrators must determine which topics are to be transported on which multicast groups.

IP multicast addresses are in the range 224.0.0.0 to 239.255.255.255 this is a range of approximately 268 million addresses practically only a few thousand are available for use in the hybrid message delivery network . In hexadecimal the multicast IP addresses are in the range of E0 00 00 00 to EF FF FF FF or a range of 28 bits. When using Ethernet to carry IP multicast traffic the Ethernet MAC addresses will be in the range of 01 00 5E 00 00 00 to 01 00 5E 7F FF FF a range of 23 bits. The lower 23 bits of the multicast IP address are used as the lower 23 bits of the MAC address. If there are two IP multicast groups that share the same lower 23 address bits then any Ethernet attached hosts that wish to receive the traffic from either IP multicast address will receive all the traffic sent to both groups and it will be up to the network stack on the host to remove and discard the unwanted data. For efficiency reasons it is preferable to avoid the previously described scenario and most network administrators would assign their IP multicast groups such that their addresses differ only in the lower 23 bits. The number of usable multicast groups is further limited to a few thousand by the number of multicast groups that the network switches can support. An IP host indicates its interest in receiving traffic from an IP multicast address by issuing an IGMP join message network switches will typically snoop these messages in a process known as IGMP snooping and use this data to build a multicast forwarding table. The data stored in the multicast forwarding table is used to only send data with the corresponding multicast MAC address to those ports that have attached hosts that have expressed an interest in receiving data from that particular multicast group. The only alternative is for the network switches to send multicast data to all ports and force the hosts to process it and filter off data sent on multicast groups for which it has no active listeners. Network switches currently available are not able to support all 2possible Ethernet multicast addresses and are typically limited to a few thousand based on this limitation the hybrid message delivery system cannot use a one to one mapping between topics and multicast groups. Put another way in the hybrid message delivery system each multicast group must be able to carry messages for more than one topic in order to meet the requirements for topic scalability. Aside from the limitation in terms of the size of the multicast forwarding table supported by current network switches an implementation whereby there is a one to one mapping between the topic and multicast address has other scaling issues. The mapping of multicast addresses to topics becomes difficult to manage as the size of the topic space increases and support of interests that include wild cards or regular expressions requires that all participating applications have knowledge of the entire topic space. The methods described in the present invention support interests that include wild cards and allow sending applications to create topics dynamically without the need to maintain an up to date copy of the entire topic space in every participating application. The size of the topic space for a hybrid message delivery system could scale to millions of topics.

The messaging layer header contains the PublisherID of the application that generated the packet . Each application that wants to generate and send messages over the hybrid message delivery system must have a unique PublisherID assigned to them this could be done by a controlling application a system administrator or by the application itself. Without a PublisherID in each packet there would be no way for receiving systems to know which application generated a particular packet and therefore no way to detect lost messages as will be described. Those skilled in the art will see that there are possible alternate implementations that don t contain a publisherID in the messaging layer header for example the source IP address and source UDP port could be used to uniquely identify a message s source application. If message loss is detected by mechanisms to be described subsequently the receiving application s must have enough information to uniquely identify the message s source application and the multicast stream which it came from so that a retransmission of the missing data can be requested from the source.

In addition to the PublisherID the messaging layer header contains the multicast group on which the packet was sent. The multicast group is also contained in the destination address field of the IP header but is included again in the messaging layer header to allow for implementations where the routing filtering function over writes the destination IP address in the process of generating a unique message stream for each receiving application . As was stated previously the multicast group is required by receiving applications so that they can request retransmissions from source in the event of message loss. The publisherID is not sufficient to identify the source stream of a message as a single application may publish to topics carried by more than one multicast group.

The packet sequence number is the primary loss detection mechanism it uniquely identifies a packet sent by a particular application or publisherID to a particular multicast group . The matching filtering function is downstream of the publishing application and may remove messages that its subtending receiving application s are not interested in processing. If the matching filtering function removes an entire packet from the message stream then it must have a mechanism to communicate this information to the receiving application . The sequence gap provides this mechanism. It indicates the number of packets that were intentionally removed from the stream since the last packet was sent. In order for end to end loss detection mechanisms to function every packet must be accounted for.

The keep alive field is a flag utilized by a keep alive protocol to indicate that this packet should be sent to all applications that are listening to a particular multicast group . This is a part of a higher level keep alive protocol the goal of which is to maintain a minimum packet rate to all applications. The loss detection mechanisms depend on a constant flow of packets from all publisherIDs on each multicast group to which they are sending messages to function effectively. The keep alive protocol ensures this.

A network packet may contain one or more messages and each of which must contain a message header and . Contained within the message header and is a continuation flag a topic length field a topic and a message length . The continuation flag is used to indicate that this particular message is a continuation of the previous message sent in the previous packet from the same message stream. Alternately it could be viewed as a start of message indicator. In this example implementation the continuation flag is shown as a sixteen bit field only one bit is required to convey this information. The remaining fifteen bits could be used in the implementation of advanced features beyond the scope of the present invention. The topic length is the length in bytes of the topic . The topic is a variable length field the topic length is included to enable a parser to locate the next field in the message header . In this implementation the next field in the message header is the message length similar to the topic length the message length is the length of the message in bytes and is required to enable a parser to find the start of the next message header in the packet . The following description of a packet walk through including the operations performed by each of the intermediate systems on the protocol fields will illustrate the preferred embodiments of the invention. A sending application creates a message content and a topic . This data is passed to the messaging layer via a send call to the messaging layer API. The messaging layer will take the message content and topic and proceed to assemble the messaging layer header and the message header . Based upon which multicast group the topic is transported on and which application made the send call the messaging layer must look up the PublisherID and the next packet sequence number . Based on the information received from the send call and the subsequent lookup the messaging layer can assemble the messaging layer header the message header and the message . The sequence gap field should be zero this field is to be operated on by the matching filtering logic in a subsequent step and is included here as a place holder. Before making the call to the network stack to generate a packet the messaging layer may choose to combine the message with one received by a previous send call from the same application or wait for a subsequent send. There is some cost in terms of CPU cycles associated with generating and receiving a network packet there can be some advantage to packing multiple messages into a single network packet . However waiting for the application to generate multiple messages adds latency to the delivery of all but the last message sent which in many instances is deemed a larger problem than increased CPU utilization and so most systems will endeavor to send the messages as quickly as possible. Once the messaging layer frame which includes the messaging layer header the message headers and the message content its total length must be checked to make sure that it does not exceed the maximum length supported by the network also known as the maximum transmission unit or MTU. If it exceeds the MTU then it must be broken into at least two packets . The message header of the message that is severed must be replicated and then modified by setting the continuation flag before inclusion in the second packet . The messaging layer header of the second packet will be the same as the previous packet however the packet sequence number will be incremented by one. It is possible that the message will have to be further subdivided if the length of the remaining part of the message plus headers still exceeds the network MTU in this case the previously described process will be repeated until the final segment of the message fits within a packet that does not exceed the network MTU. At this point the messaging layer may send the content of the first packet to the network stack . New messages may be added after the final segment of the current message if desired before sending the packet to the network stack .

It is important to note that one of the features of the hybrid message delivery system is that the communication is to be reasonably resilient and must include mechanisms to retransmit messages that are contained in packets that are discarded by the network to any or all of the interested receiving server hosts . Protocols that accomplish this are well known in the art as reliable multicast protocols typically they are based on a system of negative acknowledgements or NACKs and require the sending system to hold recently sent data for a period of time. The NACKs may be sent point to point or multicast back to the sender similarly retransmitted data may be sent point to point or multicast back to the receiving systems. The primary message delivery path is the main focus of the present invention however the hybrid message delivery system similar to the brokerless message delivery system requires a secondary message delivery mechanism to recover from data loss in the network . Other known reliable multicast systems have previously developed these techniques and they are equally applicable to the hybrid message delivery system of the present invention. While the protocols to request and redeliver lost data are not critical to the present invention mechanisms to detect data loss are required to enable the retransmission protocols to work. In the exemplary implementation of the present invention the loss of one or more packets can be detected using the packet sequence number and sequence number gap . Upon detecting packet loss the messaging layer of a receiving host can identify the source of the lost data by the source address in the IP header the publisherID and multicast group . Once the source of the lost packets has been identified retransmission of the missing packet sequence numbers can be requested.

There are two possible places where data could be lost in the hybrid message delivery system in the network including the sending server host and between the matching filtering function and the receiving application . The mechanism for detecting loss in the network is the packet sequence number . The matching filtering function must store the last packet sequence number for every PublisherID and multicast group in the hybrid message delivery network . If the packet sequence number for a newly received packet is not exactly one greater than the last packet sequence number stored for the sending PublisherID and multicast group then the retransmission mechanisms must be triggered for the missing packet s as will be discussed in a subsequent section. The second loss detection mechanism is between the matching filtering function and the receiving applications and is complicated by the matching filtering function that is intentionally removing messages and sometimes packets from the stream that it is sending to a given application . The simple sequence number mechanism previously described no longer works. In this case when the matching filtering function sends a packet to an application it also sends with it an expected sequence number gap . The receiving application must store the packet sequence number of the last packet it received from the current PublisherID and multicast group . The last received packet sequence number plus the sequence number gap should be exactly one less than the packet sequence number of the current packet . If the previously described check fails the lost packet s will need to be retransmitted. In this case the exact missing packet sequence numbers are not known only that some packet s were lost between the last received packet sequence number and the current packet sequence number. This information is sufficient to recover the lost packet s from source.

Most message delivery systems also feature a keep alive protocol to communicate the status of applications and to aid in the detection of data loss. The hybrid message delivery system is no different sending applications are required to periodically send keep alive messages so that other receiving applications know whether or not they should continue to maintain state for a particular PublisherID . Aside from helping applications keep track of active PublisherIDs the keep alive protocol solves two problems in the hybrid message delivery system the first is that it limits the size of the retransmission buffer that a sending application must keep and two it helps detect the loss of the last message sent in cases where a particular PublisherID has not sent a message for a period of time. The loss detection mechanisms previously described and typically used by reliable multicast messaging systems cannot detect message loss until a message after the lost one is received what if the lost message is the last one sent In the case of the hybrid message delivery system gaps in sequence numbers are intentionally being introduced between the matching filtering function and the applications what if a message is lost between matching filtering function and the application followed by a long intentional period of inactivity in the message stream from the publisher In this case it may be a long time before the message loss is detected and the sending PublisherID may have to save messages for a very long time in order to satisfy the retransmission protocols consuming a lot of resources in the sending applications . The introduction of a keep alive protocol running over the hybrid message delivery system will address these issues. The keep alive protocol is simple every sending application or publisherID is required to send a packet with the correct next sequence number periodically on each multicast group on which it is sending messages. The period may be time based or it may be after a certain number of packets are sent or both and in most systems would be configurable by system administrators. The keep alive messages have the keep alive flag set so that they can be identified by the matching filtering function . The keep alive messages would be forwarded to the messaging layer of all receiving server hosts that are hosting applications that are listening to a particular multicast group . This would provide a constant stream of messages to all receiving applications and periodically reset all of data loss detection mechanisms of the messaging layer . Note that in order to reset the packet loss detection mechanisms the matching filtering function must insert the correct sequence gap into each keep alive packet that is generated.

The messaging layer communicates with the network stack using the sockets API as it is know in the art. The present invention does not require the use of the sockets API however it is a convenient choice since this API is commonly used with IP multicast over Ethernet networks as in the present example. If the underlying network in the example was based on Infiniband technology then the Openfabrics user space verbs interface would be the most convenient choice for the messaging layer to use to send and receive packet data to and from the network stack . Once the content of the packet has been decided upon by the messaging layer as previously described it is easy for those skilled in the art to see how to use the socket interface to send the packet to the multicast group. Which multicast group to use or which topics are associated with a particular multicast group must be decided upon by a higher layer protocol or configured by a system administrator and is not relevant to the present invention. It is the responsibility of the network stack to transfer the now fully assembled packet including Ethernet IP and UDP headers to the network interface . Note that it is possible within the scope of the present invention to optionally use a network interface card that includes hardware acceleration of some parts of the network stack in order to further reduce latency. This technology is known to those skilled in the art as kernel bypass or TCP offload and is optionally included with some Ethernet and Infiniband network interface cards .

The packet is sent over the network shown in as message but may contain multiple messages to the matching filtering function corresponding to each of the server hosts that have indicated an interest in receiving messages sent to a topic associated with the multicast group to which the packet was sent. The network will replicate the packet as required to deliver a copy to any and all ports on which it received an IGMP join request for the multicast group to which the packet is addressed with the exception of the port on which the packet was originally received. Note that the switch core of a modern network switch can replicate multicast packets with very high efficiency.

Prior to the matching filtering logic delivering any messages to applications a series of control interactions must take place between the applications and the control logic of the enhanced network switch . Before an application can receive any messages from the hybrid message delivery system it must connect to the control logic of the enhanced network switch to provide the details of what topic interests it has as well as some details about how it would like to receive the messages. The application preferentially establishes a TCP connection to the control logic if there is more than one application on a particular server host then each application must have a unique connection to the control logic . Over the control connection an application will send a list of interests and associated multicast group addresses to the control logic along with a UDP port number on which the application is listening. The UDP port number must be unique among applications that are running on a single server host . After gathering this information the control logic must program the matching filtering logic such that it can compare the topic of any received messages with the interests gathered from the applications .

The switch core will have snooped any IGMP join messages that were sent by hosted applications and will forward a copy of any packet with the matching multicast address to ports connected to those server hosts . The matching filtering logic will receive or intercept the packet prior to it being sent to the server host . The matching filtering logic will inspect the IP header looking for a destination IP address that matches one of the ones for which it has collected interests for one or more of its applications . If the destination IP address is a match then the matching filtering logic will begin to parse the rest of the header in the packet . First it will extract the PublisherID . Every application in the hybrid message delivery system has a unique PublisherID . The matching filtering logic must maintain state for all possible PublisherIDs and so must be aware of them this could be configured by a higher level control application or the PublisherIDs could be learned dynamically. The matching filtering logic will use the PublisherID and the multicast group as a key to a lookup table containing the sequence number of the last packet received on that multicast group from that PublisherID . The sequence number resulting from the lookup should be one less than the packet sequence number contained in the packet . If the packet sequence number fails this check then there has been data loss in the network and one of the reliable multicast protocols known in the art can be used to recover the lost data.

If packet loss is detected in the network by the matching filtering logic the reliable multicast protocols to recover the lost data could be implemented by the matching filtering logic or the messaging layer . If the messaging layer is to implement the reliable multicast protocol then a copy of the packet with the incorrect next sequence number and a sequence number gap of zero is forwarded to each application that has joined the multicast group . The matching filtering logic should process a copy of the packet for each application as will be described but it should send a packet even if it contains no messages after the filtering function is performed. This is to trigger the message retransmission mechanisms as soon as possible. Furthermore the matching filtering logic should take steps to prevent applications from requesting more data retransmission than is actually required. If the matching filtering logic has introduced any intentional packet sequence number gaps then before forwarding the current packet the matching filtering logic should generate a packet that contains the last correctly received packet sequence number and the correct sequence number gap for each application listening to the multicast group . Applications for which the matching filtering logic had intentionally introduced a sequence number gap will receive two packets . The first packet will contain the sequence number and sequence number gap for the last packet that the matching filtering logic correctly received from publisher ID and multicast group . This will bring the state that the applications must keep for this publisher ID and multicast group up to date. The second packet will contain the incorrect next sequence number as detected by the matching filtering logic . Upon receiving the second packet the applications will perform their own packet sequence number check. The applications will not be able to tell where the packet loss occurred in the network or between the matching filtering logic and the application but will be able to use the sequence number and sequence number gap to detect loss. The application will lookup the last sequence number received from the same publisherID and multicast group as the current packet . If the last packet sequence number received plus the sequence number gap does not equal the sequence number of the current packet then a retransmission of all packets between the two packet sequence numbers must be requested.

If the packet sequence number passes the previous check then the matching filtering logic can proceed to look for a match between the topic of the first message and the interests that the control logic gathered from the applications reachable via the corresponding port . There are three possible outcomes no match a match for one application or a match for more than one application .

The processing begins at step with a copy of the packet as it is received by the matching filtering logic from the switch core . The headers are transformed to convert the packet from multicast to point to point at step . The destination Ethernet address is modified to be the point to point address of the server host corresponding to the matching filtering logic the destination IP address is similarly transformed from multicast to point to point. The transformation of the Ethernet and IP addresses will see that the packet can be properly received by the network interface and network stack of the server host the UDP destination port must also be transformed so that the network stack can determine the correct application to send the packet to.

Processing of the individual message headers begins at step the remaining steps of the algorithm are repeated for each message that the packet contains. The topic from the message header is matched to interests previously received from the application that is currently being processed at step . Note that in this example matching of topics to interests is described at step but matching of interests to any part of the message or meta data describing it is applicable to the present invention. If any matching interests are found in step then at step the decision on whether or not to include the message in the packet is made. If a matching interest is detected the message is to be included in the network packet and the algorithm proceeds to the next message in the packet at step . If no matching interest was detected at step then the message and its corresponding header is to be removed from the packet at step . After step the algorithm returns to step . If there are no more messages in the current packet then proceed to step . At step the algorithm tests to see if the packet still contains any messages after filtering off or removing all that are uninteresting to the current application . If there are no messages remaining then the entire packet is discarded at step . If the packet is discarded at step then the sequence gap that is stored for this receiving application against the publisherID and multicast group must be incremented and stored. If the current packet still contains one or more message s at step then the sequence gap stored at step for a previous network packet is inserted into the messaging layer header and the Ethernet IP and UDP headers and the Ethernet trailer must be updated to reflect the changes made to the packet . The updates may include updating length fields recalculating checksums and CRCs etc. Once the updates to the packet are completed at step it should be correctly formed and ready for transmission to the server host further processing to take place on the server host has been previously described. Once the network packet has been sent the sequence gap should be reset to zero and stored until the next packet from the same publisherID and multicast group is received at step .

Those skilled in the art will be able to see other possible implementations that differ slightly in mechanics to the one described in the previous example packet format and processing algorithm . For example one could imagine an implementation where a single copy of a packet containing messages is sent the server hosts using the multicast address. In this implementation all applications would receive all messages or just those for which there is a matching interest for at least one application and a bit mask present in the header of each message could be operated upon by the matching filtering function to indicate to the applications on a message by message basis which messages they have indicated an interest in processing. Such an implementation simplifies the implementation of the matching filtering function and ensures only one copy of a message is ever sent over the link but it forces the applications to inspect every message and potentially filter some out. It does however still accomplish the primary goal of offloading the application of the task of matching messages to interests. In a variant of the alternate implementation matching filtering function could remove all messages for which no matching interests are detected and the applications could inspect the topics to see if they match any of their interests.

