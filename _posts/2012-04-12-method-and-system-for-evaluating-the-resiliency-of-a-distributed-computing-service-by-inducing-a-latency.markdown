---

title: Method and system for evaluating the resiliency of a distributed computing service by inducing a latency
abstract: Techniques are disclosed for validating the resiliency of a networked application made available using a distributed computing infrastructure. In one embodiment, a latency monitoring application observes each active application component and at specified or unspecified intervals, selects one and introduces latency or error messages in one or more messages emanating from the selected active application component. The latency monitoring application then measures the effect of the latency or error messages on other active application components that are dependent on the affected active application component. By observing the effects of the failed server on the rest of the network application, a provider can ensure that each component can tolerate any unexpected latency or error conditions with the distributed computing infrastructure.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09015289&OS=09015289&RS=09015289
owner: Netflix, Inc.
number: 09015289
owner_city: Los Gatos
owner_country: US
publication_date: 20120412
---
Embodiments of the present invention generally relate to distributed computing systems and methods and more specifically to evaluating the resiliency of a distributed computing service by inducing latency.

A broad variety of computing applications have been made available to users over computer networks. Frequently a networked application may be provided using multiple interacting computing nodes within a distributed computer system. The networked application exists as one or more networked application components executing on one or more computing nodes. For example a web site may be provided using a web server running on one node within the distributed computing system configured to receive requests from users for web pages. The requests can be passed to an application server running on another node within the distributed computing system which in turn processes the requests and generate responses passed back to the web server and ultimately to the users.

Another example of a networked application includes a content distribution system used to provide access to media titles over a network. Typically a content distribution system may include various servers such as access servers and content servers. Clients may connect to the servers using a content player such as a gaming console computing system computing tablet mobile telephone or network aware DVD player. The content server stores files or streams available for download from the content server to the content player. Each stream may provide a digital version of various forms of video or other content such as a movie a television program a sporting event user generated content or a staged or live event captured by recorded video. Users access the service by connecting to a web server where a list of content is available. Once a request for a particular title is received the title may be streamed to the client system over a connection to an available content server.

In systems such as these latency and errors may occur in various communication paths between a networked application component running on one server and a dependent networked application component running on another server. These latency or error conditions may result from a server or network device that is overburdened or has experienced a software or hardware failure. In some cases the dependent networked application component may not be resilient to such latency or errors in the communication paths with the target application. As a result the dependent networked application components may in turn introduce latency or errors in communication paths to other networked application components potentially cascading latency error conditions or other problems in one or more application components throughout the distributed computer system.

Such cross latencies and errors across multiple networked application components are difficult to test in that latencies and errors within a complex distributed computer system are difficult to sufficiently model accurately. Network application components that may appear to be sufficiently resilient on a test system may nevertheless fail when deployed on the distributed computer system. As the foregoing illustrates what is needed is a better way to test the resiliency of an application running on a distributed computer system.

One embodiment of the invention disclosed herein provides a computer implemented method for evaluating resiliency of a networked application. The method may include identifying a plurality of active application components within a network through which the networked application is provided selecting a first active application component from the plurality of active application components based on one or more selection criteria altering a message transmitted by the first active application component according to a predefined alteration rule and monitoring a second active application component included in the plurality of active application components to determine an effect on the second active application component caused by the altered message.

Other embodiments include without limitation a computer readable medium that includes instructions that enable a processing unit to implement one or more aspects of the disclosed methods as well as a system configured to implement one or more aspects of the disclosed methods.

Embodiments of the invention provide techniques for validating the resiliency of a networked application made available using a collection of interacting computing elements within a distributed computing system. Such computing elements are referred to herein as nodes. For example a network monitoring application referred hereafter as a latency application may be configured to introduce latency or errors into communication paths associated with an instance of a target networked application component that is running on a particular node. The latency application may then determine whether systems that depend on the target networked application component can still function correctly or degrade gracefully following such induced latency or error conditions. Thus the latency application may observe the impact of latency or error conditions on other systems within the distributed computing system in a controlled manner. This approach may be useful in cloud based computing environments where the location of various computing components is unknown as well as for physical servers in a data center.

In one embodiment the latency application observes each running application component at unspecified intervals selects one of the running application components and introduces latency or error in one or more of the application component s communication paths. The selected application component is referenced herein as the target application component. The latency application then observes changes in behavior of application components dependent on the target application component.

By observing the effects on dependent application components a provider can ensure that each component can tolerate such latency or errors. In one embodiment the latency application may be used in a test environment prior to deploying an update or patch to application components or other software modules in a production environment. Doing so allows the effects of the update or patch to be evaluated without being deployed to the production environment. In another embodiment the latency application may be used in a production environment where latency or errors are introduced in a distributed computer system while the system is online. Thus in various embodiments the latency application helps enforce requirements for fault tolerance within a distributed computer system which might otherwise be lost over time as production systems are upgraded patched or otherwise changed in manners that create unintended or unwanted dependencies. More generally any logical group of systems may be defined and tested by the latency application described herein.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances well known features have not been described in order to avoid obscuring the present invention.

Further particular embodiments of the invention are described using an example of a networked application used to stream movies music television programming or user generated content over a data communications network to end user client devices. However it should be understood that embodiments of the invention may be adapted to validate the resiliency to individual system failure for a broad variety of networked applications or services. Accordingly references to a streaming media service are merely illustrative and not limiting.

In one embodiment the cloud is hosted by a cloud services provider such as Amazon . The cloud services provider houses the nodes in various datacenters in different physical locations around the world and enables clients to access the cloud services over the network . For example Amazon hosts a virtual cloud storage solution called Amazon Simple Storage Service S3 as well as a virtual processing solution called Amazon Elastic Compute Cloud EC2 accessible through the internet using common transport protocols such as Hypertext Transport Protocol http . In another embodiment a single organization may host both the cloud and the client device in a private network.

Each of the nodes includes a processor CPU a memory a network interface controller NIC and one or more non volatile storage devices such as a hard disk drive a magnetic tape drive optical disk drives a drive array e.g. RAID or the like not shown . Each node may include an operating system e.g. Microsoft Windows Linux Unix etc. as well as one or more applications stored in memory and running on the CPU. Some of the applications may provide a software framework for various cloud service architectures such as a distributed database management system like Apache Cassandra or distributed application system like Apache Hadoop. In one embodiment each node comprises a blade server where two or more blade servers are housed in a chassis and share certain resources such as common power supplies and cooling systems.

Client device also includes a processor CPU a memory a NIC and one or more non volatile storage devices not shown . Similar to nodes client device also includes an operating system as well as one or more applications such as client application stored in memory and running on the CPU. In one embodiment client computer may be maintained by a data analyst to analyze the distributed computer system . Client device may communicate with one or more of the nodes via network through NICs on the client device and nodes . Thus the client application may access one or more networked applications executing on the cloud by causing the client device to communicate to one or more nodes via the network .

An administration server may perform administrative tasks for the distributed computer system autonomously or may perform administrative tasks in response to one or more commands issued by a system administrator. The administration server may be any computing device that includes conventional components such as a processor memory storage and network interface including one of the nodes . The administration server may include a software application such as a latency application that produces a graphical user interface or a command line interface and allows a system administrator perform various functions including without limitation configuring monitoring and testing the cloud . The administration server may communicate to one or more of the nodes via communication link .

A latency application is configured to execute on administration server . As further described below the latency application schedules one or more simulations of increased latency or error conditions within the cloud . The latency application introduces the latency or error conditions in a specified communication path associated with a selected active application component referred to herein as the target component .

In general the CPU retrieves and executes programming instructions stored in the memory . Similarly the CPU stores and retrieves application data residing in the memory . The interconnect facilitates transmission of programming instructions and application data between the CPU I O devices interface storage network interface and memory . CPU is included to be representative of a single CPU multiple CPUs a single CPU having multiple processing cores and the like. The memory is generally included to be representative of a random access memory. The storage may be a disk drive storage device. Although shown as a single unit the storage may be a combination of fixed and or removable storage devices such as fixed disc drives floppy disc drives tape drives removable memory cards optical storage network attached storage NAS or a storage area network SAN .

Illustratively the memory includes a latency application and storage includes monitoring logs . As shown the latency application includes a latency component a recovery monitor and simulation monitoring parameters . As noted above the latency application may provide a software application configured to periodically select and introduce latency or error conditions in an active networked application component associated with a networked application. The networked application component may be executing on a node in distributed computing system running in a cloud computing environment or on a server in a provider s data center.

In one embodiment the latency component selects a target active application component and simulates latency or error conditions in one or more communications paths associated with the application component. The latency component configures the simulation according to monitoring parameters . The monitoring parameters controlling a given simulation may be predetermined automatically by the latency application . Alternatively the latency application may receive one or more monitoring parameters from a system administrator via a graphical or command line interface. For example the latency application may set a monitoring parameter associated with whether a simulation will operate in latency mode or error mode. If latency mode is specified the latency application causes the target component to delay messages by a predetermined amount of time. Alternatively a random delay may be introduced rather than a specific amount of time. If error mode is specified the latency application causes the target component to introduce an error message in place of an otherwise expected message. For example in response to a request associated with a specified uniform resource locator URL the latency application may cause the target component to return an error message such as a not found error rather than the web page at the referenced URL.

Other monitoring parameters associated with a simulation include without limitation the number of times a simulation is scheduled to execute the start time of a simulation the duration of a simulation and the duration between successive executions of a simulation. The latency application may also determine whether all messages emanating from the selected component are affected or only messages that meet one or more event descriptors specified by the system administrator. For example a simulation may be programmed to introduce latency only in response to messages requesting a user s mailing address. In another example the simulation may be programmed to affect a certain percentage of the total number of messages emanating from the target component.

Once a target application component is selected and the simulation begins the recovery monitor may observe the actions of application components that are dependent on the target application component. The recovery monitor gathers latency and other information from the dependent application component and then stores the information in logs . The content of logs may include information specified by the monitoring parameters as well as include the logging data created by the dependent application components.

Application components provide one or more functions associated with a networked application. An application component may function as a server as a client or as both a server and a client. For example application component functions as a server for application component . Correspondingly application component functions as a client of application component . In addition application components may function as clients and servers for other application components executing on other nodes not shown .

Server interface intercepts server based messages transmitted or received by application component . Correspondingly server interface intercepts server based messages transmitted or received by application component . The server interface performs various functions on these messages including without limitation data compression decompression and error or exception handling for incorrectly formatted messages. For example server interface may receive a message from client interface check the message for proper formatting and then pass the message to application component . Application component processes the message and generates a response message. Application component transmits the response message to server interface . Server interface performs one or more functions on the response message and then transmits the response message to client interface . The server interface may also be programmed to provide test and measurement functions such as measuring the latency between a message from a client and a corresponding response message from the server. The server interface may then store these measurements for later retrieval and evaluation.

Client interface intercepts client based messages transmitted or received by application component . Correspondingly client interface intercepts client based messages transmitted or received by application component . The client interface performs various functions on these messages including without limitation data compression decompression error or exception handling for incorrectly formatted messages and re trying transmission of a message when no response to the message is received from the server. For example application component may generate a message to transmit to application component . Application component transmits the message to client interface . Client interface performs one or more functions on the message and then transmits the message to server interface . As described above server interface and application component process the message and generated a response message. Client interface receives and processes the response message and transmits the response message to application component . The client interface may also be programmed to provide test and measurement functions such as measuring the latency between a message and a corresponding response message. The client interface may then store these measurements for later retrieval and evaluation.

As described above the administration server communicates to one or more of the nodes over communications links during the configuration monitoring and testing functions. The latency application may use the communication links to configure a simulation begin execution of a simulation and collect metrics resulting from a simulation. In particular the latency application sets parameters within client interfaces and server interfaces to introduce latency or error conditions to messages as they are passed between various application components . For example the latency application may set a parameter in server interface to delay messages transmitted to or from application component by a predetermined period in order to introduce increased latency. In another example the latency application may set a parameter in server interface to replace messages with an error message rather than the original message. The latency application may configure server interface to alter all messages that pass through server interface or a certain percentage of messages. Alternatively the latency application may configure server interface to alter messages that meet one or more criteria including without limitation messages that specify an access to a particular uniform resource locator URL . The latency application may also set parameters on client interface in a manner similar to that described above for server interface .

When the time scheduled for a simulation has arrived the latency application selects an application component the target application component writes parameters to client interface and server interface according to the settings in the simulation and begins the simulation. During the simulation application components dependent on the target application component may experience increased latency error conditions or other problems because of the latency or error conditions introduced by the simulation. The dependent application components may have a direct connection with the target application component direct dependence . Alternatively dependent application components may have a connection with the target application component through one or more other application components indirect dependence . When the simulation has run for the duration scheduled the latency application restores parameters within client interface and server interface to their original operational values and the simulation terminates. The latency application collects latency information and other metrics by querying client interfaces and server interfaces associated with application components that are directly or indirectly affected by the target application component . The latency application stores the metrics for later analysis by a system administrator.

The method begins at step where the latency application determines whether the mode for the simulation is latency mode. If the mode of the simulation is latency mode then the method proceeds to step where the latency application sets the latency mode for the simulation and sets the delay time associated with the simulation. During the simulation select messages experience an increased latency related to the delay time where the delay time may represent without limitation an actual delay time a maximum delay time or an average delay time. Returning to step if mode of the simulation is not latency mode then the mode of the simulation is error mode. The method proceeds to step where the latency application sets the error mode. In an error mode simulation select messages return an error message rather than the appropriate message response.

From either step or the method proceeds to step where the latency application may set one or more event descriptors associated with the simulation such that certain message types experience increased latency or error conditions rather than all messages. For example the simulation may introduce latency or error conditions only for messages requesting a user s mailing address or for messages that request access to a specified uniform resource locator URL . If no event descriptors are set all messages transmitted by the application component are subject to the increased latency or error response. At step the latency application sets the simulation frequency and duration. For example the simulation may be scheduled for a duration of ten minutes and to occur once periodically such as once per week or at random intervals. At step the latency application determines the set of applications that are dependent on the target application. Dependent applications may be directly dependent on the target application where the dependent application has a direct communication link with the target application. Alternatively dependent applications may be indirectly dependent on the target application where the dependent application may be affected by the target application via one or more intervening applications. At step the latency application saves the simulation schedule including the mode any applicable event descriptors and frequency as described above.

At step the latency application waits until the time to run the simulation has been reached. Once the time to run the simulation has been reached the method proceeds to step where the latency application sets the simulation properties within the client interface or the server interface according to the previously saved simulation. At step the latency application begins recording of observed latencies within the distributed computer system . In particular the latency application records latencies experienced by applications that are directly or indirectly dependent on the target application. At step the latency application waits for the simulation duration period to expire. At step the latency application resets the simulation properties within the client interface or the server interface according to the original values prior to the simulation. At step the latency application collects the recorded results from the simulation. The latency application may organize the collected results in any technically feasible manner such as a relational database report or series of graphs. The method then terminates.

In sum the resiliency of networked applications is evaluated within a distributed computer system by introducing latency or error conditions on various communication links. A latency application is configured to schedule a simulation that causes increased latency or error conditions associated with a specific target application. In one embodiment a latency application observes each active application component and at specified or unspecified intervals selects one and introduces latency or error messages in one or more messages emanating from the selected active application component. The latency application then measures the effect of the latency or error messages on other active application components that are dependent on the affected active application component.

Advantageously results from latency or error simulations may be useful to determine resiliency of one or more application components associated with a networked application. By introducing latency and error conditions in a simulation followed by measuring the effect on dependent components the information collected by the latency application may be helpful to the system administrator to improve various components in the networked application to be more resilient during periods of increased latency or error conditions.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the present invention.

