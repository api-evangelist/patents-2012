---

title: Generating a predictive model from multiple data sources
abstract: Techniques are disclosed for generating an ensemble model from multiple data sources. In one embodiment, the ensemble model is generated using a global validation sample, a global holdout sample and base models generated from the multiple data sources. An accuracy value may be determined for each base model, on the basis of the global validation dataset. The ensemble model may be generated from a subset of the base models, where the subset is selected on the basis of the determined accuracy values.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08996452&OS=08996452&RS=08996452
owner: International Business Machines Corporation
number: 08996452
owner_city: Armonk
owner_country: US
publication_date: 20120710
---
This application is a continuation of U.S. patent application Ser. No. 13 048 536 filed on Mar. 15 2011 which application is incorporated herein by reference in its entirety.

Data mining is an application of computer databases to extract useful information from large volumes of data. Extracting the useful information may include processing the large volumes of data identifying the most significant and or meaningful patterns and presenting the identified patterns as knowledge for achieving the goals of a user. For a data mining application to be widely applicable a user should be able to supply the data mining application with data specific to a problem domain without having to inform the data mining application about the nuances of the problem domain. The data mining application may then identify patterns with respect to the supplied data.

Embodiments of the invention provide a computer implemented method computer program product and system for performing an operation that includes generating for each of a plurality of data sources a validation sample a holdout sample and a base model from the respective data source. The operation also includes merging the validation samples and the holdout samples for the plurality of data sources into a global validation dataset and a global holdout dataset respectively. The operation also includes determining an accuracy value for each base model based on the global validation dataset. The operation also includes generating an ensemble model from a subset of the base models that are selected based on the determined accuracy values.

Embodiments of the invention provide techniques for generating predictive models from multiple data sources. Predictive modeling refers to an area of data mining and knowledge discovery that is directed toward extracting data patterns having predictive value. For example predictive modeling may be used in the direct mail marketing industry to improve return on marketing investment by ranking consumers according to their predicted response to promotional materials and mailing the promotional materials only to those consumers deemed most likely to respond and generate revenue. Predictive modeling may also be used in the credit industry to determine a probability that a consumer or business will default on a loan of a specified size based information known about the consumer or business. The predictive models may then be used in deciding whether to grant loans and or determining maximum loan amounts. Predictive modeling may also be used in the insurance industry to determine a frequency with which a consumer or business will file insurance claims and or an average loss amount per claim. The predictive models may then be used to set insurance premiums and or to set underwriting rules for different categories of insurance coverage. Predictive modeling may also be used in the Internet advertising industry to determine a probability that a user will click through an advertisement based on information known about the user and the content in the advertisement. The predictive models may then be used to select an advertisement to serve to each user to improve click through rates and or revenue. Of course the above applications of predictive modeling are merely exemplary and are not intended to be limiting of the disclosure and other applications of predictive modeling are broadly contemplated.

One embodiment of the invention provides an application configured to generate predictive models from multiple data sources. To this end the application may make one or more calls to an application programming interface API supported by an underlying application framework. The application framework may be configured to support distributed computing on vast amounts of data and using a cluster of compute nodes. In some embodiments the data may amount to petabytes of data and the cluster may include thousands of compute nodes. To facilitate distributed computing the application framework may schedule operations to be performed by the compute nodes monitor the compute nodes and or the operations being performed and reschedule failed operations to be re performed by the compute nodes. The operations may include at least a map operation and or a reduce operation which are further described below. The application may make an API call to the application framework to provide implementations of the map operation and the reduce operation to the application framework. The implementations may be provided using object oriented techniques such as by implementing interfaces and or abstract classes supported by the application framework. By providing implementations of the map operation and the reduce operation the application may configure the application framework to suit the needs of the application. The application may also make additional API calls to the application framework to specify locations of desired input data sets and output data sets respectively.

As described above in one embodiment the application is configured to generate predictive models from multiple data sources. However depending on the embodiment some or all of the functionality of the application may be performed by the underlying application framework and vice versa. Further any application framework may be used according to the techniques disclosed herein including application frameworks implementing the MapReduce interface from Google Inc. such as Hadoop which is available from the Apache Software Foundation.

In one embodiment once the application framework is configured the application framework splits the input data set into a multiple subsets to be processed in parallel on the cluster of compute nodes. To this end each compute node executes the map operation in parallel on a respective subset of the input data to create a subset of intermediate data. The application framework then provides the intermediate data as input to the reduce operation which executes on each compute node. The reduce operation generates an output data set which is stored in the desired location as specified by the application during the configuration process. At least in some embodiments a user only desires the map operation to be performed. In such embodiments the application may not necessarily provide any implementation of the reduce operation to the application framework. Accordingly in such embodiments the intermediate data generated by the map operation may be regarded as the final output and may be stored in the desired location as specified by the application.

In one embodiment the map operation outputs the intermediate data in the format of multiple pairs of data each pair including a key and an associated value. Further the reduce operation may accept as input data in the format of the multiple pairs of data. The output of the reduce operation may also be in the format of the multiple pairs of data. To illustrate usage of the format of multiple pairs of data by the map operation and or reduce operation suppose a user desires to generate a count of each word in the English language that appears in a plurality of documents. In this particular example the format of multiple pairs of data may represent a count of occurrences of each English word across the documents. Each key stores an English word and each value stores a corresponding count of occurrences of the English word as determined by the map operation and or reduce operation. Suppose that the application framework schedules each compute node to perform the map operation on a respective document. The intermediate data generated by the map operation represents the occurrences of each word in the respective document. The application framework may then schedule each compute node to perform a reduce operation which tallies the occurrences across all of the documents to generate the output data set. Although the above example is described with reference to a plurality of documents as input data to the map operation in other embodiments the input data to the map operation may also be formatted as multiple pairs of data each pair including a key and an associated value.

As described above in one embodiment the application generates predictive models from multiple data sources in a distributed computing environment. To this end the application may use the application framework executing in the distributed computing environment. Additionally or alternatively the application may also adhere to a predefined architecture for generating predictive models. In some embodiments the architecture for generating predictive models may facilitate generating predictive models from various types of data sets. The types of data sets may include a first type representing a single data source to be processed in a single pass to generate a single predictive model. The types of data sets may also include a second type representing real time data streams to be processed to generate a predictive model. The types of data sets may also include a third type representing distributed data sources. In some embodiments the distributed data sources may include a plurality of predictive models to be combined to generate a single predictive model without accessing any data set from which the plurality of predictive models is generated. Depending on the embodiment some or all of the functionality of the application adhering to the predefined architecture may be performed by the underlying application framework. One example of an architecture that the application may adhere to is the Pass Stream Merge PSM architecture by Leland Wilkinson.

In one embodiment to generate predictive models from multiple data sources in a distributed computing environment the application may implement a map operation configured to generate a base model for each data source. The map operation may also be configured to extract a validation sample and a holdout sample from the respective data source. In some embodiments the validation sample and the holdout sample may be extracted randomly from the respective data source. The application may also implement a reduce operation that is configured to generate an ensemble model based on a subset of base models generated by the map operation. The subset of base models may be selected by evaluating all base models against the extracted validation samples. Accordingly the ensemble model may be generated without first requiring all of the data sources or base models to be merged. Advantageously the ensemble model may be generated more conveniently and or efficiently at least in some cases.

In the following reference is made to embodiments of the invention. However it should be understood that the invention is not limited to specific described embodiments. Instead any combination of the following features and elements whether related to different embodiments or not is contemplated to implement and practice the invention. Furthermore although embodiments of the invention may achieve advantages over other possible solutions and or over the prior art whether or not a particular advantage is achieved by a given embodiment is not limiting of the invention. Thus the following aspects features embodiments and advantages are merely illustrative and are not considered elements or limitations of the appended claims except where explicitly recited in a claim s . Likewise reference to the invention shall not be construed as a generalization of any inventive subject matter disclosed herein and shall not be considered to be an element or limitation of the appended claims except where explicitly recited in a claim s .

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

Embodiments of the invention may be provided to end users through a cloud computing infrastructure. Cloud computing generally refers to the provision of scalable computing resources as a service over a network. More formally cloud computing may be defined as a computing capability that provides an abstraction between the computing resource and its underlying technical architecture e.g. servers storage networks enabling convenient on demand network access to a shared pool of configurable computing resources that can be rapidly provisioned and released with minimal management effort or service provider interaction. Thus cloud computing allows a user to access virtual computing resources e.g. storage data applications and even complete virtualized computing systems in the cloud without regard for the underlying physical systems or locations of those systems used to provide the computing resources.

Typically cloud computing resources are provided to a user on a pay per use basis where users are charged only for the computing resources actually used e.g. an amount of storage space consumed by a user or a number of virtualized systems instantiated by the user . A user can access any of the resources that reside in the cloud at any time and from anywhere across the Internet. In context of the present invention an application framework may execute in the cloud where the application framework is configured to generate one or more predictive models from multiple data sets stored in the cloud. Having the application framework execute in the cloud allows the user to access the predictive models from any computing system attached to a network connected to the cloud e.g. the Internet .

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

The computer generally includes a processor connected via a bus to a memory a network interface device a storage an input device and an output device . The computer is generally under the control of an operating system. Examples of operating systems include UNIX versions of the Microsoft Windows operating system and distributions of the Linux operating system. More generally any operating system supporting the functions disclosed herein may be used. The processor is included to be representative of a single CPU multiple CPUs a single CPU having multiple processing cores and the like. Similarly the memory may be a random access memory. While the memory is shown as a single identity it should be understood that the memory may comprise a plurality of modules and that the memory may exist at multiple levels from high speed registers and caches to lower speed but larger DRAM chips. The network interface device may be any type of network communications device allowing the computer to communicate with other computers via the network .

The storage may be a persistent storage device. Although the storage is shown as a single unit the storage may be a combination of fixed and or removable storage devices such as fixed disc drives solid state drives floppy disc drives tape drives removable memory cards or optical storage. The memory and the storage may be part of one virtual address space spanning multiple primary and secondary storage devices. Further as described above the application receives identity records and or entity accounts from the data source . Additionally or alternatively the application may also receive identity records and or entity accounts via the storage .

The input device may be any device for providing input to the computer . For example a keyboard keypad light pen touch screen track ball or speech recognition unit audio video player and the like may be used. The output device may be any device for providing output to a user of the computer . For example the output device may be any conventional display screen or set of speakers along with their respective interface cards i.e. video cards and sound cards not shown . Although shown separately from the input device the output device and input device may be combined. For example a display screen with an integrated touch screen a display with an integrated keyboard or a speech recognition unit combined with a text speech converter may be used.

In one embodiment input data for generating a predictive model is divided into three datasets a training dataset a validation dataset and a holdout dataset. The training dataset is used to generate base models. More specifically each base model is generated by applying a specified learning method on a given portion of the training dataset. The specified learning method may be tailored for the needs of a particular case. For example the specified learning method may be a supervised learning method such as decision tree neural network and regression. The validation dataset is used for selecting base models based on predefined criteria. The holdout dataset is used to evaluate the selected base models. An ensemble model refers to a collection of generated base models and one or more rules for combining predictions of the base models. In some embodiments a reference model is generated from the validation dataset to be used to evaluate the ensemble model.

As shown the memory of the computer includes an application and an application framework . The storage of the computer includes a global validation dataset a global holdout dataset base models and an ensemble model . As described above the application and the application framework are configured to generate the ensemble model from the data sources . To this end the global validation dataset the global holdout dataset and the base models may first be generated from the data sources according to the techniques disclosed below. Further although the application and the application framework are shown to be executing on the single computer in other embodiments the application and or the application framework may execute in parallel across multiple compute nodes connected via the network .

In one embodiment the data flow also includes a further map operation corresponding to each data source . In this regard the map operation does not necessarily access the respective data source and may merely access the global validation dataset to evaluate one or more base models. The map operation includes a first step of scoring the base model corresponding to the respective data source . Scoring the base model may include computing a score or prediction for each record in the global validation dataset . The map operation includes a second step of determining an accuracy of the base model against the global validation dataset . Determining an accuracy of the base model may include comparing the computed scores against target values in the global validation dataset . In doing so each base model is compared using data other than the source data from which the respective base model is generated. As an example suppose the input data represents customer loan defaults and associated customer background information. The input data may include a loan default flag that stores a value of 1 to represent a loan default and a value of 0 to represent an absence of the loan default. In one embodiment a score of either 1 or 0 is generated for each customer represented in the global validation dataset using the base models and the customer background information where the base models are generated using a different dataset and or data source relative to the global validation dataset. A generated score is correct when the generated score matches an actual loan default value for a respective customer. The accuracy of the base model may be determined as a percentage of correct scores for a given dataset. For example if the scores in base model are correct for 350 out of 500 customers in the dataset then the accuracy may be computed as seventy percent.

In one embodiment the data flow also includes a second reduce operation which includes a first step of selecting a subset of the base models based on the accuracy determined in the step . The second reduce operation also includes a second step of generating the ensemble model from the subset of the base models. The second reduce operation also includes a third step of generating the reference model from the global validation dataset . The second reduce operation also includes a fourth step of evaluating the ensemble model and the reference model against the global holdout dataset . Based on the evaluation the application may designate either the ensemble model or the reference model for use in data modeling and or predictive scoring. In one embodiment predictive scoring refers to using data models for predictive purposes such as deriving knowledge about input data or an underlying process represented by the input data. Users may review the data model to identify relevant predictors and an associated measure of influence. Additionally users may review an ensemble model to identify measures of importance of one or more variables. Accordingly by performing the map operations and reduce operations the application may generate the ensemble model without first requiring all of the data sources or base models to be merged.

At step the application generates an ensemble model from a subset of the base models the subset being selected based on the determined accuracy values. At step the application generates a reference model from the global validation dataset. At step the application evaluates the ensemble model and the reference model using the global holdout dataset. If the ensemble model is determined to be more accurate than the reference model then the application designates the ensemble model to be used in at least one of data modeling and predictive scoring. Otherwise the application designates the reference model to be used in at least one of data modeling and predictive scoring. After the step the method terminates.

At step application framework initiates a map operation for each data block to generate a base model a validation sample and a holdout sample for the respective data block. The base model may be stored in a base model container and the validation sample and the holdout sample may both be stored in a data container. Depending on the embodiment both the validation sample and the holdout sample may be generated using a single predefined randomization procedure. In other embodiments the validation sample and the holdout sample are generated using different predefined procedures. Further in some embodiments data that is not included in any sample may be designated as training data for use in generating the base model. In this regard the base model may be generated only from data that is not included in any sample.

At step each map operation generates a validation sample and a holdout sample from the respective data block. At step each map operation generates a base model from the data block. At step the application framework initiates one or more reduce operations to merge the validation samples and holdout samples from the map operations to create a global validation dataset and a global holdout dataset respectively.

In some embodiments for reasons relating to scalability and or performance the sizes of each of the global validation dataset and the global holdout dataset may be limited to a first predefined maximum size. In one embodiment the first predefined maximum size is enforced by only merging a portion of each holdout sample and or validation sample into the global validation dataset and or the global holdout dataset where the portion does not exceed a second predefined maximum size. Depending on the embodiment the second predefined maximum size may be determined by dividing the first predefined maximum size by a count of data blocks generated by the application framework . In an alternative embodiment each holdout sample and or validation sample is limited in size to a third predefined maximum size. The third predefined maximum size may be determined by dividing the second predefined maximum size by a count of map operations initiated by the application framework . In this alternative embodiment the holdout samples and or validation samples may be merged into the global validation dataset and the global holdout dataset respectively without having to impose any size limits during the merging operations.

In one embodiment the application framework also generates a reference model from the global validation dataset. The single predictive model deployed for generating predictions is ultimately selected from the reference model and the ensemble model based on accuracy. In this sense the reference model serves as a competitor to the ensemble model for deployment in generating predictions. At step the application framework distributes the base models and the global validation dataset to one or more map operations. At step the one or more map operations score each base model and determine an accuracy for the respective base model on the basis of the global validation dataset. In at least some embodiments each of the one or more map operations accesses the entire global validation dataset at the step . At step the application framework selects a subset of the base models for use in generating an ensemble model. At step the application framework scores the ensemble model and reference model. The application framework may then evaluate the ensemble model and the reference model against the global holdout dataset. At step upon determining that the ensemble model is more accurate than the reference model the application framework deploys the ensemble model for use in generating predictions based on subsequent input data. After the step the method terminates.

Advantageously embodiments of the invention provide techniques for generating an ensemble model from multiple data sources. One embodiment provides an application configured to generate the ensemble model using a global validation sample a global holdout sample and base models generated from the multiple data sources. The application may also determine an accuracy value for each base model based on the global validation dataset. The application may also generate an ensemble model from a subset of the base models that are selected based on the determined accuracy values. Accordingly the ensemble model may be generated without first having to merge data from the data sources into a single data source. Advantageously the ensemble model may be generated more conveniently and or efficiently at least in some cases.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof and the scope thereof is determined by the claims that follow.

