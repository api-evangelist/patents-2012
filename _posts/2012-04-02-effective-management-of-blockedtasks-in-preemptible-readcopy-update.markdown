---

title: Effective management of blocked-tasks in preemptible read-copy update
abstract: A technique for managing read-copy update readers that have been preempted while executing in a read-copy update read-side critical section. A single blocked-tasks list is used to track preempted reader tasks that are blocking an asynchronous grace period, preempted reader tasks that are blocking an expedited grace period, and preempted reader tasks that require priority boosting. In example embodiments, a first pointer may be used to segregate the blocked-tasks list into preempted reader tasks that are and are not blocking a current asynchronous grace period. A second pointer may be used to segregate the blocked-tasks list into preempted reader tasks that are and are not blocking an expedited grace period. A third pointer may be used to segregate the blocked-tasks list into preempted reader tasks that do and do not require priority boosting.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08869166&OS=08869166&RS=08869166
owner: International Business Machines Corporation
number: 08869166
owner_city: Armonk
owner_country: US
publication_date: 20120402
---
This application is a continuation under 35 U.S.C. 120 of application Ser. No. 13 164 265 filed Jun. 20 2011 entitled Effective Management Of Blocked Tasks In Preemptible Read Copy Update. 

The present disclosure relates to computer systems and methods in which data resources are shared among data consumers while preserving data integrity and consistency relative to each consumer. More particularly the disclosure concerns an implementation of a mutual exclusion mechanism known as read copy update in a computing environment wherein the data consumers are subject to being preempted while referencing shared data.

By way of background read copy update also known as RCU is a mutual exclusion technique that permits shared data to be accessed for reading without the use of locks writes to shared memory memory barriers atomic instructions or other computationally expensive synchronization mechanisms while still permitting the data to be updated modify delete insert etc. concurrently. The technique is well suited to both uniprocessor and multiprocessor computing environments wherein the number of read operations readers accessing a shared data set is large in comparison to the number of update operations updaters and wherein the overhead cost of employing other mutual exclusion techniques such as locks for each read operation would be high. By way of example a network routing table that is updated at most once every few minutes but searched many thousands of times per second is a case where read side lock acquisition would be quite burdensome.

The read copy update technique implements data updates in two phases. In the first initial update phase the actual data update is carried out in a manner that temporarily preserves two views of the data being updated. One view is the old pre update data state that is maintained for the benefit of read operations that may have been referencing the data concurrently with the update. The other view is the new post update data state that is seen by operations that access the data following the update. In the second deferred update phase the old data state is removed following a grace period that is long enough to ensure that the first group of read operations will no longer maintain references to the pre update data. The second phase update operation typically comprises freeing a stale data element to reclaim its memory. In certain RCU implementations the second phase update operation may comprise something else such as changing an operational state according to the first phase update.

It is assumed that the data element list of is traversed without locking by multiple readers and occasionally updated by updaters that delete insert or modify data elements in the list. In the data element B is being referenced by a reader r as shown by the vertical arrow below the data element. In an updater u wishes to update the linked list by modifying data element B. Instead of simply updating this data element without regard to the fact that r is referencing it which might crash r u preserves B while generating an updated version thereof shown in as data element B and inserting it into the linked list. This is done by u acquiring an appropriate lock to exclude other updaters allocating new memory for B copying the contents of B to B modifying B as needed updating the pointer from A to B so that it points to B and releasing the lock. In current versions of the Linux kernel pointer updates performed by updaters can be implemented using the rcu assign pointer primitive. As an alternative to locking during the update operation other techniques such as non blocking synchronization or a designated update thread could be used to serialize data updates. All subsequent post update readers that traverse the linked list such as the reader r will see the effect of the update operation by encountering B as they dereference B s pointer On the other hand the old reader r will be unaffected because the original version of B and its pointer to C are retained. Although r will now be reading stale data there are many cases where this can be tolerated such as when data elements track the state of components external to the computer system e.g. network connectivity and must tolerate old data because of communication delays. In current versions of the Linux kernel pointer dereferences performed by readers can be implemented using the rcu dereference primitive.

At some subsequent time following the update r will have continued its traversal of the linked list and moved its reference off of B. In addition there will be a time at which no other reader process is entitled to access B. It is at this point representing an expiration of the grace period referred to above that u can free B as shown in .

In the context of the read copy update mechanism a grace period represents the point at which all running tasks e.g. processes threads or other work having access to a data element guarded by read copy update have passed through a quiescent state in which they can no longer maintain references to the data element assert locks thereon or make any assumptions about data element state. By convention for operating system kernel code paths a context switch an idle loop and user mode execution all represent quiescent states for any given CPU running non preemptible code as can other operations that will not be listed here . The reason for this is that a non preemptible kernel will always complete a particular operation e.g. servicing a system call while running in process context prior to a context switch.

In four tasks and running on four separate CPUs are shown to pass periodically through quiescent states represented by the double vertical bars . The grace period shown by the dotted vertical lines encompasses the time frame in which all four tasks that began before the start of the grace period have passed through one quiescent state. If the four tasks and were reader tasks traversing the linked lists of or none of these tasks having reference to the old data element B prior to the grace period could maintain a reference thereto following the grace period. All post grace period searches conducted by these tasks would bypass B by following the updated pointers created by the updater.

Grace periods may synchronous or asynchronous. According to the synchronous technique an updater performs the first phase update operation blocks waits until a grace period has completed and then implements the second phase update operation such as by removing stale data. According to the asynchronous technique an updater performs the first phase update operation specifies the second phase update operation as a callback then resumes other processing with the knowledge that the callback will eventually be processed at the end of a grace period. Advantageously callbacks requested by one or more updaters can be batched e.g. on callback lists and processed as a group at the end of an asynchronous grace period. This allows asynchronous grace period overhead to be amortized over plural deferred update operations. In some RCU implementations asynchronous grace period processing is the norm but a synchronous expedited grace period sometimes referred to as a Big Hammer grace period is also available for updaters that need it. This expedited grace period forces a context switch and thus a quiescent state on each processor so that an updater can quickly perform its second phase update operation. Existing callbacks associated with asynchronous grace periods are not affected. They must await the end of an asynchronous grace period before becoming ripe for processing.

It will be appreciated from the foregoing discussion that the fundamental operation of the RCU synchronization technique entails waiting for all readers associated with a particular grace period to complete. Multiprocessor implementations of RCU must observe or influence the actions performed by multiple processors whereas uniprocessor implementations do not. In so called non preemptible variants of RCU readers are never preempted and rescheduled within an RCU read side critical section. Orderly grace period processing in such implementations may then be ensured by either forcing or waiting for each reader s processor to pass through a quiescent state.

The situation is different for so called preemptible variants of RCU wherein readers are subject to preemption within RCU read side critical sections. In that case a context switch will occur but will not constitute a quiescent state as in the case of non preemptible RCU. For example in a preemptible operating system kernel the servicing of a system call during process context could be interrupted by a higher priority task while the system call code is in the midst of an RCU read side critical section. In this situation other techniques are required to track quiescent states. The approach most often used is to treat all reader processing outside of an RCU read side critical section as a quiescent state and to provide some form of tracking methodology that allows readers to specify when they are performing RCU read side critical section processing. A grace period will not end until all readers being tracked in this manner indicate that they have completed such processing. Throughout the present document readers that are preempted within an RCU read side critical section will also be referred to as blocked readers.

Unfortunately separate tracking of preempted readers is typically required for asynchronous grace periods and synchronous expedited grace periods because there is not necessarily any direct relation between the two. They might overlap be disjoint or have one wholly contained within the other. This separate tracking complicates RCU grace period detection processing. Preemptible readers may also be tracked in order to determine which readers are tardy in completing their RCU read side critical section processing and thus may be blocked by a higher priority process. Such preempted readers can be given a scheduling priority boost in RCU implementations that support such functionality. Without a priority boost such readers could delay the end of a current grace period potentially leading to problems such as an out of memory OOM condition caused by excessive callback accumulation. Unfortunately tracking preemptible readers for possible priority boosting further complicates RCU grace period detection processing.

In conventional RCU implementations the tracking of preemptible readers has been accomplished using a number of methods. According to one such technique per processor counters track the number of still in progress RCU read side critical sections that began on the corresponding processors see P. McKenney et al. Extending RCU for Realtime and Embedded Workloads Aug. 11 2006 . According to a variant of this technique per processor counters track the difference between the number of RCU read side critical sections that began on a given processor and the number of RCU read side critical sections that ended on that same processor see Id. P. McKenney The Design of Preemptible Read Copy Update Aug. 7 2007 . Both of the foregoing techniques have several shortcomings to wit 1 expensive atomic operations and memory barriers are required in RCU read side primitives 2 there is no convenient way to determine which tasks block an expedited grace period and 3 there is no convenient way to determine which tasks need priority boosting in order to permit the current grace period to end.

One existing RCU implementation augments the above counter based techniques with a set of lists linking together tasks that blocked while in an RCU read side critical section during a given time period. Tasks that block and then remain in the RCU read side critical section for too long are priority boosted see P. McKenney Priority Boosting RCU Read Side Critical Sections Apr. 16 2007 . This technique also has shortcomings namely 1 because there is no direct connection between grace periods and time periods this approach can boost tasks that do not need to be boosted unnecessarily delaying execution of real time tasks and also can unnecessarily delay boosting tasks that do need to be boosted 2 there is no convenient way to determine which tasks block an expedited grace period and 3 the array of lists consumes considerable memory which can be a problem on embedded platforms.

According to a further existing RCU implementation any task that is preempted while in an RCU read side critical section is given an immediate priority boost see S. Rostedt RFC PATCH RFC Preemption Priority Boosting Oct. 3 2007 . A disadvantage of this approach is that tasks may be priority boosted that do not need it thereby unnecessarily delaying execution of real time tasks.

A still further existing RCU implementation known as hierarchical RCU maintains an array of four blocked reader lists. The first list tracks readers that block neither the current synchronous nor the current asynchronous grace periods the second list tracks readers that block the current synchronous grace period but not the current asynchronous grace period the third list tracks readers that do not block the current synchronous grace period but do block the current asynchronous grace period and the fourth list tracks readers that block both the current synchronous and the current asynchronous grace periods see I. Molnar et al. Linux kernel rcutree.h 2008 lines struct list head blocked tasks field of struct rcu node data structure . A disadvantage of this approach is that four separate lists must be managed. Also there are no lists tracking boosted readers. However commonly owned U.S. Patent Application Publication No. 2011 0055183 discloses that two boost lists respectively indexed to the current and previous asynchronous grace periods may be used in conjunction with blocked reader tracking However combining boost list tracking with the four list blocked reader tracking system of Hierarchical RCU would double the existing four lists to a total of eight lists. This is because each of the existing four lists would have a boost list counterpart to identify blocked readers that have been boosted.

A method system and computer program product are provided for managing read copy update readers that have been preempted while executing in a read copy update read side critical section. Advantageously a single blocked tasks list is used to track preempted reader tasks that are blocking an asynchronous grace period preempted reader tasks that are blocking an expedited grace period and preempted reader tasks that require priority boosting. In an example embodiment a first pointer may be used to segregate the blocked tasks list into preempted reader tasks that are and are not blocking a current asynchronous grace period. A second pointer may be used to segregate the blocked tasks list into preempted reader tasks that are and are not blocking an expedited grace period. A third pointer may be used to segregate the blocked tasks list into preempted reader tasks that do and do not require priority boosting.

In an example embodiment the blocked tasks list may be ordered such that 1 the first pointer references a first preempted reader task on the blocked tasks list that is a newest preempted reader task blocking a current asynchronous grace period and all preempted reader tasks that follow the first preempted reader task are also blocking the current asynchronous grace period 2 the second pointer references a second preempted reader task on the blocked tasks list that is a newest preempted reader task blocking an expedited grace period and all preempted reader tasks that follow the second preempted reader task are also blocking the expedited grace period and 3 the third pointer references a third preempted reader task on the blocked tasks list that is a newest preempted reader task that requires priority boosting and all preempted reader tasks that follow the third preempted reader task also require priority boosting.

In an example embodiment the first preempted reader task the second preempted reader task and the third preempted reader task may either be one and the same task or they may be different tasks. In the example embodiments the blocked tasks list may be further ordered such that all preempted reader tasks that are ahead of the first preempted reader task are blocking a subsequent asynchronous grace period that follows the current asynchronous grace period. In the example embodiments the above described technique may be used in either a uniprocessor computer system or a multiprocessor computer system. In a uniprocessor system the blocked tasks list can be ordered to maintain all preempted reader tasks in strict reverse time order. In a multiprocessor system the blocked tasks list can be ordered to maintain all preempted reader tasks starting from the first preempted reader task in strict reverse time order.

In an example embodiment one or more data structures may be provided that each maintain an instance of the blocked tasks list the first pointer the second pointer and the third pointer one behalf of at least one processor. Each data structure may further maintain a grace period number a quiescent state indicator and a grace period completed indicator on behalf of the least one processor.

Applicant has invented an improvement in RCU grace period detection processing that supports exact determination of which RCU reader tasks that have been preempted during an RCU read side critical section are 1 blocking a current asynchronous grace period 2 blocking a current synchronous expedited grace period or 3 in need of priority boosting. In example embodiments the improvement utilizes a simple small and fast data structure to track such blocked tasks and provides routines that manipulate the fields of this blocked task data structure as each grace period progresses to completion. The improvement has applicability to both uniprocessor and multiprocessor environments with the uniprocessor environment utilizing one blocked task data structure and the multiprocessor environment utilizing plural blocked task data structures that are each assigned to a group of processors.

According to the example embodiments the blocked task data structure utilizes a single doubly linked list of tasks to optimally track blocked readers and their relationships to asynchronous grace periods expedited grace periods and priority boosting. Intelligent list insertion and pointers are used to segregate the blocked task list into 1 tasks that do don t block the current asynchronous grace period 2 tasks that do don t block the current expedited grace period and 3 tasks that do don t require priority boosting. A priority boost routine performs incremental priority boosting given the potential large numbers of tasks that may be in need of boosting thereby avoiding unnecessarily delay of real time tasks.

Normal case low overhead read side processing with occasional special case blocked reader handling is also implemented using techniques evolved from commonly owned U.S. Patent Application Publication No. 2011 0055183 and the existing hierarchical RCU implementation mentioned in the Background section above.

Turning now to the figures wherein like reference numerals represent like elements in all of the several views respectively illustrate example uniprocessor and multiprocessor computing environments in which the grace period processing technique described herein may be implemented. In a uniprocessor computing system includes a single processor a system bus or other interconnection pathway and a program memory . A conventional cache memory and a cache controller are associated with the processor . A conventional memory controller is associated with the memory . As shown the memory controller may reside separately from processor e.g. as part of a chipset . Alternatively the memory controller could be integrated with the processor as is known in the art . In a multiprocessor computing system A includes multiple processors . . . a system bus and a program memory . There are also cache memories . . . and cache controllers . . . respectively associated with the processors . . . . A conventional memory controller is again associated with the memory . As shown the memory controller may reside separately from processors . . . e.g. as part of a chipset . Alternatively the memory controller could be provided by plural memory controller instances respectively integrated with the processors . . . as is known in the art .

In each of the example computing systems and A may represent any of several different types of computing apparatus. Such computing apparatus may include but are not limited to general purpose computers special purpose computers portable computing devices communication and or media player devices set top devices embedded systems to name but a few. In the processor may be implemented as a single core CPU Central Processing Unit device. In the processors . . . may each be a single core CPU device. Alternatively the processors . . . could represent individual cores within a multi core CPU device. Each CPU device embodied by any given processor of is operable to execute program instruction logic under the control of a software program stored in the memory or elsewhere . The memory may comprise any type of tangible storage medium capable of storing data in computer readable form including but not limited to any of various types of random access memory RAM various flavors of programmable read only memory PROM such as flash memory and other types of primary storage. In the processors and the memory may be situated within a single computing device or node. In the processors . . . may be situated within a single computing device or node e.g. as part of a single node SMP system or they may be distributed over plural nodes e.g. as part of a NUMA system a cluster a cloud etc. .

An update operation updater may periodically execute within a process thread or other execution context hereinafter task on any processor of . Each updater runs from program instructions stored in the memory or elsewhere in order to periodically perform updates on a set of shared data that may be stored in the shared memory or elsewhere . illustrates a single updater executing on the lone processor . In reference numerals . . . illustrate individual data updaters that may periodically execute on the several processors . . . . As described in the Background section above the updates performed by an RCU updater can include modifying elements of a linked list inserting new elements into the list deleting elements from the list and other types of operations. To facilitate such updates the processors of are programmed from instructions stored in the memory or elsewhere to implement a read copy update RCU subsystem as part of their processor functions. illustrates a single RCU subsystem executing on the lone processor . In reference numbers . . . represent individual RCU instances that may periodically execute on the several processors . . . . Any given processor in may also periodically execute a read operation reader . Each reader runs from program instructions stored in the memory or elsewhere in order to periodically perform read operations on the set of shared data stored in the shared memory or elsewhere . illustrates a single reader executing on the lone processor . In reference numerals . . . illustrate individual reader instances that may periodically execute on the several processors . . . . Such read operations will typically be performed far more often than updates this being one of the premises underlying the use of read copy update. Moreover it is possible for several of the readers to maintain simultaneous references to one of the shared data elements while an updater updates the same data element. The updaters and the readers are further assumed to be preemptible and the systems and A may for example support real time operations.

During run time an updater will occasionally perform an update to one of the shared data elements . In accordance the philosophy of RCU a first phase update is performed in a manner that temporarily preserves a pre update view of the shared data element for the benefit of readers that may be concurrently referencing the shared data element during the update operation. Following the first phase update the updater may register a callback with the RCU subsystem for the deferred destruction of the pre update view following a grace period second phase update . As described in the Background section above this is known as asynchronous grace period processing. In some cases an updater may perform an update request an expedited grace period and block until the expedited grace period has elapsed. As also mentioned in the Background section an expedited grace period is a form of synchronous grace period processing.

The RCU subsystem handles both asynchronous and synchronous grace periods. Each type of grace period processing entails starting new grace periods and detecting the end of old grace periods so that the RCU subsystem knows when it is safe to free stale data or take other actions . Asynchronous grace period processing further entails the management of callback lists that accumulate callbacks until they are ripe for batch processing at the end of a given grace period. An additional function of the RCU subsystem is to identify and boost the priority of readers that may be holding up the expiration of a grace period. All of the foregoing grace period processing operations may be performed by periodically running the RCU subsystem on the lone processor in or on each of the several processors . . . in . As described in more detail below different components of the RCU subsystem may be variously invoked by an operating system scheduler a scheduling clock interrupt handler in process context and in bottom half context.

Turning now to example components of the RCU subsystem are shown. These components include several RCU subsystem data structures namely an RCU control block an RCU preempt control block and several RCU specific fields in each reader s task structure e.g. a task struct data structure in the Linux kernel . The components of the RCU subsystem also include several RCU subsystem support functions namely an RCU reader API Application Programming Interface an RCU updater API an RCU grace period invocation API and a set of grace period detection and callback processing functions .

The RCU donetail pointer B references the next pointer of the last callback D on the RCU callback list whose asynchronous grace period has completed and is thus ready to be invoked. This portion of the RCU callback list may be referred to as the donelist. The donelist extends from the first callback referenced by the RCU callback list head pointer A to the callback whose next pointer is referenced by the RCU donetail pointer B. In the example illustration of there are two callbacks D on the donelist namely a first callback referenced by the RCU callback list head pointer A and a second callback whose next pointer is referenced by the RCU donetail pointer B. During times when there are no callbacks on the donelist the RCU donetail pointer B may be initialized to point to the RCU callback list head pointer A. The RCU curtail pointer C references the next pointer of the last call back D that is waiting for the current asynchronous grace period to end. This portion of the RCU callback list may be referred to as the curlist. The curlist extends from the first callback following the tail of the donelist pointer B to the callback whose next pointer is referenced by the RCU curtail pointer C. In the example illustration of there is one callback D on the curlist namely the third callback whose next pointer is referenced by the RCU curtail pointer C. During times when there are no callbacks on the curlist the RCU curtail pointer B may be initialized to point to the RCU callback list head pointer A. As further described in connection with there is a third portion of the callback list that follows the curlist. This list portion may be referred to as the nextlist and the next pointer of its tail callback is referenced by a pointer maintained in the RCU preempt control block . Alternatively the next pointer could be maintained in the RCU control block but would be wasteful of memory when compiling for non preemptible uniprocessor RCU which does not need a nextlist . In an example embodiment the RCU control block may be coded in software using the following C programming language declaration 

By segregating the RCU callback list into separate donetail curtail and nexttail portions each list portion can be processed in separate stages in conjunction with separate grace periods. This allows new callbacks to safely accumulate while other callbacks are being processed. For example at the end of a given grace period all callbacks on the donelist will be ready to be invoked. As discussed below the callback handler that actually processes such callbacks could be and usually is executed in a deferred manner such as in softirq context or kthread kernel thread context . It would not be appropriate to process additional callbacks that are registered after a processor quiescent state but before the commencement of deferred callback processing. Such callbacks could for example have been registered from within an interrupt handler that was invoked between the time that the quiescent state occurred and the deferred callback handler started executing. Meanwhile there could be a reader that entered an RCU read side critical section and is now referencing the data associated with one or more of the new callbacks. By placing new callbacks on the curlist and waiting for a subsequent grace period to end the reader can be protected. The additional nextlist is used to handle callbacks that are registered while there are blocked readers preventing the end of the grace period. Note that the grace period does not actually conclude until the blocked readers have resumed execution and completed their RCU read side critical sections. During this time period new callbacks are placed on the nextlist to await the next grace period. The management of callbacks on the donelist curlist and nextlist is further discussed below particularly in connection with which describes an example of how callbacks may be advanced on the RCU callback list and which describes an example of how callbacks may be processed.

The RCU preempt control block is the data structure mentioned in the Introduction section above. It is used to track which readers are 1 blocking a current asynchronous grace period 2 blocking a current synchronous expedited grace period or 3 in need of priority boosting. This data structure also tracks the beginning and end of asynchronous grace periods and notes when processor quiescent states have occurred. Advantageously there is no combinatorial explosion of lists required to track these three categories of readers. As previously stated blocked reader tracking may be performed with a single easy to manage list.

In an example embodiment the RCU preempt control block may be implemented as a data structure comprising nine fields A I. The first field A labeled ctrlblk is a pointer to the RCU control block discussed above. The second field B labeled nexttail is a pointer to the next pointer of the last callback D that must wait for an asynchronous grace period following the current asynchronous grace period i.e. after the next grace period. The callback whose next pointer is pointed to by the RCU nexttail pointer B marks the end of the nextlist portion of the RCU callback list. This is where new callbacks are added by updaters . In the example illustration of there is one callback D on the nextlist namely the fourth callback whose next pointer is referenced by the RCU nexttail pointer B. During times when there are no callbacks on the nextlist the RCU nexttail pointer B may be initialized to point to the RCU callback list head pointer A.

The third field C labeled blkd tasks is the head of a doubly linked blocked tasks list of all readers that are currently blocked within an RCU read side critical section. In an example embodiment the blkd tasks list header C may be implemented as a conventional list head data structure. The fourth field D labeled gp tasks is a pointer to the first element on the blocked tasks list that is preventing the current asynchronous grace period from completing. The fifth field E labeled exp tasks is a pointer to the first element on the blocked tasks list that is preventing the current expedited grace period from completing. The sixth field F labeled boost tasks is a pointer to the first element on the blocked tasks list that needs to be priority boosted.

The seventh field G labeled gpnum indicates the number of the most recently started asynchronous grace period. The eighth field H labeled gpcpu indicates the number of the asynchronous grace period to which the processor has most recently responded. It is effectively a quiescent state indicator that signifies to the RCU subsystem whether a processor quiescent state has been reached in which a context switch occurred. The condition where gpcpu gpnum signifies that the processor has passe through a quiescent state. Note that a processor quiescent state does not necessarily mean that a grace period has ended because one or more readers may have been preempted within their RCU read side critical sections. Instead the processor quiescent state may be thought of as marking the beginning of the end of the current grace period. A multiprocessor alternative to the gpcpu field H is described in more detail below in connection with . The ninth field labeled completed indicates the number of the asynchronous grace period that has most recently completed. The condition where completed gpnum signifies that there is no grace period in progress.

In an example embodiment the RCU preempt control block may be coded in software using the following C programming language declaration 

The RCU READ UNLOCK BLOCKED flag indicates to the RCU subsystem that a reader was preempted within its RCU read side critical section. This flag may be defined to have any suitable value such as 1. The RCU READ UNLOCK NEED QS flag indicates to the RCU subsystem that the reader needs to pass through a quiescent state in order start the completion of an asynchronous grace period so that callbacks may be processed . This flag may be defined to have any suitable value such as 2. The RCU READ UNLOCK BOOSTED flag indicates to the RCU subsystem that the reader needs a priority boost. This flag may be defined to have any suitable value such as 4. 

The third field C labeled rcu node entry may be implemented as a pointer to a conventional list head structure. It is used to enqueue a blocked reader on the blocked tasks list.

In an example embodiment the foregoing fields of the reader task structure may be coded in software using the following C programming language declaration 

Turning now to an example will now be described to illustrate how the RCU preempt control block may be used to track blocked readers in a uniprocessor embodiment. The use of a single blocked tasks list is made feasible by virtue of the fact that an expedited RCU grace period typically forces or simulates a context switch on the processor forcing all in flight RCU read side critical sections to be preempted. Therefore after an expedited RCU grace period has forced or simulated a context switch on the processor any subsequent blocked readers cannot possibly be blocking the current expedited RCU grace period. The single blocked tasks list contains all readers that have blocked within their current RCU read side critical sections and this list can be maintained in strict reverse time order. This strict time order in turn means that if any reader is blocking the current asynchronous grace period all subsequent readers in the blocked tasks list which blocked earlier in time are also blocking the same grace period. Similarly if any reader is blocking the current expedited grace period all subsequent tasks in the blocked tasks list are also blocking the same expedited grace period. Finally if a given reader needs to be boosted so do all the readers that follow this reader in the blocked tasks list. All required state can thus be maintained in the single blocked tasks list with one pointer each for asynchronous grace period processing the gp tasks pointer D expedited grace period processing the exp tasks pointer E and boosting the boost tasks pointer F .

If task T exits its RCU read side critical section it removes itself from the blocked tasks list resulting in the situation shown in . As shown in if a new task T blocks within an RCU read side critical section at this point it is added to the head of the blocked tasks list and the gp tasks pointer D is updated so as to point to the new task. This is due to fact that an end to the current grace period was not previously requested. Such a condition is indicated by the fact that the gpcpu field H is less than the gpnum field G. However the addition of new task T while a grace period is in progress will trigger a request for an end to the current grace period assuming no previous request has been made . This request will in turn result in the gpcpu field H being being set equal to the gpnum field G to acknowledge that the processor has reached a quiescent state and that end of grace period processing is underway. Any subsequent RCU read side critical section will now be deemed to start subsequent to when the current grace period began. Readers that block within such subsequent RCU read side critical sections will not prevent the current grace period from ending. Such tasks will be added to the head of the blocked reader list but the gp tasks pointer D will not be adjusted. An example of this condition is shown in . Here task T has exited its RCU read side critical section and then a new task T blocks while in an RCU read side critical section. Because the gpcpu field H is equal to the gpnum field G the RCU subsystem knows that T s RCU read side critical section started after the beginning of the current grace period. As such there is no need to adjust the gp tasks pointer D to point to task T.

If tasks T and T remain blocked for too long then RCU priority boosting might begin. The first action is to point the boost tasks pointer F at the same task referenced by the gp tasks pointer D as shown in . Then task T is priority boosted and the boost tasks pointer D is advanced to task T as shown in . Because the boost tasks pointer D is moved from one task to the next on the blocked tasks list reader boosting can be carried out incrementally thereby avoiding excessive scheduling latencies. In this particular case it is not possible for a newly blocked task to block the current grace period because the gpcpu field H is equal to the gpnum field G . However if this were possible the new task would be boosted immediately upon blocking Alternatively if the boosting process waits for all processors to pass through a quiescent state before boosting any blocked tasks then it is never possible for a newly blocked task to block the current grace period once boosting has started and thus there is never a need to immediately boost a new task upon blocking. Once task T is priority boosted the data structure layout returns to that shown in except that Tasks T and T are now at a high priority.

In task T has completed its RCU read side critical section removed itself from the blocked tasks list and advanced the gp tasks pointer D to point to task T. Once task T completes its RCU read side critical section it also removes itself from the blocked tasks list. Because task T was at the tail of the blocked tasks list instead of advancing the gp tasks pointer D it sets the pointer to a NULL value. Because task T was the last task blocking the current grace period the grace period ends and the completed field I is set equal to gpnum. This condition is shown in .

In the blocked tasks list comprises task T but then another task T enters an RCU read side critical section. It is further assumed that an updater starts an expedited grace period. This expedited RCU grace period forces a context switch which places task T on the blkd tasks list and then sets the exp tasks pointer E to reference T. This means that both T and T must finish their current RCU read side critical sections before the expedited grace period can be permitted to complete. As shown in if another task T enters an RCU read side critical section and is preempted it will be added to the head of the blocked tasks list. If an asynchronous grace period begins at this point the gp tasks pointer D will be set to reference task T and the gpnum field G will be incremented to reflect the start of the new grace period. This condition is shown in .

Supposing now that task T completes its RCU read side critical section it will removes itself from the blocked tasks list. As shown in the gp tasks pointer D will be advanced to the next task in the list which happens to be task T. Thus both the gp tasks pointer D and the exp tasks pointer E will now reference task T. If task T now completes its RCU read side critical section removing itself from the blocked tasks list both of the gp tasks pointer D and the exp tasks pointer E will be updated to reference the next task in the list namely T. The result is shown in . When task T completes its RCU read side critical section it removes itself from the blocked tasks list. Because there are no more blocked tasks in the list the gp tasks pointer D and exp tasks pointer E are set to NULL. This means that both the asynchronous and expedited synchronous grace periods have completed. The gpcpu field H and the completed field I are set equal to the gpnum field G. The result is shown in .

Turning now to further details of the RCU subsystem support functions briefly introduced above in connection with will now be described. These functions are common to both the uniprocessor embodiment of and the multiprocessor embodiment of . The RCU reader API comprises a reader registration component A and a reader unregistration component B. As described in more detail below the reader registration component A and the reader unregistration component B are respectively invoked by readers as they enter and leave their RCU read side critical sections. These operations allow the RCU subsystem to track reader quiescent states with all processing performed outside of a set of bounded calls to the reader registration unregistration components A B being treated as a quiescent state. The RCU updater API comprises a register callback component A and an expedited grace period component B. The register callback component A is used by updaters to register a callback following a first phase update to a shared data element . A call to the register callback component A initiates processing that places the callback on the RCU callback list managed by the RCU control block see and starts an asynchronous grace period so that the callback can be processed after the grace period has ended as part of second phase update processing to remove stale data or perform other actions . The expedited grace period component B is used by updaters to request an expedited grace period following a first phase update to a shared data element . The updater blocks while the expedited grace period is in progress then performs second phase update processing to free stale data or perform other actions . The RCU grace period API comprises a check callbacks component A. This component may be run periodically e.g. in response to a scheduler clock interrupt in order to check for new callbacks start a new grace period if one is needed and request callback processing.

With continuing reference to the grace period detection and callback processing functions may include a blocked reader handler A a start normal grace period component B a record quiescent state end grace period component C a boost reader component D a read side helper component E and a process callbacks component F. These functions are common to both the uniprocessor embodiment of and the multiprocessor embodiment of . However the multiprocessor embodiment does require certain modifications to the blocked reader handler A as will be discussed in connection with .

As described in more detail in the ensuing paragraphs the blocked reader handler A performs responsive actions when a reader is preempted while in its RCU read side critical section. These actions include adding the preempted reader to the blocked task list extending from the blkd tasks list header C of the RCU preempt control block . The blocked reader handler A also manipulates the rcu read unlock special field B in the reader s task structure . The start normal grace period component B is responsible for starting asynchronous grace periods and performing actions such as manipulating the gp tasks field D and the gpnum field G of the RCU preempt control block . The record quiescent state end grace period component C is responsible for recording quiescent states ending asynchronous grace periods and requesting callback processing. This component manipulates the gpnum field G and the completed field H of the RCU preempt control block and also manipulates the rcu read unlock special field B in the reader s task structure . The boost reader component D is responsible for boosting preempted readers that are delaying the end of a grace period. This component manipulates the boost tasks field F of the RCU preempt control block . It also manipulates the rcu read unlock special field B in the reader s task structure. The read side helper component E is responsible for removing readers from the blocked tasks list. The read side helper also manipulates the gp tasks pointer D the exp tasks pointer E and the boost tasks pointer F of the RCU preempt control block . It also manipulates the rcu read unlock special field B in the reader s task structure. The process callbacks component F causes callbacks to be processed at the end of a grace period. It may be run in softirq context by kthread processing or in any other suitable manner.

Turning now to a reference map is shown to illustrate the operational inter relationships between the various RCU subsystem data structures and support functions . The details of will be discussed in conjunction with the flow diagrams of which respectively illustrate example operations of the RCU subsystem support functions . Unless otherwise noted the operations of the various RCU support functions are described in the context of uniprocessor operation. Specific modifications to the blocked reader handler A for supporting multiprocessor operation will be discussed in connection with below.

The RCU reader registration component A is illustrated at the left of the top row of functional components shown in . It is called by readers each time they enter an RCU read side critical section. In an example embodiment a function name such as rcu read lock may be used when coding the RCU reader registration component A in software. With additional reference now to the sole operation of the RCU reader registration component A is to non atomically increment the rcu read lock nesting field A of the reader s task structure as shown in block . It will be seen that there are no locks atomic instructions memory barriers or disabling of interrupts or preemption. At most a compiler directive may be needed prior to block to prevent a compiler from undertaking code motion optimizations that would move any code following the call to the RCU reader registration component A outside of the RCU read side critical section. The Linux kernel barrier directive is an example.

The RCU reader unregistration component B is illustrated next to the RCU reader registration component A in the top row of functional components shown in . It is called by readers each time they leave an RCU read side critical section. In an example embodiment a function name such as rcu read unlock may be used when coding the RCU reader unregistration component B in software. With additional reference now to the RCU reader unregistration component B implements block in which it non atomically decrements the rcu read lock nesting field A of the reader s task structure that was incremented in block of . In block a compound test is made to determine if the reader has exited its outermost critical section i.e. the rcu read lock nesting field A has decremented to zero and if a flag has been set in the rcu read lock special field B of the reader s task structure . This could be any one of the RCU READ UNLOCK BLOCKED flag the RCU READ UNLOCK NEED QS flag or the RCU READ UNLOCK BOOSTED flag. If the condition checked for in block is present the reader requires special handling due to the reader having been preempted. Processing proceeds to block and the read side helper E is invoked. The operations of the read side helper E are discussed in more detail below in connection with . If it is determined in block that the rcu read lock nesting field A is not zero or if a flag is not set in the rcu read lock special field B the RCU reader registration component B returns. A non zero value of the rcu read lock nesting field A means that the reader is ending a nested RCU read side operation and no further read side action is required other than the decrement of block . The condition wherein no flag is set in the rcu read lock special field B also means that no further read side action is required. It will be seen that there are no locks atomic instructions memory barriers or disabling of interrupts or preemption. At most a compiler directive may be needed prior to block to prevent a compiler from undertaking code motion optimizations that would move any code prior to the call to the RCU reader unregistration component outside of the RCU read side critical section.

The blocked reader handler A is illustrated on the left hand side of immediately below the RCU specific task structure . In an example embodiment a function name such as rcu note context switch may be used when coding the blocked reader handler A in software. This component is called by the context switch code of the operating system scheduler early in the context switch process. With additional reference now to the blocked reader handler A implements block to disable interrupts and then block to check the condition of the outgoing reader . In particular the reader s task structure is checked and a determination is made whether the rcu read lock nesting field A is incremented e.g. greater than zero indicating that the reader is about to be blocked inside an RCU critical section. Block also checks whether the RCU READ UNLOCK BLOCKED flag in the rcu read unlock special field B has not yet been set. If the rcu read lock nesting field A is not incremented or if the READ UNLOCK BLOCKED flag is already set the blocked reader handler A proceeds to block and invokes the record quiescent state end grace period component C to record a quiescent state. On the other hand if the conditions of block are met block sets the reader s READ UNLOCK BLOCKED flag to arrange for the read side helper E to take action when the reader ultimately completes its RCU read side critical section. Block adds the reader to the beginning of the blocked tasks list. In block the RCU preempt control block is checked and a determination is made whether the gpcpu field H equals the gpnum field G indicating that the processor has acknowledged the current grace period and is therefore in a quiescent state . If it has processing proceeds to block and the record quiescent state end grace period component C is invoked in order to end the current grace period. If the processor has not yet acknowledged the current grace period block is implemented and the gp tasks pointer D in the RCU preempt control block is set to reference the reader on the blocked tasks list. Processing then proceeds from block to block so that the record quiescent state end grace period component C can be invoked to record a quiescent state and end the current grace period. Finally block restores interrupts.

The record quiescent state end grace period component C is illustrated on the lower left hand side of . In an example embodiment a function name such as rcu preempt cpu qs may be used when coding the record quiescent state end grace period component C in software. As noted in the paragraph above this component is called by the blocked reader handler A to record processor quiescent states and end grace periods. As described in more detail in subsequent paragraphs below the record quiescent state end grace period component C is also called by the start normal grace period component B the check callbacks component A and the read side helper E. It records a quiescent state for the processor and for the current reader attempts to end the current grace period if it is possible to do so i.e. if there are no blocked readers and then initiates callback processing if there are any eligible callbacks.

With additional reference now to the record quiescent state end grace period component C implements blocks and to record that both the processor and the current reader have acknowledged the current grace period thereby indicating that they have reached a quiescent state . In block the gpcpu field H is set equal to the gpnum field G in the RCU preempt control block to show that the processor has acknowledged the current grace period. In block the RCU READ UNLOCK NEED QS flag is cleared in the reader s task structure to show that the reader has acknowledged the current grace period. Block checks whether there are any tasks referenced by the gp tasks pointer D in the RCU preempt control block . If there are the current grace period cannot be ended and the record quiescent state end grace period component C returns without performing any further processing. If there are no tasks holding up the current grace period block marks the end of the grace period by setting the completed field I equal to the gpnum field G in the RCU preempt control block . Block advances the pending callbacks if any for callback processing setting the donetail pointer B equal to the curtail pointer C in the RCU control block and the setting the curtail pointer C equal to the nexttail pointer B in the RCU preempt control block . In block a check is made whether there are any further blocked readers in the blocked tasks list or any running readers. If not this means that the next grace period the one following the current grace period can also be ended and any callbacks associated with that grace period may also be advanced for callback processing. Block performs the callback advancement by setting the donetail pointer B equal to the RCU nexttail pointer B. Following block or if block determines that the next grace period cannot yet be ended block checks whether there are any callbacks on the donelist that need to be processed. If there are callback processing is initiated in block e.g. by performing actions that invoke the process callbacks component F .

The start normal grace period component B is illustrated on the left hand side of immediately above the record quiescent state end grace period component C. In an example embodiment a function name such as rcu preempt start gp may be used when coding the start normal grace period component B in software. This component is called by the register callback component A when an updater registers a new callback and by the read side helper E when a reader is leaving its outermost RCU read side critical section after having been preempted during the critical section. It is run with interrupts disabled and starts a new asynchronous grace period if one is warranted.

With additional reference now to the start normal grace period component B implements block to determine whether a new grace period should be started. A new grace period will be started only if there is no current grace period in progress and if a new grace period is needed e.g. due to callbacks being present on the curlist . Otherwise the start normal grace period component B returns. If a new grace period is needed block is implemented and the gpnum field G is advanced in the RCU preempt control block to officially start the new grace period. In block a check of the blocked tasks list is made to determine if there are any blocked readers . If there are no blocked readers on the blocked tasks list processing moves to block . If there are blocked readers block sets the gp tasks pointer D in the RCU preempt control block to reference the first task on the list. In block a check is made to determine if there are any readers that are currently running within an RCU read side critical section. This condition may arise if the start normal grace period component B is executed in interrupt context while there is a running reader e.g. due to an interrupt handler executing the register callback component A . If there is a running reader the start normal grace period component B returns. If there are no such readers block implements a call to the record quiescent state end grace period component C to record a quiescent state and end the current grace period.

The check callbacks component A is illustrated on the bottom left hand side of immediately below and to the right of the record quiescent state end grace period component C. In an example embodiment a function name such as rcu preempt check callbacks may be used when coding the check callbacks component A in software. This component is called by the scheduling clock interrupt handler of the operating system and is run with interrupts disabled. It checks for eligible callbacks and invokes callback processing if a grace period has ended. If a grace period is in progress and there is a current reader running on the processor it advises the reader that a quiescent state is needed.

With additional reference now to the check callbacks component A implements block to check whether the current grace period should end. The current grace period will end only if there a current grace period in progress and if no reader is currently running within an RCU read side critical section. If both conditions are satisfied block implements a call to the record quiescent state end grace period component C to record a quiescent state and end the current grace period. Moreover as previously mentioned the record quiescent state end grace period component C advances callbacks on the callback lists. Following block or if the conditions for implementing block were not satisfied block checks whether there are any callbacks from a previously completed grace period that are ripe for processing. This is determined by checking for callbacks on the donelist. If there are such callbacks callback processing is initiated in block e.g. by performing actions that invoke the process callbacks component F . Following callback processing or if block determines that there are no callbacks on the donelist block checks if there is a grace period in progress and if the current task i.e. the one that was interrupted by the scheduling clock interrupt that invoked the check callbacks component A is a reader currently running inside an RCU read side critical section. If both conditions are satisfied the RCU READ UNLOCK NEED QS flag is set in the rcu read unlock special field B of the reader s task structure . As previously mentioned this flag is set in order to advise the RCU subsystem that the reader needs it to pass through a quiescent state before the current grace period can end.

The process callbacks component F is illustrated at the bottom left hand side of immediately below the check callbacks component A. In an example embodiment a function name such as  rcu process callbacks may be used when coding the process callbacks component F in software. As mentioned in the paragraph above this component is invoked when the check callbacks component A detects that there are callbacks on the donelist that require processing. In an example embodiment the process callbacks component F may be invoked in a deferred manner such as in a bottom half context of the operating system. One example would be to run the process callbacks component F as a softirq a tasklet etc. Processing within a kthread may also be used if such functionality is provided by the operating system e.g. as is it in current versions of the Linux kernel . This component runs with interrupts disabled. It identifies callbacks that are ripe for processing on the donelist and curlist portions of the RCU callback list and manipulates the RCU callback list pointer A the donetail pointer B and the curtail pointer C. An additional function which may be named rcu preempt remove callbacks may also be invoked if conditions warrant processing of the nextlist portion of the RCU callback list.

With additional reference now to the process callbacks component A implements block to check for callbacks on the donelist portion of the RCU callback list. If block determines that there are such callbacks block disables interrupts and copies the RCU callback list head pointer A to a temporary local list pointer effectively creating a local callback list. Block cleaves the donelist portion of the RCU callback list from the remainder of the list e.g. by pointing the RCU callback list head pointer A to the start of curlist . Block also NULLs the pointer of the last callback on the donelist such that the local callback list created in block now represents a fully intact isolated donelist that is in proper condition for callback processing. In block a check is made for callbacks on the curlist. If there are none block initializes the RCU curtail pointer C. In block a check is made for callbacks on the nextlist. If there are none block initializes the RCU nexttail pointer B. Block initializes the RCU donetail pointer B. As previously discussed the foregoing initializations may be performed by pointing the RCU curtail pointer C the RCU nexttail pointer B and the RCU donetail pointer B to point to the RCU callback list head pointer A. Block restores interrupts. Block processes the callbacks one the local donelist using a conventional RCU callback processing technique.

The register callback component A is illustrated next to the reader unregistration component B in the top row of functional components shown in . In an example embodiment a function name such as call rcu may be used when coding the register callback A in software. This component is invoked by updaters . Its purpose is to register a callback for subsequent processing following a corresponding grace period by placing them on the RCU callback list. With additional reference now to the register callback component A implements block to initialize the callback including its next pointer . Block disables interrupts. Block enqueues the new callback at the tail of the nextlist portion of the RCU callback list. This may be done by setting the next pointer of the existing callback at the end of nextlist to point to the new callback and by setting the RCU nexttail pointer B in the RCU preempt control block to point to the new callback s next pointer. Following callback registration block restores interrupts.

The expedited grace period component B is illustrated next to the reader register callback component A in the top row of functional components shown in . In an example embodiment a function name such as synchronize rcu expedited may be used when coding the expedited grace period component B in software. This component is invoked by updaters . Its purpose is to force an expedited grace period following an update while the updater blocks on a wait queue. With additional reference now to the expedited grace period component B implements block to execute a barrier instruction and then acquires a mutex lock that prevents other updaters from running this component at the same time. Block checks to see if an expedited grace period is already in progress and exits if there is one. Block disables interrupts and block sets the exp tasks pointer E in the RCU preempt control block to point to the first task on the blocked tasks list. If block finds that there are no blocked tasks the exp task pointer E is set to NULL. If there blocked tasks block restores interrupts block waits for any blocked readers if there are any and block implements a barrier and releases the mutex lock that was acquired in block .

The boost reader component D is illustrated near the middle right hand side of immediately above the RCU control block . In an example embodiment a function name such as start boost may be used when coding the boost reader component D in software. This component may be invoked by the record quiescent state end grace period component C by the expedited grace period component B or by some other component of the RCU subsystem if it is determined that one or more readers are blocked for too long. What constitutes a reader blocking for too long may be judged by various criteria such as the duration of the RCU read side critical section the number of callbacks waiting for the current grace period to complete the amount of memory waiting for the current grace period to complete a combination of the foregoing or based on other criteria. The purpose of the boost reader component D is to boost the priority of such readers so that they can leave their RCU read side critical section and allow a grace period to be completed.

With additional reference now to the boost reader component D implements block to disable interrupts and then block to set the boost tasks pointer F equal to the gp tasks pointer D in the RCU preempt control block . This points the boost tasks pointer F to the first blocked reader on the blocked tasks list that is blocking the current grace period. Blocks represent a loop in which one blocked reader is priority boosted on each pass through the loop. Block causes an exit if there is no blocked reader task. If there is a blocked reader block sets the RCU READ UNLOCK BLOCKED flag in the readers rcu read unlock special task structure field B. Block boosts the reader s priority using any suitable technique to a desired increased priority level the exact value of which is a matter of design choice. Block restores interrupts and block checks if the boosting was provoked by an emergency condition. An example of an emergency condition would be where the system s memory is danger of dropping too low to continue normal operation. The purpose of this check is to prevent large numbers of boosted readers from consuming all available processor time if there is no emergency. If an emergency condition is not detected block causes the boost reader component D to block for a short time period for example by waiting until all tasks that have been boosted to exit their RCU read side critical sections or by waiting for a fixed length of time . Following this blocking period or if an emergency was detected in block block advances the boost tasks pointer F to reference the next reader task on the blocked tasks list. This completes the loop and processing returns to block . The foregoing loop is performed until the end of the blocked tasks list is reached. At that point the No path is taken out of block and interrupts are restored in block .

If desired the boost reader component D may be implemented in alternative ways. For example instead of a loop this function could rely on code in the scheduling clock interrupt handler of the operating system to boost individual readers that are preempted within an RCU read side critical section. The function could also take the precaution of boosting itself to ensure that it is not preempted by the boosted tasks. The function could also boost all blocked tasks not just the ones blocking the current grace period. The function could also record a priority indicator in the RCU preempt control block . This indicator could then be used to immediately boost subsequent readers upon being preempted. The function could also continue boosting tasks until some criterion was met for example some amount of memory being freed by RCU callbacks. The function could also boost the priority of the callback processing code e.g. a softirq thread thus enabling the callbacks to execute despite a looping realtime thread.

The read side helper E is illustrated at the upper portion of below the reader unregistration component B. In an example embodiment a function name such as rcu read unlock special may be used when coding the read side helper E in software. This component is invoked by the reader unregistration component B when a reader is exiting its outermost RCU read side critical section and detects that a flag has been set in its rcu read lock special field B see block of .

With additional reference now to the read side helper E implements block and returns if it was called from within an NMI Non Maskable Interrupt handler. NMI handler code is typically allowed to contain RCU read side critical sections. However NMI handlers cannot be interrupted and thus do not require the services of the read side helper E which deals with reader blocking Being non interruptible NMI handlers should never block within an RCU read side critical section. In block the read side helper component E disables interrupts which prevents scheduling clock interrupt code from running either due to an interrupt or due to preemption . Block checks the rcu read unlock special field B in the reader s task structure and determines whether the RCU READ UNLOCK NEED QS flag is set. If so block invokes the record quiescent state end grace period component C to clear the flag and record a processor quiescent state. Following block or if block found that the RCU READ UNLOCK NEED QS flag is not not processing reaches block . Blocks and cause the read side helper E to restore interrupts and return if it was called from within an interrupt handler. Interrupt handlers cannot block see block discussed below so there is nothing more to do in that case. If the read side helper E is not in an interrupt handler block checks the rcu read unlock special field B in the reader s task structure to determine if the RCU READ UNLOCK BLOCKED flag is set. If it is processing proceeds to block . If not processing proceeds to block of .

Block clears the RCU READ UNLOCK BLOCKED flag thus marking the reader as no longer being blocked within an RCU read sided critical section. Block checks the RCU preempt control block and records whether there are readers blocking an asynchronous grace period and or an expedited grace period. Block removes the reader from the blocked tasks list. Block also checks whether the reader was the first blocked task that was blocking the current asynchronous grace period and or was the first blocked task that was blocking the current expedited grace period and or was the first blocked task being boosted. If so block adjusts one or more of the gp tasks pointer D the exp tasks pointer E and the boost tasks pointer F to point to the next blocked task on the blocked tasks list. If there are no further blocked tasks the pointer s will be set to NULL. Block also initializes the rcu node entry field C in the reader s task structure to reflect the fact that the reader has been removed from the blocked tasks list.

With further reference now to block uses the information recorded in block to determine if the current asynchronous normal grace period was previously blocked by a reader but is no longer blocked. If this is the case block invokes the record quiescent state end grace period component C to record a quiescent state for the processor . Block then invokes the start normal grace period component B to start a new grace period. Block uses the information recorded in block to determine if a current expedited grace period was previously blocked by a reader but is no longer blocked. If this is the case block ends the expedited grace period. Processing advances to block following block or if block determines there are still tasks blocking the current expedited grace period. Block checks the rcu read unlock special field B in the reader s task structure to determine if the RCU READ UNLOCK BOOSTED flag is set. If it is block clears this flag and invokes a reader unboost component not shown to unboost the reader . Following block or if the No path was taken from block block restores interrupts and the read side helper E returns.

Having now described the operations of the various RCU subsystem support functions the discussion returns to the RCU preempt control block that was first mentioned in connection with . As previously stated the RCU preempt control block is intended for use in a uniprocessor implementation of preemptible RCU such as the uniprocessor system of . Multiprocessor implementations such as the multiprocessor system A of require consideration of how multiple processors can access and manipulate the various RCU preempt control block fields in a manner that is synchronized and preferably scalable. A proposed solution is to adopt the hierarchical RCU model used in current versions of the Linux kernel and which has been previously publicized by applicant See P. McKenney Hierarchical RCU Nov. 4 2008 . In hierarchical RCU a hierarchy of rcu node structures beginning from a root rcu node structure and extending to plural leaf rcu node structures is used to track processor quiescent states and other information. This information includes the four task list array described in the Background section above for tracking readers that do don t block a current asynchronous grace period and do don t block an expedited grace period. The present grace period detection technique could be implemented in a multiprocessor system running hierarchical RCU by modifying the rcu node structures. In particular the leaf rcu node structures and the root rcu node structure could be modified to remove the existing four task list array and incorporate a modified RCU preempt control block as shown in . The reason the root rcu node structure may include the RCU preempt control block is to handle tasklist migration in case all processors for a given rcu node structure have gone offline. In that case the blocked tasks list of the rcu node structure could be moved to the root rcu node structure. It will be seen that the multiprocessor RCU preempt control block is similar to its uniprocessor counterpart. Differences include the fact that the control block field A and the RCU nexttail pointer B may be removed as shown by the use of cross hatch shading . With respect to the control block field A hierarchical RCU uses a per processor data structure called rcu data to maintain per processor callback lists. The rcu data structure for each processor includes a pointer that references the processor s designated leaf rcu node structure. Thus instead of the RCU preempt control block maintaining a pointer to an rcu data structure the rcu data structure would maintain a pointer to the rcu node containing the RCU preempt control block . With respect to the nexttail pointer B the rcu data structure in hierarchical RCU maintains the processor s callback list head pointer and an array of tail pointers denoting various callback list portions. Thus a separate nexttail pointer is not needed in the RCU preempt control block . A further difference is that the gpcpu field H is replaced by a qsmask field H. This field is already present in existing rcu node structures. It is a bitmask that contains one bit for each processor and is use to indicate processor quiescent states. Whereas the gpcpu field H indicates whether a single processor has reached a quiescent state the qsmask field H indicates whether each of the assigned processors has reached a quiescent state. In an example embodiment the RCU preempt control block may be synchronized by the same lock that is already used to protect each rcu node structure i.e. rcu node lock as well as by disabling interrupts.

An additional multiprocessor complication arises because the processors e.g. processors . . . of that correspond to a given rcu node structure might become aware of a new grace period at different times. It is therefore possible that a reader whose RCU read side critical section began after the current asynchronous grace period might be enqueued onto the blocked tasks list before some other reader whose RCU read side critical section began before the current RCU grace period. This requires that modifications be made to the blocked reader handler A described above in connection with . For example consider the situation shown in . Here task T has been queued by processor on the blocked tasks list. The act of queuing task T caused processor to respond to the current grace period as indicated by the low order 1 bit in the qsmask field H and to set the gp tasks pointer D to reference task T because it is blocking the current grace period.

Now suppose that processor which uses the same rcu node structure as does processor responds to the current grace period and later runs a task T that blocks within an RCU read side critical section. Because processor already responded to the current grace period T is queued at the head of the blocked tasks list as shown in . It will be seen that the the qsmask field H now has its two least significant bits set one for processor and the other for processor . As is appropriate the gp tasks pointer D has not been changed so that it continues to reference task T. Suppose further that processor which has not yet responded to the current grace period has a task T that blocks within its RCU read side critical section. As shown in processor would place task T at the head of the blocked tasks list set its bit in the qsmask field H and set the gp tasks pointer D to reference task T. However this would incorrectly indicate that task T is blocking the current grace period. The correct operation would have been to insert insert task T before task T and point gp tasks at T resulting in the situation shown in .

To accomplish this a modified blocked reader handler A as shown in may be used for multiprocessor implementations in lieu of the original blocked reader handler A which is for uniprocessor implementations. The multiprocessor blocked reader handler A is similar in many respects to the uniprocessor blocked reader handler A but includes additional logic for determining where to place a newly preempted reader on the blocked tasks list to avoid the misplacement scenario shown in . In operations of the multiprocessor blocked reader handler A that are the same as those of the uniprocessor blocked reader handler A shown in are indicated by the use of corresponding reference numbers appended with a 1 modifier. Newly added operations are represented by blocks A E.

Turning now to the multiprocessor blocked reader handler A implements block to disable interrupts and then block to check the condition of the outgoing reader . In particular the reader s task structure is checked and a determination is made whether the rcu read lock nesting field A is incremented e.g. greater than zero indicating that the reader is about to be blocked inside an RCU critical section and whether the RCU READ UNLOCK BLOCKED flag in the rcu read unlock special field B has not yet been set. If the rcu read lock nesting field A is not incremented or if the READ UNLOCK BLOCKED flag is already set the blocked reader handler A proceeds to block and invokes the record quiescent state end grace period component C to record a quiescent state. On the other hand if the conditions of block are met block sets the reader s READ UNLOCK BLOCKED flag to arrange for the read side helper E to take action when the reader ultimately completes its RCU read side critical section. Block A starts the new set of operations of the multiprocessor blocked reader handler A that are not present in the uniprocessor blocked reader handler A. It checks the gp tasks pointer D to see if there are already readers blocking the current grace period and also compares the gpnum field G to the qsmask field H to see if the current processor has not yet acknowledged a quiescent state. If both conditions are present block B inserts the current reader on the blocked tasks list immediately before the task referenced by the gp tasks pointer D. Block C checks the boost tasks pointer F to determine if boosting is in progress. If so block D invokes priority boosting on behalf of the newly blocked reader using any suitable technique . This is the last of the new set of operations provided by the multiprocessor blocked reader handler A .

Turning now to processing now proceeds to block which is reached by either the No path from block A by the No path from block C or from block D. Block adds the reader to the beginning of the blocked tasks list. In block the RCU preempt control block is checked and a determination is made whether the qsmask field H equals the gpnum field G indicating that the processor has acknowledged the current grace period and is therefore in a quiescent state . If it has processing proceeds to block and the record quiescent state end grace period component C is invoked in order to end the current grace period. If the processor has not yet acknowledged the current grace period block is implemented and the gp tasks pointer D in the RCU preempt control block is set to reference the newly added reader on the blocked tasks list. Processing then proceeds from block to block so that the record quiescent state end grace period component C can be invoked to record a quiescent state and end the current grace period. Finally block restores interrupts.

Note that the multiprocessor implementation described above violates the uniprocessor implementation s strict reverse time ordering of the blocked tasks list. This is acceptable for normal asynchronous grace periods because the blocked tasks list is strictly segregated into tasks that do not block the current grace period at the head of the list and the tasks that are blocking the current grace period at the tail. Any temporal misordering is likely to be limited and will occur only in the head portion of the blocked tasks list in the vicinity of the task referenced by the gp tasks pointer D. Strict reverse time order will be maintained with respect to all tasks extending from the gp tasks pointer reference to the tail of the blocked tasks list. The departure from strict reverse time ordering is likewise acceptable for expedited grace periods because all processors are forced into the operating system scheduler at the beginning of an expedited grace period. Thus later readers cannot be blocking the expedited grace period even if they do block the current asynchronous grace period which might happen if an expedited grace period executes concurrently with initialization for a new asynchronous grace period . The departure from strict reverse time ordering of the blocked tasks list is also acceptable from the standpoint of boosting due to the fact that only those readers blocking the current grace period need boosting and these are all maintained at the tail of the blocked tasks list in strict reverse time order beginning with the task referenced by the gp tasks pointer D. Any readers that block after boosting begins will be boosted immediately upon blocking due to the operation of blocks C and D of . Therefore the limited temporal misordering that occurs at the head of the block tasks list is acceptable for the multiprocessor case.

Accordingly a technique for has been disclosed for effectively managing blocked tasks in preemptible RCU. It will be appreciated that the foregoing concepts may be variously embodied in any of a data processing system a machine implemented method and a computer program product in which programming logic is provided by one or more machine useable storage media for use in controlling a data processing system to perform the required functions. Example embodiments of a data processing system and machine implemented method were previously described in connection with . With respect to a computer program product digitally encoded program instructions may be stored on one or more computer readable data storage media for use in controlling a computer or other digital machine or device to perform the required functions. The program instructions may be embodied as machine language code that is ready for loading and execution by the machine apparatus or the program instructions may comprise a higher level language that can be assembled compiled or interpreted into machine language. Example languages include but are not limited to C C assembly to name but a few. When implemented on a machine comprising a processor the program instructions combine with the processor to provide a particular machine that operates analogously to specific logic circuits which themselves could be used to implement the disclosed subject matter.

Example data storage media for storing such program instructions are shown by reference numerals memory and cache of the uniprocessor system of and the multiprocessor system A of . The systems and A may further include one or more secondary or tertiary storage devices not shown that could store the program instructions between system reboots. A further example of media that may be used to store the program instructions is shown by reference numeral in . The media are illustrated as being portable optical storage disks of the type that are conventionally used for commercial software sales such as compact disk read only memory CD ROM disks compact disk read write CD R W disks and digital versatile disks DVDs . Such media can store the program instructions either alone or in conjunction with an operating system or other software product that incorporates the required functionality. The data storage media could also be provided by portable magnetic storage media such as floppy disks flash memory sticks etc. or magnetic storage media combined with drive systems e.g. disk drives . As is the case with the memory and the cache of the storage media may be incorporated in data processing platforms that have integrated random access memory RAM read only memory ROM or other semiconductor or solid state memory. More broadly the storage media could comprise any electronic magnetic optical infrared semiconductor system or apparatus or device or any other tangible entity representing a machine manufacture or composition of matter that can contain store communicate or transport the program instructions for use by or in connection with an instruction execution system apparatus or device such as a computer. For all of the above forms of storage media when the program instructions are loaded into and executed by an instruction execution system apparatus or device the resultant programmed system apparatus or device becomes a particular machine for practicing embodiments of the method s and system s described herein.

Although various example embodiments have been shown and described it should be apparent that many variations and alternative embodiments could be implemented in accordance with the disclosure. It is understood therefore that the invention is not to be in any way limited except in accordance with the spirit of the appended claims and their equivalents.

