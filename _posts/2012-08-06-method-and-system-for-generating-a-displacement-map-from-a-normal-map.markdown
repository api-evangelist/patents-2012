---

title: Method and system for generating a displacement map from a normal map
abstract: One embodiment of the present invention sets forth a technique for generating a displacement map. The technique involves receiving a normal map which includes one or more normal vectors associated with a texture map, processing the one or more normal vectors to a calculate one or more depth difference vectors associated with the texture map, and generating one or more rays associated with a first texel of the texture map. The technique further involves calculating, for each of the one or more rays, relative depths of each of the one or more other texels traversed by the ray based on each of the depth difference vectors that correspond with the one or more other texels traversed by the ray, determining a displacement value associated with the first texel based on the relative depths calculated for the one or more rays, and storing the displacement value in a displacement map.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09153209&OS=09153209&RS=09153209
owner: NVIDIA Corporation
number: 09153209
owner_city: Santa Clara
owner_country: US
publication_date: 20120806
---
The present invention generally relates to computer graphics and more specifically to a method and system for generating a displacement map from a normal map.

Conventionally graphics processing systems have relied on techniques such as bump mapping to produce realistic lighting effects in computer generated images. In bump mapping the surface normals of a polygon mesh are calculated and stored in a normal map. During rendering the normal map is used to perform lighting calculations which are applied to a lower resolution version of the polygon mesh. In this way geometric details present on the original polygon mesh can be simulated and applied to a lower resolution polygon mesh in order to conserve computational resources. Although bump mapping is capable of simulating the lighting of the original object the underlying geometry of the lower resolution object is unchanged. Consequently bump mapping cannot accurately produce silhouettes occlusion and shadows revealing the coarseness of the object s underlying geometry.

As the processing power of graphics systems increases it has become possible to render images having higher and higher polygon counts. Accordingly current graphics application programming interfaces APIs e.g. DirectX 11 have begun to implement functions that enable more sophisticated control over geometry shaders such as the ability to perform tessellation of incoming graphics primitives. Through tessellation developers have the ability to increase the geometric detail of an object by generating additional graphics primitives and displacing the vertices of those primitives to more realistically reproduce the geometric details of the object. However as discussed above many existing graphic assets were designed to be used with techniques e.g. bump mapping that do not affect object geometries and were not designed or intended to be used with tessellation. Consequently existing graphic assets typically lack the geometric information e.g. depth information needed to generate realistic and detailed object geometries with the additional vertices created during tessellation. Moreover the process of converting existing graphic assets to take advantage of tessellation as well as other sophisticated geometric processing techniques included in current graphics APIs is time consuming and expensive. Thus given the financial risks and uncertain return on investment few developers are willing to expend the resources necessary to update existing graphic assets to include the required geometric information.

Accordingly what is needed in the art is an approach that allows existing graphic assets to be used in conjunction with the functions of more advanced graphics APIs that enable more sophisticated control over object geometries.

One embodiment of the present invention sets forth a method for generating a displacement map. The method involves receiving a normal map which includes one or more normal vectors associated with a texture map processing the one or more normal vectors to a calculate one or more depth difference vectors associated with the texture map and generating one or more rays associated with a first texel of the texture map where each of the one or more rays associated with the first texel traverses one or more other texels of the texture map. The method further involves calculating for each of the one or more rays associated with the first texel relative depths of each of the one or more other texels traversed by the ray based on each of the depth difference vectors that correspond with the one or more other texels traversed by the ray determining a displacement value associated with the first texel based on the relative depths calculated for the one or more rays and storing the displacement value in a displacement map.

Further embodiments provide a non transitory computer readable medium and a computing device to carry out the method set forth above.

One advantage of the disclosed technique is that the normal maps of existing graphic assets can be quickly and inexpensively converted into displacement maps enabling existing graphic assets to be used in systems capable of performing tessellation of incoming geometries and displacing the vertices of the resulting graphic primitives to generate more detailed geometric features.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details.

A switch provides connections between I O bridge and other components such as a network adapter and various add in cards and . Other components not explicitly shown including universal serial bus USB or other port connections compact disc CD drives digital versatile disc DVD drives film recording devices and the like may also be connected to I O bridge . The various communication paths shown in including the specifically named communication paths and may be implemented using any suitable protocols such as PCI Express AGP Accelerated Graphics Port HyperTransport or any other bus or point to point communication protocol s and connections between different devices may use different protocols as is known in the art.

In one embodiment the parallel processing subsystem incorporates circuitry optimized for graphics and video processing including for example video output circuitry and constitutes a graphics processing unit GPU . In another embodiment the parallel processing subsystem incorporates circuitry optimized for general purpose processing while preserving the underlying computational architecture described in greater detail herein. In yet another embodiment the parallel processing subsystem may be integrated with one or more other system elements in a single subsystem such as joining the memory bridge CPU and I O bridge to form a system on chip SoC .

It will be appreciated that the system shown herein is illustrative and that variations and modifications are possible. The connection topology including the number and arrangement of bridges the number of CPUs and the number of parallel processing subsystems may be modified as desired. For instance in some embodiments system memory is connected to CPU directly rather than through a bridge and other devices communicate with system memory via memory bridge and CPU . In other alternative topologies parallel processing subsystem is connected to I O bridge or directly to CPU rather than to memory bridge . In still other embodiments I O bridge and memory bridge might be integrated into a single chip instead of existing as one or more discrete devices. Large embodiments may include two or more CPUs and two or more parallel processing subsystems . The particular components shown herein are optional for instance any number of add in cards or peripheral devices might be supported. In some embodiments switch is eliminated and network adapter and add in cards connect directly to I O bridge .

Referring again to as well as in some embodiments some or all of PPUs in parallel processing subsystem are graphics processors with rendering pipelines that can be configured to perform various operations related to generating pixel data from graphics data supplied by CPU and or system memory via memory bridge and the second communication path interacting with local parallel processing memory which can be used as graphics memory including e.g. a conventional frame buffer to store and update pixel data delivering pixel data to display device and the like. In some embodiments parallel processing subsystem may include one or more PPUs that operate as graphics processors and one or more other PPUs that are used for general purpose computations. The PPUs may be identical or different and each PPU may have a dedicated parallel processing memory device s or no dedicated parallel processing memory device s . One or more PPUs in parallel processing subsystem may output data to display device or each PPU in parallel processing subsystem may output data to one or more display devices .

In operation CPU is the master processor of computer system controlling and coordinating operations of other system components. In particular CPU issues commands that control the operation of PPUs . In some embodiments CPU writes a stream of commands for each PPU to a data structure not explicitly shown in either or that may be located in system memory parallel processing memory or another storage location accessible to both CPU and PPU . A pointer to each data structure is written to a pushbuffer to initiate processing of the stream of commands in the data structure. The PPU reads command streams from one or more pushbuffers and then executes commands asynchronously relative to the operation of CPU . Execution priorities may be specified for each pushbuffer by an application program via the device driver to control scheduling of the different pushbuffers.

Referring back now to as well as each PPU includes an I O input output unit that communicates with the rest of computer system via communication path which connects to memory bridge or in one alternative embodiment directly to CPU . The connection of PPU to the rest of computer system may also be varied. In some embodiments parallel processing subsystem is implemented as an add in card that can be inserted into an expansion slot of computer system . In other embodiments a PPU can be integrated on a single chip with a bus bridge such as memory bridge or I O bridge . In still other embodiments some or all elements of PPU may be integrated on a single chip with CPU .

In one embodiment communication path is a PCI Express link in which dedicated lanes are allocated to each PPU as is known in the art. Other communication paths may also be used. An I O unit generates packets or other signals for transmission on communication path and also receives all incoming packets or other signals from communication path directing the incoming packets to appropriate components of PPU . For example commands related to processing tasks may be directed to a host interface while commands related to memory operations e.g. reading from or writing to parallel processing memory may be directed to a memory crossbar unit . Host interface reads each pushbuffer and outputs the command stream stored in the pushbuffer to a front end .

Each PPU advantageously implements a highly parallel processing architecture. As shown in detail PPU includes a processing cluster array that includes a number C of general processing clusters GPCs where C 1. Each GPC is capable of executing a large number e.g. hundreds or thousands of threads concurrently where each thread is an instance of a program. In various applications different GPCs may be allocated for processing different types of programs or for performing different types of computations. The allocation of GPCs may vary dependent on the workload arising for each type of program or computation.

GPCs receive processing tasks to be executed from a work distribution unit within a task work unit . The work distribution unit receives pointers to processing tasks that are encoded as task metadata TMD and stored in memory. The pointers to TMDs are included in the command stream that is stored as a pushbuffer and received by the front end unit from the host interface . Processing tasks that may be encoded as TMDs include indices of data to be processed as well as state parameters and commands defining how the data is to be processed e.g. what program is to be executed . The task work unit receives tasks from the front end and ensures that GPCs are configured to a valid state before the processing specified by each one of the TMDs is initiated. A priority may be specified for each TMD that is used to schedule execution of the processing task. Optionally the TMD can include a parameter that controls whether the TMD is added to the head or the tail for a list of processing tasks or list of pointers to the processing tasks thereby providing another level of control over priority.

Memory interface includes a number D of partition units that are each directly coupled to a portion of parallel processing memory where D 1. As shown the number of partition units generally equals the number of dynamic random access memory DRAM . In other embodiments the number of partition units may not equal the number of memory devices. Persons of ordinary skill in the art will appreciate that DRAM may be replaced with other suitable storage devices and can be of generally conventional design. A detailed description is therefore omitted. Render targets such as frame buffers or texture maps may be stored across DRAMs allowing partition units to write portions of each render target in parallel to efficiently use the available bandwidth of parallel processing memory .

Any one of GPCs may process data to be written to any of the DRAMs within parallel processing memory . Crossbar unit is configured to route the output of each GPC to the input of any partition unit or to another GPC for further processing. GPCs communicate with memory interface through crossbar unit to read from or write to various external memory devices. In one embodiment crossbar unit has a connection to memory interface to communicate with I O unit as well as a connection to local parallel processing memory thereby enabling the processing cores within the different GPCs to communicate with system memory or other memory that is not local to PPU . In the embodiment shown in crossbar unit is directly connected with I O unit . Crossbar unit may use virtual channels to separate traffic streams between the GPCs and partition units .

Again GPCs can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying laws of physics to determine position velocity and other attributes of objects image rendering operations e.g. tessellation shader vertex shader geometry shader and or pixel shader programs and so on. PPUs may transfer data from system memory and or local parallel processing memories into internal on chip memory process the data and write result data back to system memory and or local parallel processing memories where such data can be accessed by other system components including CPU or another parallel processing subsystem .

A PPU may be provided with any amount of local parallel processing memory including no local memory and may use local memory and system memory in any combination. For instance a PPU can be a graphics processor in a unified memory architecture UMA embodiment. In such embodiments little or no dedicated graphics parallel processing memory would be provided and PPU would use system memory exclusively or almost exclusively. In UMA embodiments a PPU may be integrated into a bridge chip or processor chip or provided as a discrete chip with a high speed link e.g. PCI Express connecting the PPU to system memory via a bridge chip or other communication means.

As noted above any number of PPUs can be included in a parallel processing subsystem . For instance multiple PPUs can be provided on a single add in card or multiple add in cards can be connected to communication path or one or more of PPUs can be integrated into a bridge chip. PPUs in a multi PPU system may be identical to or different from one another. For instance different PPUs might have different numbers of processing cores different amounts of local parallel processing memory and so on. Where multiple PPUs are present those PPUs may be operated in parallel to process data at a higher throughput than is possible with a single PPU . Systems incorporating one or more PPUs may be implemented in a variety of configurations and form factors including desktop laptop or handheld personal computers smart phones servers workstations game consoles embedded systems and the like.

For example as shown in sample point on the normal map corresponds to a texel of a texture map and contains a vector specified as Texel N.x Texel N.y and Texel N.z indicating the orientation of a theoretical surface of the texel. The vector represents the normal vector of the theoretical surface corresponding to the texel. In conventional rendering operations PPU receives one or more primitives e.g. a triangle quad etc. which are processed to generate pixel data for display on display device . The vertices of the primitive include vertex attributes such as position information color information texture coordinate information and the like. Texture coordinates enable PPU to map additional color information stored in the texture map onto the surface of the primitive rather than calculating the color for each pixel of the primitive by interpolating between color attributes stored in the vertices of the primitive. In some rendering algorithms e.g. bump mapping the normal vectors associated with each texel in a texture map are used to perform lighting calculations across a primitive to vary the brightness of each pixel associated with the primitive based on the orientation of the surface with a light source. Although the exemplary normal and displacement maps shown in include sample points on a per texel basis persons skilled in the art will understand that these maps can be configured to include samples having different levels of granularity e.g. texel sub texel etc. . In other words normal and displacement maps may have more than one or less than one sample point for each corresponding texel of the texture map.

Vector information e.g. may be stored in the normal map in any format useful for performing lighting computations. In one embodiment each of the N sample points of normal map includes X Y and Z components specified in a format such as 1 0 1 . In another embodiment the same vector may be specified using 8 bit values such as 0 128 255 . In the latter embodiment each normal vector may be conveniently stored as an RGB color value in a texture map.

During processing of the normal map the CPU may execute the displacement map engine to compute for each texel of the corresponding texture map the change in depth when traversing the texel in a particular direction. More specifically because the texel size is known and because the normal map includes a vector indicating the orientation of a theoretical surface of each texel basic trigonometric functions and vector multiplication can be used to determine the change in depth when traversing the texel in the x direction and the change in depth when traversing the texel in the y direction . These intermediate values shown in may optionally be stored to a depth difference map DDM in system memory or the intermediate values may be computed on the fly. In one embodiment a sample point on the DDM corresponds to a texel of a texture map as well as a sample point on the normal map and contains a two component vector specified as Texel N.DDM x and Texel N.DDM y indicating the rate of change of height across the texel in an x dimension and the rate of change of height across a texel in a y dimension. The DDM may be for example a texture map which stores floating point values e.g. Float2 .

Finally the displacement map engine may generate a displacement map by integrating across one or more rays based on the depth difference vectors e.g stored in the DDM to find a displacement associated with a texel of the texture map. In one embodiment discussed in further detail in conjunction with FIGS. and A C the DDM may be integrated over multiple rays originating from the same texel in a plurality of directions and the integration results may be averaged to compute a relative displacement of the sample point . The computed displacement value corresponding to a particular sample point may be stored in the displacement map in system memory . Thus the displacement map engine is capable of receiving a normal map and generating a displacement map allowing displacement information to be efficiently generated for existing graphic assets. The displacement map engine may be used offline to prepare displacement maps for existing graphic assets or the displacement map engine may be used to generate displacement maps in real time during the execution of graphics software.

The method begins at step where the CPU executes the displacement map engine that receives a normal map from the system memory . The normal map includes a plurality of normal vectors associated with a plurality of texels of a corresponding texture map with each normal vector indicating a surface orientation associated with a particular texel of the texture map. At step the displacement map engine processes the normal map to generate a depth difference map DDM associate with the texture map. As discussed above the DDM may be generated with basic trigonometric functions based on the size of the texel and orientation of the theoretical surface of the texel. The values stored in the DDM may include an X channel indicating the rate of change of height when traversing a texel in an x dimension and a Y channel indicating the rate of change of height when traversing a texel in an y dimension.

Next at step once the DDM has been generated a sample point in the displacement map is selected as shown in . In the current embodiment each sample point of displacement map corresponds to a texel location in the corresponding texture map . However persons skilled in the art will understand that the displacement map can be configured to include samples having any level of granularity e.g. texel sub texel etc. . At step a plurality of J rays associated with the texel are generated. The J rays may share a common starting point within the texel such as a center edge interior or exterior of a texel that corresponds with the sample point of the displacement map . Alternatively the J rays may have one or more different starting points within the texel. Because the normal vectors from which the DDM is computed are inexact values often stored in low precision which do not contain information regarding discontinuities in surface orientation between adjacent texels the displacement value computed for a particular sample point based on these normal vectors may be inaccurate. Consequently to compensate for these inaccuracies displacement values may be computed independently for each texel by uniformly distributing the J rays over 360 degrees and computing an average displacement across multiple texels in multiple directions. For texel locations at or near the edge of the texture map the J rays may distributed using a partial circle i.e. less than 360 degrees .

Any number of rays extending across any number of texels may be generated. In general 500 rays having a radius of approximately 250 texels is sufficient for any given texture. However to conserve computational resources approximately 5 50 rays extending across 10 100 texels may be generated for each texel in a texture map. The embodiment shown provided for illustrative purposes includes ten rays each of which share a common starting point at the center of a texel of a texture map which corresponds with normal map DDM and displacement map . Additionally the rays are relatively evenly distributed over 360 degrees and each ray traverses approximately three to five texels.

At step for each ray in the J rays the displacement map engine integrates over the ray to determine the depth associated with each of the texels traversed by the ray relative to the depth associated with the starting point of the ray . Integration may be performed in any useful coordinate system Cartesian coordinates polar coordinates etc. . As shown in a ray may cross near the middle of a texel or a ray may cross near the edge of a texel. Consequently the degree to which each texel contributes to the computed depth may vary. The contribution of each texel may be computed from Equation 1 as illustrated in where height A is the height relative to the starting point of the ray when entering the texel DDM x is the rate of change of height when traversing a texel in an x dimension DDM y is the change in depth when crossing the texel in the vertical direction dx is the magnitude of the interval over which the ray traverses the texel in the X direction and dy is the magnitude of the interval over which the ray traverses the texel in the Y direction. For example a value of 1.5 for DDM x indicates that when traversing the texel in the horizontal direction the height decreases by 1.5 units across the width of the texel while a value of 0.5 for DDM y indicates that when traversing the texel in the vertical direction the height increases by 0.5 units across the height of the texel. In the example provided in dx has a value of 1.0 and dy has a value of approximately 0.4. Moreover as an additional example were the ray to traverse a texel in a purely vertical direction dx would have a value of 0 and dy would have a value of 1.0. depth depth DDM Eq. 1 

At step the relative depths associated with each of the texels traversed by the J rays are averaged. Additionally weighting values may be assigned to particular texels traversed by the rays . In one example a texel which is traversed by multiple rays e.g. a texel near the starting point may be weighted such that it does not disproportionately contribute to the average relative depth of the texels traversed by the rays. At step a displacement value for the starting texel is determined based on the average depth associated with the texels traversed by the J rays. In order to maintain substantially the same average height of an object onto which the displacement values are to be mapped the displacement values recorded for the texel may be computed by offsetting the sample point by the computed average depth. For instance if an average depth of 3.0 units is calculated for the texels traversed by the J rays a displacement value of 3.0 units may be recorded for the sample point . This zero average depth approach enables object vertices to be displaced without significantly increasing the size the object itself. In other embodiments the displacement value may be determined by further comparing the average depth to the average depth s calculated for nearby texel s and or by applying one or more weighting or smoothing algorithms to the displacement values.

Finally in step the displacement value for the sample point is stored in a displacement map in the system memory . In step the displacement map engine determines whether to calculate displacement values for additional sample points. If there are additional sample points to calculate then method returns to step . However if there are no additional sample points to calculate then method terminates.

Data assembler collects vertex data for high order surfaces primitives and the like and outputs the vertex data including the vertex attributes to vertex processing unit . Vertex processing unit is a programmable execution unit that is configured to execute vertex shader programs lighting and transforming vertex data as specified by the vertex shader programs. For example vertex processing unit may be programmed to transform the vertex data from an object based coordinate representation object space to an alternatively based coordinate system such as world space or normalized device coordinates NDC space. Vertex processing unit may read data that is stored in a GPC cache parallel processing memory or system memory by data assembler for use in processing the vertex data.

Primitive assembler receives vertex attributes from vertex processing unit reading stored vertex attributes as needed and constructs graphics primitives for processing by geometry processing unit . Graphics primitives include triangles line segments points and the like. Geometry processing unit is a programmable execution unit that is configured to execute geometry shader programs transforming graphics primitives received from primitive assembler as specified by the geometry shader programs. For example geometry processing unit may be programmed to perform tessellation of incoming graphics primitives to subdivide the graphics primitives into one or more new graphics primitives. A displacement map e.g. displacement map may then be applied to the vertices of the new graphics primitives generated during tessellation to displace the vertices and increase the geometrical detail and realism of objects within the scene. Additionally the geometry processing unit may be programmed to calculate parameters such as plane equation coefficients that are used to rasterize the new graphics primitives.

In some embodiments geometry processing unit may also add or delete elements in the geometry stream. Geometry processing unit outputs the parameters and vertices specifying new graphics primitives to a viewport scale cull and clip unit . Geometry processing unit may read data that is stored in parallel processing memory or system memory for use in processing the geometry data. Viewport scale cull and clip unit performs clipping culling and viewport scaling and outputs processed graphics primitives to a rasterizer .

Rasterizer scan converts the new graphics primitives and outputs fragments and coverage data to fragment processing unit . Additionally rasterizer may be configured to perform z culling and other z based optimizations.

Fragment processing unit is a programmable execution unit that is configured to execute fragment shader programs transforming fragments received from rasterizer as specified by the fragment shader programs. For example fragment processing unit may be programmed to perform operations such as perspective correction texture mapping shading blending and the like to produce shaded fragments that are output to raster operations unit . Fragment processing unit may read data that is stored in parallel processing memory or system memory for use in processing the fragment data. Fragments may be shaded at pixel sample or other granularity depending on the programmed sampling rate.

Raster operations unit is a processing unit that performs raster operations such as stencil z test blending and the like and outputs pixel data as processed graphics data for storage in graphics memory. The processed graphics data may be stored in graphics memory e.g. parallel processing memory and or system memory for display on display device or for further processing by CPU or parallel processing subsystem . In some embodiments of the present invention raster operations unit is configured to compress z or color data that is written to memory and decompress z or color data that is read from memory.

In sum a displacement map engine converts a normal map into a depth difference map DDM which includes an X channel indicating the change in depth when traversing a texel in a horizontal direction and a Y channel indicating the change in depth when traversing the texel in a vertical direction. The displacement map engine then generates a displacement map from the DDM by integrating across the DDM from each sample position in both angular and radial directions over a selected radius length and a selected range of angles. The resulting displacement values are then used to perform displacement mapping on one or more tessellated surfaces of an object to create more realistic and detailed object geometries.

One advantage of the disclosed technique is that the normal maps of existing graphic assets can be quickly and inexpensively converted into displacement maps enabling existing assets to be used in systems capable of performing tessellation of incoming geometries and displacing the vertices of the resulting graphic primitives to generate more detailed geometric features.

One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored.

The invention has been described above with reference to specific embodiments. Persons of ordinary skill in the art however will understand that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

