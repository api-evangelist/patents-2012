---

title: Integration of a calculation engine with a software component
abstract: Various embodiments of systems and methods for integrating a calculation engine of an in-memory database with a software component are described herein. A control unit schedules and triggers jobs to be processed by an operational unit. The control unit and the operational unit are at an application level. The operational unit divides a job workload corresponding to a job trigger into work packages based on one or more parameters. The work packages are sent to a calculation engine in an in-memory database. At the in-memory database, operations are performed on the work packages and an output is generated. A log in the control unit is updated based on the output.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09058215&OS=09058215&RS=09058215
owner: SAP SE
number: 09058215
owner_city: Walldorf
owner_country: DE
publication_date: 20121019
---
Traditional database management systems rely on disk storage and have limited main memory. The main memory is accessible by a central processing unit CPU and input output operations are performed between the disk and the main memory. These disk input output operations are a performance bottleneck. An in memory database overcomes this bottleneck. In an in memory database entire data relevant to a processing activity is stored in the main memory. Therefore read operations can be executed without disk input output operations thereby enhancing performance. Any disk writing operations can happen asynchronously in the background without affecting CPU performance.

In memory databases process large amounts of data in very short time. Typically one or more software components are involved in a processing activity. Such software components can be stored external to the in memory database. As an example an external software component can be part of an existing data management system. Several situations require integration of an external software component and a process or a component of an in memory database.

Embodiments of techniques for integration of a calculation engine with a software component are described herein. In the following description numerous specific details are set forth to provide a thorough understanding of the embodiments. One skilled in the relevant art will recognize however that the embodiments can be practiced without one or more of the specific details or with other methods components materials etc. In other instances well known structures materials or operations are not shown or described in detail.

Reference throughout this specification to one embodiment this embodiment and similar phrases means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one of the one or more embodiments. Thus the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more embodiments.

Referring to an in memory database can be hosted on one or more machines. A host machine includes one or more central processing units main memory network etc. A central processing unit CPU can include a plurality of cores which enable faster processing. Increased number of cores in the CPUs and other similar technological advancements in main memory and processing hardware enable processing of large amounts of data in a short time frame. In an in memory database the capacity of the main memory enables storing of entire data required for a processing activity also called as active data in the main memory itself. Compared to lower and slower memory hierarchy options e.g. as in disk this data in the main memory can be read during processing activity without disk input output operations. Coupled with the multiple cores in CPU and use of data in the main memory processing times are drastically improved.

Several software components deal with large amounts of data in the order of terabytes petabytes or even more. This data is typically stored in a disk based storage system . Examples of such software components include enterprise resource planning ERP components and business intelligence BI application components. A retail software component for example can deal with point of sale and multi channel sales data of many physical and online stores in a country. Similarly inventory data at several warehouse locations can be managed by an inventory management component. An in memory database can be used to store and analyze such large amounts of data. Data from the disk storage also known as cold storage is extracted into the main memory of the in memory database. The in memory database includes one or more calculation engines to analyze the extracted data. Proper integration of the software component and the calculation engine of the in memory database provides several benefits.

The point of sale data can be analyzed to obtain insights such as when a particular product would be out of shelf at a particular store. Accordingly a potential out of shelf situation can be avoided. As another example point of sale data can also be used to estimate which products have stronger sales price sensitivities in different areas etc. Point of sale data can be analyzed using appropriate calculations. First the point of sale data stored in a retail system is extracted into the in memory database . The in memory database includes a calculation engine that performs operations on the point of sale data. In one embodiment the calculation engine runs on shelf availability calculations on the point of sale data to estimate out of shelf situations for products. An example of the on shelf availability calculation is explained in reference to .

The framework includes a user interface component . The user interface component provides one or more user interfaces that provide various options to configure execution and behavior of the framework. Various configuration parameters can be provided via the user interfaces. In one embodiment the user interface component includes an engine job scheduler module . An authorized user can select or provide a job scheduling option via the user interfaces related to the engine job scheduler module . For example execution time of the calculation engine can be scheduled using these user interfaces. Also user interfaces of the engine job scheduler module can be used to monitor the performance of the calculation engine in the in memory database . For example a monitoring user interface of the engine job scheduler module can be used to view errors warnings or any similar system messages that are generated during the runtime.

In one embodiment the user interface component also includes a customization module for configuring and customizing the calculation engine . The customization module provides one or more user interfaces to support configuration and customizing of various parameters. The parameters can include application parameters and engine parameters. The application parameters are related to triggers of the calculation engine in the context of on shelf availability calculations an example of an application parameter is a probability threshold parameter for triggering the calculation engine. Engine parameters can be used to adjust the behavior of the calculation engine . For example engine parameters can be used to influence the input and the output of the calculation engine . Other examples of customization parameters include parallel processing parameters such as maximum number of requests for a resource outlier tolerances level of granularity confidence threshold levels etc.

The framework includes an application level component . The application level component is part of the software component and includes a control unit and an operational unit . The control unit triggers jobs to be processed by the operational unit . The control unit is responsible for commanding the right sequence of jobs which depends on the current control state the current operation state and any external input such as log data and customization data. The operational unit is responsible for input and output operations to the calculation engine . The operational unit receives input from the control unit . In one embodiment the application level component also includes a customization unit . As mentioned previously authorized users provide configuration parameters via the user interfaces. The customization unit receives and stores these configuration parameters. The stored configuration parameters are used by the control unit and operational unit during the execution time of the calculation engine .

In one embodiment the customization unit includes an engine parameters module and a user settings module . The engine parameters module receives engine parameters from the authorized users through the user interface component and stores the configuration parameters. The user settings module receives application parameters from the authorized users through the user interface component and stores the application parameters. In one embodiment a middleware platform can be used to integrate the application level component and the calculation engine . This middleware can be an application server middleware that is capable of integrating applications and data sources.

The point of sale data includes sale data such as the type of product sold and the location of sale. For example if a product P is sold at store data of this sale is collected by the point of sale data management component. This point of sale data implies that product P is sold at store . This point of sale of sale data from various stores is then sent to a backend ERP system or a retail system of the company. This data can be stored in a disk based storage system associated with the retail system. In one embodiment the point of sale of sale data is sent directly to an in memory database. Entire point of sale data may not be needed for analysis. The control unit in combination with customization settings may specify what part of the point of sale data needs to be analyzed. For example the point of sale data for the current month can be selected for analysis and forms the job workload.

Referring back to at the application level component the job workload is divided into a plurality of work packages at based on one or more parameters. The operational unit divides the workload into work packages based on the job trigger received from the engine dispatcher module . Depending on the field of application these parameters can vary. In the context of point of sale data the workload can be divided based on store location parameter. In another embodiment the workload can be divided based any combinations of store locations and product categories. Therefore a work package includes point of sale data of one or more stores. In one embodiment the workload is divided into work packages using Advanced Business Application Programming ABAP based parallel processing. Parallel processing can be implemented using a function module and appropriate variant of asynchonous remote function calls RFC . As an example the variant CALL FUNCTION STARTING NEW TASK DESTINATION IN GROUP is used for parallel processing.

The work packages are then sent to the in memory database . In one embodiment at the in memory database level each work package is divided into a plurality of parallel processes at . This division can be based on one or more parameters which can vary depending on field of application. For example in the context of point of sale data when a work package includes point of sale data of a store the work package can be divided based on product category parameter. For example a first parallel process can contain point of sale data of a first group of products from the store and a second parallel process can contain point of sale data of a second group of products from the store. As another example if a work package covers point of sale data of multiple stores the work package can be divided by refining the store location parameter and product category parameter. In one embodiment the work packages are divided such that each parallel process i.e. divided work package and includes point of sale data of equal number of products.

In one embodiment Structure Query Language SQL partitioning technique is used to divide each work package into parallel processes and . SQL declarative logic can be used to divide the work packages into parallel processes and . Declarative logic can be used for efficient execution of data intensive computations. Declarative logic can be represented as data flows which can be executed in parallel. Operations in a dataflow graph have to be free of side effects. This means they should not change any global state either in the database or in the application. Procedure call approach can be used to parallelize SQL statements. For example a procedure or table function can be called within the body of a procedure. The input of a procedure is split into multiple smaller data sets. The same procedure is called for these smaller data sets. Since data of each parallel process and is distinct the calls can be parallelized. A separate call is used for each parallel process and . Since data of each parallel process and is distinct data used by each call is also distinct. Therefore the calls can be parallelized.

Each parallel process and is then processed by the calculation engine . Operations are performed on each parallel process and and an output is generated for each parallel process and . Following which the outputs are merged at . In the context of point of sale data the calculation engine performs on shelf availability calculations. On shelf availability calculations are performed on each parallel process by the calculation engine . The on shelf availability calculations use the sales transactions for a given location product and analyzes each sales interval to determine if the sales interval is unusually long indicating a potential out of shelf situation. A sales interval is the time between two subsequent sales transactions of a product at a particular store location. In one embodiment the on shelf availability calculations output the probability of a product being out of shelf during a sales interval.

On shelf availability calculations are explained in reference to . Data such as sales history prediction history product hierarchy and public holidays are used for the on shelf availability calculations. The out of shelf detection includes three processing steps namely pattern analysis estimation and monitoring . The pattern analysis step creates linear scales which are models for the regular intra week and intra day sales fluctuations of a single product or category. The pattern analysis calculations may be executed at regular intervals e.g. once every week and the results are used by the estimation step. The estimation step estimates the model parameters for base estimation trend and the demand influencing factors. The estimation step can be executed daily. The monitoring step applies the estimated model to either the past sales transaction or the last sales transaction. When the estimated model is applied to the last sales transaction products that are probably out of shelf currently are identified. When the estimated model is applied to the past sales transaction previous out of shelf situations are searched. The monitoring step can be performed daily or as often as necessary.

Referring back to the results or output of the on shelf availability calculations on each parallel process are merged at . The merged results are then persisted at . In one embodiment the results are persisted in the in memory database . In addition to the output of the calculation engine configuration data master data and intermediate data during on shelf availability calculations can also be persisted in the in memory database . Each type of data can be stored in a respective table or a set of tables. A log in the control unit is updated at after the merged results are persisted. Following which the process flow in the control unit can move to job triggers depending on the scheduling configurations. The log can be used to monitor job statuses and any engine exceptions.

In one embodiment the work packages are not divided into parallel processes at the in memory database . In such case the work packages are directly processed by the calculation engine . The calculation engine generates an output for each work package. These outputs are merged and persisted and the log in the control unit is then updated. In one embodiment the work packages are divided into parallel processes only for some job workloads. The decision whether to divide the work packages into parallel processes can be based on the size of the workload and available computing resources.

Referring to if there is a probable out of shelf situation then an alert can be generated and sent to an end user. A mobile application can be developed to provide out of shelf alerts. The end user can install this mobile application on a mobile computing device such as a phone or a tablet computer. An out of shelf alert can be sent to the end user s mobile device via the mobile application .

The above described framework and method integrates a software component with a calculation engine in an in memory database. Such integration provides a means to monitor the performance of the calculation engine schedule jobs for the calculation engine and make any adjustments to the behavior of the calculation engine. Log data from output of the calculation engine cart be used for several applications. Also parallelization of workload enables efficient use of computing resources.

Some embodiments may include the above described methods being written as one or more software components. These components and the functionality associated with each may be used by client server distributed or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as functional declarative procedural object oriented lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively the components maybe implemented in server and client applications. Further these components may be linked together via various distributed programming protocols. Some example embodiments may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level e.g. a graphical user interface . These first and second computer systems can be configured in a server client peer to peer or some other configuration. The clients can vary in complexity from mobile and handheld devices to thin clients and on to thick clients or even other servers.

The above illustrated software components are tangibly stored on a computer readable storage medium as instructions. The term computer readable storage medium should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term computer readable storage medium should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store encode or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described represented or illustrated herein. Examples of computer readable storage media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROMs DVDs and holographic devices magneto optical media and hardware devices that are specially configured to store and execute such as application specific integrated circuits ASICs programmable logic devices PLDs and ROM and RAM devices. Examples of computer readable instructions include machine code such as produced by a compiler and files containing higher level code that are executed by a computer using an interpreter. For example an embodiment may be implemented using Java C or other object oriented programming language and development tools. Another embodiment may be implemented in hard wired circuitry in place of or in combination with machine readable software instructions.

A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases such as relational transactional hierarchical multi dimensional e.g. OLAP object oriented databases and the like. Further data sources include tabular data e.g. spreadsheets delimited text files data tagged with a markup language e.g. MOIL data transactional data unstructured data e.g. text files screen scrapings hierarchical data e.g. data in a file system XML data files a plurality of reports and any other data source accessible through an established protocol such as Open DataBase Connectivity ODBC produced by an underlying software system e.g. ERP system and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams broadcast data and the like. These data sources can include associated data foundations semantic layers management systems security systems and so on.

In the above description numerous specific details are set forth to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize however that the embodiments can be practiced without one or more of the specific details or with other methods components techniques etc. In other instances well known operations or structures are not shown or described in detail.

Although the processes illustrated and described herein include series of steps it will be appreciated that the different embodiments are not limited by the illustrated ordering of steps as some steps may occur in different orders some concurrently with other steps apart from that shown and described herein. In addition not all illustrated steps may be required to implement a methodology in accordance with the one or more embodiments. Moreover it will be appreciated that the processes may be implemented in association with the apparatus and systems illustrated and described herein as well as in association with other systems not illustrated.

The above descriptions and illustrations of embodiments including what is described in the Abstract is not intended to be exhaustive or to limit the one or more embodiments to the precise forms disclosed. While specific embodiments of and examples for the one or more embodiments are described herein for illustrative purposes various equivalent modifications are possible within the scope as those skilled in the relevant art will recognize. These modifications can be made in light of the above detailed description. Rather the scope is to be determined by the following claims which are to be interpreted in accordance with established doctrines of claim construction.

