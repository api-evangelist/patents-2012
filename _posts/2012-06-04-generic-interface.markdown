---

title: Generic interface
abstract: A system and process for ensuring the smooth flow of electronic ink is described. Ink-stroke information associated with one or more data packets is received, and it is determined that the ink-stroke information comprises a gesture indication. The gesture indication is communicated to an ink collection object which causes the ink collection object to delete the ink stroke information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08400665&OS=08400665&RS=08400665
owner: Microsoft Corporation
number: 08400665
owner_city: Redmond
owner_country: US
publication_date: 20120604
---
This application is a Continuation of U.S. application Ser. No. 13 112 806 filed on May 20 2011 entitled Generic Interface which is a Divisional of U.S. application Ser. No. 11 681 535 filed on Mar. 2 2007 now U.S. Pat. No. 7 973 957 issued Jul. 5 2011 entitled Generic Interface which is a Continuation of U.S. application Ser. No. 10 986 779 filed Nov. 15 2004 now U.S. Pat. No. 7 199 885 issued Apr. 3 2007 entitled Generic Interface which is a continuation of U.S. application Ser. No. 10 879 527 filed Jun. 30 2004 now U.S. Pat. No. 7 436 535 issued Oct. 14 2008 entitled Real Time Inking which is a non provisional of U.S. Provisional No. 60 513 591 filed Oct. 24 2003 entitled Tablet Platform Controls and APIs. Each of these applications is incorporated herein by reference in its entirety.

Aspects of the present invention relate to image processing and information manipulation. More specifically aspects of the present invention relate to receiving and handling electronic ink information.

Typical computer systems especially computer systems using graphical user interface GUI systems such as Microsoft WINDOWS are optimized for accepting user input from one or more discrete input devices such as a keyboard for entering text and a pointing device such as a mouse with one or more buttons for driving the user interface. The ubiquitous keyboard and mouse interface provides for fast creation and modification of documents spreadsheets database fields drawings photos and the like. However there is a significant gap in the flexibility provided by the keyboard and mouse interface as compared with the non computer i.e. standard pen and paper. With the standard pen and paper a user edits a document writes notes in a margin and draws pictures and other shapes and the like. In some instances a user may prefer to use a pen to mark up a document rather than review the document on screen because of the ability to freely make notes outside of the confines of the keyboard and mouse interface.

When a user writes with a pen he expects ink to flow from the pen tip. In the electronic ink realm a similar goal exists. One issue that impedes electronic ink from flowing from a pen or stylus is how the electronic ink is handled.

Previous approaches have attempted to handle all aspects of inking at the same time. Once ink information exists previous approaches have attempted to render the ink look for gestures combine the ink information with other ink information recognize the ink and smooth the appearance of the ink among other processes. These processes have caused delays in displaying ink to a user thereby making the user wait to enter more ink and more importantly reduce or eliminate the illusion that ink is flowing from the tip of the electronic stylus.

Aspects of the present invention address one or more of the issues mentioned above thereby providing flow of ink from a stylus. A dynamic render object may be moved about in a process flow to reduce a delay between a user s movement and the display of electronic ink.

Aspects of the present invention relate to handing stylus events in an efficient manner to quickly render electronic ink to a user.

This document is divided into sections to assist the reader. These sections include characteristics of ink terms general purpose computing environment real time inking overview object model dynamic rendering and wet ink gesture recognition synchronous and asynchronous processes cascading dynamic plug in collection modification error propagation managed unmanaged illustrations data sets and flows data synchronization and application programming interfaces.

As known to users who use ink pens physical ink the kind laid down on paper using a pen with an ink reservoir may convey more information than a series of coordinates connected by line segments. For example physical ink can reflect pen pressure by the thickness of the ink pen angle by the shape of the line or curve segments and the behavior of the ink around discreet points and the speed of the nib of the pen by the straightness line width and line width changes over the course of a line or curve . Further examples include the way ink is absorbed into the fibers of paper or other surface it is deposited on. These subtle characteristics also aid in conveying the above listed properties. Because of these additional properties emotion personality emphasis and so forth can be more instantaneously conveyed than with uniform line width between points.

Electronic ink or ink relates to the capture and display of electronic information captured when a user uses a stylus based input device. Electronic ink refers to a sequence or any arbitrary collection of strokes where each stroke is comprised of a sequence of points. The strokes may have been drawn or collected at the same time or may have been drawn or collected at independent times and locations and for independent reasons. The points may be represented using a variety of known techniques including Cartesian coordinates X Y polar coordinates r and other techniques as known in the art. Electronic ink may include representations of properties of real ink including pressure angle speed color stylus size and ink opacity. Electronic ink may further include other properties including the order of how ink was deposited on a page a raster pattern of left to right then down for most western languages a timestamp indicating when the ink was deposited indication of the author of the ink and the originating device at least one of an identification of a machine upon which the ink was drawn or an identification of the pen used to deposit the ink among other information.

The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the invention include but are not limited to personal computers server computers hand held or laptop devices including smart phones smart watches and personal data assistants multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The invention may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to random access memory RAM read only memory ROM electronically erasable programmable read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as ROM and RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disc drive that reads from or writes to a removable nonvolatile optical disc such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disc drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a digital camera a keyboard and pointing device commonly referred to as a mouse trackball or touch pad. Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers can be used. The existence of any of various well known protocols such as TCP IP Ethernet FTP HTTP and the like is presumed and the system can be operated in a client server configuration to permit a user to retrieve web pages from a web based server. Any of various conventional web browsers can be used to display and manipulate data on web pages.

A programming interface or more simply interface may be viewed as any mechanism process protocol for enabling one or more segment s of code to communicate with or access the functionality provided by one or more other segment s of code. Alternatively a programming interface may be viewed as one or more mechanism s method s function call s module s object s etc. of a component of a system capable of communicative coupling to one or more mechanism s method s function call s module s etc. of other component s . The term segment of code in the preceding sentence is intended to include one or more instructions or lines of code and includes e.g. code modules objects subroutines functions and so on regardless of the terminology applied or whether the code segments are separately compiled or whether the code segments are provided as source intermediate or object code whether the code segments are utilized in a runtime system or process or whether they are located on the same or different machines or distributed across multiple machines or whether the functionality represented by the segments of code are implemented wholly in software wholly in hardware or a combination of hardware and software.

Notionally a programming interface may be viewed generically as shown in or . illustrates an interface Interface as a conduit through which first and second code segments communicate. illustrates an interface as comprising interface objects I and I which may or may not be part of the first and second code segments which enable first and second code segments of a system to communicate via medium M. In the view of one may consider interface objects I and I as separate interfaces of the same system and one may also consider that objects I and I plus medium M comprise the interface. Although show bidirectional flow and interfaces on each side of the flow certain implementations may only have information flow in one direction or no information flow as described below or may only have an interface object on one side. By way of example and not limitation terms such as application programming interface API entry point method function subroutine remote procedure call and component object model COM interface are encompassed within the definition of programming interface.

Aspects of such a programming interface may include the method whereby the first code segment transmits information where information is used in its broadest sense and includes data commands requests etc. to the second code segment the method whereby the second code segment receives the information and the structure sequence syntax organization schema timing and content of the information. In this regard the underlying transport medium itself may be unimportant to the operation of the interface whether the medium be wired or wireless or a combination of both as long as the information is transported in the manner defined by the interface. In certain situations information may not be passed in one or both directions in the conventional sense as the information transfer may be either via another mechanism e.g. information placed in a buffer file etc. separate from information flow between the code segments or non existent as when one code segment simply accesses functionality performed by a second code segment. Any or all of these aspects may be important in a given situation e.g. depending on whether the code segments are part of a system in a loosely coupled or tightly coupled configuration and so this list should be considered illustrative and non limiting.

This notion of a programming interface is known to those skilled in the art and is clear from the foregoing detailed description of the invention. There are however other ways to implement a programming interface and unless expressly excluded these too are intended to be encompassed by the claims set forth at the end of this specification. Such other ways may appear to be more sophisticated or complex than the simplistic view of but they nonetheless perform a similar function to accomplish the same overall result. We will now briefly describe some illustrative alternative implementations of a programming interface.

A communication from one code segment to another may be accomplished indirectly by breaking the communication into multiple discrete communications. This is depicted schematically in . As shown some interfaces can be described in terms of divisible sets of functionality. Thus the interface functionality of may be factored to achieve the same result just as one may mathematically provide 24 or 2 times 2 times 3 times 2. Accordingly as illustrated in the function provided by interface Interface may be subdivided to convert the communications of the interface into multiple interfaces Interface A Interface B Interface C etc. while achieving the same result. As illustrated in the function provided by interface I may be subdivided into multiple interfaces IIIetc. while achieving the same result. Similarly interface I of the second code segment which receives information from the first code segment may be factored into multiple interfaces IIIetc. When factoring the number of interfaces included with the 1st code segment need not match the number of interfaces included with the 2nd code segment. In either of the cases of the functional spirit of interfaces Interface and I remain the same as with respectively. The factoring of interfaces may also follow associative commutative and other mathematical properties such that the factoring may be difficult to recognize. For instance ordering of operations may be unimportant and consequently a function carried out by an interface may be carried out well in advance of reaching the interface by another piece of code or interface or performed by a separate component of the system. Moreover one of ordinary skill in the programming arts can appreciate that there are a variety of ways of making different function calls that achieve the same result.

In some cases it may be possible to ignore add or redefine certain aspects e.g. parameters of a programming interface while still accomplishing the intended result. This is illustrated in . For example assume interface interface of includes a function call Square input precision output a call that includes three parameters input precision and output and which is issued from the 1st Code Segment to the 2nd Code Segment. If the middle parameter precision is of no concern in a given scenario as shown in it could just as well be ignored or even replaced with a meaningless in this situation parameter. One may also add an additional parameter of no concern. In either event the functionality of square can be achieved so long as output is returned after input is squared by the second code segment. Precision may very well be a meaningful parameter to some downstream or other portion of the computing system however once it is recognized that precision is not necessary for the narrow purpose of calculating the square it may be replaced or ignored. For example instead of passing a valid precision value a meaningless value such as a birth date could be passed without adversely affecting the result. Similarly as shown in interface I is replaced by interface I redefined to ignore or add parameters to the interface. Interface I may similarly be redefined as interface I redefined to ignore unnecessary parameters or parameters that may be processed elsewhere. The point here is that in some cases a programming interface may include aspects such as parameters which are not needed for some purpose and so they may be ignored or redefined or processed elsewhere for other purposes.

It may also be feasible to merge some or all of the functionality of two separate code modules such that the interface between them changes form. For example the functionality of may be converted to the functionality of and I respectively. In the previous 1st and 2nd Code Segments of are merged into a module containing both of them. In this case the code segments may still be communicating with each other but the interface may be adapted to a form which is more suitable to the single module. Thus for example formal Call and Return statements may no longer be necessary but similar processing or response s pursuant to interface Interface may still be in effect. Similarly shown in part or all of interface I from may be written inline into interface I to form interface I . As illustrated interface I is divided into Iand Iand interface portion Ihas been coded in line with interface I to form interface I . For a concrete example consider that the interface I from performs a function call square input output which is received by interface I which after processing the value passed with input to calculate the square of an input by the second code segment passes back the squared result with output. In such a case the processing performed by the second code segment squaring input can be performed by the first code segment without a call to the interface.

A communication from one code segment to another may be accomplished indirectly by breaking the communication into multiple discrete communications. This is depicted schematically in . As shown in one or more piece s of code Divorce Interface s since they divorce functionality and or interface functions from the original interface are provided to convert the communications on the first interface Interface to conform them to a different interface in this case interfaces Interface A Interface B and Interface C. This might be done e.g. where there is an installed base of applications designed to communicate with say an operating system in accordance with an Interface protocol but then the operating system is changed to use a different interface in this case interfaces Interface A Interface B and Interface C. The point is that the original interface used by the 2nd Code Segment is changed such that it is no longer compatible with the interface used by the 1st Code Segment and so an intermediary is used to make the old and new interfaces compatible. Similarly as shown in a third code segment can be introduced with divorce interface DI to receive the communications from interface I and with divorce interface DI to transmit the interface functionality to for example interfaces Iand Iredesigned to work with DI but to provide the same functional result. Similarly DI and DI may work together to translate the functionality of interfaces I and I of to a new operating system while providing the same or similar functional result.

Yet another possible variant is to dynamically rewrite the code to replace the interface functionality with something else but which achieves the same overall result. For example there may be a system in which a code segment presented in an intermediate language e.g. Microsoft IL Java ByteCode etc. is provided to a Just in Time JIT compiler or interpreter in an execution environment such as that provided by the .Net framework the Java runtime environment or other similar runtime type environments . The JIT compiler may be written so as to dynamically convert the communications from the 1st Code Segment to the 2nd Code Segment i.e. to conform them to a different interface as may be required by the 2nd Code Segment either the original or a different 2nd Code Segment . This is depicted in . As can be seen in this approach is similar to the Divorce scenario described above. It might be done e.g. where an installed base of applications are designed to communicate with an operating system in accordance with an Interface protocol but then the operating system is changed to use a different interface. The JIT Compiler could be used to conform the communications on the fly from the installed base applications to the new interface of the operating system. As depicted in this approach of dynamically rewriting the interface s may be applied to dynamically factor or otherwise alter the interface s as well.

It is also noted that the above described scenarios for achieving the same or similar result as an interface via alternative embodiments may also be combined in various ways serially and or in parallel or with other intervening code. Thus the alternative embodiments presented above are not mutually exclusive and may be mixed matched and combined to produce the same or equivalent scenarios to the generic scenarios presented in . It is also noted that as with most programming constructs there are other similar ways of achieving the same or similar functionality of an interface which may not be described herein but nonetheless are represented by the spirit and scope of the invention i.e. it is noted that it is at least partly the functionality represented by and the advantageous results enabled by an interface that underlie the value of an interface.

The stylus may be equipped with one or more buttons or other features to augment its selection capabilities. In one embodiment the stylus could be implemented as a pencil or pen in which one end constitutes a writing portion and the other end constitutes an eraser end and which when moved across the display indicates portions of the display are to be erased. Other types of input devices such as a mouse trackball or the like could be used. Additionally a user s own finger could be the stylus and used for selecting or indicating portions of the displayed image on a touch sensitive or proximity sensitive display. Consequently the term user input device as used herein is intended to have a broad definition and encompasses many variations on well known input devices such as stylus . Region shows a feedback region or contact region permitting the user to determine where the stylus as contacted the display surface .

In various embodiments the system provides an ink platform as a set of COM component object model services that an application can use to capture manipulate and store ink. One service enables an application to read and write ink using the disclosed representations of ink. The ink platform may also include a mark up language including a language like the extensible markup language XML . Further the system may use DCOM as another implementation. Yet further implementations may be used including the Win 32 programming model and the Net programming model from Microsoft Corporation.

Using a stylus or pen a user creates electronic ink. The ink is handled by a system that allows the ink to be displayed closer to a time the user creates the ink rather than waiting until additional processes have been completed.

Two types of sets of inputs may be handled data resulting from contact between a stylus and a digitizer and data resulting from movement made above a digitizer. The movements made above the digitizer that do not contact the digitizer are referred to as in air stylus inputs. The internal stylus input source separates the two sets of inputs and routes them accordingly. The following lists various actions that occur in 

The above approach as shown in provides the benefits that ink lag is only critical for stylus down events. Ink lag is only perceptible while the stylus is actively drawing. All other stylus events can be delayed with little negative user impact.

The approach of provide for multi thread awareness being localized in the input manager queue and the RTI object. It also guarantees that once focus has been established there will be no lag or delay.

The first part is a pen services application that supports the gathering of electronic ink. An example is wisptis.exe provided from the Microsoft Corporation and used in Windows XP Tablet Edition.

Second a real time stylus service shown associated with process is an application that forwards stylus data from pen services to the appropriate windows for collection. The real time stylus service may handle an unlimited number of objects or may be limited to minimize over usage. For instance if limited an illustrative number of objects per thread may be 16 32 64 128 and the like. Of course other values may be used.

Third real time styluses and are shown in process . Real time styluses and may receive stylus data from real time stylus service . Each real time stylus object may be receiving stylus data for a given section of a window or region based on an associated window or region for that real time stylus object.

To show how multiple processes may be implemented at the same time process is also shown. Real time stylus service may also receive stylus data from pen services and forwards this information to real time styluses and .

The real time stylus objects and are shown in greater detail in . The pen services component forwards data to the real time stylus service in data flow A. Next the real time stylus service forwards stylus data onto one or more real time stylus components in data flow B. Alternatively as shown by the real time stylus service shown by dashed lines this service may be omitted and stylus data flowing directly to the real time stylus component .

The stylus data received at the real time stylus component may be directly fed to pluggable components . Alternatively received stylus data may be fed into its input queue for ordered processing. The real time stylus component next forwards stylus data to one or more pluggable components. These components may include a dynamic renderer with a visual store that stores the currently rendered stylus data. The data flows include flows C and D.

The dynamic renderer may accumulate and store packet data for one or more strokes in visual store . This is advantageous for instance when a stroke extends beyond an edge then reenters an inkable region while the stylus is still down. If the displayed window receives a repaint request while the pen is down the store provides the information to repaint the window quickly. If the dynamic renderer did not store stylus data in the system would have to wait to repaint the window and render the most current stroke or strokes until the data made it out of the output queue and into the ink collection object .

The pluggable components are class objects that may respond to certain calls through an interface to process stylus data. One example of an interface that may be used includes IStylusSyncPlugin. The combination of pluggable components allows a developer to fully control modify and even delete data from the packet stream within the plug ins. The modified packet stream from data flow E is then stored in the output queue .

The output of output queue flows through data flows F and G to another collection of pluggable components and . These components may include a gesture recognizer and an ink collection object with ink storage . A variety of additional plug in objects may be tapped by data flows F and G.

The decision to separate pluggable components from and may be based on a variety of criteria. For instance components may be synchronous plug ins and components and may be asynchronous plug ins. Alternatively plug ins with shorter stylus data handing times may be handled by data flows C D and longer stylus data handling times addressed by data flows F G. The components from one thread C D may be exchanged with those of thread F G.

One advantage of separating the two sets of pluggable components and is that the pluggable components are handled by different threads. Here the difference between the synchronous plug ins and the asynchronous plug ins lie in the thread they execute in and the calling sequence synchronous plug ins may be called by the thread on which the real time stylus is executing and the asynchronous plug ins are called by normally the user interface application thread after the packet stream has been processed by the synchronous plug ins and stored in the output queue .

In some cases there may be public communication from the real time stylus component back to pen services or real time stylus service . In other cases there is no public communication from the real time stylus component back to pen services or real time stylus service . Preventing communication may help the flow of data from these components.

In some situations the real time stylus component may notify the plug ins when retrieving data by sending calls to the plug ins in a predefined sequence. The sequence and types of plug ins that receive these notifications may be controlled by the developer. The packet data in the events may be modified by any of these plug ins and .

Aspects of the present invention work with a variety of data types including packet data from pen services notifications of changes regarding a display tablet pen and the like and other data sets that may be handled by the real time stylus. While the following description describes the use of packet data from pen services this is but one of the many types of data that may be used with the real time stylus . For the following packet data is used as an illustrative example for the data type handled by the RTS but is to be understood as referencing the more general data that may be handled by the RTS.

The real time stylus component may also include queues and . The output queue may maintain all of the packet data that the time stylus component processes. Once the packet data has returned from the plug in the packet data is added to the output queue from data flow E. The output queue may then be used by the plug ins for instance asynchronous and generally including the ink collection object . This may occur by extracting data out data flow F and building an ink object from the data held within in the output queue in data flow G.

The size of output queue may or may not be fixed. If fixed after the queue is full all subsequently received data packets may be lost. If not fixed the size of queue may expand to receive additional data packets. One benefit of keeping a fixed size queue is that it limits the backlog of data to that what can be processed in a reasonable period of time. For instance if the end user is interacting with the system and it becomes unresponsive it is typical for the end user to pause until the system is once again responsive thereby allowing the queue to process the backlog without losing data. Also if for some reason a high volume of stylus data was created queue may help eliminate some of the data by having a fixed size.

The output queue may be fixed in receiving data in order. Alternatively as described below data may be placed in output queue out of sequence to maintain synchronization with real time rendering.

Input queue receives information in data flow B or if no real time stylus service then data flow A . The input queue provides a process to input data to plug ins . Alternatively stylus data may flow directly to plug ins . One advantage to having input queue as an intermediary between data flows B and C here as data flow Z is that it allows created stylus data to be inserted where none exists.

The following describes an alternative approach to how the real time stylus object may handle the tablet pen data. It is appreciated that the following may be applied with minor modification to and with the modification being the arrangement of the plug ins on the synchronous thread from each being daisy chained to each being called separately by the real time stylus object .

Fourth the system includes an asynchronous plug in represented here as an ink collection object . The ink collection object here may be representative of one or more plug in objects. Ink collection and storage may be one of various actions that occur in the UI or asynchronous thread. Once the packet data or modified packet data returns from the synchronous plug ins it is placed in the output queue of the real time stylus . The real time stylus then places the data in the output queue . The data is then forwarded to the next set of plug ins in a collection or chain . This may include forwarding the data to the ink collecting object where it may be destroyed deleted recycled freed as specified by the various plug ins on the asynchronous thread.

Fifth the system may include standard plug ins which may be designed to run on either or both of the synchronous or asynchronous threads that provide basic functionality to the system. The standard plug ins may include a dynamic renderer and a gesture recognizer . Of course the standard plug ins may be replaced with other plug ins if desired. Further in some implementations of aspects of the invention no standard plug ins may be initially included with the real time stylus. Rather developers may be encouraged to select from third party suppliers and or create their own plug ins as needed.

With respect to the data of FIGS. number and each data set as transmitted through the RTS may be a single data set or a bundle of data sets that are bundled together for efficiency since the digitizer is sampling at a very high rate. These data sets provide notifications of various events or forward new information through the RTS. In some situations the data set may be deleted. In other situations where the data set is a bundle of data sets a single data set in the bundle may be deleted while retaining the other data sets. Effectively the bundle of data sets is modified. The real time stylus then may post a private message to the window to which it is attached and proceed to the next data set in the input queue or if none returns from the function called by pen services on the pen client interface.

For the following description of data packets are used. However it is appreciated that other data sets may be used as well to convey information. Data packets are but one example of the type of data sets that may be used. Here the real time stylus has two data packets A and B in output queue . Data packet C is currently being processed by dynamic renderer when a color change CC is received by pen services . The color change CC may be immediately forwarded to and processed by one of the asynchronous plug ins. However doing so may create a confusing situation where data packets A B and C were created prior to the color change. Accordingly one may desire to process the color change only after the final processing and final rendering of data packets A B and C by asynchronous plug in collection .

To delay the processing of color change CC one of the synchronous plug ins in plug in collection may create and push a data object CC into input queue . Next that data object may be processed by the input queue in online with the result in color change being represented by CC in output queue . Using this approach the instruction to change a color of strokes may be properly ordered with the previously received data packets.

Some plug ins including but not limited to the dynamic renderer may have two categories of properties namely those where changes take immediate effect versus those that take effect from the next stylus down stroke start . The separation between the two categories may occur because of a variety of reasons including technical considerations concern for user experience and user expectations and the like. For instance a stroke color change may be delayed so as to preserve the order in which the strokes and events occurred from the user s perspective.

For instance an InkCollectingObject plug in which may build up a table of packets and then creates an ink stroke on SU may have already created the stroke by the time the GR gets to it. So upon receipt of the GR the InkCollectingObject may simply delete the previously created stroke. Another plug in may then be responsible for triggering the appropriate action on the GR.

The processing of data within the synchronous and asynchronous plug in collections allows for various handling techniques for data. If some data was relevant only to some plug ins other plug ins may ignore or pass the data as needed. For example a first plug in may determined that data packets relate to a non inkable the region of a display. A second plug in may handle the data packets in a variety of ways including 

This third approach C offers a performance benefit by removing the overhead of a function call when none is needed.

Custom stylus data can be added to the real time stylus object by calling the AddCustomStylusDataToQueue method. If the call to the AddCustomStylusDataToQueue method is made from a synchronous plug in in response to a call to one of its IStylusSyncPlugin methods then the custom stylus data is added to the tablet pen data stream in a deterministic manner otherwise it is added in an indeterministic manner. The AddCustomStylusDataToQueue method throws an exception if the RealTimeStylus object is disabled.

In each of the above cases data added by subsequent plug ins in the synchronous plug in collection is added after data added by preceding plug ins.

Custom stylus data is added to the queue as a custom stylus data object and plug ins receive this data through their IStylusSyncPlugin.CustomStylusDataAdded or IStylusAsyncPlugin.CustomStylusDataAdded method.

The real time stylus object calls the IStylusSyncPlugin.CustomStylusDataAdded method on the thread from which it receives the call to its AddCustomStylusDataToQueue method.

The real time stylus object may or may not be configured to collect ink. In the event that it does not collect ink one can use the real time stylus to forward ink data to an ink collection object. The ink collection object may be in the form of an ink collection plug in which plugs into the output of the real time stylus.

Ink analysis or handwriting recognition is not a function of the real time stylus object. As the ink collection plug in collects and creates ink or as one wants to recognize the ink one can copy the ink to a RecognizerContext or Divider object.

As described above ink may be displayed more than once. Ink may be displayed the first time with the dynamic renderer. Ink may be displayed the second time with a static renderer after it has been collected in an ink collection object. This may permit other types of renderers to be used to render the ink as it is received from the ink collection object. For instance one may have multicolored ink as part of the static renderer. Pushing this set of effects to the dynamic renderer may be too intensive for the synchronous thread. Accordingly one may create a renderer and attach it to the asynchronous thread. Alternatively one may ignore the default dynamic renderer and create one s own dynamic renderer and plug it into the synchronous thread. One may also create a dynamic renderer which internally reuses a standard dynamic renderer through polymorphism aggregation or containment as used in object oriented approaches.

One may also reuse this new renderer on the asynchronous thread as the static renderer or may create a new renderer for this purpose. For instance one may want to render ink as if drawn with charcoal or other tip. Further one may create a renderer that displays ink as if it was constantly changing color over time quickly or slowly to represent how physical ink dries. Moreover one may create a renderer that displays ink with cycling colors as in a rainbow to highlight the ink. Specifically one may create a dynamic renderer plug in by creating a synchronous plug in that subscribes to the StylusDown Packets and StylusUp notifications. The plug in may then render the stroke as it is being drawn. The new renderer may handle inking as well as various selection mechanisms.

A dynamic render plug in is an object that displays the tablet pen data in real time as it is being handled by the real time stylus object. Later for events such as a form refresh the dynamic renderer plug in or an ink collection plug in may redraw the ink.

The dynamic renderer object implements the IStylusSyncPlugin interface. The dynamic renderer may additionally implement an asynchronous interface. The dynamic renderer object renders the ink in real time as it is being drawn. By default when the refresh method is called the dynamic renderer object redraws the stroke currently being collected along with any other previously collected strokes which would correspond to DynamicRenderer sCachedData . Other overloads of the refresh behavior are possible that include parameters to constrain the behavior of a drawing for instance with a clipping region so that ink is not rendered outside a given shape.

This is shown in the various figures that the dynamic renderer object can temporarily cache ink data . When the dynamic renderer object receives a call to its IStylusSyncPlugin.StylusUp method it caches the stroke data and adds custom stylus data to the Input queue in response to the StylusUpData object for the stroke. The CustomStylusData object s CustomDataId property is set to the DynamicRendererCachedDataGuid value and the CustomStylusData object s Data property contains a DynamicRendererCachedData object. One may then clear the dynamic renderer s cache of the associated data once the ink has been rendered downstream. Alternatively refreshing the ink redrawing current strokes and data stored in CachedData may not always clear the dynamic renderer s cache of ink strokes because those ink strokes may not yet have passed through and stored by the ink collecting object.

In step the packet enters the synchronous plug in collection. For systems such as that of this step may mean forwarding the packet to the first of the plug ins. The real time stylus calls the function appropriate for the particular packet data on the first plug in in the collection or chain if a chain is present . In many cases this component has the option of modifying the data or leaving it alone. As the component completes its operation it calls the same function on the next plug in object and so on.

In step the packet proceeds through the synchronous plug in collection or chain . This may or may not include packets forwarded to a gesture recognizer or dynamic renderer as shown in step . If a dynamic renderer is used it may start accumulating packet data on a cursor down event also referred to as a pen down event in a storage and beings rendering them on a screen the operation of the dynamic renderer . On a cursor up event or pen up event the dynamic renderer may clear its storage for the next cursor down event.

If a gesture recognizer is used the gesture recognizer may listen for a cursor down event and begin accumulating data in its own storage for instance storage . As strokes accumulate the gesture recognizer passes the strokes into a recognizer and if the strokes correspond to a desired pattern or gesture then a the gesture data is added to the output queue and b the storage is emptied and accumulation begins again with the next cursor down event passes through the queue. Here it is noted that gestures may include one or more strokes. described in greater detail below shows how multiple stroke gestures may be handled with respect to the process of .

To what extent a plug in should or can be aware of previous strokes depends on the purpose of the plug in.

In both of these example scenarios the distinction between single and multiple stroke gestures does not really matter the application scenario may call for multiple stroke gestures e.g. arrow in which case both of the example plug ins above will be aware of multiple stroke gestures out of necessity.

Next in step the packet enters the output queue after being processed by the collection of synchronous plug ins. As described previously the collection of plug ins may in handling each of the objects sent to it modify delete and or replace the data packet. Assuming that none of the synchronous plug ins deleted the packet step is executed.

The system provides the ability to handle stylus data quickly and efficiently. To make electronic ink behave like real ink the electronic ink needs to appear to flow as easily as real ink from the tip of a stylus. Small disruptions or delays in the flow of ink are detrimental to the electronic inking experience. The follow describes various approaches to ensuring electronic ink appears to flow smoothly from the stylus. Wet ink is considered the ability to control how long the dynamic renderer owns static rendering after collecting ink. To help handle the management the lifetime of ink in the dynamic renderer a notification may be used referred to herein as DynamicRendererCachedData allows an ink collecting plug in to free the cached or wet ink from the dynamic renderer.

A variety of different types of dynamic renderers may be created. For instance instead of rendering ink as having been created by a fine point or chisel point pen a dynamic renderer may renderer ink as having been created by translucent water based paint also referred to as water colors . Additionally a dynamic renderer may be created that renders ink as having been created by a charcoal stylus. Further the dynamic renderer may render ink such that it is not fixed but regularly changes colors and or moves. For instance the dynamic renderer may render ink appearing as small drops of ink or dust that coalesce into the desired ink form as small worms that eventually move together to form desired ink or as ink that changes color and shape.

The dynamic renderer may display ink in the same form as that later to be rendered by an object associated with an asynchronous thread of the RTS. Alternatively a relationship may exist between the ink rendered by the dynamic renderer and final display of ink associated with the asynchronous thread of the RTS. For instance the dynamic renderer may show ink in a first shade or shape only to be later modified by the plug in on the asynchronous thread to a second shade or shape. This may appear to the user as drying of ink or paint as flowing from a stylus.

The following description of dynamic rendering and wet ink may be applied to . For purposes of explanation is referenced. The arrangement of is equally applicable and the following description is desired to encompass as well.

Referring to digitizer input enters from pen services and reaches real time stylus . The real time stylus passes the digitizer input through multiple synchronous plug in objects and stores the result into output queue . Objects may be connected through an interface that describes the link between the objects for instance IStylusSyncPlugin. The asynchronous plug in collection of objects then receives the output from output queue and begins to process it. For instance ink collecting object many extract digitizer input from the output queue and store it as ink. Dynamic rendering of the digitizer input occurs when real time stylus component passes the digitizer input as modified or not through to dynamic renderer . Static rendering of the digitizer input as modified or not occurs when the digitizer input is stored in the ink storage inside of the ink collecting object .

One issue that may occur is where an inking surface may become invalidated after dynamic rendering and prior to the digitizer input being stored inside of the ink collecting object . The resulting user experience would be displayed ink vanishing until the digitizer input reaches the ink collecting object . The user may believe he or she needs to re create the ink and then spend time doing so resulting in duplicate ink eventually being stored. This visual hiccup is due to the ink not being readily shown to a user or shown after a delay.

In order to avoid this vanishing ink scenario a communication protocol may be established between the dynamic renderer and ink collecting object . The dynamic renderer may continue to cache digitizer input in visual store until it is told that it can release the digitizer input by the ink collecting object for instance when the digitizer input has been stored in ink store .

For purposes herein the temporal cache of digitizer input in the dynamic renderer is currently referred to as cacheddata. Wet ink is the ability for the system to render ink prior to digitizer input being stored in the ink collection object .

Step B above may or may not perform properly based on whether or not the synchronization of drawing attribute modifications have occurred prior to all strokes having been moved out of an output queue. relates to a process for synchronizing drawing attribute changes with previously received data packets.

The drawing attributes may be set in the system in accordance with a developer s desires or among other approaches may be provided in the object passed to the ink collecting object . The release notification may be a call on an interface provided by the dynamic renderer . Here the notification may be ReleaseCachedData.

The output of the synchronous plug in collection of real time stylus component is forwarded to output queue . Asynchronous plug in objects may then handle the data packets in output queue . Again ink is dynamically rendered and flows smoothly from the pen even when the application is blocked.

It is noted for reference that the various plug in components may be chained together instead of following one another in a plug in collection. An example is shown here in where synchronous plug in component A is chained to synchronous plug in component B . Of course the approaches of chaining plug in components together or collecting them in a collection may be used in alternatively or in addition to each other for addressing plug in components in accordance with aspects of the present invention

Gesture recognition attempts to determine if a gesture has been made and handles it appropriately. Gesture recognizer for example is responsible for looking at digitizer input and injecting gesture recognition results into the input queue similar to the dynamic renderer . described how gesture recognition may be performed with synchronous and asynchronous plug in collections. That description is relevant with respect to the operation of the gesture recognition object.

The gesture recognizer may use an algorithm. Here the gesture recognizer may use a permutation algorithm to recognize multiple stroke gestures. For instance when a property relating to the maximum number of strokes has been set the gesture recognizer looks back that many strokes. For instance if the property is set to 2 the gesture recognizer looks back to the most recent 2 strokes trying to recognize them as gestures. This may result in multiple recognition calls. However this approach eliminates a constant delay for having to wait for a gesture recognizer to start processing after the last stroke.

Once the ink collecting object receives the gesture object here GestureRecognitionData it removes the strokes for the gesture from the ink store and conducts the appropriate actions in response to the gesture.

As described above to perform gesture recognition the system may add a SystemGestureData object to the Input queue in response to the data that finishes the gesture such as a StylusUpData object for the Tap gesture.

The gesture recognizer may be implemented as an object with various interfaces. For example the gesture recognizer object may implement IStylusSyncPlugin and IStylusAsyncPlugin interfaces.

When the gesture recognizer object recognizes a gesture it adds custom stylus data to the Input queue in response to the StylusUpData object for the stroke. The CustomStylusData object s CustomDataId property is set to the GestureRecognitionDataGuid value and the CustomStylusData object s Data property contains a GestureRecognitionData object.

By default the gesture recognizer object only recognizes single stroke gestures. The gesture recognizer object can be set to recognize multistroke gestures see for instance . For multistroke gestures the CustomStylusData object is added to the Input queue in response to the StylusUpData object for the final stroke of the gesture. When recognizing multistroke gestures one may receive notifications for overlapping sets of strokes. For example the first and second strokes together may be recognized as one gesture the second stroke by itself may be recognized as a gesture and the second and third strokes together may be recognized as another gesture.

If one is using the gesture recognizer object for multi stroke gesture recognition one may use a cascaded real time stylus model and attach the gesture recognizer object to the secondary real time stylus object in order to reduce delays on the real time thread but prevent gesture recognition from being affected by delays on the user interface thread.

Further one may create a custom gesture recognizer plug in that recognizes handwriting gestures or other objects in three ways.

The real time stylus object receives data about system gestures as they are recognized by the system. The following table describes where the SystemGestureData objects occur in the pen data stream in relation to other pen data. The following list is illustrative and not exhaustive. Other gestures may be used in conjunction with aspects of the present invention without departing from the scope of the invention.

When a real time stylus instance is instantiated an execution thread may be instantiated. The execution thread may be separated into synchronous objects and asynchronous objects. The synchronous objects generally operate in synchronization with packets originating from a pen services component. The asynchronous objects are generally grouped as objects that do not have to be always executed in syncretism with ink strokes and or other data packets originating from pen service components. The separation of these two threads permits a dynamic renderer object to quickly handle data packets in synchronization with the receipt of the data packets and permits other plug in objects which while still important may be handled correctly even with a slight delay from the or receipt of the original data packets.

The collection of synchronous plug ins are executed on this new thread that was instantiated for the real time stylus instance. The collection of asynchronous plug ins may be executed in a user interface thread.

The real time stylus thread may be intended for computationally light activities so that inking packet queuing and dynamic rendering is generally responsive and smooth. Therefore only computationally light processing should generally be implemented with the thread with for the synchronous plug ins.

The user interface thread usually associated with the output of the output queue is usually used by asynchronous plug ins that require computationally intensive activities. To assist a queue architecture is provided between the real time stylus thread and the user interface thread to be robust against temporary blockages in the user interface UI thread. The UI thread may or may not be the final destination of packets and other data collected on the real time stylus thread. It is noted that alternative architectures may handle computationally intense activities better thereby not readily forcing a developer to compromise between blocking a pen thread and a user interface thread. For instance a cascaded design as described herein allows the separation of threads to better handle different activities.

The gesture recognizer may be implemented on the synchronous thread or may be implemented on the asynchronous thread if the gesture recognizer is determined or anticipated to be slow from expected heavy gesture recognition activities e.g. a large number of accepted gestures to which strokes are going to be compared against . The gesture recognizer object may have both a synchronous plug in interface and an asynchronous plug in interface to give a developer the flexibility to utilize the object from either or both threads. This capability is not limited to the gesture recognizer. The dynamic renderer or any other plug in may optionally support usage in either or both queues. It is appreciated that all plug ins may or may not have a synchronous interface an asynchronous interface or both in order to allow a developer to place the plug in in asynchronous collection or in an asynchronous collection or both if the plug in supports this depending where the developer anticipates a good location for the plug in to be.

The real time stylus object provides real time access to the tablet pen data stream and may run on its own thread. Synchronous plug ins may or may not generally run on the real time stylus object s thread while asynchronous plug ins may or may not generally run on the application s user interface UI thread. One may separate the synchronous thread from the asynchronous thread by placing plug ins for tasks that require real time access to the data stream and are computationally light such as dynamic rendering on the synchronous thread. Plug ins for tasks that do not require real time access to the data stream such as ink collection may be placed on the asynchronous thread.

Certain tasks may be computationally intensive yet still require close to real time access to the tablet pen data stream such as multi stroke gesture recognition. Plug ins to handle these tasks may be grouped on one thread or the other or may be part of cascaded real time stylus objects as shown in .

Real time stylus instances are in many ways a thread host that encapsulates extensibility and policy. shows an example of how multiple synchronous threads may work together. Gesture recognizer may be placed on the synchronous thread at location or may be placed on the synchronous thread at location .

If there were multiple functionalities that the developer wants to connect in a multi threaded manner the developer can cascade multiple real time stylus instances and plug their functionality in as synchronous plug ins.

The specific scenario that suggests this feature is to realize truly uninterruptible inking. The gesture recognizer may at times cause significant latency to obtain recognition results when the developer is interested especially in multi stroke gestures. Therefore the gesture recognizer may not be on the synchronous collection of real time stylus where the dynamic renderer is positioned as it has a potential to block dynamic rendering. The gesture recognizer may be also located with the ink collection object with the collection of asynchronous plug ins.

The system as shown in is beneficial where one wants to separate computationally intensive operations from the gesture recognizer or other threads for operations including such as accessing a database posting to web server refreshing a screen and the like. Where gesture recognition is an integral part of the truly uninterruptible experience one may have the gesture recognizer run on its own thread namely a second real time stylus thread.

Real time stylus may support this usage by implementing an asynchronous interface thus allowing it to behave as a mere asynchronous plug in instance. The following describes how a real time stylus may be added to another real time stylus. The following provides a number of options that may or may not be implemented.

It is noted that while one implementation may re use an asynchronous plug in collection as a collection point for cascading an alternate implementation may have a dedicated connection point for connecting a cascaded RTS thereby allowing each RTS in the cascade to have its own independent set of synchronous and asynchronous plug ins.

It is appreciated that the existence of the ErrorData object may be independent from cascading. So the generation of the ErrorData object may occur with respect to a single real time stylus component as well as with cascaded real time stylus components.

The synchronous and asynchronous plug in collections on the real time stylus may be modified without disabling and then re enabling the real time stylus for performance benefits. Thus there is no assurance that there is an enabled or disabled operation done at the real time stylus scope.

In order to ensure a timing where plug ins can initialize clean up artificial meaning not resulting from true client code calls to enable disable RealTimeStylusEnabled RealTimeStylusDisabled calls may be made to plug ins which are dynamically inserted or removed from the plug in collections.

The way these relationships are maintained may or may not include incrementing a counter each time it gets a real time stylus enabled call. Every time it gets a real time stylus disabled call this counter is decremented. When the counter is 1 this plug in functions. When the counter becomes larger than 1 this plug in raises an exception and inhibits its functionality. When the counter comes back down to 1 this plug in stays disabled. The plug in only re enables itself when the counter is back down to 0 again. Other approaches may be used.

While in a development environment for instance Visual Studio.NET by Microsoft Corporation developers may break at any Exception that is raised regardless of whether it is caught or not with a try catch. Therefore error reporting is straightforward for the purpose of detecting invalid configurations of the RealTimeStylus framework.

The error reporting propagation issue may become difficult for run time errors as real time stylus and synchronous plug ins are running on the real time stylus thread ink thread which is different from the UI thread app thread . If a synchronous plug in were to raise an exception it can be caught by the real time stylus but the exception has no where to go beyond that since it is on the real time stylus thread ink thread and the origin of the control flow is the real time stylus. Propagating the error to the user interface thread and allowing the client code to gracefully deal with the error may be difficult. The following describe a solution.

The .NET standard error handling is to fire events from the plug ins when exceptions occur and have the developer s error handling code in the UI thread listen to this event. This does not work for Real Time Stylus though since when a plug in fires an event there is a possibility that the data that caused the exception may not have reached the UI thread due to the queuing. It is challenging to conduct graceful error handling without the availability of the context namely the bad data as well as preceding and succeeding data in which the exception occurred to the error handling code. This approach is only good for simplistic error handling such as raising an error dialog and terminating the application.

The proper places to conduct error handling within the real time stylus framework is in the plug ins synchronous or asynchronous as the plug in is the only code blocks that are under the developer s control.

The real time stylus thread ink thread should not immediately stop functioning on an exception raised from a synchronous plug in as this makes it impossible to conduct error handling in the UI thread app thread e.g. the queues need to stay intact for error handling . Furthermore what one plug in considers invalid input may be completely valid for another plug in.

As shown in the real time stylus catches all exceptions coming from plug ins and creates an ErrorData object. The following shows a process for identifying errors 

The ErrorData object may be passed through the plug in collection through dedicated methods for instance IStylusSyncPlugin.Error method or IStylusAsyncPlugin.Error method .

More particularly when a plug in throws an exception the normal flow of data is interrupted. The real time stylus object generates an ErrorData object and calls the IStylusSyncPlugin.Error or IStylusAsyncPlugin.Error method of the plug in that threw the exception and the IStylusSyncPlugin.Error or IStylusAsyncPlugin.Error method of the remaining plug ins in that collection. If the plug in that threw the exception is a synchronous plug in the ErrorData object is added to the output queue. Then real time stylus object resumes normal processing of the original data.

If a plug in throws an exception from its error method the real time stylus object catches the exception but does not generate a new error data object. Alternatively a new error data object may be produced depending on the implementation or desire of the developer.

In this alternative approach the real time stylus may then reduce any created loop by limiting the number of recursions or it may ignore the risk altogether. In relationship to custom stylus data added by synchronous plug ins the error data is added to the output queue after any custom stylus data that is added to the output immediate queue prior to the exception that created the error data and before any custom stylus data that is added to the output immediate queue by subsequent plug ins in the synchronous plug in collection. If any of the synchronous plug ins adds custom stylus data to the output immediate queue in response to the error data the data is added immediately before the error data. If any of the synchronous plug ins adds custom stylus data to the output queue in response to the error data the data is added immediately after the error data.

The real time stylus object calls the IStylusSyncPlugin.Error method on the thread from which the exception is thrown.

Pen services sends stylus data to real time stylus component with its input queue and output queue in the unmanaged code region. Stylus data is passed to the real time stylus component in the managed code region.

The dynamic renderer is the first synchronous plug in attached to the real time stylus component. In the unmanaged space the dynamic renderer with its data cache is attached to the real time stylus component . Similarly in the managed space dynamic renderer with its data cache is part of the synchronous plug in collection for real time stylus component . The next synchronous plug in in the synchronous plug in collection is synchronous plug in . Synchronous plug in follows after dynamic renderer in synchronous plug in collection for the RealTimeStylus component . Because synchronous plug in Y only exists in managed space a synchronous plug in wrapper allows the unmanaged RealTimeStylus component to access synchronous plug in over the managed unmanaged boundary.

Data crossing between the managed and unmanaged sides of may need to be converted or marshaled between the structures used in unmanaged space and structures used in managed space. The .NET Framework by Microsoft Corporation provides an interoperability layer that performs much of this marshaling automatically. This additional data processing incurs an implied performance penalty so the design as shown in is tuned to minimize the number of interoperability layer crossings.

The relationship between managed wrapper for RTS and unmanaged RTS is that to the native unmanaged RTS the managed RTS looks like another RTS event sink. When instantiated with dynamic renderer in its constructor the RTS accesses the corresponding unmanaged dynamic renderer and hooks it in to synchronous plug in collection after itself.

The managed gesture recognizer object may be a full implementation of an asynchronous plug in. It accumulates packet data on the managed side and marshals it across the interoperability layer and passes into the unmanaged code implementation . The return code is whether packets correspond to a gesture or not.

The managed and unmanaged dynamic renderer objects and are also shown in . The managed dynamic renderer object may be a thin wrapper over the properties of the unmanaged dynamic renderer . The managed dynamic renderer is optional. If the dynamic renderer is not instantiated here it may be instantiated as one of the other synchronous plug ins.

Step c may be realized with an alternative arrangement. For instance the API may not have any plug in specific accommodations on the RTS constructor. Instead the various overloads of the RTS constructor dictate how the RTS itself will be used e.g. attached to a window or control associated with one or many digitizers mouse verses pen behavior etc. The DynamicRenderer parameter may be used because of performance implications of data crossing the interop boundary multiple times. As a result DynamicRenderer may be used in an architectural sense to be the first or last synchronous plug in in the plug in collection or chain.

In one implementation one may not allow plug in collection implementations to know whether packet data had been modified prior to entering the plug in collection. Alternatively the plug in collections may be informed if the packet data has been modified. For instance a flag on the data or a flag independent of the data may be set. One advantage of allowing plug in collections the knowledge of whether packet data has been modified provides plug in collections the ability to ignore modified packet data out of caution. On the other hand this approach provides further options for a developer to make mistakes. More importantly it muddles the simplicity and object oriented nature of the design pattern because plug ins are not longer agnostic to the origin of the data. If the plug in can inspect both the original and the modified data then it is probably performing operations that belong in the previous plug in.

For performance efficiency reasons one may internally maintain two data structures so that unless the developer intends to modify the data one does not need to allocate the memory.

An ICO may use the input and output queues as a signaling mechanism in order to synchronize other requests that come in on the UI thread with pending data coming through the inking thread.

However instead of adding the mode switch event to queue at the present time it is delayed until after the current processing is finished at time for stylus data. This may occur two ways. First the mode switch operation event may be delayed until the stylus data starting in the plug ins at time is completed. Second the system may input the mode switch event in queue leaving enough room for the result from plug in at time to be placed in front of it in the queue . So in this case the ICO may insert a marker into the output queue at the instant that the user made the mode change. After a period of time has elapsed that marker will be passed back into the ICO via the CustomDataAdded method on real time stylus plug in collection interface at which point the ICO can begin interpreting incoming packet data as eraser requests.

Referring to a pen device sends data to pen services . A mouse may also generate information and send it to user also known as user . . Some pen data clicking on buttons for example may represent mouse events and is rerouted to user to be handled as mouse events Likewise some mouse events may represent ink and is rerouted at to be handled as pen input. Mouse events are then passed to the windows message pump then HWND HWND mouse device the input queue and then input manager . Pen input for example when the pen is moved into a range of a potential inking service or a stylus event is sent to the pen input manager unmanaged and managed real time stylus services . The pen input manager handles all the communication between the pen services and the application. This handling may be performed on a normal priority thread or on a high priority status thread. Pen services may generate various events. Pen events may be sent to the pen input manager to bypass the standard messaging system and .

Pen services may generate the following events stylus in range where the stylus has come into range of the digitizer stylus out of range where the stylus can no longer be detected by the digitizer stylus packets raw point data from a digitizer the pen may or may not be in contact with the digitizer stylus in air points tablet added removed and system gesture events for instance press and hold and hover events .

The stylus may generate raw preview events. These raw preview events may be handled by a real time inking service from . Other services may listen for these events as well. The real time inking service may perform a number of steps on the raw preview events including 

The return value from the raw preview event is used by the pen input manager to Target the event. If a non null target is returned then the event may be placed on the input queue with that specific target. This ensures that ink that has been drawn on an element is actually delivered to that element rather than some other element as a result of other events in the input queue.

Now the stylus event is ready to become an input event. However in most cases each stylus event also has a corresponding mouse message flowing through the message system. Before the pen input manager can convert the stylus event into an input event it should first match up the event with the corresponding mouse message. If necessary the pen input manager can wait for the mouse message to arrive.

Once the pen input manager has both the mouse message and the stylus event it combines the two into the appropriate input report and places the report on the input queue .

The following provides an overview of the various application programming interfaces that may be used by aspects of the present invention.

The real time stylus may be part of a real time stylus input class. The instantiated real time stylus object may be attached to a window handle or control. The real time stylus may include default constructors. Using a default constructor permits one to accept input only from another real time stylus object.

To allow plug ins to interact with a pen data stream the real time stylus object may maintain two plug in collections. The collections may be specified in a property of the real time stylus object for instance SyncPluginCollection for synchronous plug ins and AsyncPluginCollection for asynchronous plug ins . One may add a plug in to either collection by calling an add method for instance StylusSyncPluginCollection.Add for adding a plug in to the synchronous collection or StyluAsyncPluginCollection.Add for adding a plug in to the asynchronous collection on the appropriate property.

Synchronous plug ins may implement an interface for instance IStylusSyncPlugin and asynchronous plug ins may implement a different interface for instance IStylusAsyncPlugin . Each plug in may have property that specifies its data interest for instance IStylusSyncPlugin.DataInterest or IStylusAsyncPlugin.DataInterest . The real time stylus object may call notification methods of the plug in for methods in which the plug in has subscribed.

The real time stylus object implements the IStylusAsyncPlugin interface. To instantiate a real time stylus that accepts input from another real time stylus may include using a default constructor. Further alternative mechanisms may be used to associate a child or cascaded RTS with a parent. Another mechanism may use a dedicated pointer associated with a parent RTS to hold a reference to the child RTS. Here the parent RTS would not need to implement the asynchronous plug in interface.

The real time stylus object may have two or more internal queues that transport pen data. These include the input queue and the output queue. Another queue may be added between these two queues. Also the input queue may be eliminated when data is only intended to enter the synchronous plug ins from a pen data stream. The process that these queues use to handle pen data is described above in relation to at least and .

The following is an example scenario for using the real time stylus object on a form that collects ink.

Each real time stylus object maintains a list of unique identifiers for the objects with which it can interact. The real time stylus object may have a few methods for translating between a unique identifier and the tablet object. These may include the GetTabletContextIDFromTablet and GetTabletFromTabletContextID methods.

A tablet property description object e.g. TabletPropertyDescription object may contain a property globally unique identifier GUID and a tablet property metrics e.g. TabletPropertyMetrics structure that describes the range resolution and units of the property for a specific tablet.

A method may exist that takes a unique tablet identifier and returns a collection of property description objects supported by the tablet. For instance the GetTabletPropertyDescriptionCollection method of the real time stylus object takes the unique tablet identifier and returns the collection of TabletPropertyDescription objects supported by the tablet. The real time stylus object s GetDesiredPacketDescription method returns an array of GUIDs for the packet properties that the real time stylus object will forward to its plug ins.

The set of packet properties that is sent to the plug ins for a given tablet may be the intersection of the set returned by the GetTabletPropertyDescriptionCollection method and the set returned by a GetDesiredPacketDescription method. To modify the set of packet properties the real time stylus will pass to its plug ins the real time stylus object s SetDesiredPacket Description method may be called.

When the real time stylus object is enabled each plug in receives a call to its IStylusSyncPlugin.RealTimeStylusEnabled or IStylusAsyncPlugin.RealTimeStylusEnabled method. The RealTimeStylusEnabledData object passed in the notification contains a collection of the context identifiers for the available tablets at the time the RealTimeStylus object is enabled. When a tablet that the RealTimeStylus object can use is added to or removed from a pen enabled computing system while the RealTimeStylus object is enabled the RealTimeStylus object notifies its plug ins that a tablet has been added or removed.

Styluses may have additional interfaces. Each stylus may have information associated with it that describes packets associated with the styluses. The real time stylus object may pass information about the styluses to the plug ins in a number of notification methods. Information about a pen or stylus may be represented by a stylus object. The object is a snapshot of the state of the tablet pen at the time the data was gathered. Since plug ins are receiving the tablet pen data as part of the tablet pen data stream the plug ins should use the information in the stylus object instead of checking for the current state of a particular tablet pen through the cursor class.

The following describes plug ins and the RealTimeStylus class. Plug ins objects which implement the IStylusSyncPlugin or IStylusAsyncPlugin interface can be added to a real time stylus object.

Both the IStylusSyncPlugin and IStylusAsyncPlugin interfaces define the same methods. These methods allow the real time stylus object to pass the pen data to each plug in. The IStylusSyncPlugin.DataInterest and IStylusAsyncPlugin.DataInterest properties allow each plug in to subscribe to specific data in the tablet pen data stream. A plug in should only subscribe to the data necessary to perform its task which minimizes potential performance issues. Alternatively additional subscriptions may be included for a plug in.

The real time stylus object may use objects in the StylusInput.PluginData namespace to pass the pen data to its plug ins. The real time stylus also catches exceptions thrown by plug ins. When it does so it may notify the plug ins by calling the IStylusSyncPlugin.Error or IStylusAsyncPlugin.Error method.

Plug ins for the real time stylus may implement either the IStylusSyncPlugin or IStylusAsyncPlugin interface. One may or may not implement all methods in the real time stylus.

The methods defined on the interfaces may use objects in the StylusInput.PluginData namespace to pass the pen data to the plug ins. The following table describes the data objects that are parameters in the notification methods and lists the DataInterestMask value associated with the notification.

The real time stylus object passes information about the tablet pen to its plug ins in a number of the notification methods. Information about the tablet pen is represented by a Stylus object. This object is a snapshot of the state of the tablet pen at the time the data was gathered. Since plug ins are receiving the tablet pen data as part of the tablet pen data stream the plug ins should use the information in the Stylus object instead of checking for the current state of a particular tablet pen through the Cursor class. Each Stylus object contains the tablet context identifier for the tablet that generated the data.

The following 13 functions may be implemented on the synchronous and asynchronous interfaces. The table compares the information that is passed through the various events. The list of events and parameters is illustrative and not exhaustive. Other events and parameters may be used with or in place of the following.

Many of the synchronous parameters differ from the asynchronous parameters only in that the former allows the recipient to modify the data passing through the queue. Alternatively both sets of parameters may be allowed to modify the data passing through the queues.

Aspects of the present invention have been described in terms of illustrative embodiments thereof. Numerous other embodiments modifications and variations within the scope and spirit of the appended claims will occur to persons of ordinary skill in the art from a review of this disclosure.

