---

title: Internal privacy invasion detection and prevention system
abstract: Data privacy administration is described, including receiving, with a computer system, resource access records that correspond to accesses of user resources by an administrator of an application that stores the user resources; processing, with the computer system, the resource access records to generate structured audit records that correspond to the resource access records, the structured audit records includes a resource identifier that corresponds to the resource that was accessed and an accessed-by identifier that indicates an administrator that accessed the resource; and analyzing the structured audit records using a plurality of resource privacy modules that include resource privacy rules that define violation detection scores specifying likelihoods of whether one or more resource accesses are problematic accesses, wherein the resource privacy modules are provided from two or more different domains.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08893289&OS=08893289&RS=08893289
owner: Google Inc.
number: 08893289
owner_city: Mountain View
owner_country: US
publication_date: 20120711
---
Data storage and application hosting services may store significant amounts of user data. Some data may be the result of documents and files created by users in hosted applications and other data may include logs metadata or other information that is generated by the hosted application in the course of providing services to the users.

In the normal course of operations the organizations that manage the data storage and hosted applications often do not need to access such data. However some occasions may arise where a member of the organization must do so for example to troubleshoot an application or correct an error with a user s documents and files. In such cases organizations may restrict access permissions to only a select group of members. Those members may have their actions monitored to ensure the appropriate protection of the user s data.

The subject matter herein describes systems and techniques that can store information about instances of access that are made to pieces of data stored by a computer system. Such stored information can be aggregated filtered and otherwise managed to produce useful statistics and other data about the manner in which accesses have occurred whether in individual instances or in groups. For example engineers or researches may create rules to be applied to such data in order to identify anomalies in the data that might indicate particular illegitimate accesses or groupings or trends in the data that represent situations that might be of concern from a security or privacy standpoint. An organization that manages the data may add such rules to an overall rules set that is applied to additional data including by being applied prospectively so as to identify and potentially block requests for access that have been determined to have an illegitimate character to them e.g. the requests can be blocked totally or a requester may be asked for additional identification or verification data before access will be granted to them . In addition the rules may be used to generate alerts that can be reviewed manually by an administrator of such a system so as to determine whether such accesses were legitimate and whether system access policies should be adjusted. Aspects of the example embodiments include a computer implemented method which includes receiving with a computer system resource access records that correspond to accesses of user resources by an administrator of an application that stores the user resources. The example embodiment also includes processing with the computer system the resource access records to generate structured audit records that correspond to the resource access records the structured audit records comprising a resource identifier that corresponds to the resource that was accessed and an accessed by identifier that indicates an administrator that accessed the resource. Further the example embodiment includes analyzing the structured audit records using a plurality of resource privacy modules that include resource privacy rules that define violation detection scores specifying likelihoods of whether one or more resource accesses are problematic accesses the resource privacy modules are provided from two or more different domains.

Additional aspects of the example embodiments include at least one computing device collectively having storage and at least one processor configured to receive resource access records for analysis by the computer system the resource access records corresponding to accesses of user resources by an administrator of an application that stores the user resources. Further the example embodiment is configured to process the resource access records to generate structured audit records that correspond to the resource access records. The structured audit records include a resource identifier that corresponds to the resource that was accessed and an accessed by identifier that corresponds to the administrator that accessed the resource. The analysis pipeline comprises a plurality of resource privacy modules configured to analyze the structured audit records using resource privacy rules that define violation detection scores that define likelihoods of whether one or more resource accesses are problematic and the resource privacy modules are provided from two or more different domains.

Further aspects of the example embodiments include a non transitory computer readable medium having stored therein computer executable instructions for receiving with a computer system resource access records that correspond to accesses of user resources by an administrator of an application that stores the user resources. The example embodiment includes instructions for processing with the computer system the resource access records to generate structured audit records that correspond to the resource access records the structured audit records comprising a resource identifier that corresponds to the resource that was accessed and an accessed by identifier that indicates an administrator that accessed the resource. The example embodiment also includes instructions for analyzing the structured audit records using a plurality of resource privacy modules that include resource privacy rules that define violation detection scores specifying likelihoods of whether one or more resource accesses are problematic accesses. The resource privacy modules are provided from two or more different domains. The details of one or more implementations are set forth in the accompanying drawings and the description below. Other privacy events and advantages will be apparent from the description and drawings and from the claims.

Large organizations may store data that are accessed millions of times by internal and external users. Most such instances of access are appropriate and benign but a tool to monitor all such instances may be used to examine the activity and demonstrate to the users that their data are being properly protected. An analysis pipeline may aggregate and analyze records of data access and prioritize the instances of access for review. The analysis pipeline may let researchers security engineers and privacy advocates create event analysis rules and contribute those rules to a unified event privacy auditing pipeline. These researchers security engineers and privacy advocates may come from different domains internal employees application experts government regulators third party advocates and customers to name a few. The analysis pipeline may take logs or audit records from hosted applications examine them and produce privacy alerts that flag potentially questionable activities taken by application administrators. The privacy alerts may be reviewed by an auditor for corrective action.

The analysis pipeline may be used to monitor data accesses that signal potential privacy violations such as break glass events predefined actions that may be legitimate but are always reviewed accessing data of a user close to an administrator on a social graph interactions with data of a white listed users and interactions with data of users that are geographically near. These and other potential privacy violations may be defined by the event analysis rules created by the researchers security engineers and privacy advocates.

Analysis rules may with machine readable information define privacy events that are identified by the analysis pipeline . The analysis pipeline for example may be comprised of modules that have been created to implement different types of analysis rules and those modules may be configured in a pipeline scheme that routes the output of some modules as input for other modules. Yet other modules may be applied in parallel to data in the pipeline .

The analysis rules may be designed or provided by one or more privacy administrators . The privacy administrators may be tasked with identifying potential privacy events for an application or organization.

Each type of privacy administrators may be associated with a domain depending upon the employment specialization or knowledge of each privacy administrator . The domain describes a particular group of data or data type such as electronic mail related data shopping data healthcare data and the like. Each type of privacy administrator may contribute analysis rules based on the privacy administrator s knowledge of technical business legal or logical features of that domain. The following describes privacy administrators from application organization and privacy expert domains but other types of privacy administrators from other domains are possible.

Application domain privacy administrators include application administrators that have a particular knowledge of an application. These privacy administrators may include email administrators network engineers hosted storage managers and similar workers.

Organization domain privacy administrators may be employees or users associated with a particular interest in the analysis pipeline or applications examined by the analysis pipeline. For example a company may contract with a hosted email provider for that company s email services. An information technology manager who creates analysis rules for the analysis pipeline may be classified as from that company s organizational domain. Additionally an administrator who is responsible for a group of applications that are monitored by the analysis pipeline may also be classified as a part of an organizational domain.

A privacy expert privacy administrator may also generate analysis rules for the analysis pipeline. For example the operators of the analysis pipeline may contract with a well known reputable privacy advocate or a government agency with a privacy mandate to generate analysis rules . These privacy administrators may be classified as a part of a privacy organization domain.

Hosted applications may include any appropriate application that executes on a server that is remote from the end user interacting with the application. Examples of remote hosting include but are not limited to web based email social networking hosted storage shared document editors etc. Although the system is shown with hosted applications other types of applications such as locally executing applications may be monitored by the analysis pipeline . The hosted applications may record internal events in logs for processing and examination. For example a hosted storage hosted application may record object uploads deletions and modifications to a log . Entries in these logs may specify information such as a timestamp when they occurred and or the user or administrator that initiated the event.

Some logs may be confusing to an untrained reader and logs from different hosted applications may not conform to a single format structure or convention. The logs may be converted by the analysis pipeline into audit records such as structured audit records SARs . The SARs may catalog entries of the logs according to a single format structure and convention so that SARs from various hosted applications may be interpreted in a similar manner. Further the SARs may generalize or group related log entries so that they are easier to understand or parse. For example the hosted storage system may make three log entries for an administrator directed movement of a data object one log entry to identify the administrator one to record writing the object to the new location and one to record the deletion of the old copy of the object . A SAR for those entries may specify in a single entry the administrator and the movement event. Further because the SARs are generalized and standardized they may be read or parsed by a machine or a properly trained human without any particular knowledge of how a particular hosted application operates. Related SARs may be grouped into composite SARs CSARs .

The analysis pipeline may receive logs from the hosted applications and generate privacy alerts . The privacy alerts specify events in the hosted applications that according to the analysis rules should be flagged for further analysis. The further analysis may be performed by the analysis pipeline schematically shown with a privacy alert as an input to the analysis pipeline or by an auditor . The auditor may be a human user that may be from one of the same domains as a privacy administrator but not necessarily. For example a privacy alert may describe a system administrator accessing hosted documents of a person one or two hops away from the administrator on a social network i.e. there is one other person separating the person and the administrator . The auditor may read the privacy alert and begin to determine if the actions described in the privacy alert were appropriate. In some cases the auditor may decide that the system administrator was randomly assigned work that required the system administrator to access the hosted document and the system administrator did not know the hosted document was owned by a person one or two hops away from the administrator on a social network. In some cases the auditor may decide that the system administrator did violate the person s privacy.

In another example another privacy alert may describe a different system administrator accessing location data for a person on a white list political activists celebrities etc. . The auditor may determine perhaps after further investigation that the white listed user validly requested assistance with a location based hosted application and the administrator acted correctly or the auditor may determine that the administrator acted incorrectly. In either example privacy alert may contain information about a potential privacy violation which is to be examined by the auditor not a conclusive determination that a privacy violation did occur.

According to the techniques and systems described here multiple domain experts may contribute to the analysis pipeline e.g. by providing one or more analysis modules that may be used to analyze events or groups of events that have been gathered from a number of different applications. For example a domain expert from an email application may provide rules that monitor for abnormal or repeated access of user email attachments by an email administrator a domain expert from a third party social networking system may provide rules that identify an email administrator s social graph and a domain expert from a government agency may provide rules that monitor for violations of the data retention policy of that agency. The analysis modules may be integrated into the pipeline to analyze SARs generated from email service logs. Then based on the processing provided by the modules a report of privacy alerts is generated and presented to an auditor. The report ranks and orders the privacy alerts according to the highest priority possible violations. The ranked reports allow auditors to focus on reviewing higher priority issues first.

The hosted applications may generate application logs . These logs may be collected and submitted to or requested by a SAR generator . The SAR generator may receive the application logs and generate SARs based on some or all of the analysis rules . In some implementations the SAR generator may remove or ignore any of the application logs that are not associated with an administrator user or a user that is normally capable of violating another user s privacy. In other examples not shown the analysis pipeline may receive the SARs directly instead of from the application logs . For example some hosted applications may be configured to generate SARs in addition to or instead of application logs.

The SAR generator may add additional data to a SAR that is not included in the application logs . For example some users may have explicit prohibition from or approval to perform certain actions and the SAR generator may include this approval in any SAR associated with that user.

In some implementations the SARs may be stored in rows in for example a data store organized into tables. The rows of SARs may be organized in reverse time sequence order with column families for efficient filtering. An example schema for the SARs is shown in the Table 1 SAR Schema below.

Some of the fields may be left empty when the SARs are created. For example the feature name fields may be filled by a feature extractor after the SAR generator creates a SAR . Each field may contain string type data or other data types. Some fields may contain multiple entries. These fields have names that include name . For each entry the name portion may be replace with a string that is unique within the field.

The row key field may consist of a shard type of SAR descending time sequence and or other event data that uniquely identifies the SAR. The to do field may record a Boolean value that denotes if the SAR has been processed false or is to be processed true .

The feature name field may contain multiple entries. The name portion may be replaced with a feature generated for that SAR and a float value from 0 to 1. The value is an indication of the potential privacy impact of a feature. An example feature may be break glass event in a log indicating that the event logged is a break glass event. A field feature break glass event may be created with a value of 0.01. The label name field may contain multiple labels extracted from a log . The data access log field may contain the name of the format of the log from which the information in the SAR is extracted. The classification result name field may contain numerical values indexing extracted features.

The property name field may contain multiple strings describing properties of the SAR. A property timestamp may be a human readable timestamp e.g. 20100808 22 23 01.87435 . A property access by may record the user who initiated a data access recorded in the SAR. A property resource name may be the name of the resource access. A property resource owner may be the user that owns or controls the accessed resource.

The audit name field may contain multiple strings describing a current audit involving the SAR. An audit status may describe the status of the audit involving the SAR. An audit auditor my list an auditor performing the audit. An audit notes may contain notes maintained by the auditor. An audit link may contain one or more links to external resources related to the audit such as a bug report software documentation etc. The audit entry field may contain a list of past audits involving the SAR.

An info field may contain multiple strings describing the SAR. An info error may be empty or contain an error message from the processing of the SAR. An info elapsed time processor may contain the time to the SAR. An info debug may contain debugging output for the SAR. An info analysis time may contain a human readable timestamp of when the analysis of the SAR was produced. A report field may contain an additive list of reports that have included the SAR.

The SAR generator may construct a group of SARs into a composite SAR . For example if a group of SARs have the same timestamp are from the same hosted application or are initiated by the same user of multiple hosted applications the SAR generator may group those SARs into a single composite SAR.

The feature extractor may receive the SARs extract features for the SARs from the label name fields of the SAR and store the features in the features name fields of the SARs. This extraction may be performed according to analysis rules created by privacy administrators . For example three SARs may be accessed by the feature extractor . The three SARs may have label name fields of email access userDocumentLoad and browsehistoryreview indicating that they correspond to log entries for administrator access to email user documents and browsing history respectively. One or more privacy administrators may have created analysis rules that map label name fields of email access userDocumentLoad and browsehistoryreview to the same feature admin access of user data. In this case all three of the SARs may be assigned features admin access of user data indicating that each is related to administrator access of user data. Other and more complex analysis rules may be used by the feature extractor and each SAR may be assigned many features by the feature extractor . Once the feature extractor assigns features to SARs those SARs are stored by the feature extractor as SARs with access events .

A feature classifier may receive the SARs with access events and may access the features in the SARs with access events and may classify those features into new features. The new features may be stored with the SARs with access events feature name field to create SARs with classified access events . For example the feature classifier may receive a SAR with access events with the feature name fields feature admin access of social graph neighbor and feature location data access. An analysis rule in the feature classifier may map those two feature name entries to a new feature name entry feature known aquantance physical information indicating that the administrator may have accessed physical information about person the administrator may know. The same analysis rule may include logic to determine the float value to be applied to feature known aquantance physical information. This float value may be based at least in part on the float values of feature admin access of social graph neighbor and feature location data access. 

In some implementations the feature classifier may include both a manual classifier and a machine learning classifier . The manual classifier may include the analysis rules created by the privacy administrators . The previous example of the feature known aquantance physical information feature may be performed by the manual classifier .

The machine learning classifier may generate machine learning based rules for mapping feature name fields to new feature name fields and apply those rules to the SARs with access events . For example the feature classifier may monitor the operations of the manual classifier and the processing of the SARs with classified access events as the SARs with classified access events are processed through the analysis pipeline . Based on those observations the machine learning classifier may generate analysis rules and process the SARs with access events to generate the SARs with classified access events .

Based on the SARs with access events and the SARs with classified access events an alert generator may create alerts . The alert may include human readable information from the SARs with access events and the SARs with classified access events . This human readable information may describe the events in the hosted application recorded in the SARs with access events and the SARs with classified access events .

A given SAR with access events or SARs with classified access events may potentially trigger multiple alerts . For example from one SAR with classified access events one alert may indicate that a hosted application administrator has never logged into on a particular machine before and a separate alert may indicate that the administrator ran a script to attempt to force log in at multiple machines simultaneously.

The alerts may have priority values assigned based on float values of the feature name fields of the SARs with access events and the SARs with classified access events . The alert may indicate how likely it is that a particular behavior is a privacy violation.

An alert server may generate and serve an auditing interface . The auditing interface may display in a human readable graphical user interface GUI a list of alerts . The alerts may be ordered by for example the priority value of each event . An example auditing interface is described in below.

Resource access records are received for analysis by the computer system step . For example the analysis pipeline may receive the application logs from the hosted applications . In some implementations resource access records are associated with another system are received. For example the organization that operates the analysis pipeline may not be the same organization that operates some or all of the hosted applications .

The resource access records correspond to accesses of user resources by an administrator of an application that stores the user resources. For example the application logs may record operations taken by the hosted applications . These operations may be performed at the direction of users of the hosted applications as well as the administrators of the hosted applications .

The resource access records are processed to generate structured audit records that correspond to the resource access records step . For example the application logs may be flat or structured text files. In some implementations application logs for each of the hosted applications may conform to different protocols standards and formats. The SAR generator may receive the application logs in all of these different protocols standards and formats and produce SARs that all conform to the same protocols standards and formats for use thought the analysis pipeline .

The processing includes generating structured audit records from the resource access records from another system. For example the SAR generator may process application logs from third party hosted applications as well as from hosted applications operated by the operator of the analysis pipeline .

The processing includes labeling structured audit records. In some implementations the labels identify specific user accounts and or the labels identify geographic regions associated with specific user accounts. For example data from the application logs including user account information and geographic regions may be parsed by the SAR generator from the application logs and stored in label name fields of the SARs .

The structured audit records include a resource identifier that corresponds to the resource that was accessed and an accessed by identifier that corresponds to the administrator that accessed the resource. Similarly the SAR generator may parse the application logs and store the name of accessed resources and accessed by identifiers in label name fields of the SARs .

The structured audit records are analyzed using a plurality of resource privacy modules that include resource privacy rules that define violation detection scores that define likelihoods of whether one or more resource accesses are problematic step . The analyzing includes analysis that is based at least in part on the labels. For example the SARs and eventually the SARs with access events and the SARs with classified access events may be analyzed by the feature extractor the feature classifier and the alert generator . Each of the feature extractor the feature classifier and the alert generator may comprise a plurality of privacy modules created from analysis rules . In some implementations each analysis rule may be used to create a unique privacy module or all of the analysis rules from a particular privacy administrator may be used to create a single privacy module. The resource privacy modules are provided from two or more different domains. For example the privacy administrators that submit the analysis modules may be associated with different domains.

The violation detection score is based on values of features of the resource access records. For example each feature name field may have a float value from 0 1 associated and those values may be used by the analysis rules to calculate a violation detection score. In some implementations the highest feature name field value may be used directly. In others feature name field values may be some of the values used in a calculation to determine a violation detection score.

A report is generated that includes alerts of problematic resource accesses step . For example a report such as the GUI shown in may be generated by the alert server and presented on the auditing interface . The report is ordered according to the violation detection score. For example the report may include information about multiple SARs with access events and SARs with classified access events and may be presented in the order of the violation detection score. In some implementations all of the SARs with access events and SARs with classified access events may be reported in the report. In other implementation only the SARs with access events and SARs with classified access events with a violation detection score above a threshold are displayed.

Users associated with trusted privacy domains may supply trusted privacy rules to be used in the analysis pipeline . In some implementations the trusted privacy domain users may be independent of the organization that administers the analysis pipeline and may contribute the trusted privacy rules in order to demonstrate that the analysis pipeline conforms to best practices formal regulatory compliance or an impartial third party review. Some example organizations that may be classified as in the trusted privacy domain include government regulators privacy activists and computer security consultants.

Hosted application domain users may supply universal rules . In some implementations such as some when the same organization operates both the analysis pipeline and the hosted applications the hosted application domain users may be system developers and administrators with responsibility for and a deep knowledge of the hosted applications and or the analysis pipeline . The universal rules may be rules that are built based on the structure and behavior of the hosted applications or general privacy best practices and may be applicable for any users of the hosted applications . In other implementations such as when one organization operates the analysis pipeline and one or more different organization operates the hosted applications the developers and administrators of the analysis pipeline may be associated with a trusted privacy domain or an analysis pipeline domain not shown .

Customer domain users may be users that are customers of the hosted applications . In this example customers may include users of no cost hosted applications . A customer domain may include all employees of a particular business government body etc. that use the hosted applications in the course of their work. The customer rules may be rules that only apply to a specific group. For example a human resources department in a company may have medical financial and other sensitive employee information and the customer rules may ensure that data stored in the hosted applications conform to other privacy measures applied to local applications used by the human resources department. In some implementations the customer rules may build on the universal rules and or the trusted privacy rules .

Universal alerts may be alerts created from the trusted privacy rules and the universal rules . The universals alerts may apply for all users of the hosted applications including users in and out of the customer domain . Customer alerts may be alerts created from the trusted privacy rules the universal rules and customer rules . The customer alerts may be created only for users of the hosted applications that fall within the customer domain .

Alert categories may list categories of alerts . For example if the alerts include collections of SARs the alerts may be categorized by fields of the SARs. A user may select e.g. click with a pointer use key presses or tap on a touch screen one of the alert categories and a list of alerts may be displayed in the alert list .

The alert list may display those alerts within the selected alert category . The alerts may be sorted by priority value by default but in some implementations the user may resort on another field. A user may select one of the displayed alerts in the alert list and the details of that alert may be displayed in the alert details .

The memory stores information within the computing system . In some implementations the memory is a computer readable medium. In some implementations the memory is a volatile memory unit. In some implementations the memory is a non volatile memory unit.

The storage device is capable of providing mass storage for the computing system . In some implementations the storage device is a computer readable medium. In various different implementations the storage device may be a floppy disk device a hard disk device an optical disk device or a tape device.

The input output device provides input output operations for the computing system . In some implementations the input output device includes a keyboard and or pointing device. In some implementations the input output device includes a display unit for displaying graphical user interfaces.

Some features described may be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The apparatus may be implemented in a computer program product tangibly embodied in an information carrier e.g. in a machine readable storage device for execution by a programmable processor and method steps may be performed by a programmable processor executing a program of instructions to perform functions of the described implementations by operating on input data and generating output. The described features may be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that may be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program may be written in any appropriate form of programming language including compiled or interpreted languages and it may be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer will also include or be operatively coupled to communicate with one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM erasable programmable read only memory EEPROM electrically erasable programmable read only memory and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM compact disc read only memory and DVD ROM digital versatile disc read only memory disks. The processor and the memory may be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with a user some features may be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user may provide input to the computer.

Some features may be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system may be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include e.g. a LAN local area network a WAN wide area network and the computers and networks forming the Internet.

The computer system may include clients and servers. A client and server are generally remote from each other and typically interact through a network such as the described one. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

Computing device can be communicatively coupled to input user interface and output device interface . Either one or both of input user interface and output device interface can be wired or wireless interface and can be detachable. Input user interface may include any device component sensor or interface physical or virtual that can be used to provide input e.g. keyboard a pointing cursor control microphone camera braille motion sensor optical reader or the like . Output device interface may include a display monitor printer speaker braille or the like. In some example embodiments input user interface and output device interface can be embedded with or physically coupled to computing device e.g. a mobile computing device with buttons or touch screen input user interface and an output or printing display or a television .

Computing device can be communicatively coupled to external storage and network for communicating with any number of networked components devices and systems including one or more computing devices of same or different configuration. Computing device or any connected computing device can be functioning as providing services of or referred to as a server client thin server general machine special purpose machine system computer system or by other label.

I O interface can include but is not limited to wired and or wireless interfaces using any communication or I O protocols or standards e.g. Ethernet 802.11x Universal System Bus WiMax modem a cellular network protocol and the like for communicating information to and or from at least all the connected components devices and network in computing environment . Network can be any network or combination of networks e.g. the Internet local area network wide area network a telephonic network a cellular network satellite network and the like .

Computing device can use and or communicate using computer usable or computer readable media including transitory media and non transitory media. Transitory media include transmission media e.g. metal cables fiber optics signals carrier waves and the like. Non transitory media include magnetic media e.g. disks and tapes optical media e.g. CD ROM digital video disks Blu ray disks solid state media e.g. RAM ROM flash memory solid state storage and other non volatile storage or memory.

Computing device can be used to implement techniques methods applications processes or computer executable instructions to implement at least one embodiment e.g. a described embodiment . Computer executable instructions can be retrieved from transitory media and stored on and retrieved from non transitory media. The executable instructions can be originated from one or more of any programming scripting and machine languages e.g. C C C Java Visual Basic Python Perl JavaScript and others .

Processor s can execute under any operating system OS not shown in a native or virtual environment. To implement a described embodiment one or more applications can be deployed that include logic unit application programming interface API unit input unit output unit records processing unit analysis unit report generation unit and inter unit communication mechanism for the different units to communicate with each other with the OS and with other applications not shown . For example records processing unit analysis unit and report generation unit may implement process sequence . The described units and elements can be varied in design function configuration or implementation and are not limited to the descriptions provided.

In some example embodiments when information or an execution instruction is received by API unit it may be communicated to one or more other units e.g. logic unit input unit output unit records processing unit analysis unit and report generation unit . For example after input unit has read one or more records input unit may use API unit to communicate the records to records processing unit . Records processing unit may via API unit interact with the analysis unit to create SARs. Using API unit analysis unit may interact with report generation unit to generate one or more reports and or alerts.

In some examples logic unit may be configured to control the information flow among the units and direct the services provided by API unit input unit output unit records processing unit analysis unit and report generation unit in order to implement an embodiment described above. For example the flow of one or more processes or implementations may be controlled by logic unit alone or in conjunction with API unit .

This foregoing disclosure includes storage of information about instances of access that are made to pieces of data stored by a computer system. Such stored information can be aggregated filtered and otherwise managed to produce useful statistics and other data about the manner in which accesses have occurred whether in individual instances or in groups. For example engineers or researches may create rules to be applied to such data in order to identify anomalies in the data that might indicate particular illegitimate accesses or groupings or trends in the data that represent situations that might be of concern from a security or privacy standpoint. An organization that manages the data may add such rules to an overall rules set that is applied to additional data including by being applied prospectively so as to identify and potentially block requests for access that have been determined to have an illegitimate character to them e.g. the requests can be blocked totally or a requester may be asked for additional identification or verification data before access will be granted to them . In addition the rules may be used to generate alerts that can be reviewed manually by an administrator of such a system so as to determine whether such accesses were legitimate and whether system access policies should be adjusted.

Various implementations of the foregoing subject matter described here may in some cases provide one or more of the following advantages. An analysis pipeline as described here may be used provide detailed systematic review of privacy events that occur for a number of different applications. An analysis pipeline may allow publicly trusted third parties to set privacy policies that may be encapsulated in modules used by an analysis pipeline. A customer may receive individualized privacy alerts related specifically to that customer s requirements. Applying freeform labels in data access records may allow a wide range of alert reports with less memory allocation than is needed for binary flags. An analysis pipeline with support for module rule logic may support rules written by people with no knowledge the analysis pipeline or the types of events that are analyzed by the pipeline.

Although a few example embodiments have been shown and described these example embodiments are provided to convey the subject matter described herein to people who are familiar with this field. It should be understood that the subject matter described herein may be embodied in various forms without being limited to the described example embodiments. The subject matter described herein can be practiced without those specifically defined or described matters or with other or different elements or matters not described. It will be appreciated by those familiar with this field that changes may be made in these example embodiments without departing from the subject matter described herein as defined in the appended claims and their equivalents.

