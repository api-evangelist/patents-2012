---

title: Device and method for processing user input
abstract: A method for generating display data comprises detecting user input via an input interface. A processor is in communication with the input interface to generate display data comprising a display object for display by a display device. The display object is representative of an action that will subsequently be performed by the processor on continuation of the user input. The display data on the display device is output while the user input is being detected. Alternatively, the display object is caused to appear on the display device over time as the user input is being performed, wherein the rate at which the display object appears is different to the rate of performance of the user input. A device and executable computer program for performing the steps of the method is also provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09128598&OS=09128598&RS=09128598
owner: BlackBerry Limited
number: 09128598
owner_city: Waterloo, Ontario
owner_country: CA
publication_date: 20120717
---
This application is a continuation of U.S. patent application Ser. No. 13 460 270 filed Apr. 30 2012 the entire contents of which is hereby incorporated by reference herein.

Electronic devices may increasingly be controlled using a wide variety of input types. For example gesture based user interfaces enable a user to control the device using gestures such as swipes across a touchscreen interface. However a common problem found with such user interfaces is how to inform a user of the inputs required to interact with and control the device. Users unaware of the required inputs will not be able to interact effectively with the device and may accidentally activate input commands resulting in undesired actions being performed by the device.

Furthermore precise input commands such as selection of discreet icons or buttons requires a level of precision that is beyond the capabilities of users who are unfamiliar with such user interfaces unable to view or concentrate on the screen or unable to execute the required motions with the necessary precision.

In a first aspect there is provided a method for generating display data. The method comprises detecting user input via an input interface the user input comprising a first input and operating a processor in communication with the input interface to generate display data comprising a display object for display by a display device wherein the display object is representative of an action that will subsequently be performed by the processor on completion of the first input and operating the processor to output the display data on the display device whilst a common initial input of the first input is being detected.

In one example the first input comprises a first additional input which is detectable by the processor after the common initial input. As discussed below in more detail the common initial input may comprise a swipe gesture across a touchscreen interface performed using a finger or stylus and the first additional input may comprise removing the finger or stylus from the touchscreen interface. In general the first additional input may simply be the step that completes the first input at the end of the common initial input.

The display object may be representative of the first additional input which must be detected by the processor for it to determine that the user input comprises the first input.

The user input may comprise a second input in response to which the processor does not perform the action the second input also comprising the common initial input.

In addition to the common initial input the second input may also comprise a second additional input which is detectable by the processor after the common initial input wherein the first additional input and the second additional input are different.

The processor may further operate to determine whether completion of the first input has occurred and perform the action only if completion of the first input is detected. For example if the processor detects the common initial input and the first additional input the processor determines that the first input has been completed and the action will be performed by the processor. On the other hand if the processor detects that the common initial input and the second additional input the processor determines the second user input and that the first user input has not been completed in which case the processor does not perform the action.

The processor may generate the display data in such a way that the display object is caused to appear on the display device as the common initial input is being performed wherein the rate at which the display object appears is different to the rate of detection of the common initial input. The rate at which the display object appears may be greater i.e. faster that the rate of performance of the common initial input. This permits a user to acquire additional information concerning their action when providing user input which might not otherwise be available if the information were to appear on the display at the same rate as the user input is performed.

The display object may be representative of an extent of completion of the common initial input. The display object may additionally be representative of an extent of completion of the first input.

The action may correspond to selection of media content such as audio or video content in which case the processor outputs the media content. In this case the display object may be representative of the media content.

The user interface may be a touchscreen interface the user input comprise a swipe gesture across the touchscreen interface and the action comprise modifying a current output of media content for example by pausing output of the media content.

In a second aspect there is provided a method for generating display data the method comprising detecting user input via an input interface the user input comprising a first input and operating a processor in communication with the input interface to generate display data comprising a display object for display by a display device wherein the display object is representative of content that will subsequently be output on completion of the first user input and output the display data on the display device whilst a common initial input of the first input is being detected in such a way that the display object is caused to appear on the display device as the user input is being detected wherein the rate at which the display object appears is different to the rate of detection of the common initial input. For example the display object may appear at a faster rate than the rate at which the processor detects the user input via the input interface. This permits a user to acquire additional information concerning their action when providing user input which might not otherwise be available if the information were to appear on the display at the same rate as the user input is performed.

In a third aspect there is provided a method for modifying an output of media content the method comprising operating a processor to cause an output of media content detecting user input via a touchscreen interface the user input comprising a swipe gesture across the touchscreen interface and operating the processor responsive to the user input to cause a first modification of the output of the media content.

The user input may comprise a vertical swipe gesture across the touchscreen interface in a first direction.

The processor may detect second user input via the input interface. The second user input may comprise a vertical swipe gesture across the touchscreen interface in a second direction opposite to the first direction and the processor may perform the reverse of the first modification in response to the second user input detected.

In a fourth aspect there is provided a computer readable medium comprising executable instructions which when executed cause the processor to perform the above methods.

In a fifth aspect there is provided a device for generating display data the device comprising an input interface configured to detect user input the user input comprising a first input a processor in communication with the input interface the processor being configured to generate display data comprising a display object for display by a display device wherein the display object is representative of an action that will subsequently be performed by the processor on completion of the first input and output the display data on the display device whilst a common initial input of the first input is being detected. The device may be an electronic device as described further below.

In one example the processor is configured to detect if the first input comprises a first additional input which is detectable by the processor after the common initial input.

The processor may be additionally configured to generate the display data such that the display object is representative of the first additional input which must be detected by the processor for it to determine that the user input comprises the first input.

The processor may be additionally configured to determine if the user input comprises a second input in response to which the processor does not perform the action the second input also comprising the common initial input.

The processor may be additionally configured to detect if the second input comprises a second additional input after the common initial input wherein the first additional input and the second additional input are different.

The processor may be additionally configured to determine whether completion of the first input has occurred and perform the action only if completion of the first input has occurred.

The processor may be additionally configured to generate the display data in such a way that the display object is caused to appear on the display device as the common initial input is being detected wherein the rate at which the display object appears is faster than the rate of detection of the common initial input. The display object may representative of one or more of an extent of completion of the common initial input an extent of completion of the first input or further user input required for the processor to determine that the user input comprises the first input.

The processor may be configured to perform an action corresponding to selection of media content and additionally to output the media content. In this case the display object may be representative of the media content.

The user interface of the device may be a touchscreen interface the user input comprise a swipe gesture across the touchscreen interface and the processor may be configured to perform an action comprising modifying a current output of media content for example by pausing output of the media content.

In a sixth aspect there is provided a device for generating display data the device comprising an input interface for detecting user input the user input comprising a first input and a processor in communication with the input interface the processor being configured to generate display data comprising a display object for display by a display device wherein the display object is representative of content that will subsequently be output on completion of the user input and output the display data on the display device whilst a common initial input of the first input is being detected in such a way that the display object is caused to appear on the display device as the user input is being performed wherein the rate at which the display object appears is different to the rate of detection of the user input. The device may be an electronic device as described further below.

In a seventh aspect there is provided a device comprising a touchscreen interface configured to detect user input the user input comprising a swipe gesture across the touchscreen interface and a processor configured to cause an output of media content and to cause a first modification of the output of the media content responsive to the user input. The device may be an electronic device as described further below.

The processor may be configured to detect user input comprising a vertical swipe gesture across the touchscreen interface in a first direction.

The processor may be further configured to detect second user input via the input interface the second user input comprising a vertical swipe gesture across the touchscreen interface in a second direction opposite to the first direction and the processor may perform the reverse of the first modification in response to the second user input detected. In one example the first modification comprises pausing output of the media content.

This disclosure below is a description of one or more exemplary embodiments which are not intended to be limiting on the scope of the appended claims.

Reference is made to which illustrates an exemplary electronic device which is usable in accordance with the disclosure below. An electronic device such as the electronic device of is configured to generate a user controllable interface on a built in display or on a remote external display device or on a built in display and on a remote external display device. In the context of this disclosure the term remote means a display screen which is not built in to the electronic device with which the electronic device communicates via a physical wired connection or via a wireless connection.

It will be appreciated that in other embodiments some of the features systems or subsystems of the electronic device discussed below with reference to may be omitted from electronic devices which are intended to perform solely operations in relation to the generation and output of display data and the modification of media content output.

In the illustrated exemplary embodiment the electronic device is a communication device and more particularly is a mobile communication device having data and voice communication capabilities and the capability to communicate with other computer systems for example via the Internet. It will be appreciated that the electronic device may take other forms including any one of the forms listed below. Depending on the functionality provided by the electronic device in certain exemplary embodiments the electronic device is a multiple mode communication device configured for both data and voice communication a mobile telephone such as a smartphone a wearable computer such as a watch a tablet computer a personal digital assistant PDA or a computer system such as a notebook laptop or desktop system. The electronic device may take other forms apart from those specifically listed above. The electronic device may also be referred to as a mobile communications device a communication device a mobile device and in some cases as a device. In the context of this disclosure the term mobile means the device is of a size or weight which makes it readily portable by a single individual e.g. of a weight less than 5 4 3 2 1 0.5 0.4 0.3 0.2 or 0.1 kilograms or of a volume less than 15 000 10 000 5 000 4 000 3 000 2 000 1 000 500 400 300 200 100 90 80 70 60 50 40 30 20 10 or 5 cubic centimeters. As such the device may be portable in a bag or clothing pocket.

The electronic device includes a controller including a processor such as a microprocessor which controls the operation of the electronic device . In certain electronic devices more than one processor is provided with each processor in communication with each other and configured to perform operations in parallel so that they together control the overall operation of the electronic device. The processor interacts with device subsystems such as a wireless communication subsystem for exchanging radio frequency signals with a wireless network to perform communication functions. The processor is communicably coupled with additional device subsystems including one or more output interfaces such as one or more of a display a speaker electromagnetic EM radiation source one or more input interfaces such as one or more of a camera microphone keyboard not shown control buttons not shown a navigational input device not shown a touch sensitive overlay not shown associated with a touchscreen an orientation subsystem memory such as flash memory random access memory RAM read only memory ROM etc. auxiliary input output I O subsystems a data port which may be a serial data port such as a Universal Serial Bus USB data port an external video output port a near field communications NFC subsystem a short range communication subsystem a clock subsystem a battery interface and other device subsystems generally designated as . Some of the subsystems shown in perform communication related functions whereas other subsystems may provide resident or on device functions.

The electronic device stores data in an erasable persistent memory which in one exemplary embodiment is the flash memory . In various exemplary embodiments the data includes service data including information used by the electronic device to establish and maintain communication with the wireless network . The data may also include user application data such as email messages address book and contact information calendar and schedule information notepad documents presentation documents and information word processor documents and information spread sheet documents and information desktop publishing documents and information database files and information image files video files audio files internet web pages and other commonly stored user information stored on the electronic device by its user and other data. The data may also include program application data such as functions controls and interfaces from an application such as an email application an address book application a calendar application a notepad application a presentation application a word processor application a spread sheet application a desktop publishing application a database application a media application such as a picture viewer a video player or an audio player and a web browser. The data stored in the persistent memory e.g. flash memory of the electronic device may be organized at least partially into one or more databases or data stores. The databases or data stores may contain data items of the same data type or associated with the same application. For example email messages contact records and task items may be stored in individual databases within the device memory.

The electronic device includes a clock subsystem or module comprising a system clock configured to measure system time. In one example the system clock comprises its own alternate power source. The system clock provides an indicator of a current time value the system time represented as a year month day hour minute second milliseconds value. In other examples the clock subsystem additionally or alternatively provides an indicator of the current time value represented as a count of the number of ticks of known duration since a particular epoch.

The clock subsystem the communication subsystem the NFC subsystem the short range wireless communications subsystem and the battery interface together form a status report subsystem which is configured to provide an indicator of the operating status of the device.

The display receives display data generated by the processor such that the display displays certain application data stored as a segment of the data from the memory any of the flash memory random access memory RAM read only memory ROM in a predetermined way on display screen not shown of the display according to the processing performed by the processor .

In certain exemplary embodiments the external video output port is integrated with the data port . The external video output port is configured to connect the electronic device via a wired connection e.g. video graphics array VGA digital visual interface DVI or high definition multimedia interface HDMI to an external or remote display device which is separate and remote from the electronic device and its display . The processor outputs external display data generated by the processor via the external video output port such that the external display device can display application data from the memory module in a predetermined way on an external display screen not shown of the external display device . The processor may also communicate the external display data to the external display device in a similar fashion over a wireless communications path.

At any given time the display data and the external display data generated by the processor may be identical or similar for a predetermined period of time but may also differ for a predetermined period of time with the processor controlling whether the display data and the external display data are identical or differ based on input from one or more of the input interfaces . In this context the word identical means that both sets of data comprise similar content so as to generate an identical or substantially similar display at substantially the same time on both the external display device and the display . In this context the word differ means that the external display data and display data are not identical this is to say that these data may but not necessarily include identical elements of data for example representative of the same application data but the external display data and display data are not wholly identical. Hence the display on both the external display device and the display are not wholly identical although similar or identical individual items of content based on the application data may be displayed on both the external display device and the display .

In at least some exemplary embodiments the electronic device includes a touchscreen which acts as both an input interface e.g. touch sensitive overlay and an output interface i.e. display . The touchscreen may be constructed using a touch sensitive input surface which is connected to an electronic controller and which overlays the display . The touch sensitive overlay and the electronic controller provide a touch sensitive input interface and the processor interacts with the touch sensitive overlay via the electronic controller.

As discussed in detail below with respect to the processor is in communication with the memory and the touch sensitive input interface to detect user input via the input interface . The processor then generates or updates display data comprising a display object for display by the display device in accordance with the user input. The display object may be representative of an action that will subsequently be performed by the processor on continuation of the user input. Additionally or alternatively the display object may be representative of content that will be output on continuation of the user input. The processor then outputs the display data for display on the display device . Additionally or alternatively the processor may modify a current output of media in accordance with user input detected via the touchscreen interface . In an example the user input comprises a swipe gesture across the touchscreen interface .

In at least some exemplary embodiments the touch sensitive overlay has a touch sensitive input surface which is larger than the display . For example in at least some exemplary embodiments the touch sensitive overlay may extend overtop of a frame not shown which surrounds the display . In such exemplary embodiments the frame not shown may be referred to as an active frame since it is capable of acting as an input interface . In at least some exemplary embodiments the touch sensitive overlay may extend to the sides of the electronic device .

As noted above in some exemplary embodiments the electronic device includes a communication subsystem which allows the electronic device to communicate over a wireless network . The communication subsystem includes a receiver a transmitter and associated components such as one or more antenna elements and local oscillators LOs and a processing module such as a digital signal processor DSP which is in communication with the processor . The antenna elements and may be embedded or internal to the electronic device and a single antenna may be shared by both receiver and transmitter. The particular design of the wireless communication subsystem depends on the wireless network in which electronic device is intended to operate.

In at least some exemplary embodiments the electronic device communicates with any one of a plurality of fixed transceiver base stations of the wireless network within its geographic coverage area. The electronic device may send and receive communication signals over the wireless network after the required network registration or activation procedures have been completed. Signals received by the antenna through the wireless network are input to the receiver which may perform such common receiver functions as signal amplification frequency down conversion filtering channel selection etc. as well as analog to digital ND conversion. A D conversion of a received signal allows more complex communication functions such as demodulation and decoding to be performed in the DSP . In a similar manner signals to be transmitted are processed including modulation and encoding for example by the DSP . These DSP processed signals are input to the transmitter for digital to analog D A conversion frequency up conversion filtering amplification and transmission to the wireless network via the antenna . The DSP not only processes communication signals but may also provide for receiver and transmitter control. For example the gains applied to communication signals in the receiver and the transmitter may be adaptively controlled through automatic gain control algorithms implemented in the DSP .

In some exemplary embodiments the auxiliary input output I O subsystems include an external communication link or interface for example an Ethernet connection. The electronic device may include other wireless communication interfaces for communicating with other types of wireless networks for example a wireless network such as an orthogonal frequency division multiplexed OFDM network. The auxiliary I O subsystems may include a vibrator for providing vibratory notifications in response to various events on the electronic device such as receipt of an electronic communication or incoming phone call or for other purposes such as haptic feedback touch feedback .

In some exemplary embodiments the electronic device also includes a removable memory module typically including flash memory such as a removable memory card and a memory interface . Network access may be associated with a subscriber or user of the electronic device via the memory module which may be a Subscriber Identity Module SIM card for use in a GSM network or other type of memory card for use in the relevant wireless network type. The memory module is inserted in or connected to the memory card interface of the electronic device in order to operate in conjunction with the wireless network .

The data port may be used for synchronization with a user s host computer system not shown . The data port enables a user to set preferences through an external device or software application and extends the capabilities of the electronic device by providing for information or software downloads to the electronic device other than through the wireless network . The alternate download path may for example be used to load an encryption key onto the electronic device through a direct reliable and trusted connection to thereby provide secure device communication.

In at least some exemplary embodiments the electronic device also includes a device orientation subsystem including at least one orientation sensor which is connected to the processor and which is controlled by one or a combination of a monitoring circuit and operating software. The orientation sensor detects the orientation of the device or information from which the orientation of the device can be determined such as acceleration. In some exemplary embodiments the orientation sensor is an accelerometer such as a three axis accelerometer. An accelerometer is a sensor which converts acceleration from motion e.g. movement of the device or a portion thereof due to the strike force and gravity which are detected by a sensing element into an electrical signal producing a corresponding change in output . Accelerometers may be available in one two or three axis configurations. Higher order axis configurations are also possible. Accelerometers may produce digital or analog output signals depending on the type of accelerometer.

An orientation sensor may generate orientation data which specifies the orientation of the electronic device . The orientation data in at least some exemplary embodiments specifies the orientation of the device relative to the gravitational field of the earth. Additionally or alternatively the orientation sensor may generate orientation data which specifies the orientation of the device relative to known locations or fixtures in a communication network.

In some exemplary embodiments the orientation subsystem includes other orientation sensors instead of or in addition to accelerometers. For example in various exemplary embodiments the orientation subsystem may include a gravity sensor a gyroscope a tilt sensor an electronic compass or other suitable sensor or combinations thereof. In some exemplary embodiments the device orientation subsystem may include two or more orientation sensors such as an accelerometer and an electronic compass.

The electronic device in at least some exemplary embodiments includes a Near Field Communication NFC subsystem . The NFC subsystem is configured to communicate with other electronic devices or tags using an NFC communications protocol. NFC is a set of short range wireless technologies which typically require a distance of 4 cm or less for communications. The NFC subsystem may include an NFC chip and an NFC antenna. In such an embodiment the orientation sensor may generate data which specifies a distance between the electronic device and an NFC transceiver.

The electronic device includes a microphone or one or more speakers. In at least some exemplary embodiments an electronic device includes a plurality of speakers . For example in some exemplary embodiments the electronic device includes two or more speakers . The two or more speakers may for example be disposed in spaced relation to one another. That is in at least some exemplary embodiments the electronic device may include a first speaker and a second speaker and the first speaker and the second speaker may be spatially separated from one another within the electronic device . In at least some exemplary embodiments the display may be disposed between the first speaker and the second speaker of the electronic device. In such exemplary embodiments the first speaker may be located at one side of the display and the second speaker may be located at another side of the display which is opposite the side of the display where the first speaker is located. For example the first speaker may be disposed at a left side of the display and the second speaker may be disposed at a right side of the display.

In at least some exemplary embodiments each speaker is associated with a separate audio channel. The multiple speakers may for example be used to provide stereophonic sound which may also be referred to as stereo .

The electronic device may also include one or more cameras . The one or more cameras may be capable of capturing images in the form of still photographs or motion video.

In at least some exemplary embodiments the electronic device includes a front facing camera . A front facing camera is a camera which is generally located on a front face of the electronic device . The front face is typically the face on which a display is mounted. That is the display is configured to display content which may be viewed from a side of the electronic device where the camera is directed. The front facing camera may be located anywhere on the front surface of the electronic device for example the camera may be located above or below the display . The camera may be a fixed position camera which is not movable relative to the display of the electronic device or the housing of the electronic device . In such exemplary embodiments the direction of capture of the camera is always predictable relative to the display or the housing. In at least some exemplary embodiments the camera may be provided in a central location relative to the display to facilitate image acquisition of a face.

In at least some exemplary embodiments the electronic device includes an electromagnetic EM radiation source . In at least some exemplary embodiments the EM radiation source is configured to emit electromagnetic radiation from the side of the electronic device which is associated with a camera of that electronic device . For example where the camera is a front facing camera the electronic device may be configured to emit electromagnetic radiation from the front face of the electronic device . That is in at least some exemplary embodiments the electromagnetic radiation source is configured to emit radiation in a direction which may visible by the camera. That is the camera and the electromagnetic radiation source may be disposed on the electronic device so that electromagnetic radiation emitted by the electromagnetic radiation source is visible in images detected by the camera.

In some exemplary embodiments the electromagnetic radiation source is an infrared IR radiation source which is configured to emit infrared radiation. In at least some exemplary embodiments the electromagnetic radiation source may be configured to emit radiation which is not part of the visible spectrum. The camera may be a camera which is configured to capture radiation of the type emitted by the electromagnetic radiation source . Accordingly in at least some exemplary embodiments the camera is configured to capture at least some electromagnetic radiation which is not in the visible spectrum.

In some exemplary embodiments the electronic device is provided with a service routing application programming interface API which provides an application with the ability to route traffic through a serial data i.e. USB or Bluetooth Bluetooth is a registered trademark of Bluetooth SIG Inc. connection to a host computer system using standard connectivity protocols. When a user connects their electronic device to the host computer system via a USB cable or Bluetooth connection traffic that was destined for the wireless network is automatically routed to the electronic device using the USB cable or Bluetooth connection. Similarly any traffic destined for the wireless network is automatically sent over the USB cable Bluetooth connection to the host computer system for processing.

The electronic device also includes a battery as a power source which is typically one or more rechargeable batteries that may be charged for example through charging circuitry coupled to a battery interface such as the data port . The battery provides electrical power to at least some of the electrical circuitry in the electronic device and the battery interface provides a mechanical and electrical connection for the battery . The battery interface is coupled to a regulator not shown which provides power V to the circuitry of the electronic device .

The electronic device includes a short range communication subsystem which provides for wireless communication between the electronic device and other electronic devices . In at least some exemplary embodiments the short range communication subsystem is a wireless bus protocol compliant communication mechanism such as a Bluetooth communication module to provide for communication with similarly enabled systems and devices.

Any one or more of the communication subsystem the NFC subsystem and the short range wireless communications subsystem serves as a communication subsystem which is configured to provide an indicator of the number of incoming messages being received by the electronic device . The incoming messages may be emails messages received via a social networking website SMS short message service messages or telephone calls for example.

The electronic device is in some exemplary embodiments a mobile communication device which may provide two principal modes of communication a data communication mode and a voice communication mode. In the data communication mode a received data signal such as a text message an email message or Web page download will be processed by the communication subsystem and input to the processor for further processing. For example a downloaded Web page may be further processed by a browser application or an email message may be processed by an email messaging application and output to the display . A user of the electronic device can compose data items such as email messages for example using the input devices in conjunction with the display . These composed items may be transmitted through the communication subsystem over the wireless network .

In the voice communication mode the electronic device provides telephony functions and operates as a typical cellular phone. The overall operation is similar except that the received signals would be output to the speaker and signals for transmission would be generated by a transducer such as the microphone . The telephony functions are provided by a combination of software firmware i.e. a voice communication module and hardware i.e. the microphone the speaker and input interfaces . Alternative voice or audio I O subsystems such as a voice message recording subsystem may also be implemented on the electronic device . Although voice or audio signal output is typically accomplished primarily through the speaker the display screen may also be used to provide an indication of the identity of a calling party duration of a voice call or other voice call related information.

The processor operates under stored program control and executes software modules stored in memory such as persistent memory for example in the flash memory . As illustrated in the software modules include operating system software and other software applications such as a media player module . In the exemplary embodiment of the media player module is implemented as a stand alone application . However in other exemplary embodiments the presentation module could be implemented as part of the operating system or other applications .

As discussed above electronic devices which are configured to perform operations in relation to a communications log may take a variety of forms. In at least some exemplary embodiments one or more of the electronic devices which are configured to perform operations in relation to the presentation module are a smart phone or a tablet computer.

Referring now to a front view of an exemplary electronic device which in one example may be a smartphone is illustrated. The smartphone is a mobile phone which offers more advanced computing capability than a basic non smartphone cellular phone. For example the smartphone may have the ability to run third party applications which are stored on the smartphone.

The smartphone includes all of the components discussed above with reference to or a subset of those components. The smartphone includes a housing which houses at least some of the components discussed above with reference to .

In the exemplary embodiment the smartphone includes a display which may be a touchscreen which acts as an input interface . The display is disposed within the smartphone so that it is viewable at a front side of the smartphone . That is a viewable side of the display is disposed on the front side of the smartphone. In the exemplary embodiment illustrated the display is framed by the housing .

The example smartphone also includes other input interfaces such as one or more buttons keys or navigational input mechanisms. In the example illustrated at least some of these additional input interfaces are disposed for actuation at a front side of the smartphone.

The example smartphone also includes a speaker . In the exemplary embodiment illustrated the smartphone includes a single speaker which is disposed vertically above the display when the smartphone is held in a portrait orientation where its height is longer than its width. The speaker may be disposed on the front face of the smartphone .

While the example smartphone of includes a single speaker in other exemplary embodiments the smartphone may include a greater number of speakers . For example in at least some exemplary embodiments the smartphone may include a second speaker which is disposed vertically below the display when the smartphone is held in a portrait orientation where its height is longer than its width i.e. the orientation illustrated in .

The example smartphone also includes a microphone . In the example illustrated the microphone is vertically disposed below the display when the smartphone is held in the portrait orientation. The microphone and at least one speaker may be arranged so that the microphone is in close proximity to a user s mouth and the speaker is in close proximity to a user s ear when the user holds the phone to their face to converse on the smartphone.

The example smartphone also includes a front facing camera which may be located vertically above the display when the smartphone is held in a portrait orientation where its height is longer than its width. The front facing camera is located so that it may capture images of objects which are located in front of or surrounding the front side of the smartphone .

The example smartphone also includes an electromagnetic radiation source . The electromagnetic radiation source is disposed on the front side of the smartphone . In this orientation electromagnetic radiation which is produced by the electromagnetic radiation source may be projected onto objects which are located in front of or surrounding the front side of the smartphone . Such electromagnetic radiation or the projection of electromagnetic radiation onto objects may be captured on images detected by the camera .

Referring now to a front view of an example electronic device which in one example may be a tablet computer is illustrated. The tablet computer may include the components discussed above with reference to or a subset of those components. The tablet computer includes a housing which houses at least some of the components discussed above with reference to .

The tablet computer includes a display which may be a touchscreen which acts as an input interface . The display is disposed within the tablet computer so that it is viewable at a front side of the tablet computer . That is a viewable side of the display is disposed on the front side of the tablet computer . In the exemplary embodiment illustrated the display is framed by the housing .

A frame surrounds the display . The frame is portion of the housing which provides a border around the display . In at least some exemplary embodiments the frame is an active frame . That is the frame has a touch sensitive overlay which allows the electronic device to detect a touch applied to the frame thus allowing the frame to act as an input interface .

The exemplary tablet computer includes a plurality of speakers . In the exemplary embodiment illustrated the tablet includes two speakers . The two speakers are disposed on opposing sides of the display . More particularly when the tablet computer is held in a landscape orientation such as the orientation illustrated in where its width is longer than its height one of the two speakers is disposed on a right side of the display and one of the speakers is disposed on the left side of the display .

The exemplary tablet computer also includes a microphone . In the example illustrated the microphone is vertically disposed below the display when the tablet computer is held in the landscape orientation illustrated in . The microphone may be located in other locations in other exemplary embodiments.

The exemplary tablet computer also includes a front facing camera which may be located vertically above the display when the tablet computer is held in a landscape orientation i.e. the orientation of . The front facing camera is located so that it may capture images of objects which are located in front of or surrounding the front side of the tablet computer .

The example tablet computer also includes an electromagnetic radiation source . The electromagnetic radiation source is disposed on the front side of the tablet computer . In this orientation electromagnetic radiation which is produced by the electromagnetic radiation source may be projected onto objects which are located in front of or surrounding the front side of the tablet computer . Such electromagnetic radiation or the projection of electromagnetic radiation onto objects may be captured on images detected by the camera .

The tablet computer may have the ability to run third party applications which are stored on the tablet computer.

The electronic device which may be tablet computer is usable by an end user to send and receive communications using electronic communication services supported by a service provider.

The end user of an electronic device may send and receive communications with different entities using different electronic communication services. Those services may or may not be accessible using one or more particular electronic devices. For example a communication source of an end user s text messages sent and received by an end user using a particular electronic device having a particular memory module such as a USIM may be accessible using that device but those text messages may not be accessible using another device having a different memory module. Other electronic communication sources such as a web based email account may be accessible via a web site using a browser on any internet enabled electronic device.

Servers and are also connected to the Internet and one or more of them may individually or together support electronic communications services available to end users of electronic devices and enabling them to send and receive electronic communications. Servers and may be web servers or communications servers such as email servers.

Other servers and services may of course be provided allowing users of electronic devices and to send and receive electronic communications by for example Voice over IP phone calls video IP calls video chat group video chat blogs file transfers instant messaging and feeds.

Wireless network may also support electronic communications without using Internet . For example a user of smart phone may use wireless network to make telephony calls video calls send text messages send multimedia messages and send instant messages to smart phone and to display application data on a display screen of the external display device or control the display of application data.

The example shown in is intended to be non limiting and additional network infrastructure may of course be provided such as a Public Switched Telephone Network not shown which may be used for example to make telephony calls using smartphone to a wired phone not shown .

The input interface may also comprise the touchscreen in which case the electronic device may be referred to as a multi touch device . The input detected by the touchscreen interface may comprise any suitable user touch based input. For example the input may comprise a gesture input such as a tap a multi tap a long press a swipe or scroll or slide a pan a flick a multi swipe a multi finger tap a multi finger scroll or swipe a pinch a two hand pinch a spread a two hand spread a rotation a two hand rotation a slide and rotation a multi direction slide a multi finger slide and rotation a multi finger slide etc. It will be appreciated that the gesture input may comprise a sequence of input elements or stages performed within a specified or predetermined time frame for example a three tap gesture in which each tap comprises an element or a sub input a phase or a stage of the input and the three taps are performed within a time frame that enables the processor to detect the taps as elements of a single input. Additionally or alternatively an input may comprise removing a point of contact e.g. a finger or stylus from the touchscreen interface.

Although many examples described herein refer to a gesture detected by a touch sensitive display other methods of gesture detection may be utilized. For example a gesture may be a generalized trajectory description characterized as a sequence of 3D points in time and as such many different sensors may be utilized to detect such a gesture. The gesture may be performed by moving a portable electronic device or moving one or more body parts such as fingers or thumbs as a 3D spatial gesture. For example sensors such as an accelerometer gyroscope or proximity sensors or time of flight cameras may detect such gestures. Gesture recognition and detection techniques of this type are known.

An accelerometer or gyroscope may be utilized to detect 3D spatial gestures. A sequence of acceleration values may be detected in the different spatial dimensions as a function of time and constitute trajectory information that can be recognized as a gesture. For example a quick flick or tilt of the portable electronic device are examples of detectable gestures. A 3D spatial gesture includes a continuous movement a sequence of movements and a series of continuous movements or sequences of movements. Proximity sensors optical sensors and or cameras may be utilized to detect 3D spatial gestures comprising motion of objects spaced from the device.

A gesture input is different to input of a command by manipulation of a control component presented on the screen because a gesture input can be performed at any location within the display screen or a large area of the display screen in contrast to a single contact point for a user finger or input stylus on a corresponding control element. In order to input a command using a control component the user must contact the screen at a specific location corresponding to that component. For example in order to change an output volume using a volume control the user must select the volume control by touching the location at which the volume control is displayed and moving the displayed control element by a desired amount through movement of the user s finger across the screen. Such user input must therefore be precisely controlled in order to use control elements to input commands. Gesture based inputs on the other hand do not require the same precise control as they are not tied to a specific location on the screen. Instead a user wishing to e.g. scroll through a list of media content can do so by performing a swipe gesture at any location within a media player display.

At block the processor generates or updates the display data comprising a display object for display by the display device . The display object is representative of an action that will be performed by the processor if the input is continued or completed i.e. the action that will subsequently be performed by the processor only if the input is determined to be completed or continued beyond a threshold extent or sufficiently for the processor to determine that the input comprises a command to perform the action. Up to this point the processor does not perform the action and the input is therefore undoable up until its completion and the action is not performed. This is discussed in further detail with respect to below.

At block the processor outputs the generated or updated display data comprising the updated display object to the output interface .

At block the processor determines whether the input detected via the interface is a first input as shown in FIG. A i iii or a second input as shown in i to iii .

At block the processor performs the action only on continuation or completion of the input or on determination that the input comprises the first input. If the input is not continued the processor determines that the input comprises the second input and does not perform the action. Instead if the input comprises the second input processing resumes at block .

FIGS. A i iv and B i iv depict the display displaying an interface of a media player which is generated from the display data output by the processor . A user can control or modify the media output by manipulating the control components . This manipulation requires the user to touch the screen at the location at which each control component is displayed. Additionally or alternatively the user can control or modify the output of the media using gesture based inputs. As discussed in relation to a gesture input may be performed at any location on the media player interface .

FIGS. A i iv and B i iv depict example sequence of inputs the continuation or completion of which results in the processor causing a media player to output or play a next track in a playlist. In particular FIG. A i shows the display for a media player application running or outputting a current track on the electronic device through the speaker whilst an input is initiated by touching or making contact with the touchscreen interface e.g. with a finger or touchscreen stylus .

In FIG. A ii the input is continued by swiping or moving or sliding the point of contact in a horizontal motion across the touchscreen interface . It will be appreciated that continuation of the input may equally comprise moving the contact in a vertical or diagonal motion across the touchscreen or a combination of the three . Additionally or alternatively continuation of the input may comprise maintaining the contact with the touchscreen interface without movement of the point of contact or completing any of the gesture inputs discussed above with respect to block . Completing an input e.g. a gesture input means performing the input to an extent required to cause the processor to determine that an action e.g. start playing the next track is to be performed in response to the input.

The display object is representative of the action that will be performed if the input is continued beyond the common initial phase to provide the first input. In the example of the display object comprises a well known symbol representing the action of skipping or jumping to the subsequent track listed by the media player and outputting that track. In this case the action that will be performed on continuation of the action will be the output of the next track in the playlist and this action is represented by the next track display object .

In addition to representing the action that the processor will subsequently perform on continuation of the input the display object may also represent a current phase stage or degree of completion of the input through variation of a parameter or characteristic of the display object . For example the display object shown in FIGS. A ii and B ii is part filled or part coloured in to represent that the contact has been moved part of the distance required to provide the first input i.e. part of the distance required to cause the processor to perform the action .

Further examples of suitable display objects include arrows other known media player control symbols text egg timer symbols images of media content or software applications or a number of these elements grouped together as a display object. Each display object has one or more visual parameters associated with it which can be varied to show degree of completion of the input and which comprise one or more of brightness colour contrast opacity frequency amplitude speed or the number or thickness of a plurality of lines e.g. hatching .

As shown in FIG. A iii the input is completed by moving the contact to a sufficient extent to cause the processor to perform the action thereby resulting in the media player outputting the subsequent track in a playlist. In this case the display object is filled in thereby indicating that the input has been completed. FIG. A iv depicts the output display of the media player after the action corresponding to the input has been completed i.e. the media player display depicting the track which is now being played.

FIGS. B i iv show the display depicting a second input in which the input is not continued to a sufficient extent to result in the processor performing the action. It can be seen that the input stages depicted in FIGS. B i and B ii are respectively the same as those depicted in FIGS. A i and A ii . Hence these input stages correspond to an initial input or initial input phase or stage that is common to both the first and second input.

During this common initial input phase the processor is able to determine the potential action that it will perform in response to the input i.e. the action that will subsequently be performed by the processor if the input is continued to provide a first input as depicted in i.e. if the common initial input phase is followed by the phase depicted in FIG. A iii . However during this common initial input the processor cannot yet determine whether or not this action will be performed as the common initial input may instead be followed by the phase depicted in FIG. B iii .

In the example depicted in FIG. B iii the contact with the touchscreen interface has not moved a sufficient distance for continuation of the input beyond the common initial phase as depicted in FIG. A iv . Instead the contact is moved back toward the location at which the contact was initially made or simply released thereby undoing or abandoning the input. In this case the media player interface returns to the original screen at FIG. B iv and the media player continues to play the current track.

Whilst the displays of FIGS. A i iv and B i iv relate to an input comprising a swipe across a touchscreen interface analogous sequences arise for other types of input. For example for a voice input the common initial phase may comprise inputting a voice signal of a given intensity with a first input type being provided if the voice input intensity continues above a threshold intensity or for a duration longer than a threshold duration whilst a second input is provided if the voice input intensity does not surpass the intensity or duration threshold in which case the processor does not perform the action.

Similarly in the example of an input comprising shaking the electronic device if the shaking intensity continues beyond a threshold intensity or a threshold duration the input will be the first input and the processor will perform the corresponding action. Alternatively if the shaking intensity does not continue beyond the threshold intensity the second input is provided in which case the processor does not perform the corresponding action.

As discussed the display object is progressively filled further or coloured in as the distance moved by the contact increases. In this way the further movement or input required in order to cause the processor to perform the relevant action is indicated or represented or symbolised by the display object . A user of the device is therefore guided by the display object with respect to the input required in order to cause a desired output. Additionally the user is guided by the display object as to whether or not it is possible to abandon the input without causing performance of the subsequent action.

At block the processor generates or updates data comprising a second type of display object for display by the display device wherein the display object is representative of content that will subsequently be output on continuation or completion of the user input. In the examples of the display object is a banner displaying a title of a song that will be played if the user completes a horizontal swipe gesture. Further examples of display objects include thumbnail images or any other representation of an output on the display screen or from other outputs of the device that will occur in response to completion of the input.

At block the processor outputs the generated or updated data on the display device . In this case the processor causes the display object to appear on the display device over time as the user input is being detected by the input interface or during performance of the user input . Furthermore the processor causes the display object to appear on the display device at a different rate to the rate at which the user input is detected. For example the processor may cause the display object to appear on the display device at a rate faster or slower than the rate at which the user input is detected via the interface. A particular example is when completion of the user input results in the processor causing a media player to play a next track in which case the display object shown in the figures comprises a banner display of the title of the next track and the banner display appears on the display screen at a faster rate than a rate of completion of the user input.

In the example of FIGS. A i iv the display object comprises the title of the song that will be played if the user completes the input. The display object appears during the common initial input and is decipherable before completion of the input. Accordingly the user is informed of the consequence of completing the input in sufficient time before completion of the input to allow the user to abandon or undo the input if desired. In this way the display object provides a preview of a future operational state of the device that will arise if the input is completed.

At block the processor detects a first input comprising a swipe gesture across the touchscreen interface . In particular the swipe gesture may be across the media player interface . The swipe may be in a vertical horizontal or diagonal direction across the touchscreen interface or a gesture input comprising a multi directional swipe gesture.

At block the processor modifies the current output of the media content in response to the first input detected by the touchscreen interface . For example the processor may pause the output of the media content increase or decrease the output volume of the media player cause the media player to output the next or the previous track instead of a current track or perform any other suitable modification of the media content output. In this manner the main functions of a media player application can be easily and efficiently controlled by a user even in situations where the user is unable to view the electronic device or precisely control the input.

At block the processor detects a second user input comprising a swipe gesture in a direction or directions opposite to the first swipe gesture input. For example if the first swipe gesture input is a vertical swipe across the touchscreen interface in an upward direction the second swipe gesture input comprises a vertical swipe across the touchscreen interface in a downward direction.

At block the processor responds to the second swipe gesture by reversing the performance of the modification or undoing the modification of block . For example if the processor pauses output of a song in response to a downward vertical swipe gesture the processor then re commences output of the song in response to an upward vertical swipe gesture. Similarly if the processor increases the output volume in response an upward vertical swipe gesture the processor then decreases the output volume or returns to the original output volume in response to a downward vertical swipe gesture.

It will be appreciated that as discussed in relation to A i iv and B i iv at block or both the processor may only modify the media output i.e. perform the action corresponding to the input if the input is determined to be a first type of input as discussed in relation to FIGS. A i iv and B i iv .

