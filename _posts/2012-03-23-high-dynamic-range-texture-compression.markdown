---

title: High dynamic range texture compression
abstract: A method for compressing a high dynamic range (HDR) texture. A first block of texels of the HDR texture in a red-green-blue (RGB) space may be transformed to a second block of texels in a luminance-chrominance space. The first block may have red values, green values and blue values. The second block may have luminance values and chrominance values. The chrominance values may be based on a sum of the red values, a sum of the green values and a sum of the blue values. The luminance values and the chrominance values may be converted to an 8-bit integer format. The luminance values may be modified to restore a local linearity property to the second block. The second block may be compressed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08498476&OS=08498476&RS=08498476
owner: Microsoft Corp.
number: 08498476
owner_city: Redmond
owner_country: US
publication_date: 20120323
---
This is a division of prior application Ser. No. 12 133 369 entitled High Dynamic Range Texture Compression and filed Jun. 5 2008.

High dynamic range HDR imaging technologies have introduced a new era of recording and reproducing the real world with digital imaging. While traditional low dynamic range LDR images only contain device referred pixels in a very limited color gamut HDR images provide the real radiance values of natural scenes. HDR textures facilitate improvements in the lighting and post processing of images resulting in unprecedented reality in rendering digital images. Thus supporting HDR textures has become the trend in designing both graphics hardware and application programming interfaces APIs . However LDR textures continue to be indispensable to efficiently support existing features of imaging technologies such as decal maps that do not typically require the expansive HDR resolution.

One of the challenges in using textures in imaging is that the size of textures is generally large. The LDR textures in typical 24 bit per pixel bpp raw red green blue RGB format typically consume too much storage and bandwidth. HDR textures which are usually in half floating or floating point format in current rendering systems can cost 2 to 4 times more space than the raw LDR textures. Large texture size constrains the number of HDR textures available for rendering a scene. Large texture size also limits the frame rate for a given memory bandwidth especially when complicated filtering methods are used. These limits on the available textures and the frame rate constrain the quality of digital imaging in rendering a scene.

Texture compression TC techniques can effectively reduce the memory storage and memory bandwidth requirements in real time rendering. For LDR textures many compression schemes have been devised including the de facto standard DirectX texture compression DXTC which may also be known as S3TC. DXTC has been widely supported by commodity graphics hardware.

In general one or more implementations of various technologies described herein are directed towards a method for compressing high dynamic range HDR textures. The HDR textures which are represented as values in red green blue RGB channels may be transformed onto a luminance and chrominance space. The transformation may be an adaptive process that removes the dominant RGB channel from the chrominance space. The transformed values may be quantized from floating point format to an integer format. The HDR textures in the luminance and chrominance space may be modified to accord with the standard input format of a joint color channel compression scheme for low dynamic range LDR textures such as DirectX texture compression DXTC . The textures may then be compressed using the joint color channel compression.

In one implementation of compressing HDR textures two of the RGB channels may be adaptively selected for converting to chrominance channels. The two RGB channels with the lowest values of the three RGB channels may be used in converting the RGB channels to chrominance channels. The values in the luminance and chrominance channels may be converted to an 8 bit integer format. The 8 bit integer values may be modified to restore a local linearity property that may be removed by converting the RGB channels to luminance and chrominance channels. The modified values may be compressed using DirectX texture compression.

The modification to the textures may be stored in a new data structure which may be used to facilitate decompression. In one implementation the compression method may produce a data structure that can be used to render HDR images in real time using existing LDR hardware. The data structure may include some blocks in DirectX Texture formats that accommodate HDR texture data compressed according to the above method. The data structure may increase the texture compression ratio from 8 bits per pixel bpp to 10 bpp.

Various implementations described herein may also be directed to a method is provided for decompressing the HDR texture which have been compressed as described above. In one implementation the compressed data may be decompressed with a new apparatus that uses the extension block along with the DirectX Texture formatted block to produce values in the RGB channels based on the original HDR textures.

Various implementations described herein may also be directed to a method for rendering HDR images in real time using existing hardware designed for real time rendering of low dynamic range LDR images.

The above referenced summary section is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description section. The summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

Implementations of various technologies described herein may be operational with numerous general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the various technologies described herein include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The various technologies described herein may be implemented in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. The various technologies described herein may also be implemented in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network e.g. by hardwired links wireless links or combinations thereof. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

The computing system may be configured to facilitate high performance processing of texel data i.e. graphics data. For example in addition to the system bus the computing system may include a separate graphics bus . The graphics bus may be configured to facilitate communications regarding the processing of texel data. More specifically the graphics bus may handle communications between the CPU graphics processing unit GPU the system memory a texture memory and an output device .

The system bus and the graphics bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures may include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus Peripheral Component Interconnect PCI bus also known as Mezzanine bus PCI Express PCIE integrated device electronics IDE serial advantage technology attachment SATA and accelerated graphics port AGP .

The system memory may store various programs or applications such as an operating system for generating texel data in the form of raw textures for display on the output device . Examples of operating systems include a Graphical Device Interface GDI component of the Microsoft Windows operating system. In one implementation the raw textures may be HDR textures represented as 16 bit floating point values in the RGB channels.

The system memory may also store a compressor program . To facilitate high performance processing of texel data the compressor program may compress the raw textures into compressed textures . Because the compressed textures occupy less bandwidth on the graphics bus transferring the compressed textures over the graphics bus may be preferable to transferring the raw textures in high performance graphics processing.

In one implementation the GPU may be configured to support texel data that is compressed using a joint color channel compression method such as DXTC. Accordingly the compressor program may include a standard DXTC coder not shown . As such the compressed textures may represent the raw textures in a format that facilitates processing by the DXTC configured GPU . The compressed textures are described in greater detail in the description for . It should be noted that DXTC is merely used as an example of a joint color channel compression method and is not intended to limit implementations described herein. Other joint color channel compression methods may be used in various implementations.

The system memory may further store a driver for enabling communication with the GPU . The driver may implement one or more standard application program interfaces APIs such as Open Graphics Library OpenGL and Microsoft DirectX for communication with the GPU . By invoking appropriate API function calls the operating system may be able to instruct the driver to transfer the compressed textures to the GPU via the graphics bus and invoke various rendering functions of the GPU . Data transfer operations may be performed using conventional DMA direct memory access or other operations.

Visual output may be provided on an output device e.g. a conventional CRT TV or LCD based monitor projector etc. operating under control of the GPU . In one implementation the GPU may be configured to provide visual output by processing the compressed textures .

The GPU may include various components for receiving and processing graphics system commands received via the graphics bus . The GPU may include a display pipeline and a memory management unit .

The display pipeline may generally be used for image processing. The display pipeline may contain various processing modules configured to convert the compressed textures into texel data suitable for displaying on the output device . In one implementation the display pipeline may include a texel shader .

The texel shader may decompress the compressed textures into decompressed textures . In one implementation the texel shader may use a standard DXTC decoder not shown to decompress the compressed textures . As such the decompressed textures may represent texel data as 8 bit integer values in the RGB channels. The decompressed textures are described in greater detail in the description for .

Additionally the texel shader may perform real time image rendering whereby the decompressed textures may be configured for processing by the GPU . In one implementation the texel shader performs real time HDR rendering. The texel shader is described in greater detail with reference to the description of .

The memory management unit may read the compressed textures from the system memory to facilitate decompression by the texel shader . Additionally the memory management unit may read the decompressed textures from a texture memory to facilitate real time rendering. The texture memory may be specialized RAM TRAM that is designed for rapid I O facilitating high performance processing for the GPU in rendering images including 3 D images from the decompressed textures .

The computing system may further include a storage which may be connected to the bus . Examples of storage include a hard disk drive for reading from and writing to a hard disk a magnetic disk drive for reading from and writing to a removable magnetic disk and an optical disk drive for reading from and writing to a removable optical disk such as a CD ROM or other optical media. The storage and associated computer readable media may provide nonvolatile storage of computer readable instructions data structures program modules and other data for the computing system .

It should be appreciated by those skilled in the art that the computing system may also include other types of storage and associated computer readable media that may be accessed by a computer. For example such computer readable media may include computer storage media and communication media. Computer storage media may include volatile and non volatile and removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media may further include RAM ROM erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM flash memory or other solid state memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computing system . Communication media may embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and may include any information delivery media. The term modulated data signal may mean a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media may include wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above may also be included within the scope of computer readable media.

It should be understood that the various technologies described herein may be implemented in connection with hardware software or a combination of both. Thus various technologies or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes CD ROMs hard drives or any other machine readable storage medium wherein when the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus for practicing the various technologies. In the case of program code execution on programmable computers the computing device may include a processor a storage medium readable by the processor including volatile and non volatile memory and or storage elements at least one input device and at least one output device. One or more programs that may implement or utilize the various technologies described herein may use an application programming interface API reusable controls and the like. Such programs may be implemented in a high level procedural or object oriented programming language to communicate with a computer system. However the program s may be implemented in assembly or machine language if desired. In any case the language may be a compiled or interpreted language and combined with hardware implementations.

In operation original HDR textures may be input to an adaptive color transformation process . The original HDR textures may be the raw textures partitioned into 4 4 blocks of 16 texels. The adaptive color transformation process may produce the transformed textures by transforming the original HDR textures from the RGB space to blocks of texels in a luminance chrominance space. Herein the luminance chrominance space may also be referred to as a Y UV space. In one implementation the adaptive color transformation process is based on HDR color transformation which may include converting RGB values to Y UV values.

Here Y is the luminance channel and Sare chrominance channels corresponding to R G and B. ware constant weights. It should be noted that only two of the chrominance channels need to be determined for color transformation because the third channel may be derived based on the values of the other two chrominance channels. For example each of the R G and B values may derived as follows 

However if the third channel is not encoded during compression in this case the blue channel may accumulate errors which can be relatively large. The amount of accumulated error can be controlled however by adaptively selecting which channel to leave out of the color transformation. As such an error accumulative channel may be determined from one of the R G and B channels. In one implementation the error accumulation channel also referred to herein as Ch mode may be derived for each texel calculated as 

Here the dominant chrominance channel may not be included in the color transformation and accordingly not encoded in the compressed textures . By leaving the highest or dominant chrominance value out of the transformation the relative error may be controlled because the values of the two encoded chrominance channels may fall in the range of 0 0.5 . In one implementation the error accumulation channel may be determined per block instead of per texel. In such an implementation the color values for each texel may be summed by channel providing a total sum for the block for each of the three channels R G and B. In other words the two channels with the lowest total sums for the block may be selected for color transformation.

Returning to the transformed textures may be input to a local HDR reduction process . The transformed textures may represent the luminance and chrominance values the Y UV values in 16 bit floating point format which typically is more difficult to compress than integer values. Accordingly the local HDR reduction process may convert the 16 bit floating point Y UV values to an 8 bit integer format. The values in 8 bit integer format may be included in reduced textures .

To convert the Y values to 8 bit integers a global luminance range may be determined. The global luminance range may be the upper and lower bound of values in the Y channel for all the texels in the block. The upper bound may be derived from 5 bit quantizing and rounding up the maximal luminance value to the nearest integer. The lower bound may be derived from 5 bit quantizing and rounding down to the nearest integer. Each of the 16 bit floating point Y values may then be mapped into relative values within the global luminance range. The relative Y values may then be quantized using linear quantization in log 2 space.

To convert the UV values to 8 bit integers linear encoding and log encoding may be alternatively employed for each 4 4 block of texels. The values of chrominance channels UV generally fall into 0 1 and thus may be directly quantized into 256 levels in 0 1 i.e. 8 bit integer values.

The reduced textures may represent each of the Y UV values as 8 bit integers for each texel in a 4 4 block. Additionally the reduced textures may include the global luminance range values upper and lower bound luminance values in 5 bit integer format . The reduced textures may be input to a joint channel compression process and a point translation process which collectively produce the compressed HDR textures .

DXTC is typically applied to raw LDR textures that are represented as Y UV channel values in 8 bit integer format. As such the joint channel compression process may apply DXTC to the reduced textures . However applying DXTC directly to the reduced textures may produce large distortions because the adaptive color transformation process and the local HDR reduction process may remove a local linearity property in the Y UV color spaces that is relied upon by DXTC. As such the local linearity property is restored by the point translation process before employing DXTC in the joint channel compression process . DXTC may further compress the 8 bit Y UV values to produce the compressed HDR textures .

The point translation process may reshape distribution of each block of reduced textures in the Y UV space such that the local linearity property may be restored. In doing so the point translation process may shift the texels in the Y UV space such that each point is positioned close to a single line segment in the Y UV space. In one implementation each texel is shifted solely along the Y axis. In another implementation a modifier table may be used to determine a re distribution of each block of the reduced textures .

For example the Y values in each block of the reduced textures may be modified according to the following formula modifier

Modifier values may be selected according to which values attenuate the reconstruction error. More specifically for each block all possible T idx values 0 1 . . . 15 are enumerated. Then for each T idx the M idx value that provides the minimal reconstruction error for each texel is determined. Finally the per block T idx and per texel M idx are selected to minimize the overall block reconstruction error. Once the texels in the block have been translated as described above the DXTC process can be applied in the joint channel compression process .

DXT block may include base color and base color . Each base color is represented as Y U and V values. Accordingly base color may include Y U and V. Similarly base color may include Y U and V. Base color and base color may represent the values of endpoints of the line segment approximated by the point translated texels in one block. Color indices represent a value in the Y UV space for each texel based on a DXTC algorithm.

The extension block may include data that facilitates decompression and rendering by the texel shader . The extension block may include data values that represent changes to the original HDR textures introduced by the pre processing performed prior to the DXTC.

More specifically the Ch mode may represent the R G or B channel that was not included in the adaptive color transformation process . The global luminance range includes the upper bound A and lower bound B of the luminance values Y values for each block. As previously stated during the joint channel compression process the luminance values for each texel were converted to relative values within the global luminance range . Also the T idx and M idx values indicate the modifier values used in the point translation process . One T idx may be recorded for each block and one M idx value may be recorded for each texel. In one implementation a log linear UV encoding flag value may be embedded in the mutual order of A and B.

The T idx and M idx may be used to look up the modifier value in the modifier table . The modifier value may then be added to the Y value determined by the DXT decoder . Modifying the Y value may compensate for the modification to the Y values of the texels in the point translation process .

The global HDR recovery module may perform the inverse process of the local HDR reduction process including luminance log decoding and chrominance log or linear decoding. It should be noted that log decoding is a combination of linear decoding and exp2 operation. The global HDR recovery module may use the global luminance range A B to determine absolute Y U and V values based on the relative Y U and V values input to the module .

The inverse color transform module may perform the inverse process of the adaptive color transformation process . The Ch mode may identify the R G or B value left out of the adaptive color transformation process . By identifying the Ch mode the inverse color transform module may determine R G and B values based on the Y UV values output by the global HDR recovery module .

Advantageously a decoder for the data structure may be implemented with moderate extension of standard DXT decoder hardware. The inverse color transform module may involve one addition two tri channel multiplications and a MUX to reorder signals based on the Ch mode . Additionally the global HDR recovery module may include one tri channel uniform dequantization and one tri channel exponentiation operation.

As an alternative to decompression the texel shader may perform real time rendering using the compressed textures . Advantageously real time HDR rendering may be performed with the compressed textures in the data structure format without modifications to existing GPU hardware.

At step the 3 DDS texture frames are loaded into the texture memory . At step the texel shader may perform HDR texturing. When an HDR texel is used by the GPU the texel shader may sample all 3 DDS frames using texture coordinates determined by the nearest point sampling algorithm. The texel shader may then simulate the hardware decoding process described in to recover the desired texel value.

In one implementation the DDS texture frame and DDS texture frame may be used to store per block components with 1 16 down sampled resolution. The DDS texture frame may include the T idx the base color Y value Y and the Ch mode . The DDS texture frame may include the lower bound A and upper bound B luminance values and the base color Y value Y.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

