---

title: Modular script designer for next generation testing system
abstract: A method for modular script design includes receiving, at a modular script designer component, script information from a user, generating a list of suggested modules based on the script information, and receiving, at the modular script designer component, a selection of a next module from the user. The selection of the next module includes a selection of the next module from among the list of the suggested modules or a request for a new module. If the selection of the next module includes the request for the new module, the method further includes generating the new module.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09448915&OS=09448915&RS=09448915
owner: Accenture Global Services Limited
number: 09448915
owner_city: Dublin
owner_country: IE
publication_date: 20120411
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 61 475 057 filed Apr. 13 2011 which is incorporated by reference in its entirety herein.

This disclosure relates to software testing and in particular this disclosure relates to an integrated platform for developing debugging and executing tests to insure the integrity and functionality of software systems.

The development of computer software involves a rigorous testing process to insure that the software functions as intended. During the testing process testers write various test scripts or software test modules for performing different types of tests necessary to ensure that the computer software is functioning as designed. The testers also set up and run the test scripts while tracking the results and report the test result to appropriate personnel. This process is inefficient and time consuming and requires significant tester involvement.

Further as businesses continue to rely on computer software and complex software packages an increasing number of highly complex computer software has been developed to meet business demands. Due to the increased complexity and scale such software programs require a large scale testing process involving far more testers and test scripts than were required previously. Such increases are related to organizations centralizing their testing and moving to an outsourced testing model. Traditionally testing was embedded into the software development life cycle for each project but now central discrete testing functions exist within organizations which test across multiple projects and releases.

Testing tools have been developed to assist the testers in performing the various steps of the testing process. However existing testing tools are not able to provide the required functionality and efficiency to overcome the challenges posed by the large scale testing process.

Testing of various products and or software products has increased in complexity and scope. In the past relatively small groups of designers and developers perhaps 10 to 30 in number developed various tests for testing and verifying the function of software modules or code segments. Such small groups of individuals have been manageable. However as the number of individuals contributing to the project becomes large redundancy and complexity increase which contributes to increased cost and an increase in the number of errors. Therefore a need exists to address the above.

A method for modular script design includes receiving at a modular script designer component script information for a modular script from a user generating a list of suggested modules based on the script information and receiving at the modular script designer component a selection of a next module from the user. The selection of the next module includes a selection of the next module from among the list of the suggested modules or a request for a new module. If the selection of the next module includes the request for the new module the method further includes generating the new module.

Other embodiments of systems methods features and their corresponding advantages will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems methods features and advantages be included within this description be within the scope of the invention and be protected by the following claims.

As shown in a system for next generation testing NGT system using automation controller provides a platform allowing increased efficiency and functionality for testing computer software. The system may be embodied as a system cooperating with computer hardware components and or as a computer implemented method.

The NGT system may include a unified desktop which includes a test planning tool a modular script designer an execution toolbar and a defect management component . The NGT system may also include a prioritization and assignment manager an automation controller a data supply chain controller an integration layer and a reporting portal . The integration layer may link to an existing testing tool such as Hewlett Packard s HP Quality Center an existing test management and quality management tool such as IBM Rational Quality Manager and a database or server such as a Microsoft SQL Server with SQL Integration Services and SQL Analysis Services. The NGT may also include virtual machines which interface with the automation controller . The virtual machines may run a functional test automation tool such as functional and regression test software such as Hewlett Packard s HP QuickTest Professional QTP . Other types of testing tools may also be used.

The NGT system provides a suite of wrapper tools for a testing process. The NGT system may consist of a set of tools that integrate with existing test tools and extend their functionality. The NGT system allows functional testing at a larger scale by delivering tools to reduce the testing effort and increase the quality of testing. The NGT system may reduce testing effort by more than 20 as compared to existing testing tools such as HP Quality Center . Further the NGT system may be extendible for use across multiple clients. The NGT system may be built as an internal set of assets for use across clients and may be designed to allow client specific functionality to be handled through configuration and extension.

The memory subsystem may include any suitable storage components such as RAM EPROM electrically programmable ROM flash memory dynamic memory static memory FIFO first in first out memory LIFO last in first out memory circular memory semiconductor memory bubble memory buffer memory disk memory optical memory cache memory and the like. Any suitable form of memory may be used whether fixed storage on a magnetic medium storage in a semiconductor device or remote storage accessible through a communication link. A user or system interface may be coupled to the computer and may include various input devices such as switches selectable by the system manager and or a keyboard. The user interface also may include suitable output devices such as an LCD display a CRT various LED indicators a printer and or a speech output device as is known in the art.

To facilitate communication between the computer and external sources a communication interface may be operatively coupled to the computer system. The communication interface may be for example a local area network such as an Ethernet network intranet Internet or other suitable network . The communication interface may also be connected to a public switched telephone network PSTN or POTS plain old telephone system which may facilitate communication via the Internet . Any suitable commercially available communication device or network may be used.

Description of the modular script designer MSD follows. MSD combines a simple interface for developing scripts or facilitating script creation using a modular approach along with an approvals framework. Modularization is the process of grouping test steps into small modules that describe a piece of functionality. These modules combine together to form test scripts or cases. The MSD provides intelligent module suggestions for developing test scripts. Test scripts may include one or more modules. When a module is added to a script a list of likely next modules is displayed to the user. Therefore the MSD may improve knowledge management and decrease duplicated efforts in creating modules. Users can also search for modules with an in line search function.

The MSD also allows for meta tagging and indicating parameters in the modules. Metadata is added to modules so that the system can understand how and where the module is used. Input and output parameters are specified to enable re use of modules and data driven approaches. The MSD also allows the specification of skills and pre requisites associated with a module. Skills are assigned to the tests so that the system knows who will be able or qualified to execute the script. Pre requisites including data are specified to track the readiness of a test for execution. The MSD also provides automated approvals workflow. A centralized workflow system is used to enable modules to be approved or rejected. After a module is created or modified the approver is notified. The approver may approve the module to be used in all scripts for a subset of scripts or for a single script.

Description of the test execution toolbar follows. The test execution toolbar may be a unified toolbar incorporating all of the tools that a tester requires. The test execution toolbar may provide in line test execution. Test scripts can be opened directly within the toolbar which saves room on a tester s desktop and avoids certain keystrokes such as ALT Tabbing between screens. Defect raising and screen capture may be part of the process. The text execution toolbar may also provide an embedded approvals lists. All module script approvals may be shown in the toolbar and an approver can quickly open the relevant script module for approval. The test execution toolbar also allows quick access to all NGT tools. A quick launch bar may be provided to enable the tester to quickly access all of the NGT tools. The toolbar may also handle login management for NGT. A user profile section is available to change user information. The test execution toolbar is also dockable with an auto hide function. The test execution toolbar may be docked to the left hand side of the screen and it can be selected to be visible or auto hide. An extendable framework allows additional panels to be added to the toolbar.

Description of the prioritization and assignment manager PAM follows. The PAM provides a centralized automated prioritization of test scripts with real time assignment logic. The PAM provides configurable prioritization factors. Test scripts are prioritized based on a centralized set of factors and the factors can be configured centrally to influence the entire test operation for example to improve performance against contractual key performance indicators KPIs . The PAM further provides a skill based assignment it provides a pull rather than push approach. Testers may click Get Next via a user interface to get assigned the next script to execute. The best script is chosen in real time based on weighted assignment factors. Managers may control the skills as compared against the skills of their team members. The PAM may also provide manager overrides. Managers are given a view of the scripts planned for execution by their team. They are able to change the factors of specific scripts for example business priority to re prioritize the queue and force scripts to be assigned to specific individuals. The PAM may also provide a pluggable framework for new factors. New decision factors can be added by defining a new factor class. The factor may be presented through the user interface and can be weighted in the decision logic. This could be used to enable advanced Applied Statistic decision models.

Description of the automation controller follows. The automation controller may be an automation framework for resilient off line automation on a virtual farm such as a computing machine in a cloud environment. The automation controller provides remote execution of test scripts. An automation controller agent may run on virtual machines VM s to manage the execution of test scripts. A logging framework is used to support the execution. The automation controller also may communicate with the PAM to get the next script. This allows the centralized factors to apply to both manual and automated execution.

The automation controller also provides intelligent selection of modules to maximize the return on investment or ROI associated with each test script that is run automatically. The automation controller selects for automation the test scripts that provide the greatest ROI collectively. The choice whether to automate a particular test script using the automation controller may be based on the ROI associated with the test script. For example a particular test script may be a test script that handles initial login by a user. Because a test script that handles initial login by user may be used by hundreds of different test scripts without variation this testing script provides a high ROI and as such may be a good candidate for automation. The ROI essentially is a measure of increased efficiency attained by automation of the test script. A prioritization workflow aids the automation team in assessing the next module to be automated. The user interface allows the automation team to check in and upgrade automated modules.

The automation controller further provides modular design and partial automation. Automation scripts may be developed as modules and each automation module may have one or more manual modules mapped against it. Partial automation enables rapid execution of automated parts of scripts. Essentially the automation control is used where applicable to automate the execution of test scripts.

Description of the reporting portal follows. The reporting portal provides an automated reporting capability accessible through a central on line portal. The reporting portal may include a full Microsoft Business Intelligence BI suite. The solution makes use of SQL Server Integration Services SQL Server Analysis Services and SQL Server Reporting Services which are available from Microsoft Corporation. A custom SQL Server Integration Services SSIS component directly communicates with external testing tools such as an HP Quality Center which is available from Hewlett Packard Corporation.

The reporting portal also includes an off line data warehouse to avoid testing tool degradation. An off line data warehouse may be maintained to avoid queries directly on the external testing tool. A dimension based data model is used for simplified reporting. Further data is pre aggregated in a multidimensional online analytical processing MOLAP database to provide quick analysis. The reporting portal further provides cube based metrics and KPIs key process indicators . Using SS Analysis Services measures and targets may have been pre defined which can be included into reports. PowerPivot a spreadsheet add in available from Microsoft Corporation allows data to be quickly analyzed in spreadsheet programs such as Microsoft Excel for ad hoc reports. Further the reporting portal provides integration with solutions such as Microsoft SharePoint . Where data from systems other than the HP Quality Center is required for example financial production data the solution can receive data from solutions such as Microsoft SharePoint . The SSIS component allows the solution to be easily extended to direct data sources where required.

Description of the defect management tool follows. The defect management tool may simplify the process for raising tracking and updating defects. The defect management tool may provide a defect watch list. Toolbar based list of defects with real time Red Amber or Green RAG status indicators may be provided. Red status indicates high risk or serious project issues amber status indicates medium risk and green status indicates low risk. The defect management tool may allow quick access to full information of the defects to see the latest status. The defect management tool may also provide in line defect raising with test history. While executing a test through the toolbar screenshots and test steps may be captured. When a defect is raised this information is pre populated in the defect. Screenshots and other attachments can be uploaded directly. The defect management tool also reduces alt tab operations. By including core defect management in the toolbar the defect management tool is able to reduce the need to alt tab into an external testing system such as the HP Quality Center . The defect management tool also enables automated un blocking of scripts to further avoid time spent in the external testing system. The defect management tool further provides team based views. Managers have a team view to enable them to see the defects currently impacting their team with the relevant size and status.

Description of the test planning tool follows. The test planning tool provides an intelligent interface for estimating planning selecting regression and assigning prep work. The test planning tool provides assisted estimation. A three stage process is used to provide estimation at increasing levels of accuracy. Information is used from previous testing releases to improve estimates. Pluggable architecture for client specific calculations may be used. The test planning tool also provides deconstruction of requirements into tests. The test planning tool assists the user in breaking down requirements into a manageable number of tests. Collaborative working capabilities allow a divide and conquer approach. The test planning tool further provides resource forecasting by skill. Early foresight of skills required to support the testing activities is made possible and graphical display of availability versus demand may be presented on the user interface. The test planning tool further helps to shape the test organization by promoting cross skilling. The test planning tool also provides regression pack suggestions. Using a meta data driven approach the system will suggest an appropriate regression pack. Risk based testing scores can be used to size the pack accordingly.

Description of the test data supply chain follows. The test data supply chain automates the demand management and supply of test data. The test data supply chain may provide a data catalogue. Data types are modeled and stored in a database. The test data team can check data in and out of the catalogue. Also rules can be specified to enable basic data mining. The test data supply chain also provides mapping data to test scripts. During preparation the data type required is selected against the script. Also using the modular script designer data parameters can be mapped directly to script parameters to allow automated assignment at run time. The test data supply chain further provides monitoring of stock levels and re ordering. The test data supply chain can monitor demand versus capacity for all types of data and as data gets used by test scripts the levels are updated. The test data supply chain can order additional data from the data team or via an automated provision. The test data supply chain may also be integrated with the PAM . The stock levels can be used during prioritization to avoid running scripts that do not have available test data or where stock levels are low.

For example if fifty specific test scripts require input data type A and twenty seven specific test scripts require input data type B the test data supply chain organizes the required data types for each script and provides the data to the test script in a just in time manner to avoid redundancy and reduce complexity. Further such test data may change throughout the lifecycle of the testing process based on the results of a particular test. Accordingly the test data supply chain tracks the required changes and updates the data sets required for the corresponding test scripts so that as the test scripts are being executed up to date test data is available to the test script.

The MSD may provide the following functionalities Define New Script The user is able to create a new test script and enter key information about that script Edit Existing Script The user is able to load or load an existing script and edit the information modules in that script Select Test Data The user is able to select test data types from the data catalogue to associate to the script Search for Modules The user is able to search for existing modules Top 10 Next Modules The MSD may suggest the most likely next modules which may be ten modules or any other number of modules to the tester based on the existing scripts within the repository and Create New Module The user is able to design a new module when required.

The Create New Module may include the following sub functionalities Define Test Steps Test steps may be captured against the module Define Expected Results Expected Results may be captured against the Test Steps Define Input Variables The tester may be able to define the input variables for the module and include these as required in the test steps results Define Output Variables The tester may be able to define the output variables for the module and include these as required in the test steps results.

The MSD may further provide the following functionalities Map Module Input Variables The Input of the modules is mapped to the output of previous modules entered by the tester at run time or mapped to a test data field Module Metadata The MSD allows additional configurable metadata to be specified against each module Skill Capture The tester is able to enter the skills required to execute the test Pre Requisite Capture The MSD allows the tester to enter any required pre requisites against the script Priority and Risk Capture The user is able to enter the business priority likelihood of failure and impact of failure against the test script.

MSD may further provide functionalities such as allowing users to clone test scripts save scripts as drafts view legacy steps easily re order modules in the script mark modules as favorite view favorite modules submit modules to module approvers save modules as draft define source of input and output variable as a fixed value mark scripts as not requiring review attach documents or images to scripts and cancel creation of a script. The MSD may also ensure no modules are created with the same name. The MSD may provide fewer additional or other functionalities.

The MSD may further allow the tester to create new scripts . To create a new script in the MSD the tester may enter script details including a unique script name a brief description of script capabilities and skill details. Skill details may include the skills required to execute the script successfully. At the tester may specify in the MSD input and output variables for the script and review all data that the tester inputted for the script select an approver for the script and attach any data that the script may require. The tester may submit the script to a testing tool such as the HP Quality Center .

The MSD also allows the tester to input modules into the test script. The MSD may suggest to the tester modules to be added to the script. At the tester may also use the MSD to search for other modules to add to the script create a new module edit existing modules or clone existing modules. The MSD may also store the tester s favorite modules. The MSD may allow the tester to add selected newly created edited or cloned modules to the script. The tester may optionally submit a module to an approver who may be a peer reviewer such as a test lead. The approver may provide comments for the script and may approve the module or reject the module . If the approver rejects the module the approver may distribute the module back to the tester for editing and the module may only be edited from the point where the module was submitted . A rejected module is inactive which means that the module cannot be searched for and cannot be used. The tester may edit the script based on comments from the approver . If the approver accepts the module the module is marked as ready for test which means the module is ready for execution and added to the script.

In a specific embodiment the MSD may provide the following approval process for approving a newly created module. When the tester submits a module for approval the MSD may set a status indicator of the module to pending approval and alert an approver to review the module. The tester may designate an individual to be the approver or the MSD may select an approver based on a role of the approver and skills required for the module. When the approver approves the module the MSD may set the status indicator of the module to approved for use and the module is then available for use in other scripts and is searchable by users of the MSD . The approver may also amend the module before approving the module. When the approver rejects a module the MSD may prompt the approver to enter a reason for rejection and sets the status indicator of the module to rejected and alerts the tester that the approver rejected the module. The tester may edit or update the rejected module in the MSD . The tester may edit or update the rejected module and submit the module for review again or the tester may remove the rejected module from the script in which case the MSD sets the status indicator of the rejected module to inactive or deletes the rejected module.

The MSD may allow the user to search for a module by prompting the user to enter search details perform the search and display the search results to the user. Then the MSD may allow the user to select a module from existing modules in the search results and give the user the option to edit the module .

The MSD may also allow a user to use a favorite module . The MSD allows the user to select a module from existing modules and gives the user the option to edit the module . If the user cannot use any existing modules e.g. a suggested module a module from search results or a favorite module the user may use the MSD to create a new module . After the user creates a new module the MSD may prompt the user to add the module to favorites . The user may check a box to add the module to favorites and then submit the module . Alternatively the user may submit the module without adding the module to favorites. After the module is submitted the MSD may prompt the user to cancel or add the module to the script add other modules enter script input output information and complete the script creation process .

As shown in the Scripting tab may display to the user all modules that are in the test script and allow the user to add a module to the script by creating a new module editing an existing module or cloning an existing module. The user may also input data regarding a module including for example a module name a status of the module a version of the module and a module description . The user interface may further display to the user a plurality of options in panes including suggested modules to include in the script and the option to search for modules .

The user may select a module from the suggested modules by clicking and dragging a module of choice into a Current Script field . The user may input additional information regarding the module including components to which the module is linked pulled from a configuration management database CMDB and any other metadata . The user interface may display to the user other information regarding the script including for example module steps test steps for each module step expected results for each module step current script steps attribute names attribute values and parameters . The user may click the Add to Script button to add a module to the script.

The MSD updates the list of suggested modules based on the last module in the script. If the script has no modules the MSD may provide a list of the most popular modules to be used as the first step in the script. For example the MSD may suggest a popular first module such as Log in to App. If one or more modules are in the script the MSD may suggest popular modules that follow the last module listed in the script. The MSD may add the user selected module from the list of suggested modules to the script and display the details of the selected module to the user for review and modification. The details may include for example the steps in a given module the attributes for that module and the module s parameters. Attributes can be hidden to allow more space to review the steps. After reviewing the details the tester can add the selected module to the test script by clicking Add to Script . The details of each step in the current script may be shown in a pane such as a Current Script pane for the tester to view the entire script as the tester progresses. After the tester adds the selected module to the script the MSD may update the suggested module panes to show the most likely next steps or modules in the script. The MSD may determine based on the order of modules in other existing scripts which modules are commonly added after the selected module. The MSD allows the tester to develop the script by adding modules to the script changing the order of modules in the Current Script pane or removing modules from the Current Script pane .

On the Input Output tab the MSD may display a list of all input put parameters associated with the test script. The tester may amend the source for the input output parameters by selecting a parameter to change. For example the tester may change an input parameter to a fixed value. Fixed values are entered directly into the Value field and are stored with the script. Alternatively the user may change the source of the input parameter to User Defined. 

On the Finish tab the MSD displays to the tester a summary of the details for the test script. The MSD may present the new module to the tester so that the tester can add the new module to the current script. The user may select one of their peers to review the script. When the script is submitted for review the MSD triggers an approval workflow to ensure that modules of the script are not incorrectly created. The user may also browse the test tool to decide where to store the script that has been developed. The MSD allows the tester to add attachments to the script and submit the script for peer review. The MSD may allow the tester to enter a reason for no review and proceed with submitting the test script.

The Step Design tab may guide the tester through adding steps to the module. The Step Design tab may prompt the tester to input information regarding a description parameters and expected results for each step in the module. Parameters may be embedded in the steps using notations such as Input

An exemplary module may be a View Billing module that allows a user to view information or details regarding the user s account. A test step for the View Billing module may be Click on the Account Tab for which the expected result is Account tab should open. Another test step may be Click on the Account Details link for which the expected result is Summarized account details should be shown. Another test step may be Click View more for which the expected result is All account details should be displayed. 

In another embodiment of the MSD a user interface may include drop down menus to allow the user to input other information about the script. For example the user may describe the likelihood of failure and impact of failure for the script and based on the user s description the system may calculate a risk based testing score for the script. For example a user may select from among Low Medium High and Very High drop down choices on a drop down menu for likelihood of failure and from among Low Medium High and Very High drop down choices on a drop down menu for impact of failure. A configurable list of attributes is then completed. These attributes can be directly linked to an underlying test tool e.g. HP QC fields .

In yet another embodiment a tester may search for the type of test data that will be required for the script. The user may select test data that is required to execute the test input a description of the required test data and input additional comments about the data type. The user may input additional comments about the specific configuration of the test data required. For example the user may specify Customer must have an open order. The MSD may further require the tester to input certain data for the script. The required data may include for example customer type e.g. business or consumer address type and product e.g. landline broadband or mobile phone. The MSD may require the tester to input fewer additional or other data for the script.

The integration layer provides backend agnostic access to the upstream layers business components layer and presentation layer and enables plug ability via a common interface to one or more backend systems such as QC Rational and Team Foundation Server. Integration layer implements the following design pattern an abstract base class inherits from ProvideBase which is a class available with Microsoft s .Net framework each concrete implementer in turn inherits from the abstract class above Appropriated Provider which may be an NGT component that communicates with a backend system such as QC is loaded based on type definition in a .config file. The integration layer also includes the integration fa ade. Integration fa ade exposes a simplified interface to the business components layer and reads data from a combination of data transfer objects from one or more backend repository or cache R2 and merges them to a common super data transfer object to return to the business components layer . Integration layer also includes NGT components which interface between the integration fa ade and the data layer and may provide mapping functionality for the integration layer if required. The integration layer also includes caching components and testing tool components . Testing tool components are providers servicing requests for data read write from a Testing Tool .

The data layer includes data access components which centralize the logic necessary to access underlying NGT data store exposing methods to allow easier and transparent access to the database. It also includes data helper utilities which are used to centralizing generic data access functionality such as managing database connections. The data layer also includes service agents which provide Windows Communication Foundation services proxy for talking to application server services. The data layer may be an Enterprise Library Data Access Application Block or a custom designed data layer. Alternatively object relational mapping tools such as Entity Spaces available from EntitySpaces LLP Genome available from TechTalk GmbH LINQ to SQL available from Microsoft Corporation Entity Framework also available from Microsoft Corporation or LLBLGen Pro available from Solutions Design may be used to generate the data layer components.

Cross cutting functions in the NGT may include for example security exceptions handling locking and communication. The NGT may also include a local cache . Outputs from the NGT may include for example email functionality or other information communication functionality. Emails may include notifications to testers regarding script rejection or approval notifications to approvers regarding scripts that are ready for review and notifications regarding security concerns system exceptions and auditing. The NGT may also communicate information to testing tool and an NGT database .

The MSD may have a centralized workflow system for approving rejecting modules and scripts. When a module is created or modified the MSD notifies an approver to review the module. The approver may choose to approve the module to be used in all scripts for a subset of scripts or for a single script.

When the approver approves a module change for all scripts the MSD sets the status indicator of the module to approved for use. The new version of the module is updated against all scripts containing the previous version of the module. If the approver indicates that the test scripts will require review after the update MSD sets the status indicator of the script to pending review.

When the approver approves a module change for a subset of scripts the MSD prompts the user to enter a new name for the module and clones the module by creating a new module identifier linking the new module to the existing module and setting the status indicator of the new module to approved for use. The MSD associates or adds the new cloned module to the subset of scripts selected by the approver. The approver may choose whether the scripts require review following addition of the new module to the selected subset of scripts.

When the approver rejects a module the MSD prompts the approver to enter a reason for rejection marks the module as rejected and allows the approver to suggest a replacement module to the testers. Then the MSD sends a notification for example by email to the tester to notify the tester that the module is rejected. Then the MSD may allow the tester to update and resubmit the module or remove the module from the script.

The MSD also provides a script approval process. When a new script is created the MSD sets the status indicator of the new script to pending review. The MSD assigns a reviewer to review the script. When the reviewer approves the script the MSD sets the status indicator of the script to ready for test if all modules in the script are approved for use. If some of the modules in the script are pending approval the MSD may set the status indicator of the script to pending module approval.

When a script is updated the person updating the script may indicate whether the script requires review and the MSD sets the status indicator of the script to pending review. Then the MSD sends notification to the reviewer to review the script. If the reviewer approves the script the MSD sets the status indicator of the script to ready for test if all modules in the script are approved for use. If some of the modules are still pending approval the MSD sets the status indicator of the script to pending module approval until all modules in the script are approved for use. If the person updating the script indicates that the script does not require review the MSD sets the status indicator of the script to ready for test if all modules in the script are approved for use. If some of the modules are still pending approval the MSD sets the status indicator of the script to pending module approval until all modules in the script are approved for use.

The logic circuitry and processing described above may be encoded in a computer readable medium such as a CDROM disk flash memory RAM or ROM an electromagnetic signal or other machine readable medium as instructions for execution by a processor. Alternatively or additionally the logic may be implemented as analog or digital logic using hardware such as one or more integrated circuits or one or more processors executing instructions or in software in an application programming interface API or in a Dynamic Link Library DLL functions available in a shared memory or defined as local or remote procedure calls or as a combination of hardware and software.

The logic may be represented in e.g. stored on or in a computer readable medium machine readable medium propagated signal medium and or signal bearing medium. The media may comprise any device that contains stores communicates propagates or transports executable instructions for use by or in connection with an instruction executable system apparatus or device. The machine readable medium may selectively be but is not limited to an electronic magnetic optical electromagnetic or infrared signal or a semiconductor system apparatus device or propagation medium. A non exhaustive list of examples of a machine readable medium includes a magnetic or optical disk a volatile memory such as a Random Access Memory RAM a Read Only Memory ROM an Erasable Programmable Read Only Memory i.e. EPROM or Flash memory or an optical fiber. A machine readable medium may also include a tangible medium upon which executable instructions are printed as the logic may be electronically stored as an image or in another format e.g. through an optical scan and then compiled and or interpreted or otherwise processed. The processed medium may then be stored in a computer and or machine memory.

The systems may include additional or different logic and may be implemented in many different ways. A controller may be implemented as a microprocessor microcontroller application specific integrated circuit ASIC discrete logic or a combination of other types of circuits or logic. Similarly memories may be DRAM SRAM Flash or other types of memory. Parameters e.g. conditions and thresholds and other data structures may be separately stored and managed may be incorporated into a single memory or database or may be logically and physically organized in many different ways. Programs and instruction sets may be parts of a single program separate programs or distributed across several memories and processors.

While various embodiments of the invention have been described it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the invention. Accordingly the invention is not to be restricted except in light of the attached claims and their equivalents.

