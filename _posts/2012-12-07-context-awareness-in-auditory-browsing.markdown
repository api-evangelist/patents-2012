---

title: Context awareness in auditory browsing
abstract: In a method for generating an audio summary of a portion of an electronic document, a user input selecting a focus position within a rendered electronic document is received. The plurality of document elements included in the rendered electronic document is identified. A plurality of audio objects corresponding to the plurality of document elements is generated. An audio signal is generated. The audio signal includes a subset of the plurality of audio objects corresponding to a subset of the plurality of document elements contained within a predetermined range from the focus position. The audio signal indicates the spatial relation between the elements of the elements subset. The audio signal is rendered to the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09483573&OS=09483573&RS=09483573
owner: International Business Machines Corporation
number: 09483573
owner_city: Armonk
owner_country: US
publication_date: 20121207
---
The present invention relates generally to accessibility to electronic documents for visually impaired users and more specifically to enhancing auditory browsing.

The Internet has become an important communication tool. The widespread use of graphical user interfaces GUIs increasingly bars visually impaired people from accessing digital information. To facilitate visually impaired person s access to digital data that is offered over internet the development of electronic aids has been ongoing for several decades. Blind and visually impaired computer users currently benefit from many forms of adaptive technology including speech synthesis large print processing braille desktop publishing and voice recognition. However presently a very few of the foregoing tools have been adopted for auditory browsing.

There are multiple screen reading tools including software programs available to blind and visually impaired persons enabling them to operate computers and or mobile devices and to browse the internet in an auditory manner. However auditory browsing of an information space typically proceeds in serial fashion. As the users move their focus from one webpage element to another the software tool typically presents auditorially to the users the one or more elements that have focus. Those elements are typically presented in sequence. Text information is typically rendered as synthesized speech. Consequently this approach is time consuming and provides no awareness of other webpage elements spatially located near the focused on webpage elements.

In one aspect a method for generating an audio summary of a portion of an electronic document is provided. The method comprises receiving user input selecting a focus position within a rendered electronic document. The method further comprises identifying a plurality of document elements included in the rendered electronic document. The method further comprises generating a plurality of audio objects corresponding to the plurality of document elements. The method further comprises generating an audio signal that includes a subset of the plurality of audio objects corresponding to a subset of the plurality of document elements contained within a predetermined range from the focus position. The audio signal indicates the spatial relation between the elements of the elements subset. The method further comprises rendering the audio signal to the user.

In another aspect a computer program product for generating an audio summary of a portion of an electronic document is provided. The computer program product comprises one or more computer readable tangible storage devices and a plurality of program instructions stored on at least one of the one or more computer readable tangible storage devices. The plurality of program instructions comprises program instructions to receive user input selecting a focus position within a rendered electronic document. The plurality of program instructions further comprises program instructions to identify a plurality of document elements included in the rendered electronic document. The plurality of program instructions further comprises program instructions to generate a plurality of audio objects corresponding to the plurality of document elements. The plurality of program instructions further comprises program instructions to generate an audio signal that includes a subset of the plurality of audio objects corresponding to a subset of the plurality of document elements contained within a predetermined range from the focus position. The audio signal indicates the spatial relation between the elements of the elements subset. The plurality of program instructions further comprises program instructions to render the audio signal to the user.

In yet another aspect a computer system for generating an audio summary of a portion of an electronic document is provided. The computer system comprises one or more processors one or more computer readable tangible storage devices and a plurality of program instructions stored on at least one of the one or more storage devices for execution by at least one of the one or more processors. The plurality of program instructions comprises program instructions to receive user input selecting a focus position within a rendered electronic document. The plurality of program instructions further comprises program instructions to identify a plurality of document elements included in the rendered electronic document. The plurality of program instructions further comprises program instructions to generate a plurality of audio objects corresponding to the plurality of document elements. The plurality of program instructions further comprises program instructions to generate an audio signal that includes a subset of the plurality of audio objects corresponding to a subset of the plurality of document elements contained within a predetermined range from the focus position. The audio signal indicates the spatial relation between the elements of the elements subset. The plurality of program instructions further comprises program instructions to render the audio signal to the user.

Embodiments of the present invention recognize that there are multiple screen reading tools including software programs e.g. the so called talking browsers available to blind and visually impaired persons enabling them to operate computers and or mobile devices and to browse the internet in an auditory manner. It is to be noted that throughout the present document terms blind and visually impaired are interchangeably used. However one problem with such browsers is that an overview of the web page or a portion of the web page is unavailable typically because this type of web browser moves from element to element in a sequential manner as discussed below in conjunction with . This is very limiting to an impaired user who may want for example to obtain an overview of the web page with a quick scan of at least a portion of the web page which is possible by users who do not have a visual impairment.

The illustrative embodiments used to describe the invention generally address and solve the above described problems and other problems related to context awareness in auditory browsing of electronic documents. Generally an embodiment enables users to hear an audio summary of a portion of electronic document by leveraging the so called cocktail party effect as discussed below. In one example a user may provide a focus position and the desired direction within an electronic document e.g. a web page using a touch sensitive display or other input device. In response to the selected focus position and direction an audio summary may be rendered to the user that summarizes a portion of the electronic document contained within the predetermined range from the focus position in accordance with an embodiment of the present invention. Advantageously the audio summary may provide an audio representation of elements or groups of elements contained within the predetermined range from the focus position and their spatial relation with respect to the focus position. Thus various embodiments facilitate visually impaired users to have better awareness of an electronic document content during auditory browsing.

Embodiments of the present invention will now be described with reference to the figures. Various embodiments of the present invention may be implemented generally within any computing device suited for allowing visually impaired users to browse electronic documents. More specifically embodiments of the present invention may be implemented in a mobile computing device i.e. a cellular phone GSM Global System for Mobile communications phone media player personal digital assistant PDA and the like which may enable a user to browse electronic documents in auditory manner. While some embodiments of the present invention are described with reference to an exemplary mobile computing device it should be appreciated that such embodiments are exemplary and are not intended to imply any limitation with regard to the environments or platforms in which different embodiments may be implemented.

As shown in the figure the client device includes a processing unit CPU in communication with a memory via a bus . Mobile device also includes a power supply one or more network interfaces an audio interface that may be configured to receive an audio input as well as to provide an audio output a display an input output interface and a haptic interface . The power supply provides power to the mobile device . A rechargeable or non rechargeable battery may be used to provide power. The power may also be provided by an external power source such as an AC adapter or a powered docking cradle that supplements and or recharges a battery.

The network interface includes circuitry for coupling the client device to one or more networks and is constructed for use with one or more communication protocols and technologies including but not limited to GSM code division multiple access CDMA time division multiple access TDMA user datagram protocol UDP transmission control protocol Internet protocol TCP IP short message service SMS general packet radio service GPRS wireless application protocol WAP ultra wide band UWB IEEE 802.16 Worldwide Interoperability for Microwave Access WiMax session initiation protocol real time transport protocol SIP RTP Bluetooth Wi Fi ZigBee universal mobile telecommunications system UMTS high speed downlink packet access HSDPA wideband CDMA W CDMA or any of a variety of other wired and or wireless communication protocols. The network interface is also known as a transceiver transceiving device or network interface card NIC .

The audio interface is arranged to produce and receive audio signals such as the sound of a human voice. For example the audio interface may be coupled to a speaker shown in and or microphone not shown to enable telecommunication with others and or render audio signals received from for example an audio browser program . The display may be a liquid crystal display LCD gas plasma light emitting diode LED or any other type of display used with a mobile computing device. At least in some embodiments of the present invention the display may also include a touch sensitive screen arranged to receive input from an object such as a stylus or a human finger.

The client device also includes the input output interface for communicating with external devices such as a set of headphones not shown or other input or output devices not shown in . The input output interface can utilize one or more communication technologies such as a universal serial bus USB infrared Bluetooth or the like. The haptic interface may be arranged to provide tactile feedback to a user of the mobile device . For example the haptic interface may be employed to vibrate the mobile device in a particular way when for example another user of a mobile computing device is calling.

The memory may include a RAM a ROM and other storage means. The memory illustrates an example of computer readable tangible storage media for storage of information such as computer readable instructions data structures program modules or other data. The memory may also store a basic input output system BIOS for controlling low level operation of the mobile device . The memory may also store an operating system for controlling the operation of the mobile device . It will be appreciated that this component may include a general purpose operating system such as a version of UNIX or LINUX or a specialized mobile communication operating system such as ANDROID Apple iOS BlackBerry OS and SYMBIAN OS . The operating system may include or interface with a Java virtual machine component that enables control of hardware components and or operating system operations via Java application programs.

The memory may further include one or more data storage units which can be utilized by the mobile device to store among other things applications and or other data. For example the data storage unit may be employed to store information that describes various capabilities of the mobile device a device identifier and the like. The data storage unit may also be used to store data generated by various applications as described below.

In one embodiment the data storage unit may also include one or more audio objects generated by the audio browser program as well as user s document browsing history. In this manner the mobile device may maintain at least for some period of time audio objects that may then be rendered to a user by employing for example the audio interface . The data storage unit may further include cookies and or user preferences including but not limited to user interface options and the like. At least a portion of the document browsing history audio objects and the like may also be stored on an optional hard disk drive optional portable storage medium or other storage medium not shown within the mobile device .

Applications may include computer executable instructions which when executed by the mobile device transmit receive and or otherwise process messages e.g. SMS MMS IMS IM email and or other messages audio video and enable telecommunication with another computing device and or with another user of another mobile device. Other examples of application programs include calendars browsers email clients IM applications VOIP applications contact managers task managers database programs word processing programs security applications spreadsheet programs games search programs and so forth. Applications may further include a web browser and an audio browser .

The web browser may include virtually any application for mobile devices configured to receive and render graphics text multimedia and the like employing virtually any web based language. In one embodiment the web browser application is enabled to employ Handheld Device Markup Language HDML Wireless Markup Language WML WMLScript JavaScript Standard Generalized Markup Language SMGL HyperText Markup Language HTML eXtensible Markup Language XML and the like to render received information. However any of a variety of other web based languages may also be employed.

The web browser may be configured to enable a user to access a webpage and or any other electronic document. The web browser may be integrated with an auditory user interface which may be configured to enable a visually impaired user to access the webpage and or electronic document in an auditory manner.

Referring now to audio browsing using a conventional auditory user interface of a mobile device is illustrated. The exemplary mobile device illustrated in may include a relatively large contact sensitive display . Specifically the contact sensitive display may be a resistive type touch screen that can sense the touch pressure applied by the user. In addition the exemplary mobile device may include a speaker disposed within the housing of the mobile device . The speaker may be employed to project audible sounds. The mobile device may be capable of running relatively sophisticated applications such as games document processing applications web browsers and the like. The example illustrated in depicts the mobile device running the web browser . For illustrative purposes only assume that a visually impaired user has navigated to a particular web page using the web browser . Typically a web page contains visual information that is rendered by the web browser . The web page shown in in addition to containing text content such as for example text string may also contain links to other web page files. For example a link may read Download the ASSETS 2012 Flyer PDF and may allow the user to download the corresponding file in PDF format. Another link may allow the user to navigate to a submission site. Furthermore the exemplary web page may contain a variety of images such as a button located near the link . However blind users cannot utilize the web page rendered by the web browser while visually impaired users may experience difficulty doing so. Accordingly the mobile device may be capable of running an auditory user interface that may assist blind and visually impaired users to access information when they use the mobile device . Specifically the auditory user interface may be a screen reader program that cooperates with the web browser and that reads aloud information appearing on the web page in response to receiving an input from the visually impaired user which may be a touch. The conventional auditory user interface may communicate directly with the contact sensitive display web browser or any other application running on the mobile device .

As illustrated in a visually impaired user may activate the auditory user interface by for example touching a particular portion of the contact sensitive display that can sense the touch pressure applied by the user s finger . In response to receiving the input the auditory user interface may read aloud the content of the web page located in the portion of the contact sensitive display selected by the user. In other words when the visually impaired user touches the button the auditory user interface may cause the speaker to read aloud a text associated with the button . In the example illustrated in the user may hear a first audio representation corresponding to the button such as Latest News. Image . In order to find out what other elements are contained within the web page the visually impaired user needs to move his her finger along the surface of the contact sensitive display . For example as shown in in response to the touch pressure applied to the portion of the contact sensitive display where the link is located the auditory user interface may render a second audio representation corresponding to the link . Thus the visually impaired user may hear the following synthesized speech The submission site is now available at . . . . illustrates further movement of the user s finger . In this example the finger applies touch pressure to the portion of the contact sensitive display containing the text string . In response the conventional auditory user interface would render a third audio representation corresponding to the text string . In other words the user would now hear April 3 by Assets 2012 .

As described above the conventional auditory user interface presents all information serially thus requiring the user to wait for some of the data to process. The conventional auditory user interface requires a user to memorize location of each of the spoken elements of the electronic document. Thus it would be desirable to have an auditory interface with an improved efficiency at which the visually impaired user can work.

In an embodiment of the present invention the web browser may be integrated with an audio browser which may be configured to enable a visually impaired user to access the webpage and or electronic document in an auditory manner. In one embodiment the audio browser may operate as a separate application widget or the like. However in another embodiment the audio browser may be configured as a plug in to the web browser . Thus the audio browser may comprise an optionally downloadable program or program component useable to enable a visually impaired user to navigate electronic document in auditory manner. In accordance with an embodiment of the present invention the audio browser may be configured to collect textual and non textual display information generated by the web browser and or a word processor and configured to generate an audio representation of a subset of the collected display information based on a user defined criteria and control information as described below.

Next at the audio browser program may utilize the DOM to classify the electronic document elements into one or more collections. In an embodiment of the present invention the elements may be classified based on content. For example a plurality of menu item elements may be combined into a menu collection. In an alternative embodiment the elements of the electronic document may be classified based on a proximity to the current focus position as described below.

Subsequently to creating the DOM associated with the electronic document at the audio browser program may generate an audio object for each of the elements identified at and or the audio browser program may generate an audio object for each collection generated at . The term audio object as used herein refers to an electronic form of an audio signal. Each audio object may convey information associated with a corresponding element collection of the electronic document. For example an audio object may contain a synthesized speech corresponding to the textual information contained within an electronic document element. Similarly an audio object may contain a synthesized speech corresponding to the name of the collection generated at . Additionally the audio browser program may also generate audio objects to convey non textual aspects of the information being delivered to the user. For instance different types of electronic document elements with which the user needs to interact buttons radio buttons combo boxes menus sliders check boxes and the like need to be identified to the visually impaired user by their type in order that the visually impaired user can understand how to interact with the element. Identifying the control type of the electronic document element may be done in a variety of ways. For example when the electronic document contains a check box the audio browser program may generate an audio object that can speak the text check box . Alternatively the generated audio object may play a sound that represents a check box to the visually impaired user. At least in some embodiments the generated audio objects may contain sounds that signify the action a visually impaired user should take in order to activate a particular control of the electronic document. It is contemplated that distinct voices and or sounds may be employed to represent various types of elements and or collections.

Furthermore the audio browser program may be capable of determining whether to render a collection name or individual elements included in the collection based on the proximity to the current focus position. In other words if a particular collection of elements is located substantially adjacent to a current focus position within the electronic document then the audio browser program may render to the user audio objects corresponding to each element of the collection. On the other hand if the collection of elements is located for example somewhere near the boundary of the grazing area discussed below the user may only hear for example the audio object that indicates a name of the collection.

Next at the audio browser program may obtain user s input indicative of a current position within the electronic document. According to an embodiment of the present invention the visually impaired user may use a finger and or a stylus like device to indicate the current position. In some exemplary embodiments the finger touch and or stylus location can be determined based on a global coordinate system of the contact sensitive display . In accordance with various embodiments of the present invention a single touch by a single finger may also indicate user s desire to navigate the electronic document in a particular direction. By way of example if a user touches the contact sensitive display so that his finger points to the left of the current position the audio browser program may in response render audio objects corresponding to electronic document elements located to the left of the selected position.

At the audio browser program may identify a grazing area shown in . As used herein the term grazing area refers to a predetermined range from the current focus position. In an embodiment of the present invention the grazing area may comprise a circle having a predetermined radius with a center at the current focus position. In alternative embodiment the grazing area may be shaped like a cone emanating from the current focus position in a direction specified by the user at . It is contemplated that the web browser may render only a portion of the electronic document on the contact sensitive display . Therefore in some embodiments of the present invention the grazing area may extend beyond the visible portion of the electronic document.

Then at the audio browser program may determine values of one or more rendering parameters for each audio object representing a corresponding electronic document element within the grazing area. The rendering parameters may include at least one of volume tempo treble and bass stereo width surround and dynamic range. For example in an embodiment of the present invention a value of the volume parameter may be adjusted for each audio object representing a document element within the grazing area based on a proximity to the current focus position. In other words the audio browser program may render the audio objects representing electronic document elements located in the immediate vicinity of the current focus position with a higher volume setting as compared to the audio objects representing the document elements located further from the current focus position. According to an embodiment of the present invention the farther away the element is from the current focus position the weaker is the sound of the corresponding audio object. Similarly the audio browser program may adjust the stereo width settings for each of the audio objects to indicate a relative direction of the corresponding document elements with respect to the current focus position. As a consequence of such adjustment the visually impaired user may perceive the sound of the signal as coming from a particular direction indicative of the corresponding element s position within the grazing area.

Next at the audio browser program may generate a multi channel audio signal by digitally encoding a plurality of audio objects that correspond to the plurality of electronic document elements contained within the grazing area. Various techniques and standards have been developed for communication of such multi channel audio signals. For example six discrete channels representing a 5.1 surround sound system may be transmitted in accordance with standards such as the Advanced Audio Coding AAC Dolby Digital and the like. In an alternative embodiment of the present invention the multi channel audio signal can be a stereo signal which comprises only two channels. The generated multi channel audio signal represents an audio summary of a portion of an electronic document contained within the grazing area. In an embodiment of the present invention the plurality of audio objects can be spatially audio encoded based on the rendering parameters determined at step . As previously indicated the grazing area may extend beyond the portion of the electronic document rendered on the contact sensitive display . Accordingly the generated audio summary may include elements that are not currently rendered by the web browser program on the contact sensitive display . In other words the audio browser program facilitates an awareness of the not yet displayed electronic document elements contained within the user specified grazing area.

Subsequently at step the audio browser program may send the audio summary to the audio interface of the mobile device . In an embodiment of the present invention the audio interface may include a decoder capable of decoding the rendering parameters of the multi channel audio signal in accordance with the selected standard. If the mobile device has a relatively limited processing power the decoder of the audio interface may be computationally optimized. Furthermore in a preferred embodiment the multi channel audio signal may be rendered to a visually impaired user through the earplugs or headphones coupled to the mobile device . In an embodiment of the present invention the multi channel surround sound audio signal may be delivered by employing for example but not limited to 3D audio or binaural rendering techniques well known in the art.

At decision block the audio browser program may determine whether the current focus position within the electronic document has changed. In other words the audio browser program may determine whether the user provided a new input indicative of a new current position and or direction within the electronic document. In response to determining that the user provided an updated position and or direction the audio browser program may repeat through in order to generate a new audio summary based on the updated user specified spatial and or directional input.

Thus the audio summary generated by the audio browser program in accordance with various embodiments of the present invention allows a visually impaired user to hear a particular section of an electronic document thereby precluding the need to hear the entire electronic document and allows the user to navigate only through information that he or she is interested in. Use of the audio summary on the mobile device enhances navigation in an electronic document for both blind and visually impaired users. Advantageously rather than hearing the potentially large electronic document sequentially which makes the audio navigation through large electronic documents time consuming the users may iteratively navigate the electronic document based on the provided audio summary. This improves the efficiency at which a visually impaired user can work.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computing device partly on the user s computing device as a stand alone software package partly on the user s computing device and partly on a remote computing device or entirely on the remote computing device or server computer. In the latter scenario the remote computing device may be connected to the user s computing device through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computing device for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer mobile device or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computing device or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computing device other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computing device other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computing device other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

The description above has been presented for illustration purposes only. It is not intended to be an exhaustive description of the possible embodiments. One of ordinary skill in the art will understand that other combinations and embodiments are possible.

