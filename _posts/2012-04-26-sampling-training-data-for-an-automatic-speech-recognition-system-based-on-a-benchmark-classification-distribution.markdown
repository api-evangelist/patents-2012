---

title: Sampling training data for an automatic speech recognition system based on a benchmark classification distribution
abstract: A set of benchmark text strings may be classified to provide a set of benchmark classifications. The benchmark text strings in the set may correspond to a benchmark corpus of benchmark utterances in a particular language. A benchmark classification distribution of the set of benchmark classifications may be determined. A respective classification for each text string in a corpus of text strings may also be determined. Text strings from the corpus of text strings may be sampled to form a training corpus of training text strings such that the classifications of the training text strings have a training text string classification distribution that is based on the benchmark classification distribution. The training corpus of training text strings may be used to train an automatic speech recognition (ASR) system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08374865&OS=08374865&RS=08374865
owner: Google Inc.
number: 08374865
owner_city: Mountain View
owner_country: US
publication_date: 20120426
---
A goal of automatic speech recognition ASR technology is to map a particular audio utterance to an accurate textual representation of that utterance. For instance ASR performed on the utterance cat and dog would ideally be mapped to the text string cat and dog rather than the nonsensical text string skate and hog or the sensible but inaccurate text string Kate and Doug. An ASR system can be trained with a language s syntax as appearing in a large corpus of training text strings. However ASR system performance may vary based on the characteristics of this corpus.

In a first example embodiment a set of benchmark text strings may be classified to provide a set of benchmark classifications. The benchmark text strings may correspond to a benchmark corpus of benchmark utterances in a particular language. A benchmark classification distribution of the set of benchmark classifications may be determined. A respective classification for each text string in a corpus of text strings may also be determined. Text strings from the corpus of text strings may be sampled to form a training corpus of training text strings such that the classifications of the training text strings have a training text string classification distribution that is based on the benchmark classification distribution. The training corpus of training text strings may be used to train an ASR system.

A second example embodiment may include a non transitory computer readable medium having stored thereon program instructions that upon execution by a computing device cause the computing device to perform operations in accordance with the first example embodiment.

A third example embodiment may include a computing system comprising at least one processor data storage and program instructions in the data storage that upon execution by the at least one processor cause the computing system to operate in accordance with the first example embodiment.

These as well as other aspects advantages and alternatives will become apparent to those of ordinary skill in the art by reading the following detailed description with reference where appropriate to the accompanying drawings. Further it should be understood that the description provided in this summary section and elsewhere in this document is intended to illustrate the claimed subject matter by way of example and not by way of limitation.

A corpus of utterance to text string mappings may be used to train an ASR system. In particular these mappings may contain a quantity of audio utterances e.g. audio files of human speech . In some implementations there may be thousands tens of thousands hundreds of thousands tens of millions or more audio utterances. The mappings may associate each audio utterance with a manually transcribed and or automatically transcribed text string of that audio utterance. Possibly using various mathematical and or machine learning techniques the ASR system may use the corpus to develop probabilistic mappings between sounds and phonemes phoneme patterns and words and or words and word frequencies. These probabilistic mappings may be represented as a search graph.

In some embodiments the ASR system may be trained offline prior to becoming operational. For example training an ASR system with a large corpus may take several hours or days. On the other hand the ASR system may instead be trained online. In the latter case the ASR system may be dynamically updated while operating.

An ASR system may include a language model. Briefly as language models will be described in more detail in later sections a language model may represent the conditional probability of a particular word appearing in a phrase given the pattern of the n 1 previous words in the phrase. For example given a phrase containing the pattern in the a language model might assign a relatively high probability to the next word being house and a relatively low probability to the next word being louse. 

ASR systems may use a language model to improve speech recognition accuracy by taking phrase level and sentence level context into account. Thus language models may be developed based on a large corpus of phrases and sentences in a particular language. For instance a language model can be trained with a database of millions of phrases and or sentences derived from general usage of the particular language.

However the performance of the language model may vary dramatically based on the characteristics of the phrases and or sentences used to train the language model. Thus a language model trained with phrases and or sentences derived from World Wide Web WWW documents may perform poorly when used by an ASR system to recognize utterances from voice instant messaging applications. Similarly a language model trained with phrases and or sentences derived from voice instant messaging applications may perform poorly when used by an ASR system to recognize utterances from news broadcasts.

Consequently it may be beneficial to train the language model of an ASR system with phrases and or sentences related to the language domain in which the ASR system is expected to be used. One way of doing so is to sample training data from a corpus of phrases and or sentences such that the sampled training data exhibits characteristics that match or are similar to those of speech from one or more target users. These characteristics may include but are not limited to topics style e.g. formal or spontaneous and dialect of the target users speech.

For example a language model for recognizing voice instant messaging can be developed by gathering a benchmark set of utterances made by users of voice instant messaging applications. Each of these benchmark utterances may be transcribed into a corresponding benchmark text string. Then a topic classifier may be applied to these benchmark text strings.

In some embodiments the topic classifier may estimate or otherwise determine one or more topics discussed in each benchmark text string. Examples of topics include news sports weather economics politics technology science business entertainment health general conversation etc.

Once the text strings are classified a benchmark topic distribution of the benchmark text strings may be determined. For instance 50 of the benchmark text strings may be general conversation 20 news 10 sports and so on. The same or a similar topic classifier may be used to determine the topics of a large corpus of text strings. Then training data can be sampled from the large corpus of text strings such that the topic distribution of the training data approximates the benchmark topic distribution. Thus the training data may be used to train the language model of an ASR system for voice instant messaging applications. In this way the ASR system is trained so that it is more likely to be able to accurately recognize utterances made to voice instant messaging applications.

The above processes and example embodiments thereof will be described in detail in Sections 5 and 6. However in order to further embody ASR system implementations the next three sections describe respectively example computing systems and devices that may support ASR systems an overview ASR systems training and an overview of ASR system operation.

ASR systems have been deployed in various environments. Some ASR systems are just a single machine e.g. a personal computer into which a user speaks utterances and the ASR system transcribes the utterances into one or more text strings. Other ASR systems are client server based in which the user speaks an utterance into a client device and the client device may encode the utterance and transmit it to a server device. Then the server device performs speech recognition on the encoded utterance and transmits one or more text string mappings to the client device for presentation to the user. Particularly on wireless communication devices such as mobile phones client server based ASR can be supported by Internet search applications geo location and mapping applications text messaging and instant messaging applications and by virtually any third party application as well. The server component of an ASR system may include just a single server device or may be distributed in various ways across a number of server devices.

The methods devices and systems described herein can be implemented using client devices and or so called cloud based server devices. Under various aspects of this paradigm client devices such as mobile phones and tablet computers may offload some processing and storage responsibilities to remote server devices. At least some of the time these client services are able to communicate via a network such as the Internet with the server devices. As a result applications that operate on the client devices may also have a persistent server based component. Nonetheless it should be noted that at least some of the methods processes and techniques disclosed herein may be able to operate entirely on a client device or a server device.

Furthermore the server devices described herein may not necessarily be associated with a client server architecture and therefore may be interchangeably referred to as computing devices. Similarly the client devices described herein also may not necessarily be associated with a client server architecture and therefore may be interchangeably referred to as user devices. 

This section describes general system and device architectures for such client devices and server devices. However the methods devices and systems presented in the subsequent sections may operate under different paradigms as well. Thus the embodiments of this section are merely examples of how these methods devices and systems can be enabled.

Network may be for example the Internet or some other form of public or private Internet Protocol IP network. Thus client devices and may communicate using packet switching technologies. Nonetheless network may also incorporate at least some circuit switching technologies and client devices and may communicate via circuit switching alternatively or in addition to packet switching.

A server device may also communicate via network . Particularly server device may communicate with client devices and according to one or more network protocols and or application level protocols to facilitate the use of network based or cloud based computing on these client devices. Server device may include integrated data storage e.g. memory disk drives etc. and may also be able to access a separate server data storage . Communication between server device and server data storage may be direct via network or both direct and via network as illustrated in . Server data storage may store application data that is used to facilitate the operations of applications performed by client devices and and server device .

Although only three client devices one server device and one server data storage are shown in communication system may include any number of each of these components. For instance communication system may comprise millions of client devices thousands of server devices and or thousands of server data storages. Furthermore client devices may take on forms other than those in .

User interface may comprise user input devices such as a keyboard a keypad a touch screen a computer mouse a track ball a joystick and or other similar devices now known or later developed. User interface may also comprise user display devices such as one or more cathode ray tubes CRT liquid crystal displays LCD light emitting diodes LEDs displays using digital light processing DLP technology printers light bulbs and or other similar devices now known or later developed. Additionally user interface may be configured to generate audible output s via a speaker speaker jack audio output port audio output device earphones and or other similar devices now known or later developed. In some embodiments user interface may include software circuitry or another form of logic that can transmit data to and or receive data from external user input output devices.

Communication interface may include one or more wireless interfaces and or wireline interfaces that are configurable to communicate via a network such as network shown in . The wireless interfaces if present may include one or more wireless transceivers such as a BLUETOOTH transceiver a Wifi transceiver perhaps operating in accordance with an IEEE 802.11 standard e.g. 802.11b 802.11g 802.11n a WiMAX transceiver perhaps operating in accordance with an IEEE 802.16 standard a Long Term Evolution LTE transceiver perhaps operating in accordance with a 3rd Generation Partnership Project 3GPP standard and or other types of wireless transceivers configurable to communicate via local area or wide area wireless networks. The wireline interfaces if present may include one or more wireline transceivers such as an Ethernet transceiver a Universal Serial Bus USB transceiver or similar transceiver configurable to communicate via a twisted pair wire a coaxial cable a fiber optic link or other physical connection to a wireline device or network.

Processor may include one or more general purpose processors e.g. microprocessors and or one or more special purpose processors e.g. digital signal processors DSPs graphical processing units GPUs floating point processing units FPUs network processors or application specific integrated circuits ASICs . Processor may be configured to execute computer readable program instructions that are contained in data storage and or other instructions to carry out various functions described herein.

Thus data storage may include one or more non transitory computer readable storage media that can be read or accessed by processor . The one or more computer readable storage media may include volatile and or non volatile storage components such as optical magnetic organic or other memory or disc storage which can be integrated in whole or in part with processor . In some embodiments data storage may be implemented using a single physical device e.g. one optical magnetic organic or other memory or disc storage unit while in other embodiments data storage may be implemented using two or more physical devices.

Data storage may also include program data that can be used by processor to carry out functions described herein. In some embodiments data storage may include or have access to additional data storage components or devices e.g. cluster data storages described below .

Server device and server data storage device may store applications and application data at one or more places accessible via network . These places may be data centers containing numerous servers and storage devices. The exact physical location connectivity and configuration of server device and server data storage device may be unknown and or unimportant to client devices. Accordingly server device and server data storage device may be referred to as cloud based devices that are housed at various remote locations. One possible advantage of such cloud based computing is to offload processing and data storage from client devices thereby simplifying the design and requirements of these client devices.

In some embodiments server device and server data storage device may be a single computing device residing in a single data center. In other embodiments server device and server data storage device may include multiple computing devices in a data center or even multiple computing devices in multiple data centers where the data centers are located in diverse geographic locations. For example depicts each of server device and server data storage device potentially residing in a different physical location.

In some embodiments each of the server clusters A B and C may have an equal number of server devices an equal number of cluster data storages and an equal number of cluster routers. In other embodiments however some or all of the server clusters A B and C may have different numbers of server devices different numbers of cluster data storages and or different numbers of cluster routers. The number of server devices cluster data storages and cluster routers in each server cluster may depend on the computing task s and or applications assigned to each server cluster.

In the server cluster A for example server devices A can be configured to perform various computing tasks of server device . In one embodiment these computing tasks can be distributed among one or more of server devices A. Server devices B and C in server clusters B and C may be configured the same or similarly to server devices A in server cluster A. On the other hand in some embodiments server devices A B and C each may be configured to perform different functions. For example server devices A may be configured to perform one or more functions of server device and server devices B and server device C may be configured to perform functions of one or more other server devices. Similarly the functions of server data storage device can be dedicated to a single server cluster or spread across multiple server clusters.

Cluster data storages A B and C of the server clusters A B and C respectively may be data storage arrays that include disk array controllers configured to manage read and write access to groups of hard disk drives. The disk array controllers alone or in conjunction with their respective server devices may also be configured to manage backup or redundant copies of the data stored in cluster data storages to protect against disk drive failures or other types of failures that prevent one or more server devices from accessing one or more cluster data storages.

Similar to the manner in which the functions of server device and server data storage device can be distributed across server clusters A B and C various active portions and or backup redundant portions of these components can be distributed across cluster data storages A B and C. For example some cluster data storages A B and C may be configured to store backup versions of data stored in other cluster data storages A B and C.

Cluster routers A B and C in server clusters A B and C respectively may include networking equipment configured to provide internal and external communications for the server clusters. For example cluster routers A in server cluster A may include one or more packet switching and or routing devices configured to provide i network communications between server devices A and cluster data storage A via cluster network A and or ii network communications between the server cluster A and other devices via communication link A to network . Cluster routers B and C may include network equipment similar to cluster routers A and cluster routers B and C may perform networking functions for server clusters B and C that cluster routers A perform for server cluster A.

Additionally the configuration of cluster routers A B and C can be based at least in part on the data communication requirements of the server devices and cluster storage arrays the data communications capabilities of the network equipment in the cluster routers A B and C the latency and throughput of the local cluster networks A B C the latency throughput and cost of the wide area network connections A B and C and or other factors that may contribute to the cost speed fault tolerance resiliency efficiency and or other design goals of the system architecture.

As shown in client device may include a communication interface a user interface a processor and data storage all of which may be communicatively linked together by a system bus network or other connection mechanism .

Communication interface functions to allow client device to communicate using analog or digital modulation with other devices access networks and or transport networks. Thus communication interface may facilitate circuit switched and or packet switched communication such as POTS communication and or IP or other packetized communication. For instance communication interface may include a chipset and antenna arranged for wireless communication with a radio access network or an access point. Also communication interface may take the form of a wireline interface such as an Ethernet Token Ring or USB port. Communication interface may also take the form of a wireless interface such as a Wifi BLUETOOTH global positioning system GPS or wide area wireless interface e.g. WiMAX or LTE . However other forms of physical layer interfaces and other types of standard or proprietary communication protocols may be used over communication interface . Furthermore communication interface may comprise multiple physical communication interfaces e.g. a Wifi interface a BLUETOOTH interface and a wide area wireless interface .

User interface may function to allow client device to interact with a human or non human user such as to receive input from a user and to provide output to the user. Thus user interface may include input components such as a keypad keyboard touch sensitive or presence sensitive panel computer mouse trackball joystick microphone still camera and or video camera. User interface may also include one or more output components such as a display screen which for example may be combined with a presence sensitive panel CRT LCD LED a display using DLP technology printer light bulb and or other similar devices now known or later developed. User interface may also be configured to generate audible output s via a speaker speaker jack audio output port audio output device earphones and or other similar devices now known or later developed. In some embodiments user interface may include software circuitry or another form of logic that can transmit data to and or receive data from external user input output devices. Additionally or alternatively client device may support remote access from another device via communication interface or via another physical interface not shown .

Processor may comprise one or more general purpose processors e.g. microprocessors and or one or more special purpose processors e.g. DSPs GPUs FPUs network processors or ASICs . Data storage may include one or more volatile and or non volatile storage components such as magnetic optical flash or organic storage and may be integrated in whole or in part with processor . Data storage may include removable and or non removable components.

Generally speaking processor may be capable of executing program instructions e.g. compiled or non compiled program logic and or machine code stored in data storage to carry out the various functions described herein. Therefore data storage may include a non transitory computer readable medium having stored thereon program instructions that upon execution by client device cause client device to carry out any of the methods processes or functions disclosed in this specification and or the accompanying drawings. The execution of program instructions by processor may result in processor using data .

By way of example program instructions may include an operating system e.g. an operating system kernel device driver s and or other modules and one or more application programs e.g. address book email web browsing social networking and or gaming applications installed on client device . Similarly data may include operating system data and application data . Operating system data may be accessible primarily to operating system and application data may be accessible primarily to one or more of application programs . Application data may be arranged in a file system that is visible to or hidden from a user of client device .

Application programs may communicate with operating system through one or more application programming interfaces APIs . These APIs may facilitate for instance application programs reading and or writing application data transmitting or receiving information via communication interface receiving or displaying information on user interface and so on.

In some vernaculars application programs may be referred to as apps for short. Additionally application programs may be downloadable to client device through one or more online application stores or application markets. However application programs can also be installed on client device in other ways such as via a web browser or through a physical interface e.g. a USB port on client device .

Before describing language model training in detail it may be beneficial to understand overall ASR system training and operation. Thus this section describes ASR systems in general including how the language model can interact with other logical components of an ASR system in order to facilitate speech recognition.

It should be noted that the discussion in this section and the accompanying figures are presented for purposes of example. Other methods of training an ASR system including different modules different configurations of modules and or different training steps may be possible.

A phoneme may be considered to be the smallest segment of an utterance that encompasses a meaningful contrast with other segments of utterances. Thus a word typically includes one or more phonemes. For purposes of simplicity phonemes may be thought of as utterances of letters but this is not a perfect analogy as some phonemes may present multiple letters. An example phonemic spelling for the American English pronunciation of the word cat is kaet consisting of the phonemes k ae and t. Another example phonemic spelling is d aw g consisting of the phonemes d aw and g. 

Different phonemic alphabets exist and these alphabets may have different textual representations for the various phonemes therein. For example the letter a may be represented by the phoneme ae when used to make the a sound in cat by the phoneme ey when used to make the a sound in ate and by the phoneme ah when used to make the a sound in beta. Other phonemic representations are possible.

Common phonemic alphabets for American English contain about 40 distinct phonemes. Each of these phonemes may be associated with a different set of nominal output vector values. Thus acoustic model may be able to estimate the phoneme s in a sample utterance by analyzing the sample in the time and or frequency domains and finding the phoneme with nominal output vector values e.g. frequency characteristics that best match the output vector values of the sample. Or put another way acoustic model can be used to provide scores every s milliseconds that describe how well the current sound in an utterance matches some or all possible phonemic sounds.

This process is illustrated in . For the input utterance cat and dog acoustic model may phonemically interpret this utterance as k ae t ae n d d aw g . assumes that the input utterance is clean and that acoustic model is well trained. In some environments the input utterance may be distorted by background noise clipping or some other form of interference. Also for some input utterances particularly those with uncommon words or words spoken with an unknown accent acoustic model may incorrectly evaluate the input utterance.

One way of implementing an acoustic model such as acoustic model is by using a hidden Markov model HMM . Some HMM based acoustic models may also consider context when performing this mapping. For example acoustic model may consider the phoneme that precedes the current sample to provide a better estimate of the phoneme represented by the current sample. The use of context in this fashion can account for certain phoneme combinations e.g. aet being more common than other phoneme combinations e.g. tk . But HMMs are just one technology that can be employed to develop an acoustic model and acoustic model can be based on technology other than HMMs.

Furthermore acoustic model may operate based on syllables or a segment of language other than context dependent phonemic sounds. For instance acoustic model may interpret a series of phonemes as syllables or as one or more words. For purposes of simplicity throughout this specification and the accompanying drawings it is assumed that acoustic models represent one or more phonemes as context dependent phonemic sounds. However acoustic models that use other types of representations are within the scope of the embodiments herein.

Once one or more phonemes are interpreted from an input utterance dictionary may be used to determine a pre established mapping e.g. from a list of tens or hundreds of thousands of phoneme pattern to word mappings of these phonemes into words. This process is illustrated by . For the input phonemic interpretation k ae t ae n d d aw g dictionary provides a mapping to the text string cat and dog. 

In some embodiments dictionary may include a lookup table such as Table 1. Table 1 illustrates how dictionary may list the phonemic sequences that search graph uses for the words that the ASR system is attempting to recognize.

Turning back to one output of the ASR system training process may be language model . Language model may define the conditional probability of w the nth word in a phrase transcribed from an utterance given the values of the pattern of n 1 previous words in the phrase. More formally language model may define In general a language model may operate on n grams which for example may be sequences of n words that were recognized from the utterances in corpus via acoustic model and dictionary . Alternatively or additionally the n grams may be derived from a corpus of phrases and sentences written in a target language.

In some embodiments a language model may operate on a sequence of n phonemes syllables words or series of words. In practice language models with values of n greater than 5 are rarely used because of their computational complexity and also because smaller n grams e.g. 3 grams which are also referred to as tri grams tend to yield acceptable results. In the example described below tri grams are used for purposes of illustration. Nonetheless any value of n may be may be used with the embodiments herein.

Thus through analysis of the corpus tri gram probabilities can be estimated based on their respective number of appearances in the training corpus. In other words if C w w w is the number of occurrences of the word pattern w w win corpus then

Thus a language model may be represented as a table of conditional probabilities. Table 2 illustrates a simple example of such a table that could form the basis of language model . Particularly Table 2 contains tri gram conditional probabilities.

For the 2 gram prefix cat and Table 2 indicates that based on the observed occurrences in corpus 50 of the time the next 1 gram is dog. Likewise 35 of the time the next 1 gram is mouse 14 of the time the next 1 gram is bird and 1 of the time the next 1 gram is fiddle. Clearly in a fully trained ASR system the language model would contain many more entries and these entries would include more than just one 2 gram prefix.

Nonetheless using the observed frequencies of word patterns from a corpus of speech and or from other sources is not perfect as some acceptable tri grams may not appear in the training corpus and may therefore be assigned a probability of zero. Consequently when given a zero probability tri gram at run time the language model may instead attempt to map this tri gram to a different tri gram associated with a non zero probability.

In order to reduce this likelihood the language model may be smoothed so that zero probability tri grams have small non zero probabilities and the probabilities of the tri grams in the training corpus are reduced accordingly. In this way tri grams not found in the training corpus can still be recognized by the language model.

Another possible output from the ASR training process illustrated in is a search graph such as search graph . A search graph may be a data structure that represents the totality or a large part of the speech patterns of an input corpus and may serve to enable rapid recognition of new input utterances in an operational ASR system. Thus search graph may be based on output from acoustic model dictionary and language model .

Each circle in search graph may represent a state associated with the processing of an input utterance that has been mapped to phonemes. These states are named based on the current phoneme context of the input utterance using the format x y z to indicate that the current phoneme being considered y has a left context of the phoneme x and a right context of the phoneme z. In other words the state x y z indicates a point in processing an utterance in which the current phoneme being considered is y the previously phoneme in the utterance is x and the next phoneme in the utterance is z. The beginning of an utterance and the end of an utterance are represented by the character and also may be referred to as null phonemes.

Terminal states may be represented by a recognized word or phrase in quotes. Search graph includes five terminal states representing recognition of the words or phrases catapult cat and mouse cat and dog cat and cap. 

Transitions from one state to another may represent an observed ordering of phonemes in the corpus. For instance the state k ae represents the recognition of a k phoneme with a left context of a null phoneme and a right context of an ae phoneme. There are two transitions from the state k ae one for which the next phoneme the phoneme after the ae is a t and another for which the next phoneme is a p. 

Based on acoustic model dictionary and language model costs may be assigned to one or more of the states and or transitions. For example if a particular phoneme pattern is rare a transition to a state representing that phoneme pattern may have a higher cost than a transition to a state representing a more common phoneme pattern. Similarly the conditional probabilities from the language model see Table 2 for examples may also be used to assign costs to states and or transitions. For instance in Table 2 given a phrase with the words cat and the conditional probability of the next word in the phrase being dog is 0.5 while the conditional probability of the next word in the phrase being mouse is 0.35. Therefore the transition from state ae n d to state n d m may have a higher cost than the transition from state ae n d to state n d d. 

Once an ASR system is trained search graph possibly including any states transitions between states and associated costs therein may be used to estimate text string transcriptions for new input utterances. The next section describes ASR system operation in more detail.

An illustrative model of an operational ASR system is shown in . Example ASR system may include representations of acoustic model dictionary language model and search graph . Alternatively ASR system may omit one or more of these modules. For example characteristics of dictionary and language model may be incorporated into the structure of search graph and therefore may not be necessary in ASR system .

Input to ASR system may be an input utterance such as a word a phrase a sentence or a series of sentences. The input utterance may take the form of an analog or digital audio signal. Output from ASR system may be one or more text strings that the ASR system has transcribed based on the input utterance. While ASR system may seek to produce accurate text string transcriptions of input utterances this may not always be possible. Thus for some input utterances ASR system may produce more than one possible text string transcription that could match the input utterance. For instance ASR system may estimate the N best transcriptions of an input utterance and output one or more of these transcriptions.

Additionally shows search module being coupled with search graph and search graph being coupled with acoustic model dictionary and language model . However other arrangements are possible. For instance search module may interact directly with acoustic model and or dictionary .

Search module may be used to determine a sequence of one or more words that matches an input utterance. Formally search module may attempt to find max where a is a stream of feature vectors derived from the input utterance P a w represents the probability of those feature vectors being produced by a word sequence w and P w is the probability assigned to w by language model . For example P w may be based on n gram conditional probabilities as discussed above as well as other factors. The function argmaxmay return the value of w that maximizes P a w P w .

Particularly as part of the process of transcribing the input utterance to one or more text strings search module may apply acoustic model to the input utterance. The result of this step may be a sequence of phonemes. Then the sequence may serve as input to search graph . In some embodiments search module may attempt to find paths from an initial state in search graph to a terminal state in search graph based on this sequence. This process may involve search module performing a breadth first search depth first search beam search or some other type of search. Search module may assign a total cost to one or more paths based on costs associated with the states and or transitions of each path. Some of these costs may reflect for instance a confidence level that a particular segment of the utterance maps to a particular phoneme context in the path.

As an example suppose that the input utterance is the phrase cat and dog. Referring back to in a possible scenario search module would step through search graph phoneme by phoneme and find the path beginning with initial state k ae and ending with terminal state cat and dog. Search module may also find one or more additional paths through search graph . For example search module may also associate the input utterance with the path with initial state k ae and ending with terminal state cat and mouse and with the path with initial state k ae and ending with terminal state catapult. Nonetheless search module may assign a lower cost to the path with terminal state cat and dog than to each of the other paths. Consequently the path with terminal state cat and dog may be selected as the best transcription for the input utterance.

It should be understood that ASR systems can operated in many different ways. The embodiments described above are presented for purposes of illustration and may not be the only way in which an ASR system operates.

As noted in Section 1 training data for a language model may be developed by sampling a large corpus of text strings according to a benchmark classification distribution. In order to do so the benchmark classification distribution may first be obtained. depicts an example embodiment that derives a benchmark topic distribution of a set of benchmark text strings.

Benchmark utterances may be digital encodings of human voice. In some cases a benchmark utterance may be a small number of words from an uttered phrase or sentence. In other cases a benchmark utterance may be a larger number of words from one or more uttered phrases or sentences. Thus benchmark utterances may include utterances made by users of voice recognition applications e.g. voice search voice maps and or voice instant messaging . Alternatively or additionally benchmark utterances may include utterances from broadcast news sporting events speeches and so on. It should be understood that benchmarks utterances can be gathered from any source and may be gathered from multiple sources.

Benchmark utterances may be of a particular language domain in order to train an ASR system to perform effectively on utterances from that language domain. Thus benchmark utterances could be entirely or primarily from a particular source from a particular user or users in a particular dialect etc. In some embodiments benchmark utterances may consist of a relatively small set of utterances perhaps no more than 30 minutes total. However larger or smaller sets of benchmark utterances may be used.

Benchmark utterances may be transcribed to produce benchmark text strings . This transcription process may be automated e.g. performed by a computing device manual e.g. performed by a human or some combination thereof. In some cases the transcription may be performed by a non real time ASR system. One advantage of using a non real time ASR system is that it can dedicate more time than a real time ASR system to e.g. evaluating phonemes and or exploring various paths of its search graph. For example a non real time ASR system may utilize a multi decoding pass system to perform lattice rescoring. As a result a non real time ASR system may produce a high quality transcription of input utterances.

Once one or more of benchmark text strings are transcribed these text strings may be classified. Various techniques of text string classification may be used. For instance the classifier may search each text string for keywords that are indicative of certain topics. Upon finding one or more of the keyword s associated with a particular topic the classifier may indicate that the text string contains text related to that topic.

Examples of classification are shown in benchmark topics . The text strings gas prices and poll results are both classified as news while the text string hockey scores is classified as sports and the text string call me later is classified as conversation. Nonetheless there may be different ways of performing text string classification. For instance there may be tens hundreds or thousands of topics. Thus in some scenarios the topic news could be subdivided into additional subtopics such that the text string gas prices is classified as economics and the text string poll results is classified as politics. 

Alternatively or additionally the benchmark text strings may be classified in other ways such as based on speech style or dialect. Thus in some embodiments the classifier may classify all text strings into one of two speech style categories formal or spontaneous. For instance text strings derived from broadcast news recordings might be classified as formal speech while text strings derived from voice instant messaging or voice search might be classified as spontaneous speech. Of course more than just two categories of speech style may be used.

Similarly in other embodiments the classifier may classify all text strings into one or more dialects. It should be noted that in general a dialect refers to a vocabulary grammar and or pronunciation of a language that is particular to a group of speakers. Thus a dialect may be specific to a geographic region a social class and or cultural class. For example a speaker who is native to New York City may speak a notably different dialect of American English than a speaker who is native to Texas.

Throughout the rest of this specification and its accompanying drawings text string classification will be shown by topic for purposes of illustration. However it should be understood that text strings can be classified based any one or more of topic style dialect or other types of categories now known or developed in the future.

Once benchmark topics are determined a benchmark topic distribution can be obtained. This distribution may represent the relative likelihood that each benchmark topic is the result of a classification of a benchmark text string. Thus the benchmark topic distribution for benchmark text strings is 50 news 25 sports and 25 conversation. One way in which a benchmark topic distribution can be determined is to count the number of times each particular benchmark topic occurs in benchmark topics and divide the result by the total number of text strings in benchmark text strings .

In at least some embodiments the benchmark topic distribution may represent the distribution of topics that occur in benchmark utterances and thus provide a reasonable estimate of the topic distribution in the target language domain for which the ASR system is expected to be used. Since the number of utterances in benchmark utterances may be too small to effectively train an ASR system it may be beneficial to sample a much larger corpus of text strings to derive training data from the ASR system. This much larger corpus may be sampled such that the resulting training data exhibits a topic distribution that is roughly equivalent to the benchmark topic distribution. This resulting training data is likely to be able to train the ASR system to perform effectively in the target language domain.

Text strings may be classified into topics . The classifier used to perform this classification may be the same as or similar to the classifier used to classify benchmark text strings into benchmark topics . Once at least some of topics are known text strings can be sampled to form training text strings . As noted above this sampling may be conducted such that the topic distribution of training text strings matches the benchmark topic distribution. Thus as shown in 50 of training text strings were classified as news 25 as sports and 25 as conversation.

One way in which the topic distribution of training text strings can be made to match the benchmark topic distribution is to sample text strings according to the following method. Assume that there are c text strings in text strings and a goal is to have t text strings in training text strings . In some embodiments t may be smaller than c.

Assume further that B i is the representation of topic i in the benchmark topic distribution where B i 1. For example in the benchmark topic distribution discussed above B news B sports and B conversation . Also assume that N i is the number of text strings classified with topic i in text strings . Then each text string in text strings may be sampled according to the probability given by

Nonetheless the example provided above is merely for purposes of illustration. Text strings may be sampled in other ways in order to obtain a training topic distribution of training text strings that is based on the benchmark topic distribution.

Once training text strings are determined they may be used to train the language model of an ASR system. In some implementations this may involve in accordance with the discussion in Section 3C calculating

At step a set of benchmark text strings may be classified to provide a set of benchmark classifications. At step a benchmark classification distribution of the set of benchmark classifications may be determined.

The benchmark text strings in the set may correspond to a benchmark corpus of benchmark utterances in a particular language and each benchmark text string in the set of benchmark text strings may have been transcribed from a respective benchmark utterance in the benchmark corpus of benchmark utterances. The set of benchmark classifications may include topic classifications speaking style classifications dialect classifications or some other type of classification.

Further the benchmark utterances may have been made by users in a category of users and the ASR system may be configured to transcribe new utterances made by these users. For instance the benchmark utterances may have been made by a single user by users with a particular dialect and or by users from a particular geographic location.

At step a respective classification for each text string in a corpus of text strings may be determined. Each text string in the corpus of text strings may have been transcribed from a respective utterance from an associated corpus of utterances or may have been derived from some other source.

At step text strings from the corpus of text strings may be sampled to form a training corpus of training text strings such that the classifications of the training text strings have a training text string classification distribution that is based on the benchmark classification distribution. For example the training text string classification distribution may be substantially similar to the benchmark classification distribution. In other words the training text string classification distribution may differ to some extent from the benchmark classification distribution but should still reflect at least some statistical properties of the benchmark classification distribution.

In some embodiments there may be fewer benchmark text strings in the benchmark corpus than training text strings in the training corpus. For example there may be a few hundred benchmark text strings but millions or more training text strings.

At step the training corpus of training text strings may be used to train an ASR system. The training may involve training a language model of the ASR system with a combination of the training corpus of training text strings and an additional corpus of text strings that were transcribed from utterances made by users of the ASR system.

The above detailed description describes various features and functions of the disclosed systems devices and methods with reference to the accompanying figures. In the figures similar symbols typically identify similar components unless context dictates otherwise. The illustrative embodiments described in the detailed description figures and claims are not meant to be limiting. Other embodiments can be utilized and other changes can be made without departing from the spirit or scope of the subject matter presented herein. It will be readily understood that the aspects of the present disclosure as generally described herein and illustrated in the figures can be arranged substituted combined separated and designed in a wide variety of different configurations all of which are explicitly contemplated herein.

For situations in which the systems discussed here collect personal information about users the users may be provided with an opportunity to opt in out of programs or features that may collect personal information e.g. information about a user s preferences or a user s utterances made to an ASR system . In addition certain data may be anonymized in one or more ways before it is stored or used so that personally identifiable information is removed. For example a user s identity may be anonymized so that the no personally identifiable information can be determined for the user and so that any identified user preferences or user interactions are generalized for example generalized based on user demographics rather than associated with a particular user.

With respect to any or all of the message flow diagrams scenarios and flow charts in the figures and as discussed herein each step block and or communication may represent a processing of information and or a transmission of information in accordance with example embodiments. Alternative embodiments are included within the scope of these example embodiments. In these alternative embodiments for example functions described as steps blocks transmissions communications requests responses and or messages may be executed out of order from that shown or discussed including in substantially concurrent or in reverse order depending on the functionality involved. Further more or fewer steps blocks and or functions may be used with any of the message flow diagrams scenarios and flow charts discussed herein and these message flow diagrams scenarios and flow charts may be combined with one another in part or in whole.

A step or block that represents a processing of information may correspond to circuitry that can be configured to perform the specific logical functions of a herein described method or technique. Alternatively or additionally a step or block that represents a processing of information may correspond to a module a segment or a portion of program code including related data . The program code may include one or more instructions executable by a processor for implementing specific logical functions or actions in the method or technique. The program code and or related data may be stored on any type of computer readable medium such as a storage device including a disk drive a hard drive or other storage media.

The computer readable medium may also include non transitory computer readable media such as computer readable media that stores data for short periods of time like register memory processor cache and or random access memory RAM . The computer readable media may also include non transitory computer readable media that stores program code and or data for longer periods of time such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks and or compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. A computer readable medium may be considered a computer readable storage medium for example or a tangible storage device.

Moreover a step or block that represents one or more information transmissions may correspond to information transmissions between software and or hardware modules in the same physical device. However other information transmissions may be between software modules and or hardware modules in different physical devices.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope and spirit being indicated by the following claims.

