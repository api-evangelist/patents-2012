---

title: Adaptive queue-management
abstract: In one embodiment, a method includes storing in a QoS-enabled communication system a data structure that has a multi-level hierarchy including a physical level, a logical level, and a class level; receiving a first request for M number of services provided by the QoS-enabled communication system; in response to the first request, modifying an allocation of the logical-level nodes by mapping M class-level nodes to a first one of the logical-level nodes according to a first mapping mode of the data structure; receiving a second request for P services provided by the QoS-enabled communication system, with P being greater than M; and, in response to the second request, modifying an allocation of the logical-level nodes by mapping P class-level nodes to a second one of the logical-level nodes according to a second mapping mode of the data structure.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08923120&OS=08923120&RS=08923120
owner: Cisco Technology, Inc.
number: 08923120
owner_city: San Jose
owner_country: US
publication_date: 20121206
---
This application is a continuation of U.S. application Ser. No. 12 781 209 filed May 17 2010 now U.S. Pat. No. 8 335 157 by Lenard John Stephan Jayakumar. and entitled Adaptive Queue Management .

Various telecommunication networks are designed to carry services with a range of quality of service QoS requirements for a variety of different classes of service. A network network equipment or a network protocol that supports QoS may agree on a traffic contract with a service requestor client or customer and reserve a fixed capacity in the network nodes for example during a session establishment phase for each class of service. In certain situations a significant amount of QoS resources may be wasted corrupted lost or inefficiently used.

In one embodiment a method includes storing in a QoS enabled communication system a data structure that has a multi level hierarchy including a physical level a logical level and a class level receiving a first request for M number of services provided by the QoS enabled communication system in response to the first request modifying an allocation of the logical level nodes by mapping M class level nodes to a first one of the logical level nodes according to a first mapping mode of the data structure receiving a second request for P services provided by the QoS enabled communication system with P being greater than M and in response to the second request modifying an allocation of the logical level nodes by mapping P class level nodes to a second one of the logical level nodes according to a second mapping mode of the data structure.

Particular embodiments relate to adaptively managing communication resources for communication networks. In particular embodiments a communication network may be designed to carry services with a range of quality of service QoS requirements. The term quality of service or QoS as used herein refers to a variety of resource reservation control mechanisms that may be used by certain communication networks. For example the resource reservation control mechanisms of particular embodiments may allocate or guarantee a certain level of performance to particular data flows. Additionally or alternatively the resource reservation control mechanisms of particular embodiments may provide different priority to different applications users or data flows. Various embodiments provide an adaptive framework that defines a hierarchy of network nodes over which QoS requirements may be configured. An example hierarchy of traffic nodes is illustrated in .

One type of data queue is the collection of network nodes that are directly mapped to each other and to a particular physical level node. As shown in for example one data queue includes network nodes and and another data queue includes nodes and In particular embodiments data queues may be configurable and may be able to map dynamically to any one of the network nodes according to a variety of mapping modes. Configurable data queues that may be dynamically mapped are distinguishable from static data queues that have only one fixed mode of mapping during system initialization and that remain static with respect to the one fixed mode of mapping until the end.

In a particular embodiment physical level nodes logical level nodes or class level nodes may each be a bandwidth limited traffic flow BLT . The term BLT as used herein generally refers to a data flow of packets whose maximum bandwidth is constrained or limited in some manner. An example BLT of a physical level node physicalBLT may include the physical interface over which traffic will be transmitted such as for example the physical interface of an application specific integrated circuit ASIC the physical interface of a router the physical interface of another device of communication network or any combination of the preceding. The term router as used herein generally refers to a network device that forwards packets to an intended destination. Various embodiments may use routers substantially similar to those manufactured by Cisco Systems. Particular physicalBLTs may be configured to schedule or shape BLTs of a corresponding logical level node logicalBLT . Certain logicalBLTs may be configured to schedule or shape BLTs of a corresponding class level node classBLT . Although various embodiments may include BLTs at the physical logical and class levels particular embodiments may not include bandwidth limited traffic streams.

In particular embodiments logical level nodes may include a virtual local area network VLAN a frame relay virtual circuit VC a Ethernet Flow Point EFP or other interfaces that in some instances may include virtual circuits. In various embodiments each logical level node may contain or may otherwise be assigned or guaranteed one or more parameters or configurations related to performance of a data flow a queue through the logical level node . Example parameters may include minimum bandwidth maximum bandwidth bit rate delay jitter packet dropping probability bit error rate another suitable parameter or configuration related to performance of a data flow or queue or any combination of the preceding.

In particular embodiments each class level node may contain or may otherwise be assigned or guaranteed one or more parameters or configurations specific to a particular class of service of the communication network. Example classes of service may include voice e.g. voice over IP video data telepresence Internet protocol television IP TV routing protocol traffic various signaling protocols online gaming or any other suitable class of service enabled by the communication network.

As shown in network node hierarchy may include multiple modes for mapping class level nodes to logical level nodes . In a first mode for example class level nodes and are mapped to logical level node at a 4 1 ratio. In a second mode for example class level nodes and are mapped to logical level node at an 8 1 ratio. Although the illustrated example includes alternative mappings of client level nodes to logical level nodes at either 4 1 or 8 1 ratios class level nodes may be mapped to logical level nodes according to any suitable ratio. For example alternative embodiments may map class level nodes to logical level nodes at ratios of 2 1 3 1 5 1 8 1 16 1 32 1 64 1 etc. Although illustrates two different modes for mapping class level nodes to logical level nodes any suitable number of mapping modes may be used e.g. 1 3 4 5 10 etc. mapping modes . In particular embodiments four or more mapping modes may be used each mapping mode having a ratio of P 1 where P is a power of 2.

Network device generally refers to any device or collection of devices forming a part of communication network . For example network device may include a directory database processor router server ASIC chip or any combination of the preceding. Particular network devices may include a programmable machine that is at least partially implemented in hardware software firmware or any combination thereof. In one embodiment network device at least partially operates all or a portion of the queue hierarchies shown in . In particular embodiments network device implements all of the queue managing features disclosed herein.

In particular embodiments network device includes memory at least one processor and at least one physical interface I F . Processor executes logic stored in program memory . Memory is one example of a computer readable medium. Memory may include a volatile memory. Another form of computer readable medium storing the same or substantially similar logic may be non volatile storage such as for example floppy disks CD ROMs DVD ROMs hard disks flash memory or other non volatile storage. In particular embodiments memory includes a queue manager and a data structure each of which is explained further below. I F may interface network device with physical media. Although memory processor and I F are shown as at least partially residing on network device in alternative embodiments all or a portion of memory processor or I F may be external to and accessible by network device .

In particular embodiments queue manager includes a platform independent adaptation layer PIAL a platform dependent layer PD a hardware abstraction layer HAL and a driver layer . In operation queue manager may adaptively manage queues of a communication network. As explained further below the management of queues may include setting up the queues configuring scheduler parameters and tracking the queues in real time. In particular embodiments queue manager may track in real time the particular physical level nodes logical level nodes or class level nodes that are available for allocation. In particular embodiments queue manager may access network nodes affected by an event and program modify corresponding data structures of one or more physical network devices e.g. shadow data structures of an ASIC chip . Although particular embodiments include layers and other embodiments may include some or none of these layers and . Particular embodiments of queue manager may include additional layers or modules. Additionally queue manager may include alternative configurations. For example layers or may be internal modules of each other or of another layer not explicitly shown .

In particular embodiments PI may be configured to interface queue manager with other features of a communication network. For example PI may receive and respond to incoming requests. In particular embodiments PI may respond to incoming requests by initializing configuration changes calling PD to perform validity checks or calling QRM to create queues.

In various embodiments PD may be configured to validate features of a communication network perform resource availability checks create network nodes or attach particular network nodes to corresponding mapping modes. In particular embodiments PD may call a hierarchy QoS manager HQM to assign Or mark a particular node of a queue for use with a mapping mode optimized for that queue.

In this example HAL includes two internal sub layers a queue resources manager layer QRM and a shim layer . In particular embodiments QRM may be configured to manage queuing data structures such as for example BLTs profiles or mapping information. In a particular embodiment QRM may process a queue related request by modifying one or more queue related platform dependent data structures and by communicating the modifications to shim layer for hardware programming. In particular embodiments QRM may interface another layer or module of queue manager to shim layer . In particular embodiments shim layer is an abstraction layer configured to translate calls from QRM so that they are reader by a particular physical interface. For example shim layer may deal with ASIC details and map data structures received from QRM to corresponding ASIC structures. Although QRM and shim layer are internal modules of HAL in this example in alternative embodiments QRM or shim layer may be modules external to or operationally independent of HAL .

In particular embodiments driver layer may manage hardware address mapping manage software structures for the corresponding hardware resources or perform read write to particular data structures of physical devices e.g. ASIC data structures . Calls to driver layer may in certain instances be directly addressed to data structures with values.

In various embodiments queue manager may interface with or may form a part of a particular data structure comprising a stack of memory blocks. In a particular embodiment a data strcture may be organized such that each logical level node is located at a respective memory block of a range table. In particular embodiments the data structure may be used to implement particular hierarchical mappings discussed previously with reference to . One example of a data structure that may implement multi modal hierarchical mappings is data structure illustrated in .

During operation of particular embodiments data structure may actively use portions of at least two stacks of BLT blocks corresponding to ranges and . Range may be used for hierarchical mappings according to a first mode. Range may be used for hierarchical mappings according to a second mode different from the first mode.

In particular embodiments use of multiple mapping modes may enhance efficiency of a communication network by adaptively selecting a mode for any given data queue according to the number of classes of service desired for the data queue. For example range may be used for mappings of class level nodes to logical level nodes at a ratio of 4 1 for particular data queues that have at most four classes of service. Range may for example be used for mappings of class level nodes to logical level nodes at a ratio of 8 1 for particular data queues that have more than four and at most eight classes of service. Although this example uses at least a 4 1 mapping mode and an 8 1 mapping mode any suitable number and type of mapping or allocation modes may be used.

One advantage of this multi modal approach may be explained by comparing the dynamic and adaptive multi modal approach to a static approach that is fixed at initialization and remains unchanged until the end. According to this alternative static approach if all requests for service are mapped according to a single fixed 8 1 ratio of class level nodes to logical level nodes then implementation of a particular request for four classes of service may result in wasting or dropping half of the data i.e. because only four class level nodes are mapped and the static mode provided a total of eight . In contrast to the static mapping approach particular embodiments may minimize or possibly eliminate wasted or dropped queues in certain instances by adaptively selecting a mode for each queue from multiple modes based on the particulars of requests for service. In particular embodiments the mapping modes may be selected using a command line interface CLI .

As shown in for example queue manager may select for the first time after initialization to apply a 4 1 mapping mode for a new queue. If range has been allocated to the 4 1 mapping mode queue manager may effect the mapping at a block at the start of range . For example queue manager may write data to block that effects the mapping of four class level nodes and to one logical node according to a 4 1 ratio. If queue manager later selects the 4 1 mapping mode again for a subsequent new queue allocation request for another logical node queue manager may effect the mapping of that second queue at a block within data structure that is substantially adjacent to end block . This process may be repeated for each new queue allocation request for another logical node created according to mapping mode 4 1 such that range expands as data structure implements new queues. In this example the last queue mapped according to the 4 1 mode is effected at block of range . Accordingly blocks and define the upper and lower boundaries of range .

In particular embodiments queue manager may select for the first time after initialization to apply an 8 1 mapping mode for a new queue. If range has been allocated to the 8 1 mapping mode queue manager may effect the mapping at a block at the start of range . For example queue manager may use block to effect the mapping of eight class level nodes and to one logical node according to an 8 1 ratio. If queue manager later selects the 8 1 mapping mode again for a subsequent new queue allocation request for another logical node queue manager may effect the mapping of that second queue at a block within data structure that is substantially adjacent to end block . This process may be repeated for each new queue allocation request for another logical node created according to mapping mode 8 1 such that range expands as new queues are recorded to data structure . In this example the last queue mapped according to the 8 1 mode is effected at block of range . Accordingly blocks and define the upper and lower boundaries of range .

In certain instances ranges or may use increasing percentages of data structure as new queues are added. The expansion of ranges and may shrink the size of free blocks disposed between ranges and . At some point in time during operation free blocks may diminish in size until ranges or collectively use portions of data structure extending substantially from block to block . In particular embodiments queue manager may be configured to automatically adapt to the convergence of ranges and by using available portions of data structure between any fragmented segments of ranges and . Blocks and of range and blocks and represent portions of data structure that may be available for use.

In particular embodiments queue manager may be configured to track the use of data storage and identify in real time any free blocks within ranges or that may be available for use. For example as queues are deleted during operation the corresponding blocks within range or range may be reset deleted or otherwise freed for future use. Queue manager may respond to a queue deletion by determining whether the freed block is the last entry of the corresponding range or . If the deleted block is not the last entry but rather internal to the range or queue manager may update one or more lists identifying the block that has been freed from prior allocation and is presently available for use. In particular embodiments queue manager may maintain a list of free blocks for each range and . In particular embodiments queue manager may use lists of free blocks to respond to new queue requests either before or after ranges and converge and free blocks collapses. For example queue manager may respond to a new queue request by first using any free blocks identified by a list for the corresponding range or . If the list indicates no free blocks are available then queue manager may use a block at end or of the corresponding range or .

In particular embodiments if queue manager selects the 4 1 mode of range for a new queue request and determines that range is full i.e. not fragmented then queue manager may respond to the new queue request by using an available block of range . If no blocks are available within range then queue manager may determine whether end of range may be modified to expand range . If no modification is available queue manager may send a resource outage notification. In another example queue manager selects the 8 1 mode of range for a new queue request and determines that range is full i.e. not fragmented then queue manager may respond to the new queue request by using an available block of range . If no blocks are available within range then queue manager may determine whether end of range may be modified. If no modification is available queue manager may send a resource outage notification.

Particular embodiments of queue manager may be configured to respond to requests to upsize a particular service request. For example a service requestor client or customer may request communication network to enable four classes of service. Queue manager may process the request by creating a new queue according to a 4 1 mode. The creation of the new queue may include allocating a particular block X of range within data structure . The same service requestor client or customer may later request communication network to enable an additional four classes of service in connection with the four classes of service originally requested. In one embodiment queue manager may process the second request at least in part by creating a new queue according to an 8 1 mode allocating a particular block Y of range within data structure transferring from block X to block Y one or more parameters or configurations associated with the four originally requested classes of service deleting or resetting block X and updating a list to indicate block X is free of allocation and available for use. In this manner queues created in response to service modifications may automatically inherit properties when applicable of related queues generated in response to former requests.

Particular embodiments of queue manager may be configured to respond to requests to downsize a particular service request. For example a service requestor client or customer may request communication network to enable eight classes of service. Queue manager may process the request by creating a new queue according to an 8 1 mode. The creation of the new queue may include allocating a particular block Z of range within data structure . The same service requestor client or customer may later request communication network to disable four of the eight previously requested classes of service. In one embodiment In one embodiment queue manager may process the second request at least in part by creating a new queue according to a 4 1 mode allocating a particular block W of range within data structure transferring from block Z to block W one or more parameters or configurations associated with the four originally requested classes of service deleting or resetting block Z and updating a list to indicate block Z is free of allocation and available for use.

Thus particular embodiments may simultaneously support multiple modes for mapping network nodes together. The particular mapping modes used may be chosen dynamically and may be adapted to changing requirements. Based at least in part on the particular modes chosen particular embodiments may setup internal data structures such that queues may be dynamically allocated from corresponding ranges. In particular embodiments lower ratio ranges may take precedence over higher ratio ranges. In certain instances different modes may share portions of the same range. Range boundaries may be adaptively adjusted according to particular allocation patterns or emphasis. Under particular circumstances any range may grow to the point that the range occupies the entire space of a data structure. The above features may be implemented seamlessly from the service requestor client or customer perspective such that the requesting entity may in certain instances be unaware of the backend processing performed by queue manager .

At step a request for services is received. In particular embodiments the request may be transmitted by service requestor client or customer and received by queue manager via communication network . In a particular embodiment queue manager may receive the request via PIAL . Certain requests received in step may be for various classes of services to be provided by a QoS enabled communication network.

At step a mapping mode is selected. In particular embodiments the mapping mode may be selected from among a plurality of mapping modes simultaneously enabled by a QoS enabled communication network. Although the method of includes two mappings modes Mode and Mode any suitable number of mapping modes may be used. In particular embodiments the selection of mapping modes may be based on ratio ranges such that lower ratio ranges may take precedence over higher ratio ranges. In particular embodiments each mapping mode may have a corresponding P 1 ratio that is unique with respect to the other mapping modes. The mapping mode may be selected as being the one having the smallest positive value V with respect to the other mapping modes for the equation where M is the number of services quested.

If a first mapping mode is selected then network nodes are mapped to each other at step according to the first mapping mode at which point the method may end. Alternatively if a second mapping mode is selected then network nodes are mapped to each other at step according to the second mapping at which point the method may end. In particular embodiments the mapping performed in step or may be substantially similar to the mapping discussed above. Although this disclosure describes and illustrates particular steps of the method of as occurring in a particular order this disclosure contemplates any suitable steps of the method of occurring in any suitable order. Moreover although this disclosure describes and illustrates particular components carrying out particular steps of the method of this disclosure contemplates any suitable combination of any suitable components carrying out any suitable steps of the method of .

This disclosure contemplates any suitable number of computer systems . This disclosure contemplates computer system taking any suitable physical form. As example and not by way of limitation computer system may be an embedded computer system a system on chip SOC a single board computer system SBC e.g. a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a mobile telephone a personal digital assistant PDA a server or a combination of two or more of these. Where appropriate computer system may include one or more computer systems be unitary or distributed span multiple locations span multiple machines or reside in a cloud which may include one or more cloud components in one or more networks. Where appropriate one or more computer systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computer systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computer systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

In particular embodiments computer system includes a processor memory storage an input output I O interface a communication interface and a bus . Although this disclosure describes and illustrates a particular computer system having a particular number of particular components in a particular arrangement this disclosure contemplates any suitable computer system having any suitable number of any suitable components in any suitable arrangement.

In particular embodiments processor includes hardware for executing instructions such as those making up a computer program. As an example and not by way of limitation to execute instructions processor may retrieve or fetch the instructions from an internal register an internal cache memory or storage decode and execute them and then write one or more results to an internal register an internal cache memory or storage . In particular embodiments processor may include one or more internal caches for data instructions or addresses. This disclosure contemplates processor including any suitable number of any suitable internal caches where appropriate. As an example and not by way of limitation processor may include one or more instruction caches one or more data caches and one or more translation lookaside buffers TLBs . Instructions in the instruction caches may be copies of instructions in memory or storage and the instruction caches may speed up retrieval of those instructions by processor . Data in the data caches may be copies of data in memory or storage for instructions executing at processor to operate on the results of previous instructions executed at processor for access by subsequent instructions executing at processor or for writing to memory or storage or other suitable data. The data caches may speed up read or write operations by processor . The TLBs may speed up virtual address translation for processor . In particular embodiments processor may include one or more internal registers for data instructions or addresses. This disclosure contemplates processor including any suitable number of any suitable internal registers where appropriate. Where appropriate processor may include one or more arithmetic logic units ALUs be a multi core processor or include one or more processors . Although this disclosure describes and illustrates a particular processor this disclosure contemplates any suitable processor.

In particular embodiments memory includes main memory for storing instructions for processor to execute or data for processor to operate on. As an example and not by way of limitation computer system may load instructions from storage or another source e.g. another computer system to memory . Processor may then load the instructions from memory to an internal register or internal cache. To execute the instructions processor may retrieve the instructions from the internal register or internal cache and decode them. During or after execution of the instructions processor may write one or more results which may be intermediate or final results to the internal register or internal cache. Processor may then write one or more of those results to memory . In particular embodiments processor executes only instructions in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere and operates only on data in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere . One or more memory buses which may each include an address bus and a data bus may couple processor to memory . Bus may include one or more memory buses as described below. In particular embodiments one or more memory management units MMUs reside between processor and memory and facilitate accesses to memory requested by processor . In particular embodiments memory includes random access memory RAM . This RAM may be volatile memory where appropriate Where appropriate this RAM may be dynamic RAM DRAM or static RAM SRAM . Moreover where appropriate this RAM may be single ported or multi ported RAM. This disclosure contemplates any suitable RAM. Memory may include one or more memories where appropriate. Although this disclosure describes and illustrates particular memory this disclosure contemplates any suitable memory.

In particular embodiments storage includes mass storage for data or instructions. As an example and not by way of limitation storage may include an HDD a floppy disk drive flash memory an optical disc a magneto optical disc magnetic tape or a Universal Serial Bus USB drive or a combination of two or more of these. Storage may include removable or non removable or fixed media where appropriate. Storage may be internal or external to computer system where appropriate. In particular embodiments storage is non volatile solid state memory. In particular embodiments storage includes read only memory ROM . Where appropriate this ROM may be mask programmed ROM programmable ROM PROM erasable PROM EPROM electrically erasable PROM EEPROM electrically alterable ROM EAROM or flash memory or a combination of two or more of these. This disclosure contemplates mass storage taking any suitable physical form. Storage may include one or more storage control units facilitating communication between processor and storage where appropriate. Where appropriate storage may include one or more storages . Although this disclosure describes and illustrates particular storage this disclosure contemplates any suitable storage.

In particular embodiments I O interface includes hardware software or both providing one or more interfaces for communication between computer system and one or more I O devices. Computer system may include one or more of these I O devices where appropriate. One or more of these I O devices may enable communication between a person and computer system . As an example and not by way of limitation an I O device may include a keyboard keypad microphone monitor mouse printer scanner speaker still camera stylus tablet touchscreen trackball video camera another suitable I O device or a combination of two or more of these. An I O device may include one or more sensors. This disclosure contemplates any suitable I O devices and any suitable I O interfaces for them. Where appropriate I O interface may include one or more device or software drivers enabling processor to drive one or more of these I O devices. I O interface may include one or more I O interfaces where appropriate. Although this disclosure describes and illustrates a particular I O interface this disclosure contemplates any suitable I O interface.

In particular embodiments communication interface includes hardware software or both providing one or more interfaces for communication e.g. packet based communication between computer system and one or more other computer systems or one or more networks. As an example and not by way of limitation communication interface may include a network interface controller NIC or network adapter for communicating with an Ethernet or other wire based network or a wireless NIC WNIC or wireless adapter for communicating with a wireless network such as a WI FI network. This disclosure contemplates any suitable network and any suitable communication interface for it. As an example and not by way of limitation computer system may communicate with an ad hoc network a personal area network PAN a local area network LAN a wide area network WAN a metropolitan area network MAN or one or more portions of the Internet or a combination of two or more of these. One or more portions of one or more of these networks may be wired or wireless. As an example computer system may communicate with a wireless PAN WPAN e.g. a BLUETOOTH WPAN a WI FI network a WI MAX network a cellular telephone network e.g. a Global System for Mobile Communications GSM network or other suitable wireless network or a combination of two or more of these. Computer system may include any suitable communication interface for any of these networks where appropriate. Communication interface may include one or more communication interfaces where appropriate. Although this disclosure describes and illustrates a particular communication interface this disclosure contemplates any suitable communication interface.

In particular embodiments bus includes hardware software or both coupling components of computer system to each other. As an example and not by way of limitation bus may include an Accelerated Graphics Port AGP or other graphics bus an Enhanced Industry Standard Architecture EISA bus a front side bus FSB a HYPERTRANSPORT HT interconnect an Industry Standard Architecture ISA bus an INFINIBAND interconnect a low pin count LPC bus a memory bus a Micro Channel Architecture MCA bus a Peripheral Component Interconnect PCI bus a PCI Express PCI X bus a serial advanced technology attachment SATA bus a Video Electronics Standards Association local VLB bus or another suitable bus or a combination of two or more of these. Bus may include one or more buses where appropriate. Although this disclosure describes and illustrates a particular bus this disclosure contemplates any suitable bus or interconnect.

Herein reference to a computer readable storage medium encompasses one or more tangible computer readable storage media possessing structure. As an example and not by way of limitation a computer readable storage medium may include a semiconductor based or other integrated circuit IC such as for example a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive or another suitable computer readable storage medium or a combination of two or more of these where appropriate. Herein reference to a computer readable storage medium excludes any medium that is not eligible for patent protection under 35 U.S.C. 101. Herein reference to a computer readable storage medium excludes transitory forms of signal transmission such as a propagating electrical or electromagnetic signal per se to the extent that they are not eligible for patent protection under 35 U.S.C. 101.

This disclosure contemplates one or more computer readable storage media implementing any suitable storage. In particular embodiments a computer readable storage medium implements one or more portions of processor e.g. one or more internal registers or caches one or more portions of memory one or more portions of storage or a combination of these where appropriate. In particular embodiments a computer readable storage medium implements RAM or ROM. In particular embodiments a computer readable storage medium implements volatile or persistent memory. In particular embodiments one or more computer readable storage media embody software. Herein reference to software may encompass one or more applications bytecode one or more computer programs one or more executables one or more instructions logic machine code one or more scripts or source code and vice versa where appropriate. In particular embodiments software includes one or more application programming interfaces APIs . This disclosure contemplates any suitable software written or otherwise expressed in any suitable programming language or combination of programming languages. In particular embodiments software is expressed as source code or object code. In particular embodiments software is expressed in a higher level programming language such as for example C Perl or a suitable extension thereof. In particular embodiments software is expressed in a lower level programming language such as assembly language or machine code . In particular embodiments software is expressed in JAVA. In particular embodiments software is expressed in Hyper Text Markup Language HTML Extensible Markup Language XML or other suitable markup language.

This disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Similarly where appropriate the appended claims encompass all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Moreover reference in the appended claims to an apparatus or system or a component of an apparatus or system being adapted to arranged to capable of configured to enabled to operable to or operative to perform a particular function encompasses that apparatus system component whether or not it or that particular function is activated turned on or unlocked as long as that apparatus system or component is so adapted arranged capable configured enabled operable or operative.

