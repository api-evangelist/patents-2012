---

title: Release lifecycle management system for a multi-node application
abstract: A deployment system provides the ability to deploy a multi-node distributed application, such as a cloud computing platform application that has a plurality of interconnected nodes performing specialized jobs. The deployment system may update a currently running cloud computing platform application according to a deployment manifest and a versioned release bundle that includes jobs and application packages. The deployment system determines changes to the currently running cloud computing platform application and distributes changes to each job to deployment agents executing on VMs. The deployment agents apply the updated jobs to their respective VMs (e.g., launching applications), thereby deploying an updated version of cloud computing platform application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08997078&OS=08997078&RS=08997078
owner: Pivotal Software, Inc.
number: 08997078
owner_city: Palo Alto
owner_country: US
publication_date: 20120323
---
The present application claims the benefit and priority of U.S. provisional patent application Ser. No. 61 474 669 filed on Apr. 12 2011 and entitled DEPLOYMENT FRAMEWORK FOR CLOUD PLATFORM ARCHITECTURE which is hereby incorporated by reference. The present application is related to the patent application entitled Deployment System for Multi Node Applications Ser. No. 13 428 109 and the patent application entitled Release Management System for a Multi Node Application Ser. No. 13 428 121 which are assigned to the assignee of this application and have been filed on the same day as this application.

 Platform as a Service also commonly referred to as PaaS generally describes a suite of technologies provided by a service provider as an integrated solution that enables a web developer or any other application developer to build deploy and manage the life cycle of a web application or any other type of networked application . One primary component of PaaS is a cloud computing platform which is a network e.g. Internet etc. infrastructure run and maintained by the service provider upon which developed web applications may be deployed. By providing the hardware resources and software layers required to robustly run a web application the cloud computing platform enables developers to focus on the development of the web application itself and leave the logistics of scalability and other computing and storage resource requirements e.g. data storage database access processing power facilities power and bandwidth etc. to the cloud computing platform e.g. at a cost charged by the service provider . A service provider may additionally provide a plug in component to a traditional IDE i.e. integrated development environment that assists a developer who creates web applications using the IDE to properly structure develop and test such applications in a manner that is compatible with the service provider s cloud computing platform. Once the developer completes a web application using the IDE the plug in component assists the developer in deploying the web application into the cloud computing platform.

However due to complexities in providing flexible and scalable cloud computing platforms PaaS is offered by few service providers. Current implementations of cloud computing platforms use multiple components e.g. cloud controller health manager service provisioner router and application execution agents that perform different roles and coordinate amongst each other to provide cloud computing services. To deploy such a cloud computing platform a system administrator must build configure deploy and maintain each of the components e.g. cloud controller health manager service provisioner router and application execution agents . While deployment may be performed manually when installing all components on a single system e.g. laptop server the deployment process becomes challenging when the components are installed across a plurality of networked systems because in such installations each system must be provisioned with specific computing resources set up with a particular networking configuration and have a different software application installed with dependent libraries and or runtimes to perform the system s assigned role within the cloud computing platform. Additionally updating any of the components e.g. security patch for a library or operating system requires a system administrator to have to modify operations for other components in the cloud computing platform. For example when one of the components needs to be updated a system administrator may have to suspend operations of other components currently connected to the component or in another example update settings of other components to correctly connect to the updated component. Accordingly the deployment process for a multi node application such as a cloud computing platform may be too complex and time consuming for a system administrator to manage.

One or more embodiments of the present invention provide a deployment system for a multi node distributed application e.g. a cloud computing platform having any number of nodes that perform specialized roles as well as any dependent software and or networking storage and service configurations utilized for each specialized role. Instances of the deployment system may be implemented on top of a hardware infrastructure that allows for dynamic provisioning of computing resources such as a virtualized infrastructure. The deployment system includes an automation framework that utilizes codified deployment manifests to automatically provision infrastructure e.g. virtual machines as well as install and configure application packages needed for each specialized role. The codified deployment manifests simplify the deployment process for a complex multi node application having varying requirements and enables repeatable and predictable deployments.

A method for updating an application having a plurality of functional components that are executed on a plurality of different virtual machines VMs includes according to an embodiment receiving by a deployment module a specification for the application to be updated. The specification identifies a set of software components representing an updated version of the application and containing code which implements each of the functional components of the application. The method includes identifying at least one functional component that is to be updated by comparing the set of software components for the updated version of the application and a set of software components that have been deployed for a currently deployed application. The method further includes directing an agent in each of the VMs that is executing as an instance of the identified functional component to install one or more software components in the VM thereby causing the VM to execute as an updated instance of the functional component of the application.

A non transitory computer readable storage medium comprising instructions that when executed in a computing device update an application having a plurality of functional components that are executed on a plurality of different virtual machines VMs . The instructions according to an embodiment perform the steps of receiving by a deployment module a specification for the application to be updated wherein the specification identifies a set of software components representing an updated version of the application and containing code which implements each of the functional components of the application. The instructions further perform the steps of identifying at least one functional component that is to be updated by comparing the set of software components for the updated version of the application and a set of software components that have been deployed for a currently deployed application and directing an agent in each of the VMs that is executing as an instance of the identified functional component to install one or more software components in the VM thereby causing the VM to execute as an updated instance of the functional component of the application.

A computer system for updating an application having a plurality of functional components that are executed on a plurality of different virtual machines VMs comprises a system memory and a processor. The processor according to an embodiment is programmed to carry out the steps of receiving by a deployment module a specification for the application to be updated. The specification identifies a set of software components representing an updated version of the application and containing code which implements each of the functional components of the application. The processor is further programmed to carry out the steps of identifying at least one functional component that is to be updated by comparing the set of software components for the updated version of the application and a set of software components that have been deployed for a currently deployed application and directing an agent in each of the VMs that is executing as an instance of the identified functional component to install one or more software components in the VM thereby causing the VM to execute as an updated instance of the functional component of the application.

In one embodiment cloud controller orchestrates a deployment process for web applications submitted by a developer . Cloud controller interacts with other functional components of cloud computing platform application to bind services required by submitted web applications and package web applications for transmission to application execution agents for deployment. Health manager tracks and maintains the health of cloud computing platform application by monitoring messages broadcast on message bus by other functional components of cloud computing platform application . Web applications access a set of services provided by cloud computing platform application such as a relational database service e.g. MySQL etc. monitoring service background task scheduler logging service messaging service memory object caching service and the like. A service provisioner serves as a communications intermediary between services and other functional components of cloud computing platform application e.g. cloud controller health manager router etc. and assists with the task of provisioning or binding such available services to web applications during a web application deployment process. Message bus provides a common interface through which functional components of cloud computing platform application such as service provisioner cloud controller health manager router and application execution agents can communicate and receive notifications.

Once cloud controller successfully orchestrates the deployment of web application in one or more application execution agents an end user can access web application for example through a web browser or any other appropriate client application residing on a computer laptop or generally any computing device. Router receives the web browser s access request e.g. a uniform resource locator or URL and routes the request to the corresponding system which hosts web application .

As described each component has a separate role within cloud computing platform application with separate software application and library dependencies e.g. MySQL Redis MongoDB Apache and is specially built configured deployed and maintained for cloud computing platform application to function as a whole. Further since each component is typically run in one or more virtual machines VMs each VM is also specially provisioned configured deployed and maintained by a system administrator. As such cloud computing platform application in which web applications are deployed itself has a deployment procedure that is cumbersome and complex. Accordingly embodiments provide a deployment technique for cloud computing platform application that uses an automation framework and tooling for simplified automatic and repeatable deployments.

In one embodiment system administrator instructs deployment system by issuing one or more commands through an administrative client communicatively connected to deployment system for example through a command line interface CLI or other user interface of administrative client . In addition to transmitting one or more commands issued by system administrator administrative client may further transmit a bundle of application data configuration files and other information collectively referred to as a release or release bundle which are unpacked processed and or distributed by deployment system to deploy cloud computing platform application as described later in conjunction with . In addition to the release administrative client provides a deployment manifest associated with the release that describes a desired computing environment of cloud computing platform application after cloud computing platform application has been deployed. The deployment manifest describes attributes of the desired computing environment such as a number of resource pools e.g. groups of VMs to be utilized networks to be set up and other settings as will be described later and functions as a specification for deployment in this embodiment.

Multi node application platform includes an infrastructure platform upon which cloud computing platform application is deployed and executed. In the embodiment of infrastructure platform comprises hardware resources such as servers to and one or more storage array networks SAN such as SAN which are configured in a manner to provide a virtualization environment that supports execution of a plurality of virtual machines VMs across servers to . As further detailed below these VMs provide virtual computing resources that support the services and functions carried out by deployment system as well as virtual computing resources for hosting functional components of the cloud computing platform application . In one embodiment infrastructure platform may be implemented as cloud infrastructure services or other Infrastructure as a Service IaaS that provide computer infrastructure as a service.

Virtualization environment includes an orchestration component e.g. implemented as a process running in a virtual machine in one embodiment that monitors the infrastructure resource consumption levels and requirements of deployment system e.g. by monitoring communications routed through addressing and discovery layer as further detailed below and provides additional infrastructure resources to deployment system as needed or desired. For example if deployment system requires additional VMs to host newly deployed functional components of cloud computing platform application and scale the currently running multi node application to support peak demands orchestration component can initiate and manage the instantiation of virtual machines on servers to to support such needs. In one example implementation of an embodiment similar to that of virtualization environment may be implemented by running VMware ESX based hypervisor technologies on servers to provided by VMware Inc. of Palo Alto Calif. although it should be recognized that any other virtualization technologies including Xen and Microsoft Hyper V virtualization technologies may be utilized consistent with the teachings herein .

In the embodiment of deployment system includes a deployment director e.g. running in one or more VMs that orchestrates the deployment process for cloud computing platform application according to a deployment manifest that has been submitted to deployment system . Deployment director receives instructions of the deployment manifest and interacts with other components of deployment system to generate a logical infrastructure onto which cloud computing platform application is to be deployed. In the embodiment depicted in deployment director exposes a communications interface such as a Representative State Transfer REST architecture through which deployment director receives administrative commands and other deployment data e.g. a release from a client e.g. administrative client .

Deployment director may provision VMs identified as stem cell VMs to to host functional components of cloud computing platform application such as cloud controller application execution agents health manager router service provisioner etc. In the embodiment of deployment director request infrastructure platform to dynamically create and delete stem cell VMs e.g. stem cell VMs to . Stem cell VMs to are VMs created based on a pre defined VM template referred to as stem cell that includes a base operating system an agent and supporting libraries runtimes and or applications. Agents coordinate with deployment director to configure stem cell VMs to to perform various roles of cloud computing platform application . Agents applies a particular job to a stem cell VM executing thereon such that stem cell VM performs a particular management role within cloud computing platform application e.g. the job of one of cloud controller health manager application execution agents etc. .

In addition to provisioning stem cell VMs deployment director may request infrastructure platform to dynamically create and delete temporary VMs referred to as workers which perform one or more processing tasks that facilitate deployment. In one embodiment for example workers may be created to perform software compilation for component applications and or libraries to be deployed on stem cell VMs to . Workers are configured with a similar configuration as stem cell VMs to e.g. have an identical virtual hardware specification architecture and or configuration to enable compiled software to execute on stem cell VMs to . Results of processing tasks e.g. software compilation and other cached data may be stored in an object store e.g. blob store used to hold artifacts generated during the deployment process. Further deployment director may utilize a set of services e.g. run in one or more VMs to facilitate orchestration of the deployment process. For example a relational database service e.g. MySQL etc. monitoring service background task scheduler logging service messaging service memory object caching service and the like may comprise services .

Addressing and discovery layer provides a common interface through which components of deployment system such as deployment director health monitor services workers and one or more agents executing on stem cell VMs to can communicate and receive notifications. For example deployment director may utilize addressing and discovery layer to request the provisioning of VMs from infrastructure platform and to provide agents with deployment instructions during deployment of cloud computing platform application . Similarly stem cell VM may communicate through addressing and discovery layer with other stem cell VMs through addressing and discovery layer during deployment of cloud computing platform application . In one embodiment addressing and discovery layer is implemented as a message brokering service e.g. running in one or more VMs that defines a common protocol and message format through which components of deployment system can exchange messages and broadcast notifications and other information. In such an embodiment the components of deployment system establish a connection with the message brokering service e.g. also sometimes referred to as subscribing to the message brokering service for example through known authentication techniques e.g. passwords etc. and once connected to the message brokering service can provide receive and request messages notifications and other similar information to and from other components that have also subscribed to the message brokering system. One example of a message brokering service that may be used in an embodiment is RabbitMQ which is based upon the AMPQ Advanced Message Queuing Protocol open protocol standard. It should be recognized however that alternative interfaces and communication schemes may be implemented for addressing and discovery layer other than such a message brokering service.

Deployment system further comprises a health monitor e.g. run in a VM that tracks and maintains the health of deployment system by monitoring messages broadcast on addressing and discovery layer by other components of deployment system . For example health monitor may detect a lack of communication from an agent e.g. run on a stem cell VM and determine the failure of the stem cell VM e.g. failure of a component of cloud computing platform application . Health monitor may automatically broadcast a request to deployment director to re start the failed stem cell VM or provision a replacement stem cell VM to perform the same role. Health monitor may be further configured to initiate restart of failed available services or other components of deployment system e.g. deployment director object store services workers and one or more agents executing on stem cell VMs to etc. .

It should be recognized that deployment system architectures other than the embodiment of may be implemented consistent with the teachings herein. For example while implements deployment system on an infrastructure platform hosted by multi node application platform it should be recognized that deployment system may be implemented by entities other than multi node application platform on top of any type of hardware infrastructure such as on a non virtualized infrastructure platform as processes or daemons directly on hardware resources . It should further be recognized that embodiments may configure deployment system and infrastructure platform in a loosely coupled manner with communication between deployment system and infrastructure platform only occurring through orchestration component of infrastructure platform which monitors hardware resource consumption by connecting to addressing and discovery layer . In such loosely coupled embodiments it should be recognized that deployment system may be implemented on any infrastructure platform including on a laptop or personal computer e.g. in which case each component of deployment system runs as a separate process or daemon on the laptop or personal computer .

Deployment manifest may specify a network configuration for cloud computing platform application that includes one or more networks and or virtual local area networks VLANs . For example deployment manifest may define one or more network having settings that specify subnets static or dynamic IP addresses gateways and DNS addresses and reserved Internet Protocol IP addresses i.e. IP addresses not to be used by deployment system . In the example deployment in Table 1 a first network labeled management and a second network labeled apps are specified under a section titled networks. The network labeled management is specified having a static IP address range of 11.23.3.2.17 to 11.23.2.128 with a gateway address of 11.23.2.1 and DNS address of 11.22.22.153. Deployment manifest may specify a range of the network that may be used by deployment director as a dynamic pool of IP address minus static and reserved IP addresses. Gateway and DNS information specified by deployment manifest may be passed onto stem cell VMs and agents executing thereon for their initial launch and bootstrapping. Deployment manifest may include in each section one or more pass through settings e.g. cloud properties that will be provided to infrastructure platform during deployment.

Based on deployment manifest deployment director generates a logical infrastructure comprising one or more resource pools identified as resource pools and in that associate stem cell VMs with a stem cell e.g. VM template and a network. For example a resource pool labeled small is associated with a stem cell specified as bosh stemcell version 0.2.39 and with the management network defined within deployment manifest . A stem cell refers to a VM template that defines a generalized software infrastructure that supports execution of a job provided by deployment director and as specified by deployment manifest . In some embodiments the stem cell is a VM template that includes an agent installed on a guest operating system and any supporting runtimes frameworks and libraries for the agent . Each resource pool may be assigned a size corresponding to a number of stem cell VMs to be provisioned for the resource pool. For example deployment director provisions stem cell VMs for the small resource pool. Deployment manifest may include pass through settings for infrastructure platform for provisioning resource pools . For example the cloud properties section indicates ram disk and cpu properties that are intended for use by infrastructure platform in provisioning stem cell VMs i.e. having 1024 MB of RAM 4096 Mb of disk space and 1 CPU for the small resource pool.

Deployment manifest may define a specialized resource pool of workers e.g. workers for compilation of software packages and or other ancillary processing tasks during deployment. The specialized resource pool of workers may comprise one or more ancillary VMs provided by infrastructure platform . Deployment manifest may specify the number of VMs allocated to the workers resource pool and a network on which compilation may be performed. For example the compilation section above specifies a resource pool having 6 workers assigned to the management network for compiling software packages.

Deployment manifest defines a plurality of jobs that may be performed by one or more stem cell VMs M as one or more roles in cloud computing platform application e.g. cloud controller router application execution agents health manager service provisioner services message bus etc. . Deployment manifest specifies a mapping of each job onto logical infrastructure of resource pools and networks specified above. Deployment manifest may specify the number of instances to be deployed of a particular job which resource pool to use stem cell VMs and or which network the job is on. For example in the example in Table 1 a job labeled as cloud controller is listed as having eight instances e.g. stem cell VMs drawn from resource pool large and assigned to the management network. Each job may include a number of configuration file templates wherein key parameters e.g. login credentials IP addresses ports are specified as variables.

In one embodiment deployment manifest includes a properties section that provides enables a system administrator to parameterize these configuration file templates. As such when deployment director deploys cloud computing platform application deployment director may parse the configuration file templates and fill in the appropriate parameters based on the corresponding values provided in properties section. For example a router job may have a configuration file that lists a login credential for the router service as variables . In such an example deployment director parses out and evaluates the variables based on user and password name value pairs provided in the properties section. Table 2 lists an example configuration file template embodied as a Ruby on Rails script file e.g. ERB template that may be parsed by deployment director .

In step deployment director determines a logical infrastructure to host cloud computing platform application based on deployment manifest . For example in one embodiment deployment director processes deployment manifest to determine an allocation of stem cell VMs organized into resource pools and network groupings for hosting nodes of cloud computing platform application . In step deployment director transmits a provision request for a plurality of stem cell VMs based on logical infrastructure determined in step to infrastructure platform which in turn receives the provisioning request in step . For example in one embodiment deployment director may call for provision of instances of a stem cell VM from a cloud infrastructure service provider utilizing a cloud provider Application Programming Interface sometimes referred to as a cloud provider interface CPI . In step infrastructure platform creates one or more instances of stem cell VMs utilizing a stem cell template having agent pre installed and having resource and network configurations as specified by deployment manifest . For example in one embodiment infrastructure platform may create a stem cell VM utilizing a template e.g. stem cell having a packaged format such as Open Virtualization Format OVF and containing a guest operating system kernel utilities e.g. openssh server monit libraries e.g. libxml libmysql libsqlite runtime dependencies e.g. Ruby Java Virtual Machine and agent . In one particular implementation the stem cell may be generated prior to start of the deployment procedure and stored for later retrieval by infrastructure platform and or deployment director .

In step one or more stem cell VMs e.g. stem cell VM begins operation and launches agent . In step deployment director provides job configuration and data to stem cell VMs for each job specified by deployment manifest via addressing and discovery layer . For example deployment director determines that deployment manifest specifies a cloud controller job uses eight instances of stem cell VMs drawn from a pre determined resource pool and from a pre determined network group. Deployment director provides job configuration and data for the cloud controller job to eight instances of stem cell VMs . In step stem cell VMs e.g. stem cell VM receives the job configuration and data via address and discovery layer . Job configuration and data may include one or more packaged applications libraries runtimes configuration files metadata and other supporting data for performing a role within cloud computing platform application . In one embodiment agent may retrieve job configuration and data utilizing a link or address provided by deployment director and corresponding to one or more data objects stored in object store .

In step agent applies the received job configuration and data to transform stem cell VM into a distributed node within cloud computing platform application . Agent installs one or more application packages of the received job data utilizes the received job configuration to perform any suitable setup and configuration of the installed software packages and launches processes for connecting to other deployed jobs of cloud computing platform application and performing one or more specialized tasks within cloud computing platform application . For example in one embodiment agent may install configure and launch one or more application packages for executing a router e.g. router to forward incoming requests to other components of cloud computing platform application that are running web applications. Deployment director repeats operations of step until all jobs have been deployed onto one or more stem cell VMs as specified by deployment manifest . As such after the deployment procedure has been completed a plurality of stem cell VMs have transformed into a plurality of interconnected nodes that constitute a deployed cloud computing platform application e.g. cloud controller application execution agents health manager router service provisioner etc. as depicted in .

Administrative client includes a software module referred to as a release manager which builds and manages releases of the multi node application according to techniques described herein. In one embodiment release manager uses metadata and configurations provided by one or more job specifications and one or more package specifications to build a release . Release generally refers to a self contained bundle of management job definitions configurations and application data packages needed to deploy and execute cloud computing platform application . Each release represents a frozen version of application data packages and configurations needed to perform the management jobs for providing cloud computing platform services. As shown in release includes a release manifest that specifies the contents of release a plurality of jobs and a plurality of packages . Each job represents a management role in cloud computing platform application to be performed e.g. by a stem cell VM and describes what packages should be deployed e.g. by an agent executing in a stem cell VM and monitored e.g. by health monitor . Jobs include code and configurations for use with one or more packages . Packages includes custom application code configured to perform management jobs specific to cloud computing platform application e.g. cloud controller application execution agents as well as re usable application services and or supporting software e.g. MySQL RabbitMQ . Packages may contain code stored in machine architecture independent representation e.g. source code bytecode or alternatively may include executable runtimes e.g. binaries . In one embodiment jobs and packages are organized into one or more tape archive files e.g. tarballs .

Package specification includes metadata that specifies contents that are to be included in a package e.g. package when a release is built e.g. by release manager . Examples of package specification are produced below in Tables 3A and 3B.

Package specification specifies a preparation script for inclusion in package e.g. packaging packages cloudcontroller packaging . The preparation script is configured to when executed prepare package for the environment of deployment system . For example a script for compiling package may include shells commands to unpack package and invoke a make command that compiles contents of package to generate an executable runtime compatible with stem cell VMs. In one embodiment the preparation script is configured to be executed on a virtual machine such as a worker having a system architecture compatible with stem cell VMs . An example preparation script is provided below in Table 4.

In step administrative client receives the one or more package specifications . In one embodiment administrative client retains the received package specifications in a local workspace having a directory folder structure configured according to a predetermined convention e.g. naming convention . For example package specifications e.g. cloudcontroller.pkg rabbitmq.pkg may be placed in a packages folder that has sub directories e.g. packages cloudcontroller packages rabbitmq corresponding to a name identifier provided by each package specification . It should be recognized that file paths file globs URLs and other file references provided in package specification as well as for job specification may be specified relative to the local workspace or to a location within the local workspace determined according to the predetermined convention. In the example above the location of package files e.g. cloudcontroller.tar.gz rabbitmq server 1.8.0.tar.gz may be specified relative to sub directories corresponding to name identifiers provided by each package specification e.g. packages cloudcontroller packages rabbitmq . It should be recognized that the location of package files may be in a system directory e.g. src used to store package files and source code according to conventions of an operating system.

In step the user provides one or more job specifications to administrative client that describes a job that may be executed e.g. by an agent in deployment system . Job specification provides a name identifier field e.g. cloudcontroller messagebus that uniquely identifies a particular job from among other jobs. An example job specification is provided below 

Job specification specifies one or more packages that are used e.g. by an agent to perform a management role within cloud computing platform application . For example job specification for a cloud controller e.g. cloud controller may specify a cloud controller package which includes custom application code for orchestrating cloud services with other components of cloud computing platform application and a MySQL package which includes a relational database that may be used by the cloud controller to store cloud orchestration metadata. In another example job specification for an application execution agent may specify an application execution agent package which includes custom application code for receiving and deploying web applications from cloud controller and a Java Runtime Environment package that may be used by application execution agents to provide a Java virtual machine JVM to execute web applications. In one embodiment job specification specifies the one or more packages according to their name identifier specified by package specifications .

Job specifications may specify one or more of the same packages in cases where different jobs utilize the same supporting application services or share common code. For example multiple job specifications may specify an application service such as MySQL or Redis which is used by each component of cloud computing platform application in various ways. In another example job specification for a health monitor e.g. health monitor may specify the cloud controller package as being used by health monitor because of common code used to orchestrate cloud services with components of cloud computing platform application and monitor components of cloud computing platform application .

Job specification specifies one or more configuration files for inclusion in job . The configuration files provide configuration settings which are specific to job for packages and to setup an instance of job on a stem cell VM . For example job specification for a particular job may identify one or more configuration scripts that provide networking configurations e.g. IP addresses of other jobs that the particular job depends on. In one embodiment the configuration files are configuration file templates that are parsed by deployment system e.g. by deployment director and filled in with values provided from a deployment manifest as described above. In one embodiment job specification specifies for each configuration file template a source file path to the configuration file template e.g. within the local workspace and a destination file path e.g. within a stem cell VM for where a configuration file generated from the configuration file template should be placed.

In one embodiment job specification further specifies a monitoring script to be included in job . The monitoring script is specific to each job and is configured to when executed e.g. by an agent or by direction of health monitor start stop and monitor processes that are associated with performing job . In one example a monitoring script may be configured to check for existence of a predetermined process identifier PID assigned to job . In another example a monitoring script may be configured to alert health monitor to low available memory or high disk latency conditions during performance of job .

In one embodiment job specification specifies one or more lifecycle scripts to be included in job . Each lifecycle script is associated with a lifecycle hook such that the lifecycle scripts are invoked e.g. by an agent when a particular application lifecycle action takes place. Deployment director may use the lifecycle hooks to notify a running instance of job of pending actions as described later. In one embodiment the application lifecycle actions include an update which represents a change in version of the running instance of job and a restart which represents a restart of the running instance of job . In the example above job specification includes a generalized lifecycle hook identified as drain however other lifecycle hooks are contemplated such as a before and after lifecycle hook to be used before and after updates take place.

In step administrative client receives the one or more job specifications . In one embodiment administrative client retains the received job specifications in a local workspace described above having a directory folder structure configured according to a predetermined convention e.g. naming convention . For example job specifications e.g. cloudcontroller.job rabbitmq.job may be placed in a jobs directory in the local workspace.

In step the user provides an instruction to build a release according to job specifications and package specifications . In one implementation the user may provide a command line instruction e.g. create release to administrative client to build release . The user may specify that release be locally built sometimes referred to as a developer version or dev version or alternatively may specify release as a production level version sometimes referred to as a final version that is uploaded to object store and made available to other users.

In step responsive to user command to build release administrative client determines one or more packages used by each job according to job specifications . In one embodiment administrative client scans the local workspace in a predetermined location such as a jobs sub directory to locate job specifications . Administrative client then processes each located job specification to determine which packages need to be built for each job. In one embodiment administrative client locates and retrieves package specifications for any packages specified in the packages section of each job specification .

In step for each specified package administrative client determines whether a cached copy of package may be found in a local cache or alternatively in object store . In step responsive to determining that package has not been cached administrative client generates a new package according to package specification . In one embodiment administrative client generates a new package by bundling a preparation script and the one or package files specified by package specification into a package formatted as an archive file such as a tar file. Administrative client then generates a package manifest e.g. cloudcontroller.MF mysql.MF that includes the contents of package specification e.g. name preparation scripts file listings and other metadata for package . In one embodiment the package manifest includes a fingerprint value that is generated to uniquely identify contents of package e.g. package files locations permissions checksums etc. and may be later used determine whether changes have been made to contents of package e.g. new versions of package files . The package manifest further includes a build number that is a versioning identifier for package within release manager and is auto incremented from a previous build number upon generation of a new changed package . In step administrative client stores the generated package in a local storage cache or alternatively in object store to be made available later or to other users.

In step responsive to determining that a package has been cached administrative client determines whether a given package has been changed or modified from the cached copy of package that may represent a previous version of the package. A given package may be deemed modified based on changes to package specification preparation scripts package files and or other contents specified for the given package. In some embodiments a test fingerprint value is generated using contents specified by package specification e.g. package files found in working directory and compared to a fingerprint value provided by a package manifest of the cached copy of package . The given package may be deemed changed if the fingerprint values do not match and vise versa.

Responsive to determining that a given package has been changed administrative client proceeds to step to generate a new package according to package specification as described above. Responsive to determining that a given package has not been changed in step administrative client retrieves the cached copy of package . It is recognized that the operations described in steps to may be repeated for each package specified for jobs of cloud computing platform application . After retrieving and or generating all packages the operations of administrative client proceed to step .

In step administrative client generates one or more jobs according to job specifications . In one embodiment administrative client generates a job by bundling monitoring scripts and configuration files specified by job specification as well as a job manifest into an archive file. Administrative client generates a job manifest that includes the contents of job specification in addition to other metadata for job . In one embodiment the job manifest includes a fingerprint value for example as generated by a hash function or other algorithm which may be used to verify the integrity of contents of job and or determine whether the contents of job have been modified. The job manifest further includes a build number that is a versioning identifier for job within release manager similar to the build number for packages . It should be recognized that to facilitate building and managing releases in one embodiment administrative client includes a caching and versioning mechanism for jobs similar to the caching and versioning system for packages described above.

In step administrative client generates a release that includes jobs and packages . In one embodiment administrative client generates release by bundling jobs and packages e.g. as generated and or retrieved earlier into a single self contained archive file e.g. tarball .

Administrative client generates a release manifest that specifies the contents of release and that is incorporated into release . Release manifest includes a name identifier field that provides a text label for release e.g. appcloud and a build version field that provides a versioning identifier for release within release manager . In one embodiment administrative client increments the build version field of a release upon determining any change made to jobs and or packages e.g. a change in build version of a job or package . Release manifest further includes a listing of jobs and packages contained within the release bundle. For example in an example release manifest produced in Table 6 below release manifest specifies a version 23 of an appcloud release which includes jobs identified as cloudcontroller dea healthmanager messagebus and includes packages identified as dea cloudcontroller healthmanager router rabbitmq and mysql. In some embodiments release manifest further includes a checksum value generated for each job and or package specified. The checksum values may be used for integrity checking during deployment to verify that contents of jobs and packages have not been changed during distribution.

Upon completion of generating release administrative client reports status back to the user. In step the user receives status output regarding the building of release which may include a verbose output describing what packages and jobs have been changed modified newly generated and or retrieved from cache. The user may instruct administrative client to transmit release to a deployment system such as deployment system shown in and utilized to deploy a cloud computing platform application . In one embodiment release may be provided to deployment director and stored within object store for later access. In one embodiment administrative client maintains a catalog of built releases identified by name and version number may be deployed to test staging and or production environments.

Embodiments of the invention may be adapted to perform application lifecycle management operations on pre existing deployments of multi node applications such as cloud computing platform application . For example embodiments of the invention allow an operations team to update components of a cloud computing platform application by rolling e.g. staggering updates and enabling the components to drain their traffic. Accordingly embodiments of the invention reduce the impact of upgrades and other changes on a customer s then running applications. While embodiments of the invention are described for updating cloud computing platform application it should be recognized that the techniques and system provided herein can be extended to other application lifecycle management operations such as rollbacks wind ups and scaling up and down of a deployment.

To generate updated release administrative client detects one or more changes to an existing release such as the addition of a new job specification removal of an existing job specification modification of an existing job specification modification of contents of a job e.g. changes to a dependent package or script addition removal and modification of a package specification and contents of a package e.g. application data bits . In one implementation administrative client generates updated release manifests job manifests and package manifests that include incremented build version numbers to represent corresponding changes in each of package job and release . For example administrative client may detect an upgrade of Java Runtime Environment package e.g. from version 1.5 to version 1.6 for application execution agent . In this example administrative client generates an updated release having an updated job for application execution agent to reflect a new dependency on a different version of Java and an updated package for Java Runtime Environment that reflects new application bits for the different version of Java .

In step responsive to user input administrative client transmits a deployment request to deployment director to deploy updated release using a deployment manifest provided by the user. In step deployment director of deployment system receives the deployment request from administrative client . The deployment request may include updated release and deployment manifest or alternatively may include a reference or other resource identifier that can be used to retrieve updated release from object store .

Deployment manifest may be similar to deployment manifest described above and extended to include one or more update settings that defines how updates of jobs behave. In one implementation deployment manifest includes an update section having configuration name value pairs that define update settings for all jobs specified in deployment manifest . An excerpt from an example deployment manifest having update settings is produced below in Table 7. Portions have been omitted for sake of clarity.

In one implementation deployment manifest includes a updates section that provides default update properties that may be overridden in individual jobs. For example while a global update property may define a max in flight value of 1 the application execution agent job which typically have many instances may specify an override max in flight value of 12.

Update settings of deployment manifest may specify a number of test instances to be updated for a job. The test instances referred to as canaries are updated prior to other instances of the job are updated thereby allowing the user to catch deployment errors without bringing down all instances of the job. Update settings may further specify a time interval referred to as canary watch time that indicates a wait period after a job update to a canary test instance before deployment director checks if the canary instance is healthy running correctly and has been successfully updated. In the example produced above the canaries setting indicates one test instance is updated prior to other instances and is given a period of 30 000 milliseconds before deployment director checks on the test instance. Update settings of deployment manifest may further specify a second time interval referred to as a update watch time that indicates a wait period after a job update to a non canary instance before deployment director checks if the job instance is healthy running correctly and has been successfully updated.

Update settings of deployment manifest may further specify a number of instances that may be updated concurrently. The number of instances referred to as a max in flight value enables the user to limit a number of job instances that will be taken down and updated. For example for a job typically having many instances such as application execution agent the user may wish to upgrade only instances at a time to reduce the impact on cloud services that deploy web applications.

Update settings of deployment manifest may further specify a maximum number of errors that may occur during a job update without automatically aborting the update operation. In the example shown above deployment manifest specifies a max errors setting of 2 to allow an update operation to attempt completion without raising more than 2 errors.

Referring back to in step deployment director determines one or more changes to a deployment of cloud computing application platform by comparing updated release to the release of the existing deployment. In one embodiment deployment director compares build versions of each job and each package used by each job to determine which packages and jobs should be updated. In one implementation deployment director processes a release manifest of updated release to retrieve deployment metadata and compares the retrieved deployment metadata to metadata stored for existing deployment of cloud computing application platform .

In step deployment director distributes update request having one or more updated jobs and or packages to each stem cell VM running a job instance determined to be updated in step via addressing and discovery layer . For example deployment director may determine that the only change found in an updated release is an upgraded version of a Java Runtime Environment package for an application execution agent job. In this example deployment director may distribute an update of the application execution agent job and leave the remaining components of cloud computing platform application untouched. In step agent e.g. executing on a stem cell VM receives the update request and updated jobs and or packages from deployment director via addressing and discovery layer .

In step agent executes a lifecycle script for existing job to prepare for an update for example by gracefully suspending operation of the job instance on stem cell VM . The lifecycle scripts may be configured to when executed by agent cease accepting new requests or work finish processing of requests or work already in progress sometimes referred to as draining and notify deployment director of a ready to update status. For example a lifecycle script for an application execution agent job may be configured to stop accepting new web applications for execution and evacuate running web applications to other running application execution agents.

In one embodiment the lifecycle script is configured to when executed by agent determine which component e.g. package application service are affected by an update and to dynamically configure the lifecycle script to allow for major and minor updates. For example responsive to determining that an update is to a package containing code for application execution agent job a lifecycle script may leave web applications running while the existing application execution job process is restarted. In contrast responsive to determining that an update is to other packages supporting the web applications e.g. Java Apache Tomcat Server Ruby interpreter the lifecycle script may drain the web applications from the job instance by refusing new web applications and evacuating running web applications to other instances of the application execution agent job. In one implementation the lifecycle scripts for a job may return e.g. output an integer value that represents a number of milliseconds to wait before executing a stop command via the monitoring script after the lifecycle script has been executed. As such deployment system may utilize job specific scripts to avoid killing requests mid process thereby reduce service interruptions and down time during updates of cloud computing platform application .

In step agent e.g. executing in stem cell VM applies updated job to update job instance of cloud computing platform application according to updated release . When an updated job is deployed to a stem cell VM agent stores the contents of updated job while retaining contents of previous versions of job to enable rollbacks. In one embodiment agent stores job in a directory structure having slots that represent different build versions of a job e.g. jobs . An example directory layout e.g. within stem cell VM is provided in Table 8.

As shown each slot contains a monitoring script e.g. monit configuration files lifecycle scripts e.g. drain packages or references to packages that are associated with a build version of job . Multiple versions stored in slots may be used for updates rollbacks and troubleshooting of a deployment. For example if an upgrade e.g. to build 29 runs incorrectly agent may quickly revert to a previously running version e.g. build 28 . Each slot keeps track of the live version of job with for example a symbolic link or file pointer. A data directory e.g. data may be used to pass state across updates and versions such as a list of process identifiers PIDs that a previous application execution agent was monitoring.

While discussion of release update management has been focused on updates to application code data configurations e.g. jobs and packages that make up cloud computing platform application it should be recognized that techniques described herein may be extended to modify a logical infrastructure on which cloud computing platform application is deployed e.g. logical infrastructure . For example deployment manifest for a given release may be modified to increase or decrease stem cell VM instances assigned to a particular job change virtual resource allocations e.g. CPU memory for stem cell VMs and alter network groups and addressing. In such an embodiment deployment director is configured to determine changes to the logical infrastructure and instruct infrastructure platform to transition existing logical infrastructure to an updated logical infrastructure according to an updated release and deployment manifest .

It should be recognized that various modifications and changes may be made to the specific embodiments described herein without departing from the broader spirit and scope of the invention as set forth in the appended claims. For example while the foregoing description has discussed embodiments of a distributed cloud computing platform application it should be recognized that any network utilizing application can leverage the techniques disclosed herein and as such cloud computing platform application as used herein shall be interpreted to include any type of multi node distributed application that employs network based communications. Furthermore although the foregoing embodiments have focused on the use of stem cell VMs to host deployed jobs it should be recognized that any application container may be used to host deployed jobs including such stem cell VMs processes in virtual machines kernel level containers processes in traditional non virtualized operating systems and any other execution environment that provides an isolated environment capable of running application level code. Similarly while the various components of deployment system have been generally described as being implemented in one or more virtual machines e.g. for load balancing and scalability purposes it should be recognized that any type of application container as previously discussed above can also implement such components including for example traditional non virtualized computing environment background processes threads or daemons. Furthermore any combination of different types of application containers to host deployed jobs and implement other components e.g. deployment director health monitor services object store workers addressing and discovery layer etc. can comprise any particular deployment system implementation. It should further be recognized that multiple instances of the various components of deployment system e.g. deployment director health monitor services workers object store etc. may be implemented in alternative embodiments for example for scalability purposes.

The various embodiments described herein may employ various computer implemented operations involving data stored in computer systems. For example these operations may require physical manipulation of physical quantities usually though not necessarily these quantities may take the form of electrical or magnetic signals where they or representations of them are capable of being stored transferred combined compared or otherwise manipulated. Further such manipulations are often referred to in terms such as producing identifying determining or comparing. Any operations described herein that form part of one or more embodiments of the invention may be useful machine operations. In addition one or more embodiments of the invention also relate to a device or an apparatus for performing these operations. The apparatus may be specially constructed for specific required purposes or it may be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines may be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The various embodiments described herein may be practiced with other computer system configurations including hand held devices microprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like.

One or more embodiments of the present invention may be implemented as one or more computer programs or as one or more computer program modules embodied in one or more computer readable media. The term computer readable medium refers to any data storage device that can store data which can thereafter be input to a computer system computer readable media may be based on any existing or subsequently developed technology for embodying computer programs in a manner that enables them to be read by a computer. Examples of a computer readable medium include a hard drive network attached storage NAS read only memory random access memory e.g. a flash memory device a CD Compact Discs CD ROM a CD R or a CD RW a DVD Digital Versatile Disc a magnetic tape and other optical and non optical data storage devices. The computer readable medium can also be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.

Although one or more embodiments of the present invention have been described in some detail for clarity of understanding it will be apparent that certain changes and modifications may be made within the scope of the claims. Accordingly the described embodiments are to be considered as illustrative and not restrictive and the scope of the claims is not to be limited to details given herein but may be modified within the scope and equivalents of the claims. In the claims elements and or steps do not imply any particular order of operation unless explicitly stated in the claims.

Plural instances may be provided for components operations or structures described herein as a single instance. Finally boundaries between various components operations and data stores are somewhat arbitrary and particular operations are illustrated in the context of specific illustrative configurations. Other allocations of functionality are envisioned and may fall within the scope of the invention s . In general structures and functionality presented as separate components in exemplary configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements may fall within the scope of the appended claims s .

