---

title: Techniques for managing deduplication based on recently written extents
abstract: A technique is directed to managing deduplication of extents in a data storage apparatus having processing circuitry and memory which stores the extents (e.g., blocks). The technique involves constructing, by the processing circuitry, a recently written extent list which identifies recently written extents stored within the memory. The technique further involves referencing the recently written extent list to bypass (or skip over) extents identified by the recently written extent list when obtaining a candidate extent for possible deduplication. The technique further involves processing the candidate extent for possible deduplication. Here, by identifying frequently overwritten extents on the recently written extent list, the data storage apparatus is able to easily avoid cycles of deduplicating and subsequently splitting frequently overwritten extents.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08799601&OS=08799601&RS=08799601
owner: EMC Corporation
number: 08799601
owner_city: Hopkinton
owner_country: US
publication_date: 20120628
---
Block deduplication is the process of i finding block mappings that map to separate instances of identical data and ii updating those block mappings to refer to a single instance of that data. Using block deduplication data storage systems are able to eliminate storage of redundant copies of host data.

One conventional approach to performing block deduplication in a data storage system involves closely evaluating each block of host data stored by the data storage system for possible deduplication. In particular the data storage system applies a hash algorithm to each block of host data stored by the data storage system. After the data storage system computes a hash result from a particular block of host data the data storage system compares that hash result to a database of stored hash results previously computed from other blocks of host data. If the data storage system finds a matching hash result in the database the data storage system performs a bit by bit comparison to determine whether the blocks of host data are identical. If so the data storage system shares a single instance of the block of host data among block mappings. Otherwise the data storage system adds a new record to the database i.e. the data storage system adds the hash result computed from the particular block of host data to the database for possible matching in the future.

When a host modifies a block of host data that has been deduplicated the data storage system splits that shared block of host data into separate instances. Along these lines suppose that a data storage system maintains a first block mapping and a second block mapping to a single instance of host data. Further suppose that a host issues an IO command to modify the block of host data as referenced by the second block mapping while the first block mapping is intended to continue to reference the original block of host data. The data storage system responds by maintaining the original instance of the host data on behalf of the first block mapping and creating a new instance which includes the modification on behalf of the second block mapping.

Unfortunately there are deficiencies to the above described conventional approach to performing block deduplication which involves methodically evaluating each block of host data stored by the data storage system for possible deduplication. For example a host may frequently overwrite certain blocks with new data. In such a situation deduplication of frequently overwritten blocks may result in cycles of hash result computation instance sharing and instance splitting i.e. inefficient use of deduplication processing.

Additionally as these blocks get overwritten and reconsidered for deduplication the data storage system tends to add new records to the database of previously computed hash results. That is the data storage system adds new records which refer to the same physical block location thus filling the database of previously computed hash results with stale records. Accordingly the database becomes unnecessarily large in size thus consuming excess memory as well as increasing the amount of time needed to complete database searches.

Furthermore even if deduplication is performed in the background on the data storage system i.e. during idle system time consumption of resources for deduplication iterations of frequently overwritten blocks takes away resources that otherwise could be devoted to other services. For example another background process which is configured to remove stale records from the database of previously computed hash results may be prevented from running as often.

In contrast to the above described conventional approach to performing block deduplication which may inefficiently deduplicate frequently overwritten blocks an improved technique is directed to managing deduplication based on recently written extents. Such operation enables a data storage system to avoid evaluation of frequently overwritten extents and thus save processing and memory resources involved in hash computation comprehensive block comparisons and so on. Additionally such operation provides for a smaller extent sharing index table used for deduplication since the technique is able to eliminate adding table entries corresponding to recently written extents. Furthermore such operation enables quick cleanup of the extent sharing index table by simply deleting any table entries corresponding to recently written extents. Accordingly the technique enjoys lower memory consumption by the extent sharing index table as well as quicker table searching.

One embodiment is directed to a method of managing deduplication of extents which is performed in a data storage apparatus having processing circuitry and memory which stores the extents e.g. blocks . The method includes constructing by the processing circuitry a recently written extent list which identifies recently written extents stored within the memory. The method further includes referencing the recently written extent list to bypass or skip over extents identified by the recently written extent list when obtaining a candidate extent for possible deduplication. The method further includes processing the candidate extent for possible deduplication. Here by identifying frequently overwritten extents on the recently written extent list the data storage apparatus is able to easily avoid deduplicating and then splitting frequently overwritten extents.

In some arrangements the data storage apparatus maintains an extent sharing index table having entries which i have existing hash values and ii identify extents. In these arrangements processing the candidate extent for possible deduplication includes digesting the candidate extent to produce a current hash value and searching the extent sharing index table for an existing entry having an existing hash value which matches the current hash value. Processing the candidate extent for possible deduplication further includes when an existing entry in the extent sharing index table is found to have an existing hash value which matches the current hash value 

In some arrangements the method further includes performing a cleanup operation to reduce the size of the extent sharing index table based on the recently written extent list. In particular the data storage apparatus deletes from the extent sharing index table existing entries which identify extents identified by the recently written extent list. Such operation reduces the amount of memory consumed by the extent sharing index table and improves table searching efficiency.

Other embodiments are directed to systems apparatus processing circuits computer program products and so on. Some embodiments are directed to various methods devices electronic components and circuitry which are involved in managing deduplication of extents based on recently written extents.

Improved techniques are directed to managing deduplication based on recently written extents. Such operation permits a data storage system to avoid evaluation of frequently overwritten extents thereby saving processing and memory resources involved in hash computation comprehensive block comparisons etc. Additionally such operation provides for a smaller extent sharing index table used for deduplication since the techniques are able to eliminate adding table entries corresponding to recently written extents. Furthermore such operation enables quick cleanup of the extent sharing index table by simply deleting any index table entries corresponding to recently written extents. As a result the techniques enjoy lower memory consumption by the extent sharing index table as well as quicker searching of the extent sharing index table.

The host devices are constructed and arranged to store host data into and load host data from the data storage system . Along these lines each host device provides host IOs e.g. read commands to read host data write commands to write host data etc. to the data storage system for processing.

The data storage system is constructed and arranged to process the host IOs from the host devices by performing host TO operations e.g. read IOs write IOs etc. in response to the host IOs on a set of LUNs . Each LUN is partitioned into 1 GB slices and each 1 GB slice is partitioned into extents e.g. 8 KB data blocks . Such extents are addressable e.g. via logical block addressing or LBAs and are mappable e.g. to file system block numbers or FSBNs .

Additionally the data storage system is constructed and arranged to manage deduplication operations based on a list of recently written extents . Such deduplication operations include among others digest operations to generate hash values of extents sharing operations to share identical extents and cleanup operations to efficiently maintain an indexing table used by many of the deduplication operations . As will be explained in further detail below the data storage system is able to identify recently written extents from range lock information stored in a lock history database and manage the deduplication operations based on such range lock information .

The communications medium connects the various components of the data storage environment together to enable these components to exchange electronic signals e.g. see the double arrow . At least a portion of the communications medium is illustrated as a cloud to indicate that the communications medium is capable of having a variety of different topologies including backbone hub and spoke loop irregular combinations thereof and so on. Along these lines the communications medium may include copper based data communications devices and cabling fiber optic devices and cabling wireless devices combinations thereof etc. Furthermore the communications medium is capable of supporting LAN based communications SAN based communications or combinations thereof.

During operation the data storage system receives host IOs from the host devices . In order to maintain data consistency the data storage system imposes locks on the extents when processing the host IOs . For example the data storage system applies read or shared locks on ranges of extents when the host devices read host data from these ranges of extents . Furthermore the data storage system applies write or exclusive locks on ranges of extents when the host devices write host data to these ranges of extents .

As the data storage system imposes range locks on the ranges of extents the data storage system updates the range lock information in the lock history database based on these range locks. Accordingly the data storage system is then able to identify which extents have been recently written based on the range lock information . In particular the data storage system constructs a list of the recently written extents and then efficiently manages deduplication operations based on the list . For example based on the list the data storage system avoids evaluating recently written extents for deduplication. Additionally based on the list the data storage system quickly cleans up an indexing table used for deduplication thus reducing memory consumed by the indexing table and improving table searching performance. Further details will now be provided with reference to .

The host interface is constructed and arranged to connect the data storage system to the communications medium . Accordingly the host interface enables the data storage system to communicate with the other components of the data storage environment such as the host devices .

The memory is intended to represent both volatile memory e.g. DRAM SRAM etc. and non volatile memory e.g. flash storage units magnetic disk drives etc. . The data storage applications represent the operating system drivers utilities and tools user level applications GUIs and so on. The storage represents memory which contains the host data. The other memory constructs include additional memory based items such as a buffer cache metadata for locks metadata for deduplication operations e.g. the indexing table the list of recently written extents etc. and so on.

In some arrangements the storage is tiered based on access speed. For example the storage may include a first tier of flash memory a second tier of SAS memory and a third tier of near line SAS memory.

The processing circuitry is constructed and arranged to perform load and store operations i.e. to process host IOs on behalf of the host devices . Additionally the processing circuitry is constructed and arranged to control updating of the lock history database generate a list of recently written extents based on the lock history database and manage deduplication operations based on the list also see .

It should be understood that the processing circuitry can be implemented in a variety of ways including via one or more processors running specialized software application specific ICs ASICs field programmable gate arrays FPGAs and associated programs discrete components analog circuits other hardware circuitry combinations thereof and so on. In the context of one or more processors running specialized software a computer program product is capable of delivering all or portions of the software to the data storage system . The computer program product has a non transitory or non volatile computer readable medium which stores a set of instructions which controls one or more operations of the data storage system . Examples of suitable computer readable storage media include tangible articles of manufacture and apparatus which store instructions in a non volatile manner such as CD ROM flash memory disk memory tape memory and the like.

During operation the data storage system performs host IO operations in response to the host IOs received from the host devices . As the data storage system imposes locks on ranges of extents prior to accessing the ranges of extents the data storage system updates range lock information in the lock history database based on the ranges of extents which were locked by the host IO operations .

With the range lock information of the lock history database now available for analysis these contents of the lock history database are able to identify particular extents which are active and inactive and in particular which extents have been recently written. As a result the data storage system is able to effectively manage the deduplication process by eliminating evaluation of recently written extents and thus improve deduplication performance. Further details will now be provided with reference to .

The range lock module is constructed and arranged to impose range locks on ranges of extents as the data storage system performs the host IO operations and thus preserve data coherency and consistency. By way of example the range lock module is shown as responding to a host IO to read host data from extents A . . . B by providing as part of that host IO operation a read lock i.e. a shared lock on extents A . . . B . Additionally the range lock module is shown as responding to another host IO to write host data to extents X . . . Y by providing as part of that host IO operation a write lock i.e. an exclusive lock on extents X . . . Y .

The lock history module is constructed and arranged to manage the lock history database holding the range lock information also see . In particular the lock history module receives IO event messages from the range lock module which informs the lock history module of the range locks imposed by the range lock module . For example when the range lock module imposes the read lock on extents A . . . B the range lock module provides an IO event message informing the range lock module that a read lock was imposed on the range of extents A . . . B and the lock history module responds by adding an appropriate entry into the lock history database . Likewise when the range lock module imposes the write lock on extents X . . . Y the range lock module provides an IO event message informing the range lock module that a write lock was imposed on the range of extents X . . . Y and the lock history module responds by adding another appropriate entry into the lock history database .

As further shown by the deduplication module is able to communicate with the lock history module . In particular the deduplication module sends a request signal to the lock history module to obtain the contents of the lock history database . In response to the request signal the lock history module provides a response signal containing the contents of the lock history database thus enabling the deduplication module to operate based on the contents.

Once the range lock information is obtained by the deduplication module the deduplication module is able to construct the list of recently written extents . In some arrangements the deduplication module applies a policy to determine which extents appear on the list . For example the policy may require that the extent have been modified within a predefined amount of time such as six hours one hour 15 minutes and so on. As another example the policy may require that the extent have been written a predefined number of times within the last time period such as six times within the last six hours three times within the last hour once within the last 15 minutes and so on. Other policies are suitable for use as well.

In some arrangements the range lock module and the deduplication module communicate with the lock history module through an application programming interface API . That is each module is able to call a predefined routine or issue a predefined instruction to the lock history module . Similarly the lock history module is able to call a predefined routine or issue a predefined instruction to the other modules . Further details will now be provided with reference to .

With attention directed to the list of recently written extents identifies extents which recently received write range locks as imposed by the range lock module and tracked by the lock history module . Such a list is capable of being constructed by filtering and tabulating the range lock information obtained from the lock history module .

By way of example list includes entries which correspond to respective extents . Each entry includes a logical extent identifier field a time stamp field a count field and other fields . The logical extent identifier field is constructed and arranged to hold the logical extent identifier of a particular extent e.g. a logical block address . The time stamp field is constructed and arranged to hold the time stamp of the most recent write to the particular extent . The count field is constructed and arranged to hold the number of times the particular extent has been overwritten i.e. modified since the last time the deduplication module constructed the list or within a predefined amount of time . The other fields are constructed and arranged to hold additional data such as the file identifier or owner of the particular extent the physical location of the particular extent etc.

As mentioned earlier the criteria for adding an entry to the list of recently written extents is capable of being set by a policy . Over time a user of the data storage system is able to make adjustments e.g. tune to the operation of the deduplication module by changing the policy e.g. modifying policy settings adding enhancements to the policy etc. .

With attention directed to the extent sharing index table includes entries corresponding to digested extents i.e. extents for which the deduplication module has already generated hash values. The deduplication module uses the extent sharing index table to find possible matching extents i.e. as a preliminary matching tool . By way of example each entry of the extent sharing index table includes a hash value field and a set of key fields to form keys corresponding to a particular extent . The set of key fields includes a logical extent identifier field a physical extent identifier field a generation count field and other data fields .

The hash value field is constructed and arranged to hold a hash value computed by the deduplication module when applying a hashing algorithm to a particular extent . The logical extent identifier field is constructed and arranged to hold a logical identifier of the particular extent e.g. a logical block address . The physical extent identifier field is constructed and arranged to hold a physical extent identifier of the particular extent e.g. a block aligned address in physical memory a lower level logical block address if multiple levels of abstraction are used etc. . The generation count field is constructed and arranged to hold a generation count of the particular extent e.g. a number of times the extent has been written accessed . The other data fields are constructed and arranged to hold other data such as a time stamp of when the entry was added to the list and so on.

With attention directed to the deduplication module also see performs a procedure of evaluating extents for possible deduplication. In particular rather than attempt to deduplicate all identical extents the deduplication module ignores recently written extents to avoid iterations of deduplicating and splitting frequently overwritten extents . In some arrangements such operation occurs in the background i.e. during system idle time as a low priority process thread etc. .

In step the deduplication module constructs a recently written extent list which identifies recently written extents also see . As mentioned above the deduplication module is able to access range lock information from the lock history module in order to create the list . Along these lines the deduplication module filters out non useful information e.g. non write lock data and builds the list to include various write based details .

In step the deduplication module obtains a candidate extent while referencing the list to bypass extents which have been recently written. In particular the deduplication module has access to a series of extent identifiers identifying candidate extents e.g. from a table of non digested extents . Here the deduplication module reads an extent identifier e.g. an LBA from the series and determines whether the extent identifier is on the recently written extent list . If the extent identifier is not on the recently written extent list the deduplication module considers the extent identified by that extent identifier as the candidate extent . If the extent identifier is on the recently written extent list e.g. the LBA does not match any LBAs of the entries of the list also see the extent identified by the extent identifier was recently modified and the deduplication module skips over that extent identifier to the next extent identifier in the series and so on until the deduplication module finds an extent identifier that is not on the list .

After step with a candidate extent which was not recently modified now under consideration the deduplication module performs the remaining portion of the procedure to process the candidate extent for possible deduplication.

In step the deduplication module digests the candidate extent to produce a current hash value. That is the deduplication module applies a hashing algorithm to generate a current hash value which identifies the candidate extent although uniqueness is not guaranteed .

In step the deduplication module searches the extent sharing index table for an entry having an existing hash value see the hash value field in which matches the current hash value. Step then proceeds to step .

In step if the deduplication module did not find an entry having an existing hash value which matches the current hash value step proceeds to step . However if the deduplication module did find an entry having an existing hash value which matches the current hash value step proceeds to step .

In step the deduplication module adds a new entry to the extent sharing index table to represent the candidate extent . The deduplication module also updates a table of non digested extents to indicate that the candidate extent has been digested.

In step if the deduplication module found an entry having an existing hash value which matches the current hash value the deduplication module searches the recently written extent list to confirm that the extent identified by the entry has not been recently written. Step then proceeds to step .

In step if the extent identified by the entry has been recently written the deduplication module returns to step to search for other matches. In particular it is possible that multiple entries within the extent sharing index table having existing hash values which match the current hash value since uniqueness is not guaranteed. Accordingly the deduplication module is constructed and arranged to continue evaluation for a possible match and for possible deduplication. One should also appreciate that even if the extent identified by the entry is identical to the candidate extent the deduplication module does not further process the extent identified by the entry since it has been recently written thus avoiding the possibility of an inefficient deduplication and split cycle.

Still in connection with step if the extent identified by the entry has not been recently written the deduplication module proceeds to step . In this situation neither the extent identified by the entry nor the candidate extent has been recently written.

In step the deduplication module performs a comprehensive compare operation between the extents to determine whether the extents are identical. Such a compare may involve comparing each bit of the candidate extent with a corresponding bit of the extent identified by the entry . Step then proceeds to step .

In step the deduplication module proceeds to step if the extents are not identical i.e. the comparison is unsuccessful . However if the extents are identical i.e. the comparison is successful step proceeds to step .

In step the deduplication module performs an extent sharing operation to deduplicate the extents . This operation involves the updating of deduplication metadata also see the memory constructs in so that the block mappings for the extents refer to a single instance.

The deduplication module then performs the procedure to determine whether to the block mappings LBA A and LBA B are able to share a single instance. In particular the procedure bases the deduplication decision on the list of recently written extents in order to prevent iterations of duplication and splitting of frequently overwritten extents .

As shown in the lower portion of provided that the instances of host data are identical and the instances have not been recently written the deduplication module shares a single instance of the host data among the block mappings. That is the deduplication module adjusts the metadata associated with accessing host data so that block mappings LBA A and LBA B both identify the first instance of host data at physical location X. As a result physical location Y is now free and suitable for other use.

It should be understood that the duplication module is constructed and arranged to cleanup the extent sharing index table based on the recently written extent list . That is it is possible that the extent sharing index table accumulates stale entries as extents which are identified by the table are modified in real time. Accordingly the duplication module searches the table for entries that identify extents on the list . If the deduplication module finds such an entry the deduplication module deletes the entry from the table . As a result extents which have been recently modified have their availability removed from the table . Further details of the lock history module will now be provided with reference to .

As shown in the lock history database includes a set of range lock entries . Each time the lock history module receives an event message informing the lock history module of a new lock imposed on a range of extents from the range lock module the lock history module adds a new range lock entry in the lock history database to record that lock also see .

Each range lock entry includes a lock type field a logical unit identifier or file ID field a time stamp field and a set of range fields . The fields of each range lock entry hold range lock information corresponding to a range lock imposed by the range lock module during a particular host IO operation thus recording the details of that range lock . In particular the lock type field holds a value indicating the type of lock e.g. a read lock or a write lock for that range lock . The logical unit identifier field holds a logical unit identifier to identify a logical unit for that range lock i.e. a particular logical unit among multiple logical units maintained for reading and writing by the data storage system . The time stamp field holds a time stamp indicating a particular time in which a particular host IO operation locked the range of extents . The set of range fields holds range data identifying the particular range of extents which was locked by the particular host IO operation .

In some arrangements the set of range fields includes a starting offset field and a range length field . The starting offset field of a range lock entry holds a starting offset of a particular range lock and the range length field holds the length of that particular range lock .

In other arrangements the set of range fields define range locks differently. For example in some arrangements the set of range fields simply includes a start offset field and an end offset field to hold the starting and ending offsets of a particular range lock .

Once a set of range lock entries has been processed to produce aggregated lock data the aggregated lock data indicates the extents that had been identified by the set of range locks . Accordingly the aggregated lock data identifies extents which have been recently accessed and which are thus considered active or hot . Once the aggregated lock data has been formed future processing of a new set of range lock entries i.e. range lock entries which have been added to the lock history database since the last consolidation process involves adjusting or updating the existing aggregated lock data based on the new set of range lock entries .

In some arrangements when the lock history module receives a request signal for the contents of the lock history database the lock history module performs the consolidation process on any existing range lock entries to update the aggregated lock data . The lock history module then provides as a response signal only the aggregated lock data . For example the response signal may include a file or a pointer to a file containing just the aggregated lock data or a copy of the aggregated lock data .

In some arrangements the aggregated lock data persists until it is cleared e.g. in response to a user command to reset the values of the lock history database . In some arrangements the lock history database resides in non volatile storage so that the lock history database persists even during a reboot of the data storage system .

In some arrangements the aggregated lock data includes a mapping table which maps tallied access counts to each extent . In other arrangements the aggregated lock data includes nodes corresponding to time intervals e.g. one hour ago two hours ago etc. where each node identifies ranges of extents which have been accessed within a particular time interval. Accordingly the particular structure for the range lock information in the aggregated lock data may take a variety of forms e.g. trees linked lists counters combinations thereof and so on.

One will appreciate that a variety of criteria may be used as a determining factor as to whether each extent is active or inactive. In some arrangements if the lock history database indicates that an extent was accessed within a predefined amount of time e.g. an hour six hours etc. the extent is considered active. In other arrangements if the lock history database indicates that an extent was accessed at least a certain predefined amount of times within a particular amount of time e.g. at least 3 times within the last 24 hours etc. the extent is considered active. Similarly an extent may be considered inactive if the extent fails to satisfy the active criteria. Further details will now be provided with reference to .

In step the lock history module receives a lock history request. For example the deduplication module or another service module may provide a request signal to the lock history module requesting the contents of the lock history database .

In step the lock history module providing the contents of the lock history database to identify as the IO hot spots extents which were locked by the host IO operations . In particular the lock history module outputs a response signal back to the requesting deduplication module .

As described above an improved technique is directed to managing deduplication based on recently written extents . Such operation enables a data storage system to avoid evaluation of frequently overwritten extents and thus save processing and memory resources involved in hash computation comprehensive block comparisons and so on. Additionally such operation provides for a smaller extent sharing index table used for deduplication since the technique is able to eliminate adding table entries corresponding to recently written extents . Furthermore such operation enables quick cleanup of the extent sharing index table by simply deleting any table entries corresponding to recently written extents . Accordingly the technique enjoys lower memory consumption by the extent sharing index table as well as quicker table searching.

While various embodiments of the present disclosure have been particularly shown and described it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the spirit and scope of the present disclosure as defined by the appended claims.

For example it should be understood that the above described technique for cleaning up the extent sharing index table based on the recently written extent list may be used in combination with a conventional cleanup mechanism. In some arrangements cleanup of the extent sharing index table based on the recently written extent list routinely occurs prior to starting a more exhaustive cleanup phase of removing duplicate entries to the same extent . In other arrangements cleanup of the extent sharing index table based on the recently written extent list occurs during certain times of operation e.g. periods of high IO traffic during regular business hours etc. and a more exhaustive cleanup phase is performed during other times of operation e.g. periods of low IO traffic nightly etc. .

Additionally it should be understood that some data storage systems may have a standard map for digest procedure which returns a new extent to digest i.e. from which to compute a hash value . In these situations the standard map for digest procedure is capable of being enhanced to skip over extents which appear on the recently written extent list . That is the map for digest procedure is modified so as not to return an extent which is recently written thus avoiding further processing of the recently written extent for deduplication purposes. As a result cycles of deduplicating and splitting frequently overwritten extents are avoided.

In the context of a call back file system CBFS using thin provisioning one should appreciate that the above described techniques improve deduplication efficiency by utilizing range lock stats from CBFS generating write hot spot hints and avoiding deduplication of extents that are most recently written. In short the CBFS mapping service is able to synchronize data access to mapped LUs by applying IO range locks for different IO types and such information is able to be made available externally through a CBFS API . In these situations a deduplication service is able to periodically poll the range lock stats from CBFS and construct write hot ranges based on the stats data . When deduplication service performs deduplication operations it then utilizes the write hot ranges in following ways 

