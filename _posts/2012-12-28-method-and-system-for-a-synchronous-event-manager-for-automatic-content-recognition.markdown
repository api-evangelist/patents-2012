---

title: Method and system for a synchronous event manager for automatic content recognition
abstract: A method and system for a synchronous event manager for automatic content recognition (ACR) are described. A display device, such as a connected television or mobile device, may be operable to perform ACR and may utilize a synchronous event manager comprising a software layer that may continuously be executed as a background process. The software layer may comprise a single framework or framework from which to execute one or more user-interaction applications. The software layer may monitor internal and external events and may detect an event trigger produced in response to a match resulting from the ACR. After receiving a user-interaction application corresponding to the detected event trigger, the software layer may launch or invoke the user-interaction application from the single framework. In some instances, multiple user-interaction applications may be launched concurrently from the single framework. These user-interaction applications may interface with each other through the single framework.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08832723&OS=08832723&RS=08832723
owner: Turner Broadcasting System, Inc.
number: 08832723
owner_city: Atlanta
owner_country: US
publication_date: 20121228
---
This application makes reference to claims priority to and claims the benefit of U.S. provisional application 61 596 012 filed on Feb. 7 2012.

Each of the above referenced applications is hereby incorporated herein by reference in its entirety.

Certain embodiments of the invention relate to digital audio video content recognition. More specifically certain embodiments of the invention relate to a method and system for a synchronous event manager for automatic content recognition.

Smart or connected televisions TVs may receive data from data networks that allow a viewer to not only access broadcast digital content but to also receive multimedia content.

Further limitations and disadvantages of conventional and traditional approaches will become apparent to one of skill in the art through comparison of such systems with some aspects of the present invention as set forth in the remainder of the present application with reference to the drawings.

A system and or method is provided for a synchronous event manager for automatic content recognition substantially as shown in and or described in connection with at least one of the figures as set forth more completely in the claims.

These and other advantages aspects and novel features of the present invention as well as details of an illustrated embodiment thereof will be more fully understood from the following description and drawings.

Certain embodiments of the invention may be found in a method and system for a synchronous event manager for automatic content recognition ACR . Various embodiments of the invention provide a display device such as a connected television TV or mobile device for example which may be utilized with an ACR system. The display device may be operable to perform ACR and may utilize a synchronous event manager comprising a software layer that is continuously executed. In one aspect of the invention the software layer may run as a background process. The software layer may comprise a single environment or framework from which to execute one or more applications that enable a user to engage in interactive events with the display device. The software layer may monitor internal and external events and may detect an event trigger produced in response to a match resulting from the ACR. After receiving a user interaction application corresponding to the detected event trigger the software layer may launch or invoke the user interaction application from the single framework. In some instances multiple user interaction applications may be executed concurrently from the single framework. Moreover these user interaction applications may interface with each other through the single environment or framework. The request and or launching of the user interaction applications may occur through the synchronous event manager and are transparent to the user. In this regard the operation of the synchronous event manager is transparent to the user.

The ACR system in which end user devices such as display devices utilize a synchronous event manager to monitor events may be implemented with a single network time server that coordinates the triggering of events. The ACR system may also comprise multiple fingerprint servers each of which utilizes different fingerprinting technology. The network time server may also be referred to as a network protocol time NTP server. Each of the fingerprint servers may generate a set of video fingerprints in real time from a network television feed by utilizing a video fingerprint technology that is different from the technology utilized by any of the other fingerprint servers. The different fingerprinting technologies may be from different fingerprinting vendors for example. The fingerprint servers may also be referred to as real time fingerprint servers RTFSs . The network time server may be operable to assign one or more interactive event identifiers to the different sets of video fingerprints generated by the fingerprint servers. The fingerprint servers may communicate the sets of video fingerprints and interactive event identifiers to corresponding fingerprint match systems which in turn may communicate with end user devices that utilize the same video fingerprint technology as the corresponding fingerprint server.

Fingerprinting and more particularly ACR fingerprinting may refer to a process by which features of a video frame and or of an audio frame may be analyzed to create representations i.e. fingerprints for each piece of content for example. The fingerprints may be unique to each piece or sequence of content and may be highly robust against broadcast distortions such as re encoding aspect ratio frame rate up down conversion and pitch correction to name a few. The fingerprints may be stored in a reference database in the ACR system such that unidentified content e.g. content from a network television feed may be identified by comparing fingerprints taken of the unidentified content with the stored fingerprints.

Once the interactive event identifiers have been assigned by the network time protocol server the real time fingerprint servers may communicate the video fingerprints and the assigned event identifiers to corresponding fingerprint match systems. In some instances the fingerprint match systems may be operated by a third party e.g. television manufacturers vendors etc. as hosted services over the Internet e.g. cloud computing etc. . Each of the fingerprint match systems may communicate with end user devices e.g. connected TVs tablets smartphones etc. that utilize the same video fingerprint technology utilized by the fingerprint server that corresponds to that fingerprint match system. The end user devices may be referred to as viewer devices for example. The end user devices may utilize the synchronous event manager to monitor and manage internal events corresponding to ACR operations and or external events such as event triggers in the form of interactive event identifiers for example.

The fingerprint match systems receive video fingerprints from the end user devices and compare them to the ones received from the real time fingerprint servers. When a match occurs the fingerprint match systems may notify the end user devices that an interactive event is to take place if there is an event identifier that corresponds to the matched video fingerprints. The synchronous event manager in each of the end user devices monitors and manages signals and or notifications related to the ACR related operations of the device including but not limited to notifications that an interactive event is to take place.

As described above automatic content recognition may be utilized across several platforms including connected TVs from various manufacturers as well as smartphones and tablets. Since television viewing may be rapidly evolving from a single screen experience to a multiple screen experience television networks may need to automatically identify the context of what a viewer is watching and the time in the program both during a live television broadcast and in subsequent viewings such as when a program is being reproduced by a digital video recorder DVR . In multi screen viewing experiences for example companion applications on second screen devices may also be utilized to interact with the television programming.

Having the ability to identify context and program timing may enable a network to increase audience engagement extend viewing times and provide program sponsors additional ways to engage with the audience such as offering viewers personalized advertising offers or creating a second screen experience during an advertisement break. These features may be implemented by having a central video fingerprint repository and management platform that facilitates triggering interactive events across various platforms regardless of the ACR vendor solution e.g. fingerprinting technology . For example an ACR system may utilize a single broadcast ACR solution to support connected TVs from multiple vendors as well as second screen devices running companion applications. In this regard connected TVs from a particular vendor may utilize a synchronous event manager with functionality and or interfaces that are suitable for those connected TVs. An ACR system supporting multiple vendors may be scalable and additional ACR vendor solutions may be easily added without architectural changes. Moreover such a system may handle both real time and pre recorded offline content.

Below are described various examples of aspects related to an ACR system in which end user devices utilize a synchronous event manager. These exemplary aspects may comprise the system architecture processes application programming interfaces APIs and or web based services.

The ACR system may also comprise an NTP server that is operable to provide synchronization to various parts of the ACR system via a common reference clock. For example the NTP server may be operable to synchronize the operation of the RTEM with the operation of the RTFSs . . . . The operations of the NTP server may be based on for example the Internet Engineering Task Force IETF RFC 5905 Network Time Protocol Version 4 Protocol and Algorithms Specification. 

The offline fingerprint module may comprise suitable logic circuitry code and or interfaces that may be operable to handle the offline fingerprinting portion of the operations performed by the ACR system . The offline fingerprint module may be operable to receive pre recorded or offline content such as commercials programs and promotions for example. In this regard the offline fingerprint module may be able to ingest and process content with defined interactivity. The monitor application module may comprise suitable logic circuitry code and or interfaces that may be operable to process a network television feed and the content handled by the offline fingerprint module to create a real time timeline and or real time event triggers. During the process the monitor application module and or the timeline event creation module may interact with backend analytics databases that comprise user engagement data for example. Some of the operations that may be performed by the offline fingerprint module may comprise for example ingest operations storage operations monitoring operations and or content version comparison operations.

The RTEM may comprise suitable logic circuitry code and or interfaces that may be operable to manage real time events based on inputs provided by one or more sources. For example the RTEM may be operable to manage real time events based on events stored in an interactive timeline archive a network schedule and or those provided by an interactive director that may assign interactive event IDs to live programming as the network television feed is being fingerprinted in real time. Moreover the RTEM may be operable to trigger interactive events in legacy systems and or in web based systems. The RTEM may be referred to as a real time event trigger infrastructure for example. The RTEM may comprise a real time event inserter RTEI not shown which is operable to insert the events into the RTFSs . . . .

In accordance with an embodiment of the invention the RTEM may be operable to instruct the monitor application module and or the timeline event creation module to record the fingerprints associated with a live program as well as to store the corresponding set of events created during the live program in the interactive timelime archive. This enables playback of the program with interactivity even after expiration of the corresponding fingerprints in the vendor s third party database. This may occur in instances when there is a re broadcast of the live event at a subsequent date. In the case of timeline based devices the events may be stored and timeline retrieval may be enabled even during the active window of the corresponding fingerprints since there will be no available event to fingerprint association.

In accordance with an embodiment of the invention the RTEM may be operable to receive one or more inputs from a user e.g. an interactive director and to generate based on those inputs interactive event identifiers that can be communicated to the fingerprint servers where they can be associated with or assigned to the video fingerprints generated by the fingerprint servers. The RTEM may be operable to communicate the interactive event identifiers to a television system e.g. legacy system and or to a web system. The interactive event identifiers may be utilized in the television system and or in the web system to trigger interactive events. Moreover the communication of the interactive event identifiers may be based on one or more of an EBIF an HTTP live streaming HLS a satellite network protocol or some other protocol.

In an embodiment of the invention the Real time event manager may be operable to generate one or more signals that provide instructions to the RTFSs . . . to enable the identification of a network television station based on the logo symbol sign watermark and or text that are typically utilized to represent the network television station. The instructions may be related to information that is to be generated and or provided to the end user devices for network television station identification. The instructions may indicate the type of information that is to be provided to the end user devices and or when such information is to be provided. In some instances a portion of the ACR system other than the Real time event manager or in conjunction with the Real time event manager may generate the signals for providing instructions to the RTFSs . . . .

The RTFSs . . . may comprise suitable logic circuitry code and or interfaces that may be operable to handle fingerprinting and fingerprint communications to the fingerprint match systems . Since each vendor or television manufacturer is likely to utilize its own fingerprint technology each of the RTFSs . . . may be a dedicated server for each of the fingerprint technologies supported by the ACR system . In some embodiments of the invention a portion of the RTFSs . . . may be operable to perform video fingerprinting while the remaining portion of the RTFSs . . . may be operable to perform audio fingerprinting or some combination thereof. Fingerprint technologies from multiple vendors may utilize different computations to perform fingerprinting of video and or audio frames. For example each fingerprint technology may utilize a specific set of algorithms parameters operations and or data processing methods for example.

In an embodiment of the invention the RTFSs . . . may be operable to receive one or more signals from the Real time event manager and or from another portion of the ACR system to enable the identification of a network television station based on the logo symbol sign watermark and or text that are typically utilized to represent the network television station. The instructions may be utilized to determine and or provide locations to the end user devices to take fingerprints of the video content being displayed on a viewing screen. In some instances at least a portion of the fingerprinting locations may be provided by the Real time event manager and or by another portion of the ACR system through the instructions received by the RTFSs . . . . In other instances the fingerprinting locations may be determined by the RTFSs . . . based on locally and or remotely stored information. Each fingerprinting location may comprise coordinates in a video frame e.g. x coordinates y coordinates that indicate a particular region in the video frame to fingerprint.

The RTFSs . . . may provide the fingerprinting locations for communication to the end user devices for example in the form of fingerprint profiles. The fingerprint profiles may comprise fingerprinting locations and or other information to be utilized by an end user device for ACR fingerprinting. In some instances the fingerprint profiles may be generated by the RTFSs . . . in response to the instructions received. In other instances the fingerprint profiles comprising the fingerprinting locations may be received by the RTFSs . . . from the Real time event manager and or from another portion of the ACR system . The fingerprint profile of a particular end user device may be updated based on an indication that additional and or different locations may be needed during fingerprinting to identify the network television station logo or symbol being displayed on a viewing screen at the end user device . The update may be generated by the corresponding RTFS and then communicated to the end user device or may be received by the corresponding RTFS from the Real time event manager and or from another portion of the ACR system and then communicated to the end user device .

The indication that a fingerprint profile update may be needed may be the result of network operations that recognize that certain content is being broadcast by several network television stations concurrently e.g. State of the Union address . In such instances the fingerprinting locations being utilized may not analyze the region in a video frame where the logo of the network television station is displayed. Thus providing additional fingerprinting locations in this region may enable detection and identification of the logo and consequently of the network television station.

The indication that a fingerprint profile update may be needed may also be the result of feedback provided by an end user device . The feedback may indicate for example that the content being displayed has been identified but that the content may have originated in any one of several sources and the particular source of the content has not been identified. In such instances the fingerprinting locations being utilized may not analyze the region in a video frame where the logo of the network television station is displayed. Thus providing additional fingerprinting locations in this region may enable detection and identification of the logo and consequently of the source of the content.

In some instances the fingerprint profile and or the fingerprint profile update received by an end user device may comprise information that indicates to the end user device that any additional fingerprinting locations may be utilized automatically when the source e.g. network television station of a particular content is not initially identified.

In one or more embodiments of the invention the RTFSs . . . may be operable to communicate fingerprint profiles and or fingerprint profile updates to the end user devices through the fingerprint match systems . Feedback and or queries from the end user devices may be received by the RTFSs . . . for processing. The RTFSs . . . may in turn communicate information corresponding to the feedback and or queries from the end user devices to the Real time event manager and or to another portion of the ACR system for further processing.

The fingerprint match systems may comprise suitable logic circuitry code and or interfaces that may be operable to enable hosted services in the Internet for matching fingerprints produced by the RTFSs . . . with fingerprints produced by the end user devices . Each of the fingerprint match systems corresponds to a particular ACR or fingerprint technology. In this regard each of the fingerprint match systems may be supported by a third party such as a TV manufacturer for example.

The fingerprint match systems may be operable to compare fingerprints produced by the end user devices with fingerprints provided by the RTFSs . . . . When matches occur the fingerprint match systems may indicate that interactive events are to take place in the end user devices . These interactive events may allow a viewer to be presented with information on the screen or display of an ACR based device and to interact with the device based on the information presented.

The end user devices may comprise a plurality of devices such as connected TVs connected TV with paired devices e.g. tablets and second screen devices such as smartphones and tablets for example. The ACR based devices may be referred to as end user devices for example. Since each of the fingerprint match systems supports a different ACR or fingerprint technology those end user devices that support a particular fingerprint technology are operable to communicate with the corresponding fingerprint match systems that support the same fingerprint technology. Moreover when a secondary or paired device that supports a particular fingerprint technology is used that device may also be able to communicate with the corresponding fingerprint match system that supports the compatible fingerprint technology.

The end user devices may be operable to receive and utilize a fingerprint profile and or a fingerprint profile update and to take fingerprints in a pre determined number of locations in a video frame. Each fingerprinting location may be defined by a set of coordinates that describe a region in the video frame where a fingerprint of the video content is to be taken. The end user devices may be operable to receive a series of fingerprint profiles and or fingerprint profile updates and may be operable to adjust ACR fingerprinting accordingly.

The end user devices may be operable to execute or run a synchronous event manager as a background process. The synchronous event manager may comprise a software layer that monitors events and is enabled to receive event triggers and associated data when there is a fingerprint match that results in an interactive event. The execution of the synchronous event manager may be performed continuously at least for a period of time during which the event monitoring is to take place. The events monitored may comprise events that occur in connection with the internal ACR operations of the device for example and events provided by external sources such as the event triggers and associated data for example.

In some instances the synchronous event manager in an end user device may be enabled to determine whether the user has elected to participate in events corresponding to a particular network television station. When such election has been made the synchronous event manager may enable or allow applications related to the interactive event to be requested and or launched. The synchronous event manager may enable the event trigger and associated data to interface with a framework environment or engine of the software layer.

The fingerprint match systems may comprise suitable logic circuitry code and or interfaces that may be operable to enable hosted services in the Internet for matching fingerprints produced by the RTFSs . . . with fingerprints produced by the end user devices . Each of the fingerprint match systems corresponds to a particular ACR or fingerprint technology. In this regard each of the fingerprint match systems may be supported by a third party such as a TV manufacturer for example.

The fingerprint match systems may be operable to compare fingerprints produced by the end user devices with fingerprints provided by the RTFSs . . . . When matches occur the fingerprint match systems may indicate that interactive events are to take place in the end user devices . These interactive events may allow a viewer to be presented with information on the screen or display of an ACR based device and to interact with the device based on the information presented.

The end user devices may comprise a plurality of devices such as connected TVs connected TV with paired devices e.g. tablets and second screen devices such as smartphones and tablets for example. The ACR based devices may be referred to as end user devices for example. Since each of the fingerprint match systems supports a different ACR or fingerprint technology those end user devices that support a particular fingerprint technology are operable to communicate with the corresponding fingerprint match systems that support the same fingerprint technology. Moreover when a secondary or paired device that supports a particular fingerprint technology is used that device may also be able to communicate with the corresponding fingerprint match system that supports the compatible fingerprint technology.

The end user devices may be operable to receive and utilize a fingerprint profile and or a fingerprint profile update and to take fingerprints in a pre determined number of locations in a video frame. Each fingerprinting location may be defined by a set of coordinates that describe a region in the video frame where a fingerprint of the video content is to be taken. The end user devices may be operable to receive a series of fingerprint profiles and or fingerprint profile updates and may be operable to adjust ACR fingerprinting accordingly.

The applications and analytics module may comprise suitable logic circuitry code and or interfaces that may be operable to provide data to the end user devices determine what platforms are to be served and when these platforms are to be served handle communications with third party partners and advertisers handle communication with backend analytics databases and determine unique responses for a given device request e.g. fix targeting .

The timeline event creation module may comprise suitable logic circuitry code and or interfaces that may be operable to produce a timeline of the content in a program or show based on information provided by the monitor application module . The timeline event creation module may then provide the timeline created to the applications and analytics module to have the timeline disseminated to the appropriate End user devices that may not support event to fingerprint association. Once the End user devices have the timeline for a particular program or show they may monitor the program or show relative to the timeline and launch appropriate event requests when a specified point in the timeline indicates that a particular event is to take place.

Communication between the RTFSs . . . and the fingerprint match systems may occur through one or more wireless and or wireline communication links. Similarly communications between the fingerprint match systems and the end user devices and or the applications and analytics module may occur through one or more wireless and or wireline communication links. The communication links described above may support one or more communication protocols. For example communication protocols based on Internet Protocol IP may be typically used. Accordingly the RTFSs . . . the fingerprint match systems and the applications and analytics module may comprise suitable logic circuitry code and or interfaces to enable the use of the communication protocols.

In operation the monitor application module and or the RTEM may generate and or handle event identifiers or event triggers that correspond to specific times in a program. These event identifiers may be generated from live programming from a network schedule or from information provided by the offline fingerprint module . The event identifiers may be assigned to the appropriate fingerprints generated by the RTFSs . . . . Since each RTFS relies on a different fingerprint technology system synchronization is needed to appropriately assign the event identifiers to the right spot on a video and or audio sequence. Such synchronization may be achieved by the use of a common reference clock provided by the NTP server .

Each of the RTFSs . . . may communicate the event identifiers and the fingerprints to its corresponding one of the fingerprint match systems . The fingerprint match systems in turn receive fingerprints from their corresponding end user devices and try to match those fingerprints to the ones received from their corresponding RTFSs . . . . When a match occurs the event identifier and or other information may be passed to the appropriate ACR based device. With this information the ACR based device may obtain for example interactive information e.g. graphics from the applications and analytics module . For example a connected TV may receive code or data specific for that device from a content management system CMS via a cloud based content delivery network CDN . There may be other actions performed by the user in connection with the interactive event and or other information presented or produced in connection with the interactive event.

In instances when the match occurs and the event identifier and or other information may be passed to the appropriate end user device the information passed may be monitored and handled by a synchronous event manager running in the end user device. The synchronous event manager may utilize the information to obtain graphics or other interactive information from the applications and analytics module . The interactive information may be provided in the form of a user interactive application for example which is executed in a portion of the synchronous event manager configured to handle the user interactive application.

In operation the ACR system may generate a fingerprint profile that may be communicated to one of the end user devices . The fingerprint profile may be communicated through one or more of the Real time event manager one of the RTFSs . . . and one of the fingerprint match systems . The fingerprint profile may comprise locations where the end user device is to take fingerprints of the video content being reproduced by the device. Once the content is identified based on the fingerprints taken and subsequently matched in the corresponding fingerprint match system it may be determined that the source of the content is not known. Knowing the source of the content may be needed in some instances to enable interactive events associated with that source on the end user device. Otherwise an interactive event from for example one network television station may occur when a viewer is watching programming provided by a different network television station.

When the source of the content is not known the end user device may automatically utilize additional locations provided in the fingerprint profile or in a fingerprint profile update. These locations may correspond to the region in the video frame where the network television station logo or symbol is typically placed. Once these fingerprints are taken they may be compared to fingerprints of the network television station logo or symbol at the corresponding fingerprint match systems . When a match occurs and the logo is identified the end user device may be able to receive interactive event identifiers from the corresponding RTFS. Once these interactive event identifiers are received the end user device may communicate with the applications and analytics module to enable the interactive events to occur.

Also shown in are various end user devices such as connected TVs with paired devices and connected TVs without paired devices and mobile devices such as smartphones e.g. iPhone Android etc. and tablets e.g. iPad Samsung Galaxy etc. . A paired device associated with the connected TVs may be a tablet smartphone or other like devices for example.

The end user devices may be operable to utilize the same video fingerprinting technology e.g. video ACR utilized by the video RTFS and supported by the video fingerprint vendor . The video fingerprint vendor may be a vendor manufacturer or other third party service provider that may comprise suitable logic circuitry code and or interfaces operable to provide hosted services over the Internet e.g. cloud computing etc. for the end user devices . These services may comprise video fingerprint matching as well as the delivery of any interactive event IDs associated with a match. The services may also comprise the communication of fingerprint profiles and or other related information to the end user devices and or the reception of feedback and or queries from the end user devices to be communicated to the video RTFS . In addition the video fingerprint vendor may provide a network television station identifier and or network timing information e.g. heartbeat message or NTP based network timestamp that may be utilized by the end user devices for ACR related applications and or to maintain synchronization with the network television feed.

The end user devices may comprise suitable logic circuitry code and or interfaces that may be operable to take and send video fingerprints to the video fingerprint vendor for matching. Moreover each of the end user devices may be operable to run or execute a synchronous event manager continuously as a background software operation to monitor events and handle applications related to interactive opportunities to be presented to users. The synchronous event manager may be operable to receive and process information from a corresponding video fingerprint vendor .

The end user devices may be operable to utilize the same video fingerprinting technology utilized by the video RTFS and supported by the video fingerprint vendor . The video fingerprinting technology utilized by the end user devices may be different from that utilized by the end user devices . The video fingerprint vendor may be a vendor manufacturer or other third party service provider that may comprise suitable logic circuitry code and or interfaces operable to provide hosted services over the internet for the end user devices . These services may comprise video fingerprint matching as well as the delivery of any interactive event IDs associated with a match. The services may also comprise the communication of fingerprint profiles and or other related information to the end user devices and or the reception of feedback and or queries from the end user devices to be communicated to the video RTFS . In addition the video fingerprint vendor may provide a network television station identifier and or network timing information that may be utilized by the end user devices for ACR related applications and or to maintain synchronization with the network television feed. The end user devices may comprise suitable logic circuitry code and or interfaces that may be operable to take and send video fingerprints to the video fingerprint vendor for matching. The end user devices and may be operable with a second device e.g. smartphones tablets that may be paired to the parent device. In this regard the second device may comprise suitable logic circuitry code and or interfaces that may be operable to take and send video and or audio fingerprints to a corresponding video fingerprint vendor for matching or enable suitable pairing with the parent device to provide analogous functionality. Moreover each of the end user devices may be operable to run or execute a synchronous event manager continuously as a background software operation to monitor events and handle applications related to interactive opportunities to be presented to users. The synchronous event manager may be operable to receive and process information from a corresponding video fingerprint vendor .

The end user devices may utilize the same video fingerprinting technology utilized by the video RTFS and supported by the video fingerprint vendor . The video fingerprint vendor may be a vendor manufacturer or other third party service provider that may comprise suitable logic circuitry code and or interfaces operable to provide hosted services over the Internet for the end user devices . These services may comprise video fingerprint matching as well as the delivery of any interactive event IDs associated with a match. In addition the video fingerprint vendor may provide a network television station identifier and or network timing information that may be utilized by the end user devices for ACR related applications and or to maintain synchronization with the network television feed. The end user devices may comprise suitable logic circuitry code and or interfaces that may be operable to take and send video fingerprints to the video fingerprint vendor for matching.

The end user devices may comprise suitable logic circuitry code and or interfaces that may be operable to take and send video fingerprints to the video fingerprint vendor for matching. Moreover each of the end user devices may be operable to run or execute a synchronous event manager continuously as a background software and or firmware operation to monitor events and handle applications related to interactive opportunities to be presented to users. The synchronous event manager may be operable to receive and process information from a corresponding video fingerprint vendor .

The end user devices may utilize the same audio fingerprinting technology e.g. audio ACR utilized by the audio RTFS and supported by the audio fingerprint vendor . The end user devices may be referred to as second screen devices for example. The audio fingerprint vendor may be a vendor manufacturer or other third party service provider that may comprise suitable logic circuitry code and or interfaces operable to provide hosted services over the Internet for the end user devices . These services may comprise audio fingerprint matching as well as the delivery of any interactive event IDs associated with a match. The services may also comprise the communication of audio fingerprint profiles and or other related information to the end user devices and or the reception of feedback and or queries from the end user devices to be communicated to the audio RTFS . Audio fingerprint profiles may comprise information related to the characteristics e.g. segments frequencies of the audio fingerprints to be taken by the end user devices . In addition the audio fingerprint vendor may provide a network television station identifier and or network timing information that may be utilized by the end user devices for ACR related applications and or to maintain synchronization with the network television feed.

The end user devices may comprise suitable logic circuitry code and or interfaces that may be operable to take and send audio fingerprints to the audio fingerprint vendor for matching. Moreover each of the end user devices may be operable to run or execute a synchronous event manager continuously as a background software operation to monitor events and handle applications related to interactive opportunities to be presented to users. The synchronous event manager may be operable to receive and process information from the audio fingerprint vendor .

The RTFSs . . . may comprise suitable logic circuitry code and or interfaces that may be operable to perform fingerprinting of content received from the network television feeds. Each video RTFS may utilize a different video fingerprinting technology or computation from that utilized by the other video RTFSs. Similarly when more than one audio RTFS is utilized its audio fingerprint technology or computation may be different from that utilized by the other audio RTFSs. That is since each vendor supports a different technology for handling fingerprinting dedicated RTFSs may be needed for each vendor and for that vendor s corresponding end user devices. The RTFSs . . . may be operable to send fingerprints interactive event IDs television network station identifiers and or network timing information to their corresponding fingerprint vendors through one or more networks e.g. wireline networks wireless networks and or by utilizing one or more communication protocols.

The RTFSs . . . may be operable to handle instructions and or information that enable the identification of a network television station based on the logo symbol sign watermark and or text that are typically utilized to represent the network television station. In this regard the RTFSs . . . may be operable to handle instructions and or information as described above with respect to the RTFSs . . . that are illustrated in for example.

The RTEM may comprise suitable logic circuitry code and or interfaces that may be operable to perform real time event triggering. In this regard the RTEM may be operable to manage real time events based on inputs from different sources. For example the RTEM may comprise a pre recorded event trigger module to provide real time triggering from the monitor application module shown in a time scheduled event trigger module to schedule the occurrence of a trigger based on a broadcast schedule and a live event trigger module each of which is operable to handle a different type of input.

The pre recorded event trigger module may be operable to receive real time event triggers from the timeline event creation module described above with respect to . These interactive event IDs may be stored in the interactive timeline archive and may be utilized by the pre recorded event trigger module to assign interactive events via for example defined APIs to fingerprints generated as the network television feeds are fingerprinted by the RTFSs . . . .

The time scheduled event trigger module may be operable to receive a network or broadcast schedule and to assign based on the network schedule interactive events to fingerprints generated as the network television feed is fingerprinted by the RTFSs . . . . The network or broadcast schedule can be in XML format or in some other structured data format for example.

The live event trigger module may be operable to received interactive event IDs assigned by an interactive director to live programming. The interactive director may be an operator that is responsible for inserting events into the live broadcast. For pre produced content for example the interactive director may watch an episode and may determine when an interactive element is to take place when to push a trivia question when to push a fun fact when to drive social engagement and or when to share a clip or post a comment. For live content for example the interactive director may determine when to trigger a poll question and may manage the prompting of interactive games and determine when to trigger particular questions to engage viewers in a friendly competition. For advertisement for example the interactive director may determine when to bring up an offer when to prompt to prepare for interaction or interaction event and or determine how long to leave interactive content on screen based on frequency rules and or time of day. When advertisement is pre fingerprinted for example interactive advertisement activities may occur automatically.

The RTEM may also be operable to trigger interactive events in legacy television systems and or in web based systems. The infrastructure provided by the RTEM may support the triggering of interactive events against applications and set top boxes STBs via enhanced television binary interchange format EBIF hypertext transfer protocol HTTP live streaming HLS via ID3 tags and satellite delivery systems e.g. DISH DirectTV via the appropriate mechanism on the corresponding STB software platform. For HLS an ID3 tag may be utilized for sending interactive event IDs for example.

The RTEM may be operable to assign interactive event IDs to particular fingerprints in a sequence of audio or video fingerprints generated by the RTFSs . . . . The RTEM may also be operable to provide television network station identifiers and or network timing information associated with any sequence of fingerprints.

In the example shown in the RTFSs . . . may correspond to the RTFSs . . . the fingerprint vendors . . . may correspond to the fingerprint match systems and the end user devices . . . may correspond to the end user devices which are illustrated in .

The RTEM may be operable to handle instructions and or information that enable the identification of a network television station based on the logo symbol sign watermark and or text that are typically utilized to represent the network television station. In this regard the Real time event manager may be operable to handle instructions and or information as described above with respect to the Real time event manager that is illustrated in for example.

In operation the RTEM may generate and or handle one or more interactive event IDs that correspond to a particular set of fingerprints generated by the RTFSs . . . . The RTEM may have determined the interactive event IDs based on live event inputs time scheduled event inputs and or pre recorded event inputs. The RTEM may assign or associate the interactive event IDs to their appropriate fingerprints based on the synchronization of its operation to the operation of the RTFSs . . . via broadcast NTP. The RTEM may also provide television network station identifiers and or network timing information to the RTFSs . . . . The RTFSs . . . may communicate the fingerprints interactive event IDs the television network station identifiers and or the network timing information to their corresponding fingerprint vendors.

The client or end user devices may take and send fingerprints to their corresponding fingerprint vendors which in turn determine whether there is a match with the fingerprints received from the RTFSs. Upon detection or determination of a match the fingerprint vendors may return to the viewer device various pieces of information including but not limited to network timing information and any interactive event ID that is triggered as a result of the match.

The portion in may also illustrate the implementation of an abstraction layer that enables the ACR system to assign the same interactive event identifiers to different sets of video and or audio fingerprints that are generated from different fingerprint technologies. That is by appropriately timing the assignment of interactive event identifiers to multiple sequences of fingerprints that are generated from the same video content but with different fingerprinting technologies the ACR system may be able to support fingerprinting technologies from multiple vendors. Such implementation may provide flexibility by enabling a vendor to update its fingerprinting technology without affecting other fingerprinting technologies. Moreover the architecture of the ACR system may provide scalability by enabling new or additional fingerprint technologies from other vendors or from the same vendors to be added and supported.

The end user devices may take and send fingerprints to their corresponding fingerprint vendors which in turn determine whether there is a match with the fingerprints received from the RTFSs. Upon detection or determination of a match the fingerprint vendors may return to the end user device various pieces of information including but not limited to television network station identifiers network timing information and any interactive event ID that is triggered as a result of the match. A synchronous event manager running in each of the end user devices may monitor information being received from a corresponding RTFS and may process the various pieces of information described above to enable an interactive opportunity to take place.

Referring to there is shown a portion b of the ACR system that may comprise the end user devices . . . and the fingerprint vendors . . . shown in . Also shown are application data servers an analytics module a rules engine a cloud based content delivery network CDN and a content management system CMS . In addition shows a user response module and third party partners advertisers .

The application data servers may comprise suitable logic circuitry code and or interfaces that may be operable to receive from a viewer device information related to an interactive event ID a network television station fingerprinted broadcast time CID and additional data and or a device type. The information may be provided by the viewer device in response to a match between a fingerprint taken by the device and a fingerprint taken by the corresponding RTFS. Once a match occurs and the viewer device obtains the appropriate information from its corresponding fingerprint vendor the viewer device may communicate the information to the application data servers which in turn returns the appropriate content that corresponds to the interactive event ID and related data in a callback. Content may be pushed to a second screen or device paired with a connected TV that is logged in to an appropriate application or Web page.

The content provided by the application data servers may comprise user interaction applications that may be executed by a portion of a synchronous event manager running on an end user device. In some instances more than one user interaction application may be sent to the same end user device from the application data servers and these multiple applications may be executed concurrently by the end user device.

The application data servers may be operable to send information to the analytics module as to what kind of interactions e.g. clicks selections options viewing behavior on a given broadcaster s network are taking place in a viewer device. The application data servers may be operable to handle the flow of user response data with third party partners and or advertisers . The user response data may comprise but need not be limited to TV IDs coupon IDs and event IDs for example. Communication of the user response data between the application data servers and the third party partners advertisers may be handled by the user response module for example. The application data servers may be operable to call the CMS for text banners graphics overlays and or video for example.

The application data servers may also be operable to deliver event schedules to end user devices to deliver correct content uniform resource locator URL based on the type of viewer device to integrate with a variety of back end systems to integrate with polling servers not shown to integrate with gaming services such as leader boards and or to integrate with customer databases such as those used in connection with store user preferences and social circle members for example. With respect to integrating with back end systems the application data servers may for example integrate with social networks for storage of tweets for later playback and or to filter comments and push back to applications.

The rules engine may comprise suitable logic circuitry code and or interfaces that may be operable to determine which platforms e.g. end user devices are to be served and when are those platforms to be served by the application data servers . The rules engine may be preconfigured and or dynamically configured.

The CMS may comprise suitable logic circuitry code and or interfaces that may be operable to store the content that is delivered to the end user devices. For example content that may be delivered may comprise text banners graphics overlays and video. The content may be provided as user interaction applications that may be handled by a synchronous event manager running in the end user device. Other examples of content may comprise polls and fun facts clips to share games and trivia and advertising content. These examples are provided by way of illustration and not of limitation. Accordingly other examples of contents that may be utilized for user interactive events with the end user devices may also be stored in the CMS .

The CMS may comprise suitable logic circuitry code and or interfaces that may be operable to enable communication between the application data servers and the CDN . The CMS is operable to post assets to the CDN . ACR based devices are operable to download the assets graphics banners overlays video etc from the CDN .

The analytics module may comprise suitable logic circuitry code and or interfaces that may be operable to receive user interaction information from the application data servers or directly from the viewing devices. The analytics module may be operable to communicate with the fingerprint vendors . . . to receive information and determine what is being watched in various viewer devices or end user devices. The analytics module may comprise one or more back end databases to store mange and or process user information.

In operation content may be provided by the application data servers to one of the end user devices . . . in response to receiving an interactive event ID a network television station device type and other data from that viewer device. A synchronous event manager in the end user devices may be utilized to request the content from the application data servers and to receive and or process the content to enable interactive opportunities for a user. Rules regarding which viewer device is to be served and when the device may be served may be determined by the rules engine . The content to be served by the application data servers to the viewer device may be stored in the CMS .

The analytics module may determine which viewers are interacting with content and what those viewers are watching based on information received from the application data servers or directly from the viewing devices. Viewer responses that result from interactive events may be handled by the user response module which in turn communicates with third party partners advertisers .

The third party partners advertisers may comprise and or be connected to advertisement servers and or one or more fulfillment systems. The advertisement servers may be utilized to deliver advertisement overlays to ACR based applications running on end user devices. The advertisement servers may also be operable to support the tracking of user impressions and click throughs and or to perform other advertising related functions.

The ACR system may communicate with one or more advertisement servers and or one or more fulfillment systems. The advertisement servers may be utilized to deliver advertisement overlays to ACR based applications running on end user devices. In this regard a synchronous event manager running on an end user device may be operable to handle information received from the advertisement servers. The advertisement servers may also be operable to support the tracking of user impressions and click throughs and or to perform other advertising related functions.

The fulfillment systems may utilize one or more technologies to fulfill viewer requests that occur in connection with ACR based applications and user interaction. Examples of such technologies may comprise but need not be limited to coupon delivery technologies technologies for movie ticket purchases and delivery and or short message service multimedia messaging service SMS MMS gateways.

At step the program s fingerprints may be loaded or stored into a fingerprint database. At step an interactive timeline and corresponding fingerprint content may be built. In this instance the offline fingerprint module may be utilized to generate an XML file for example which may comprise the interactive timeline information. At step the interactive timeline built in step may be loaded or stored into application servers such as the application data servers for example.

At step on screen graphics for different target end user devices e.g. end user devices end user devices . . . may be built. For example some of the end user devices may support Shock Wave Flash or Small Wave Format SWF files. This type of files may be utilized in multimedia and vector graphics and may comprise animations or applets with different levels of interactivity and function. In another example some of the end user devices may support Hyper Text Markup Language 5 HTML5 which is a language that allows the structuring and presentation of content in the World Wide Web. At step the content previously fingerprinted in step may be pushed to a content delivery network utilized by the network television station for distribution.

Referring to there is shown another portion of the flow chart after step . At step the viewer devices may receive the content from the content delivery network and may take fingerprints of the content. At step the viewer devices may send the fingerprints to a third party database for matching. The third party database may be part of the fingerprint match systems shown in or part of the fingerprint vendors . . . shown in for example.

At step when a match occurs the third party database may return to the end user devices a combination of a content identifier CID that may be representative of the program or network being watch an interactive event ID that may be representative of an interactive event that is being triggered a media time that may be representative of a time in the program corresponding to the interactive event and a network time that may be representative of a benchmark or reference network time such as a network time utilized by an NTP server e.g. NTP server NTP server to synchronize network operations. The benchmark or reference network time may be referred to as a network timestamp for example. The information returned to the end user devices may be monitored by a synchronous event manager running as a background process in those devices.

At step the synchronous event manager in the end user device may utilize the information received from the third party database to call application servers such as the application data servers . Depending on the type of end user device e.g. different manufacturers models the call made by the end user device may comprise different information. For example for a first device type the call to the application servers may comprise CID and device type information. In another example for a second device type the call to the application servers may comprise the interactive event ID and the device type.

At step the end user device may receive a reply from the application servers. The reply may comprise a content URL that is appropriate for the type of end user device. For example for a first type of viewer device the application servers may return the URL of the SWF while for a second type of viewer device the application servers may return the URL of an HTML5 page. The application servers may also return event timeline information to the various types of end user devices. The reply and or other information returned from the application servers may be handled by the synchronous event manger running on the end user device.

Referring to there is shown another portion of the flow chart after step . At step the application servers may call an advertisement server or ad server to target and track advertisement overlays. At step an end user device may call the content delivery network to receive the content URL. The content delivery network may return the URL for the content which may be a SWF or HTML page based on the type of viewer device. The call to the content delivery network to receive the content URL may be handled at least partially by the synchronous event manager running on the end user device.

At step the requests made by a user of the end user device may result in additional step or operations. For example a user may request a coupon or other type of reward in response to content displayed on the user s viewer device as a result of an interactive event. In this instance the end user device may call the application servers as part of the request. At step the application servers may send an acknowledgement or ACK to the end user device in response to the request. At step the application servers may call an MMS gateway or some other type of fulfillment mechanism to deliver the coupon or reward to the user. The delivery may be made to the end user device to another device to an electronic account e.g. email etc. or to another device account that the user identifies as a preferred place for receiving the coupon or reward.

The processor module may comprise suitable logic circuitry code and or interfaces that may be operable to perform the operations functions processes computations and the like described herein with respect to the end user devices and the end user devices . . . . In this regard the processor module may be operable to enable ACR fingerprinting and ACR related operations.

The processor module may be operable to run or execute a synchronous event manager as a background process for example to monitor events that occur internal to the end user device and or events from sources external to the end user device . The synchronous event manager may be executed continuously during those periods where monitoring is to take place. An example of events from external sources may include but need not be limited to an overlay event corresponding to an automatic content recognition match. Examples of internal events may include but need not be limited to a process an application and or a function corresponding to the automatic content recognition performed by the end user device . In various embodiments of the invention the synchronous event manager may be implemented in software firmware and or hardware. In some instances the synchronous event manager may be implemented as a state machine. For example the synchronous event manager may be implemented in a specialized processor or ASIC.

The processor module may comprise at least one processing device . The processing device may be a central processing unit CPU a digital signal processor DSP and or other type of integrated circuit that may be utilized to perform data processing operations. The processing device may utilize an operating system that enables the execution of the synchronous event manager.

The memory module may comprise suitable logic circuitry code and or interfaces that may be operable to store information utilized to enable ACR related applications. The network module may comprise suitable logic circuitry code and or interfaces that may be operable to allow the end user device to communicate with a fingerprint vendor and its corresponding RTFS and or with the applications data servers . The network module may be operable to support one or more communication protocols such as wireline protocols and or wireless protocols. The network module may be operable to receive information related to ACR fingerprinting matches and or interactive events.

The I O interface module may comprise suitable logic circuitry code and or interfaces that may be operable to enable a user of the end user device to interact with the device. In some instances the I O interface module may enable the interaction of a remote control and or a second screen e.g. tablet with the end user device .

The video display module may comprise suitable logic circuitry code and or interfaces that may be operable to process video content for reproduction for user consumption. The video display module may comprise a display that may comprise a screen such as a liquid crystal display LCD plasma display light emitting diode LED display for example for video reproduction. In some instances the display may comprise a touch screen that enables a user to interact with the end user device through the display .

The audio reproduction module may comprise suitable logic circuitry code and or interfaces that may be operable to process video content for reproduction for user consumption. In some instances the audio reproduction module may comprise speakers not shown for audio reproduction. The audio reproduction module may also be operable to communicate with an audio reproduction system external to the end user device .

In operation the synchronous event manager may execute or run as a software layer background process on the processor module . The synchronous event manager may monitor external events through for example the network module and or internal events through the processor module . In response to detected event triggers the synchronous event manager may request and receive applications such as user interaction applications which may be executed to produce interactive opportunities that may be presented to a user through the display for example.

The autonomous application layer module may comprise suitable logic circuitry interfaces and or code that may be operable to handle TV applications that are not necessarily synchronized to broadcast. For example the autonomous application layer module may operable to handle a TV widget or native app.

The co TV application layer ACR container app framework module may comprise suitable logic circuitry interfaces and or code that may be operable to handle application the framework container e.g. framework which may be invoked in response to ACR events.

The synchronous event manager may comprise suitable logic circuitry interfaces and or code that may be operable to listen for events passed from the content recognition ACR layer . The synchronous event manager may be operable to invoke the intended Co TV application framework module as defined by event parameters for a given event if there are available resources for example graphics plane and any operating system constraints are also satisfied. An exemplary operating system constrain may be that only a single app is allowed to be executed at a given time. Event parameters such as a callback number may be obtained via multiple requests to an ACR vendor control service.

The synchronous event manager may be operable to supply additional events to applications that have been invoked as necessary. These may or may not be acted upon by the invoked applications e.g. current timecode of onscreen content change in content ID etc . The synchronous event manager may also be operable to supply control information to invoked applications as necessary e.g. remaining time for an alert message etc . The synchronous event manager may be operable to teardown an application framework in response to ACR events comprising for example a change in underlying content expiration of defined duration of an event channel change user cancellation or other input.

The synchronous event manager may also be operable to provide dynamic management of ACR state comprising for example on network off network current network current program. The synchronous event manager may also be operable to modify ACR parameters based on for example query rate in response to the current state. This may aid in reducing the query volume from the TVs to capture service when the TVs are not on a designated network or program with ACR based interactivity. This may dramatically reduce the cost of providing ACR service.

The synchronous event manager may also be operable to dynamically determine freeze frame blackscreen fast forward pause rewind or other trick mode channel change modes and real time modification of ACR state. The synchronous event manager may be operable to handle these determinations directly or via the content recognition layer ACR . The synchronous event manager may be operable to receive from and communicate events to autonomous applications which are handled by the autonomous application layer module as requested for example TV widgets. For example if a NBA TV application is already active ACR events related to broadcast are passed to the application instead of invoking Co TV application framework module .

The advanced TV layer software SW abstraction layer module may comprise suitable logic circuitry interfaces and or code that may be operable to provide a software abstraction layer upon which TV widgets or apps may be built and or developed. The content recognition ACR layer module may provide access to TV primitives that is stateful to changes to input video and so on. In this regard the advanced TV layer software SW abstraction layer module may be operable to provide SDK functionality.

The content recognition ACR layer module may comprise suitable logic circuitry interfaces and or code that may be operable to provide ACR content recognition functionality to the upper layer modules namely the autonomous application layer module a co TV application layer ACR container app framework module .

The real time operating system RTOS module may comprise suitable logic circuitry interfaces and or code that may be operable to provide an execution environment for an embedded processor . The RTOS may be stored in a memory module such as the memory module which may comprise a ROM module or system on chip SoC and or other type of memory such as RAM and variants thereof. Executable RTOS code may read from the memory and executed by the embedded processor .

The synchronous event manager may comprise an environment framework or engine in which applications may be executed or launched to initiate interaction opportunities. The framework may be empty until an object or application is received for execution or launch. Once the application is no longer needed it may be removed or deleted from the framework .

In operation a user interaction application and data may be received from for example the application data servers shown in . The user interaction application and data may be received in response to a request that resulted from an event trigger being detected by the synchronous event manager . The user interaction application and data may be provided to the framework as an object or application to be executed or launched. In the example shown in the launch of the object may result in an overlay being displayed on the display .

As illustrated by the launching of an overlay on the display as a result of an interactive event taking place may occur without the user having to download or install the application related to the interactive opportunity that is presented to the user. Instead the call or request and the subsequent invocation or launching of the application may occur through the synchronous event manager and are transparent to the user.

Referring to an additional user interaction application and data may be provided to the framework as an object or application to be executed or launched. In the example shown in the launch of the object may result in an additional overlay being displayed on the display . The overlay and the overlay may be independent from each other or may interact with each other. When the overlays and interact with each other they may do so by interfacing through the framework for example.

As illustrated by the single framework in the synchronous event manager may support multiple objects or applications being launch concurrently. In such instances and when the applications interact with each other the framework may be utilized to provide an interface for the interaction. Although the term object is utilized herein the invention is not necessarily limited to object oriented programming. Accordingly any other type of programming or implementation may be utilized without departing from the scope of the various embodiments of the invention.

At step the synchronous event manager may detect from the events being monitored an event trigger and its associated data. At step the synchronous event manager may generate an alert message in response to the detection of the event trigger. At step based on the alert message a call may be made to an applications data server or to another device to receive a user interaction application or file. At step after the user interaction application or file is received by the end user device the synchronous event manager may generate an invocation message to launch or execute the application. At step the user interaction application may be launched from the synchronous event manager to initiate an interactive opportunity for a user.

In another embodiment of the invention a display device such as the end user devices or the end user devices . . . for example may be operable to perform automatic content recognition. The display device may be operable to execute a software layer e.g. synchronous event manager as a background process. The display device may comprise a television or mobile device that is operable to communicate with a data network e.g. Internet to receive the user interaction application.

The software layer may be executed on a processor such as the processor module for example. The software layer may comprise a single container e.g. framework from which to execute one or more user interaction applications. The software layer may be utilized to detect an event trigger where the event trigger may be produced in response to a match resulting from the automatic content recognition operation associated with the display device. The software layer may be operable to receive a user interaction application corresponding to the detected event trigger and to execute the received user interaction application from the single container. Moreover the software layer may be utilized to generate an alert message corresponding to the detection of the event trigger and an invocation message to execute the user interaction application from the single container.

In another aspect of this embodiment of the invention the software layer may monitor one or more events to detect the event trigger. The one or more events may comprise one or more events internal to the display device and or one or more events received by the display device from an external source e.g. fingerprint matching system fingerprint vendor . The events received by the display device from the external source may comprise for example an overlay event corresponding to an automatic content recognition match. The events internal to the display device may be based on one or more of a process application and function corresponding to the automatic content recognition performed by the display device.

In another aspect of this embodiment of the invention the software layer may generate an overlay e.g. overlays for reproduction on a screen e.g. display of the display device when executing the received user interaction application from the container.

In another aspect of this embodiment of the invention the software layer may support multiple user interaction applications. For example the software layer may be utilized to detect an additional event trigger may receive an additional user interaction application in response to the detected additional event trigger and may execute the received additional user interaction application from the container while the another received user interaction application is also being executed from the same container.

In another aspect of this embodiment of the invention the software layer may be utilized to determine whether user participation with the received user interaction application is enabled prior to executing the received user interaction application from the single container.

Another embodiment of the invention may provide a non transitory machine and or computer readable storage and or media having stored thereon a machine code and or a computer program having at least one code section executable by a machine and or a computer thereby causing the machine and or computer to perform the steps as described herein for a synchronous event manager for automatic content recognition.

Accordingly the present invention may be realized in hardware software or a combination of hardware and software. The present invention may be realized in a centralized fashion in at least one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software may be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention may also be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

While the present invention has been described with reference to certain embodiments it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted without departing from the scope of the present invention. In addition many modifications may be made to adapt a particular situation or material to the teachings of the present invention without departing from its scope. Therefore it is intended that the present invention not be limited to the particular embodiment disclosed but that the present invention will include all embodiments falling within the scope of the appended claims.

