---

title: Image motion blurring
abstract: The disclosed systems and methods make the motion of an object in an animation appear smooth by blending a number of subframes of visually adjusted images of the object for each frame of the animation. A request to animate an object along a motion path can be received by a graphics processing system of a device, where the motion path traverses at least a portion of a user interface presented on a display of the device. For each frame of the animation, the graphics processing system blends N subframes of visually adjusted images of the object to create a final blurred image which is rendered on the display. The graphics processing system can determine whether there is more processing time to perform additional blending of subframes prior to rendering a final frame for display, and then blending more subframes of images prior to rendering the final frame for display.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08749560&OS=08749560&RS=08749560
owner: Apple Inc.
number: 08749560
owner_city: Cupertino
owner_country: US
publication_date: 20120518
---
This application is a continuation of and claims priority to pending U.S. application Ser. No. 13 251 020 entitled Image Motion Blurring filed on Sep. 30 2011 which claims priority to pending U.S. Provisional Application Ser. No. 61 394 722 entitled Image Motion Blurring filed on Oct. 19 2010 the entire contents of each of which are incorporated herein by reference.

An object displayed in a graphical user interface can be animated. One common animation technique is to move the object along a motion path in the user interface. To create the appearance of motion a graphics processing system renders frames of the object at different positions along the motion path. If enough frames are rendered the object will appear to be in motion. The human eye however can perceive gaps between individual frames which can make the motion of the object appear choppy. More frames can be added to an animation to make the animation appear smoother. In many applications however there may be insufficient time or resources to render the additional frames.

The disclosed systems and methods make the motion of an object in an animation appear smooth by blending a number of subframes of visually adjusted images of the object for each frame of the animation. In some implementations a request to animate an object along a motion path is received by a graphics processing system of a device where the motion path traverses at least a portion of a user interface presented on a display of the device. Responsive to the request and for each frame of the animation the graphics processing system blends N subframes of visually adjusted images of the object to create a final blurred image which is rendered on the display. In some implementations the graphics processing system can determine whether there is more processing time to perform additional blending prior to rendering a frame and then blending more subframes of images prior to rendering the final frame for display.

This disclosure describes systems and methods for image motion blurring where subframes of visually adjusted images of an object are blended to produce a blurred image of the object which can be rendered as a frame in an animation. The use of blended subframes to produce a blurred image can reduce the choppy or strobe effect that may occur when using non blurred images. Image motion blurring can be used for a variety of animations including but not limited to moving objects e.g. icons files documents along motion paths on user interfaces and minimizing or maximizing user interface elements e.g. windows .

Image motion blurring can use any number of visually adjusted images to produce a final blurred image to be rendered on a display. Image motion blurring can be iteratively repeated for as long as time remains to prepare an image frame for rendering on a display. For example if some frame processing time remains before rendering the final frame of the blurred image additional blending can be performed to create a final blurred image which when included in the animation can result in the appearance of smoother object motion.

The animation is a sequence of blurred images produced by a graphics processing system. For each frame of the animation displayed at a point on the motion path multiple visually adjusted subframe images of the object can be blended to produce a final rendered blurred image which can be displayed at that point on the motion path . For instance the blurred image is rendered at time t the blurred image at time t the blurred image at time t the blurred image at time t and the blurred image at time T. The time T can be the total duration of the animation. In practice the amount of time available to render a frame of animation at a given point on the motion path can change from frame to frame and among different animations based on the computing resources available at the time of rendering. An advantage of the disclosed image motion blurring is that the number of subframe images blended is dynamically adjusted based on the amount of time available for rendering a blurred image frame.

Time tin the animation timeline represents the time that the animation starts or the time at which the animation is requested. For example a request to start an animation of a given object can be triggered at twhen the user interacts with the object in some manner e.g. closing the document . A graphics processing system can interpret the interaction as a request to perform an animation on the object. In general the graphics processing system can automatically determine when to use image motion blurring in an animation rather than a conventional animation using non blurred images. In some implementations the animation request can identify the starting and ending point e.g. pixel locations in two dimensions of a user interface or other display area where the animation is to occur. The animation request can also identify the shape of the motion path such as a straight line curved arc or any other desired motion path .

Each of the blurred images of the object represents a separate frame of the animation. Each of the blurred images can be generated by blending multiple subframes of visually adjusted images of the object. During the blending the graphics processing system can adjust one or more visual properties of the object image such as color opacity size shape rotation brightness etc. Each subframe used in the blending can contain an image that has different visual properties then images of other subframes. The adjusting of visual properties creates the blurring effect. For example one or more colors or the opacity of each subframe image can be reduced by a percentage from the original image properties before being blended with the other subframes. A greater number of subframes blended for each final rendered blurred image in the animation generally results in a smoother looking animation.

The number of subframes to be blended can vary for each blurred image . For example the blurred image is made up of four blended subframes. These subframe images can be blended over a frame duration tR. The final blurred image or blurred image is depicted as being made up of a single subframe or simply a non blurred image of the object. This can be the case for example if the object is stationary not moving during a portion of the animation such as the start or end of an animation where a non blurred image would be expected.

In some implementations the number of subframes that can be blended for any particular blurred image can depend on the frame duration tavailable for the graphics processing system to render a frame in the animation sequence. For example after the blurred image is rendered at time t but before the blurred imaged is rendered at time t the frame duration available to the processor can allow the blurred image to be blended from a composite of five subframes as shown . In some implementations after some initial blending occurs the graphics processing system can check the time available for preparing the frame e.g. by checking a system clock and then determine an additional number of subframes M that can be blended to generate the final blurred image

In some implementations the graphics processing system can make use of previous blending calculations to improve efficiencies of blending additional subframe images. For example if two subframe images are blended to generate final blurred image each subframe image can contribute 50 in color to the final blurred image to create the blurred effect. If a third subframe image is to be blended the graphics processing system can decide not to re blend the first two subframe images again. Rather the third subframe image can be blended with the current blend in the frame buffer and the color contributions of the three subframe images can be adjusted accordingly. For example if four subframe images are to be blended the graphics processing system can copy the original object image A at 100 to the frame buffer then blend a subframe image B 50 over the frame buffer then blend an subframe image C 33 over the frame buffer then blend an subframe image D 25 over the frame buffer and so on. Doing so can result in equal contributions from each subframe image to the final blurred image in the frame buffer without having to re blend previously blended subframe images.

Process can be invoked when a user interacts with an object on a user interface. Alternatively process can be invoked automatically by an application or operating system in response to a trigger event. In some implementations process begins when parameters are initialized for a particular blurred image to be rendered . Specifically the parameters can include 1 the time initially available to render the current frame of the animation e.g. T 16 milliseconds and 2 an initial number N e.g. N 2 of subframe images to blend for the current blurred image or the current frame of the animation at a given position along the motion path. As an example referring to the parameters listed here can be initialized for each of the blurred images of the animation. Depending on the processing resources available and the time of animation each of the blurred images can potentially get a new value for T e.g. T

A non blurred image of the object is obtained . For example when the graphics processing system receives a request for an animation e.g. to animate an object in motion across the user interface the graphics processing system can obtain an image of the object from a frame buffer or other repository. The frame buffer can contain the current state of the image that is waiting to be rendered at the next rendering event in the animation e.g. at a time t t etc. .

N subframe images are generated from the non blurred image . The N subframe images can be generated by adjusting one or more visual properties of the non blurred image of the object such that each subframe image contributes a percentage of a visual property e.g. color opacity to the resulting blurred image to be displayed. Alternatively a known blurring algorithm can be applied to the non blurred image to create a blurred image in the frame buffer that can be rendered for display without performing steps through .

N subframe images are blended in frame buffer . For example during the first pass through the process N can be 2 meaning two subframes images are blended. In subsequent iterations of the process additional sub frame can be blended in the frame buffer producing a blurred image in the frame buffer.

A determination is made whether time remains to perform more blending before rendering of the blurred image in the frame is to occur . For example each blending step can take time away from the original allotted time before rendering e.g. initially 16 milliseconds . The determination can predict how much time would be needed to perform another blending iteration and the predicted blending time can be compared to the remaining time before rendering. In some implementations the graphics processing system can factor in the current load on the computer system such as if other processes have recently started that are draining computer resources e.g. CPU time etc. . In other implementations the determination made in this step can be a simple one conservatively estimating that it takes x milliseconds worse case to perform an average blending iteration.

If adequate time remains to perform an additional blending the number of subframe images to be blended is incremented by M where M is a positive integer representing the number of additional subframe images to be blended. The number of subframe images to be blended is incremented in anticipation of repeating the step for the next blending iteration. The number of subframe images to be blended can also be used to determine the percentage contribution of one or more visual properties of each subframe image in the blend. For example if there are 4 subframe images then the percentage contribution of each subframe image is 25 .

If adequate time does not remain to perform an additional blending the blurred image in the frame buffer is displayed . For example the display can result in drawing one of the blurred images on the screen . If this is the first pass through the process for example the blurred image is displayed. Because indicates that the blurred image is blended from four subframe images the rendered image in the frame buffer is based on three iterations through the step above.

Once the blurred image is displayed the process can repeat for other blurred images in the animation. For example step of the process can reinitialize the parameters for process steps involving the blurred image . In this case because indicates that the blurred image is blended from two subframes images only one iteration of the step described above is performed as the determination in step is false or No e.g. no time remains to perform any additional subframe image blending for the blurred image .

The process can be repeated as needed over the duration of the animation over time T . For example as depicted in the animation includes five blurred images so the process in this example can occur five times once for each blurred image . Again in practice many more frames would be needed in the animation.

Within the system a motion blur engine can communicate with a rendering engine . The motion blur engine for example can create blurred images from two or more individual subframe images using process as described in reference to . The blurred images such as blurred images can then be rendered by the rendering engine . For instance the blurred images can provide the animation that the user sees on the user interface that shows a document object in motion across the user interface . In general the rendering engine can render any content on the user interface including blurred images as well as non blurred images text and other displayable components of the graphical user interface .

The system can include a frame buffer in communication with an animation engine . The frame buffer can contain at any given time the final blurred image to be displayed at the next frame rendering event. For example as described with reference to the process in the frame buffer can initially contain the non blurred image of the object then a blurred image blended from two subframes images then a blurred image blended from three subframes and so on. At any one time the blurred image in the frame buffer can be the most extensively blended image up to that time. The animation engine can use images over time that are available from the frame buffer to create animations such as the animation depicted in .

The animation engine can communicate with a timer counter which can initialize and maintain timers and the subframe counter e.g. N described above . More specifically as the animation engine performs repeated iterations of blending multiple sub frames images into a final blurred image for rendering the timer counter can keep track of the time used as well as the time remaining until the final blurred image is to be rendered. At the same time the timer counter can maintain a subframe counter. For example the timer counter can handle initializations of timer and subframe counter variables for the process as described above with reference to .

The graphics processing system can include and communicate with an operating system . For example the operating system can provide access to various operating system level services such as graphics functions kernel level commands and procedures device specific parameters e.g. screen size etc and so on.

Display device can be any known display technology including but not limited to display devices using Liquid Crystal Display LCD or Light Emitting Diode LED technology. Graphics processors can use any known graphics processor technology including but are not limited to NVIDIA GeForce processor technology. Input device can be any known input device technology including but not limited to a keyboard including a virtual keyboard mouse track ball and touch sensitive pad or display. Bus can be any known internal or external bus technology including but not limited to ISA EISA PCI PCI Express NuBus USB Serial ATA or FireWire. Computer readable medium can be any medium that participates in providing instructions to processors for execution including without limitation non volatile media e.g. optical disks magnetic disks flash drives etc. or volatile media e.g. SDRAM ROM etc. .

Computer readable medium can include various instructions for implementing an operating system e.g. Mac OS Windows Linux . The operating system can be multi user multiprocessing multitasking multithreading real time and the like. The operating system performs basic tasks including but not limited to recognizing input from input device sending output to display device keeping track of files and directories on computer readable medium controlling peripheral devices e.g. disk drives printers etc. which can be controlled directly or through an I O controller and managing traffic on bus . Network communications instructions can establish and maintain network connections e.g. software for implementing communication protocols such as TCP IP HTTP Ethernet etc. .

A graphics processing system can include various instructions that provide graphics capabilities. For example the graphics processing system can support animations and image motion blurring as described with reference to . Moreover the graphics processing system can facilitate the process described with reference to . In some implementations the graphics processing system can provide the functionality for the graphics processing system described with reference to .

The graphics processing system includes a motion blur engine in communication with an animation engine . The motion blur engine can produce blurred images used by the animation engine such as to create animations. The animations can be rendered frame by frame or in any other way by a rendering engine . A frame buffer can contain any image such as a blurred image that can be rendered as part of the animation or any non blurred image used for any other reason. A timer counter included in the graphics processing system can maintain counters e.g. the number of subframe images used in a given blend etc. and timers e.g. how much time is remaining before rendering a blurred image is to occur .

The disclosed and other embodiments and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. The disclosed and other embodiments can be implemented as one or more computer program products e.g. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device or a combination of one or more them. An apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user the disclosed embodiments can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

The disclosed embodiments can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of what is disclosed here or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN e.g. the Internet.

While this specification contains many specifics these should not be construed as limitations on the scope of what being claims or of what may be claimed but rather as descriptions of features specific to particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understand as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

Particular embodiments of the subject matter described in this specification have been described. Other embodiments are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example the processes depicted in the accompanying figures do not necessarily require the particular order shown or sequential order to achieve desirable results. In certain implementations multitasking and parallel processing may be advantageous.

