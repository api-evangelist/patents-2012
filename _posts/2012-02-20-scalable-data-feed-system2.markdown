---

title: Scalable data feed system
abstract: A scalable data feed system is disclosed. The data feed system may be offered as a cloud service that can serve many enterprises or tenants that require data to be pulled from information sources such as FTP, POP3, databases, line of business systems, a topic subscription, or an RSS feed, and pushed the data to information sinks, such as SMTP, email, FTP, mobile phones, and other devices and services. A pull agent pumps data from pull sources and pushes the data out to push agent counterparts. The push agent transforms and sends the data in messages to push sink, such as FTP, SMTP, or a mobile device. Both the pull agent and the push agent services are implemented as replicated services over a structured overlay network for high availability that can serve multiple requests to pump out data from multiple pull sources and push the data to multiple information sinks.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09596127&OS=09596127&RS=09596127
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09596127
owner_city: Redmond
owner_country: US
publication_date: 20120220
---
Developers often design applications that are loosely coupled to each other instead of being tightly linked. This configuration is advantageous and beneficial but introduces the problem of how to gather and distribute information that spans the application. This problem may be further compounded if the line between the applications and the enterprise or consumer is not well defined. Information or data is often required to be collected from many sources or endpoints and distributed to many destinations or sinks. For example an enterprise application may push data to a social media platform or to mobile devices. The data may come from an information source such as an RSS feed or a Topic Pub Sub.

Traditionally the problem of distributing data is solved by developing a one off or custom solution that pumps data between specific information sources and sinks. Generally the data pump has to poll information sources which may use a lot of compute resources and thereby requires a dedicated machine to poll the information sources. This configuration causes additional problems because pull sources may or may not have data available at all times. This causes spikes in the compute requirements when data is available and wasted resources when the pump is simply polling to see if data exists. In some configurations this is addressed by providing a notification or activation message when data becomes available. These notification mechanisms may be built into information pull sources such as queues.

Historically data feed systems were limited because the data pump must be close to either the pull source or the push sink and is generally built stand alone or purpose built application that is not capable of future connectivity or integration with other systems. Polling from the pull sources can require a lot of compute resources that could be put to better use. Additionally getting data from a pull source to a push sink invariably requires some kind of transformation of the data that is generally hand coded.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

In one embodiment a scalable data feed system is offered as a cloud service serving many enterprises or tenants that require data to be pulled from various information sources such as FTP servers POP3 services databases line of business systems etc. and pushed to information sinks such as SMTP or email services FTP servers mobile phones databases and other devices.

Embodiments of the system include but are not limited to the following aspects and features. Pull agents and their counterpart push agents accommodate efficient pumping of data. The pull agents and push agents are scalable and are configured on top of a structured overlay network. The pull and push agent services may be independently scaled. The generic design and implementation of the pull agent allows it to pull from any passive data source. The generic design and implementation of the push agent allows it to push data to any information sink. The data may be transformed as it is sent between the pull agent and the push agent or by the pull agent or the push agent.

Pull agent service comprises a collection of pull endpoint hosting services that pull data from pull sources . Pull endpoint hosting services are replicas or instances that partition work among themselves which allows the pull agent service to scale as necessary. The pull sources may be external pull sites such as an FTP or mail server or internal sources such as a topic subscription or database for example. Pull sources are partitioned among the replicas . The replicas are responsible for their assigned set of sources . The replicas are on top of a structured overlay network to provide high availability.

Push agent service comprises a collection of push endpoint hosting services that receive data from pull endpoint hosting services and push the data to information sinks . Push endpoint hosting services are replicas that partition work among themselves to allow for scaling of the push agent service . The replicas partition work by partitioning the information sinks where each replica sinks data. The replicas are on top of a structured overlay network to provide high availability.

Both pull agent service and push agent service may be partitioned for scale. Additionally if one of the pull endpoint hosting service or push endpoint hosting service fails or is otherwise unavailable one of the other replicas will take over the failed replica s workload.

To simplify the diagram only one pull source and one information sink are shown however it will be understood that additional pull sources not shown are associated with each pull endpoint hosting service and that additional information sinks are associated with each push endpoint hosting service . As illustrated in the pull and push networks in scalable data feed service may have a symmetrical design but may differ in their scale characteristics in one embodiment. The data feed service is highly scalable by partitioning of work among the pull endpoint hosting services and the push endpoint hosting services and by controlling how the pull agent service schedules and pulls data stream from pull sources and delivers the data to push agent service .

Push agent service can be further partitioned into a push rendering system that renders data in a form suitable for information sink and a push distribution system that is specific to each information sink . The push rendering systems and push distribution systems may be distributed and scaled independently or they may be implemented together in the push endpoint hosting service .

Pull hosting service schedules a pull job from information source and gets data which may be read as a stream from pull source . Pull endpoint hosting service downloads the data stream either in parallel or sequentially based on the configuration of the pull endpoint. In one embodiment the pulled data is then converted to an internal SOAP based protocol and pushed out to the push agent service .

Before pushing data an address resolution is performed based on the address of information sink to ensure that data is sent to the correct push endpoint hosting service that is responsible for the information sink . Structured overlay network may maintain a table or database to assist in identify how the push endopoint hosting services are partitioned among the information sinks .

Data may be transformed to meet the specific protocol needs of the information sink . This protocol is published by the push agent service . For every new information sink push agent service defines a SOAP based protocol with appropriate SOAP headers and interpretation and creates a new runtime push endpoint hosting service replica for that protocol. Based on the transformation desired by the user the pull endpoint hosting service may transform the downloaded stream into a protocol required by push agent service . In other embodiments a pipeline component may perform transformations between the pull agent and the push agent. For example the pull agent may perform some basic transforms and a dedicated pipeline component between the pull agent and the push agent performs more elaborate transformations. The push endpoint hosting service receives the incoming message and translates the data to the protocol or format specific to the information sink .

The pull agent service has a gateway that provides an external user interface. The pull agent gateway may provide a Representational State Transfer REST interface in one embodiment. The gateway receives configuration information identifying new information sources and requests to pull data from the information sources . Users enter requests such as GET PUT and DELETE requests at pull agent gateway which is the only means for users to operate on the endpoints to perform actions such as get create update or delete operations.

A pull agent management provider is responsible for either servicing the requests coming from gateway such as GET requests or forwarding the requests such as PUT and DELETE requests as a message to the appropriate pull endpoint hosting service . Pull agent management provider may assign a pull endpoint hosting service responsibility for a particular pull source . The pull endpoint hosting service stores the endpoint configuration to a database such as a SQL database. Pull agent management provider reads endpoint configuration information from database directly when it receives a request for the pull source to identify which pull endpoint hosting service is responsible for that source .

The pull endpoint hosting service is responsible to poll the pull source which may be a poll to an external FTP server for example and then download data from the pull source . Once the contents are downloaded from the pull source the pull endpoint hosting service creates a message such as an HTTP or SOAP message using the data and passes the message on to a push agent gateway . The push agent gateway address may be provided as part of the pull endpoint configuration information stored to database .

The pull agent service is a scheduler that schedules many pull sources which represent information sources from which data is pulled. The pull agent is configured with a collection of pull sources that are partitioned among the pull endpoint hosting services . Each pull endpoint hosting service is responsible for pulling data from a set of specific information sources . This may be configured by hashing on the pull information source configuration. For example in the case of an FTP server the FTP server name server port and user name may be used by the pull endpoint hosting service to connect to the FTP service. In the case of another pull source or information source the hashing function uses a different set of inputs. The hashing logic may take co location into account to optimize resource usage on the information source . The pull agent service may also check for critical errors such as authentication failure during poll and may shut down the poll if critical errors are found or if too many non critical errors occur in a given poll or during a given time interval.

The structured overlay network underneath the pull agent service helps in providing high levels of scalability and availability. Each pull endpoint hosting service is a stateful service and the structured overlay network notifies if there is a change in the network. For example if there are one hundred pull sources to pull data from and there are four pull endpoint hosting services on the structured overlay network then each pull endpoint hosting service pulls data from approximately twenty five pull sources . One or more machines or servers are used to host the pull endpoint hosting services . A state change in the network occurs for example if one of the hosting machines fails or if a new pull endpoint hosting service is added to handle the pull agent workload. The structured overlay network notifies each of the pull endpoint hosting service of the change in how the pull sources are partitioned. The pull endpoint hosting services query the database which stores the configuration data for all of the pull endpoints and how they are allocated to partitions. Each pull endpoint hosting service fetches the set of pull sources that it is responsible for scheduling and schedules jobs to pull data from the information sources .

In one embodiment a pull endpoint or information has two parts an implementation specific to the technology of the pull endpoint choice such as FTP or a topic subscription and a representation of the pull endpoint configuration such as an address.

Once work items are found and gathered the pull agent begins downloading the data streams from the information sources in step such as downloading files from an external FTP server. Based on the concurrency count the downloading may be done in parallel. The contents of the data streams are queued in work item stream queue . When the data streams are downloaded an HTTP or SOAP message is created based on the pull endpoint configuration to push the data out to a push agent service in step . The SOAP messages are queued in work item post processing queue . Another thread will pick up these messages and will post them to the push agent service. The post processing queue will have an acknowledgement status for each data stream that was posted to a push agent service. Upon acknowledgment from the push agent service that the data has been pushed out successfully the data may be deleted from the information source in step . Alternatively in the case of a mail source the data may be marked as read. This allows the data pump to support ALO At Least Once semantics on pull push.

Once a pull endpoint has exhausted all of the work items it reschedules the next poll. Rescheduling may be based on internal monitoring of errors and thresholds for example. The following algorithm may be used for rescheduling in one embodiment 

The push agent service has a gateway that provides an interface for endpoint request messages . The push agent gateway may provide a REST interface in one embodiment. The gateway receives configuration information identifying new information sinks and requests to push data to the information sink .

A push agent management provider is responsible for either servicing the requests coming from gateway or forwarding the requests as a message to the appropriate push endpoint hosting service . Push agent management provider may assign a push endpoint hosting service responsibilities for a particular information sink . The push endpoint hosting service stores the information sink configuration to a database which may be the same database as used in the pull agent service. Push agent management provider reads endpoint configuration information from database directly when it receives a request for the information sink to identify which push endpoint hosting service is responsible for that information sink .

The push agent service is a reactive service that is triggered when a pull service sends a message to be transmitted. Push endpoints represent information sinks to which data is pushed. The push agent is configured with a collection of information sinks that are partitioned among the push endpoint hosting services . Each push endpoint hosting service is responsible for pushing data to a set of specific information sinks . This may be configured by hashing on the push information source configuration. For example in the case of an FTP server the FTP server name server port and user name may be used by the push endpoint hosting service to connect to the FTP service. In the case of another information sink the hashing function uses a different set of inputs. The hashing logic may take co location into account to optimize resource usage and to preventing denial of service attack detection on the information sink . The push agent service may also check for critical errors such as authentication failure and send an error message back to the pull agent or may shut down the poll if critical errors are found.

The structured overlay network underneath the push agent service helps in providing high levels of scalability and availability. Each push endpoint hosting service is a stateful service and the structured overlay network notifies if there is a change in the network. For example if there are one hundred information sinks to push data to and there are four push endpoint hosting services on the structured overlay network then each push endpoint hosting service pushes data to approximately twenty five information sinks . One or more machines or servers are used to host the push endpoint hosting services . A state change in the network occurs for example if one of the hosting machines fails or if a new push endpoint hosting service is added to handle the push agent workload. The structured overlay network notifies each of the push endpoint hosting service of the change in how the information sinks are partitioned. The push endpoint hosting services query the database which stores the configuration data for all of the information sinks and how they are allocated to partitions. Each push endpoint hosting service fetches the set of information sinks that it is responsible for scheduling and schedules jobs to push data to the information sinks .

In one embodiment a push endpoint or information has two parts an implementation specific to the technology of the information sink choice such as FTP or a mobile device and a representation of the information sink configuration such as an address.

Upon receipt of a message the push agent service retrieves the external sink address and the endpoint configuration for that endpoint from database . An in memory cache may be implemented to optimize on the configuration lookups. A handler for the transport is obtained based a configuration sub class and the message is dispatched to that handler. The handler uses the appropriate protocol library to send the message over that transport.

Embodiments of the data pump disclosed and described herein may be implemented using for example a general purpose computing device. Components of such a device may include but are not limited to various hardware components such as a processing unit data storage such as a system memory and a system bus that couples various system components including the data storage to the processing unit. The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

The computing device may typically include a variety of computer readable media such as any available media that can be accessed by the computer and includes both volatile and nonvolatile media and removable and non removable media but excludes propagated signals. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can accessed by the computer. Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above may also be included within the scope of computer readable media. Computer readable media may be embodied as a computer program product such as software stored on computer storage media.

The data storage or system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM. RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by a processing unit. By way of example and not limitation data storage holds an operating system application programs and other program modules and program data.

Data storage may also include other removable non removable volatile nonvolatile computer storage media. By way of example only data storage may be a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The drives and their associated computer storage media provide storage of computer readable instructions data structures program modules and other data for the computer.

A user may enter commands and information through a user interface or other input devices such as a tablet electronic digitizer a microphone keyboard and or pointing device commonly referred to as mouse trackball or touch pad. Other input devices may include a joystick game pad satellite dish scanner or the like. Additionally voice inputs gesture inputs using hands or fingers or other natural user interface NUI may also be used with the appropriate input devices such as a microphone camera tablet touch pad glove or other sensor. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device may be also connected to the system bus via an interface such as a video interface. The monitor may also be integrated with a touch screen panel or the like. Note that the monitor and or touch screen panel can be physically coupled to a housing in which the computing device is incorporated such as in a tablet type personal computer. In addition computers such as the computing device may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface or the like.

The computer may operate in a networked or cloud computing environment using logical connections to one or more remote devices such as a remote computer. The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer. The logical connections may include one or more local area networks LAN and one or more wide area networks WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a networked or cloud computing environment the computer may be connected to a public or private network through a network interface or adapter. Additionally the service might be hosted in a data center in multiple locations around the world for spatial efficiency and resilience. In some embodiments a modem or other means for establishing communications over the network. The modem which may be internal or external may be connected to the system bus via the network interface or other appropriate mechanism. A wireless networking component such as comprising an interface and antenna may be coupled through a suitable device such as an access point or peer computer to a network. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. It may be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

