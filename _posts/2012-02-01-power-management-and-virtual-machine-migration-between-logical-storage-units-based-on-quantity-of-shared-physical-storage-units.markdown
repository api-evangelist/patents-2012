---

title: Power management and virtual machine migration between logical storage units based on quantity of shared physical storage units
abstract: In a shared storage system for supporting virtual machines, virtual machine images are opportunistically migrated between logical storage units to free up physical storage units and achieve better storage hardware resource utilization and reduced power consumption by powering down freed-up physical storage units. The destination for the opportunistic migration of a virtual machine is selected based on the extent to which the physical storage units are shared between the logical storage unit in which the virtual image is currently stored and the destination. In situations where the demand for storage hardware resources increases, the powered-down physical storage units may be opportunistically powered up to meet the increased demand.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09047087&OS=09047087&RS=09047087
owner: VMware, Inc.
number: 09047087
owner_city: Palo Alto
owner_country: US
publication_date: 20120201
---
A virtual machine VM is an abstraction a virtualization of an actual physical computer system. The VM also known as the guest is installed on a host computer platform which includes system hardware and one or more virtualization layers. Each VM is configured with its own operating system that runs on top of virtual system hardware as emulated by the virtualization layers. One of the emulated system hardware devices is a virtual disk. In typical implementations the VM s virtual disk is encapsulated as a file or a set of files that are stored on a storage device accessible by the host. The storage device can be local to the host or as is common in large scale implementations such as data centers it can be a shared storage device accessed over a network such as a storage area network SAN device or a network attached storage NAS device.

The size of a VM s virtual disk can be quite large and in data centers where many thousands or even millions of VMs may be provisioned the costs associated with storing each VM image comprising a VM s virtual disk and other files of the VM e.g. configuration files can be very high. Although in recent years storage costs per gigabyte have decreased significantly this has not translated to cost savings for the data centers because the consumption of storage capacity has far outpaced the declining per gigabyte cost. Furthermore the day to day cost of operating storage devices in data centers is significant because most of the storage capacity is provided by disk arrays which are known to be power hungry devices.

One or more embodiments of the invention provide techniques to manage power consumption in a storage system having physical storage units by opportunistically powering them down or up. In one embodiment the storage system is a shared storage system that supports VMs and includes physical storage units e.g. rotating disks and logical storage units mapped to one or more of the physical storage units in which VM images are stored.

A method of managing power consumption in a storage system having physical storage units and logical storage units mapped to one or more of the physical storage units according to an embodiment of the invention includes the steps of identifying a first logical storage unit in which a VM image is stored and a second logical storage unit based on the extent to which the physical storage units are shared between the first and second logical storage units migrating the VM image from the first logical storage unit to the second logical storage unit and powering down at least one of physical storage units to which the first logical unit is mapped. The method may also include the step of opportunistically powering up powered down physical storage units in situations where the utilization level of powered up physical storage units increases beyond a threshold value e.g. 80 utilization.

A non transitory computer readable storage medium according to an embodiment of the invention includes instructions that are to be executed on a controller of a storage system that supports VMs and includes physical storage units and logical storage units mapped to one or more of the physical storage units to cause the controller to carry out the method set forth above.

A system according to an embodiment of the invention includes a plurality of computers in which VMs are executed a storage system that supports the VMs the storage system including physical storage units and logical storage units mapped to one or more of the physical storage units and a virtual machine management unit that is programmed to direct migrations of VM images between logical storage units based on correlation data that indicates the extent to which the physical storage units are shared between the logical storage units. According to further embodiments the storage system includes a controller that is programmed to opportunistically power down or power up physical storage units and the virtual machine management unit is further programmed to select for migration a VM image based on a utilization level of the logical storage unit in which the VM image is stored and select a logical storage unit as a migration destination for the VM image based on a utilization level of the logical storage unit.

Storage system is shared among host systems and stores VM images i.e. virtual disks and other files of the VMs executing in host systems . Storage system may be a disk array or a group of disk arrays accessible over a network such as a SAN and includes physical data storage units DSUs also referred to herein as spindles that are exposed as a set of logical units LUNs two of which are illustrated in as LUN and LUN . Storage system further includes a management interface that exposes a set of application programming interfaces APIs for managing storage system from another device such as management server including APIs that allow the other device to retrieve usage information of LUNs and DSUs and DSU mapping correlations between LUNs as well as APIs that allow the other device to issue commands to power on or power off DSUs . In one embodiment these APIs are included in a set of APIs known as VASA VMware Aware Storage APIs .

Management server manages VMs executing in host systems and storage resources allocated to the VMs. The management software running in management server includes user interface by which an administrator can power ON and power OFF VMs and provision new VMs. During VM provisioning the administrator allocates hardware resources including storage resources to the VM. Management server can obtain information about the storage resources provided by storage system and issue commands thereto by invoking the APIs exposed by management interface of storage system .

The management software running in management server also includes a distributed power management DPM module . DPM module examines utilization levels of LUNs such as storage capacity and input output IO throughput and correlation data that indicate the extent to which the LUNs exposed by storage system share spindles to identify one or more LUNs that can be freed up through migration of VM images between LUNs. If any of DSUs become idle as a result of the VM image migrations such DSUs may be powered down. In the embodiment illustrated in VM image for a VM running in host system is migrated from LUN to LUN . The migration is carried out using the technique described in U.S. patent application Ser. No. 12 184 134 filed Jul. 31 2008 and entitled Online Virtual Machine Disk Migration the entire contents of which are incorporated by reference herein.

Each virtual machine implements a virtual hardware platform that supports the installation of a guest operating system OS which is capable of executing applications . Examples of a guest OS include any of the well known commodity operating systems such as Microsoft Windows Linux and the like. In each instance guest OS includes a native file system layer not shown for example either an NTFS or an ext3FS type file system layer. These file system layers interface with virtual hardware platforms to access from the perspective of guest OS a data storage HBA which in reality is virtual HBA implemented by virtual hardware platform that provides the appearance of disk storage support in reality virtual disks e.g. virtual disk A X . In certain embodiments virtual disks A X may appear to support from the perspective of guest OS the SCSI standard for connecting to the virtual machine or any other appropriate hardware connection interface standard known to those with ordinary skill in the art including IDE ATA SATA and ATAPI. Although from the perspective of guest OS file system calls initiated by such guest OS to implement file system related data transfer and control operations appear to be routed to virtual disks A X for final execution in reality such calls are processed and passed through virtual HBA to adjunct virtual machine monitors VMM that implement the virtual system support needed to coordinate operation with hypervisor . In particular HBA emulator functionally enables the data transfer and control operations to be correctly handled by hypervisor which ultimately passes such operations through its various layers to HBA that connect to storage system .

Input output operations IOs from VMMs are received by a SCSI virtualization layer which converts them into file IOs understood by a virtual machine file system VMFS driver . VMFS driver then converts the file IOs into block IOs and provides the block IOs to logical volume manager . Logical volume manager is typically implemented as an intermediate layer between the driver and file system layers and supports volume oriented virtualization and management of the LUNs accessible through RBA . Logical volume manager issues raw SCSI commands to device access layer based on the LUN block IOs. Data access layer includes a device access layer which discovers storage system and applies command queuing and scheduling policies to the raw SCSI commands and a device driver which understands the input output interface of RBA interfacing with storage system and sends the raw SCSI commands from device access layer to RBA to be forwarded to storage system .

It should be recognized that the various terms layers and categorizations used to describe the components in may be referred to differently without departing from their functionality or the spirit or scope of the invention. For example VMM may be considered separate virtualization components between VM and hypervisor which in such a conception may itself be considered a virtualization kernel component since there exists a separate VMM for each instantiated VM. Alternatively each VMM may be considered to be a component of its corresponding virtual machine since such VMM includes the hardware emulation components for the virtual machine. In such an alternative conception for example the conceptual layer described as virtual hardware platform may be merged with and into VMM such that virtual host bus adapter is removed from i.e. since its functionality is effectuated by host bus adapter emulator .

Although the inventive concepts disclosed herein have been described with reference to specific implementations many other variations are possible. For example the inventive techniques and systems described herein may be used in both a hosted and a non hosted virtualized computer system regardless of the degree of virtualization and in which the virtual machine s have any number of physical and or logical virtualized processors. In addition the invention may also be implemented directly in a computer s primary operating system both where the operating system is designed to support virtual machines and where it is not. Moreover the invention may even be implemented wholly or partially in hardware for example in processor architectures intended to provide hardware support for virtual machines. Further the inventive system may be implemented with the substitution of different data structures and data types and resource reservation technologies other than the SCSI protocol. Also numerous programming techniques utilizing various data structures and memory configurations may be utilized to achieve the results of the inventive system described herein. For example the tables record structures and objects may all be implemented in different configurations redundant distributed etc. while still achieving the same results.

Method begins at step where storage controller retrieves usage information of a DSU. If it determines at step that the DSU is idle the DSU is powered down at step . On the other hand if it determines at step that the DSU is not idle another DSU is selected if available as determined at step and subject to the same analysis. When no more DSUs are available as determined at step method ends. It should be recognized that storage controller may be programmed to detect a DSU as being idle and power it down if it detects a certain threshold lack of activity thereat. In one embodiment the threshold lack of activity is no IO activity over a predetermined time period e.g. 15 minutes.

Method begins at step where storage controller periodically monitors usage levels of all DSUs. If it determines at step that the utilization level of all the DSUs is not above a threshold e.g. not greater than 80 method returns to step . On the other hand if the utilization level of all the DSUs is greater than the threshold step is carried out. At step storage controller powers up one or more DSUs associated with an idle LUN. Then at step storage controller notifies connected host systems of the availability of a new LUN so that the connected host systems can begin directing new workloads or migrating existing workloads to the new LUN. After such notification method returns to step .

In an alternative embodiment storage system may be provided with a user interface that displays the usage information of DSUs . An administrator of storage system may then issue commands through the user interface to power down or power up DSUs based on the displayed usage information. In another embodiment storage controller executes one or more programs for achieving power savings and these programs are exposed to connected host systems through one or more APIs.

Advantageously one or more embodiments of the invention opportunistically migrate VM images to cause spindles to become idle and placed into a reduced power consumption mode thereby reducing power consumption in storage systems. In one example where VMs cause 15 storage arrays to each be used at 10 storage space or IO capacity consolidating the usage of storage space and IO onto 5 storage arrays and placing the remaining 10 storage arrays on standby would save 66 power. Further by using dynamic storage power management to place spindles on standby where appropriate the useful life of storage system hardware may be increased.

The various embodiments described herein may be practiced with other computer system configurations including hand held devices microprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like.

With the above embodiments in mind it should be understood that the invention can employ various computer implemented operations involving data stored in computer systems. These operations are those requiring physical manipulation of physical quantities. Any of the operations described herein that form part of the invention are useful machine operations. The invention also relates to a device or an apparatus for performing these operations. In one embodiment the apparatus can be specially constructed for the required purpose e.g. a special purpose machine or the apparatus can be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines can be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The embodiments of the present invention can also be defined as a machine that transforms data from one state to another state. The transformed data can be saved to storage and then manipulated by a processor. The processor thus transforms the data from one thing to another. Still further the methods can be processed by one or more machines or processors that can be connected over a network. The machines can also be virtualized to provide physical access to storage and processing power to one or more users servers or clients. Thus the virtualized system should be considered a machine that can operate as one or more general purpose machines or be configured as a special purpose machine. Each machine or virtual representation of a machine can transform data from one state or thing to another and can also process data save data to storage display the result or communicate the result to another machine.

The invention can also be embodied as computer readable code on a computer readable medium. The computer readable medium is any data storage device that can store data which can thereafter be read by a computer system. Examples of the computer readable medium include hard drives network attached storage NAS read only memory random access memory CD ROMs CD Rs CD RWs magnetic tapes and other optical and non optical data storage devices. The computer readable medium can include computer readable tangible medium distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.

Although the method operations were described in a specific order it should be understood that other housekeeping operations may be performed in between operations or operations may be adjusted so that they occur at slightly different times or may be distributed in a system which allows the occurrence of the processing operations at various intervals associated with the processing as long as the processing of the overlay operations are performed in the desired way.

Although the foregoing invention has been described in some detail for purposes of clarity of understanding it will be apparent that certain changes and modifications can be practiced within the scope of the appended claims. Accordingly the present embodiments are to be considered as illustrative and not restrictive and the invention is not to be limited to the details given herein but may be modified within the scope and equivalents of the appended claims.

The embodiments of the present invention described above are exemplary. Many changes and modifications may be made to the disclosure recited above while remaining within the scope of the invention. Therefore the scope of the invention should not be limited by the above description but instead should be determined with reference to the appended claims along with their full scope of equivalents. Additionally embodiments of the present invention may be implemented in software firmware or as an abstract of a physical computer system known in the art as a virtual machine or a combination of software firmware and a virtual machine. With respect to implementing embodiments of the present invention as a virtual machine expression of such embodiments may be either as virtual system hardware guest system software of the virtual machine or a combination thereof. The scope of the invention should therefore be limited not to the above description but instead should be determined with reference to the appended claims along with their full scope of equivalents.

