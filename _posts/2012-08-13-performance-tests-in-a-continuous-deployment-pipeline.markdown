---

title: Performance tests in a continuous deployment pipeline
abstract: A method to perform performance tests on an application in a continuous deployment pipeline is provided herein. The method identifies code changes are two distinct builds in a performance test environment. The method obtains a baseline test result by executing a set of customized test scripts on a baseline build with a first code base. The method similarly tests the new build by executing the set of customized test scripts on the new build with a second code base to obtain a new test result. Performance values are determined by comparing the baseline test result and the new test result.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09183123&OS=09183123&RS=09183123
owner: Hewlett-Packard Development Company, L.P.
number: 09183123
owner_city: Houston
owner_country: US
publication_date: 20120813
---
Software development life cycles use continuous integration CI and continuous deployment CD to reduce the time code changes spend in a production line. Continuous integration automates the process of receiving code changes from a specific source configuration management SCM tool constructing deliverable assemblies with the code changes and testing the assemblies.

In the following detailed description reference is made to the accompanying drawings which form a part hereof and in which is illustrated by way of specific examples in which the present disclosure may be practiced. It is to be understood that other examples may be utilized and structural or logical changes may be made without departing from the scope of the present disclosure.

Continuous integration CI and continuous deployment CD automate the construction testing and deployment of code assemblies with a code change. Continuous integration automates the process of retrieving code changes from the SCM tool constructing deliverable assemblies such as executing a build and unit testing the assemblies. The automation begins after a code change is committed to a source configuration management SCM tool. When the code change is committed to the SCM tool the code change is assigned to a particular continuous deployment pipeline CD pipeline or deployment pipeline . The code change moves through the continuous deployment pipeline as the code change is tested as part of a code base or an assembly of code.

Continuous deployment extends continuous integration by automatically deploying the assemblies into a test environment and executing testing on the assemblies. The amount of testing is determined by the continuous deployment pipeline. The tests used for the continuous deployment pipelines are typically static tests assigned based on the classification of the continuous deployment pipeline such as low priority or high priority. Typical tests include unit tests and application programming interface tests. Load and performance tests are rarely included in the tests due to cost and time constraints since the execution time of performance and load tests are longer than unit tests and application programming interface tests. As a result the tests lack a quality guarantee since the test sets do not include tests that measure performance of the code changes under testing conditions.

In examples a method to perform performance tests on an application in a continuous deployment pipeline is provided. The method performs performance tests on an application in a continuous deployment pipeline. The method identifies code changes between a baseline build and a new build. The baseline build and the new build are two distinct builds in a performance test environment. The method obtains a baseline test result by executing a set of customized test scripts on the baseline build. The baseline build includes the first code base that successfully completed the set of performance tests in the continuous deployment pipeline. The method similarly tests the new build by executing the set of customized test scripts on the new build to obtain a new test result. The new build includes the second code base that is being tested in the continuous deployment pipeline. Performance values are determined by comparing the baseline test result and the new test result. The performance values are based on test results that focus on the changes between the baseline build and the new build which enable easier identification of performance problems.

The phrase code change refers to a change in the source code for any software application. The phrase code change may also refer to a code change that is part of a code base constructed as part of a continuous integration process. Examples of code changes include changes or updates to a method function line of code and or a call to a method or function such as deletion or addition of a method and or function.

The phrase continuous deployment pipeline or deployment pipeline refers to a set of actions executed serially and or in parallel on a queue of code changes. For example the continuous deployment pipeline may include building the code executing unit tests deploying the code running automated tests staging the code running end to end tests and deploying the code to production. Each continuous deployment pipeline may be classified to receive code changes that match a defined set of criteria for example a specific continuous deployment pipeline may be used for low risk and high priority code changes. The test scripts used to test the pipeline may be based on the code changes.

The phrase test script refers to the tests run on a continuous deployment pipeline in a simulated environment. The test script tests performance and or identifies deficiencies in the performance of the application under test AUT . The test script tests various aspects of application performance with code changes integrated into the build.

The phrase baseline build refers to a build of a code base that includes accumulated code changes that have been tested and result in successful execution or completion of testing for performance and or load. For example the baseline build includes a first set of code changes which are identified as previous code changes that have been cumulated and incorporated into a code base or first code base. The first code base may include code changes from a previous testing period such as a previous day s work.

The phrase new build refers to a build of a code base that includes the baseline build i.e. the accumulated code changes that have been test and result in successful execution or completion of testing for performance and or load in addition to any changes to the baseline build such as additions deletions and modifications of the code base since the baseline build was tested. For example the new build includes a second set of code changes. The second set of code changes include changes to the code base or first code base since the previous testing period such as changes since the previous day s testing.

The phrase baseline test result refers to results from the execution of the test scripts on the baseline build.

The phrase new test result refers to results from the execution of the test scripts on the new build.

The phrase performance value refers to analysis and collection of test results from the execution of test scripts. The performance value may include analysis of a baseline test result and a new test result individually and in aggregate.

The client device represents a computing device and or a combination of computing devices configured to interact with the test device and the deployment device via the link . The interaction may include sending and or transmitting data on behalf of a user such as the code change. The interaction may also include receiving data such as a software application with the code changes. The client device may be for example a personal computing device which includes software that enables the user to create and or edit code for a software application. The client device may further include a user s computing device that runs the application for the user.

The test device represents a computing device and or a combination of computing devices configured to perform performance tests on an application in a continuous deployment pipeline. The test device is also configured to execute a set of test scripts on the continuous deployment pipeline in an application under test environment to integrate the code changes for use in a software application.

The data store represents generally any memory configured to store data that can be accessed by the test device and the deployment device in the performance of its function. The test device functionalities may be accomplished via the link that connects the test device to the deployment device the client device and the data store .

The link represents generally one or more of a cable wireless fiber optic or remote connections via a telecommunication link an infrared link a radio frequency link or any other connectors or systems that provide electronic communication. The link may include at least in part an intranet the Internet or a combination of both. The link may also include intermediate proxies routers switches load balancers and the like.

For example the test engine obtains a baseline test result by executing a set of customized test scripts on a baseline build in a performance test environment. The baseline build including a first code base that successfully completed the set of performance tests in the continuous deployment pipeline. The test engine also executes the set of customized test scripts on a new build in a performance test environment to obtain a new test result. The new build including a second code base being tested in the continuous deployment pipeline.

The decision engine identifies code changes between the baseline build and the new build. The new build and the baseline build are two distinct builds in a performance test environment. The decision engine then determines a performance value by comparing the baseline test result and the new test result.

The set of instructions identify code changes between a baseline build and a new build. The baseline build and the new build are two distinct builds in a performance test environment. The code changes may be monitored to determine and periodically build a new code base. The monitoring may include instrumentation of the code to include lines of code for monitoring performance and or load. The monitoring may also include measurement of performance and or load of specific line s of code changed over a predefined period such between daily builds.

The set of instructions obtain a baseline test result by executing a set of customized test scripts on a baseline build in a performance test environment. The baseline build includes the first code base that the set of performance tests were successfully completed in the continuous deployment pipeline. The baseline build may be obtained from a data store such as a build repository that stores daily builds.

The set of instructions also execute the set of customized test scripts on a new build in a performance test environment to obtain a new test result. The new build includes the second code base being tested in the continuous deployment pipeline. The set of customized test scripts may be serially or simultaneously executed on the baseline build and the new build. The set of instructions may further generate a load on a client device and or server using the set of customized test scripts and or additional testing conditions.

The set of instructions determine a performance value by comparing the baseline test result and the new test result. The determination of the performance value may include analyzing the baseline test result and the new test result for at least one of a performance trend and a performance problem. The determination of the performance value may also include correlating the performance value to a specific portion of the second code base such as a line of code and or a function. The performance value may be provided as a performance report via email and or published via communication channels. The performance value may also be stored in a data store such as a test result repository that stores the daily test results and stores the data for current and previous test results therein.

The data store may store data accessible by the test device and or the deployment device . The data store is for example a database that stores at least one of the following a first code base a second code base a baseline build a new build a set of customized test scripts a baseline test result a new test result a performance value such as daily test results and an instruction such as an instruction to be performed by a processor .

The test device performs the set of performance tests on an application in a continuous deployment pipeline. The test device is connected to the deployment device which receives the first and second code bases from the client device illustrated in . The test device is illustrated as including a test engine and a decision engine .

The test engine represents generally a combination of hardware and or programming to obtain a baseline test result by executing a set of customized test scripts on a baseline build in a performance test environment. The baseline build includes a first code base that successfully completed the set of performance tests in the continuous deployment pipeline. The test engine also executes the set of customized test scripts on a new build in a performance test environment to obtain a new test result . The new build includes a second code base being tested in the continuous deployment pipeline. The test engine may receive an instruction and or the set of customized test scripts from the decision engine and or the data store .

The decision engine represents generally a combination of hardware and or programming to identify code changes between the first code base and the second code base . The first code base and the second code base are two distinct builds in a performance test environment. For example the decision engine or a separate monitor engine may monitor a set of code changes and build a new code base based on the set of code changes received during the monitoring. The monitoring may include instrumentation of the code to include lines of code that monitor performance and or load. The monitoring may also include measurement of performance of specific line s of code changed over a predefined period such as monitoring performance and or load of code changes on a daily basis.

The decision engine then determines a performance value by comparing the baseline test result and the new test result . The performance value that includes measuring and analyzing results for each of the baseline build and the new build . The performance value includes at least one of a system performance value corresponding to performance of a client device a server code change performance value corresponding to performance of at least one of the first code base and the second code base on a server device and a client code change performance value corresponding to performance of at least one of the first code base and the second code base on a client device. The decision engine and or a separate analysis engine may analyze the performance values . For example at least one of the following analyses may be performed analyze the baseline test result and the new test result for at least one of a performance trend and a performance problem correlate the performance value to a specific code change line of code and or function and generate a performance report to identify the performance values for diagnosis history and or reporting purposes.

The deployment device includes a deployment engine . The deployment engine represents generally a combination of hardware and or programming that deploys a code base after the code base successfully completes a set of tests in a test environment. The deployment device deploys the code base via a deployment engine . The deployment engine may work together with the test engine and the decision engine to execute the set of customized test scripts . Moreover the deployment engine controls a continuous deployment pipeline after the code base passes the set of customized test scripts .

The memory is illustrated to include an operating system and applications . The operating system represents a collection of programs that when executed by the processor serve as a platform on which applications may run. Examples of operating systems include various versions of Microsoft s Windows and Linux . Applications represent program instructions that when executed by the processor function as an application that perform a set of performance tests on an application in a continuous deployment pipeline. For example illustrates a test module and a decision module as executable program instructions stored in memory of the test device .

Referring back to the test engine and the decision engine of the test device are described as combinations of hardware and or programming. As illustrated in the hardware portions may include the processor . The programming portions may include the operating system applications and or combinations thereof. For example the test module represents program instructions that when executed by a processor cause the implementation of the of the test engine of . The decision module represents program instructions that when executed by a processor cause the implementation of the of the decision engine of . Similarly the functions of the analysis engine and the monitor engine may be performed by the test module and or the decision module or by additional module s not shown .

The programming of the test module and decision module may be processor executable instructions stored on a memory that includes a tangible memory media and the hardware may include a processor to execute the instructions e.g. instruction . The memory may store program instructions that when executed by the processor cause the processor to perform the program instructions. The memory may be integrated in the same device as the processor or it may be separate but accessible to that device and processor .

In some examples the program instructions may be part of an installation package that can be executed by the processor to perform a method using the system . The memory may be a portable medium such as a CD DVD or flash drive or a memory maintained by a server from which the installation package can be downloaded and installed. In some examples the program instructions may be part of an application or applications already installed on the server. In further examples the memory may include integrated memory such as a hard drive.

Block illustrates the performance test environment. In the performance test environment the previous build or baseline build is deployed in block and the current build or new build is deployed in block . The baseline build is the last good build before the accumulated changes are deployed. The baseline build is typically stored after successfully completed the set of performance tests i.e. successful completion of the previous execution of the load and performance testing in the continuous deployment pipeline. For example the baseline build may include changes from the previous day if the performance test is run on a daily basis. The new build includes accumulated changes over a defined period such as daily. The baseline build and the new build may be deployed simultaneously using separate test devices run on the same performance test environment conditions and or in series. The performance test environment may need to be re provisioned between the tests when run in series.

In the performance test environment the baseline build and the new build each undergo load and performance testing individually using for example the same customized test scripts on each build to enable accurate comparisons therebetween. The load and performance tests include instrumentation of the code in block to add code that monitors performance and load. The instrumentation occurs at this point if the instrumentation did not occur prior to this step. The customized test scripts are executed in block . The customized test scripts include code to add load and or stress to the system under test. The load and or stress may be added using for example a load generator. The customized test scripts also measure performance in block . The measurement of performance includes performance from the client device and or the server. The customized test scripts also monitor performance of the code base or application on the client device and the server in block . The customized test scripts then save the performance values for each of the builds in block .

The performance values of blocks and for the baseline build and the new build are compared and analyzed. The performance testing and results therefrom focus on changes between the code bases i.e. the first code base and the second code base and the customized test scripts are customized based on the changes to the code and performance and or load tests needed to test the changes to the code. For example the customized test scripts will test function calls in the code base that are added removed and or modified between the baseline build and the new build . The analysis may be automatic and include performance trends and performance problems. Specific performance problems can be correlated to a specific portion of a code change and automatically assigned to a person and or a team such as a code change committer.

The performance values are then reported in block . The reporting may include distribution via push channels such as email and or publish channels such as a continuous delivery dashboard. Depending on the performance values the new build with the second code base is deployed to production in block . For example the new build is only deployed after the performance value includes that the performance testing was successful.

A baseline test result is obtained in block . The baseline build includes the first code base that successfully completed the set of performance tests in the continuous deployment pipeline. The baseline test result may be obtained in a test engine by executing a set of customized test scripts on the baseline build in a performance test environment. The baseline build may be stored in a build repository that stores daily builds and or a history of builds. The daily builds may be accessible thereafter to use for comparison in performance tests.

In block the set of customized test scripts are executed a new build in a performance test environment to obtain a new test result. The new build is tested with the test engine. The new build includes the second code base being tested in the continuous deployment pipeline. The set of customized test scripts may be executed on the baseline build and the new build serially or simultaneously. A performance test environment in the continuous deployment pipeline is deployed to execute the set of customized test scripts. The performance test environment and or the set of customized test scripts may generate a load on a client device and or server. The set of customized test scripts test the code changes based on the code change received instead of an entire assembly of code for an application.

A performance value is determined in block by comparing the baseline test result and the new test result. A decision engine may determine the performance value based on the baseline test result and the new test result. For example the performance value comprises at least one of a system performance value corresponding to performance of a client device a server code change performance value corresponding to performance of at least one of the first code base and the second code base on a server device and a client code change performance value corresponding to performance of at least one of the first code base and the second code base on a client device.

The performance values may be analyzed and or used for a variety of purposes. For example the determination of the performance value may further include analysis of the baseline test result and the new test result for at least one of a performance trend and a performance problem. The performance value may also be correlated to a specific portion of the second code base. The performance value and any associated data and analysis may also be provided as a performance report that is distributed via for example email or published via for example communication channels. The performance values and any associated data and analysis may be stored in for example a test result repository such as a data store that stores the daily test results.

Examples can be realized in any computer readable media for use by or in connection with an instruction execution system such as a computer processor based system or an ASIC Application Specific Integrated Circuit or other system that can fetch or obtain the logic from computer readable media and execute the instructions contained therein. Computer readable media can be any media that can contain store or maintain programs and data for use by or in connection with the instruction execution system. Computer readable media can comprise any one of many physical media such as for example electronic magnetic optical electromagnetic or semiconductor media. More specific examples of suitable computer readable media include but are not limited to a portable magnetic computer diskette such as floppy diskettes or hard drives a random access memory RAM a read only memory ROM an erasable programmable read only memory or a portable compact disc.

Although the flow diagram of illustrates specific orders of execution the order of execution may differ from that which is illustrated. For example the order of execution of the blocks may be scrambled relative to the order shown. Also the blocks shown in succession may be executed concurrently or with partial concurrence. All such variations are within the scope of the present invention.

The present disclosure has been described using non limiting detailed descriptions of examples thereof and is not intended to limit the scope of the present disclosure. It should be understood that features and or operations described with respect to one example may be used with other examples and that not all examples of the present disclosure have all of the features and or operations illustrated in a particular figure or described with respect to one of the examples. Variations of examples described will occur to persons of the art. Furthermore the terms comprise include have and their conjugates shall mean when used in the present disclosure and or claims including but not necessarily limited to. 

It is noted that some of the above described examples may include structure acts or details of structures and acts that may not be essential to the present disclosure and are intended to be exemplary. Structure and acts described herein are replaceable by equivalents which perform the same function even if the structure or acts are different as known in the art. Therefore the scope of the present disclosure is limited only by the elements and limitations as used in the claims.

