---

title: Reproducing apparatus, reproducing method, reproducing program, and recording medium
abstract: For a content-prerecorded large capacity disc-shaped recording medium, a user interface having high flexibility is accomplished. Button image data, corresponding sound data as an effect sound, and control commands for the sound data and image data are multiplexed with a stream and recorded on the disc. A scenario reproduced from the disc is stored in a buffer. The image data and sound data are stored in a buffer. Image data is read from the buffer in accordance with a scenario and expanded to a graphics plane. In addition, corresponding sound data is read from the buffer and reproduced by a sound player. When a button image is varied in accordance with a state change of the button, an effect sound is reproduced. As a result, a more effective user interface is accomplished.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08606080&OS=08606080&RS=08606080
owner: Sony Corporation
number: 08606080
owner_city: Tokyo
owner_country: JP
publication_date: 20120113
---
This application is a continuation application of and claims the benefit of priority under 35 U.S.C. 120 from U.S. application Ser. No. 10 498 823 filed Jun. 23 2004 now U.S. Pat. No. 8 150 237 herein incorporated by reference which is a National Stage Application of International Application No. PCT JP03 14511 filed Nov. 14 2003 which claims the benefit of priority under 35 U.S.C. 119 from Japanese Patent Application Nos. 2002 346133 filed Nov. 28 2002 2003 022551 filed Jan. 30 2003 and 2003 074441 filed Mar. 18 2003.

The present invention relates to a reproducing apparatus a reproducing method a reproducing program and a recording medium that allow a user to interactively operate a program recorded on a large capacity recording medium such as a blu ray disc.

In recent years as a standard for a recordable disc type recording medium that is detachable from a recording and reproducing apparatus a blu ray disc standard has been proposed. The blu ray disc standard prescribes a disc that has a recording medium having a diameter of 12 cm and a cover layer having a thickness of 0.1 mm. The blu ray disc standard uses a bluish purple laser having a wavelength of 405 nm and an objective lens having a numerical aperture of 0.85. The blu ray disc standard accomplishes a recording capacity of 27 GB Giga bytes maximum. As a result a program of a BS digital high vision broadcast available in Japan can be recorded for two hours or longer without deterioration of picture quality.

As sources supply sources of AV Audio Video signals recorded on the recordable optical disc an analog signal of for example a conventional analog television broadcast and a digital signal of for example a digital television broadcast such as a BS digital broadcast will be used. The blu ray disc standard has established a method for recording AV signals of such broadcasts.

As a derivative standard of the current blu ray disc standard a reproduction only recording medium on which a movie music or the like is prerecorded is being developed. As a disc shaped recording medium on which a movie or music is prerecorded DVD Digital Versatile Disc has been widely used. The reproduction only optical disc in accordance with the blu ray disc standard is largely different from and superior to the conventional DVD in a large recording capacity and a high speed transfer speed that allow a high vision picture to be recoded for two hours or longer in high quality.

The current blu ray disc standard prescribes neither a method for displaying a list of video contents of a disc on a screen nor a user interface function for allowing a user to move a cursor on the list and select a video content that he or she wants to reproduce from the list. These functions are accomplished by a recording and reproducing apparatus main unit that records and reproduces video contents to and from the blu ray disc. Thus even if a video content is reproduced from the same recording medium the layout of the contents list screen depends on the recording and reproducing apparatus for use and so does the user interface. Thus the user cannot easily use the blu ray disc. Thus it is necessary to allow the reproduction only disc to display a menu screen and so forth that the disc contents producer has designed not depend on the reproducing apparatus.

A multiple story function of which a selection screen is displayed while a video content is being reproduced is generally called an interactive function. To accomplish the interactive function it is necessary for the disc producer to create a scenario that he or she has designated a reproduction order and branches of the video content describe the scenario using a program language a script language or the like and record the described scenario on a disc. The reproducing apparatus side reads and executes the scenario. As a result the reproducing apparatus reproduces a video content and displays selection screens that allow the user to select branches of the video content that the producer has designated.

The current blu ray disc standard blu ray disc rewritable format ver 1.0 prescribes neither a method for composing a menu screen and a branch selection screen that a contents producer has designated nor a method for describing a process for a user input. Currently it is difficult to reproduce a video content from a blu ray disc in accordance with a scenario that the producer has designated with compatibility irrespective of manufactures and models of reproducing apparatuses.

For a reproduction only disc the producer side desires a multiple angle function for allowing a user to select one of angles of an object photographed by a plurality of cameras so that the user can watch the object at his or her favorite angle. Thus it is necessary to provide such a function.

For a reproduction only disc a function for displaying subtitles is essential. However the current blu ray disc standard does not prescribe the function for describing subtitles.

The foregoing interactive function has been already accomplished in for example the DVD Digital Versatile Disc standard. In the DVD video while a moving picture is being reproduced a menu screen is called using for example a remote control commander. By selecting a button displayed on a menu screen the user can perform a process for changing the current scene that is being reproduced. The DVD standard also prescribes a function for displaying subtitles. That function allows the user to switch Japanese subtitles to English subtitles or vice versa that have been prepared. In addition the DVD video also has a multiple angle function.

In the case of the DVD a menu screen is composed of a fixed sub picture. When the menu screen is called it is displayed in such a manner that the sub picture is combined with a moving picture. Japanese Patent Laid Open Publication No. HEI 10 308924 describes a structure for combining sub picture data with moving picture data and recording the combined data on a recordable DVD.

Next an example of a menu screen according to the related art reference will be described in brief. Before a movie main part is reproduced from a DVD by a reproducing apparatus a menu screen is displayed. Generally a plurality of buttons are disposed on the menu screen. Each button is assigned a predetermined operation. When the user selects a button and causes the operation of the selected button to be executed the operation assigned to the selected button is executed. When the user selects a button movie main part and causes the operation of the selected button to be executed the operation assigned to the button is executed. As a result the movie main part is reproduced from the DVD.

The user operates keys direction keys assigned to up down left and right directions with the remote control commander hereinafter referred to as remote controller so as to select one button displayed on the menu screen. Thereafter with an OK key the user causes the operation assigned to the selected button to be executed. Each button has three states that are a normal state non selection state a selection state and an execution state. To allow the user to easily distinguish them they have different images and colors. Generally there is only one button that is placed in the selection state or the execution state.

In the DVD video each button is displayed with two types of data called sub picture and highlight. shows an example of a DVD menu screen according to a related art reference. The menu screen is referred to as title menu . The menu screen has three buttons A B and C that represent move main part play bonus picture and sound setting respectively. In the example shown in the color of an outer frame of the movie main part play button A has been changed from the original color. That describes that the movie main part play button A has been placed in the selection state.

In such a state when the user operates the direction keys on the remote controller for example as shown in and he or she can causes another button to be placed in the selection state. Like the case shown in the color of the outer frame of the button that has been selected is different from the colors of the outer frames of the other buttons that have not been selected non selected buttons . In the state shown in when the user operates an OK button disposed on the remote controller as shown in the color of the movie main part play button A is changed to a color that represents the execution state. Thereafter the menu screen is cleared and the movie main part is reproduced. The foregoing is a basic operation of buttons of the DVD video.

The menu screen as shown in is composed of three types of data that are a background picture a sub picture and a highlight . The background picture is a still picture a moving picture of a content main part prerecorded on the DVD or the like.

As shown in the sub picture has one bit map picture four color information A B C and D and coordinates X Y . The bit map picture is represented with information of two bits per pixel. The coordinates X Y represent the display start position of the sub picture . Each of the color information A B C and D is one color information data composed of one set of R Red G Green and B Blue data. Each of colors R G and B has information of eight bits. The bit map picture has information of two bits per pixel. With two bits one is selected from the foregoing four color information A B C D for each pixel. Color information also has transparency data. The sub picture may have a region in which the background picture is transparent. The display position of the upper left corner of the sub picture is represented with coordinates X Y relative to the background picture .

The sub picture may have information that represents a display start time and a display end time and commands that cause visual effects such as fade in and fade out to be applied to the sub picture .

In the DVD video a plurality of bit map pictures cannot be displayed at the same time. Thus the menu screen on which the plurality of buttons as shown in are placed is displayed with one large bit map picture that has three button images as shown in . In the bit map picture of the sub picture shown in when a region outside the buttons A B and C is designated as a transparent region and the sub picture is combined with the background picture the background picture becomes transparent outside the display regions of the buttons A B and C.

The highlight is information used to change four colors used for the sub picture to other four colors. As shown in as color information the highlight has color information A B C D of a selection state and color information A B C D of an execution state. These color information is four color information represented with RGB of eight bits each like the foregoing sub picture .

The highlight has a set of coordinates of regions in which colors are changed. The range of which colors are changed is not limited to all the sub picture but a part of the sub picture as a square region. The number of square regions in the sub picture of which colors are changed by the highlight corresponds to the number of buttons that the user can select. The display position of each square region is represented by coordinates X Y of the positions of the upper left corner and the lower left corner thereof. For example the position of the highlight A corresponding to the button A is represented by coordinates X Y and X Y . That applies to the highlights B and C corresponding to the buttons B and C respectively.

For example in the highlight A color information A B C D of a region represented by coordinates X Y and X Y of the background picture is changed to color information A B C D designated as a color of a selection state. At that point the color information A of the background picture is changed to color information A of the highlight A. Likewise the color information B of the background picture is changed to the color information B. The color information C is changed to the color information C. The color information D is changed to the color information D.

Next an example of a color change of the highlight will be described corresponding to a change of a state of the button A on the menu screen described with reference to and . It is assumed that when the button A is in the non selection state the frame front surface and characters of the button A are displayed with the color information B the color information C and the color information D respectively. When the button A is placed in the selection state the frame color B of the button A is changed to the color information B corresponding to the selection state of the highlight A. At that point the front surface color C and the character color D are not changed. Thereafter when the button A is placed in the execution state the front surface color C of the button A which is the color of the selection state is changed to the color information C. At that point the frame color B and the character color D which are the colors of the selection state are not changed.

When a picture of the DVD video is normally reproduced a picture corresponding to the background picture is displayed. When a movie that has subtitles is reproduced the background picture of which the movie main part is reproduced and the sub picture of which the subtitles are displayed are combined and displayed.

However the sub picture the highlight that represents the selection state and the highlight that represents the execution state can use only up to four colors each. Thus as a problem of the related art a sub picture having many colors cannot be displayed.

Since the highlight only changes the color of the sub picture characters of a button cannot be changed in the selection state and the execution state. In addition an effect of which the shape of a button is changed cannot be accomplished. Thus the related art cannot accomplish an enriched user interface.

Since subtitles and buttons are displayed using the same mechanism using the sub picture the subtitles and the buttons cannot be independently controlled and displayed. In addition a combining process for setting and combining transparencies of the subtitles and buttons and displaying the combined picture cannot be performed.

When the menu screen is called moving picture data reproduced in the background thereof is stopped. Thus even if such an interactive function were accomplished the flexibility of the user interface that accomplishes the function would be low.

Since a mechanism for generating an effect sound in synchronization with subtitles displayed and changed has not been prescribed in the standard an effect sound cannot be generated in synchronization with subtitles as a problem of the related art.

Since the standard does not prescribe a mechanism for generating effect sounds for buttons such as an effect sound that is generated when the user places a button in the selection state and a click sound that is generated when the user operates an OK key in the selection state of a button. Thus it is difficult to accomplish an enriched user interface as a problem of the related art.

When a user interface having high flexibility is accomplished it is largely affected by the drawing speed and update speed of buttons and the responsiveness to an input of the user. Thus a graphic decoder model that estimates them is required.

In the foregoing the effect sound is not sound data that is reproduced in synchronization with a moving picture or a still picture displayed on the moving picture plane for example sound that is recoded as a pair of a movie picture but audio data reproduced in synchronization with a display control of subtitles and buttons.

An object of the present invention is to provide a reproducing apparatus a reproducing method a reproducing program and a recording medium that allow a user interface with high flexibility for a large capacity reproduction only optical disc to be accomplished.

Another object of the present invention is to provide a reproducing apparatus a reproducing method a reproducing program and a recording medium that allow an enriched user interface for a large capacity reproduction only optical disc to be accomplished.

To solve the foregoing problem a first aspect of the present invention is a reproducing apparatus for reproducing contents data comprising inputting means for inputting a non real time stream and a real time stream the non real time stream containing at least a program code and image data composing an operation screen that prompts a user to perform an operation the real time stream containing at least moving picture data and subtitle data code storing means for storing the program code that is input by the inputting means image data storing means for storing the image data that is input by the inputting means first combining means for combining decoded moving picture data of which the moving picture data that is input by the inputting means is decoded and decoded subtitle data of which the subtitle data that is input by the inputting means is decoded and second combining means for combining the decoded image data stored in the image data storing means and the combined data of the moving picture and the subtitle data combined by the first combining means in accordance with the program code stored in the code storing means.

A second aspect of the present invention is a reproducing method for reproducing contents data comprising the steps of inputting a non real time stream and a real time stream the non real time stream containing at least a program code and image data composing an operation screen that prompts a user to perform an operation the real time stream containing at least moving picture data and subtitle data storing the program code that is input at the inputting step to code storing means storing the image data that is input at the inputting step to image data storing means combining decoded moving picture data of which the moving picture data that is input at the inputting step is decoded and decoded subtitle data of which the subtitle data that is input at the inputting step is decoded and combining the decoded image data stored in the image data storing means and the combined data of the moving picture and the subtitle data combined at the first combining step in accordance with the program code stored in the code storing means.

A third aspect of the present invention is a reproducing program for causing a computer device to execute a reproducing method for reproducing contents data the reproducing method comprising the steps of inputting a non real time stream and a real time stream the non real time stream containing at least a program code and image data composing an operation screen that prompts a user to perform an operation the real time stream containing at least moving picture data and subtitle data storing the program code that is input at the inputting step to code storing means storing the image data that is input at the inputting step to image data storing means combining decoded moving picture data of which the moving picture data that is input at the inputting step is decoded and decoded subtitle data of which the subtitle data that is input at the inputting step is decoded and combining the decoded image data stored in the image data storing means and the combined data of the moving picture and the subtitle data combined at the first combining step in accordance with the program code stored in the code storing means.

A fourth aspect of the present invention is a recording medium on which a reproducing program for causing a computer device to execute a reproducing method for reproducing contents data has been recorded the reproducing method comprising the steps of inputting a non real time stream and a real time stream the non real time stream containing at least a program code and image data composing an operation screen that prompts a user to perform an operation the real time stream containing at least moving picture data and subtitle data storing the program code that is input at the inputting step to code storing means storing the image data that is input at the inputting step to image data storing means combining decoded moving picture data of which the moving picture data that is input at the inputting step is decoded and decoded subtitle data of which the subtitle data that is input at the inputting step is decoded and combining the decoded image data stored in the image data storing means and the combined data of the moving picture and the subtitle data combined at the first combining step in accordance with the program code stored in the code storing means.

A fifth aspect of the present invention is a disc shaped recording medium on which contents data has been recorded wherein a non real time stream and a real time stream are recorded on the recording medium the non real time stream containing at least a program code and image data composing an operation screen that prompts a user to perform an operation the real time stream containing at least moving picture data and subtitle data and wherein decoded image data of which the image data that has been reproduced and stored in image data storing means is decoded and combined data of which moving picture data that has been reproduced and decoded and subtitle data that has been reproduced and decoded are combined are combined in accordance with the program code.

As described above according to the first second third and fourth aspects of the present invention a non real time stream and a real time stream are input. The non real time stream contains at least a program code and image data that composes an operation screen that prompts a user to perform an operation. The real time stream contains at least moving picture data and subtitle data. The program code and the image data that are input are stored in code storing means and image data storing means. Decoded moving picture data of which the moving picture data that is input is decoded and decoded subtitle data of which the subtitle data that is input is decoded are combined as combined data of the moving picture data and the subtitle data. The decoded image data stored in the image data storing means and the combined data of the moving picture data and the subtitle data are combined in accordance with the program code stored in the code storing means. Thus when moving picture data is reproduced an operation screen using the same image data can be easily displayed at different timings.

According to the fifth aspect of the present invention a non real time stream and a real time stream are recorded on a recording medium. The non real time stream contains at least a program code and image data that composes an operation screen that prompts a user to perform an operation. The real time stream contains at least moving picture data and subtitle data. Decoded image data of which the image data that has been reproduced and stored in image data storing means is decoded and combined data of which moving picture data that has been reproduced and decoded and subtitle data that has been reproduced and decoded are combined are combined in accordance with the program code. Thus when moving picture data is reproduced an operation screen using the same image data can be easily displayed at different timings.

Next an embodiment of the present invention will be described. According to an embodiment of the present invention based on the blu ray disc standard blu ray disc rewritable format ver 1.0 which is a standard for recording and reproducing data functions necessary for a reproduction only disc such as an interactive function and a multiple angle function are accomplished.

First of all for easy understanding of the present invention a management structure as prescribed in Blu ray Disc Rewritable Format Ver 1.0 part 3 Audio Visual Specification for contents namely AV Audio Video data prerecorded on a blu ray disc will be described. In the following description the management structure is referred to as BDAV format.

A bit stream that has been encoded in accordance with an encoding system such as MPEG Moving Pictures Experts Group video or MPEG audio and multiplexed in accordance with MPEG 2 system is referred to as clip AV stream or simply AV stream . The clip AV stream is recorded as a file on a disc by a file system defined in Blu ray Disc Rewritable Format Ver 1.0 part 2 for a blu ray disc. This file is referred to as clip AV stream file or simply AV stream .

A clip AV stream file is a management unit on the file system. Thus it cannot be said that a clip AV stream file is a management unit that the user can easily understand. From a view point of user s convenience it is necessary to record information necessary for combining a video content that has been divided into a plurality of clip AV stream files and reproducing the combined video content information necessary for reproducing only a part of a clip AV stream file information necessary for smoothly performing a special reproduction and a search reproduction and so forth as a database. Blu ray Disc Rewritable Format Ver. 1.0 part 3 as a standard for a blu ray disc prescribes such a database.

The simplest structure of a play list is composed of one AV stream file after recording of a content is started until the recording is stopped. Unless the AV stream file is edited it becomes one play list

A play list is composed of information that represents an AV stream file to be reproduced and sets of reproduction start points and reproduction stop points that designate reproduction start positions and reproduction stop positions of the AV stream file. A pair of information of a reproduction start point and information of a reproduction stop point is referred to as play item PlayItem . A play list is composed of a set of play items. When a play item is reproduced a part of the AV stream file referred from the play item is reproduced.

As described above a clip AV stream is a bit stream of which video data and audio data have been multiplexed in the format of an MPEG2 TS Transport Stream . Information about the clip AV stream is recorded as clip information to a file.

A set of a clip AV stream file and a clip information file that has corresponding clip information is treated as one object and referred to as clip. A clip is one object that is composed of a clip AV stream and clip information.

A file is generally treated as a sequence of bytes. A content of a clip AV stream file is expanded on the time base. An entry point in a clip is regularly designated on the time base. When a time stamp of an access point to a predetermined clip is given a clip information file can be used to find information of an address from which data is read in a clip AV stream file.

As shown in the same clip can be referenced from a plurality of play lists. In the example shown in a clip is referenced from two play lists and . In the horizontal direction of the clip represents the time base. The play list references regions a to f of the clip that include commercial message regions b and c and a scene e. The play list references regions d to g of the clip that include a scene e. When the play list is designated the regions a to f of the clip can be reproduced. When the play list is designated the regions d to g of the clip can be reproduced.

Next with reference to a management structure for files recorded on a recording medium prescribed in Blu ray Disc Rewritable Format Ver 1.0 part 3 will be described. Files are hierarchically managed in a directory structure. One directory a root directory in the example shown in is created on the recording medium. Under the directory files are managed by one recording and reproducing system.

Under the root directory a directory BDAV is placed. As shown in a plurality of directories such as directories BDAV BDAV BDAV . . . BDAVn can be placed. In the following description the plurality of directories BDAV BDAV BDAV . . . and BDAVn are represented by the directory BDAV. Only the representative directory BDAV will be described.

In the files .rpls and .vpls categorized as 4 represents any number. In the file .clpi categorized as 5 represents any number. In the file .m2ts categorized as 6 represents a number of which a file .m2ts corresponds to a file .clpi with the relation of one to one. A number can be the same as a number .

The file info.bdav categorized as 1 is a file that has information of all the directory BDAV. The files menu.tidx and mark.tidx categorized as 2 are files that have information of thumbnail pictures. The files menu.tdt1 menu.tdt2 mark.tdt1 and mark.tdt2 categorized as 3 are files that have thumbnail pictures. The extensions tdt1 and tdt2 of those files represent whether or not data of thumbnail pictures in those files have been encrypted.

The files .rpls and .vpls categorized as 4 are files that have information of play lists. The files .rpls and .vpls are placed under the directory PLAYLIST which is placed under the directory BDAV.

The file .clpi categorized as 5 is a file that has clip information. The file .CLP is placed under the directory CLIPINF which is placed under the directory BDAV. The file .m2ts categorized as 6 is a clip AV stream file that has a clip AV stream. A clip AV stream file is correlated with one clip information file .clpi with a file name number . The file .m2ts is placed under the directory STREAM which is placed under the directory BDAV.

Next each file will be described in detail. The file info.bda categorized as 1 is only one file placed under the directory BDAV. shows a syntax that describes an example of a structure of the file info.bdav . The syntax is represented by a descriptive method of C language which is used as a program descriptive language for computer devices. This applies to drawings that show other syntaxes.

In the file info.bdav is divided into blocks corresponding to functions. A field type indicator describes a character string BDAV that describes that the file is info.bdav . A field version number represents a version of the file info.bdav . A block UIAppInfoBDAV describes information about information placed under the directory DBAV. A block TableOfPlayList describes information about the arrangement of the play list. A block MakersPrivateData describes unique information of the maker of the recording and reproducing apparatus.

Addresses that represent the beginnings of individual blocks are described at the beginning of the file info.bdav . For example a field TableOfPlayLists Start address represents the start position of the block TableOfPlayListsQ with the number of relative bytes in the file.

A flag BDAV protect flag describes whether or not the user is unconditionally permitted to watch a content placed under the directory BDAV. When the flag has been set to 1 and the user has input a correct PIN Personal Identification Number he or she is permitted to watch a content placed under the directory BDAV. In contrast when the flag BDAV protect flag has been set to 0 even if the user does not input his or her PIN he or she is permitted to watch a content placed under the directory BDAV.

The personal identification number PIN is described in a field PIN. The personal identification number PIN is composed of for example a four digit number each digit ranging from 0 to 9. The personal identification number PIN represents a personal identification number that is required when the reproduction control is validated. Digits of the personal identification number PIN are encoded in accordance with for example ISO International Organization for Standardization IEC International Electrotechnical Commission 646 standard.

With the foregoing information described in the block UIAppInfoBDAV the reproduction restriction for the directory BDAV is prescribed. As will be described later the reproduction restriction for each play list is prescribed with a flag playback control flag defined in the block UIAppInfoPlayList described in the files .rpls and .vpls .

In the example to resume reproducing a content placed under the directory BDAV a resume function can be used. The resume function allows a play list of a content to be reproduced in priority to be designated. It is assumed that the resume function is used when the user wants to resumes reproducing a content from the last stop position.

In a flag resume valid flag describes whether the resume function is valid invalid. When the value of the flag has been set to 0 the resume function is invalid. When the value of the flag has been set to 1 the resume function is valid. At that point a play list designated by a field resume PlayList file name is treated as a play list to be reproduced in priority.

A field ref to menu thumbnail index is a region that describes a thumbnail number that identifies a thumbnail picture that typifies the directory BDAV. In the blu ray disc standard a still picture that typifies the directory BDAV is referred to as menu thumbnail. A thumbnail picture that has an index thumbnail index described in the field ref to menu thumbnail index is the menu thumbnail of the directory BDAV.

A field BDAV name length represents the byte length of the name of the directory BDAV described in a field BDAV name. The number of bytes represented in the field BDAV name length is valid for the character string of the field BDAV name that represents the name of the directory BDAV. The rest of the byte sequence after the valid character string represented by the field BDAV name length may have any value.

As described above the files .rpls and .vpls are placed under the directory PLAYLIST. These files correspond to individual play lists in the relation of one to one.

A block UIAppInfoPlayList describes attribute information of the play list. A block PlayList describes information about play items that compose the play list. A block PlayListMark describes information about a mark added to the play list. A block MakersPrivateData describes maker s unique information of the apparatus that has recorded the play list file. Fields PlayList start address PlayListMark start address and MakersPrivateData start address are placed at the beginning of each of the files .rpls and .vpls . These fields describe the start addresses of the corresponding blocks as address information of 32 bits.

Since the start address of each block is described at the beginning of each of the files .rpls and .vpls data padding word of any length can be placed before each block and or after each block. However the start position of the block UIAppInfoPlayList which is the first block of each of the files .rpls and .vpls is fixed at the 320 th byte from the beginning of each of these files.

A flag playback control flag describes whether or not display of information and reproduction of a play list are restricted in accordance with a personal identification number PIN. When the value of the flag playback control flag is for example 1 unless the user inputs a correct personal identification number PIN information such as a thumbnail picture of a play list cannot be displayed and the play list cannot be reproduced. A flag write protect flag is an erase prohibition flag. It is necessary to structure the user interface so that when the value of the flag write protect flag is 1 the user cannot easily erase the play list. A flag is played flag describes that the play list has been reproduced. A flag is edited flag describes that the play list has been edited.

A field time zone represents a time zone of which the play list was recorded. A field record time and date represents the date and time on and at which the play list was recorded. A field PlayList duration represents the reproduction duration of the play list.

Fields maker ID and maker model code describe information that identifies a maker and a model of the recording apparatus that last updated the play list. The fields maker ID and maker model code are for example numbers. A field channel number represents a channel number of a recorded clip AV stream. A field channel name represents a channel name. A field channel name length represents the length of the channel name described in the field channel name. In the field channel name a character string having the length described in the field channel name length is valid. A field PlayList name represents a play list name having an effective length of a value described in the field PlayList name length. A field PlayList detail describes detailed information of the play list having an effective length of a value described in the field PlayList detail length.

A block PlayItem describes information of a play item. A block SubPlayItem describes information of a sub play item.

A field Clip codec identifier describes an encoding system of a clip that the play item references. In the example the field Clip codec identifier is fixed to a value M2TS . A field connection condition describes information of how this play item is connected to the next play item. The field connection condition describes whether or not play items can be seamlessly reproduced.

A field ref to STC id designates a sequence STC sequence of a clip that the play item references. The sequence STC sequence is a unique structure of the blu ray disc standard. The structure represents a range of which a PCR Program Clock Reference that is a reference of an MPEG2 TS Transport Stream is continuous on the time base. A number STC id that is unique in the clip is assigned to the sequence STC sequence. In the sequence STC sequence since a continuous time base can be defined the start time and end time of a play item can be uniquely designated. The start point and end point of each play item should exist in the same sequence STC sequence. A field ref to STC id describes a sequence STC sequence with a number STC id.

Fields IN time and OUT time describe time stamps pts presentation time stamp of the start point and end point of the play item in the sequence STC sequence respectively.

A block BridgeSequenceInfo describes information about a bridge clip Bridge Clip . As shown in a bridge clip is a bit stream that is created when a function for seamlessly reproducing play items is accomplished. By reproducing a bridge clip instead of an original bit stream at a boundary of the preceding play item and the current play item the two play items can be seamlessly reproduced.

A field length describes the length of bytes immediately after the field length until the end of the block PlayListmark . A field number of PlayList marks describes the number of marks in a play list. One loop of a for statement represents information of one mark. A flag mark invalid flag describes whether or not the mark is valid. When the value of the flag mark invalid flag is 0 it describes that the mark is valid. When the value of the flag mark invalid flag is 1 it describes that although information of the mark exists in the database the mark is an invalid mark that is transparent to the user.

A field mark type describes the type of the mark. There are a mark that represents the position of a picture as a thumbnail picture representative picture of the play list a resume mark that represents a position from which reproduction is resumed a chapter mark that represents a search point a skip mark that represents a region to be skipped and reproduced a mark that represents read start timing of a graphics image a mark that represents display start timing of a graphics image a mark that represents display stop timing of a graphics image and so forth.

A field mark name length represents a data length of a field mark name that will be described later . A field maker ID describes a maker of a recording apparatus that created the mark. The field maker ID is used to identify a mark unique to a maker. A field ref to PlayItem id describes what play item has time designated by the mark. A field mark time stamp represents time designated by the mark.

A field entry ES PID describes what elementary stream the mark was added namely whether the mark was added to a stream of which picture data and or sound data was encoded . A field ref to menu thumbnail index and a field ref to mark thumbnail index describe thumbnail pictures that visually represent marks. A thumbnail picture is for example a still picture that was extracted at time designated by the mark.

A field duration is used when a mark has a length on the time base. When a skip mark is used the field duration describes for what duration the skip is performed.

A field makers information is a region that describes information unique to the maker. A field mark name is a region that describes a name that is assigned to a mark. The size of a mark is described in the foregoing field mark name length.

A block ClipInfo describes information about a clip. A block SequenceInfo describes information about an incontinuous point of PCR that represents a time reference of a transport stream of the MPEG2 system. A block ProgramInfo describes information about a program of the MPEG2 system. A block CPI describes information about characteristic point information CPI that represents a characteristic portion in an AV stream. A block ClipMark describes mark information that represents a search index point added to a clip and commercial start and or end points. A block MakersPrivateData describes information unique to a maker of a recording apparatus.

Address information that represents the beginning of each block in the file .clpi is described as fields SequenceInfo start address ProgramInfo start address CPI start address ClipMark start address and MakersPrivateData start address.

Since the BDAV format has the foregoing data structure with a play list composed of play items that describe sets of start points and end points of portions to be reproduced in a clip AV stream contents recorded on the disc can be managed in a reproduction unit that the user can recognize.

Next an embodiment of the present invention will be described. According to the present invention the foregoing BDAV format is extended for a format of a reproduction only disc BD ROM Blu ray Disc Read Only Memory . The extended BDAV format is referred to as BDMV format.

Next a structure of a plane that accomplishes a menu screen for the contents of a disc will be described. A scenario structure that allows the contents producer side to designate the reproduction order of a play list is added. For the scenario structure data necessary for accomplishing functions such as a still pause a random shuffle reproduction a multiple angle and so forth that are characteristics of the reproduction only disc and a method for storing such data will be described.

According to the embodiment of the present invention a plane structure as shown in is used. A moving picture plane is displayed on the rearmost side bottom . The moving picture plane deals with a picture mainly moving picture data designated by a play list. A subtitle plane is displayed above the moving picture plane . The subtitle plane deals with subtitle data displayed while a moving picture is being reproduced. A graphics plane is displayed on the most front. The graphics plane deals with character data for a menu screen and graphics data such as bit map data for buttons. One display screen is composed of these three planes.

The difference between the embodiment of the present invention and the conventional DVD video is in that sub pictures for subtitles a menu screen buttons and so forth are separated into the subtitle plane and the graphics plane so that the subtitles and buttons are independently controlled. In the conventional DVD video graphics such as a menu screen and buttons and subtitles are controlled by the same mechanism. They are displayed on the same plane. The number of bit map pictures that can be displayed at the same time is limited to one. Thus in the DVD video a plurality of bit map pictures cannot be displayed at the same time. In contrast according to the present invention since the subtitle plane and the graphics plane are independently disposed for subtitles and graphics respectively the foregoing problem of the DVD can be solved.

It can be thought that the subtitle plane and the graphics plane are an extension portion of Blu ray Disc Rewritable Format Ver 1.0 part 3 .

The moving picture plane the subtitle plane and the graphics plane can be independently displayed. The moving picture plane the subtitle plane and the graphics plane have resolutions and display colors as shown in . The moving picture plane has a resolution of 1920 pixels 1080 lines a data length of 16 bits per pixel a color system of YCbCr 4 2 2 where Y represents a luminance signal and Cb and Cr represent color difference signals. YCbCr 4 2 2 is a color system having a luminance signal Y of eight bits per pixel and color difference signals Cb and Cr of eight bits each. With two horizontal pixels of the color difference signals Cb and Cr data of one color data is composed.

The subtitle plane has a resolution of 1920 pixels 1080 lines a sampling depth of eight bits per pixel and a color system having eight bit color map addresses using a palette of 256 colors.

The graphics plane has a resolution of 1920 pixels 1080 lines a sampling depth of eight bits per pixel and a color system of eight bit color map addresses using a palette of 256 colors.

In the forgoing description the subtitle plane and the graphics plane have a color system of eight bit color map addresses using a palette of 256 colors. However the subtitle plane and the graphics plane are not limited to such examples. The number of colors can be increased by changing the sampling depth and increasing the number of colors of the palette. When the sampling depth is 12 bits the number of colors that can be used with the palette is 4096. When the sampling depth is 24 bits YCbCr 4 4 4 and RGB 4 4 4 of which each pixel has color information can be used.

The graphics plane and the subtitle plane can be alpha blended in 256 levels. When the graphics plane and the subtitle plane are combined with another plane the transparency can be set in 256 levels. The transparency can be set for each pixel. In the following description the transparency is represented in the range of 0 1 where transparency 0 represents perfect transparent transparency 1 represents perfect intransparent.

The subtitle plane deals with picture data of for example PNG Portable Network Graphics format. Likewise the graphics plane can deal with picture data of the PNG format. In the PNG format the sampling depth of one pixel is in the range from one bit to 16 bits. When the sampling depth is eight bits or 16 bits an alpha channel namely transparency information referred to as alpha data of each pixel component can be added. When the sampling depth is eight bits transparency can be designated in 256 levels. With the transparency information of the alpha channel alpha blending is performed. A palette image of up to 256 colors can be used. An element index of the prepared palette can be represented with an index number.

Picture data dealt with the subtitle plane and the graphics plane is not limited to the PNG format. Alternatively picture data that has been compression encoded in accordance with for example JPEG system picture data that has been run length compressed or bit map data that has not been compression encoded may be used.

Picture data of the subtitle plane is input to a palette . The palette outputs picture data of RGB 4 4 4 . When transparency of alpha blending is designated for the picture data designated transparency 0 1 1 is output from the palette .

The RGB data that is output from the palette is supplied to an RGB YCbCr converting circuit . The RGB YCbCr converting circuit converts the RGB data into a luminance signal Y and color difference signals Cb and Cr of eight bits each hereinafter they together are referred to as YCbCr data . This is because data of planes should be combined in the common data format. Data is unified to YCbCr data that is the data format of moving picture data.

The YCbCr data and the transparency data that are output from the RGB YCbCr converting circuit are input to a multiplying device . A resolution converting circuit may be disposed between the RGB YCbCr converting circuit and the multiplying device so as to convert the resolution of the YCbCr data. The multiplying device multiplies the input YCbCr data by the transparency data . The multiplied result is input to one input terminal of an adding device . The multiplying device multiplies each of the luminance signal Y and the color difference signals Cb and Cr of the YCbCr data by the transparency data . A complement 1 of the transparency data is supplied to the multiplying device .

The multiplying device multiplies the moving picture data that is input from the 422 444 converting circuit by the complement 1 of the transparency data . The multiplied result is input to the other input terminal of the adding device . The adding device adds the multiplied results of the multiplying device and the multiplying device . As the result the moving picture plane and the subtitle plane are combined. The added result of the adding device is input to a multiplying device .

Like the subtitle plane data of RGB 4 4 4 is output as picture data of the graphics plane from the palette table and input to an RGB YCbCr converting circuit . When the color system of picture data of the graphics plane is RGB 4 4 4 it is converted into YCbCr 4 4 4 and output from an RGB YCbCr converting circuit . The YCbCr data that is output from the RGB YCbCr converting circuit is input to a multiplying device . A resolution converting circuit may be disposed between the RGB YCbCr converting circuit and the multiplying device so as to convert the resolution of the YCbCr data.

When transparency of alpha blending has been designated to index values of the palette designated transparency a 0 2 1 is output from the palette . The transparency data is supplied to the multiplying device . The multiplying device multiplies each of the luminance signal Y and the color difference signals Cb and Cr of the YCbCr data that is input from the RGB YCbCr converting circuit by the transparency data . The multiplied result of the multiplying device is input to one input terminal of an adding device . A complement 1 of the transparency data is supplied to the multiplying device .

The multiplying device multiplies the added result of the adding device by the complement 1 of the transparency data . The multiplied result of the multiplying device is input to the other input terminal of the adding device . The adding device adds the multiplied results of the multiplying device and the multiplying device . As a result the graphics plane and the combined result of the moving picture plane and the subtitle plane are combined.

When the transparency a of a non picture region of the subtitle plane and the graphics plane is designated to 0 0 a plane below those planes and becomes transparent. As a result moving picture data on the moving picture plane can be displayed as a background of the subtitle plane and the graphics plane .

In the foregoing description the graphics plane has a resolution of 1920 pixels 1080 lines and a color system of eight bit color map addresses using a color palette of 256 colors. However it should be noted that the resolution and number of colors of the graphics plane are not limited to the foregoing example.

For example the graphics plane may have a resolution of 960 pixels 540 lines and a sampling depth of 24 bits of which each pixel has color information of eight bits for each color of RGB and alpha data of eight bits. In this case the number of colors that can be used becomes much larger than the foregoing 256 colors. As a result enrichness of pictures increases. Since the number of pixels decreases the rewriting speeds of the planes do not decrease. When the graphics plane is used for natural pictures and high speed animations it will be effective.

In that example the number of pixels is one fourth of the forgoing example of 1920 pixels 1080 lines. On the other hand since the amount of data per pixel is increased four times from eight bits to 32 bits the amount of data of the graphics plane does not change in total. Thus that example can be easily accomplished by changing the method for using the frame memory without need to use an additional memory.

In addition since color information of eight bits is assigned to each color of RGB the number of colors that can be displayed is sufficient. Thus the palette shown in can be omitted. Picture data on the graphics plane is directly input to the RGB YCbCr converting circuit . The alpha data is extracted and supplied to the multiplying device not through the RGB YCbCr converting circuit .

In contrast the resolution of each of the moving picture plane and the subtitle plane that are combined with the graphics plane is 1920 pixels 1080 lines. When a picture is actually displayed one pixel of the graphics plane whose resolution is quartered is repeatedly displayed for four pixels of 2 pixels 2 lines on the moving picture plane or the subtitle plane . After the apparent resolutions are adjusted the moving picture plane and the subtitle plane are combined.

With the foregoing planes designated a menu screen and buttons necessary for the reproduction only disc standard can be displayed. When a button is selected on the menu screen a play list corresponding to the button is reproduced. At that point information about a link of play lists should have been recorded on a disc. The menu screen will be described in Section 2 2 that follows. A scenario that defines a link of play lists will be described in Sections 2 3 and 2 4.

A screen that prompts the user to perform an operation for example a menu screen can be displayed on the graphics plane . shows an example of a menu screen displayed on the graphics plane . On the menu screen characters and images are displayed at particular positions. With the characters and images links and buttons that allow the user to select to new operations can be placed.

A link describes an access method to a predetermined file with a character string or image data. When the user designates the character string or image data on a screen with for example a pointing device he or she can access the predetermined file in accordance with the access method designated with the character string or image data. A button has three types of image data that represent a normal state a selection state and a pressed state for a link . When the user designates one button image the image data is changed in accordance with the state that he or she has operated so that he or she can easily recognize the current state of the button.

When the user designates a link or a button he or she moves a cursor on the screen with the mouse and clicks a mouse button presses the mouse button several times on a character string or an image on the link or an image on a button . The same operation can be performed with another pointing device other than the mouse. Alternatively with a remote control commander or a key operation of a keyboard the user can designate a link or a button . At that point the user selects his or her desired link or button with a predetermined key such as a direction key and designates the selected link or button with an OK key or the like.

In the example shown in a title as image data is displayed at an upper portion of the menu screen that is displayed on the graphics plane . The title is followed by selection items A B C and D as links. When the user selects and designates one of the selection items A B C and D with a key operation of for example the remote control commander a file linked to the designated selection item is accessed.

AT lower positions of the menu screen buttons and are displayed. With the buttons and subtitles can be displayed and a language of output sound can be selected from for example English and Japanese. When the buttons and are operated in the foregoing manner files used to display their setup screens are accessed and the predetermined screens are displayed.

At a lower left portion of the menu screen a character string that describes a method for selecting an item is displayed. The character string is displayed on the graphics plane .

To display the menu screen as shown in any descriptive language for describing a screen display method link information and so forth is required. Although there are many types of descriptive languages for describing a menu screen for a blu ray disc two types of descriptive languages will be explained.

 1 A descriptive language of which original display control commands for subtitles and buttons are added to a command system of which DVD video navigation commands are changed and extended. The commands of this descriptive language are referred to as original commands. 2 HTML Hyper Text Markup Language which is a descriptive language widely used in WWW World Wide Web of the Internet and ECMA script that is a script language that has a high affinity with HTML. 2 3. About Scenario

On the menu screen for the foregoing blu ray disc a table of for example play lists is displayed with image data a character string buttons and so forth. It is expected that when a particular play list is designated the designated play list is read and reproduced from the disc.

In the example shown in a table of play lists is displayed on the menu screen . In reality images and sound of the menu screen and those that are generated in accordance with an item selected on the menu screen are composed of a plurality of play lists. When a plurality of play lists that compose one menu item are correlated a mechanism of which a story is branched can be accomplished. When a story is branched a multiple story function that causes the contents of the story to vary in accordance with the user s selection an automatic language reproducing function that causes a proper language to be automatically reproduced in accordance with a designated language of the player and a parental function that causes scenes to be changed in accordance with the age of the user can be accomplished.

Although those functions are especially effective for recoded discs but they are not prescribed in the current blu ray disc standard which mainly aims to record reproduce television broadcasts.

In the following description the structure of which a plurality of play lists are arranged is referred to as scenario. shows an example of an internal structure of a scenario using original commands. The scenario has a plurality of play lists A to M. In addition the scenario has two portions screens A and B on which branch selection screens are displayed with the graphics plane . The screen A has graphics data A and a play list C with which a branch selection screen is displayed. Likewise the screen B has a graphics data B and a play list J with which a branch selection screen is displayed.

A scenario designates both an arrangement of play lists and display timing at which they are displayed on the graphics plane . The display timing of the play lists on the graphics plane can be designated with display control commands added to an image displayed on the graphics plane.

In the example shown in the menu screen corresponds to the screen A of the scenario . A selection item for example the selection item A on the menu screen is composed of graphics A. When the selection item A is designated on the menu screen the play list D that corresponds to the selection item is reproduced.

In the scenario shown in when a disc is loaded into the player the play list A is reproduced. After the play list A has been reproduced the play list B is reproduced.

After the play list B has been reproduced the play list C is reproduced. As a result the graphics data A is read and the screen A that prompts the user to select a branch of the story is displayed.

After the screen A is displayed the story is branched in accordance with a user s selection. In the example shown in when a first selection is performed the screen A is displayed. Thereafter the play lists D E and F are reproduced in succession. As a result the reproduction of the scenario is completed. After the play list F has been reproduced the main menu screen for example the foregoing menu screen may be displayed again.

When a second selection is performed on the screen A after the screen A is displayed the play list G is reproduced. A mark may be set in the play list G at predetermined timing. When the play list B is reproduced the play list G may be branched at the position of the mark or fully reproduced in accordance with the setting of the reproducing apparatus user s another scenario or a selection on the branch selection screen. When all the play list G is reproduced after the play list G is reproduced the play lists M and are reproduced in succession. Thereafter the play list J is reproduced.

When the play list G is branched at the position of the mark the play lists K and L are reproduced in succession. After the play list L has been reproduced the reproduction is resumed from the position of the mark that has been set in the play list .

In the play list J the graphics data B is read. The screen B that prompts the user to select a branch of the story is displayed. In the first selection on the screen B the play list F is reproduced. In the second selection of the screen B the play list K is reproduced from the position of the mark that has been set in the play list K.

When a scenario is reproduced operations corresponding to a detected mark a user s input and player s operation change are performed in accordance with command sequences programs executed by the player for play lists.

Next with reference to a scenario structure using the HTML and ECMA script as descriptive languages will be described. In for simplicity similar portions to those in will be denoted by similar reference numerals and their description will be omitted.

A scenario shown in has the same menus and branches as the scenario shown in . The scenario can be advance in the same manner as the scenario . The scenario has a plurality of play lists A to M. The scenario has two portions screens A and B on which branch selection screens are displayed on the graphics plane .

The screen A has graphics data A and a play list C for a branch selection screen. The screen B has graphics data B and a play list J for a branch selection screen. The scenario designates an arrangement of play lists and display timing at which they are displayed on the graphics plane is displayed. Display timing at which a play list is displayed on the graphics plane can be designated with a mark placed in the play list.

A mark a user s input and an operation change of the player are detected in accordance with an event driven model. When reproduction of a play list is started reproduction of a play list is completed a mark is detected while a play list is being reproduced or a user inputs data by a key operation of the remote control commander an event takes place. When a program has an event handler that is executed upon occurrence of an event an operation expected for the event is executed by the player.

The scenario shown in has two event handlers and . Among them the event handler is a global event handler that describes an event handler that is effective all the scenario . Even if any of the play lists A to M is being reproduced when a menu button of the remote control commander is pressed the menu screen for a table of scenarios is displayed. Next an operation for a reproducing process for a play list for the menu screen will be described. In this case an event handler that corresponds to an event that takes place when the menu button of the remote control commander is pressed menu button press event and that is a command that causes a play list for the menu screen to be processed is described as global event handler .

The event handler is a local event handler that is executed only while a predetermined play list is being reproduced or a predetermined user input screen is being displayed. For example when the user designates a link displayed on the screen A as a branch selection screen an operation for reproducing another play list is accomplished by describing a command that causes the play list to be reproduced against an event of which the link is designated as a local event handler.

Such a definition of an event handler is described with the ECMA script. The ECMA script is a cross platform script language in accordance with JavaScript . The ECMA script is prescribed by ECMA European Computer Manufacturers Association . The ECMA script has a high affinity with an HTML document and allows a unique object to be defined.

As will be described later one scenario is defined in the BDVM directory. One scenario is composed of one or a plurality of play lists. Categories of scenarios will be described with reference to and . Based on connections of play lists structures of scenarios can be largely categorized as three types that are 1 single play list 2 sequential play list and 3 multiple play list as shown in .

The single play list categorized as 1 is a scenario composed of one play list as shown in . For the single play list a time line can be defined. There is no interrupt during reproduction of the scenario. When the content of the single play list is a movie after the disc is loaded only a movie main part is reproduced.

The sequential play list categorized as 2 is a scenario composed of a plurality of play lists that are linearly arranged without a branch as shown in . The play lists are arranged in such a manner that the end of one play list is connected to the beginning of the next play list. In the sequential play list a time line can be defined for each play list. When the content of the sequential play list is a movie the scenario is composed of a menu screen and a movie main part. After the disc is loaded a play list that causes a menu screen to be displayed is executed. When the reproduction of the movie main part is designated on the menu screen the next play list is executed and the movie main part is reproduced.

The multiple play list categorized as 3 is a scenario that has a branch of a play list and a connection of play lists. In the multiple play list a time line cannot be defined through all play lists. Instead a time line is defined in each play list. With the multiple play list an interactive function and a game function for varying reproduction contents in accordance with a user s input can be accomplished. When the content of the multiple play list is a movie a multiple angle function that allows the user to select a desired angle from various angles photographed for the same scene can be accomplished.

In the reproduction only medium one scenario is defined for the BDVM directory. However it is necessary to allow the user to recognize the scenario in smaller units. Nevertheless the unit of a play list does not always accord with a unit that the user can recognize. When one play list describes three movies it is necessary to allow the user to see a search point of each movie. A search point entry point that is independent from the structure of a play list is referred to as title and or chapter.

Next with reference to titles and chapters will be described. A title represents any reproduction start point in a scenario. In the example shown in a title is placed at the beginning of a play list A. A title is placed in the middle of a play list D. A region after the beginning of the play list A until the title is the title . A chapter is a unit of which a title is sub divided. The can also recognize a chapter as a reproduction start point. The title is sub divided into chapters. In the example shown in the title has chapters and . Thus the title is sub divided into three portions. As shown in each of a title and a chapter can be placed in the middle of a play list.

Next a model of a reproducing apparatus that operates in accordance with description of a scenario will be considered. The modeled reproducing apparatus is referred to as BD Blu ray disc virtual player. The definition of the structure of the BD virtual player is referred to as BD virtual player model.

Next with reference to the BD virtual player model will be described. After a disc is loaded into a BD virtual player it reads as a PBC program a scenario described in the scenario descriptive language defined in the present invention from the disc and operates in accordance with the description of the scenario.

The BD virtual player reproduces data from a disc shaped recording medium defined according to an embodiment of the present invention. The BD virtual player is an object in a computer environment such as a personal computer. The computer environment is not limited to a general purpose personal computer. Instead the computer environment includes a software environment incorporated with a dedicated reproducing apparatus and or recording and reproducing apparatus that reproduces data from a disc shaped recording medium defined according to the embodiment of the present invention. Hereinafter a disc shaped recording medium defined according to the embodiment of the present invention is referred to as disc.

The BD virtual player roughly has two states A and B. In the state A the BD virtual player reproduces a play list and graphics. In the state B the BD virtual player stops reproducing a play list and graphics. A state change from one state to another state and a designation of the next operation in one state are performed by commands to an object of the BD virtual player .

The state A has a plurality of operations. As operations in the state A there would be a high speed reproduction a variable speed reproduction such as a reverse reproduction and a special reproduction such as a jumping reproduction that starts from any time of a disc. When data of the graphics plane is displayed the variable speed reproduction and the special reproduction of the BD virtual player would be restricted.

A PBC Play Back Control program corresponds to a scenario recorded on the disc. As will be described later a scenario describes a reproducing method for a play list recorded on the disc and a displaying method for a menu screen. The PBC program and the BD virtual player exchange commands through an API Application Programming Interface so as to reproduce a play list recorded on the disc.

In more reality when the state of the BD virtual player changes the PBC program causes necessary information to be transferred to common parameters defined as a dedicated memory of the BD virtual player through the API . Values of the common parameters are set directly with commands exchanged directly between the PBC program and the BD virtual player through the API or indirectly with player commands executed through the API .

According to the embodiment of the present invention the BD virtual player is controlled under an event driven model. While the BD virtual player is operating various events take place. Events are generated by hardware OS Operating System when the user performs a key input or operates the remote control commander or a timer interrupt takes place. The events are sent to the BD virtual player . Alternatively events may be generated when a mark is detected in a reproduced play list. Furthermore events may be generated by the BD virtual player itself for example the state of which the operation of the player is changed is detected.

The types of events that take place are defined in the BD virtual player model. When an event takes place an event handler corresponding to the event is executed. As a result an operation prescribed in the standard for the player is executed.

Interrupt events of the BD virtual player are roughly categorized as 1 an event that takes place in a content that is being reproduced 2 an event that takes place with an interrupt by the user and 3 an event that takes place due to a state change of the player.

The event 1 which takes place in a content that is being reproduced is a predetermined interrupt. Whenever the content is reproduced the event 1 takes place at the same timing. While the BD virtual player is reproducing a play list when time designated by a mark described in the play list has elapsed on the disc a mark detection interrupt takes place in the BD virtual player . When a timer is designated by a script a timer interrupt event takes place at the designated time or 10 seconds after the timer setup time designated by the script.

The event 2 which is a user s interrupt is an event whose occurrence and occurrence timing cannot be predicted. When the user operates a key of the remote control commander the interrupt event takes place. In this case since it is uncertain when the user performs a key operation the timing cannot be obtained in advance.

The event 3 which takes place due to a state change of the BD virtual player is an event that causes a change of a stream of sound or subtitles to be informed. This event takes place when the state of the player changes from the reproduction state to the stop state or vice versa for a content. An event due to the state change of the player may take place in association with the event 1 which takes place in a content that is being reproduced or the event 2 which takes place due to a user s interrupt event. As an example of an event that causes a change of a stream of sound or subtitles to be informed when an interrupt event of a user s key operation of the remote control commander takes place a stream of sound or subtitles is changed. As a result since the state of the BD virtual player changes the event that causes the state change to be informed takes place.

When the HTML and ECMA script are used as descriptive languages a display control using the graphics plane is described as an HTML Hyper Text Markup Language 4.0 document or an XHTML eXtensible HTML document. As events for a display screen of the graphics plane HTML 4.0 build in events are used. If events other than the HTML 4.0 built in events are required they can be described using the ECMA script.

When the HTML format and the ECMA script are used in combination if an event takes place a process that is performed depends on whether an event handler designated with an attribute of an element of the event exists in the document. When an event handler exists it is executed. When an event handler does not exist it is determined whether or not a global event handler exists in the document. As a result if a global event handler exists in the document the event handler is executed. When the document does not describe an event handler in the script language the BD virtual player performs a default event process prepared for the event.

An event handler can be described as an attribute of an element of an HTML document or a method captureEvents of the ECMA script.

Next the method for describing an event handler using an HTML document will be described. For example an event onload an event onunload an event onclick and an event onkeypress of built in events prescribed in the HTML 4.0 can be used. Each of these events is described as an attribute in an element of a tag.

The event onload takes place when the user agent ends one window or all frames defined with a pair of tags . When a menu screen is displayed the event onload takes place.

A window is a unit in which a browser application displays an HTML file in accordance with the prescription of the HTML. A frame is used to display a plurality of HTML files on divided regions of one window. HTML files in a frame and a frame itself are referred to as frame. The event onload attribute can be used with the element BODY and the element FRAMESET.

The event onunload takes place when the user agent removes one HTML document from one window or one frame. The event onunload attribute can be used with the element BODY and the element FRAMESET.

The event onclick takes place when an element is pointed with the pointing device or the like. For example when a click operation of a mouse button is performed the event onclick takes place. The event onclick attribute can be used with almost any element of the HTML 4.0.

The event onkeypress takes place when a key is pressed or released on or from an element. For example when a predetermined key is pressed on the keyboard or a key of the remote control commander is pressed in a region defined with a particular element on the screen and placed in the selection state the event onkeypress takes place. The event onkeypress attribute can be used with almost any element of the HTML 4.0.

Since the operation of the BD virtual player cannot be sufficiently controlled with events of the foregoing HTML it is necessary to define original events. and show examples of original events defined in the BD virtual player . The events are described in an HTML document using the ECMA script. As an attribute name that designates an event handler on is added to the beginning of an event name.

An event TimerFired takes place when the value of a countdown timer becomes 0 or when the value of a count up timer becomes a predetermined value. An event PlayStopped and an event PlayStilled take place when reproduction is stopped or paused. An event StillReleased takes place when the pause state is released. An event PlayPaused and an event PauseReleased take place when the user temporarily stops the reproduction and when the user releases the pause state of the reproduction. An event PlayStarted takes place when the reproduction is started. An event PlayRepeated takes place when the beginning of a region to be repeatedly reproduced is detected.

An event SPDisplayStatusChanged takes place when the display non display state of a sub picture subtitle stream is changed. An event SelectedAudioChanged and an event VideoStopped take place when an audio stream and a video stream to be reproduced is changed respectively.

An event ScenarioStarted and an event ScenarioEnded take place when the beginning and end of a scenario are detected respectively. An event PlayListStarted and an event PlayListEnded take place when the beginning and end of a play list are detected respectively. An event PlayItemStarted and an event PlayItemEnded take place when the beginning and end of a play item are detected respectively.

An event MarkEncountered takes place when a mark is detected while a play list is being reproduced. This event is used when image data is displayed on for example the graphics plane . The type and number of a detected mark are described in the common parameters .

An event ButtonPressed takes place when a button placed on a screen is pressed. For example when a button placed on the graphics plane is virtually pressed by a key operation or a click operation of the mouse the event ButtonPressed takes place.

An event ValidPeriodStarted takes place when a valid period starts. This event can be used when a valid period for which a link can be selected is designated. An event ValidPeriodEnded takes place when the valid period ended. This event can be used when a link is forcedly executed.

An event KeyPressed takes place when a key of the remote control commander is pressed. The type of a pressed key is identified with a switch statement or the like of an event handler.

When original commands are used as a scenario descriptive language events necessary for executing a scenario can be defined as a language. Thus when a scenario is described using original commands unlike the case that the general purpose ECMA script is used it is not necessary to define an event suitable for executing a scenario in a program.

The BD virtual player has commands. With these commands the operation and the state of the BD virtual player the retrieval and control of information about a video stream an audio stream and a sub picture image data on the subtitle plane the operation for the common parameters processes for timer and key input interrupts and the control of picture data handled on the graphics plane are defined.

These commands are built in the API of the BD virtual player described in . These commands are called in accordance with the description of the PBC program through the API . The reproduction for a disc of the BD virtual player is controlled in accordance with these commands. A real example of the PBC program will be described later.

Commands that the BD virtual player has slightly differ between the case that original commands are used as a scenario descriptive language and the case that the HTML and ECMA scrip are used. First of all with reference to and commands in the case that original commands are used as a scenario descriptive language will be described.

Next commands for designating a reproduction start position will be described. A command LinkPlayList playListNumber causes the reproduction of a play list designated by playListNumber to be started. A command LinkPlayItem playListNumber playItemNumber causes the reproduction of a designated play item of a designated play list to be started. playItemNumber is PlayItem id whose value starts from 0 . When playItemNumber is designated a value 0 a play list to which the play item belong is reproduced from the beginning.

A command Link position object causes the current position to be moved in a scenario. This command causes the current position to be moved to the adjacent play list play item or chapter. A parameter position is one of prey next top Parent or tail . A parameter object describes a moving method for an object a play list a play item or a chapter represented by the parameter object .

A command Exit causes the reproduction of a scenario to be stopped. In this case the value of the standard register is not held. A command RSM causes resume information stored in the memory of the player to be called set to a register and the reproduction of the scenario to be started.

Next commands for obtaining the state of the player will be described. A command getMenuDescriptionLanguage causes a language used to display a menu to be obtained. A command getScenarioNumber a command getPlayListNumber and a command getChapterNumber cause a scenario number a play list number and a chapter number that are being reproduced respectively to be obtained. A command getPlayerSupport causes version information of the player to be obtained.

Next commands for video streams will be described. A command getVideoStreamAvailability causes information that describes whether or not a designated video stream to be contained. A command setVideoStreamNumber describes a video stream to be decoded. A command getVideoStreamNumber causes the number of a video stream that is being selected to be obtained. Attributes of a video stream are for example an encoding system a resolution an aspect ratio a display mode in the case that the aspect ratio is 4 3 and presence absence of closed caption. A command setAngleNumber describes an angle number. A command getAngleNumber causes an angle number that is being selected to be obtained. A command getMaxVideoStreams causes a maximum number of bit streams to be obtained.

Next commands for audio streams will be described. A command getAudioStreamAvailability causes information that describes whether or not a designated audio stream is contained to be obtained. A command getAudioStreamLanguage causes information about a language of a designated audio stream to be obtained. A command getAudioStreamStatus causes the state of a designated audio stream to be obtained. A command setAudioStreamStatus causes a state of a designated audio stream to be designated. States of an audio stream are for example reproduction or non reproduction. A command getAudioStreamAttribute causes an attribute of a designated audio stream to be obtained.

Next commands for sub picture streams subtitle data will be described. A command getSPStreamAvailability causes information that describes whether or not a designated sub picture streams is contained to be obtained. A command getSPStreamLanguage causes a language used in a designated sub picture stream to be obtained. A command getSPDisplayStatus causes a display state of a sub picture stream to be obtained. A command setSPDisplayStatus causes a display state of a sub picture stream to be designated. Display states of a sub picture stream are for example display on off states thereof. A command getSPStreamAttribute causes an attribute of a designated sub picture stream to be obtained. Attributes of a sub picture stream are for example an aspect ratio of 4 3 and a wide screen.

Next commands for the common parameters will be described. In the drawings these commands are denoted by register read write. A command clearReg causes all registers of a memory region of the BD virtual player to be initialized. A command setReg causes a value to be set to a designated register. A command getReg causes a value to be read from a designated register.

Next commands for timers will be described. A command sleep causes a process to be stopped at designated time. A command setTimeout causes a function or a process to be executed after designated time has elapsed. A command setInterval causes a process to be executed at designated intervals. Commands for timers can be designated in the unit of a millisecond. A command clearTimer causes a process of a designated registration timer ID to be stopped. A command pauseTimer causes a timer that has a registration timer ID to be temporarily stopped. A command resumeTimer causes a timer that has a designated registration timer ID to be resumed from the paused state.

As a command for an effect sound a command playSoundEffect sound id causes a designated effect sound to be reproduced.

When commands exemplified in and are described in a post command region and a button command region that will be described later a jump to a predetermined play list can be accomplished. Besides these commands shown in and other commands can be defined.

Next with reference to and commands that use the HTML and ECMA script as a scenario descriptive language will be described.

Next commands for player operations will be described. A command playScenario scenarioNumber scenarioTime causes a scenario designated by scenarioNumber to be reproduced. scenarioNumber is a URI Universal Resource Identifier that represents the location of a file that describes a scenario structure. A command playPlayList playListNumber causes a play list designated by playListNumber to be reproduced. A command playChapterMark playListNumber chapterNumber causes a play list designated by playListNumber to be reproduced from a chapter designated by chapterNumber . A command playPlayItem playListNumber playItemNumber causes a play list designated by playListNumber from a play item designated by playItemNumber . playItemNumber is playItem id . When a value 0 is designated to playItem id a play list to which the play item belongs is reproduced from the beginning.

A command play position object causes the current position to be moved to an adjacent play list or play item. A parameter position is any one of prey next top goUp and tail . A parameter object describes a moving method to a moving object a play list a play item or a chapter .

A command stop causes the reproduction of a scenario to be stopped. In this case the value of the standard register is not held. A command resume causes the reproduction to be resumed from the last stop position. A command playSoundEffect causes a selected effect sound to be reproduced.

Next commands for player states will be described. A command getMenuDescriptionLanguage causes a language of a menu that is displayed to be obtained. A command getScenarioNumber a command getPlayListNumber and a command getChapterNumber cause a scenario number a play list number and a chapter number that are being reproduced to be obtained respectively.

Next commands for video streams will be described. A command setVideoStreamNumber describes a video stream to be decoded. A command getVideoStreamNumber a command getVideoStreamStatus and a command getVideoStreamAttr cause a video stream number a state and an attribute of a video stream that is being reproduced to be obtained respectively. Attributes of a video stream are for example an encoding system a resolution an aspect ratio a display mode in the case that the aspect ratio is 4 3 and presence absence of a closed caption. A command setAngleNumber describes an angle number. A command getAngleNumber causes an angle number that has been selected to be obtained. A command getMaxVideoStream causes a maximum number of video streams to be obtained.

Next commands for audio streams will be described. A command getAudioStreamAvailability causes information that describes whether or not a designated audio stream is contained to be obtained. A command getAudioStreamLanguage causes information about a language of a designated audio stream to be obtained. A command setAudioStreamStatus causes a state of a designated audio stream to be obtained. A command setAudioStreamStatus causes a state of a designated audio stream to be designated. States of an audio stream are for example whether or not it is reproduced. A command getAudioStreamAttribute causes an attribute of a designated audio stream to be obtained.

Next commands for sub picture streams subtitle data will be described. A command getSPStreamAvailability causes information that describes whether or not a designated sub picture stream is contained to be obtained. A command getSPStreamLanguage causes a language used in a designated sub picture stream to be obtained. A command getSPDisplayStatus causes a display state of a sub picture stream to be obtained. A command setSPDisplayStatus describes a display state of a sub picture stream. Display states of a sub picture stream are for example whether or not the sub picture stream is displayed. A command getSpStreamAttribute causes an attribute of a designated sub picture stream to be obtained. Attributes of a sub picture stream are for example whether the sub picture stream is displayed with an aspect ratio of 4 3 or with a wide screen.

Next commands for the common parameters will be described. Commands for the common parameters are represented as commands for register read write in and . A command clearReg causes all registers of a memory region of the BD virtual player to be initialized. A command setReg causes a value to be set to a designated register. A command getReg causes a value to be read from a designated register.

Next commands for timers will be described. A command sleep causes a process to be stopped at designated time. A command setTimeout causes a function or a process to be executed after designated time has elapsed. A command setInterval causes a process to be executed at intervals of designated time. Commands for timers can be designated in the unit of a millisecond. A command clearTimer causes a process that has a designated registration timer to be stopped. A command pauseTimer causes a timer that has a designated registration ID to be temporarily stopped. A command resumeTimer causes a timer that has a designated registration timer ID to be resumed from the pause state.

As a command for a key input a command getPressedKey causes the type of a key that has been input pressed to be obtained.

Next commands for graphics will be described. A command loadGraphics htmlfile ID causes a file designated by htmlfile to be read and the file to be expanded to the graphics plane in a non display state. An ID is assigned to an expanded graphics image and referenced with a command that will be described later. A command showGraphics ID causes an image expanded on the graphics plane by the foregoing command load Graphics htmlfile ID to be displayed. A command hideGraphics ID causes an image designated by ID to be hidden.

Next other commands will be described. A command random input Number num causes a random number from 1 to num to be generated. Random numbers are generated by a unique definition. A command catchEvent eventname eventhandler causes a function designated by eventhandler to be executed when an event designated by eventname takes place.

Next execution of commands that are defined as described above will be described. First of all the case that original commands are used as a scenario descriptive language will be described. When original commands are used as a scenario descriptive language a scenario has two regions for commands including a program having commands that cause the player to be operated. The two regions are referred to as global command region and local global command region.

The global command region has programs that are effective for the entire scenario. For example the global program region describes a program that causes the player to initialize parameters when a disc is loaded into the player and to jump to a play list that composes a menu screen. The local command region describes programs for play lists. Local commands are categorized as four types of commands that are pre commands play item commands post commands and button commands.

A command group a program that is initially read and executed when the disc is loaded into the player is referred to as global commands. The global commands describe for example an advertisement picture trailer and a jump command that jumps to a play list that composes a menu screen. The player reproduces the play list in accordance with the commands.

Next with reference to and reproduction of a play list in the play list reproduction phase will be described. shows an example of which a play list is composed of a single play item. A play list has a pre command region a play item command region and a post command region that describes respective programs. In the play list reproduction phase a pre command of the pre command region is executed at step S . After the pre command has been executed the player enters a play item reproduction phase for play items that compose the play list at step S . In the play item reproduction phase a stream whose start point and end point are designated by a play item is reproduced at step S . When the stream has been reproduced up to the end point the play item command is executed at step S . After the play item command has been executed a post command of the post command region is executed at step S . As a result the play list has been reproduced.

The post command is normally a jump command that describes as a jump command a play list to be reproduced next or a play list that composes a menu screen. When there is no a jump command the player enters the stop state the state B shown in .

When the play list describes a plurality of play items in the play list reproduction phase a pre command is executed at step S . In the next play item reproduction phase a stream is reproduced from the start point to the end point of each play item and a play item command is executed for each play item. In the example shown in a first play item stream is reproduced at step S . Thereafter the corresponding play item command is executed at step S . Thereafter a second play item stream not shown is reproduced at step S . The corresponding play item command is executed at step S . These operations are repeated for the number of the play items. After the last play item stream has been reproduced at step S and the corresponding play item command has been executed at step S the play item reproduction phase is completed. After the play item reproduction phase has been completed a post command is executed at step S . As a result the play list reproduction phase is completed.

According to the embodiment of the present invention scenarios play lists and play items that are executed on the BD virtual player can be hierarchically considered. In other words as shown in one scenario layer is placed under a BD virtual player layer . A play list layer that has one or a plurality of play lists is placed under the scenario layer . A play item PI layer is placed under the play list layer . Each play list may have one or a plurality of play items.

In such a hierarchical structure play lists and play items are executed by the BD virtual player through the scenario layer . Thus when control commands for play lists are described in a scenario branches and so forth of the play lists can be easily accomplished. This applies to play items as shown in .

Next an example of which the HTML and ECMA script are used as a scenario descriptive language will be described. In the following a more practical example of the PBC program that uses the HTML and ECMA script as a scenario descriptive language will be described.

When a scenario is described using the HTML and ECMA script one script file is created for one scenario. When the menu screen is displayed on the graphics plane one HTML file is created for one screen. A script file and an HTML file have extensions js and html respectively. These extensions distinguish these two types of files. A file of a script program that is initially executed when a disc is loaded into a drive device has a fixed file name for example startup.js .

Next as an example a disc having a scenario structure shown in will be considered. This disc has two scenarios Scenario and Scenario. The scenario Scenario causes a menu screen that has a link button to the scenario Scenario to be displayed. When the disc is loaded into the reproducing apparatus the menu screen is displayed. When a button on the menu screen is clicked the scenario Scenario is reproduced. After the scenario Scenario has been reproduced the menu screen is displayed again.

Among those files the file scenario000js is a script file that describes structural information of the scenario Scenario. The file scenario000js describes structural information of the menu screen namely a scenario list screen. The file 000.html is an HTML file that describes layout information of the menu screen . The file 00000.rpls is a play list file that is displayed as a background of the menu screen . The file scenario001.js is a script file that describes structural information of the scenario Scenario. The file 00001.rpls is a play list file that describes information of a play list reproduced in accordance with the scenario Scenario.

In contents files a clip information file .clip and an AV stream file .m2ts that are reproduced in accordance with the play list files 00000.rpls and 00001.rpls are omitted.

Each file shown in is recorded on a disc in accordance with a directory structure as shown in . The file startup.js is placed immediately under the directory BDAV. The directory SCRIPT is placed under the directory BDAV. Script files for example Scenario000.js and HTML files for example file 000.html that describe structural information of a scenario are placed under the directory SCRIPT.

The file scenario000js causes a moving picture of the play list 00000.rpls to be displayed on the moving picture plane . In addition the file scenario000js causes the menu screen to be displayed on the graphics plane at timing of a mark detected while the play list 00000.rpls is being reproduced.

In a portion surrounded by tags and event handlers for mouse operations on Moverhandler f on Mounthandler f and on Mclickhandler f are defined. In the example shown in image data 201.png 200.png and 202.png as button images are correlated with the event handlers on Movehandler f on Mouthandler f and on Mclickhandler f . In addition the event handler on Mclickhandler f causes the scenario file scenario001.js to be reproduced.

In a portion surrounded by tags and image data displayed on the graphics plane of the menu screen is described. File names 100.png and 200.png of image data corresponding to image names described in the portion surrounded by the tags and are described. When events on Mouseover on Mouseout and onclick take place for the image data referenced by the image name scenario000 in accordance with an operation of a pointing device such as a mouse event handlers on Moverhandler on Mouthandler f and on Mclinckhandler f are executed respectively.

The event on Mouseover is an event that takes place when the cursor is placed at a designated region. The event on Mouseout is an event that takes place when the cursor is left from a designated region. The event onclick is an event that takes place when a predetermined operation for example a clicking operation of the pointing device for example the mouse is performed while the cursor is placed in a designated region.

Next operations shown in to will be described. When the disc is loaded into the reproducing apparatus the file startup.js is read from the disc. The file scenario000.js is called from the file startup.js . When the scenario scenario000 described in the file scenario000.js is executed a moving picture of the play list 00000.rpls is displayed on the moving picture plane in accordance with the description shown in .

The file 000.html is called at timing corresponding to a mark described in the play list 00000.rpls . The menu screen that displays a table of scenarios is expanded on the graphics plane and displayed in accordance with the description of the file 000.html . The menu screen is also composed of one scenario which is the scenario scenario000 .

On the menu screen the image file 100.png of a character string for example Menu and the image file 200.png of a character string for example Scenario001 are placed. These image files are placed on the graphics plane and these character strings are displayed. On the moving picture plane displayed as a background of the graphics plane a moving picture of the play list 00000.rpls is displayed. The moving picture of the play list 00000.rpls on the moving picture plane and the menu screen of the file 000.html on the graphics plane are superimposed and displayed on the same screen. As a result the menu screen is displayed with a background of the moving picture.

At that point predetermined transparency is designated to a screen the menu screen on the graphics plane . The menu screen can be transparently displayed on the moving picture on the moving picture plane . In this example marks are described at the beginning and the end of the play list 00000.rpls . When the play list 00000.rpls is reproduced the menu screen is displayed. After the play list 00000.rpls has been reproduced the menu screen is cleared.

On the menu screen a cursor that can be moved by user s key operations of the remote controller is displayed. When the cursor is superimposed with the image file 200.png the event Mouseover defined in the file 000.html takes place. When the event Mouseover takes place the event handler on Movehandler corresponding to the event on Mouseover is executed so as to represent the state that the image file 200.pn is focused. When the event handler on Moverhandler is executed the image file 200.png is replaced with the image file 201.png . The image file 201.png is a button image or the like whose color is different from the image file 200.png .

When the cursor is placed on the image file 201.png if the user performs a clocking operation by a predetermined key of the remote control commander the event handler on Mclickhandler corresponding to the event onclick is executed. As a result the image file 201.png is replaced with the image file 202.png that represents the state that the image file 201.png has been selected. The image file 202.png is a button image that virtually represents the state that a button was pressed.

When event handlers corresponding to events focused and clicked are described in the file 000.html a menu screen that has an interactive function that responds to a user s input is accomplished.

When a button image of Scenario0001 is clicked on the menu screen a reproducing process for the scenario Scenario001 is performed. When the file scenario001.js is executed the scenario Scenario001 is reproduced. As shown in a method playPlayList 0001.rpls described in the file scenario001.js is called. As a result the play list 00001.rpls is reproduced.

After the play list 00001.rpls has been reproduced a play list reproduction end event PlayListEnded takes place. The event handler playScenario scenario000.js corresponding to the event causes the scenario Scenario000.js to be reproduced. In this example after the scenario Scenario001 has been reproduced the menu screen is displayed again.

While the scenario Scenario001 is being reproduced even if a key designated by keyID is operated the scenario Scenario000.js is reproduced and the menu screen is displayed.

The descriptions of the HTML and ECMA scripts shown in to are just examples. In other words the present invention is not limited to such examples. The HTML and ECMA scripts have flexibility in their descriptions. Thus even if the HTML and ECMA scripts are partly changed similar operations can be accomplished.

Next syntaxes of files in the case that original commands are used as a scenario descriptive language will be described. First of all a method for recording commands and databases that describe a scenario to a disc will be described. shows an example of a file management structure in the case that original commands are used as a scenario descriptive language.

On the disc one root directory is created. A portion under the root directory is managed by one reproducing system. Under the root directory a directory BDMV is placed. As shown in a plurality of directories BDMV can be placed under the root directory.

Under the directory BDMV two files scenario.hdmv and entrylist.data are placed. In addition a plurality of directories PLAYLIST CLIPINF and STREAM are placed.

The field type indicator has a data length of 32 bits. The field type indicator has a predetermined character string that describes that the file is scenario.hdmv . The field version number has a data length of 32 bits for a version number. A field Scenario start address has a data length of 32 bits for an unsigned integer of a value that represents the position of the block Scenario with the relative number of bytes from the beginning of the file scenario.hdmv .

A block Autoplay starts from the 41 st byte fixed position of the file. The block Autoplay describes a program that is executed when an initial access is performed reproduction for the disc is initially performed for example the disc is loaded . The block Autoplay is followed by any number of padding words padding word that allow a space to be formed after the block.

A block Scenario describes a scenario as explained above. The block Scenario describes information about the reproduction order of play lists and a local command region for each play list.

A field length describes a value that represents the length immediately after the end of the field length to the end of the block Scenario in bytes. A field number of PlayLists describes the number of play lists that composes the scenario. The field number of PlayLists is followed by data of each play list. Data for each play list is repeated the number of times designated by a loop counter i in a for loop the maximum value of i being represented by the field number of PlayLists.

A field Pre Command start id describes a start number of a pre command in a command table a pre command is executed before a play list is reproduced . A number described in the field Pre Command start id describes a loop counter j in a for loop that describes a field PI Command i that will be described later. Likewise a field Post Command start id describes a start number of a post command in the command table a post command is executed after a play list is reproduced . A number described in the field Post Command start id describes the loop counter j in the for loop that describes the field PL Command j that will be described later.

A field Number of Pre Commands describes the number of pre commands that compose a program. Pre commands are executed before a play list is reproduced. Likewise a field number of Post Commands describes the number of post commands that composes a program. Post commands are executed after a play list has been reproduced. These programs are described in a command table that will be described later.

A field number of PlayItems describes the number of play items that composes the play item. A field PI Command start id represents a start number of a play item command in a command table. A play item command is executed after the play item has been reproduced. A number described in the field PI Command start id describes a loop counter j in a command table that will be described later. A field number of PI Commands describes the number of play item commands which are executed after the play item has been reproduced. Commands after the position described in the field PI Command start id until the number of commands described in the field number of PI Commands are executed after the play item has been reproduced.

A field number of PL Commands describes the number of commands in a command table preceded by the field number of PL Commands. The command table has a for loop that describes a field PL Command j . Commands in the command table are assigned number j. The number j corresponds to the loop counter j in the for loop that describes the command table. A field PL Command j describes one command. The number j is referenced from the foregoing field Pre Command start id the field Post Command start id and the field PI Command start id.

The field type indicator has a data length of 32 bits for a predetermined character string that describes entry points of a title and a menu. A field version number has a data length of 32 bits for a version number. The field ScenarioEntry start address has a data length of 32 bits for an unsigned integer value that describes the start position of the block ScenarioEntry with the relative number of bytes from the beginning of the field entrylist.data .

The field BDMV name has a fixed data length of 255 bytes. The name of the directory BDMV is described for a length described in the field BDMV name length after the beginning of the field BDMV name.

When three movies are recorded on one disc only one scenario that defines the reproduction order of the movies exists on the disc. However the user would see them as if three titles were recorded on the disc. Alternatively a list of three titles would be displayed. Including a title menu that allows the user to select one of the titles he or she would see them as if four titles were recoded. Since the user considers a menu screen as one picture unit or one sound unit according to the embodiment of the present invention a menu screen is treated as one type of a title.

Since the unit of a scenario that defines a link of play lists is different from the unit that the user recognizes data as picture and audio it is necessary to define search points in a scenario. A search point in a scenario is referred to as title entry. The block ScenarioEntry describes information of a title entry.

Returning to a field length has a data length of 32 bits for an unsigned integer that describes the length immediately after the field length until the end of the block ScenarioEntry in bytes. A field name character set describes a character set of a field TopMenu name and a field Title name that are preceded by the field name character set.

The next block Top menu PL describes an entry point to a play list or a play list group that composes a menu displayed when the user presses the title menu key of the remote controller. One scenario has one top menu. The top menu is used to present for example titles to the user. A sub menu on which the user can set audio and subtitles can be placed as a lower menus of the top menu. A sub menu is also referred to as stream setup menu.

In short a field flags is a region that describes attribute information of a top menu. A field TopMenu ref to PlayList file name describes a play list that composes a top menu or a play list that is an entry to a play list group. A field TopMenu ref to PlayItem id describes the number of a play item from which the top menu starts in a play list described in the field TopMenu ref to PlayList file name. When the play list is reproduced from the beginning the value of the field TopMenu ref to PlayItem id is 0 . A field TopMenu name length represents the length of the name assigned to a top menu. A field TopMenu name describes a character string of the name assigned to a top menu.

The block Top Menu PL describes information about a title. A field number of Titles describes the number of title search points title entries in a for loop immediately preceded by the field number of Titles. In short a field flags is a region that describes attribute information about a title. A field Title ref to PlayList file name describes the file name of a play list that includes a title entry. A field Title ref to PlayItem id is used when a title starts from a particular play item of a play list described in the field Title ref to PlayList file name. A field Title name length describes the length of the name assigned to a title. A field Title name describes a character string of the name assigned to a title.

Information about a sub menu is described. Stream Setup Menu is followed by an entry point to a play list or a play list group that composes a stream setup menu namely a sub menu for each play item. A stream setup menu can be used for each play list to select such as sound subtitles or angle. For example when the buttons and shown in are pressed a sub menu is displayed as a screen.

A field number of PlayLists describes the number of play lists used for a stream setup menu. The value of the field number of PlayLists is used as the number of loop times of a for loop immediately preceded by the field number of PlayLists. In short a field SSMenu flags is a region that describes attribute information about a stream setup menu. A field SSMenu ref to PlayList file name describes a play list that composes a stream setup menu or a play list that is an entry of a play list group. A field SSMenu ref to PlayItem id describes the number of a play item from which a stream setup menu starts in a play list described in the field SSMenu ref to PlayList file name. When a play list is reproduced from the beginning the value of the field SSMenu ref to PlayItem id is 0 .

A block PLControlInfo describes attribute information about the play list. A block PlayList describes information about a play item that composes the play list. A block PlayListMark describes information of a mark added to the play list.

In the file xxxxx.mpls since start addresses of the block PLControlInfo PlayList and PlayListMark are followed by these blocks padding data padding word can be placed before and or after each block in a desired length. The start position of the first block PLControlInfo is fixed at the 41 st byte from the beginning of the file.

A field PL playback type describes a value as shown in . The field PL playback type describes whether the play list is a regular play list that is sequentially reproduced a play list of which play items are reproduced at random or a play list of which play items are shuffled and reproduced. The random shuffle is designated in the unit of a play list. One play list should not describe a regularly reproduced play item and a randomly shuffled play item block. When the disc is a reproduction only recording medium the producer may designate a random reproduction or a shuffle reproduction. At that point such information is required.

A field playback count describes the number of times of reproduction of a play item when the play list is a random reproduction play list or a shuffle reproduction play list. A field playback count describes the number of play items that are randomly reproduced or shuffle reproduced.

A field PL UOP mask table describes information about restriction of user s operations. When the user is prohibited from performing operations such as playback fast forward fast rewind and so forth while a play list is being reproduced this region is properly described. When a proper value is described in the field PL UOP mask table an alarm notice a copyright notice and so forth can be prevented from being skipped even if a fast forward operation or the like is performed.

A field PL random access mode describes a value shown in . The field PL random access mode describes whether a random access of which any position of the play list is jump reproduced from another play list can be performed. When there is a play list that the disc producer wants the user to see the value of the field PL random access mode is set to 0x1 . When this play list is jump reproduced fast forward operation fast rewind operation reproduction from any time and so forth are prohibited. At that point the play list is reproduced from the beginning. When the disc is a reproduction only recording medium scenes such as a logo of a contents production company and precautions to be seen to the user may be recorded thereon. The field PL random access mode describes information necessary for prohibiting such scenes from being skipped against variable speed reproduction operation or the like. The field PL UOP mask table describes a restriction to the user against an operation for the player while a play list is being reproduced. In contrast the PL random access mode describes a restriction to the user against a jump reproduction for the current play list from another play list.

A field PlayList duration describes a reproduction duration of a play list. A field PlayList name describes a play list name having an effective length with a value described in the field PlayList name length. A field PlayList detail describes detailed information about a play list having an effective length with a value described in the field PlayList detail length.

A block PlayItem describes information of a play item. A block SubPlayItem describes information of a sub play item.

A field Clip codec identifier describes an encoding system of a clip referenced by the play item. According to the embodiment the field Clip codec Identifier describes a fixed value M2TS2 . In other words according to the embodiment the encoding system of a clip referenced by a play item is fixed to a system represented by the value M2TS .

A field connection condition is information that describes in what manner the play item and the next play item are connected. The field connection condition describes whether or not play items can be seamlessly reproduced.

A field ref to STC id describes a sequence STC sequence in a clip referenced by the play item. The sequence STC sequence has a unique structure of the blu ray disc standard that describes that PCR Program Clock Reference as a reference of the time base of an MPEG2 TS Transport Stream represents a continuous range. The sequence STC sequence describes a number STC id that is unique in the clip. Since a continuous time base can be defined in the sequence STC sequence the start time and the end time of a play item can be uniquely designated. In other words the start point and the end point of each play item should be present in the same sequence STC sequence. A field ref to STC id describes a sequence STC sequence with a number STC id.

Fields IN time and OUT Time describe time stamps pts presentation time stamp of the start point and the end point of the play item in the sequence STC sequence respectively.

A field PI UOP mask table describes data about a restriction against user s operations. Even if the user performs such a restricted operation the player should not respond to that. To restrict a fast forward operation while a menu screen is being displayed data about a restriction against such an operation is described in the field PI UOP mask table .

The field PI UOP mask table is described for each play item. The field PI UOP mask table describes information that has the same object as the field PL UOP mask table of the foregoing block PLControlInfo which describes information about reproduction of a play list. A user s operation can be prohibited in either a play list or a play item. A user s operation during reproduction of a play item is prohibited depending on the result of an OR operation of information of a play list and information of a play item.

In short a field PID filter is a table that describes the priority in streams reproduced by play items.

A field PI random access mode describes a value as shown in . The field PI random access mode describes whether or not a random access can be performed for jump reproduction of any position of a play item. When there is a play list that the disc producer side wants the user to see a value 0x1 is described in the field PI random access mode. Thus when reproduction of a play item is started the user can be prohibited from performing a fast forward operation a rewind operation a reproducing operation from any time or the like.

A field still mode describes whether or not after reproduction of a play item is started the reproduction is temporarily stopped. The field still mode describes a value as shown in . When the value of the field still mode is 0x1 it describes that reproduction of the play item is temporarily stopped for a period described in the next field still time. Thus still pictures can be successively displayed at intervals of a predetermined period like a slide show. In this case each still picture is a play item. In addition to a setting for a designated time period a setting for a non designated time period of which reproduction is stopped until the user inputs data pause setting can be described in the field still time. When the value of the field still mode is 0 2 the pause setting can be performed.

When the value of the foregoing flag is multi angle is for example 1 the play item is a multiple angle play item. After Angle information about multiple angles is added.

A field number of angles describes the number of angles. A field is seamless angle change describes a value as shown in . The field is seamless angle change describes whether or not each angle has been recorded on the disc so that each angle can be seamlessly changed.

The next for loop describes information about clips that compose angles. A field Clip Information file name in the for loop describes a character string of a field name of a clip information file that has an extension clpi that corresponds to each clip that the play item references in the relation of 1 to 1. A field ref to STC id describes a sequence SC sequence of each clip that the play item references.

An angle corresponding to a value angle id 0 has been defined in the first half part of the block PlayItem like a regular play item that is not an angle play item. Angles after the value angle id 1 are defined in the for loop. The for loop does not contain an angle corresponding to the value angle 0.

A field Clip codec identifier describes an encoding system of a clip that the sub play item references. According to the embodiment the field Clip codec Identifier is fixed to a value M2TS .

A field is repeat flag describes a value as shown in . The field is repeat flag is a flag that describes whether or not the sub play item is repeatedly reproduced not in synchronization with a main play item main path . When the value of the field is repeat flag is 1 the sub play item is repeatedly reproduced until the main play item has been reproduced not in synchronization therewith. When the value of the field is repeat flag is 0 the sub play item is reproduced once in synchronization with the main play item.

If the sub play item is a sub play item for only audio when 1 is described in the field is repeat flag BGM Back Ground Music can be reproduced.

A field SubPlayItem type describes what characteristic the sub play item has. For example when the value of the field SubPlayItem type is 1 it describes that the sub play item is a sub play item for only audio.

A field ref to STC id describes a sequence STC sequence of a clip that the play item references. Fields SubPlayItem IN time and SubPlayItem OUT Time describe time stamps pts presentation time stamp of the start point and end point of the sub play item in the sequence STC sequence.

When the value of the foregoing field is repeat flag is 0 and it represents that the sub play item is reproduced in synchronization with the main play item the field sync PlayItem id and the field sync start PTS of PlayItem describe from what time of the main play item the sub play item is reproduced in synchronization therewith.

As shown in the field sync PlayItem id describes a play item of a main path PlayItem 1 . The field sync start PTS of PlayItem describes time of the main play item at which reproduction of a sub play item is started t . A field SubPlayItem IN time and a field SubPlayItem OUT time describe a period for which a click as a sub play item is reproduced.

A field application type describes how a clip AV stream that has an extension m2ts has been multiplexed. The field application type describes a value as shown in . The field application type describes whether the clip AV stream is a normal video stream or a stream that has been multiplexed suitably for a still picture.

More practically in the example the value of the field application type is 1 and it describes that the file of the corresponding clip AV stream complies with the rule of the BDMV transport stream according to the embodiment. With the clip AV stream a normal moving picture is reproduced.

When the value of the field application type is 2 it describes that the file of the corresponding clip AV stream complies with the rule of the BDMV transport stream for a still picture that synchronizes with the reproduction of audio. The clip AV stream is a file in accordance with for example the MPEG2 format. In the clip AV stream video data and audio data have been multiplexed. The video data has a structure of which I pictures of the MPEG2 are arranged as still pictures. As a result the still pictures can be reproduced like a slide show on the time base of audio. This reproduction is referred to as time base slide show.

When the value of the field application type is 3 it describes that the file of the corresponding clip AV stream complies with the rule of the BDMV transport stream for still pictures reproduced not in synchronization with audio. The audio data and the video data are structured as different files. While the audio data is being reproduced the video data is displayed in such a manner that still pictures are changed at any intervals or as designated by the user. The video data can be structured in such a manner that for example I pictures of the MPEG2 are arranged as still pictures. Such reproduction is referred to as browsable slide show.

When the value of the field application type is 0 the corresponding clip AV stream does not comply with the rule of the BDMV transport stream.

It is assumed that multiplexing suitable for displaying still pictures allows an application such as a slide show of still pictures to be easily accomplished. In such an application when one still picture is capsulate multiplexed with subtitles and graphics data to be superimposed they can be easily read.

When a still picture is multiplexed with subtitles and graphics in the same manner as a normal moving picture subtitles to be displayed along with a still picture are multiplexed with picture data of a preceding still picture namely so called multiplexing phase difference takes place . As a result unless stream data is read for a long time a still picture superimposed with subtitles and graphics cannot be displayed.

According to the embodiment of the present invention graphics data for video data and subtitles is contained in TS Transport Stream packets of the MPEG 2 system standard. One TS packet is composed of 188 bytes. The foregoing video data and graphics data are divided so that they are contained in TS packets. When a packet of subtitle data corresponding to particular still picture data called picture P is preceded by a packet of the next still picture called picture P to display subtitles corresponding to the picture P data of the picture P should have been read.

When a particular still picture is multiplexed with only associated subtitles and graphics capsulated a stream that is not affected by other data can be created. When such an operation is repeated for each still picture and streams are connected one stream of which data of each still picture and associated subtitles and graphics data is connected in series can be obtained. The stream that has been multiplexed in such a manner is referred to as still picture BDMV stream.

There are two types of BDMV streams for still pictures that are time base slide show and browsable slide show. According to the embodiment the two types are distinguished with different numbers of the field application type.

When a still picture and associated subtitles and graphics are capsulated and recorded accessibility of which still pictures are changed and reproduced is improved.

Returning to a field Clip stream type describes the type of a clip AV stream. The value of the field Clip stream type may be fixed to 1 that represents a normal clip in the reproduction only disc standard. A field TS recording rate describes a record rate of a clip AV stream file in bytes second. A field num of source packets describes the number of packets contained in a clip AV stream. A field BD system use and a block TS type info block do not relate to the present invention. These description will be omitted.

A field num of STC sequences describes the number of sequences STC sequence of the sequence ATC sequence. When a reproduction only medium is used since the number of sequences STC sequence is 1 the description thereof will be omitted. A field offset STC id describes a fixed value 0 . A field PCR PID describes a PID of a TS packet that has a PCR Program Clock Reference of an MPEG2 TS. A field SPN STC start describes the beginning of a sequence STC sequence with a packet number. When the number of sequences STC sequence is 1 since the field SPN STC start accords with the beginning of the clip AV stream file the value of the field SPN STC start is 0 . A field presentation start time and a field presentation end time describe a valid range of the clip AV stream. The range described in the field presentation start time and the field presentation end time can be referenced from a play item.

When data is reproduced from any time by referencing the CPI as such a database with the reproduction time the address of the reproduction position in the file can be obtained. Since this address is the beginning at which data can be decoded the player can read data therefrom and quickly display a picture.

A start position at which data can be decoded in this example the start position of a GOP is described in the CPI and is referred to as EP Entry Point entry.

A field CPI type describes the type of CPI. The field CPI type describes a value as shown in . According to the present invention the type of the field CPI type describes CPI for a reproduction only medium. In reality the value of the field CPI type is 8 that describes an EP entry map for BDMV EP map type for BDMV .

The structure of the map EP map for the recordable medium is almost the same as the structure of the map EP map for the reproduction only medium. According to the embodiment to reduce the data amount and speed up searches coarse searches and fine searches are performed for individual values. Thus the internal structure of the map EP map is divided into two for loops corresponding to coarse searches and fine searches. Consequently the map EP map for the reproduction type disc is more complicated than a simple table that correlates PTSs of the first I pictures of GOPs and addresses in a file .

A field EP fine table start address describes the position of a table used for fine searches. The next for loop describes tables for coarse searches. The for loop describes fields PTS EP coarse and SPN EP coarse. A field ref to EP fine id describes a table number for fine searches referenced from coarse searches. The fields PTS EP coarse and SPN EP coarse describe high order bits of a PTS and an SPN.

The for loop is followed by a padding word. The padding word is followed by a for loop that describes fields PTS EP fine and SPN EP fine. In addition the for loop describes a flag is angle change point and a field I end position offset. The flag is angle change point describes whether each EP point corresponds to an angle changeable point when the clip AV stream has a multiple angle structure.

All operations of the player decoder are controlled by a CPU Central Processing Unit not shown . Streams and data flows of individual portions of the player decoder are monitored and controlled by the CPU.

It is assumed that unless otherwise specified a scenario described with original commands is executed by the player decoder .

When the disc is loaded into the drive device not shown as described above the file scenario.hdmv and the file entrylist.data are reproduced. In accordance with the descriptions of the file scenario.hdmv and the file entrylist.data other necessary files are read from the disc and thereby a content recorded on the disc is reproduced. For example in accordance with the descriptions of the file scenario.hdmv and the file entrylist.data moving picture data displayed on the moving picture plane image data displayed on the subtitle plane and the graphics plane a play list file and so forth are read from the disc.

In the following description among those data that is read from the disc streams such as moving picture data sub pictures subtitle data and sound data that should be continuously processed are referred to as real time streams. In contrast non real time data such as scenario files and play list files that are not required to be continuously processed are referred to as store objects. The store objects are stored in a memory or the like and expanded thereon. Store objects stored in the memory are expanded when necessary.

The player decoder has two systems of input channels that are channel 1 and channel 2 . A store object is input to an input terminal of the input channel 1 . A real time stream is input to an input terminal of the input channel 2 . Alternatively a store object may be input to the input terminal . According to the embodiment a real time stream and a part of a store object that are input to the input terminal are for example MPEG2 TSs.

A store object that is input to the input terminal is not limited to data that is read from a disc. For example the player decoder would be provided with a network connecting function. At that point a store object obtained through the network would be input to the input terminal . Image data for button images new scenario data and so forth would be obtained through the network and input from the input terminal . Alternatively data such as subtitle data that is treated as a real time stream would be obtained through the network and input from the input terminal .

A real time stream that is input to the input terminal is not limited to an MPEG2 TS. As long as a real time stream can be transmitted in the unit of a packet and multiplexed with video data audio data still picture data or the like a stream that has another format can be input. At that point a PID filter that will be described later is used as a demultiplexer that demultiplexes video data audio data still picture data or the like.

When the rotation speed of the disc in the drive device is increased for example twice and the read transfer speed of the disc is increased the reading operations for two systems of the channels 1 and 2 drive device from the disc are performed in time division basis.

Next the system of the input channel 1 will be described. A store object that is input to the input terminal is input to a switch circuit . When a program code of an ECMA script an HTML file or the like as a store object is input the switch circuit selects an output terminal A. The input program code is stored in a code buffer .

When image data as a store object is input the switch circuit selects an output terminal B. As a result the input image data is input to a switch circuit . When a real time stream that is input to the input terminal does not contain image data displayed on the subtitle plane or the graphics plane the switch circuit selects an input terminal A. The image data that is input from the switch circuit is stored in a contents buffer .

Likewise when image data displayed on the subtitle plane or the graphics plane is contained in a real time stream that is input to the input terminal the switch circuit selects an input terminal B. As a result the image data is stored in the contents buffer . Store objects stored in the code buffer and the contents buffer are read when necessary and supplied to a multimedia engine .

The image data of the store object stored in the contents buffer is also supplied to a graphics decoder A and a graphics decoder B through switch circuits and respectively.

The multimedia engine comprises an XML parser A a script interpreter B and a graphic renderer C. The multimedia engine may be composed of independent hardware. Alternatively the multimedia engine may be accomplished by a process of a predetermined program that a CPU not shown executes.

The XML parser A has a function for parsing an XML Extensible Markup Language document. In addition the XML parser A can also parse an HTML document. An HTML document parsed by the XML parser A is converted into a format that can be executed by the player decoder . The script interpreter B analyzes an ECMA script and converts it into a format that can be executed by the player decoder . The graphic renderer C decodes image data and obtains a format that can be expanded on the subtitle plane and the graphics plane .

The multimedia engine performs processes for the XML parser A the script interpreter B and the graphic renderer C with a work memory of a buffer . For example the XML parser A and the script interpreter B uses a code buffer of the buffer . The graphic renderer C uses a graphics buffer D of the buffer . The buffer further comprises a font buffer B that stores font data used to display a character string and a tree buffer C that stores the parsed result of the HTML document by the XML parser A in a hierarchical tree structure.

When for example a combination of an HTML document and an ECMA script is used as a scenario descriptive language an ECMA script is read from the code buffer and used for the multimedia engine in accordance with the description of the ECMA script. When necessary the multimedia engine reads another ECMA script and an HTML document from the code buffer and reads image data from the contents buffer . Data that is stored in the code buffer and the contents buffer can be stored in the code buffer and the contents buffer until the data becomes unnecessary. Thus data stored in the code buffer and the contents buffer can be repeatedly read when necessary.

In addition the multimedia engine performs a demultiplexing process for the plurality of types of input data a JavaVM Java registered trademark virtual machine function and so forth. Moreover the multimedia engine receives a user s input from a remote control commander a pointing device or the like and performs a process in accordance with the user s input. The user s input is supplied to the graphics decoder graphics decoder A the graphics decoder B an audio decoder an MPEG video decoder and a system decoder that will be described later.

Image data processed by the graphic renderer C is supplied to a subtitle plane and a graphics plane through switch circuits and respectively. In this example it is assumed that image data supplied to the subtitle plane and the graphics plane has the PNG format. Timing at which the image data is supplied to the planes and is controlled by the multimedia engine .

The subtitle plane and the graphics plane correspond to the foregoing subtitle plane and graphics plane respectively. A moving picture plane corresponds to the foregoing moving picture plane . Each of the subtitle plane the graphics plane and the moving picture plane is composed of for example a frame memory.

The multimedia engine supplies a control signal that causes one of the moving picture plane the subtitle plane and the graphics plane to be selected to a presentation processor that will be described later. Likewise the multimedia engine supplies a control signal that controls an output of an audio stream to a presentation processor that will be described later.

Next the system of the input channel 2 will be described. A real time stream that is input as an MPEG2 TS to the input terminal is supplied to the PID filter . The PID filter extracts a PID Packet Identification from the MPEG2 TS transport stream and detects an attribute of a stream contained in a transport packet. The PID filter separates the input real time stream into corresponding systems for each transport packet in accordance with the attribute of the stream.

When a transport packet is a packet in which image data of a store object is contained the transport packet is temporarily stored in a buffer TBn A. The transport packet is read at predetermined timing and input to the switch circuit through the input terminal B that has been selected. Thereafter the transport packet is stored in the contents buffer through the switch circuit .

When the PID filter has determined that the transport packet contains sub picture data in accordance with the PID the transport packet is temporarily stored in a buffer TBn B and a buffer Bn B. The transport packet is read at predetermined timing and input to the switch circuit through an input terminal B that has been selected. The transport packet is supplied to the graphics decoder A through the switch circuit .

The graphics decoder A removes header information from the supplied transport packet decodes sub picture data contained in the transport packet and obtains image data for subtitles or the like. The image data is input to an input terminal B of the switch circuit and expanded to the subtitle plane through the switch circuit .

When subtitle data is obtained through a network and then input to the input terminal the subtitle data is stored in the contents buffer through the switch circuit and the switch circuit . An input terminal A of the switch circuit is selected. As a result the subtitle data is supplied from the contents buffer to the graphics decoder A .

When the PID filter has determined that a transport packet contains graphics data in accordance with the PID the transport packet is temporarily stored in a buffer TBn C and a buffer BnC. The transport packet is read at predetermined timing and input to the switch circuit through an input terminal B that has been selected. The transport packet is supplied to the graphics decoder B through the switch circuit .

The graphics decoder B removes header information from the supplied transport packet decodes graphics data contained in the transport packet and obtains graphics data. The image data is input to an input terminal B of the switch circuit at predetermined timing and expanded to the graphics plane through the switch circuit .

The function of the graphics decoder A is not largely different from the function of the graphics decoder B . That means that there are two systems of graphics decoders that independently operate. In other words it is considered that subtitle data and graphics data can be independently decoded. In a real implementation a high speed graphics decoder would be used on time division basis as if two virtual systems of graphics decoders existed.

When the PID filter has determined that a transport packet contains audio data in accordance with the PID the transport packet is temporarily stored in a buffer TBn D and a buffer BnD. The transport packet is read at predetermined timing and supplied to the audio decoder . Audio data contained in the transport packet is compression encoded in accordance with for example a system based on the MPEG.

The audio decoder also has for example a linear PCM Pulse Code Modulation audio decoder . The audio decoder removes header information from the input transport stream decodes compression encoded audio data contained in the transport packet and obtains linear PCM audio data.

The linear PCM audio data that is output from the audio decoder is input to the presentation processor for audio. In the presentation processor a sound effect is added to the linear PCM audio data under the control of the multimedia engine and then obtained from an output terminal .

When the PID filter has determined that a transport packet contains moving picture data in accordance with the PID the transport packet is temporarily stored in a buffer TBn E a buffer MBn and a buffer EBn read at predetermined timing and supplied to the MPEG video decoder . The moving picture data contained in the transport packet has been compression encoded in accordance with the MPEG2 system.

The MPEG video decoder removes header information from the supplied transport packet decodes moving picture data that has been compression encoded in accordance with the MPEG2 system and obtains base band moving picture data.

The moving picture data that is output from the MPEG video decoder is input to an input terminal A of a switch circuit . In addition the moving picture data is input to an input terminal B of a switch circuit through a buffer . In the switch circuit the input terminals A and B are selected at predetermined timing. Output moving picture data is expanded on the moving picture plane .

When the PID filter has determined that the transport packet contains system information in accordance with the PID the transport packet is supplied to the system decoder through buffers TBn F and Bsys . The system decoder removes header information from the supplied transport packet and extracts the system information therefrom. The system information is supplied to for example a CPU not shown .

Image data on the subtitle plane is supplied to a palette that corresponds to the foregoing palette . The palette has 256 colors. The palette is referenced with an index. RGB data is output. In addition transparency data is extracted. The RGB data is converted into YCbCr data by an RGB YCbCr converting circuit that corresponds to the foregoing RGB YCbCr converting circuit . The YCbCr data and the transparency data are supplied to the presentation processor .

Image data on the graphics plane is supplied to a palette that corresponds to the foregoing palette . The palette has 256 colors. The palette is referenced with an index. As a result RGB data is output. In addition transparency data is extracted. The RGB data is converted into YCbCr data by an RGB YCbCr converting circuit that corresponds to the foregoing RGB YCbCr converting circuit . The YCbCr data and the transparency data are supplied to the presentation processor .

An output of the moving picture plane is supplied to the presentation processor through an up down converter .

The up down converter is a circuit that converts the resolution of the image. The up down converter converts for example a HD High Definition image having a high resolution into an SD Standard Definition image having a standard resolution.

The presentation processor performs an alpha blending process using transparency of image data of the subtitle plane subtitle plane and transparency of the graphics plane graphics plane described in .

The presentation processor combines image data of the moving picture plane and image data of the subtitle plane in accordance with the transparency that has been set to the image data of the subtitle plane . In addition the presentation processor combines the image data of which the moving picture plane and the subtitle plane have been combined and the image data of the graphics plane in accordance with the transparency that has been set to the image data of the graphics plane . The image data of which the image data of the graphics plane the image data subtitle data of the subtitle plane and the image data of the moving picture plane have been combined is obtained from an output terminal .

In the foregoing description a graphics decoder A decodes subtitles as sub picture data and supplies the decoded data to the subtitle plane . It should be noted that subtitles may be supplied in another method. For example subtitles may be supplied as character code such as text data. The character code is converted into bit map data for a character string by referencing font data stored in the font buffer B.

The font data is reproduced from for example a disc and input as a store object to the input terminal . Thereafter the font data is stored in the code buffer through the switch circuit . Thereafter the font data is supplied from the code buffer to the font buffer B through the multimedia engine .

A character code for subtitles is reproduced from for example a disc input as a store object from the input terminal and stored in the contents buffer through the switch circuits and . Thereafter the character code is input as a real time stream from the input terminal and supplied to the switch circuit through the PID filter and the buffer TBn A and stored in the contents buffer . The character code is read from the contents buffer and supplied to the multimedia engine .

Display timing of the character code is controlled by a program. The multimedia engine references the font buffer B in accordance with the character code that is displayed at the display timing of the character code and selects corresponding font data. When the character code is 0x41 0x42 0x43 . . . where 0x is followed by a numeric value in hexadecimal notation font data for characters A B C . . . is selected. Based on the font data the text style and glyph shape are varied so as to generate bit map data having a size designated by the program referred to as rendering .

The generated bit map data is supplied to the subtitle plane through the switch circuit . This is because the subtitles should be synchronized with a moving picture on the moving picture plane .

The character code may be rendered by dedicated hardware instead of the multimedia engine and the CPU of the system. The font data that the character code references is not limited to font data that is reproduced from a disc. Alternatively the font data may be obtained through the network. The font data may be pre stored in a ROM Read Only Memory of hardware of the player. The user may be able to select a type of font data.

When subtitles are supplied as character code the data amount of the subtitles displayed is much smaller than that of subtitle data that is supplied as image data.

In the foregoing description each portion of the player decoder is composed of hardware. However the present invention is not limited to such an example. For instance the player decoder can be accomplished by a process of software. In this case the player decoder can be operated on a computer device. The player decoder can be accomplished by a combination of hardware and software. For example the audio decoder and the MPEG video decoder may be composed of hardware. The rest of the player decoder may be composed of software.

A program that causes a computer device to execute the player decoder composed of only software or a combination of hardware and software is recorded on a recording medium for example a CD ROM Compact Disc Read Only Memory and supplied therewith. The CD ROM is loaded into a CD ROM drive of the computer device. The program recorded on the CD ROM is installed to the computer device. As a result the foregoing process can be executed on the computer device. Since the structure of the computer device is well known the description thereof will be omitted.

Next a user interface according to an embodiment of the present invention will be described. is a schematic diagram showing an example of state change of a button displayed on the graphics plane . There are two button display states that are a button display state in which a button is displayed on the screen and a button non display state in which a button is not displayed on the screen. The button non display state is changed to the button display state. After the button is cleared the button display state is changed to the button non display state. The button display state has further three states that are a normal state a selection state and an execution state. The button display state can be changed among the three states. The button display state can be changed in one direction among the three states.

Next with reference to the state changes of the button display states will be described in detail. When a disc is loaded into the player or when the user presses the menu key of the remote controller the menu screen is displayed. When the menu screen is displayed the button display states of the buttons A B C D and are changed from the non display states to the display states. Normally one of the buttons A B C D and has been placed in the selection state. Now it is assumed that the button A has been placed in the selection state and the other buttons have been placed in the normal state.

When the user operates for example an arrow key of the remote controller one for example the button A of the buttons is changed from the normal state to the selection state. In addition the button A is changed from the selection state to the normal state. The cursor is moved in accordance with the user s operation. When the user operates the OK key of the remote controller the button B is changed from the selection state to the execution state. As a result a player operation assigned to the button B is executed.

As described above player operations are described in a programming language using original commands and a script language such as ECMA script. The program and script of the player operations are recorded on a disc. The program and script of the player operations may be recorded as independent files on a disc. Alternatively as graphic objects that will be described later the program and script of the player operations may be multiplexed with a clip AV stream file. The program and script of the player operations would be downloaded to a memory or a storage device of the player through the network.

Next data structures of image data of buttons that compose such a menu screen and control information associated with the image data will be described. Now subtitles and graphics still pictures that are displayed other than a moving picture that composes a content main part recorded on a disc will be considered. Elements such as subtitles and graphics displayed on the screen are considered as objects. The types of objects are categorized as three types that are subtitles synchronous graphics and asynchronous graphics.

Subtitles are displayed in synchronization with a moving picture like subtitles of a movie. Subtitles are image elements that do not relate to user s inputs through for example the remote controller. Graphics are image elements such as buttons on a menu screen that can accept user s inputs. Graphics are categorized as two types of synchronous graphics and asynchronous graphics. Synchronous graphics are image elements in synchronization with a moving picture. Synchronous graphics are for example branch selection screens that are displayed at particular timing while a content main part is being reproduced. Asynchronous graphics are image elements that are displayed not in synchronization with a content main part that is being reproduced. Examples of asynchronous graphics are a menu screen that is initially displayed when a disc is loaded into the player and a screen that is displayed in accordance with a user s input. An image element that is displayed by a Java application that operates on JavaVM and an image element displayed in accordance with the description of an HTML file on browser software are asynchronous graphics.

In the relation of each image element and a main picture displayed on the moving picture plane subtitles and synchronous graphics are displayed in synchronization with the main picture. Thus both subtitles and synchronous graphics are synchronous type. On the other hand since asynchronous graphics are displayed not in synchronization with a main picture they are asynchronous type as the name implies.

Subtitles and graphics can be categorized in accordance with planes. Subtitles are displayed on the subtitle plane . Synchronous and asynchronous graphics are displayed on the graphics plane .

Since subtitles and synchronous graphics are displayed while a main moving picture is being displayed it is preferred that they have a common data structure. Hereinafter subtitles and synchronous graphics having a common data structure are referred to as graphics objects. Since graphics objects are always displayed in synchronization with a moving picture that is being reproduced when they are multiplexed with a moving picture they can be easily handled.

In the following example it is assumed that image data treated as the graphics object has a PNG format and that the image data is PNG image data. Alternatively the graphics object may be another format image data such as bit map data having the JPEG format image data that is compressed in accordance with the run length compressing method or bit map data that is not compression encoded. For convenience image data will be represented as PNG image PNG image data or the like.

In and the graphics object header describes information that represents attributes of the graphics object . The attributes of the graphics object are for example the data size of the graphics object the number of PNG images that the graphics object has palette data used for PNG image data that the graphics object uses in common and identification information with which the graphics object is identified. The identification information is for example a number uniquely assigned to each graphics object . The graphics object header may describe further another information.

The display control command table describes information necessary for controlling display of PNG images such as display positions of PNG images that the graphics object has and display start times and display end times thereof.

The PNG data region describes image data that has been compression encoded in accordance with the PNG format hereinafter the image data is referred to as PNG data . The PNG data region can have a plurality of PNG data A B . . . and . The number of PNG data described in the PNG data region is described in the graphics object header .

It is assumed that a plurality of PNG data A B . . . N described in the PNG data region are images that are strongly correlated such as a set of a plurality of still pictures that composes an animation or images of three states of a button that is displayed. When these PNG data A B . . . and N are grouped as one graphics object PNG images can be easily handled.

The graphics object has time information that describes time at which the graphics object can be displayed. In the example of which a real time stream is transmitted as an MPEG2 TS pts Presentation Time Stamp defined in the MPEG2 Moving Pictures Experts Group 2 is used as the time information. The pts is time management information of an output that is reproduced. The pts is measured by a clock of 90 kHz as a value having a length of 33 bits. When the STC System Time Clock of the reference decoder of the MPEG system accords with the pts a corresponding access unit is reproduced and output. One graphics object can be displayed after time represented by the pts. After the time represented by the pts the display of the graphics object is turned on and off with a display control command. Since the display of the graphics object is managed with the display control command after the display of the graphics object is turned off the same graphics object can be displayed.

A special effect such as fade in fade out that does not change the contents of an image can be added to for example subtitles by adding a display control command that causes transparency of the PNG data 1 A to be changed to the display control command table . When the fade in fade out is performed it is not necessary to change the PNG data 1 itself. Likewise by adding a display control command that causes palette data that the PNG data 1 A references to be changed to the display control command table only a display color can be changed without need to change the PNG data 1 A itself.

When an effect such as an animation of which images are varied is applied to subtitles a plurality of PNG data 2 B PNG data 3 C PNG data 4 D . . . corresponding to individual motions of the animation may be described in one graphics object as represented by dotted lines shown in . In addition PNG data of subtitles of different languages such as Japanese subtitles and English subtitles can be described as PNG data 1 A PNG data 2 B . . . in one graphics object .

When the graphics object has only PNG data A for subtitles as represented by solid lines shown in a display control command for the PNG data A is described in the display control command table of the graphics object . When the graphics object has a plurality of PNG data A B and C it is necessary to identify a display control command described in the display control command table for the plurality of PNG data A B and C .

When the initial state of a button of a graphics object shown in has been designated as the selection state a button image that is displayed first and placed at the beginning of the PNG data region should not be the PNG data A for the normal state but the PNG data B for the selection state. According to a first embodiment of the present invention the display control is performed outside the graphics object .

The initial state of each button display start and display stop a program that is executed in the execution state of each button and so forth would be designated by an external script program of a graphics object for example foregoing ECMA script or JavaScript. PNG data for a button that is displayed is changed when the user operates an arrow key of the remote controller and moves the cursor. In this case the player changes PNG data of each button in accordance with a user s input.

According to the embodiment of the present invention a graphics object is divided into packets that are prescribed in the MPEG2 multiplexed with a clip AV stream and recorded as a clip AV stream file on a disc. As shown in a graphics object is divided and contained in PES Packetized Elementary Stream packets . . . that are prescribed in the MPEG2. At that point the graphics object header the display control command table and the beginning of individual PNG data A B . . . are contained at the beginning of the payload of each of the PES packets . . . . As a result when a graphics object is reproduced it can be easily searched for each data thereof.

A graphics object divided and contained in the PES packets . . . is further divided into TS packets having a fixed data size of 188 bytes not shown and multiplexed with a stream of moving picture data and sound data such as a clip AV stream.

A clip AV stream is supplied from the terminal to the PID filter . The PID filter functions as a demultiplexer for an MPEG TS transport stream and extracts moving picture data audio data and a graphics object from the MPEG TS in accordance with the PID of the TS. The moving picture data is supplied to the buffer TBn E which is a video buffer. Audio data is supplied to a buffer D that is an audio buffer. The graphics object is supplied to the buffer TBn B which is an input buffer of a graphics object denoted by GOBJ in .

The graphics object is read from the buffer TBn B and supplied to a GOBJ parser . The GOBJ parser is for example one of functions of the graphics decoder A shown in . The GOBJ parser reads the graphics object header from the supplied graphics object extracts palette data from the graphics object header and separates the display control command table the PNG data region and the sound data region from the graphics object header . The palette data and the display control command table are supplied to a command processor graphic renderer . PNG data A B . . . of the PNG data region are temporarily stored in a PNG decoder buffer . The PNG decoder buffer corresponds to the buffer Bn B shown in and .

The sound data A B . . . of the sound data region are supplied to the command processor graphic renderer and stored in respective buffers not shown thereof.

The PNG data stored in the PNG decoder buffer is decoded by a PNG decoder that is one of functions of the graphics decoder A and output as bit map data. The bit map data is stored in an object buffer . The object buffer corresponds to a buffer memory disposed in the decoder shown in and . When PNG data is decoded by software the object buffer corresponds to the graphics buffer D shown in and .

The command processor graphic renderer reads the bit map data stored in the object buffer in accordance with a display control command described in the display control command table and transfers the bit map data to a plane buffer at designated time. The plane buffer corresponds to for example the subtitle plane and the graphics plane shown in and . Plane buffers A and B not shown may be disposed for subtitles and graphics objects other than subtitles. Alternatively the subtitle plane and the graphics plane may be regions different from the plane buffer .

The command processor graphic renderer supplies palette data supplied from the GOBJ parser to a common palette table that corresponds to the palette shown in and . The command processor graphic renderer has a part of functions of the multimedia engine and a part of functions of the graphics decoder A shown in and .

The command processor graphic renderer reads sound data from a buffer in accordance with a display control command described in the display control command table supplied from the GOBJ parser and outputs the sound data. When the sound data A B . . . stored in the graphics object have been compression encoded they are decoded by the command processor graphic renderer and then output.

Sound data that is output from the command processor graphic renderer is supplied to an audio mixer and output to the presentation processor . When another type of sound data is input to the audio mixer these two types of sound data are mixed at a predetermined ratio and then output.

When a graphics object composes a button PNG data A B and C corresponding to three types of states of the button are contained in the graphics object . The PNG data A B and C are decoded by the PNG decoder and stored in the object buffer .

An input from for example the user s remote controller is received by the command processor graphic renderer . The command processor graphic renderer reads a bit map from the object buffer in accordance with the user s input and transfers the bit map to the plane buffer . When the user s input causes the state of the button to be changed from the selection state to the execution state bit map data that corresponds to the button image of the execution state is selectively read from the object buffer and transferred to the plane buffer .

The command processor graphic renderer can perform a special effect process such as an extracting process for the bit map data that is read from the object buffer in accordance with a display control command.

According to the embodiment since the sampling depth of one pixel of PNG data is eight bits data of eight bits per pixel is arranged in the plane buffer . Data of the plane buffer is read at intervals of a scanning period of a displaying system that performs a displaying process for such as a display device. Bit map data that is read from the plane buffer is supplied to the common palette table that corresponds to for example the palette shown in and . The common palette table converts the bit map data into color information of real RGB 4 4 4 in accordance with a palette index value and extracts transparency data and from the bit map data. Color information of RGB 4 4 4 is converted into color information of YCbCr 4 4 4 of a converting circuit not shown . The color information of YCbCr 4 4 4 is supplied to the presentation processor shown in and along with the transparency data and .

A special effect that requires a process for changing a palette and transparency such as fade in fade out is accomplished by the command processor graphic renderer that varies data of the common palette table in accordance with a display control command. Alternatively common palette tables A and B not shown may be disposed for subtitles and a graphics object other than subtitles.

In PNG data of the graphics object GOBJ is input to the GOBJ input buffer. At time dts of GOBJ decoding of the PNG data is started. In the PNG data is transferred from the GOBJ input buffer to the PNG decoder . The PNG data is decoded and bit map data is obtained. In reality the PNG data is temporarily moved from the GOBJ input buffer to the PNG decoder buffer . The PNG decoder performs a decoding process for data stored in the PNG decoder buffer .

Since the PNG decoder has an upper limit of a decoding speed data is supplied from the GOBJ input buffer to the PNG decoder buffer so that the transfer speed of the data does not exceed the decoding speed of the PNG decoder . Thus PNG data is input to the PNG decoder buffer at a data transfer speed corresponding to a slope against a vertical line that represents the case of a conceptual model of which the transfer time of PNG data to the PNG decoder is 0.

Even if PNG data has not been fully input to the PNG decoder decoding of the PNG data can be started. In the example shown in and after the object GOBJ stored in the GOBJ input buffer has been fully transferred to the PNG decoder an input of PNG data of the next object GOBJ to the GOBJ buffer is started.

Likewise PNG data of the object GOBJ and the object GOBJ is input to the PNG decoder buffer at respective transfer speeds corresponding to particular slopes B and C respectively. In reality the slope B varies in a plurality of regions.

When the valid period of the object GOBJ starts at time pts of GOBJ bit map data of the object GOBJ that has been decoded and stored in the PNG decoder buffer is transferred to the object buffer . The valid period of the object GOBJ transferred to the object buffer continues until time represented by presentation end of GOBJ end of presentation of GOBJ .

In the valid period of the object GOBJ when a command Display ON Cmd. of GOBJ display start command for GOBJ is issued bit map data of the object GOBJ stored in the object buffer is transferred to the plane buffer and displayed . As will be described later the upper limit of the transfer speed of bit map data to the plane buffer varies depending on an influence of a bus width and the like. Thus bit map data is written to the plane buffer at a transfer speed corresponding to for example a particular slope D.

Likewise bit map data of the other objects GOBJ and object GOBJ is transferred at transfer speeds corresponding to slopes E F and G and written to the plane buffer .

The object GOBJ is continuously displayed until a command Display OFF cmd. of GOBJ display end command for GOBJ that causes the object GOBJ to be cleared is issued. When the command Display OFF cmd. of GOBJ is issued the bit map data of the object GOBJ stored in the plane buffer is discarded and the object GOBJ is cleared on the screen.

The objects GOBJ and GOBJ are successively input to the GOBJ buffer. Like the object GOBJ decoding of the objects GOBJ and GOBJ is started at time dts of GOBJ and time dts of GOBJ . PNG data is supplied to the PNG decoder . The PNG decoder decodes the PNG data with a PNG decoder buffer and outputs bit map data. The valid period of the object GOBJ is designated time pts of GOBJ . A command Display ON cmd. of GOBJ not shown in causes the object GOBJ to be displayed. The object buffer transfers bit map data to the plane buffer . The object GOBJ is displayed until the command Display OFF cmd. of GOBJ is issued.

In the example shown in and after the object GOBJ is cleared with a command Display OFF cmd. of GOBL not shown the object GOBJ is displayed again with a command Display ON cmd. of GOBJ . Bit map data of the object GOBJ is kept stored in the object buffer until valid period end time presentation end of GOBJ is designated to the object GOBJ . Thus with the command Display ON cmd. of GOBJ the object GOBJ can be repeatedly displayed.

The valid period designated for the object GOBJ overlaps with the valid period designated for the object GOBJ . In this case the object buffer stores a plurality of bit map data in different regions in accordance with a blank capacity thereof. For example while bit map data of the object GOBJ is transferred from the object buffer to the plane buffer and displayed when bit map data of the object GOBJ is transferred from a different region of the object buffer data of two bit maps can be displayed at the same time.

Next the case that the graphics object decoder model hereinafter referred to as decoder model is implemented to the player will be considered. To allow data reproduced from the same disc to have compatibility with different players it would be necessary to apply predetermined restriction to the decoder model . For example the decoder model has an upper limit of the capability of the graphics process. Thus when graphics data that exceeds the upper limit of the capability is input it becomes impossible to perfectly decode the graphics data. As a result the graphics data cannot be normally displayed.

The minimum capability of the graphics process that the player side should have will be prescribed in a standard. On the other hand graphics that can be processed in the minimum capability prescribed in the standard will be prepared on the contents producer side. By matching the capability of the graphics process that the player side has with the capability of the graphics process that the contents producer side prepares the reproduction compatibility can be maintained.

According to the embodiment of the present invention in a data transfer speed R 1 from the GOBJ parser to the PNG decoder buffer and a data transfer speed R 2 from the command processor to the plane buffer are prescribed.

The data transfer speed R 1 prescribes the data transfer amount pre unit time of data that is input to the PNG decoder buffer . In other words the slopes A B and C shown in correspond to the data transfer speed R 1 . That prescribes the decode capability that represents the amount for which the PNG decoder disposed downstream of the PNG decoder buffer can decode compression encoded graphics data in a unit time. Thus by restricting the data transfer speed R 1 the input compression encoded graphics data can be prevented from being imperfectly decoded and being improperly displayed.

The data transfer speed R 2 prescribes an update speed of an image. The plane buffer corresponds to a screen actually displayed on the display device. The update speed of graphics that the user sees depends on the write speed of data to the plane buffer . The data transfer speed R 2 prescribes the minimum update interval of all a plane namely all a screen in the unit of bytes second . The slopes D E F and G shown in correspond to the data transfer speed R 2 .

When a part of a plane is updated since the amount of image data that is updated is small it is updated at a shorter period than the minimum update interval prescribed as the data transfer speed R 2 . The update interval is not always proportional to the data amount of the image data that is updated. The update interval is largely affected by the arrangement of image data on a plane.

Next with reference to the update speed of a plane will be described in detail. It is assumed that the object buffer stores two graphics objects and and that these two graphics objects and are written to the plane buffer and displayed.

The graphics objects and are read from the object buffer and supplied to the command processor graphic renderer . An output of the command processor graphic renderer is restricted at the foregoing data transfer speed R 2 so as to restrict the update speed update interval on the screen.

However even if two objects have the same data amount to be rewritten their update speeds on the screen vary depending on where they are placed on a plane and how they are deformed and moved. Thus it is difficult to estimate their update speeds. In the example shown in the update speeds of the graphics objects and depend on how they are placed on the plane rather than the total of their data amounts.

Thus a data amount to be rewritten to the plane buffer is defined as a square update region referred to as window. Thus the minimum update interval can be estimated as described below. As a result the accomplishment of the implementation and reproduction compatibility can be improved. Since the defined region is square it can be easily applied to a conventional graphics processor that performs a graphics process. Hereinafter a model based on the definition of the window is referred to as window model.

For example in a plane is updated with a square region that contains all the graphics objects and placed on the plane. The command processor graphic renderer forms image data of the square region in accordance with arrangement information of the graphics objects and . The image data of the square region of the square region is supplied to the plane buffer through a transfer bus. The plane buffer substitutes data of the square region with data of the square region that is newly supplied in accordance with a designated display position.

Since image data that is output from the command processor graphic renderer is bit map data the image data has a data amount in accordance with the area of the image rather than the content of the image. In the example shown in the data amount of the image of the square region that contains the graphics objects and can be represented with for example width height pixels namely width height bytes . The square region is referred to as window. A window fully contains one or a plurality of graphics objects. When the area of the window is minimized the transfer data amount becomes minimum.

Since the data transfer speed to the plane buffer is defined as speed R 2 bytes second it is clear that the graphics objects and can be updated in speed R 2 width height seconds. After a window having a predetermined width and a predetermined height has been transferred to the plane buffer when a time period of at least speed R 2 width height has elapsed the next graphics object can be drawn. When the disc producer side creates a program that allows two graphics objects to be drawn at an interval of at least the foregoing time period the same graphics can be displayed by any player. Thus the reproduction compatibility can be maintained by any player.

As described above a square region that surrounds a plurality of objects that are displayed at the same time is defined as a window. By dividing the data amount of the window by the transfer speed 2 the shortest update interval of the window can be estimated.

When an object is cleared from a plane it is necessary to write data to the plane. In the foregoing window model the entire window can be rewritten in transparent. The time period for clearing the window is the same as the shortest update interval of the window.

When graphics of which an object is deformed or moved on a plane are created the operation speed of the foregoing window mode can be estimated. For example when an object is deformed on the time base as shown in a square region X Y X Y that fully contains the object that varies on the time base is defined as a window. For example as shown in when an object varies on the time base as shown in a square region x y X y that fully contains a locus of the object that moves is defined as a window.

A plurality of for example two windows can be created on a plane. At that point the plurality of windows on the same plane should not overlap with each other.

According to the embodiment of the present invention by defining the foregoing window model the display speed can be easily obtained although it was difficult to calculate the display speed minimum update interval of graphics because of presence of many parameters such as the number of objects to be displayed shapes thereof sizes thereof deformation thereof on the time base and display positions thereof. Thus the disc producer side can pre estimate the operation speed of graphics. Thus the compatibility of the operations of players can be improved.

When the data transfer speed R 2 is estimated the animation speed of subtitles can be decided so that reproduction compatibility can be maintained as will be described later.

The block GraphicsObjectHeader starts with a field length. The field length has a data length of eight bits of an integer that is 0 or larger. The field length describes the length immediately after the field length until the end of the block GraphicsObjectHeader in bytes. A field presentation end time stamp has a data length of 33 bits of an integer that is 0 or larger. The field presentation end time describes valid period end time of the graphics object . The valid period of the graphic object is from a pts of a PES packet header until valid period end time described in this field presentation end time stamp. A field number of DispCmds has a data length of eight bits of an integer that is 0 or larger and describes the number of display control commands described in a block GOBJCommandTable . A field number of PNG images has a data length of eight bits of an integer that is 0 or larger and describes the number of PNG images described in the block PNGImageRegion . A field number of sound data has a data length of eight bits of an integer that is 0 or larger and describes the number of sound data described in a block SoundDataRegion .

A block globalPaletteTable in the block GraphicsObjectHeader describes information of a palette table commonly used in the graphics object . Information of a palette table described in the block GlobalPaletteTable is described as the contents of the common palette table . A field start address of PNG image i has a data length of 32 bits of an integer that is 0 or larger and describes the position at which data PNG image i of an i th PNG image starts with the relative number of bytes from the beginning of the block GraphicsObject .

A field PNG file name i describes a file name of PNG data that starts with the field start address of PNG image i . The contents of the field PNG image i that is a field in the block PNGImageRegion are the same as those of a single PNG file. A block PNGImageRegion is created by connecting one or more PNG files. For example in the PNG data A B . . . and are connected and the block PNGImageRegion is created. At that point a file name can be described in the field PNG file name i so that the file name is not lost. In contrast when the PNGImageRegion is decomposed and individual PNG files are obtained the individual fields PNG image i are independent files having file names described in the field PNG file name i .

A field start address of sound data i has a data length of 32 bits of an integer that is 0 or larger and describes the position that i th sound data sound data i starts with the relative number of bytes from the beginning of the block GraphicsObject .

The block GOBJCommandTable is composed of a command group DispCmds i that is a collection of display control commands that are executed at the same time. The command group DispCmds i describes display control commands starting with a command execution time time that describes an execution time. In other words a portion after the command execution time time until the next command execution time time composes one command group DispCmd i .

As described above the block PNGImageRegion describes a field PNG image i that is data of one image that has been compression encoded in accordance with the PNG system.

Any number of padding word can be described between the block GraphicsObjectHeader and the block GOBJCommandTable . Likewise any number of padding word can be described between the block GOBJCommandTable and the block PNGImageRegion .

A field palette index number describes an index number assigned to a field red value a field green value a field blue value and a field alpha that are preceded by the field palette index number. Image data references colors and transparency with the index number.

In a loop of a for statement of the block GlobalPaletteTable the field palette index number that has the same value should not be described more than twice. Each of the field red value the field green value and the field blue value has a data length of eight bits of an integer that is 0 or larger. The field red value the field green value and the field blue value designate red green and blue respectively. The field alpha has a data length of eight bits. The field alpha represents transparency . When the value of the field alpha is 0 it represents perfect transparent. When the value of the field alpha is 255 it represents perfect intrasparent.

Each PNG image can have a chunk of palette information PLTE. According to the embodiment of the present invention the palette information PLTE is not used but palette information defined by the block GlobalPaletteTable . When a plurality of PNG images are displayed at the same time if the PNG images use colors of different palettes it will be difficult to display the PNG images in correct colors. A plurality of PNG images described in the field PNG image i of GraphicsObject reference the common block GlobalPaletteTable and use the common palette table described in the block GlobalPaletteTable .

Next the command group DispCmds i will be described. The command group DispCmds i describes display control commands that control the display of a graphics object . In the command group DispCmds i a command execution time start time causes a command described before the next command execution time start time to be executed at designated time start time. The start point of the time start time is the pts of the graphics object . The unit of the time start time is the same as that of the pts.

One command group DispCmds i can describe a plurality of commands that are executed at the time start time described in the command execution time start time . Commands described in the command group DispCmds i are executed simultaneously at the time start time described in the command execution time start time . Before the commands described in the command group DispCmds i have been executed if the time start time described in the command execution time start time of the next command group DispCmds i 1 has elapsed the execution of the command group DispCmds i is cancelled. Instead the next command group DispCmds i 1 is executed.

Display control commands besides the command execution time start time described in the command group DispCmds i would be as listed in and . These display control commands are assigned numbers as shown in .

These seven types of commands preceded by the command execution time start time are just examples. In other words commands described in the command group DispCmds i are not limited to those commands. Other display control commands can be defined and added to the command group DispCmds i .

The display start command 2 and the display end command 3 of the graphics object are so called fade in fade out commands that are described as a command fade in fade in time and a command fade out fade out time respectively.

The fade in is designated by the command fade in fade in time . The command fade in fade in time causes a graphics object to be gradually displayed from the non display state to the display state. By gradually increasing the value of the transparency of the alpha blending corresponding to the time fade in time the fade in can be accomplished. When the command execution time start time is followed by the command fade in fade in time the graphics object that is transparent gradually becomes intransparent after the time start time designated by the command execution time start time . After the time designated by the argument time fade in time has elapsed the value of the transparency of all the palette indexes is set to a value designated on the common palette table.

When the time fade in time of the command fade in fade in time has been set to 0 the graphics object is immediately displayed in colors and transparency designated on the palette table.

The fade out is an inverse process of the fade in. The fade out is designated by the command fade out fade out time . The command fade out fade out time causes a graphics object that is displayed to be gradually cleared. By gradually decreasing the value of the transparency a of the alpha blending corresponding to the time fade out time the fade out can be accomplished. When the command execution time start time is followed by the command fade out fade out time a graphics object that is intransparent gradually becomes transparent immediately after the time start time designated by the command execution time start time . After the time designated by the argument time fade out time has elapsed the value of the transparency of all the palette indexes becomes 0. As a result the graphics object fully becomes transparent and invisible.

When the time fade out time of the command fade out fade out time is set to 0 the graphics object is immediately cleared.

When the value of the transparency is gradually varied in the fade in and fade out as time elapses more natural fade in and fade out effects can be preferably obtained. Alternatively in the fade in after the time designated by the time fade in time has elapsed the value of the transparency a should match the value designated on the palette table. However the resolution and graduation of the transparency are not designated by a command. In reality the resolution and gradation of the transparency depend on the implemented system.

In the foregoing example the commands are represented as texts such as fade in and fade out for high recognizability. However actually the commands fade in and fade out are converted into predetermined binary values along with their arguments and described in DispCmds i . That applies to other commands that will be described later.

The palette table color and transparency a change command 4 causes palette information to be changed. This command is described in the format of change palette index newR newG newB newAlpha . A PNG image displayed simultaneously on the subtitle plane and the graphics plane references the common palette table that is shown in and that is defined by the syntax shown in . Palette information defined as GlobalPaletteTable is used as the common palette table. With the command change palette index newR newG newB and newAlpha the common palette information can be changed.

The values index newR newG and newAlpha described as arguments in the command change palette index newR newG newB newAlpha cause values R G and B of three primary colors of color index values represented by the palette number index to be changed to the values newR newG and newB and the value of the transparency a to be changed to the value newAlpha.

The command 5 that causes the display position and size of a graphics object to be set on a plane is used in the format of set display box x y x y . The command 5 causes a graphics object to be placed in a square region x y x y defined with coordinates x y and x y on the plane. The command 6 that causes a display range of a graphics object to be set is used in the format of set clipping box a b a b . The command 6 causes a square region a b a b defined with coordinates a b and a b of a PNG image of a graphics object to be displayed on the plane.

Next with reference to and the command set display box x y x y and the command set clipping box a b a b will be described in detail. As shown in on the coordinates shown in and the upper left corner of the display screen is defined as an origin the horizontal right direction is denoted by x the lower vertical direction is denoted by y and coordinates are denoted by x y .

As shown in the command set clipping box a b a b causes a square region a b a b that is actually displayed to be set in a PNG image of a graphics object . In the example shown in it is assumed that the square region a b a b to be set is smaller than the PNG image . The command set display box x y x y causes a real display position of the square region a b a b to be set on a plane of a square region x y x y see. . Only the square region a b a b of the PNG image is displayed against the square region x y x y on the screen.

When the square region a b a b is larger than the square region x y x y that is actually displayed only the PNG image of the square region x y x y in the square region a b a b is displayed. In contrast when the square region a b a b is smaller than the square region x y x y that is actually displayed the outside of the square region a b a b in the square region x y x y is treated as a transparent region.

When the foregoing display control commands are described along with a plurality of commands execution time start time subtitles and synchronous graphics that vary as time elapses can be displayed. For example in the graphics object shown in a plurality of command groups DispCmds i are described in the block GOBJCommandTable . Each of the command groups DispCmds i describes the display control commands execution time start time whose times start time are different so as to execute the command groups DispCmds i at the start times designated by start time.

In the first command group DispCmds 0 a command set display box 800 800 1300 900 causes a display region on a plane to be set. A command set clipping box 0 0 500 100 causes a display region of a PNG image of a graphics object to be set. A command fade in 2 sec causes a fade in process for two seconds to be started at time 0 . In the next command group DispCmds 1 a command change palette index newR newG newB Alpha describes color index values 1 2 3 and 4 . The command group DispCmds 1 also causes colors and transparency a referenced by the index values 1 2 3 and 4 to be changed at time 800 . The next command group DispCmds 2 causes a graphics object that is displayed to be faded out for two seconds at time 2000 .

As shown in when the command groups DispCmds 0 DispCmds 1 and DispCmds 2 are successively described for example subtitles that vary as time elapses can be accomplished. When the command groups DispCmds 0 DispCmds 1 and DispCmds 2 are properly used subtitles and button images can be displayed as animations.

In the next command group DispCmds 1 a command execution time start time causes predetermined time that elapses after the execution of the command group DispCmds 1 to be set as start time. A command set display box x y x y causes a display region to be moved on the plane to be set. Likewise in the next command group DispCmds 2 a command execution time start time causes predetermined time that elapses after the execution of the command group DispCmds 1 to be set as start time. A command set display box x y x y causes a display region to be moved on the plane to be set.

Thus as shown in a PNG image as subtitles can be moved to a square region x y x y a square region x y x y and a square region x y x y on a plane.

In the next command group DispCmds 1 a command execution time start time causes predetermined time that elapses after the execution of the command group DispCmd 1 to be set as start time. A command set clipping box a b a b causes a display region to be moved in the PNG image to be set. Likewise in the next command group DispCmds 2 a command execution time start time causes predetermined time that elapses after the execution of the command group DispCmds 1 to be set as start time. A command set clipping box a b a b causes a square region to be moved in the PNG image to be set.

Thus as shown in a square region as a part of a PNG image as subtitles is moved from a square region a b a b to a square region a b a b to a square region a b a b in a square region x y x y on a plane. As a result the subtitles can be scrolled.

For example the command set display box x y x y causes a square region x y x y that is displayed on a plane to be set. The command set clipping box a b a b causes a square region a b a b that is displayed in the PNG image to be set. The square region x y x y and the square region a b a b form the frame A.

In the next command group DispCmds 1 a command execution time start time causes predetermined time elapses after the execution of the command group DispCmds 0 to be set as start time. A command set display box x y x y causes a square region x y x y to be set on the plane. A command set clipping box a b a b causes a square region a b a b to be set in the PNG picture . The square region x y x y and the square region a b a b form a frame B to which the frame A is moved. Likewise in the next command group DispCmds 2 a command execution time start time causes predetermined time that elapses after the execution of the command group DispCmds 1 to be set as start time. A command set display box x y x y causes a square region x y x y to be set on the plane. A command set clipping box a b a b causes a square region a b a b to be set in the PNG image . The square region x y x y and the square region a b a b form a frame B to which the frame B is moved.

Thus as shown in while a square region of a part of the PNG image of subtitles is being moved the square region can be moved from the region A to the region B to the region C on the plane.

Thus according to the embodiment of the present invention since the display control of the graphics object is performed by the command groups DispCmds i of which each display control command is grouped by the command execution time start time various displays can be easily accomplished on the subtitle plane and the graphics plane .

According to the embodiment of the present invention a sound output can be synchronized with a display control of a graphics object . A sound output is defined by the command 7 which causes an effect sound to be reproduced and the command 8 which causes an effect sound to be assigned to image data in the commands 2 to 8 excluding the command 1 execution time start time of the foregoing command group DispCmds i . Sound data is assigned a unique identification sound id.

The command 7 which causes an effect sound to be reproduced is described in the format of play sound sound id . The command play sound sound id causes sound data identified by an identifier sound id to be reproduced. When the command play sound sound id is described in a command group DispCmds i sound data identified by the identifier sound id is reproduced at time start time designated by the command execution time start time .

For example when the command play sound sound id is used along with a command fade in fade in time and a command fade out fade in time sound data as an effect sound can be reproduced while subtitles are being displayed and or cleared. shows an example of which the command play sound sound id is used. In the example shown in in the first command group DispCmds 0 a command fade in 2 sec causes a graphics object to be faded in for two seconds at start time 0 . A command play sound 1 causes sound data identified by the identifier sound id 1 to be reproduced. Thereafter in the command group DispCmds 1 a command execution time 800 causes a display color to be changed at time 800 . A command play sound 2 causes sound data identified by the identifier sound id 2 to be reproduced. In the command group DispCmds 2 a command execution time 2000 and a command fade out 1 sec cause the graphics object to be faded out for one second at time 2000 . A command play sound 1 causes sound data identified by the identifier sound id to be reproduced.

The command 8 which causes an effect sound to be assigned to PNG data is described in the format of set sound PNG image id sound id . The command set sound PNG image id sound id causes sound data designated by the identifier sound id to be reproduced for PNG data identified by the identifier PNG image id. This command set sound PNG image id sound id causes the sound data identified by the identifier PNG image id to be reproduced when PNG data identified by the identifier PNG image id is displayed. The identifier PNG image id of the PNG data is the same as the value of the loop counter i of PNG image i of the block PNGImageRegion .

It is considered that the command set sound PNG image id sound id is used for PNG data of buttons in the selection state and the execution state. As a result when the normal state of a button is changed to the execution state or vice versa sound data assigned to PNG data that represents each state can be generated as an effect sound. Beside that example this command set sound PNG image id sound id can be used for PNG data for other than buttons.

The graphics object shown in describes only the command group DispCmds 0 that is executed in the display control command table at time 0 by the command execution time 0 . Since an identifier PNG image id starts with 0 the identifier PNG image id 0 represents PNG data A in the normal state the identifier PNG image id 1 represents PNG data B in the selection state and the identifier PNG image id 2 represents PNG data C in the execution state.

When the PNG data B of the button in the selection state of which the identifier PNG image id is 1 is displayed by the command set sound 1 10 sound data identified by the identifier sound id 10 is reproduced as an effect sound. Likewise when the PNG data C of the button in the execution state of which the identifier PNG image id is 2 is displayed by the command set sound 2 11 sound data identified by the identifier sound id 11 is reproduced as an effect sound.

Although not shown in and one or a plurality of types of sound data may be pre stored in an internal memory or the like of the player. For example predetermined sound data may be pre stored in an internal non volatile memory or the like of the player before shipment.

Alternatively sound data as an effect sound may be prerecorded on a disc of which a graphics object and a content as moving data have been recorded. When the content is reproduced from the disc the sound data may be read. As a method for recording sound data on the disc a file for the sound data is prepared. When the content is reproduced from the disc the file is pre read and stored in the memory of the player.

Alternatively like a graphics object PES packets that contain sound data are created. The PES packets are divided into TS packets. The TS packets are multiplexed with a clip AV stream.

Alternatively sound data may be placed in the graphics object header or a region immediately preceded by the sound data region of the graphics object shown in and sound data is not shown corresponding to a PNG picture contained in the graphics object .

In any method since sound data can be pre read from a disc and pre stored in the memory of the player when the state of a button created with a PNG image is changed to the selection state or the execution state an effect sound can be generated. Sound data is assigned a unique identifier sound id the sound data can be uniquely identified.

Next the method for recording sound data to the disc will be described in detail. With reference to and a method for describing sound data in a graphics object will be described. and show an example of which sound data is added to a graphics object and then multiplexed with a clip AV stream.

The sound data A B . . . may be data that has not been compression encoded for example AIFF Audio Interchange File Format file or WAVE file or data that has been compression encoded for example MP3 Moving Pictures Experts Group 1 Audio Layer 3 file AAC Advanced Audio Coding file or ATRAC Adaptive Transform Acoustic Coding file. When sound data that has been compression encoded is contained the player side should have an audio decoder in accordance with the compression encoding system.

In this case the PNG data region for button images is followed by the sound data region . The sound data region contains sound data A that is reproduced when the button is placed in the selection state and sound data B that is reproduced when the button is placed in the execution state. Thus when PNG data of a button image is displayed sound data corresponding to a button state is reproduced. It is considered that an effect sound reproduced by the player is mainly used as a button click sound. Thus in such a structure the major purpose of the present invention can be sufficiently accomplished.

Next a method in the case that sound data is not multiplexed with a clip AV stream will be described. For example as shown in a directory SOUND that contains sound data is placed under a directory BDAV. The directory SOUND contains PCM waveform data as sound data. For example a sound data file sound1.aiff having the AIFF format is placed in the directory SOUND. All sound data files placed in the directory SOUND are read when the disc is initially loaded into the player and then stored in an internal memory of the player.

Each piece of sound data is assigned a unique identifier sound id. A program or a script calls desired sound data with an identifier sound id.

In this case as shown in a sound id region is disposed in a graphics object . Sound id data A and B are contained in the sound id region . In the example shown in PNG data A B and C corresponding to a normal state a selection state and an execution state of a button are contained in the PNG data region . The Sound id data A and B are identifiers sound id corresponding to the PNG data B and C respectively. When the PNG data B is displayed sound data corresponding to the identifier sound id represented by the sound id data A stored in the memory of the player is reproduced.

For example as described with reference to PNG data and sound data may be correlated in accordance with the display control command table .

Data having the structure shown in may be obtained from a network such as the Internet and then input to the input terminal not read from a disc.

Unlike a display control command that has been described with reference to since sound data is identified with an identifier sound id an effect sound of sound data can be generated anytime not in synchronization with graphics that are displayed.

In this method since sound data is read from the memory using an identifier sound id the number of types of effect sounds is restricted by the number of identifiers sound id. In addition the number of types of effect sounds that can be used is restricted by the capacity of the internal memory of the player.

Next with referenced to that method will be described in detail. When a disc is loaded a player initially accesses the disc. All sound data is read from a directory SOUND placed under a directory BDAV. The sound data PCM data that has been read is stored in an internal memory of the player. At that point a unique identifier sound id is assigned to each piece of sound data. Alternatively an identifier sound id may be added to each piece of the sound data recorded on the disc .

In the example 16 pieces of sound data are read from the disc . Identifiers sound id 1 to 16 are assigned to those pieces of sound data. The data sizes of those pieces of the sound data are obtained. It is assumed that in the example shown in the pieces of the sound data assigned the identifiers sound id 1 to 16 have data sizes of d bytes d bytes . . . and d bytes respectively.

For example on a menu screen that displays buttons A B and C when an operation is preformed for the button C sound data corresponding to an identifier sound id assigned to the button C is read from a memory . In the example shown in sound data corresponding to an identifier sound id 1 is assigned to the execution state of the button C. Sound data that is read from the memory is processed in a predetermined manner and temporarily stored in a buffer B. Thereafter the sound data is supplied to an audio mixer . The audio mixer mixes the sound data with sound data associated with for example moving picture data as a content main part and outputs the mixed data as a sound.

A buffer A temporarily stores sound data associated with for example moving picture data as a content main part. When timing at which sound data stored in the buffers A and B is read therefrom is adjusted an effect sound corresponding to the operation of the button C is output from the buffer B at proper timing of sound data stored in the buffer A. In this example with identifier sound id 0 no sound data reproduction mode is designated.

In such a model the total capacity of sound data that can be read from the disc is restricted to the capacity of the memory . The capacity of each piece of sound data is restricted in accordance with the capacity of the buffer B. When the capacity of the memory is denoted by capacity M bytes and the capacity of the buffer B is denoted by capacity Dmax bytes it is necessary to satisfy the following two conditions.

In other words when the conditions 1 and 2 are prescribed as rules on the player side and the disc producer side reproduction compatibility of sound data such as effect sounds can be maintained.

As described above in the case that sound data is not multiplexed with a clip AV stream when a disc is initially loaded into the player all sound data is read therefrom. However the preset invention is not limited to such an example. In other words sound data can be read from a disc in a plurality of sessions. For example all sound data used for one of sections of a scenario is read and stored in the memory. At that point sound data stored in the memory for the preceding section of the scenario is erased. As a result even if the data amount of sound data of one scenario exceeds the capacity of the memory the sound data can be handled.

All sound data can be recorded in a predetermined region of a disc. Alternatively sound data may be separately recorded in a plurality of regions of a disc. When sound data is separately recorded in a plurality of regions of a disc sound data for sections of a scenario may be recorded at positions of the disc corresponding to the sections of the scenario. Alternatively sound data may be downloaded from a server connected through a network. At that point when a position of a file is designated with a URL Uniform Resource Locator sound data can be accomplished in the same manner as the case that sound data is read from a disc.

In the method of which sound data is multiplexed with a clip AV stream described with reference to and the number of types of sound data is not restricted. As a result different type of sound data can be assigned to each image. When necessary sound data is supplied with a clip AV stream. Thus a different type of sound data can be used whenever a clip AV stream is supplied. Moreover in the method of which sound data is multiplexed with a clip AV stream since sound data is read from a clip AV stream along with image data the reading model can be simply structured. In addition the number of files of sound data and the sizes of files are not restricted except for the capacity of the disc.

However in the method of which sound data is multiplexed with a clip AV stream when the same sound data is used for different graphics objects since their graphics objects each should have the same sound data the sound data becomes redundant. In addition since sound data should be extracted from a graphics object after a clip AV stream is demultiplexed sound data should be separated from the graphics object.

Next with reference to and a sound data process can be synchronized with a graphics object will be described.

Sound data that is not multiplexed with a clip AV stream is input as data of for example an input channel 1 to an input terminal . The sound data is supplied to a contents buffer through switch circuits and . On the other hand a clip AV stream with which a graphics object that contains sound data has been multiplexed is input to an input terminal . A PID filter filters the graphics object and temporarily stores the graphics object in a buffer TBn A. Thereafter the graphics object is supplied to the contents buffer through the switch circuit .

A clip AV stream with which a graphics object that does not contain sound data has been multiplexed is input from the input terminal . The PID filter filters the clip AV stream and outputs a transport packet that composes the graphics object . The transport packet is temporarily stored in a buffer TBn B or a buffer TBn C. The transport packet stored in the buffer TBn B is supplied to a buffer Bn B. As a result the graphics object is combined in accordance with a PID header. The graphics object is supplied to a graphics decoder A through a switch circuit . The transport packet stored in the buffer TBn C is also combined as the graphics object through a buffer Bn C. The graphics object is supplied to a graphics decoder B through a switch circuit .

The graphics decoders A and B each remove header information from the supplied transport packet decode image data contained in the transport packet and obtain image data for example bit map data necessary for displaying subtitles or graphics.

Image data of the graphics object that contains sound data is supplied from the contents buffer to the graphics decoders A and B through the switch circuits and respectively.

In the example shown in and the graphics decoder A decodes image data to be expanded to a subtitle plane. The graphics decoder B decodes image data to be expanded to a graphics plane. Alternatively the graphics decoders A and B may decode image data that has another data format. Alternatively the graphics decoders A and B may deal with image data that has a plurality of formats.

An output of the graphics decoder A is supplied to an input terminal B of a switch circuit and to an input terminal C of a switch circuit . The image data is supplied to a subtitle plane and a graphics plane through the switch circuits and respectively.

A multimedia engine has a sound player D. A buffer has a sound buffer E. The sound player D decodes sound data that is read from the contents buffer using the sound buffer E and outputs for example linear PCM audio data. The sound data that is output from the sound player D is supplied to a presentation processor . The presentation processor mixes the sound data that is output from the sound player D with sound data that is output from an audio decoder and outputs the mixed sound data to an output terminal .

Sound data as an effect sound such as a click sound or the like that is generated when for example a button image is clicked is reproduced by the sound player D. The sound data is stored in the sound buffer E and reproduced by the sound player D.

When for example a combination of HTML and ECMA script is used as a scenario descriptive language the multimedia engine reads an ECMA script stored in a code buffer parses the ECMA script reads another ECMA script and an HTML document from the code buffer and reads image data and sound data from the contents buffer . Like data stored in the contents buffer sound data can be kept stored in the contents buffer .

The multimedia engine receives a user s input from the remote controller the pointing device or the like and performs a process corresponding to the user s input. The multimedia engine generates a control signal corresponding to a processed result of the user s input and each script. The control signal is also supplied to the graphics decoders A and B the audio decoder an MPEG video decoder and a system decoder .

Image data processed by a graphic renderer C is supplied to the subtitle plane and the graphics plane through the switch circuits and respectively. Each of the subtitle plane and the graphics plane is composed of for example a frame memory. The subtitle plane and the graphics plane correspond to the subtitle plane and the graphics plane shown in respectively.

The image data that is supplied from the graphic renderer C to the subtitle plane and the graphics plane is bit map data of which image data that has for example run length compression format PNG format or JPEG format has been decoded by the graphic renderer C.

The multimedia engine supplies a control signal that causes one of the subtitle plane the graphics plane and the moving picture plane to be switched to another to a presentation processor . In addition the multimedia engine supplies a control signal that controls an output of the audio stream to a presentation processor .

Image data on the subtitle plane is supplied to a palette that corresponds to the palette shown in . The palette that has 256 colors is referenced with an index. As a result RGB data is output. In addition transparency data is output. The RGB data is supplied to an RGB YCbCr converting circuit that corresponds to the RGB YCbCr converting circuit shown in . The RGB YCbCr converting circuit converts the color system from RGB 4 4 4 into YCbCr 4 4 4 . YCbCr data that is output from the RGB YCbCr converting circuit is supplied to the presentation processor .

Image data on the graphics plane is supplied to a palette that corresponds to the palette shown in . The palette that has 256 colors is referenced with an index. As a result RGB data is output. In addition transparency data is output. The RGB data is supplied to an RGB YCbCr converting circuit that corresponds to the RGB YCbCr converting circuit shown in . The RGB YCbCr converting circuit converts the color system from RGB 4 4 4 into YCbCr 4 4 4 . The YCbCr data that is output from the RGB YCbCr converting circuit is supplied to the presentation processor .

Moving picture data on the moving picture plane is supplied to the presentation processor through an up down converter .

The presentation processor performs an alpha blending process with the transparency of the subtitle plane subtitle plane and the transparency of the graphics plane graphics plane . This process causes image data on the moving picture plane the subtitle plane and the graphics plane to be combined. The presentation processor can perform an effect process for the image data on real time basis. Image data of which the combining process has been performed among planes and the effect process has been performed is obtained from an output terminal .

As described above a prerecorded large capacity disc according to the present invention has three independent planes that are a moving picture plane for a moving picture a subtitle plane for subtitles and a graphics plane for a screen having an interruptive function such as a menu screen. These planes are combined and displayed. Thus as an effect of the present invention a moving picture can be displayed on the moving picture plane while a menu screen and so forth are displayed on the graphics plane with a background of the moving picture.

According to the present invention since a buffer that stores image data to be displayed on the graphics plane is disposed the same image data can be repeatedly displayed on the graphics plane. Thus as an effect of the present invention a menu screen and so forth can be structured with higher flexibility than before.

According to the present invention states of a button displayed on the menu screen or the like are categorized as three states. Corresponding to the categorized states image data is provided. The image data is switched corresponding to a user s input or the like. As a result various types of enriched menus that cannot be accomplished by conventional DVD video can be accomplished.

According to the present invention a display control for graphics displayed on a graphic plane is described using display control commands. Thus as an effect of the present invention an interactive function can be accomplished with a screen displayed on the graphics plane. A simple animation of which subtitles and buttons are scrolled and moved and enriched buttons of which the contents of an image are varied corresponding to a user s input can be accomplished.

A prerecorded large capacity disc according to the present invention has three independent planes that are a moving picture plane for a moving picture a subtitle plane for subtitles and a graphics plane for a screen having an interruptive function such as a menu screen. These planes are combined and displayed. A common graphics object as a format of an object displayed on the subtitle plane and the graphics plane is defined. A decoder model display control commands and an operation model are defined. As a result as an effect of the present invention subtitles and buttons can be displayed in synchronization with a moving picture.

According to the present invention a decoder model of a graphics object is defined. To implement that a method for restricting a transfer rate of data from an object buffer to a plane buffer is presented. For a data amount of data that is rewritten to the plane buffer since the data amount varies depending on the position deformation and movement of an object on a plane a square update region called a window is defined. Thus a minimum update interval can be estimated. As a result the implementation of the decoder model and the reproduction compatibility thereof can be improved.

According to the present invention a decoder model of which sound data is contained in a graphics object and of which the sound data is reproduced while a button image contained in the graphics object is displayed is defined. Thus sound data can be easily reproduced in synchronization with a graphics object that is displayed.

According to the present invention a command that causes sound data to be reproduced is defined against a display control command for a graphics object. In addition sound data can be assigned to image data contained in a graphics object against a display control command for an object. Thus as an effect of the present invention sound data such as an effect sound can be reproduced at any time and subtitles and buttons that have effect sounds can be accomplished.

