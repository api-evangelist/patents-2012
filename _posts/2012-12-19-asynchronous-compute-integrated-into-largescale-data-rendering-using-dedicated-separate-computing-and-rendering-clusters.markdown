---

title: Asynchronous compute integrated into large-scale data rendering using dedicated, separate computing and rendering clusters
abstract: An asynchronous computing and rendering system includes a data storage unit that provides storage for processing a large-scale data set organized in accordance to data subregions and a computing cluster containing a parallel plurality of asynchronous computing machines that provide compute results based on the data subregions. The asynchronous computing and rendering system also includes a rendering cluster containing a parallel multiplicity of asynchronous rendering machines coupled to the asynchronous computing machines, wherein each rendering machine renders a subset of the data subregions. Additionally, the asynchronous computing and rendering system includes a data interpretation platform coupled to the asynchronous rendering machines that provides user interaction and rendered viewing capabilities for the large-scale data set. An asynchronous computing and rendering method is also provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09117284&OS=09117284&RS=09117284
owner: NVIDIA CORPORATION
number: 09117284
owner_city: Santa Clara
owner_country: US
publication_date: 20121219
---
This application is directed in general to data processing and more specifically to an asynchronous computing and rendering system and an asynchronous computing and rendering method.

Typically a large scale data set may be based on raw data that has been collected but has not undergone any form of processing. The large scale raw data may be multiple times larger than a corresponding reduced data set. For instance a factor of about 600 is not uncommon in the area of seismic data interpretation. That is if a rendering system visualizes 200 GB of seismic volume data then respective raw data could be approximately 120 TB in size. Usually this large scale raw data has to be preprocessed which may require hours or even days in order to provide a reduced data set that is capable of being further processed or manipulated for analysis in a user interactive environment. In another aspect preprocessing of the large scale data set may incur unwanted or unknown filtering effects on the reduced data set which in turn may provide misleading results during further analysis.

Embodiments of the present disclosure provide an asynchronous computing and rendering system and an asynchronous computing and rendering method.

In one embodiment the asynchronous computing and rendering system includes a data storage unit that provides storage for processing a large scale data set organized in accordance to data subregions and a computing cluster containing a parallel plurality of asynchronous computing machines that provide compute results based on the data subregions. The asynchronous computing and rendering system also includes a rendering cluster containing a parallel multiplicity of asynchronous rendering machines coupled to the asynchronous computing machines wherein each rendering machine renders a subset of the data subregions. Additionally the asynchronous computing and rendering system includes a data interpretation platform coupled to the asynchronous rendering machines that provides user interaction and rendered viewing capabilities for the large scale data set.

In another aspect the asynchronous computing and rendering method includes providing data storage for processing a large scale data set organized in accordance to data subregions and initiating asynchronous and parallel rendering wherein each rendering corresponds to a subset of the data subregions. The method also includes instigating asynchronous and parallel computing having compute results based on the subset of the data subregions and providing user interaction and rendered viewing capabilities for the large scale data set.

The foregoing has outlined preferred and alternative features of the present disclosure so that those skilled in the art may better understand the detailed description of the disclosure that follows. Additional features of the disclosure will be described hereinafter that form the subject of the claims of the disclosure. Those skilled in the art will appreciate that they can readily use the disclosed conception and specific embodiment as a basis for designing or modifying other structures for carrying out the same purposes of the present disclosure.

Embodiments of the present disclosure provide a scalable system having data distribution schemes that are particularly designed for user defined compute algorithms and may employ virtually unlimited graphics processing memory for high performance computing algorithms. Additionally asynchronous computing and rendering operations provide critical integration of compositing results for visualization.

The data storage unit represents a system capacity data storage that is available to components of the asynchronous computing and rendering system . The computing cluster includes a plurality of parallel compute machines and the rendering cluster includes a multiplicity of parallel rendering machines as shown. The data interpretation platform functions as the user input and viewing station for the system and the LAN provides a high speed connection between the rendering cluster and the data interpretation platform .

Operationally the computing cluster is a dedicated computing cluster that is leveraged for user defined large scale data processing by a rendering system i.e. rendering software which runs on the rendering cluster to integrate compute results. Parallel composited outputs from the multiplicity of rendering machines are provided to the data interpretation platform for display and interpretation.

The asynchronous computing and rendering system enables asynchronous parallel rendering and computing. In particular the asynchronous computing and rendering system hides network transfer costs between cluster machines and occurring latencies graphic processing unit upload and download times and computing costs. By reducing these factors that usually impact system performance the asynchronous computing and rendering system is optimized for real time visualization of large scale data that results from raw data processing done on the fly.

As an example of a possible deployment strategy each of the compute and rendering host machines A F employs a central processing unit CPU having eight parallel processing cores and 24 gigabytes GBs of high speed memory. Additionally each of the compute and rendering host machines A F employs two parallel graphics processing units GPUs wherein each has 240 parallel programmable processing cores that employ high level programming language and four GB of high speed memory. The LAN is a one GB Ethernet network.

The asynchronous computing and rendering system is representative of a scalable system that is able to integrate user defined parallel and distributed compute algorithms into a large scale data rendering algorithm. The parallel and distributed compute algorithms can leverage dedicated compute clusters to process large scale raw data and generate an input for scalable large scale data visualization using a dedicated rendering cluster. The scalable system manages compute and rendering operations asynchronously to reduce latencies and waiting times. Proper selection of scalable system cluster sizes to match a complexity of user defined compute algorithms may provide substantially real time interactive performance.

The software library is a GPU cluster aware software system that enables scalable rendering of large scale data. It provides core functionality that focuses on data set management rendering and processing. Additionally it provides a domain specific application programing interface that enables accessing and editing uploaded data and extending core functionality. The software library also provides protection between system intellectual property e.g. rendering algorithms and user proprietary algorithms. The application layer provides an interface to user interpretation through display visualizations and manages user interactions. Additionally it manages application logic by controlling functionality and workflows as well as display scene representations.

The external components extend core workflow functionality through user defined processing of data and user defined input output. Additionally it facilitates the core workflow functionality being extended by relying on application programing interfaces. The external components protect user or other proprietary programs e.g. user proprietary programs and leverage associated proprietary algorithms and file formats. The specialty library provides special functionality that is targeted toward a specific large scale data set e.g. a software library for seismic data required for processing.

Another key aspect of the asynchronous computing and rendering systems described in this disclosure is that they rely on proxy geometries which represent geometric or volumetric shapes that are able to display compute results e.g. using texture mapping techniques . Proxy geometries may include three dimensional planes rectangular three dimensional shapes heightfields heightmaps or terrain models or voxel cubes three dimensional volumes . Then implementation of an asynchronous rendering and compute and integration of the compute results into a rendering system for immediate visualization generally employs the following.

Parallel and distributed rendering starts by invoking rendering tasks. These tasks are sent through the network employing the LAN to each rendering node a rendering machine of the rendering cluster . Distributing the rendering tasks and receiving them is substantially immediate. Each rendering node of the rendering cluster then computes the intersection of a proxy geometry with those subregions that the rendering node has to process. This computation is done in a separate thread that runs parallel to the rendering thread on each rendering node. Furthermore the computation is done based on a subset of subregions and in parallel on all rendering nodes which represents a basic requirement for a scalable system.

For each subregion that is intersected by a proxy geometry the rendering nodes creates a buffer instance which contains information related to the position and orientation of the proxy geometry. The set of all buffer instances is passed to a user defined computing technique. The user defined computing technique then spawns user defined compute tasks and sends them through a network to the dedicated compute cluster. The user defined computing technique maintains specific knowledge of the dedicated distribution schemes for the large scale data set e.g. raw data and the respective user defined parallel and distributed computing algorithm that processes the large scale data set. The rendering system retains a reference to each buffer instance.

While a compute is in progress the rendering system continues with the rendering of all geometries that are defined in a three dimensional display scene that do not require any computing. When a computing task returns from the computing cluster to an invoking rendering cluster machine its results then define and populate the buffer instance contents. When the buffer instance becomes available the rendering system will be immediately notified. The rendering system then uses the available compute results of the buffer instance for texturing the proxy geometry in a subregion. A collection of all textured proxy geometries of one rendering node represents the visualization of the large scale data set for all the subregions of the respective rendering node. A composited result of all rendering nodes then visualizes the entire compute.

Generally the asynchronous and parallel rendering and computing are scalable and each of the compute results is invoked by one asynchronous and parallel rendering. Additionally the user interaction capability corresponds to selecting application specific functions to be performed on at least a portion of the large scale data set and the rendered viewing capability corresponds to a composite of separate renderings.

In one embodiment a proxy geometry corresponding to selected data subregions is employed in providing the asynchronous and parallel rendering and the compute results. Here each rendering calculates an intersection of the proxy geometry with the selected data subregions. In another embodiment each rendering calculation is processed in a separate thread that runs in parallel with other rendering threads. In yet another embodiment each rendering creates a buffer instance for each selected data subregion that is intersected by the proxy geometry. Correspondingly the buffer instance is defined and populated by a compute result returned to an invoking rendering. The method ends in a step .

While the method disclosed herein has been described and shown with reference to particular steps performed in a particular order it will be understood that these steps may be combined subdivided or reordered to form an equivalent method without departing from the teachings of the present disclosure. Accordingly unless specifically indicated herein the order or the grouping of the steps is not a limitation of the present disclosure.

Those skilled in the art to which this application relates will appreciate that other and further additions deletions substitutions and modifications may be made to the described embodiments.

