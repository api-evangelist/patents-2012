---

title: Systems and methods for a multiport synchronous-asynchronous client for scheduling and delivering content for digital radio broadcast transmission
abstract: Systems, methods, and processor readable media are disclosed for scheduling and delivering content for digital radio broadcast transmission. To overcome the inefficiencies of conventional scheduling and delivery techniques, the present disclosure describes a novel multiport synchronous-asynchronous client for receiving content from multiple sources and then scheduling and delivering that content to an importer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08660128&OS=08660128&RS=08660128
owner: iBiquity Digital Corporation
number: 08660128
owner_city: Columbia
owner_country: US
publication_date: 20120206
---
The present application is a continuation in part of U.S. patent application Ser. No. 12 923 780 filed Oct. 7 2010 entitled Systems And Methods For Transmitting Media Content Via Digital Radio Broadcast Transmission For Synchronized Rendering By A Receiver currently pending which claims the benefit of U.S. provisional application Ser. No. 61 272 580 filed Oct. 7 2009 and which is a continuation in part of U.S. patent application Ser. No. 12 385 660 filed Apr. 15 2009 entitled Systems And Methods For Transmitting Media Content Via Digital Radio Broadcast Transmission For Synchronized Rendering By A Receiver currently pending the entire contents of each of which are incorporated herein by reference.

The present disclosure relates to a multiport synchronous asynchronous client for scheduling and delivering content for digital radio broadcast transmission.

Digital radio broadcasting technology delivers digital audio and data services to mobile portable and fixed receivers. One type of digital radio broadcasting referred to as in band on channel IBOC digital audio broadcasting DAB uses terrestrial transmitters in the existing Medium Frequency MF and Very High Frequency VHF radio bands. HD Radio technology developed by iBiquity Digital Corporation is one example of an IBOC implementation for digital radio broadcasting and reception.

IBOC digital radio broadcasting signals can be transmitted in a hybrid format including an analog modulated carrier in combination with a plurality of digitally modulated carriers or in an all digital format wherein the analog modulated carrier is not used. Using the hybrid mode broadcasters may continue to transmit analog AM and FM simultaneously with higher quality and more robust digital signals allowing themselves and their listeners to convert from analog to digital radio while maintaining their current frequency allocations.

One feature of digital transmission systems is the inherent ability to simultaneously transmit both digitized audio and data. Thus the technology also allows for wireless data services from AM and FM radio stations. The broadcast signals can include metadata such as the artist song title or station call letters. Special messages about events traffic and weather can also be included. For example traffic information weather forecasts news and sports scores can all be scrolled across a radio receiver s display while the user listens to a radio station.

IBOC digital radio broadcasting technology can provide digital quality audio superior to existing analog broadcasting formats. Because each IBOC digital radio broadcasting signal is transmitted within the spectral mask of an existing AM or FM channel allocation it requires no new spectral allocations. IBOC digital radio broadcasting promotes economy of spectrum while enabling broadcasters to supply digital quality audio to the present base of listeners.

Multicasting the ability to deliver several audio programs or services over one channel in the AM or FM spectrum enables stations to broadcast multiple services and supplemental programs on any of the sub channels of the main frequency. For example multiple data services can include alternative music formats local traffic weather news and sports. The supplemental services and programs can be accessed in the same manner as the traditional station frequency using tuning or seeking functions. For example if the analog modulated signal is centered at 94.1 MHz the same broadcast in IBOC can include supplemental services 94.1 2 and 94.1 3. Highly specialized supplemental programming can be delivered to tightly targeted audiences creating more opportunities for advertisers to integrate their brand with program content. As used herein multicasting includes the transmission of one or more programs in a single digital radio broadcasting channel or on a single digital radio broadcasting signal. Multicast content can include a main program service MPS supplemental program services SPS program service data PSD and or other broadcast data.

The National Radio Systems Committee a standard setting organization sponsored by the National Association of Broadcasters and the Consumer Electronics Association adopted an IBOC standard designated NRSC 5 in September 2005. NRSC 5 and its updates the disclosure of which are incorporated herein by reference set forth the requirements for broadcasting digital audio and ancillary data over AM and FM broadcast channels. The standard and its reference documents contain detailed explanations of the RF transmission subsystem and the transport and service multiplex subsystems. Copies of the standard can be obtained from the NRSC at http www.nrscstandards.org SG.asp. iBiquity s HD Radio technology is an implementation of the NRSC 5 IBOC standard. Further information regarding HD Radio technology can be found at www.hdradio.com and www.ibiquity.com.

Other types of digital radio broadcasting systems include satellite systems such as Satellite Digital Audio Radio Service SDARS e.g. XM Radio Sirius Digital Audio Radio Service DARS e.g. WorldSpace and terrestrial systems such as Digital Radio Mondiale DRM Eureka 147 branded as DAB Digital Audio Broadcasting DAB Version 2 and FMeXtra. As used herein the phrase digital radio broadcasting encompasses digital audio broadcasting including in band on channel broadcasting as well as other digital terrestrial broadcasting and satellite broadcasting.

As described above one advantage of digital radio broadcasting systems is that they provide the capability to transmit multiple services including audio and data over one AM or FM frequency. For certain applications such as displaying album art image slide shows scrolling text information closed captioning and product purchase information it may be desirable to synchronize the content contained in one service with content contained in another service or to synchronize subservices or components of the same service.

The present inventors have observed that conventional techniques of receiving content from multiple sources place responsibility on each source for scheduling and delivering its content for broadcast. For example consider a studio having two media sources an album art application for providing images relating to a song and a station logo application for providing the station logo. Conventional systems would make the album art application responsible for scheduling and delivering its images for broadcast and the station logo application independently responsible for its images. Even in this simple example such a configuration is not ideal because it can cause redundancy e.g. both applications are involved in scheduling and misallocation of bandwidth e.g. each application may be assigned its own bandwidth which may be over or under utilized . Another inefficiency with this approach is caused by the fact that the album art application needs to broadcast its content synchronously with the song being played whereas the station logo information can be broadcast asynchronously i.e. not synchronized with any particular song . Because the transmission of the synchronous and asynchronous media is not coordinated between the applications bandwidth may be allocated inefficiently to each. Moreover when numerous media applications and or studios are involved these problems multiply accordingly.

The present inventors have determined that conventional techniques of scheduling and delivering content from multiple sources can be improved.

Embodiments of the present disclosure are directed to systems and methods that may satisfy these needs. According to exemplary embodiments a computer implemented method of scheduling and delivering content for digital radio broadcast transmission is disclosed. The method is characterized by the steps of receiving a request to render first media content in synchronization with second media content wherein the first media content is directed along a first signal path through a digital radio broadcast transmitter and the second media content is directed along a second signal path through the digital radio broadcast transmitter and wherein the request includes a requested render time of the second media content by a digital radio broadcast receiver receiving a request to render third media content asynchronously at the digital radio broadcast receiver receiving a plurality of content requests from an importer each content request including a value corresponding to a time at which media content following the second signal path that is delivered responsive to the content request would be rendered by the digital radio broadcast receiver delivering the first media content to the importer responsive to at least one of the content requests when the value of the content request corresponds to the render time of the second media content such that the first media content can be rendered synchronously with the second media content by the digital radio broadcast receiver and delivering the third media content to the importer responsive to at least one of the content requests such that the third media content can be rendered asynchronously by the digital radio broadcast receiver.

A system comprising a processing system and a memory coupled to the processing system is described wherein the processing system is configured to carry out the above described method. Computer programming instructions adapted to cause a processing system to carry out the above described method may be embodied within any suitable article of manufacture such as a computer readable storage medium.

Digital radio broadcast systems as described herein can provide scheduling and delivering content for digital radio broadcast transmission. To overcome the inefficiencies of conventional scheduling and delivery techniques the present inventors have developed a novel multiport synchronous asynchmnous client for receiving content from multiple sources and then scheduling and delivering that content to an importer.

As referred to herein a service is any analog or digital medium for communicating content via radio frequency broadcast. For example in an IBOC radio signal the analog modulated signal the digital main program service and the digital supplemental program services could all be considered services. Other examples of services can include conditionally accessed programs CAs which are programs that require a specific access code and can be both audio and or data such as for example a broadcast of a game concert or traffic update service and data services such as traffic data multimedia and other files and service information guides SIGs .

Additionally as referred to herein media content is any substantive information or creative material including for example audio video text image or metadata that is suitable for processing by a processing system to be rendered displayed played back and or used by a human.

Furthermore one of ordinary skill in the art would appreciate that what amounts to synchronization can depend on the particular implementation. As a general matter two pieces of content are synchronized if they make sense in temporal relation to one another when rendered to a listener. For example album art may be considered synchronized with associated audio if the onset of the images either leads or follows the onset of the audio by 3 seconds or less. For a karaoke implementation for example a word of karaoke text should not follow its associated time for singing that word but can be synchronized if it precedes the time for singing the word by as much as a few seconds e.g. 1 to 3 seconds . In other embodiments content may be deemed synchronized if it is rendered for example within about 3 seconds of associated audio or within about one tenth of a second of associated audio.

Referring to the drawings is a functional block diagram of exemplary relevant components of a studio site an FM transmitter site and a studio transmitter link STL that can be used to broadcast an FM IBOC digital radio broadcasting signal. The studio site includes among other things studio automation equipment an Ensemble Operations Center FOC that includes an importer an exporter and an exciter auxiliary service unit EASU . An STL transmitter links the FOC with the transmitter site. The transmitter site includes an STL receiver an exciter that includes an exciter engine exgine subsystem and an analog exciter . While in the exporter is resident at a radio station s studio site and the exciter is located at the transmission site these elements may be co located at the transmission site.

At the studio site the studio automation equipment supplies main program service MPS audio to the EASU MPS data to the exporter supplemental program service SPS audio to the importer and SPS data to the importer . MPS audio serves as the main audio programming source. In hybrid modes it preserves the existing analog radio programming formats in both the analog and digital transmissions. MPS data or SPS data also known as program service data PSD includes information such as music title artist album name etc. PSD is typically encoded using ID3 tags. Supplemental program service can include supplementary audio content as well as program service data.

The importer contains hardware and software for supplying advanced application services AAS . AAS can include any type of data that is not classified as MPS SPS or Station Information Service SIS . SIS provides station information such as call sign absolute time position correlated to GPS etc. Examples of AAS include data services for electronic program guides navigation maps real time traffic and weather information multimedia applications other audio services and other data content. The content for AAS can be supplied by service providers which provide service data to the importer via an application program interface API . The service providers may be a broadcaster located at the studio site or externally sourced third party providers of services and content. The importer can establish session connections between multiple service providers. The importer encodes and multiplexes service data SPS audio and SPS data to produce exporter link data which is output to the exporter via a data link. The importer also encodes a SIG in which it typically identifies and describes available services. For example the SIG may include data identifying the genre of the services available on the current frequency e.g. the genre of MPS audio and any SPS audio .

The importer can use a data transport mechanism which may be referred to herein as a radio link subsystem RLS to provide packet encapsulation varying levels of quality of service e.g. varying degrees of forward error correction and interleaving and bandwidth management functions. The RLS uses High Level Data Link Control HDLC type framing for encapsulating the packets. HDLC is known to one of skill in the art and is described in ISO IEC 13239 2002 Information technology Telecommunications and information exchange between systems High level data link control HDLC procedures. HDLC framing includes a beginning frame delimiter e.g. 0x7E and an ending frame delimiter e.g. 0x7E . The RLS header includes a logical address e.g. port number control field for sequence numbers and other information e.g. packet 1 of 2 2 of 2 etc. the payload e.g. the index file and a checksum e.g. a CRC . For bandwidth management the importer typically assigns logical addresses e.g. ports to AAS data based on for example the number and type of services being configured at any given studio site . RLS is described in more detail in U.S. Pat. No. 7 305 043 which is incorporated herein by reference in its entirety.

In media content transmission applications the amount of bandwidth the importer allocates to a given service depends upon several factors including a the size of the media content e.g. the image or video size b the amount of time the media content is retransmitted for error mitigation and c the rate at which the media content needs to arrive or alternatively how long the media content should be displayed.

The size of the media content e.g. images depends upon the number of pixels the amount and type of compression used and the complexity of the original image. Images transmitted for use as cover art or station logos typically have the following characteristics a image resolution within 170 200 170 200 pixels b square images are preferable c gray scale or color are possible d gray scale images are typically 8 bits per pixel f color images are typically 24 bits per pixel 8 bits each for red green and blue and g file sizes typically have 24 kbyte maximum size with 12 kbyte nominal. Other applications will have image characteristics suitable for the given application.

In exemplary embodiments it may be desirable to retransmit media content such as images to improve robustness to channel errors. The number of times media content is retransmitted is an implementation decision that relates to the reliability of the communication channel. As such various repeat strategies may be used with media content files. For example one strategy that may be desirable when transmitting album art images is that the first transmission of each image is sent prior to the start of an associated audio track and sending a second occurrence of the image file immediately after the start of the song. If there are no errors in the received file the image will be rendered by the receiver coincident with the beginning of the track. And if the receiver failed to receive the image after the first transmission it can quickly recover the image on the second occurrence while the song is still in progress. In another example if the broadcaster has sufficient bandwidth each album art image may be transmitted three times. In this case each image is sent twice prior to the beginning of the audio track and once after the start of the track for fast receiver acquisition . Each image file is interleaved with others to increase the likelihood of the receiver recovering the image in the presence of burst errors e.g. long signal dropouts on the RF channel.

The number of retransmissions is a design choice involving a tradeoff between bandwidth requirements and reliability. For example assume a packet size of 256 bytes and a conservative estimate of 1 packet loss on the communication channel. The typical image and file sizes described above will require 12 50 and 100 256 byte packets to transmit 3 kbyte 12.5 kbyte and 24 kbyte files respectively. Assuming uniformly distributed packet errors the probability of receiving an entire image file would then be approximated as P 1 0.99 where N 15 50 or 100. Table 1 below shows the result of these approximations for repeating transmission of the image 1 2 and 3 times.

The time between displaying different media content files is the third parameter when allocating bandwidth. This time is a function of the application. For example in cover art applications if only one image is displayed per song then the transfer time can be on the order of two minutes whereas if the application is a slide show or if images need to be displayed with advertisements a new image could be needed every 15 seconds. Typically the shortest time between image displays should be used to calculate bandwidth requirements. As an illustration assume a slide show displays 300 300 pixel images once every 15 seconds 10 ALFNs using a repeat value of 2. Then T Transmit time 10 ALFNs 15 seconds with 1 PDU per ALFN and S Size of the image 48 kbytes 24 kbytes . Thus B required bandwidth S T 48 kbytes 10 PDUs 4.8 kbytes per PDU which is approximately 25 kbit s.

Due to receiver implementation choices RLS packets can be limited in size to about 8192 bytes but other sizes could be used. Therefore in exemplary embodiments data may be prepared for transmission according to four data segmentation modes standard packets variable packets large object transfer LOT and byte streaming for transmitting objects larger than the maximum packet size.

In packet delivery mode i.e. standard and variable packet modes packets are delivered to the importer already encapsulated by a client application. In standard packet mode the client application is limited to packet sizes no greater than its bandwidth allocation on a per PDU basis. Therefore the client application should have knowledge of its allocated bandwidth bit s and the rate of the logical channel being used to broadcast data. For example the P1 logical channel has a PDU rate of approximately 1.486 seconds and the P3 logical channel has a PDU rate of approximately 0.186 seconds. Based on these characteristics a client application with a bandwidth allocation using P1 of 1 kbit sec would be limited in packet size to 1000 bits sec 1 byte 8 bits 1.486 seconds per PDU 185 bytes. An advantage of standard packet mode is that packets are guaranteed to be delivered to the receiver in every PDU. Therefore if the client application can adjust its native packet size to match its bandwidth allocation and logical channel rate it can use native encapsulation to minimize processing on the receiver side.

Variable packet mode is similar to standard packet mode except that the packet sizes are independent of the allocated bandwidth. This means that the bandwidth allocation is statistical in nature and client applications may incur substantial jitter in the delivery of the data packets i.e. there is a non guaranteed delivery time . However the advantage of variable packets is that the importer can allocate minimal bandwidth to the service and still maintain their native packet structure independent of the logical channel. On the other hand services that are allocated minimal bandwidth will affect the delivery jitter of all other data services using variable packet mode i.e. services do not control their own performance . Thus the variable packet mode is best suited for non real time applications. When transmitting images the difference between the packet delivery methods can affect how far in advance the image must be transmitted to ensure that it arrives in time to be rendered in synchronization with the associated audio.

The importer may also include a large object transfer LOT client e.g. a software client that executes on the same computer processing system as the importer or on a different processing system such as a remote processing system to segment a large object for example a sizeable image file into fragments no larger than the chosen RLS packet size. In typical embodiments objects may range in size up to 4 294 967 295 bytes. At the transmitter the LOT client writes packets to an RLS port for broadcast to the receiver. At the receiver the LOT client reads packets from the RLS port of the same number. The LOT client may process data associated with many RLS ports e.g. typically up to 32 ports simultaneously both at the receiver and the transmitter.

The LOT client operates by sending a large object in several messages each of which is no longer than the maximum packet size. To accomplish this the transmitter assigns an integer called a LotID to each object broadcast via the LOT protocol. All messages for the same object will use the same LotID. The choice of LotID is arbitrary except that no two objects being broadcast concurrently on the same RLS port may have the same LotID. In some implementations it may be advantageous to exhaust all possible LotID values before a value is reused.

When transmitting data over the air there may be some packet loss due to the probabilistic nature of the radio propagation environment. The LOT client addresses this issue by allowing the transmitter to repeat the transmission of an entire object. Once an object has been received correctly the receiver can ignore any remaining repetitions. All repetitions will use the same LotID. Additionally the transmitter may interleave messages for different objects on the same RLS port so long as each object on the port has been assigned a unique LotID.

The LOT client divides a large object into messages which are further subdivided into fragments. Preferably all the fragments in a message excepting the last fragment are a fixed length such as 256 bytes. The last fragment may be any length that is less than the fixed length e.g. less than 256 bytes . Fragments are numbered consecutively starting from zero. However in some embodiments an object may have a zero length object the messages would contain only descriptive information about the object.

The LOT client typically uses two types of messages a full header message and a fragment header message. Each message includes a header followed by fragments of the object. The full header message contains the information to reassemble the object from the fragments plus descriptive information about the object. By comparison the fragment header message contains only the reassembly information. The LOT client of the receiver e.g. a software and or hardware application that typically executes within the data processors and of respectively or any other suitable processing system distinguishes between the two types of messages by a header length field e.g. field name hdrLen . Each message can contain any suitable number of fragments of the object identified by the LotID in the header as long as the maximum RLS packet length is not exceeded. There is no requirement that all messages for an object contain the same number of fragments. Table 2 below illustrates exemplary field names and their corresponding descriptions for a full header message. Fragment header messages typically include only the hdrLen repeat LotID and position fields.

Full header and fragment header messages may be sent in any ratio provided that at least one full header message is broadcast for each object. Bandwidth efficiency will typically be increased by minimizing the number of full header messages however this may increase the time necessary for the receiver to determine whether an object is of interest based on the descriptive information that is only present in the full header. Therefore there is typically a trade between efficient use of broadcast bandwidth and efficient receiver processing and reception of desired LOT files.

In byte streaming mode as in packet mode each data service is allocated a specific bandwidth by the radio station operators based on the limits of the digital radio broadcast modem frames. The importer then receives data messages of arbitrary size from the data services. The data bytes received from each service are then placed in a byte bucket e.g. a queue and HDLC frames are constructed based on the bandwidth allocated to each service. For example each service may have its own HDLC frame that will be just the right size to fit into a modem frame. For example assume that there are two data services service 1 and service 2. Service 1 has been allocated 1024 bytes and service 2 512 bytes. Now assume that service 1 sends message A having 2048 bytes and service 2 sends message B also having 2048 bytes. Thus the first modem frame will contain two HDLC frames a 1024 byte frame containing N bytes of message A and a 512 byte HDLC frame containing M bytes of message B. N M are determined by how many HDLC escape characters are needed and the size of the RLS header information. If no escape characters are needed then N 1015 and M 503 assuming a 9 byte RLS header. If the messages contain nothing but HDLC framing bytes i.e. 0x7E then N 503 and M 247 again assuming a 9 byte RLS header containing no escape characters. Also if data service 1 does not send a new message call it message AA then its unused bandwidth may be given to service 2 so its HDLC frame will be larger than its allocated bandwidth of 512 bytes.

The exporter contains the hardware and software necessary to supply the main program service and SIS for broadcasting. The exporter accepts digital MPS audio over an audio interface and compresses the audio. The exporter also multiplexes MPS data exporter link data and the compressed digital MPS audio to produce exciter link data . In addition the exporter accepts analog MPS audio over its audio interface and applies a pre programmed delay to it to produce a delayed analog MPS audio signal . This analog audio can be broadcast as a backup channel for hybrid IBOC digital radio broadcasts. The delay compensates for the system delay of the digital MPS audio allowing receivers to blend between the digital and analog program without a shift in time. In an AM transmission system the delayed MPS audio signal is converted by the exporter to a mono signal and sent directly to the STL as part of the exciter link data .

The EASU accepts MPS audio from the studio automation equipment rate converts it to the proper system clock and outputs two copies of the signal one digital and one analog . The EASU includes a GPS receiver that is connected to an antenna The GPS receiver allows the EASU to derive a master clock signal which is synchronized to the exciter s clock by use of GPS units. The EASU provides the master system clock used by the exporter. The EASU is also used to bypass or redirect the analog MPS audio from being passed through the exporter in the event the exporter has a catastrophic fault and is no longer operational. The bypassed audio can be fed directly into the STL transmitter eliminating a dead air event.

STL transmitter receives delayed analog MPS audio and exciter link data . It outputs exciter link data and delayed analog MPS audio over STL link which may be either unidirectional or bidirectional. The STL link may be a digital microwave or Ethernet link for example and may use the standard User Datagram Protocol or the standard TCP IP.

The transmitter site includes an STL receiver an exciter engine exgine and an analog exciter . The STL receiver receives exciter link data including audio and data signals as well as command and control messages over the STL link . The exciter link data is passed to the exciter which produces the IBOC digital radio broadcasting waveform. The exciter includes a host processor digital up converter RF up converter and exgine subsystem . The exgine accepts exciter link data and modulates the digital portion of the IBOC digital radio broadcasting waveform. The digital up converter of exciter converts from digital to analog the baseband portion of the exgine output. The digital to analog conversion is based on a GPS clock common to that of the exporter s GPS based clock derived from the EASU. Thus the exciter includes a GPS unit and antenna . An alternative method for synchronizing the exporter and exciter clocks can be found in U.S. Pat. No. 7 512 175 the disclosure of which is hereby incorporated by reference. The RF up converter of the exciter up converts the analog signal to the proper in band channel frequency. The up converted signal is then passed to the high power amplifier and antenna for broadcast. In an AM transmission system the exgine subsystem coherently adds the backup analog MPS audio to the digital waveform in the hybrid mode thus the AM transmission system does not include the analog exciter . In addition in an AM transmission system the exciter produces phase and magnitude information and the analog signal is output directly to the high power amplifier.

IBOC digital radio broadcasting signals can be transmitted in both AM and FM radio bands using a variety of waveforms. The waveforms include an FM hybrid IBOC digital radio broadcasting waveform an FM all digital IBOC digital radio broadcasting waveform an AM hybrid IBOC digital radio broadcasting waveform and an AM all digital IBOC digital radio broadcasting waveform.

The hybrid waveform includes an analog FM modulated signal plus digitally modulated primary main subcarriers. The subcarriers are located at evenly spaced frequency locations. The subcarrier locations are numbered from to . In the waveform of the subcarriers are at locations to and to . Each primary main sideband is comprised of ten frequency partitions. Subcarriers and also included in the primary main sidebands are additional reference subcarriers. The amplitude of each subcarrier can be scaled by an amplitude scale factor.

The upper primary extended sidebands include subcarriers through one frequency partition through two frequency partitions or through four frequency partitions . The lower primary extended sidebands include subcarriers through one frequency partition through two frequency partitions or through four frequency partitions . The amplitude of each subcarrier can be scaled by an amplitude scale factor.

In addition to the ten main frequency partitions all four extended frequency partitions are present in each primary sideband of the all digital waveform. Each secondary sideband also has ten secondary main SM and four secondary extended SX frequency partitions. Unlike the primary sidebands however the secondary main frequency partitions are mapped nearer to the channel center with the extended frequency partitions farther from the center.

Each secondary sideband also supports a small secondary protected SP region including 12 OFDM subcarriers and reference subcarriers and . The sidebands are referred to as protected because they are located in the area of spectrum least likely to be affected by analog or digital interference. An additional reference subcarrier is placed at the center of the channel 0 . Frequency partition ordering of the SP region does not apply since the SP region does not contain frequency partitions.

Each secondary main sideband spans subcarriers through or through . The upper secondary extended sideband includes subcarriers through and the upper secondary protected sideband includes subcarriers through plus additional reference subcarrier . The lower secondary extended sideband includes subcarriers through and the lower secondary protected sideband includes subcarriers through plus additional reference subcarrier . The total frequency span of the entire all digital spectrum is 396 803 Hz. The amplitude of each subcarrier can be scaled by an amplitude scale factor. The secondary sideband amplitude scale factors can be user selectable. Any one of the four may be selected for application to the secondary sidebands.

In each of the waveforms the digital signal is modulated using orthogonal frequency division multiplexing OFDM . OFDM is a parallel modulation scheme in which the data stream modulates a large number of orthogonal subcarriers which are transmitted simultaneously. OFDM is inherently flexible readily allowing the mapping of logical channels to different groups of subcarriers.

In the hybrid waveform the digital signal is transmitted in primary main PM sidebands on either side of the analog FM signal in the hybrid waveform. The power level of each sideband is appreciably below the total power in the analog FM signal. The analog signal may be monophonic or stereophonic and may include subsidiary communications authorization SCA channels.

In the extended hybrid waveform the bandwidth of the hybrid sidebands can be extended toward the analog FM signal to increase digital capacity. This additional spectrum allocated to the inner edge of each primary main sideband is termed the primary extended PX sideband.

In the all digital waveform the analog signal is removed and the bandwidth of the primary digital sidebands is fully extended as in the extended hybrid waveform. In addition this waveform allows lower power digital secondary sidebands to be transmitted in the spectrum vacated by the analog FM signal.

The AM hybrid IBOC digital radio broadcasting signal format in one example comprises the analog modulated carrier signal plus OFDM subcarrier locations spanning the upper and lower bands. Coded digital information representative of the audio or data signals to be transmitted program material is transmitted on the subcarriers. The symbol rate is less than the subcarrier spacing due to a guard time between symbols.

As shown in the upper band is divided into a primary section a secondary section and a tertiary section . The lower band is divided into a primary section a secondary section and a tertiary section . For the purpose of this explanation the tertiary sections and can be considered to include a plurality of groups of subcarriers labeled and in . Subcarriers within the tertiary sections that are positioned near the center of the channel are referred to as inner subcarriers and subcarriers within the tertiary sections that are positioned farther from the center of the channel are referred to as outer subcarriers. The groups of subcarriers and in the tertiary sections have substantially constant power levels. also shows two reference subcarriers and for system control whose levels are fixed at a value that is different from the other sidebands.

The power of subcarriers in the digital sidebands is significantly below the total power in the analog AM signal. The level of each OFDM subcarrier within a given primary or secondary section is fixed at a constant value. Primary or secondary sections may be scaled relative to each other. In addition status and control information is transmitted on reference subcarriers located on either side of the main carrier. A separate logical channel such as an IBOC Data Service IDS channel can be transmitted in individual subcarriers just above and below the frequency edges of the upper and lower secondary sidebands. The power level of each primary OFDM subcarrier is fixed relative to the unmodulated main analog carrier. However the power level of the secondary subcarriers logical channel subcarriers and tertiary subcarriers is adjustable.

Using the modulation format of the analog modulated carrier and the digitally modulated subcarriers are transmitted within the channel mask specified for standard AM broadcasting in the United States. The hybrid system uses the analog AM signal for tuning and backup.

The host controller receives and processes the data signals e.g. the SIS MPSD SPSD and AAS signals . The host controller comprises a microcontroller that is coupled to the display control unit DCU and memory module . Any suitable microcontroller could be used such as an Atmel AVR 8 bit reduced instruction set computer RISC microcontroller an advanced RISC machine ARM 32 bit microcontroller or any other suitable microcontroller. Additionally a portion or all of the functions of the host controller could be performed in a baseband processor e.g. the processor and or data processor . The DCU comprises any suitable I O processor that controls the display which may be any suitable visual display such as an LCD or LED display. In certain embodiments the DCU may also control user input components via touch screen display. In certain embodiments the host controller may also control user input from a keyboard dials knobs or other suitable inputs. The memory module may include any suitable data storage medium such as RAM Flash ROM e.g. an SD memory card and or a hard disk drive. In certain embodiments the memory module may be included in an external component that communicates with the host controller such as a remote control.

The host controller receives and processes the data signals e.g. SIS MPS data SPS data and AAS . The host controller comprises a microcontroller that is coupled to the DCU and memory module . Any suitable microcontroller could be used such as an Atmel AVR 8 bit RISC microcontroller an advanced RISC machine ARM 32 bit microcontroller or any other suitable microcontroller. Additionally a portion or all of the functions of the host controller could be performed in a baseband processor e.g. the processor and or data processor . The DCU comprises any suitable I O processor that controls the display which may be any suitable visual display such as an LCD or LED display. In certain embodiments the DCU may also control user input components via a touch screen display. In certain embodiments the host controller may also control user input from a keyboard dials knobs or other suitable inputs. The memory module may include any suitable data storage medium such as RAM. Flash ROM e.g. an SD memory card and or a hard disk drive. In certain embodiments the memory module may be included in an external component that communicates with the host controller such as a remote control.

In practice many of the signal processing functions shown in the receivers of can be implemented using one or more integrated circuits. For example while in the signal processing block host controller DCU and memory module are shown as separate components the functions of two or more of these components could be combined in a single processor e.g. a System on a Chip SoC .

As shown in and there is a configuration administrator which is a system function that supplies configuration and control information to the various entities within the protocol stack. The configuration control information can include user defined settings as well as information generated from within the system such as GPS time and position. The service interfaces represent the interfaces for all services. The service interface may be different for each of the various types of services. For example for MPS audio and SPS audio the service interface may be an audio card. For MPS data and SPS data the interfaces may be in the form of different APIs. For all other data services the interface is in the form of a single API. An audio encoder encodes both MPS audio and SPS audio to produce core Stream 0 and optional enhancement Stream 1 streams of MPS and SPS audio encoded packets which are passed to audio transport . Audio encoder also relays unused capacity status to other parts of the system thus allowing the inclusion of opportunistic data. MPS and SPS data is processed by PSD transport to produce MPS and SPS data PDUs which are passed to audio transport . Audio transport receives encoded audio packets and PSD PDUs and outputs bit streams containing both compressed audio and program service data. The SIS transport receives SIS data from the configuration administrator and generates SIS PDUs. A SIS PDU can contain station identification and location information indications regarding provided audio and data services as well as absolute time and position correlated to GPS as well as other information conveyed by the station. The AAS data transport receives AAS data from the service interface as well as opportunistic bandwidth data from the audio transport and generates AAS data PDUs which can be based on quality of service parameters. The transport and encoding functions are collectively referred to as Layer 4 of the protocol stack and the corresponding transport PDUs are referred to as Layer 4 PDUs or L4 PDUs. Layer 2 which is the channel multiplex layer receives transport PDUs from the SIS transport AAS data transport and audio transport and formats them into Layer 2 PDUs. A Layer 2 PDU includes protocol control information and a payload which can be audio data or a combination of audio and data. Layer 2 PDUs are routed through the correct logical channels to Layer 1 wherein a logical channel is a signal path that conducts L1 PDUs through Layer 1 with a specified grade of service and possibly mapped into a predefined collection of subcarriers.

Layer 1 data in an IBOC system can be considered to be temporally divided into frames e.g. modem frames . In typical embodiments each modem frame has a frame duration T of approximately 1.486 seconds. It will be appreciated that in other broadcast applications a frame may have different durations. Each modem frame includes an absolute layer 1 frame number ALFN in the SIS which is a sequential number assigned to every Layer 1 frame. This ALFN corresponds to the broadcast starting time of a modem frame. The start time of ALFN 0 was 00 00 00 Universal Coordinated Time UTC on Jan. 6 1980 and each subsequent ALFN is incremented by one from the previous ALFN. Thus the present time can be calculated by multiplying the next frame s ALFN with Tand adding the total to the start time of ALFN 0.

There are multiple Layer 1 logical channels based on service mode wherein a service mode is a specific configuration of operating parameters specifying throughput performance level and selected logical channels. The number of active Layer 1 logical channels and the characteristics defining them vary for each service mode. Status information is also passed between Layer 2 and Layer 1. Layer 1 converts the PDUs from Layer 2 and system control information into an AM or FM IBOC digital radio broadcasting waveform for transmission. Layer 1 processing can include scrambling channel encoding interleaving OFDM subcarrier mapping and OFDM signal generation. The output of OFDM signal generation is a complex baseband time domain pulse representing the digital portion of an IBOC signal for a particular symbol. Discrete symbols are concatenated to form a continuous time domain waveform which is modulated to create an IBOC waveform for transmission.

The following describes an exemplary process for digital radio broadcast transmission and reception of media content for synchronized rendering at a digital radio broadcast receiver in accordance with exemplary embodiments. First a general description of exemplary components and operation of a digital radio broadcast transmitter and digital radio broadcast receiver will be provided. Then exemplary embodiments of two techniques for transmitting and receiving synchronized media content will be discussed. Finally exemplary applications of the disclosed embodiments will be discussed. Note that in the following description reference will be made simultaneously to components of both the exemplary AM IBOC receiver of and the exemplary FM IBOC receiver of since the operation of both is substantially similar for purposes of the present disclosure. Thus for example the host controller is referred to below as the host controller .

An exemplary functional block diagram of the transmit side components of a digital radio broadcast system is illustrated in . As discussed above the functions illustrated in can be performed in a suitable combination of the importer the exporter and a client . These components can comprise a processing system that may include one or more processing units that may be co located or distributed and that are configured e.g. programmed with software and or firmware to perform the functionality described herein wherein the processing system can be suitably coupled to any suitable memory e.g. RAM Flash ROM ROM optical storage magnetic storage etc. . The importer communicates with a client application via a request response type application program interface API i.e. the importer requests data from the clients to receive data content such as album art image slide shows scrolling text information closed captioning product purchase information and video. The client application can be any suitable program that has access to the data content such as via a database or file directory and that is configured to prepare and send the media content to the importer in response to the importer s requests.

As discussed above the importer prepares the data content and secondary audio if any from a secondary audio source for digital radio broadcast transmission. It should be noted that data content from the client travels through a first signal path in the importer and the secondary audio for the SPS travels through a second signal path different from the first in the importer . Specifically data content from the client is received by an RLS encoder as AAS data where it is encapsulated as discussed above. The data content can be encapsulated using either the packet streaming technique e.g. LOT or the byte streaming technique. Once the data content is encapsulated by the RLS encoder the RLS packets are sent to the AAS SPS multiplexer where they are multiplexed with any secondary audio e.g. time division multiplexed . It should be noted that data is typically encoded via the RLS protocol which is different than the protocol used to transport the audio e.g. audio transport illustrated in and is therefore asynchronous with the audio. Secondary audio from the secondary audio source is digitally encoded to produce compressed SPSA audio frames by the audio encoder . Any suitable audio encoder can be used such as an HDC encoder as developed by Coding Technologies of Dolby Laboratories. Inc. 999 Brannan Street San Francisco Calif. 94103 4938 USA an Advanced Audio Coding AAC encoder an MPEG 1 Audio Layer 3 MP3 encoder or a Windows Media Audio WMA encoder. The secondary audio source may also include PSD such as music title artist album name etc. which is encoded as SPSD PDUs. The SPSD PDUs are passed from the secondary audio source through the audio encoder to the RLS encoder . The RLS encoder then encapsulates the SPSD PDUs and passes RLS frames back to the audio encoder . The audio encoder combines the SPSA audio frames and the RLS encoded SPSD if any into a single SPS PDU and outputs it to the AAS SPS multiplexer . The AAS SPS multiplexer then outputs packets to the exporter via the importer to exporter I2E interface .

The I2E interface is a two way handshake link that exists between the importer and the exporter to request AAS SPS frames for a specific modem frame. The I2E interface is typically a TCP IP connection although it could be any other suitable type of communication connection. As part of the I2E interface there is a configurable frame buffer in the exporter that can be used to overcome poor network performance when a TCP connection is used. The I2E interface outputs the multiplexed AAS SPS packets to the multiplexer in the exporter .

The main audio travels through a separate signal path from the secondary audio and the data content and therefore incurs a delay through the digital broadcast system that is distinct from both the data content and the secondary audio. Specifically the main audio content is input at the exporter while the data content and the secondary content are input at the importer . The main audio is provided by the main audio source and is digitally encoded to produce compressed MPSA audio frames by the audio encoder . Any suitable audio encoder can be used as described above. The main audio source may also include PSD that is encoded as MPSD PDUs. The MPSD PDUs are passed from the audio encoder to the RLS encoder where they are encapsulated and sent back to the audio encoder as RLS frames. The MPSD and MPSA packets are combined into a single MPS PDO and then sent to the multiplexer . A SIS module generates the SIS information including calculating the current ALFN and sends the SIS PDUs to the multiplexer . The multiplexer multiplexes the MPS SPS AAS and SIS to form a modem frame. The multiplexer then outputs the modem frame via the STL link described with reference to above to the exciter which produces the IBOC digital radio broadcasting waveform.

As noted above the AAS SPS and MPS may all travel through different signal paths in the digital radio broadcast transmission system thereby incurring different delays. The AAS incurs typically fixed delays due to RLS encoding and multiplexing in the importer . The SPS incurs not only the delays for encoding which is different than the RLS encoding delay for data as previously discussed and multiplexing but also another typically fixed delay for audio encoding in the importer . The delay for the SPS typically requires approximately six 6 modem frames of buffering to account for processing time. Furthermore the SPS and AAS both incur an additional configurable delay through the I2E link that is typically on the order of 20 modem frames. As noted above the MPS signal path does not pass through the I2E link and typically requires only approximately one 1 modem frame of buffering to account for processing time in the exporter . In addition the portion of the digital radio broadcast transmitter downstream of the exporter typically incurs an additional two 2 modem frames of delay due to buffering and processing. While approximate delay times have been provided for exemplary purposes it should be apparent that these examples in no way limit the scope of this disclosure or the claims.

Similarly the MPS and SPS audio and the AAS may travel through different signal paths in the digital radio broadcast receiver. Specifically as discussed with reference to the MPS and SPS are decoded and output directly from the baseband processor to the audio output whereas the AAS is transmitted as data content to the host controller from which it can be rendered via the display control unit . The digital radio broadcast receiver typically incurs an approximately two 2 modem frames of delay due to buffering and processing.

While it has been noted that the delays will typically vary from one service to another it should also be noted that these different delays will also vary from one radio frequency to another and from one geographic location to another. For example since different radio stations may employ different hardware software and or configurations the delays through the systems due to processing and buffering will not be the same.

As a result of these varying delays due to the multiple signal paths audio and data content can incur different latencies through the digital radio broadcast system. The digital radio broadcast transmitter accounts for these different latencies so as to render audio and data content in synchronization at the digital radio broadcast receiver. The importer includes a delay determination module that calculates approximate values for the various delays of data and audio through the signal paths in the digital radio broadcast system and outputs these values to the client . The delay determination module can be implemented in hardware software or any suitable combination thereof e.g. a programmed processing system .

The delay determination module in conjunction with the client determine how far in advance of the start of a given piece of media content e.g. an audio track another piece of media content e.g. an album art image must be transmitted such that it is available for rendering at the receiver when the first piece of content arrives. The following variables are used to make this determination 

The times are expressed in terms of ALFNs or fractions thereof for exemplary purposes but also may be expressed in terms of units of time such as seconds milliseconds or any other suitable units.

To determine the audio latency Dand D for MPS and SPS audio respectively the delay determination module adds the various delays including the I2E delay the audio buffering delay and the transmit receive delays. Similarly to determine the data content delay D the delay determination module adds the various delays including the I2E delay the data buffering delay and the transmit receive delays. In exemplary embodiments the delay determination module receives the current ALFN T i.e. the ALFN for the modem frame currently being generated by the exporter from the SIS module . The start of an audio segment will be delivered at the Exciter if MPS audio or Importer if SPS audio at ALFN T. The latency values can then be used to calculate a time Tat which the audio Tor data content Tdelivered to the importer is to be rendered at the digital radio broadcast receiver by adding Tto the calculated latency.

It should be noted that D i.e. the data delay is typically available only if the data is being transmitted via standard packet mode or byte streaming mode as discussed above. Typically delays in other modes e.g. LOT and variable packet mode are difficult to predict because the importer does not know whether any individual packet of data will be transmitted in a given modem frame.

Next the delay determination module communicates T T and Tto the client . In certain embodiments the delay determination module also sends channel data capacity information. This channel data capacity typically includes the expected bandwidth allocated to the client application B e.g. a number of bytes that the channel can transfer per frame and the channel rate R e.g. the number of frames per second . Using these two values the client can determine the channel capacity in bits per second. Given these values the client application can apply the proper timing either in the delivery of the data content to the importer or in the packaging of the data content with timing instructions such that satisfactory time synchronization can be achieved at the receiver.

The client can calculate the transfer time of the media content file Tin ALFNs which is a function of the bandwidth B channel rate R and size of the media content file S. Trepresents the number of ALFNs needed to transfer a complete image. An exemplary calculation is as follows 

Thus to render the media content when the audio segment begins rendering at the receiver the client determines the time Tat which to start transferring the image file to the importer . Tis a function of the transfer time T the delay of the audio through the system and the delay of the data through the system. This may be represented as T T T D D for MPS audio and T T T D D for SPS audio. illustrates this calculation.

In exemplary embodiments the second media content arrives at the receiver prior to the triggering instructions indicating that the receiver should render the second media content. Second media content sent too far in advance may not be stored in receiver memory at the time when it is needed for rendering and it may also be missed for receivers tuning from one station to another station. Preferably the second media content is sent less then 10 minutes in advance of its associated trigger. In some cases it may be desirable to make the media content available in advance of the audio to guard against additional processing delays or jitter associated with the data transport. And in some instances it may be desirable to retransmit the media content immediately after the beginning of the audio segment for example in case a user tunes to the audio service after it has started or the first media content transmission was not received.

In cases where the completion of the media content is transmitted to arrive a short time before the audio content the determination of the transmit time could be represented as T T T T D D where Tis a guard time. The guard time used will depend on various factors. First it may depend on the chosen packet transport mechanism. For example when using standard packet delivery mode or byte streaming mode every PDU will have service data. In typical applications a value of approximately 4 7 frames was found to produce acceptable performance with standard packet delivery mode. But when using variable packet delivery mode or LOT the bandwidth allocation is statistical in nature depends on bandwidth allocated to other services using variable packet delivery mode or LOT and there is no guaranteed time of delivery. As a result guard time will typically be larger when using these modes. As an example in certain applications using variable packet delivery mode an extra three frames approximately 5 seconds for P1 frames may be added for a total of 7 to 10 frames. As another example if 500 bit second are allocated to a service a LOT packet will only be transferred once every three frames in exemplary embodiments. Accordingly an extra three frames of guard time may be added for a total of 7 to 10 frames. In addition the guard time may depend on the speed and configuration of the receiver s host processor. As will be appreciated the determination of an appropriate guard time depends upon the implementation and may be determined empirically.

There are several aspects to associating a client s data service with an audio service a registering the data service with the importer b transmitting the association information to the receiver and c identification by the receiver that the data packets or LOT files are intended for a particular receiver application.

The registration of a data service with the importer is performed via the importer API. This registration notifies the importer that the data service is to be associated with a given audio service and or specific audio program.

Once the data service is registered with the importer data control instructions e.g. SIG are included in each modem frame that associate the data content from the client with the audio. These data control instructions cause the receiver to read the appropriate RLS port to access data content that is to be rendered in synchronization with the audio. As discussed above each modem frame typically includes a SIG. The SIG includes information regarding the data and audio services that are advertised in SIS including RLS port assignments. SIG allows the receiver to determine that a service exists pursue reception of the indicated service and render the service if it is selected. However it should be noted that SIG does not necessarily provide access to the contents of the service for example if the service is a CA service. SIG is broadcast over a fixed RLS port by the radio station that provides the service and is periodically updated.

Structurally the SIG contains information pertaining to each service being broadcast that is organized into service records. Typically as each client connects to the importer a new audio or data service record will be constructed for that service. Service records typically include information descriptors i.e. attributes of the service . For example an audio service record will typically include information that describes the genre additional processing instructions and a service display name. In addition a service may have other services associated with it. For example an SPS may have data services associated with it as subservices that could include scrolling text album art closed captioning product purchase information e.g. ID3 tags etc. In this case the information about the associated subservice is included in the service record of the main service. When a digital radio broadcast receiver receives and decodes the SIG it parses the information of the service records to determine whether there are any associated subservices and renders any information about that subservice with the current service. For example if the receiver tunes to and renders SPS1 and the service record for SPS1 includes a subservice that includes album art then the receiver will access the associated RLS port containing the album art.

An exemplary SIG message is illustrated in . The example in includes two concatenated service records Service Record 1 and Service Record 2. Service Record 1 describes an audio service SPS and an associated data service. Service Record 1 includes a main audio service and a single associated data service indicated by the main and subservice tags. The main service is an audio service and includes audio service information descriptors. The subservice is an associated data service e.g. album art or closed captioning information and includes data service information descriptors. Likewise Service Record 2 describes only a main data service e.g. stock ticker or weather information . Service Record 2 includes a main data service tag and data service information descriptors.

While the data content is described above as being associated with the audio by including subservice information descriptors in the SIG in certain embodiments the data content can be associated with the audio in other ways. For example a descriptor of the main service could include a link to associate the audio service with a different data service record.

After the digital radio broadcast transmitter broadcasts the modem frames over the air a digital radio broadcast receiver then receives the modem frames and processes them so that the included content can be rendered for an end user. The SIG and SIS MIME types and their associated hash values are used to identify that a particular data stream is associated with a particular receiver application which may or may not be available on the host processor of the receiver . Advantageously a receiver may be able to receive programming information regarding stations that broadcast only in legacy analog waveform and otherwise have no digital or other means of conveying their program schedule.

As an example a synchronized image application typically transmits images as an audio related data service using the LOT protocol to transmit images although other data delivery modes such as standard and variable packets and byte streaming are possible. Each image may be repeated sufficiently to minimize loss of data due to bit errors as described above.

In certain embodiments a broadcaster may desire to or be required to transmit a textual promotional message along with an image as may happen with an advertisement or images such as album art that are licensed to the broadcaster for promotional use of the songs being broadcast. Also it may be desirable to communicate to a listener along with an image that a song or other item or service may be purchased. In these cases it may be desirable to require that the broadcaster also transmit a commercial frame in the PSD having a promotional message for that particular song or album to show promotional use of the images. Because the promotional message is contained within PSD it is already coupled to its associated audio content and it can be broadcast at the same time as the triggering information for its associated image. Other images such as artist performance images advertisements local station images program related images and genre related images may also be transmitted. In these examples a broadcaster may include supporting messages in the commercial frame relating to the audio segment e.g. advertisements talk shows for which an image is being broadcast. Receivers may display the content of the commercial frame during the rendering of the song audio segment for which the image is being broadcast. These messages can be displayed at any time during the duration of the associated song audio segment.

Text based applications such as closed captioning product purchase information or radio karaoke may transmit text using two different methods 1 as an audio related data service using LOT byte streaming or standard or variable packet delivery modes or 2 in the ID3 tags of the PSD. In certain embodiments LOT may be inefficient for text applications due to the typically small file size associated with text and the large overhead for LOT encoding. Additionally the jitter associated with both LOT and variable packets may make these methods inappropriate for real time text applications such as closed captioning. Accordingly for real time text based applications such as closed captioning or radio karaoke byte streaming and standard packet modes will be preferable because they provide guaranteed delivery times and minimal packet jitter. The text may be encoded using ASCII ISO 8859 1 Unicode or any other suitable method of text encoding as would be known to one of skill in the art. Alternatively text based applications may transmit text in the ID3 tags included with the PSD. For applications requiring limited text such as providing product purchase information including a commercial frame in the PSD may be preferable. However since the capacity for extra text in the PSD may be limited using a separate data service may be preferable for other text based applications.

The presentation time of media content is controlled by the service provider at the transmitter side. This means that rendering the media content associated with the audio service is done at the digital radio broadcast receiver without the digital radio broadcast receiver making determinations about the relative timing for rendering the second media content and the first media content. This may be accomplished by including triggering instructions such as a custom ID3 frame with the other PSD information e.g. song title artist tagging information etc. in an ID3 tag.

To synchronize the rendering of the media content with an audio program the transmission of the triggering instructions is scheduled so that they arrive at the digital radio broadcast receiver to trigger immediate rendering of the media content in synchronization with the associated audio program. To accomplish this the delay of the PSD relative to the various audio services is determined e.g. based on empirical measurements and the ID3 frame with the control instructions is inserted into the relevant PSD. In order keep the PSD aligned with its associated audio preferably within 3 seconds PSD messages should arrive at the broadcast equipment within 0.5 seconds of each new audio segment or song and only one PSD message should be sent per audio segment or song. If alignment tighter than 3 seconds is desired this can be achieved using the measured values of PSD alignment to send ID3 tags in advance of the audio. The delay of the PSD relative to the audio services is based on the service mode channel rate and PSD size. For example shows that in certain embodiments a 100 byte PSD message arrives about two seconds before the associated MPS audio. also shows that a 550 byte PSD arrives approximately four seconds after the MPS audio. It should be noted that SPS audio through the importer incurs an additional audio buffering delay and therefore the PSD for SPS audio arrives earlier than a similar PSD for MPS audio. For example as shown in a 550 byte PSD message arrives about 2.5 seconds after the SPS audio.

The nominal PSD rate is approximately 125 bytes per frame for frame rate channels. For block pair rate channels the nominal PSD rate is approximately 7 bytes per block pair for MPS and approximately 12 bytes per block pair for SPS . Accordingly each time the PSD size surpasses a 125 byte 7 byte or 12 byte multiple for frame rate block pair rate MPS and block pair rate SPS respectively the PSD timing is altered by a frame 1.486 seconds or a block pair 0.185 seconds . The determination of when to send the triggering instructions so that the media content is triggered to render in synchronicity with the audio program will take this additional delay into account.

In exemplary embodiments the triggering instructions can take the form of a custom ID3 frame using experimental frame identifier XHDR to trigger immediate rendering of media content in synchronization with the audio program. An exemplary format for the XHDR ID3 frame is shown in and follows the ID3v2 specification which is available at http www.id3.org and incorporated herein by reference in its entirety. The XHDR ID3 frame includes the following three parts 

1 ID3 frame header This includes information regarding the size and content of the payload so that the receiver can determine whether it has system resources to decode and present the content.

3 Body The body carries a list of different parameters describing actions to be performed by a receiver application.

As shown in an exemplary ID3 frame header includes a frameID that consists of the four characters XHDR a size field that contains the frame size excluding the frame header and a flag field for use as described in the ID3v2 specification. An exemplary ID3 frame body includes a list of different parameters followed by any specific data needed by that parameter. These parameters describe various actions to be performed by the receiver application. For example the display of an image transmitted via LOT can be triggered by the receipt of the XHDR frame that contains a LOTID that matches the LOTID of a received image. Similarly if byte streaming standard packet or variable packet delivery modes are used the XHDR frame could include a packet sequence number or range of packet sequence numbers that would trigger the rendering of data in these packets e.g. text data .

In exemplary embodiments the client adds a header to the data content to facilitate transport and decoding. illustrates a data content packet in accordance with an exemplary content protocol. The packet includes an ordered collection of the following three items a header core a header extension and a body . The header core includes information regarding the size and the content of the payload to enable a digital radio broadcast receiver to determine whether it has system resources to decode and render the content. The header extension includes information that supports the handling or rendering of the included content. And the body carries the payload where the structure and content of the data in the payload is described in the header core and the header extension .

The exemplary header core is 8 bytes in length. While exemplary lengths are used herein for illustrative purposes any suitable lengths may be used as would be readily apparent to one of ordinary skill in the art. The header core includes a number of fields. First there is a SYNC field which is a two byte ASCII sequence that identifies the start of the packet. These SYNC bytes can be used by the digital radio broadcast receiver to defragment the packets when byte streaming mode is used. Second there is a one byte PR field that describes the major revision MAJ and the minor revision MIN of the current protocol being used. This can be desirable to ensure that the receiver is compatible with the protocol being used to encode the data content. Third there is a one byte Header EXT LEN field that describes the length of the extension header in bytes. Fourth there is a two byte Body LEN field that describes the length of the body in bytes. In certain embodiments a Body LEN of zero could indicate that the body length is greater than 2 16 65536 bytes and that there is a header extension parameter describing the actual body length. Fifth there is a one byte Type field that indicates the type of data included in the body . Finally there is a one byte Format field that indicates the format of the data included in the body . Exemplary Type and Format values are shown in Table 4 below.

As illustrated in Table 4 the data content in the packets can include XML ID3 tags for example as described in the ID3 informal standard version 2.3.0 available at http www.id3.org uncompressed pulse code modulated PCM audio samples HDC encoded audio JPEG images PNG images GIF images ISO IEC 8859 1 1998 encoded text ISO IEC 10646 1 2000 encoded text or a form of data that is application specific While these data formats are shown for exemplary purposes these examples in no way limit the scope of the disclosure or the claims and any other form of data could be included as would be known to one of ordinary skill in the art such as for example MP3 audio TIF images MPEG 4 video PDF or any other suitable data format.

The exemplary header extension can be of variable length and includes a number of parameters that describe various attributes associated with the content. Each parameter includes a one byte Parameter ID field and a variable length Body field. An exemplary list of parameters is shown in Table 5 below.

As illustrated in Table 5 the header extension can include start and end times and durations for presenting content in the body . Additionally the header extension can include a block offset that allows the start and end content presentation times to be offset in increments of 1 16 of the modem frame time i.e. if the modem frame time is 1.48 seconds then one block is 92.5 msecs in length . The block offset thereby allows fine tuning of the synchronization of the data content with the audio to within approximately 92.5 msecs. Certain embodiments may provide a content reuse capability. For example the extension header may include a Content ID descriptor that uniquely identifies the content described by the component. Receivers that have the capability to store content can store the content referenced by the Content ID using the Content ID as an index. If in the future the receiver identifies the same Content ID instead of accessing the specified RLS port to retrieve the content the receiver can instead retrieve the content from memory. This may be particularly advantageous for content that is repetitive. For example assume that a Top 40s radio station broadcasts a limited number of songs. Therefore the receiver could store the album art associated with each of these songs and could retrieve and display the album art as soon as each song begins.

In exemplary embodiments data control instructions e.g. SIG are included in each modem frame that associate the data content from the client with the audio. These data control instructions cause the receiver to read the appropriate RLS port to access data content that is to be rendered in synchronization with the audio. As discussed above each modem frame typically includes a SIG. The SIG includes information regarding the data and audio services that are advertised in SIS including RLS port assignments. SIG allows the receiver to determine that a service exists pursue reception of the indicated service and render the service if it is selected. However it should be noted that SIG does not necessarily provide access to the contents of the service for example if the service is a CA service. SIG is broadcast over a fixed RLS port by the radio station that provides the service and is periodically updated.

Structurally the SIG contains information pertaining to each service being broadcast that is organized into service records. Typically as each client connects to the importer a new audio or data service record will be constructed for that service. Service records typically include information descriptors i.e. attributes of the service . For example an audio service record will typically include information that describes the genre additional processing instructions and a service display name. In addition a service may have other services associated with it. For example an SPS may have data services associated with it as subservices that could include scrolling text album art closed captioning product purchase information e.g. ID3 tags etc. In this case the information about the associated subservice is included in the service record of the main service. When a digital radio broadcast receiver receives and decodes the SIG it parses the information of the service records to determine whether there are any associated subservices and renders any information about that subservice with the current service. For example if the receiver tunes to and renders SPS1 and the service record for SPS1 includes a subservice that includes album art then the receiver will access the associated RLS port containing the album art.

An exemplary SIG message is illustrated in . The example in includes two concatenated service records. Service Record 1 and Service Record 2. Service Record 1 describes an audio service e.g. SPS and an associated data service Service Record 1 includes a main audio service and a single associated data service indicated by the main and subservice tags. The main service is an audio service and includes audio service information descriptors. The subservice is an associated data service e.g. album art or closed captioning information and includes data service information descriptors. Likewise Service Record 2 describes only a main data service e.g. stock ticker or weather information . Service Record 2 includes a main data service tag and data service information descriptors.

While the data content is described above as being associated with the audio by including subservice information descriptors in the SIG in certain embodiments the data content can be associated with the audio in other ways. For example a descriptor of the main service could include a link to associate the audio service with a different data service record.

After the digital radio broadcast transmitter broadcasts the modem frames over the air a digital radio broadcast receiver then receives the modem frames and processes them so that the included content can be rendered for an end user. Advantageously a receiver may be able to receive programming information regarding stations that broadcast only in legacy analog waveform and otherwise have no digital or other means of conveying their program schedule.

An exemplary process of receiving processing and rendering the data content is described below. First the user powers on the digital radio broadcast receiver and then tunes the receiver to a desired radio station. On power up the host controller begins to repeatedly request various types of data e.g. SIS SIG and LOT segments from the baseband processor . The baseband processor retrieves the SIS and SIG from the modem frame decodes them and communicates them to the host controller responsive to a request. The host controller then parses the SIG record of the currently selected service to determine whether the station is broadcasting any associated data content. This indication will typically include either identifying a component associated with the audio component or a descriptor associating the audio component with another data service. If associated data content is available on a particular station the SIG will also indicate the RLS port number on which the associated data content can be received.

In certain embodiments the host controller may cause the display control unit to render an indication to the user that associated data is available. For example in closed captioning implementations this could be in the form of a lighted Closed Captioning Available button or an icon on a GUI. In certain embodiments the user may be able to choose whether to activate the closed captioning at this point. The user can then activate the closed captioning e.g. by pressing a suitable button which can be for example either a physical button on the receiver or a soft key button on a GUI. In certain embodiments the host controller may automatically begin rendering available data content without requiring user input.

While the receiver is tuned to a particular radio station the baseband processor is continuously receiving and buffering RLS packets that are broadcast from the radio station. In embodiments directed to packet mode transmission using LOT protocol the data processor may also be reassembling the packets into objects. These objects are then passed to the host controller responsive to a request e.g. a polling event . Alternatively RLS packets could be passed to the host controller which could then reassemble them into objects. Additionally in embodiments directed to byte streaming data transmission the RLS packets could be reassembled in either the data processor or the host controller . Furthermore the data content can then be reconstructed based on the content protocol described with reference to above. For example the data content packets can be distinguished and reassembled by utilizing the SYNC bytes of the header core . The receiver can determine the revision of the content protocol based on the PR fields to determine whether the content protocol is supported. Further the header core provides the type and format of the data content so that it may call the appropriate rendering application.

The host controller then renders and or stores the reassembled data content. The process of rendering and or storing the data content may vary depending on the specific implementation and the receiver capabilities. For example closed captioning information is typically rendered immediately in synchronization with the audio i.e. the synchronization is performed by the digital radio broadcast transmitter and the receiver makes no determinations about the relative rendering timing of the data content and the data content is not stored. Similarly radio karaoke and streaming text would also be immediately rendered and not stored. On the other hand album art image slide shows and product purchase information will typically be stored for later rendering in synchronization with the audio based on the timing instructions included in the header extension of the content protocol packet. In other words the data content is synchronized with the audio based on timing instructions inserted by the digital radio broadcast transmitter. In certain embodiments that allow for content reuse the stored album art image slide shows and product purchase information can be indexed with a Content ID so that it can be accessed multiple times. The rendering applications can be coded in software using any suitable programming language such as C C or for example and implementing such applications is within the purview of one of ordinary skill in the art.

Additionally different receivers will have different input display and memory capabilities. Some typical receiver s displays may include 4 line by 16 character LED or LCD displays 2 line by 16 character LED or LCD displays 256 color OEL displays multi line back lit LCD displays with 6 or larger multimedia displays and portable radio back lit LCD displays. Generally the receivers with more advanced displays have more available memory. Simpler receivers may only have a small amount of RAM e.g. less than 50 Kbytes while more advanced receivers may have a larger amount of RAM e.g. 100 Kbytes or more as well as non volatile memory such as Flash ROM e.g. built in Flash a hard disk drive and or a SD Memory Card . Advantageously exemplary embodiments of the present disclosure provide adaptable rendering and storage based on the capabilities of the receiver.

The data content may be stored in any suitable memory structure. For example a file system could be used such as NTFS or Journaling Flash File System version 2 JFFS2 . Alternatively the files could be stored in a database such as SQLite or MySQL. Naturally the memory structure utilized should be consistent with the memory capabilities of the receiver. Thus more capable receivers could have more complex memory structures. In some embodiments the data content may be stored in non volatile memory. In these cases the data content may be available immediately upon power up without requiring the download of any new data content.

The way the data content is rendered may also depend on the receiver characteristics e.g. display or memory capabilities and or according to user choice. For example a simple embedded receiver may only receive and display simple text based data content while a more capable receiver may display for example image slide shows album art and even video. Once the data content has been formatted for the display it can then be rendered by the DCU . In some embodiments filtering data content may be performed according to the end user s choice. Advantageously the displayed data content may be reduced for example by preventing display of album art or closed captioning upon the end user s selection and irrespective of the display s further capabilities.

Exemplary applications for synchronizing data content with audio content will now be described. The examples include an album art image slide show video application a closed captioning application a product purchase information application and a scrolling text application. However it should be understood that these examples are provided for illustrative purposes only and should not be considered to limit the scope of the disclosure or the claims.

An album art an image slide show and a video application would all typically operate in a similar manner. As described above with reference to the exporter sends a request message to the importer for a logical channel to generate a modem frame. Part of this request is the ALFN of the current modem frame. The importer then makes a content request to the client application which request includes the current ALFN and the time at which the audio transmitted in the modem frame is expected to be rendered by a digital radio broadcast receiver. In this case the client application may be for example an album art and or an image slide show application that includes an image repository containing for example JPG or GIF images. The client application also may be a video application including for example an H.264 video encoder and a video repository containing for example MPEG 4 video clips. The client application typically also has access to information related to the audio content.

The client application schedules the transmission of the relevant image and or video for transmission such that the image and or video is available at the receiver prior to the anticipated rendering time of the related song. The nature of the scheduling algorithm is an implementation consideration that would be within the purview of one of ordinary skill in the art. Any suitable scheduling technique could be used that would allow the images videos to arrive at the receiver in time for rendering with the associated audio. In certain embodiments a sophisticated scheduler could allow the image and or video to arrive at the receiver just in time for it to be rendered with the associated audio.

For example a scheduling application could schedule rendering of one or more images videos associated with a song or audio program e.g. advertisement sporting event talk show etc. based on the start end times of the song or audio program or equivalently start time and song duration and a duration percentage for displaying the images video i.e. how long each image is to be displayed with reference to the duration of the song or audio event . To obtain the song start end times the application could have access to a database that includes an audio service s play list wherein the database includes songs associated with the time when each song will be input into the importer or exporter for broadcast. To obtain a duration percentage for each image video the image video repository could include a display order and information describing a predetermined percentage of the associated song. The scheduler would determine the appropriate times for rendering the images videos based on this information and include these times with the transmitted image video using for example the content protocol described above with reference to

The images and or videos are encoded using the content protocol described above with reference to . Specifically the header core would typically include timing instructions e.g. StartALFN EndALFN duration and or block offset that will cause the receiver to render the images videos in synchronization with the audio. These timing instructions are adjusted by adding the difference between the Tand the Tto account for system latency for example as described above with reference to . Additionally the SIG record for the service would indicate that the receiver should use for example an album art or image slide show application to render the data content by including MIME type identifiers such as application x hdradio std album art 0x79a521f4 or application x hdradio std slide show 0x065945d07 . The client sends the encoded images videos to the importer . The importer then sends them to the exporter for digital radio broadcast transmission. It should be noted that images and videos will typically be encoded and transmitted using packet transmission e.g. LOT but they may also be transmitted using byte streaming. However one of skill in the art would appreciate that when images or videos are transmitted via byte streaming available broadcast bandwidth may limit the size of images videos. For example larger images and videos typically take longer to transmit assuming a fixed bandwidth availability. Therefore assuming that the images videos are transmitted so that they arrive just in time for rendering at the receiver the bandwidth constraints may limit the use of byte streaming to images or videos that can be broadcast within for example the duration of a song so that the image video is available for rendering at the beginning of the next song.

In operation the receiver will receive and download the images and or videos which will typically include timing instructions in the header if the packet transmission mode is being used. The receiver then polls the ALFN which is broadcast in the SIS. When the timing instructions indicate that the image or video should be displayed e.g. the polled ALFN matches the StartALFN of the stored image the image video will be displayed by the display control unit in synchronization with the receiver rendering the audio via the audio speakers. In certain embodiments if no images are available the receiver can display a default image.

A closed captioning application would provide text information that is synchronized with the audio. Examples of such an application can include radio for the hearing impaired or language translations. In this case the client application is a closed captioning application. For example the client could receive closed captioning input from a human operator a software implemented speech to text translator or a pre stored text file containing the text of the speech that has associated rendering times for components of the speech. For a human operator the client could present a word processing screen to the operator that presents the text that has been typed and indicating which text has already been transmitted. For example the words that have been transmitted could be grayed out after they have been sent based on the content request messages received from the importer .

The text would be encoded using the content protocol described above with reference to . Specifically the header core would include SYNC bits that allow the receiver to reassemble the text packets as described above. The text packets can be delivered for example using a fixed time or a number of characters to delimit the packets. The header extension may also include information indicating that the text should be rendered by the receiver as soon as it is received. However in certain embodiments the header core can include timing instructions e.g. StartALFN EndALFN duration and or block offset that will cause the receiver to render the text in synchronization with the audio. These timing instructions are adjusted based on T T and Tto account for system latency. Additionally the header core would indicate that the receiver should use a text rendering application to render the data content by including MIME type identifiers such as application x hdradio std closed caption 0x08c805636 .

Typically the client sends the text packets to the importer so that they arrive at the receiver just in time to be rendered in synchronization with the associated audio. Accordingly this application would typically use byte streaming to minimize delivery jitter. Additionally in certain embodiments the I2E link delay may be reduced to minimize latency. In certain embodiments the text packets can be buffered by the client to account for system latency. For example the client can use T T and Tto determine how much to buffer the text packets so that the text is rendered in synchronization with the audio. In certain embodiments the client can also use T T and Tto buffer the audio by providing an input to the audio encoder such that there is sufficient time for the text to be generated and delivered to the importer .

In operation the receiver may receive and immediately render the text characters. Alternatively the text can be rendered in synchronization with the audio based on timing instructions as described above. The display can be updated periodically as text is received e.g. reset or lines of text scrolled up or down in a text box . For example the receiver could establish an average number of words per minute or characters per second so that the words would be rendered smoothly to mitigate the burstiness of delivery. Additionally the display could be updated upon receipt of a new content packet after a predetermined amount of time or when the text box on the display is full.

A radio karaoke application would also provide highly synchronized text with the audio and would operate very similarly to the exemplary closed captioning application described above. However in certain embodiments a radio karaoke implementation may also include a receiver capability for reducing and or eliminating the vocals from an audio track in real time. This may be desirable to improve the karaoke experience for users. and illustrate exemplary components for receiver components in accordance with certain embodiments. illustrates an exemplary digital technique for reducing and or eliminating the vocal components of an audio track. With reference to the processor and blocks of an exemplary digital radio broadcast receiver are shown. The audio signal from blocks enters the vocal eliminator and audio processing block where it is processed. The vocal eliminator and audio processing block can be implemented for example in the baseband processor or in a separate processing system that includes software hardware or any suitable combination thereof and performs digital signal processing operations on the audio sufficient to substantially filter out the vocal component.

Any suitable vocal elimination algorithm could be used as would be known to one of skill in the art. For example assuming that the vocals are encoded on a center channel an exemplary algorithm might be as follows. The processing system could transform the left and right channels of the audio signal to the frequency domain using for example the Fast Fourier Transform FFT or Fast Hartley Transform FHT . Then for each frequency component where L is the 2D vector from the left channel and R is the 2D vector from the right channel the processing system would compute the center component C L L R R and then compute such that L C R C 0. Essentially the processing system would scale C so that when it is subtracted from L and R the two resultant vectors are perpendicular. Expanding this gives the equation C C C L R L R 0 which the processing system may solve for for example by the quadratic formula. Then it would compute C C L L C and R R C. Finally it would transform U R and C back to time domain using an inverse FFT or FHT overlap and add the signal components back together. While this exemplary algorithm may result in an undesirable removal of low frequency components a low pass filter could also be used to extract and then reinsert these low frequency components after the center component has been removed.

The vocal eliminator and audio processing block also includes a control signal input that may among other functions activate and deactivate the vocal eliminator operation. This control signal may be generated by the host controller according to a user s input. For example if a user is using a radio karaoke application the user may be presented with an icon or menu selection that allows them to choose to eliminate the vocals e.g. a VOCAL ELIMINATOR button . After processing the audio signal is then output to a digital to analog converter DAC which converts the digital signal to an analog audio output suitable for rendering by for example analog speakers.

In certain embodiments the receiver may also provide the capability for recording and storing a user s karaoke performance. For example in a receiver including a microphone input and sufficient data storage e.g. a hard disk drive flash ROM and or removable memory storage such as an SD card a karaoke application at the receiver could allow a user to activate a recording function. Once the recording function is activated the user s vocals and the audio track with or without the vocals filtered could be mixed and stored in memory. The mixed audio could be stored for example in HDC compressed format and could be replayed at a later time. Exemplary storing and replaying functions in digital radio broadcast receivers are disclosed in U.S. patent application Ser. No. 11 644 083 U.S. Patent Pub. No. 2008 0152039 which is incorporated by reference herein in its entirety.

A product purchase information application could send ID3 based UFID product codes that are associated with songs that will be rendered before the actual content is broadcast. This application would be very similar to the album art and image slide show applications described above but there are a few differences. First the type and size of the content is different i.e. ID3 tags instead of images . Therefore since ID3 tags are not very large each product code can be broadcast in a single content protocol packet and thus they may more readily be sent using byte streaming. Also the SIG record for the service would indicate that the receiver should use a product purchase information application to render the data content by including MIME type identifiers such as application x hdradio std product info 0x1343c25 . Further the client would use the rendering start and stop times as validity times to match the product purchase information with the specific content being rendered. On the receiver side once the user of the receiver inputs instructions to purchase a product associated with the current media content e.g. presses a tagging button the application can poll the current ALFN from the SIS and match this ALFN to the proper product information. This product purchase information can then be transmitted to a content provider to consummate a sale. A detailed example of tagging for digital radio broadcast receivers can be found in U.S. Patent App. Pub. No. 2009 0061763 which is incorporated by reference herein in its entirety. Client applications for sending PSD information typically ID3 tags associated with the audio could operate in a similar manner.

Finally a scrolling text application is an informational text application wherein the text is not as tightly coupled to the audio as in the closed captioning application. Examples of scrolling text applications can include stock quotes traffic advisories etc. The operation of a scrolling text application is almost identical to that of a closed captioning application. However timing instructions need not be provided and the level of synchronization between the audio and the text packets need not be very high. For example there would be little need to buffer the audio to account for text generation time or to reduce the I2E link delay time. Also the header core would indicate that the receiver should use a scrolling text application to render the data content by including MIME type identifiers such as application x hdradio std scrolling text 0x97f54d9b . Also the content packet header extension may be sent with a duration indicator so that the receiver can determine a proper scrolling rate. In certain embodiments if no new text packets are available at the receiver then the receiver will scroll the last text packet until a new one is received.

In step the importer determines a second value T corresponding to a time at which a first media content transmitted in the frame is to be rendered by a digital radio broadcast receiver based on a first latency wherein the first media content is processed through a first signal path through the digital radio broadcast transmitter and the digital radio broadcast receiver thereby incurring a first latency that is based on an estimated time for processing the first media content through the first signal path. For example referring to main audio is output from the main audio source to the audio encoder in the exporter and then to multiplexer . In contrast secondary audio is output from the secondary audio source to the audio encoder then through multiplexer and finally to the exporter multiplexer via I2E interface . Accordingly it should be clear from this example that main audio and secondary audio would typically incur different latencies through the transmitter side.

In step the importer determines a third value T corresponding to a time at which a second media content in the frame would be rendered by the digital radio broadcast receiver based on a second latency wherein the second media content is processed through a second signal path through the digital radio broadcast transmitter and the digital radio broadcast receiver thereby incurring the second latency that is based on an estimated time for processing the first media content through the first signal path. This second latency is typically different than the first latency. For example referring again to data content is output from the client to the RLS encoder then through multiplexer and finally to the exporter multiplexer via I2E interface . Thus it should be apparent that the latency of data content will typically be different than the latency of audio through the transmitter side.

In step the importer communicates the first second and third values to a client application via an API. The client application may be for example a closed captioning application a karaoke radio application a scrolling text application album art or a product purchase information application. The client application then processes the second media content at a time determined by the client based on the first second and third values thereby controlling the timing at which second media content is to be transmitted so as to synchronize the timing of rendering the second media content at a digital radio broadcast receiver relative to the timing of rendering the first media content at the digital radio broadcast receiver. In step the importer receives second media content for the frame from the client . Finally in step the importer communicates the second media content to the exporter which in turn generates the frame and communicates the frame to a digital radio broadcast transmitter site via STL link . The generated frame includes the first value first media content second media content and data control instructions associating the second media content with the first media content e.g. SIG .

In certain embodiments the first latency and the second latency are transmission location dependent meaning that the latencies can vary from radio station to radio station and from one service to another. In certain embodiments the digital radio broadcast receiver renders the first media content and second media content without making determinations about the relative rendering timing for the second media content and the first media content. In certain embodiments the frame does not include an independent clock signal for synchronizing the first and second media content.

The client application then processes the second media content based on the first and second values to generate timing instructions that are included in a content protocol packet. The timing instructions are provided so as to synchronize the timing of rendering the second media content at a digital radio broadcast receiver relative to the timing of rendering the first media content at the digital radio broadcast receiver. In step the importer receives from the client second media content and the timing instructions for the digital radio broadcast receiver to render the second media content at a predetermined time in synchronization with the first media content based on the first and second values. In step the importer communicates the second media content to the exporter which in turn generates a frame and communicates the frame to a digital radio broadcast transmitter site via STL link . The generated frame includes the first value second media content timing instructions e.g. in the content protocol packet attached to the second media content and data control instructions associating the second media content with the first media content e.g. SIG . This first frame is broadcast in sufficient time so that the second media content is available for rendering at the receiver in time for it to be rendered in synchronization with the first media content when it arrives. Finally in step the importer communicates the first media content to the exporter which in turn generates a second frame and communicates the frame to a digital radio broadcast transmitter site via STL link . The generated frame includes the first media content.

In step the baseband processor processes the first media content through a first signal path in the digital radio broadcast receiver thereby incurring a first latency. For example as described above with reference to a digital demodulator demodulates the digitally modulated portion of an incoming baseband signal. The digital signal is then deinterleaved by a deinterleaver and decoded by a Viterbi decoder . A service demultiplexer separates main and supplemental program signals from data signals. A processor processes the program signals to produce a digital audio signal on line . In step the baseband processor also processes the second media content through a second signal path in the digital radio broadcast receiver thereby incurring a second latency that is different than the first latency. For example referring to data content is processed as described above until the digital signal reaches the service demultiplexer . The service demultiplexer outputs data signals to a data processor which processes the data signals and produces data output signals on lines and . The data processor then sends the data output signals e.g. the second media content to the host controller responsive to a polling request. Since the audio and the data content are processed through different signal paths in the receiver the latencies of the audio and data content are typically different through the digital radio broadcast receiver. Specifically with reference to the above example the audio is processed by processor and the data content is processed by data processor and then by the host controller .

In step the host controller then associates the second media content with the first media content based on the data control instructions. For example a SIG audio service record may include subservice information descriptors that the host controller uses to associate the audio with data content. In step the host controller renders the second media content in synchronization with the first media content based on the data control service instructions wherein the digital radio broadcast receiver renders the first media content and second media content without making determinations about the relative rendering timing for the second media content and the first media content. In certain embodiments the frame does not include an independent clock signal for synchronizing the first and second media content. The second media content may include for example closed captioning information song lyrics album art image slide shows product purchase information or scrolling text. In certain embodiments the second media content can be radio karaoke information e.g. song lyrics and the receiver can filter vocal components of the audio in real time so as to reduce the vocal component as described above with reference to and

Exemplary embodiments of a multiport synchronous asynchronous client MSAC will now be described. In certain embodiments the MSAC may be the client illustrated in . The functionality of the MSAC is illustrated in . The MSAC is typically implemented as a process executing on a processing system e.g. one or more computer processors for example a Java process with several threads running on a computer where the computer has access to a local memory e.g. a local file system . While Java implementations are described for exemplary purposes the MSAC could be any type of process on any suitable platform such as NET.

In exemplary embodiments the MSAC is a two threaded process where one thread handles communications and handshaking with the importer via the importer interface while the other thread handles communications with the studio automation equipment . The importer interface and the client request interface are message protocols i.e. application programming interfaces APIs that are described in more detail below but generally they specify the messages that can be used to communicate with the MSAC . While the MSAC is shown as only communicating with a single studio automation equipment for exemplary purposes in use the MSAC could communicate with any number of studio automation systems. The MSAC also has the capability to access a media content reservoir such as for example an image database. The media content reservoir may be any suitable storage component such as a computer file system or database which may be populated by a media server . The media server is a suitable process capable of retrieving media content from various sources such as for example an album art database e.g. the Gracenote database .

The MSAC also accesses configuration files that can store configuration information such as for example a username password of the MSAC to access the importer the importer name or IP address the directory to read for files being transmitted to the importer associations between the data clients on the MSAC and the available audio clients. Exemplary MSAC configuration parameters to be stored in the configuration files are listed below 

In addition the MSAC accesses a log file that it can maintain to yield debugging information regarding scheduling and or the success or failure of the MSAC to implement the requests from the studio automation equipment . In typical implementations the studio automation equipment will also be able to access the configuration files and log file .

The MSAC may be deployed in any suitable network location. For example the MSAC may run on the importer and the studio automation equipment could implement the client request interface . Indeed there could be several studio automation systems talking to one MSAC with the interface . Alternately the MSAC or a set of MSACs could run on a centralized server or server farm and have a network connection between the MSAC and the importers . Advantageously the MSAC can be implemented as a server process with enough flexibility to accommodate a variety of implementation options.

In operation the MSAC uses the configuration files to initiate the automatic login and open session handshake with the importer when the MSAC is started. After the handshake the data flow is reversed and the importer begins to drive the communications by sending requests to the MSAC .

In certain embodiments the MSAC may function as a data client of the importer but it typically will not function as an audio client or an administrative client to the importer . If the get audio list response message includes information matching the pre configured associations on the MSAC then the MSAC will send an open session request . This request identifies the associations of data services with audio services. The importer uses this association information to encode the SIG that is eventually transmitted to the receiver side. The importer then responds with an open session response message indicating that the handshake is successfully completed.

At this point the direction of the protocol reverses and becomes driven by the importer . The importer can then immediately send a content request message to the MSAC . The MSAC will respond with a receive content message that may include media content if available. If there is no data the MSAC can respond with a null message. However in typical embodiments if files have been registered with the MSAC via the client request interface then the MSAC will likely have data to send and will immediately begin sending data to the importer .

An exemplary operation of an MSAC thread that interacts with the importer interface will now be described. First the thread typically will include a constructor function e.g. new Multiport that receives information from the configuration files logs into the importer and sends an open session request to the importer . The thread will also typically include a get data request method that receives a content request message from the importer and a scheduler get data method that internally determines what data to send to the importer . Finally the thread will typically include a send data response method that sends data to the importer for transmission.

In operation typically only one LOT packet is sent to the importer in response to each content request. The importer will then continue requesting data until it has enough to satisfy internal buffer requirements.

The client request interface will be discussed next. The client request interface generally enables the MSAC to receive files that are to be sent to the importer via the LOT protocol. The interface will typically be an API between the MSAC receiving requests and one or more studio automation systems or processes sending requests for files to be sent to the importer . The files are typically sent in packet based mode using the LOT protocol described above but they may also be sent in byte streaming mode. Part of the information received from this interface enables the MSAC to read the storage location e.g. a file directory where the files to be sent are stored.

An exemplary operation of an MSAC thread that interacts with the client request interface will now be described. First the thread typically includes a constructor function e.g. new Scheduler that instantiates a scheduler object based on the configuration information. The scheduler object then receives and parses requests from clients e.g. studio automation equipment via schedule request and scheduler process methods. Finally the scheduler object responds appropriately to the client requests via a scheduler response method.

The physical implementation of the channel for the client request interface may be for example a UDP datagram or a TCP connection. For UDP there is typically one port the MSAC listens on and another port it responds on by replying to the IP address sending the request. These port assignments may be identified in the configuration file . Because there is typically no authentication on a UDP port exchange a UDP configuration may be more suitable for a friendly system environment. For TCP there is typically only a single port for the MSAC to send and receive messages which may also be stored in the configuration file .

The client request interface permits studio automation equipment to request transmission of files using a variety of message types. Exemplary message request types include 

These message types are described in more detail below. In exemplary embodiments the messages may be formatted using XML or may use any other suitable data structure such as JSON YAML or CSV.

First a SYNC PRE SEND message can be used to signal the MSAC to send a file to the importer for synchronization with a specific media content being rendered at a receiver e.g. a song from the MPS . This message contains the appropriate headers for the data structure for example an XML envelope tag and MSAC request tag. The message may also include one or more of the following attributes 

In typical embodiments at least the first four attributes above will be included in each SYNC PRE SEND message. The LOT Information attributes may be included and if so they will supply some or all of the necessary LOT parameters. If the LOT Information is not supplied the MSAC can choose the next available LOT ID and return it in its response message. The LOT IDs will typically be consistent across all services.

The songDuration attribute can be used to determine the number of times the associated LOT object should be sent. If this attribute is absent then the number of repeats typically defaults to 1. This causes the LOT object to be sent twice once before the song starts and once after the song starts. If the song duration is present the MSAC can calculate how many repeats are possible given several parameters that may be included in the configuration files . These parameters are 1 duty cycle which is the fraction of time over the song duration that should be budgeted for in sending images for this service 2 fraction of song duration which corresponds to the fraction of the song during which images can be sent and 3 maximum number of repeats.

The triggerType attribute can be used to signal whether synchronization is operating in passive mode which is typically the default or in active mode. Passive mode provides that the start time in the SYNC PRE SEND message is used to set the scheduled times of all the sends from the first one that will typically occur before the synchronous event and to the 2nd and following transmissions if any. For this mode the triggerType attribute is not necessary and the MSAC may assume synchronization to be in passive mode if the triggerType is not supplied. Setting synchronization to active mode provides that the 2nd and subsequent LOT object transmissions will be scheduled by the start time in a SYNC EVENT message described below . Thus a SYNC EVENT message should be received by the MSAC which may purge the associated LOT object after a set amount of time if it fails to receive such a message e.g. the LOT object may be purged after 1 minute 5 minutes 10 minutes 15 minutes 1 hour or any other configurable period of time . This behavior can accommodate situations where the exact start time is not known beforehand so that at least one LOT object can be sent before the synchronous event and subsequent ones can be sent after the synchronous event has occurred or when better information is known about when the synchronous event will occur. In addition to this behavior if the cancelPrior attribute is false which is the default any SYNC PRE SENDs that occur after the first one will be ignored. In this mode of operation the SYNC PRE SEND is used to schedule the first LOT object transmission and the SYNC EVENT message is used to supply the start time for the synchronous event for the second and any following sends of the LOT object.

An exemplary SYNC PRE SEND message rendered in XML typically includes a number of elements. For example it will include a root element e.g. HDRadio Envelope and a tag indicating the message classification e.g. MSAC Request . The message body may include various information such as for example the message type e.g. msgType Sync Pre Send a start time e.g. startTime Fri Apr 01 22 22 22 EDT 2011 a file name e.g. fileName .. data init aa0.jpg a data service identifier e.g. dataServiceName AAD0 a song duration e.g. songDuration 300 a trigger type e.g. trig Passive and LOT protocol information e.g. lotId 1234 expirationDate Wed Jan 01 12 00 00 EDT 2020 .

The MSAC responds to request messages to indicate whether the request was successfully received. For example a file that is sent to the MSAC successfully will produce a response with a unique tag e.g. uniqueTag Mon Apr 25 16 04 35 17 EDT 2011 that can be used to reference the file in the future. An exemplary XML response message may also include various other information such as the message classification e.g. MSAC Response the message type e.g. msgType Sync Pre Send a data service identifier e.g. dataServiceName AAD0 state information regarding the object e.g. state Pending and LOT protocol information e.g. lotId 1234 .

The uniqueTag attribute may be the time when the file was registered. The uniqueTag could also be any other suitably unique identifier such as a hash or auto incremented integer. Each response may also have a returnString OK or another descriptive string explaining any errors. The msgType reflects the type of command sent in and the dataServiceName reflects the data service being targeted. The state identified as PENDING means that the LOT object is waiting for the correct timing to begin transmission. The LOT ID of the file to be transferred is also included.

The ASYNC SEND message can be used to signal the MSAC to send a file to the importer that does not need to be synchronized with any particular media content being rendered at a receiver. Such a message typically only uses a subset of the attributes that the SYNC PRE SEND message uses. It can include a msgType attribute identifying the message as an ASYNC SEND message a fileName attribute to specify the file to be sent and a dataServiceName attribute to specify which data service to target with this content. Similar to the SYNC PRE SEND message LOT information is not required in which case the LOT ID can be returned with the response. The MSAC response to the ASYNC SEND message typically has a uniqueTag so that if the ASYNC SEND message needs to be canceled it can be uniquely identified.

Exemplary scheduling behaviors of an ASYNC SEND message are as follows. First the SCHEDULE POLICY is typically set to SCHEDULE POLICY RR for round robin with a SCHEDULE PRIORITY of SCHEDULE PRIORITY LOW a SCHEDULE RATE can be dynamically set e.g. 5 10 minutes per full object transmission and the SCHEDULE DYNAMIC RATE can be set ON which implies it will use extra bandwidth if available.

The LOT packets for the ASYNC SEND images may be sent such that a full copy of the object is transmitted in a predetermined period of time for example about 5 10 minutes if the SCHEDULE DYNAMIC RATE is set to OFF. This configuration may cause the packets of the object to be separated by a variable amount of time e.g. a few seconds up to approximately 15 seconds based on the size of the image file and other schedule duties . In exemplary embodiments the object will continually be sent with a repeat count of one 1 until it is either canceled with a CANCEL SEND message or another ASYNC SEND message is sent in on the same data service in which case the object is replaced.

The MODIFY START message can be sent to modify the synchronous event start time that was sent with a SYNC PRE SEND message. Such a message may be used when the start time of the associated synchronous event will slip in time. Thus this message will alter the time of the synchronous event and thus alter when image packets will be sent and when the state of the LOT object will change.

The CANCEL SEND message cancels a previously scheduled transmission regardless of state. It may include a uniqueTag identifier to cancel only a specific object or it may cancel all the objects for a designated data service identified by the dataServiceName attribute.

The STATUS REQUEST message requests the state of a LOT object or objects. It may include a uniqueTag identifier to identify one specific object or it may identify all the objects for a designated data service by using the dataServiceName attribute.

The OTHER SEND message substitutes a new file for one previously identified in a prior SYNC PRE SEND or ASYNC SEND message. This may include other associated or non associated data in the MSAC . Such a message may include a cancelPrior attribute specifying whether the MSAC should cancel the transmission of the last LOT object for the associated data service. Typically the cancelPrior attribute will default to FALSE meaning that the last object is not canceled.

The PSD SEND message requests the underlying PSD information be forwarded to the location identified in the message. The message may contain a msgType attribute identifying the message as a PSD SEND message. It may also include an inputFormat attribute specifying whether the input will be formatted for example using ID3 tags or XML. The ID3 inputFormat means that after the closing message tag there will be a binary attachment that is an ID3 tag. This binary attachment may start on the next byte after the closing tag or it may be offset by several bytes depending on for example what software package is used to pack the XML message. An offset attribute can designate the number of bytes that may be skipped before the first byte of the ID3 tag. A protocol attribute can indicate whether this PSD message is communicated by TCP or UDP. A location attribute can identify the destination IP address and port and an outputFormat attribute can identify the format of the outgoing message for example XML ID3 or HDP.

The FTP S FILE COPY message requests the MSAC to copy a remote file from a specific system to the local memory e.g. hard drive of the MSAC preferably before the file is needed at the MSAC for spooling to the importer . A msgType attribute can either be FTP File Copy or FTPS File Copy. An ftpSite attribute identifies the IP address or the URL of an FTP site. A username password attribute can be used to login to the FTP server. An ftpDirectory attribute can identify a sub directory where the desired files are located. A sourceFile attribute identifies the desired file or files and a fileDestination attribute identifies what the file will be called on the local system. The Remote File Directory from the configuration file can be prepended to the fileDestination to form a complete path name. These path names can be set in the configuration file Remote File Directory for the given system.

The HTTP FILE COPY message requests the MSAC to copy a remote file from a specific URL to the local hard drive of the MSAC preferably before the file is needed at the MSAC for spooling to the importer . The MSAC performs an HTTP GET request from any web server to retrieve the file. A fileSource attribute identifies the URL of the file which can point to a file or a process and have the authentication information contained in it. A fileDestination attribute can be prepended with the Remote File Directory from the configuration file to form full path file destination name. A username and password attribute may be used if the HTTP web server is set up to require them although this information may also be included in the URL.

The DIRECT FILE COPY message requests the MSAC to copy a file that is attached to the message to the local memory e.g. hard drive of the MSAC preferably before the file is needed at the MSAC for spooling to the importer . This mechanism is similar to the PSD SEND message where the ID3 tag attachment is placed after the message s end tag.

The REPEAT SEND LOCAL CHECK message type has several functions. The message generally can be used to supply a directory of files to be spooled to the importer . In particular it initially copies files from a remote file directory to a working file directory. Part of the remote file directory can be supplied in the request message which can be prepended with the REMOTE FILE DIRECTORY property from a configuration file. The full remote file directory is where the files are copied from and they can be copied to an appropriate working directory e.g. a .. data work root directory . The files can then be spooled to the importer from the working directory.

To mitigate concurrency problems there may be a LOCK file in the remote file directory that can be locked from the importer side e.g. written with a suitable identified such as SERVER or the MSAC side e.g. written with a suitable identifier such as MSAC while the files are being changed. If the MSAC attempts to read this directory of files when they are locked by the importer it will be blocked. It can then wait for a suitable amount of time approximately 250 msec and retry a predetermined number of times before aborting in which case it will spool the same set of files again. If the MSAC finds the LOCK file either empty or finds no LOCK file it will lock the LOCK file to prevent the importer from replacing the files in that directory. The MSAC can then copy the files into the working directory and begin spooling.

The MSAC may check for new files either after it has spooled the entire set of files in the directory or after each file based on settings in the configuration files. To trigger this check the studio automation system can send another REPEAT SEND LOCAL CHECK message which may occur while the directory is being spooled. The files may be spooled in any suitable sequence for example alphabetical order which may be adjusted based on settings in the configuration files.

For example the spooling sequence may be specified in a fileSeqList.xml file. Such a file can be consulted to get the file sequencing information for the set of files in the directory. The sequencing file may include any suitable attributes such as a forceReset attribute and a lotIdFormat attribute. The forceReset attribute can cause the file sequence to start over after the MSAC checks for updates. The lotIdFormat attribute can specify the format of the LOTID in the file name for example base64 can refer to four hexadecimal digits 0 9 a f in the filename where the LOTID is placed.

The LOCAL TIME message will send a request to obtain the local time of the system where the MSAC is running. This can be done for example to synchronize external time so that time based requests can be appropriately normalized to the timebase of the MSAC . The MSAC s response will have a localTime attribute e.g. a time string in the same format as the startTime in the SYNC PRE SEND message that represents the current time on the system running the MSAC .

The SYNC EVENT message can be sent to modify the synchronous event start time that was sent with a previous SYNC PRE SEND message. In certain embodiments the message may only affect the second and following object transmission times which advantageously allows the first object transmission to be unaffected. Such a message may be desirable when timed events are rescheduled so that the MSAC can alter the time of the sync event and thus alter when objects will be sent and when the state of the objects will change.

The SYNC EVENT message may include a uniqueTag to identify the previous SYNC PRE SEND message. If not then preferably the lot ID can be added so that the correct object can be located. As mentioned above if the SYNC PRE SEND message includes a triggerType Active attribute the MSAC will expect a SYNC EVENT message to signal the synchronous event. The startTime attribute in the SYNC EVENT message can include the synchronous event time which triggers the second and any subsequent object transmissions. The start time in the initial SYNC PRE SEND message will typically still be used to schedule the first object transmission that typically occurs before the synchronous event.

Several exemplary schedule parameters may be associated with each LOT object being sent to the importer from the MSAC . Below is a listing and a short description of each 

The schedule parameters for sending LOT packets to the importer can be defined by the type of message that is being sent into the MSAC settings in the configuration files or a combination of both. In certain embodiments the schedule parameters can be set to a default value based on the message type or can be specified in a configuration file. The SYNC PRE SEND message type for example typically would default to a SCHEDULE POLICY of SCHEDULE POLICY FIFO at a SCHEDULE PRIORITY of SCHEDULE PRIORITY LOW. This means that once a LOT object has started transmitting it will complete before any other LOT object is started. However this may be subject to exceptions for example based on the SCHEDULE PRIORITY. If a higher priority SCHEDULE POLICY FIFO object changes state and becomes sendable then this may preempt an already sendable object that had not yet completed being transmitted. There may also be a timeout for each object e.g. set for 5 minutes . If this timeout expires then a packet from the object can immediately be sent so that the receivers will not incur any ill effects from large delay between packets. The SCHEDULE RATE can be used to designate a rate for sending a LOT object. The SCHEDULE DYNAMIC RATE is a schedule parameter that controls whether a service will use more than the assigned bandwidth if available. The SYNC PRE SEND message typically does not use this parameter but the ASYNC SEND message may set the SCHEDULE DYNAMIC RATE parameter to true which implies that the LOT object for asynchronous objects will send packets to use all the available bandwidth. In other words when the SCHEDULE DYNAMIC RATE parameter is true then if nothing else is using the bandwidth of the multiport the ASYNC SEND image may be transmitted rapidly.

The SCHEDULE RATE PERCENT parameter may be set so that if multiple services exist on a REPEAT SEND LOCAL CHECK message the MSAC can divide the available bandwidth among those services. If a service has been partitioned and is not active the other services will immediately receive more bandwidth as is the case when SCHEDULE DYNAMIC RATE is set. Also the SCHEDULE COMPLETE TIME IN SECONDS parameter can be set so that the MSAC attempts to send packets at a rate to achieve a complete object transmission in the designated amount of time e.g. if set for 300 seconds then the MSAC will attempt to complete a transmission in 300 seconds . This parameter may be configurable in a configuration file and may default to some value for example 800 seconds if it is applicable. This parameter may be inapplicable for example when SCHEDULE DYNAMIC RATE is set for ASYNC SEND messages or for a REPEAT SEND LOCAL CHECK message or any other type of send.

Newly initialized objects begin in the NOT SET state before they have been copied to the MSAC s working directory. When an object is requested to be sent by the studio automation equipment it will be copied from the directory specified in the message to a working directory within the relative path of the MSAC distribution at which point the object is in the PENDING state .

If the request message associated with the object is an ASYNC SEND message the object will be transitioned to the ACTIVE state when it is first executed. Once in the ACTIVE state the object is a candidate for having packets sent to the importer . The object can remain in the ACTIVE state until it is canceled or replaced by a subsequent message. In certain embodiments the object may also be set to automatically expire after a predetermined time period e.g. 24 hours a week or a month . Once the object is to be removed from the MSAC s control it is then transitioned to the TERMINATED state and the file can be deleted from the MSAC s working directory.

If the request message associated with the object is a SYNC PRE SEND message the file is copied to the working directory and the state is transitioned to the PENDING state as described above. However the object will remain in the PENDING state until a predetermined amount of time e.g. a few minutes before the associated synchronous event at which time it will transition to the ACTIVE state and become a candidate to be sent to the importer . Once it is sent fully once the object transitions to the SYNC PENDING state to wait for the synchronous event to occur. After this occurs it transitions to the ACTIVE state again is sent again. The transitions between ACTIVE and SYNC PENDING states and the associated transmissions of the object may be repeated as many times as the object is designated to be sent to the importer for example using a count that can be decremented to zero 0 . Once complete the object transitions to the FINISHED state . The object may optionally remain in the FINISHED state for a predetermined amount of time e.g. 10 seconds to await a STATUS REQUEST message and then the object is transitioned to the TERMINATED state . At this point the internal data object representation along with the file from the working directory of the MSAC may be deleted. If a STATUS REQUEST is issued after the transition to the TERMINATED state the response may show an error because the uniqueTag will not correspond to any data object in the MSAC . Alternatively the file may be deleted from the working directory but the object may remain stored thus permitting later STATUS REQUEST queries to properly execute.

As illustrated in the first media content is directed along a first signal path through the digital radio broadcast transmitter e.g. from the MSAC through the importer exporter and to the exciter and the second media content is directed along a second signal path through the digital radio broadcast transmitter e.g. the importer the exporter and the exciter but bypassing the MSAC . As described above the SYNC PRE SEND message may include a requested render time of the second media content by a digital radio broadcast receiver.

Next in step the MSAC receives a request to render third media content a station logo news traffic weather a directory of files and a website asynchronously at the digital radio broadcast receiver. In other words the third media content can be rendered without being synchronized to the rendering time of any other content at the receiver. This request may be formatted as an ASYNC SEND or REPEAT SEND LOCAL CHECK message.

In step the MSAC receives a plurality of content requests from the importer . Each content request can include a value corresponding to a time at which media content following the second signal path that is delivered responsive to the content request would be rendered by the digital radio broadcast receiver. This value can be determined by the importer based on estimated latency through the second signal path which is typically different than the latency of content traveling through the first signal path.

Next in step the MSAC delivers the first media content e.g. album art to the importer in response to at least one of the content requests. This occurs when the value of the content request corresponds to the render time of the second media content such that the first media content can be processed for radio broadcast transmission by the exciter and then rendered synchronously with the second media content by the digital radio broadcast receiver. The entire first media content may be delivered to the importer multiple times in response to several content requests such that the first media content can be rendered synchronously with the second media content at least two times.

In certain embodiments the first media content may be delivered responsive to a predetermined number of content requests such that the first media content can be rendered synchronously with the second media content a predetermined number of times wherein the predetermined number is determined based on a duration of the second media content. For example a song duration can be provided in a SYNC PRE SEND message which can be used to determine the number of times the associated LOT object should be sent. Based on the song duration the MSAC can calculate how many repeats are possible given several parameters that may be included in the configuration files . These parameters include 1 duty cycle which is the fraction of time over the song duration that should be budgeted for in sending images for this service 2 fraction of song duration which corresponds to the fraction of the song during which images can be sent and 3 maximum number of repeats. In certain embodiments packets from the first media content may be delivered in at least two portions. i.e. split among more than one content request.

As discussed above when an object stored in the MSAC is associated with a SYNC PRE SEND message it is transitioned to the PENDING state and prepared for transmission to the importer when the designated synchronous event time arrives. The first media content can then be rendered by a digital radio broadcast receiver. In an exemplary operation the MSAC first retrieves the first media content from a file storage and then stores it in a packetized format e.g. as a LOT object . The MSAC then associates the packetized first media content with a PENDING state. When the value of at least one of the content requests i.e. the synchronous event time corresponds to the designated render time of the second media content the MSAC transitions the packetized first media content to an active state and provides the packetized first media content to the importer responsive to at least one content request.

In certain embodiments the MSAC may receive a message identifying a start time of a synchronous event related to the first media content e.g. a SYNC EVENT message. The MSAC can then deliver the first media content responsive to a second and any subsequent content requests based on the start time of the synchronous event. However typically the delivery time of the first media content responsive to the first content request will not be affected by such a message.

In certain embodiments the digital radio broadcast receiver receiving the transmitted content may render the first media content in synchronization with the second media content without making any determinations about relative timing for rendering the second media content and the first media content.

Finally in step the MSAC delivers the third media content e.g. the station logo to the importer responsive to at least one of the content requests. The third media content can then be processed for radio broadcast transmission by the exciter and rendered asynchronously by the digital radio broadcast receiver i.e. without regard for any synchronization. In certain embodiments the third media content may be delivered to the importer repeatedly e.g. the MSAC may communicate the third media content to the importer so that the importer receives the third media content a predetermined number of times in a predetermined time period. As an example the SCHEDULE RATE PERCENT parameter may be set for a REPEAT SEND LOCAL CHECK message such that the third media content receives a certain percent of available bandwidth. As another example the SCHEDULE COMPLETE TIME IN SECONDS parameter may be set such that the third media content is delivered in the designated amount of time e.g. if set for 300 seconds then the third media content is delivered every 300 seconds .

Exemplary receiver applications according to certain embodiments will now be described with reference to the exemplary receivers illustrated in . While a receiver is tuned to a particular radio station the baseband processor is continuously receiving and buffering RLS packets that are broadcast from the radio station. In embodiments directed to packet mode transmission using LOT protocol the data processor may also be reassembling the packets into objects. These objects are then passed to the host controller responsive to a request e.g. a polling event . Alternatively RLS packets could be passed to the host controller which could then reassemble them into objects. Additionally in embodiments directed to standard packets variable packets or byte streaming data transmission the RLS packets could be reassembled in either the data processor or the host controller . The data content can then be reconstructed based on the sequence numbers included in the packets as described above.

The host controller then renders and or stores the reassembled data content. The process of rendering and or storing the data content may vary depending on the specific implementation and the receiver capabilities. For example closed captioning information radio karaoke and streaming text may be rendered immediately in synchronization with the audio i.e. the synchronization is performed by the digital radio broadcast transmitter and the receiver makes no determinations about the relative rendering timing of the data content or the data content may be temporarily or even momentarily stored until triggered by the triggering instructions. Product purchase information included in the PSD such as a promotional message may be rendered immediately in synchronization with the associated audio track. Album art and image slide shows will typically be stored for rendering in synchronization with the audio based on the triggering instructions included in an XHDR ID3 frame identifying the image. In certain embodiments that allow for content reuse the stored album art image slide shows and product purchase information can be indexed with a content identifier so that it can be accessed multiple times. The rendering applications can be coded in software using any suitable programming language such as C or for example and implementing such applications is within the purview of one of ordinary skill in the art.

Buffering images within the receiver memory in general may present a better user experience to the listener. In order to meet the image display time requirements the receiver may maintain a rendering buffer in memory to store the pre sent synchronized images for the upcoming songs within each multicast channel. Then when the listener switches to a different multicast channel the listener can be immediately presented with the primary image associated with the audio program.

The number of primary images buffered by the receiver for display can be controlled by the baseband processor specifically the internal LOT memory pool within the baseband processor. However for receivers where the internal baseband processor memory is less than 256 kb for LOT the host controller may need to account for additional buffering. In certain embodiments receivers may store up to two primary images in their LOT memory pool for all programs for the currently selected station. Assuming four programs this would mean up to eight files of 24 kb each for a total of 192 kilobytes of storage. However it is highly unlikely that eight files will be the maximum size simultaneously thus a reasonable storage requirement is 144 kb assuming an average file size of 18 kilobytes .

When the listener tunes away from the station it may be desirable that the receiver flush all images associated with that station in order to conserve memory. If an image is fully received it may be desirable to discard the image after a significant period of time has passed and no trigger has been received for the image. A timeout on the order of for example 15 minutes may be desirable although any other suitable time could be used. However discarding an image may only be done if there is insufficient memory available to store a new image.

In typical embodiments the station logos are repeated every 15 minutes thus the receiver memory buffer should accommodate this. If the station logo cannot be found in the receiver memory then the default image shall be displayed if available or the display area shall be left blank. Each repetition of the station logo may be sent with the same LOT ID. The broadcaster will typically set the repeat value to a large number. They may also hold the LOT repeat value to the same non zero value for a large period of time across many repetitions until the image changes. They can then allow the repeat value to go to zero to indicate that the next image is different. The next image will then have a different LOT ID.

The station logos are typically read from LOT and stored in either receiver memory. In typical embodiments once a file is read from LOT it is purged from the LOT memory pool and cannot be read again therefore the receiver should maintain its own buffer of station logo images. Once a station logo image has been read from the baseband processor LOT memory for a particular channel it cannot be read again. For example this scenario could occur in the case when a listener tunes to another channel and then chooses to tune back to the previous channel. Thus the station logos should be buffered stored in the receiver host memory as soon as they are received and read from the baseband processor. By doing this the receiver will not have the need to download the station logos each time it is tuned to a different multicast program on the station. The receiver can also quickly revert to the station logo image when the synchronized image is not available.

In the worst case scenario where the listener first tunes to a four program station and all images are being downloaded in LOT simultaneously this could mean a total of 1 images 216 kb maximum two primary images per program current and next and one station logo per program and assuming an average file size of 18 kb . This may approach the total available memory space of LOT with the baseband processor. However given the slow bit rate of the station logo images the LOT memory pool will not be exceeded as long as the host controller always reads a station logo as soon as it is available and removes it from the LOT memory pool.

The memory buffer size for storing pending primary images shall be managed by flushing the images with the oldest discard time first. It is preferable that the station logos be stored in non volatile memory cross referenced by call sign and program number so that acquisition time is nominally very fast.

If the host controller were to store all the station logos for the current market broadcast region in non volatile memory that would total four images per frequency for four programs per frequency . Assuming 20 active frequencies transmitting the images this total memory required would be 18 kbytes 8 20 2.8 Mbytes assuming a file size of 18 kbytes 

The receiver may also choose to store the station logos in non volatile memory for the available preset stations after the images have been downloaded initially. This will enhance the user experience as well. There may also be cases where in order to make efficient use of the available memory pool the host controller may disable the ports associated with the primary image for all the other programs and multicast channels except the current program channel. In this use case when switching to a different multicast program the listener will initially see the station logo for that channel and the receiver will display the primary image only sometime after the start of the next song when it has downloaded and assembled the primary image for that song. If the receiver chooses to adopt this method it may be desirable that the receiver does store the station logos for all programs on that station.

Synchronized images and station logos can be processed on the receiver entirely in the non volatile or volatile memory available. Although a file system is not required on the receiver a file system could be beneficial for more efficient storage and retrieval of the image files and memory management. This again may be governed by the receiver design and cost considerations.

An exemplary synchronized image application will now be described with reference to to . In this application only a single image e.g. an album cover is displayed when triggered by the triggering instructions as shown in . Each image replaces the previous one and remains on the display until it is in turn replaced. However if a LOTID of an image is received in the triggering instructions e.g. XHDR ID3 frame and the image cannot be located in receiver memory in certain embodiments a default image may be displayed such as the station logo as shown in . If the default image is not available then the current image may remain on the screen until a new valid LOTID is received or the screen may display a blank image or a default HD Radio logo as shown in . In addition certain applications may render both a station logo and album art as shown in

The triggering instructions may also include memory management instructions for the receiver. For example if a Blank Display Parameter ID as discussed above is received that is associated with the currently displayed image then the image could be removed within five seconds. If a Blank Display Parameter ID is received that is not associated with the currently displayed image then it would not be removed. Also if a Flush Memory Parameter ID is received then the receiver memory would be purged of all previously stored images for the associated service with the possible exception of the station logo. Typically upon receipt of a Flush Memory message the receiver would also remove the currently displayed image and display the station logo until the next image is received.

Default images or station logos are typically broadcast as a separate service. These images are typically transmitted using LOT and should be stored in the receiver such that they will not be readily flushed from memory. For example the default image may continue to be stored even after tuning whereas the other images should typically be flushed upon tuning to a new channel. In exemplary embodiments the LOTID associated with the default images should be unique from other images being broadcast via a synchronized image service. And when updating a default image the new default image should have a different LOTID from that of the old default image.

Upon receipt of an XHDR ID3 frame with the ParameterID of 1 Blank Display the image should be immediately removed from the display and nothing displayed until a new XHDR ID3 frame is received with a valid LOTID. Upon receipt of the XHDR ID3 frame with the ParameterID set to 2 Flush Memory the receivers image memory should be flushed removing all previously stored images except the default image. The current image may be immediately removed from the display and the default image should be displayed until a new LOTID is received with an image matching that LOTID that is available in the receiver s memory. If the default image is not available the image display may be blanked. In the event the synchronized image application is terminated the screen should return to the default image when it is restarted.

In an exemplary image scheduling application operation the images and or videos can be encoded using the LOT protocol and or the content protocol described above and sent in time to be available for rendering at the designated time. Triggering instructions e.g. an XHDR ID3 frame are then sent that when executed will cause the receiver to immediately render the images videos in synchronization with the audio. Additionally the SIG record for the service would indicate that the receiver should use for example an album art or image slide show application to render the data content by including appropriate MIME type identifiers. The client sends the encoded images videos to the importer . The importer then sends them to the exporter for digital radio broadcast transmission. While images and videos will typically be encoded and transmitted using the LOT protocol they may also be transmitted using standard packets variable packets or byte streaming. However one of skill in the art would appreciate that when images or videos are transmitted via these methods available broadcast bandwidth may limit the size of images videos. For example larger images and videos typically take longer to transmit assuming a fixed bandwidth availability. Therefore assuming that the images videos are transmitted so that they arrive just in time for rendering at the receiver the bandwidth constraints may limit the use of these methods to images or videos that can be broadcast within for example the duration of a song so that the image video is available for rendering at the beginning of the next song.

In operation the receiver will receive and download and store the images and or videos. When the triggering instructions indicate that the image or video should be displayed XHDR ID3 frame s LOTID matches the LOTID of the stored image the image video will be displayed by the display control unit in synchronization with the receiver rendering the audio via the audio speakers. In certain embodiments if no images are available the receiver can display a default image.

A product purchase information application could send ID3 based product information as a commercial frame in the PSD which is rendered in synchronization with associated songs. In exemplary embodiments the PSD i.e. MPSD or SPSD may include a commercial ID3 frame. This commercial frame can be used to facilitate the sale of products or services. It can include descriptive text that is typically a short promotional message e.g. less than 128 bytes as well as information such as the contact URL name of seller and price. The content of the commercial frame can be populated by the broadcaster and or service provider.

An exemplary commercial frame in ID3 format is shown below in Table 6. In exemplary embodiments all the fields below are optional except the Description field.

In alternative embodiments the commercial frame may be included as a separate data service using standard packets variable packets LOT protocol or byte streaming. Since text based commercial information will typically not be very large it may readily be sent using standard packets variable packets or byte streaming. On the other hand image or video based product purchase information will more readily be sent using LOT protocol. In these embodiments the SIG record for the service would indicate that the receiver should use a product purchase information application to render the data content by including an appropriate MIME type identifier. Further the client could use the rendering start and stop times as validity times to match the product purchase information with the specific content being rendered. On the receiver side once the user of the receiver inputs instructions to purchase a product associated with the current media content e.g. presses a tagging button the application can poll the current ALFN from the SIS and match this ALFN to the proper product information. This product purchase information can then be transmitted to a content provider to consummate a sale. A detailed example of tagging for digital radio broadcast receivers can be found in U.S. Patent App. Pub. No. 2009 0061763 which is incorporated by reference herein in its entirety. Client applications for sending PSD information e.g. ID3 tags associated with the audio could operate in a similar manner.

One advantage is that in certain embodiments the MSAC relieves studio automation equipment and the importer from having responsibility for coordinating scheduling information for synchronous media content and centralizes scheduling. This can therefore minimize redundancy and misallocation of bandwidth for media content transmission.

Another advantage is that in certain embodiments both synchronous and asynchronous content can be coordinated by the MSAC which further minimizes inefficient allocation of bandwidth by the importer .

The exemplary approaches described may be carried out using any suitable combinations of software firmware and hardware and are not limited to any particular combinations of such. Computer program instructions for implementing the exemplary approaches described herein may be embodied on a non transitory computer readable storage medium such as a magnetic disk or other magnetic memory an optical disk e.g. DVD or other optical memory. RAM ROM or any other suitable memory such as Flash memory memory cards etc.

Additionally the disclosure has been described with reference to particular embodiments. However it will be readily apparent to those skilled in the art that it is possible to embody the disclosure in specific forms other than those of the embodiments described above. The embodiments are merely illustrative and should not be considered restrictive. The scope of the disclosure is given by the appended claims rather than the preceding description and all variations and equivalents which fall within the range of the claims are intended to be embraced therein.

