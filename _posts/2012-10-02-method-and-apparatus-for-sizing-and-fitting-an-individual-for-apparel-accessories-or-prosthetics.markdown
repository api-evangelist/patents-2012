---

title: Method and apparatus for sizing and fitting an individual for apparel, accessories, or prosthetics
abstract: A system for sizing and fitting an individual for apparel, accessories, or prosthetics includes at least one energy emitter configured to emit energy onto a field-of-view that contains an individual, and at least one energy sensor configured to capture reflected energy from within the field-of-view. A spatial measurement module calculates spatial measurements of a surface portion of the body of the individual when the individual is either stationary or moving about in real-time, based on data from the energy sensor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09341464&OS=09341464&RS=09341464
owner: ATLAS5D, INC.
number: 09341464
owner_city: Cambridge
owner_country: US
publication_date: 20121002
---
This application claims the benefit of Provisional Patent Application Ser. No. 61 548 079 filed on Oct. 17 2011 and Provisional Patent Application Ser. No. 61 561 627 filed on Nov. 18 2011 both of which are incorporated by reference herein in their entirety.

This invention relates to measurements of the surface of a person s body. The term measurement as used herein refers to the establishment of a distance angle volume or qualitative description pertaining to one or more portions of an individual s body. Examples of measurements include the circumference of a person s waist hip neck head torso or upper arm the length of an arm from shoulder to wrist or of a leg from hip to ankle the length or width of a foot an individual s height the volume and outline of space occupied by an individual s abdomen or the curve in space that would be described by a ribbon placed starting at the small of the back then following the surface of the skin across the crotch and up to the navel.

An important use of measurements is to size individuals for apparel accessories or prosthetics. The term apparel may encompass garments of any kind shirts trousers shoes hats etc. The term accessories may encompass items that are carried but not generally considered clothing jewelry purses etc. The term prosthetics may encompasses devices that replace or augment body parts that are missing or damaged artificial limbs orthotic shoes etc.

It is clear that body measurements may be used for many other purposes such as surgical fitness applications and biometrics and although this document will focus on sizing individuals for garments the scope of the system and method includes all applications that may be realized through measurements of a person s body.

Manual measurement of a person s body has been conducted for thousands of years. Today the most common way of measuring a person for example for sizing a suit is with a fabric tape measure often abbreviated to tape optionally accompanied by a set of pins markers and pre sized measurement garments. The tape is used to gauge the length width or circumference of various body portions for example the circumference of the neck or the length of the arm from shoulder to wrist and the pins markers and pre sized garments are used to mark off the measurements from the fabric tape measure and to establish the overall shape of volume of the body portion. For example a pre sized shirt may be donned by an individual and then portions of that shirt marked or pinned to confirm to the individual s body shape in this way creating a physical shell or envelope of the person s approximate shape.

Accordingly many schemes have been proposed to partially or fully automate the process of body measurement. Some methods of automation in the prior art involve the use of a 3D body scanner. Such a scanner can obtain a complete essentially 360 degree 3D scan of a person s body. Common to such methods is emitting electromagnetic or sound energy such as laser light or sonar onto a person s body wherein such energy is transmitted from multiple different directions or angles and then mathematically reassembling the reflected electromagnetic or sound pattern as received again from multiple directions or angles to build a complete computer 3D model. Because of the need to transmit and receive the electromagnetic energy from many different directions 3D scanners must use either many different transmitters and sensors set up simultaneously at different locations around the consumer or else use an array of transmitters and sensors that rotate in a tomographic fashion around the consumer typically at a fixed rate of angular change.

This burden of transmitters and sensors means that 3D body scanners are necessarily large complex devices. For example Unique Solutions manufactures as of September 2011 the MyBestFit Intellifit Virtual Fitting Room Bodyscanner which is a human sized stand alone box like device within which an individual stands in order to be scanned by radio waves . A similar large device is the NX 16 Whole Body Scanner manufactured by Shape Analysis Corporation.

3D body scanners suffer from drawbacks. First their size and complexity prevent them from being used at home a consumer must travel to a retail store or tailor who happens to have installed a 3D body scanner.

Second it is difficult to use a 3D scanner to generate the types of sizing that are common in the garment industry even if a mass of say 3D mesh data is obtained from the scanner there remains the need to extract measurements of interest such as arm circumference or foot length from that same data and since the measurements could have as easily been obtained from direct measurements of the person in the scanner this problem begs the question whether the 3D scanner was even needed in the first place.

Third because home measurements with a 3D scanner are infeasible 3D body scanners fail to eliminate the problems of inconvenience and perishable measurements.

Fourth because of the large amount of data gathered coupled with the need to rotate sensors around the individual or to perform a raster scan 3D scanners are typically slow.

Fifth because 3D scanners cannot be mass manufactured for use in consumer s homes for the reasons above there may be long lines to use the few machines that are assembled and economies of scale are not available to bring manufacturing costs down.

Sixth 3D scanners prevent real time interaction they do not give real time feedback cannot respond in real time to user commands and cannot adjust to real time changes in the user s position. This limits the utility and entertainment value of user interfaces to 3D scanners.

Other methods of automation in the prior art involve the use of special tapes or markers. Common to all such methods is having a person display special markings on their body such its ruled lines which can then either be manually entered by an operator or automatically measured by a computer program. These methods of automation are necessarily inconvenient because either the individual to be measured or another operator must take the time to learn assemble and place the special markers and prone to error since the accuracy of measurement depends on the skill with which the special markers are placed . Indeed these methods of automation do not really automate the measurement of body portions so much as parallelize the manual process of tape measurements.

Other methods of automation in the prior an utilize computerized images of a person upon which human operators manually superimpose markings which allow relevant garment measurements to be made. Common to all such methods is the requirement for a second person the operator to act upon the digitized data e.g. by using a computer console to manually highlight landmarks on the computerized images. Therefore these methods do not automate the act of manual measurement so much as postpone it to a later time or to a different physical location.

Overall known methods of automated garment sizing suffer from one or more of the following disadvantages 

Known methods may obtain limited depth knowledge about a scene Depth knowledge or depth data as used herein refers to gathering information possibly partial or incomplete about the spatial positions of objects in space relative to a known coordinate system Image knowledge or image data as used herein refers to gathering an image of a scene which may be in visual wavelengths or in other wavelengths of the electromagnetic spectrum. Color image knowledge or color image as used herein refers to gathering a visual image of a scene using color wavelength similar to the way in which a standard digital camera gathers a visual image. The term camera as used herein refers to any sensor that may gather information about the environment especially though not limited to electromagnetic measurements such as visible or infrared light. Camera as used herein is thus a general purpose term and does not refer specifically to nor is limited to visual light devices.

US patent publication 2011 0211044 Shpunt teaches a method of gathering depth knowledge about an object through the use of an illumination module which projects patterned optical radiation onto a scene and an image capture module which captures an image of the reflected pattern.

Image and or depth data may be combined to identify the spatial location of specific human body portions. US patent publication 2011 0052006 Gurman teaches a method of locating portions of a humanoid form using a temporal sequence of depth maps where each depth map represents a scene as a two dimensional matrix of pixels indicating topographic information. US patent publication 2011 0211754 Litvak teaches a method which processes image and depth data in such a way that specific parts of a body such as the head may be identified in the image and depth data. Thus post processing of image and or depth data can generate so called skeleton data or joint data describing the approximate locations in space of specific parts of a person s body.

To substantially overcome the above described problems embodiments of the present invention do not rely on 3D body scanners nor on wearable tapes or markers to gather information about a scene. Instead some embodiments of the inventive method and system rely on a minimum number of close to instantaneous data snapshots that are each obtained from a single viewpoint as described below wherein each data snapshot contains at least depth data and preferably a combination of image depth skeleton and or pixel label data. Some other embodiments of the inventive method and system rely on ongoing acquisition of such data snapshots rather than on a minimum number. Body surface measurements suitable for apparel accessory and prosthetic sizing and fitting are then obtained from one or more such data snapshots. Embodiments of the present system and method include the following advantages which are not intended to be an exhaustive list 

There are many useful applications of this low cost convenient and private system and method of sizing virtually any desired surface portion of a person s body. The following recitation of useful applications is not intended to be an exhaustive list but merely points out the wide and divergent fields in which embodiments of the present system and method find application.

The present day difficulty of sizing clothing is easily apprehended. The sizes of clothing items are not consistent across manufactures or countries and desired sizes are often out of stock at retail stores or simply non existent. Consumers must typically travel from store to store seeking clothing that fits well enough . Embodiments of the present system and method prepare standardized types of measurements that are applicable to all types of clothing and that may be translated across all brands.

Although as noted above kiosks utilizing 3D scanners are becoming available in the retail setting they still impose wait times on the consumer who must go to the location of the scanner may impose wait times on the consumer who might have to stand in line behind others to use the 3D scanner and require the consumer to return to the store if any measurements were missed or have to be repeated. Embodiments of the present system and method are designed to be used at home as much and as often as the user wishes.

In store measurements also raise privacy concerns. 3D scanners are necessarily operated by third parties and the detailed body shape data that they generate which may be used to reconstruct nude images are also stored by third parties out of the control of the consumer. The system described herein is designed to allow clothing consumers to measure themselves and then purchase custom fit clothing privately and in the comfort and convenience of their own home. The system does not require use obtain nor store full body 3D scans.

The desire for privacy may assume particular prominence in some special circumstances such as illness or injury. For example breast cancer victims who have undergone mastectomies may wish to carry out private measurements to aid in the purchase of specially shaped bras.

Some embodiments of the system are able to carry out measurements using electromagnetic waves that are only in the visual or near visual spectrum e.g. infrared . Such waves are ubiquitous in nature and harmless to humans. The system does not require the use of potentially harmful electromagnetic waves or radiation e.g. lasers which pose potential eye hazards or x rays.

Similar to the sizing situation for clothing it is challenging to size accessories such as necklaces watches sunglasses or hats. For example it is not unusual for a consumer to be gifted a necklace which doesn t fit correctly requiring the consumer to take the necklace back to the source store for resizing of the necklace chain. The advantages of the present system and method for clothing apply in equal measure to accessories.

For individuals suffering from medical conditions that require special devices attached to the body such as orthotic shoes or prosthetic legs sizing is often an even more arduous process. For example such individuals may have difficulty traveling to a practitioner who can correctly size them for the device question and if devices of different sizes need to be purchased over time for example a prosthetic leg for a young amputee the inconvenience and expense are magnified. Embodiments of the present system and method allow individuals who require medical devices or specialty clothing to easily and affordably measure and order the relevant body parts from home without the need to travel or to incur the expense of seeing a practitioner.

Embodiments of the present system and method can be used to track parameters of the person s body itself as opposed to items that are worn . This can be useful in the setting of health and fitness home care weight loss diabetes or other situations where an individual wishes to track their size and shape over time.

Embodiments of the present system and method can be used to generate custom fit devices for a wide variety of purposes ranging from consumer to industrial to military for example EEG sleep monitors to be worn for sleep studies body hugging swimwear or body armor.

Embodiments of the present system and method are not limited to humans. They may be applied to animals such as cats dogs or horses for example if custom clothing harnesses or saddles are desired.

It is also possible to continuously execute embodiments of the present system and method over time thereby creating movies of changing measurements for example to examine the motion of a muscle or the change in a person s gait. Time motion studies of this nature offer potential applications in for example medical rehabilitation surgical recovery and fall prevention.

The above examples show that embodiments of the present system and method are useful in many applications ranging from apparel to medicine to animal husbandry to home care 

In another embodiment a method of sizing and fitting an individual for apparel accessories or prosthetics includes capturing data corresponding to the individual moving within a field of view or remaining stationary for a predetermined amount of time within the field of view of at least one pattern emitter and one image capture device calculating depth data for the field of view based on the emitted pattern and received image and calculating one or more spatial measurements of a portion of a body surface of the individual based on the depth data for the field of view.

Embodiments the present invention are designed to automate taking physical measurements of portions of a user s body in ways that are compact portable private affordable repeatable rapid and convenient. The system may utilize a single energy sensor to obtain at a minimum depth data or two energy sensors of non overlapping frequencies to obtain a combination of depth data and spectral data for example color image data . Skeleton data which consists of the approximate locations in space of joints or of other ambiguous and or diffuse anatomic structures may in turn be calculated from the acquired depth and or spectral data. Pixel label data which consists of labeling pixels in acquired depth maps or color image maps such that the labeled pixels correspond to the body surfaces of humans in the field of view may also be calculated from the acquired depth and or spectral data.

Any collection of distance measurements to or between objects in a field of view is referred to herein as depth data . There are many ways to acquire calculate or otherwise generate depth data for a field of view.

For example depth data may be calculated based on a time of flight method. In this method light with known physical characteristics such as wavelength is emitted into a field of view. An energy sensor such as a camera receives the light that is reflected from the field of view. Changes in the physical characteristics of the light between its being emitted and its being received for example the round trip transit time of a light raise or the phase shift of an emitted waveform allow calculation of the distance to various objects that reflect the light in the field of view. If light pulses are utilized for example to measure round trip transit time the emitter can be for example a pulsed LED. If continuous light is utilized for example to measure phase shift the emitter can be for example a laser. Time of flight cameras are a subset of LIDAR Light Detection and Ranging technologies in which emitted and reflected light is used to remotely gauge the distance or other properties of a target. LIDAR cameras are similar to radar devices the main difference is that radar bounces radio waves off target objects but LIDAR uses ultraviolet visible or near infrared light Mesa Imaging AG of Zurich Switzerland is an example of a company that manufactures devices to acquire depth data through time of flight for example its SR4000 time of flight camera.

Besides LIDAR a different method of calculating depth data is through the use of pattern deformation methods also sometimes called light coding . In pattern deformation methods a light pattern with known physical characteristics such as pattern shape and spacing is emitted into a field of view. An energy sensor such as a camera receives the light pattern that is reflected from the field of view. Changes in the pattern between its being emitted and its being received for example gridlines moving closer further apart or average distances between speckled dots growing or shrinking allow calculation of the distance to various objects that reflect the light in the field of view.

In contrast to time of flight or LIDAR the specific wavelengths or transit of the emitted light are not crucial what matters in pattern deformation methods are the emitted pattern in which the light is placed and how that emitted pattern is subsequently reflected and deformed by objects in the field of view. Because the specific wavelength is less important in pattern deformation methods a common choice of wavelength in such methods is infrared which light cannot be seen by the human eye and can be superimposed on a scene without disturbing people. If the light pattern is relatively fixed and constant it is called structured light often structured light patterns are grids of regular lines.

If the light pattern exhibits random or pseudorandom variation it is called coded fight often coded light patterns are lattices of dots. The reason why random or pseudorandom variations may be used light patterns is so that small areas of the pattern will took slightly different compared to each other enabling easier lining up and registration of the emitted and reflected patterns. PrimeSense Limited of Tel Aviv Israel is an example of a company that manufactures sensors to acquire depth data through pattern deformation its sensors are embedded in for example the Microsoft Kinect device Microsoft Corp. Seattle USA and the Asus Xtion device Asustek Computer Inc. Taipei Taiwan .

Besides time of flight LIDAR and pattern deformation a different method of acquiring depth data is through the use of emitted energy that is not light. For example sound rather than light may be emitted and bounced off objects the reflected physical characteristics of the sound such as round trip transit time or frequency or phase shift may be used to calculate depth or other characteristics of the objects in the field of view. Sommer Mess Systemtechnik of Koblach Austria is an example of a company that manufactures devices to acquire depth data through ultrasonic impulse for example its USH 8 sensor which uses ultrasonic impulses to measure snow depth.

Embodiments of the present invention may use any type of entitled and received energy including but not limited to visible light ultraviolet light infrared light radio waves audible sound waves ultrasonic frequencies and pressure vibrations in order to acquire depth data. Embodiments of the present invention are agnostic as to the source of depth data. As used herein depth data refers to measurements of the distances to objects or portions of objects in a field of view.

Note that the term camera is used herein for convenience only and any energy sensor or image capture device or energy capture device or data capture device using various ranges of electromagnetic radiation or other types of energy may be used and substituted therefore. The terms energy sensor camera image capture device. energy capture device and data capture device are used interchangeably herein. Some such devices need not emit electromagnetic radiation because they capture energy based on reflected radiation already present in the environment. Other such devices may emit electromagnetic radiation and capture reflected radiation such as ultrasonic transducers and the like where such emitted electromagnetic or other energy radiation is not present in the environment to a sufficient degree or sufficiently present in known directions relative to a target.

Additionally the number of energy sensors are not limited to one or two such devices one energy sensor two energy sensors or more than two energy sensors may be used for example to generate additional stereoscopic data or to cover a larger region of space as well as a single energy sensor.

 Image data or image as used herein may refer to data or image captured by any of the above mentioned devices or sensors such as an energy sensor a camera an image capture device an energy capture device and or a data capture device and need not necessarily refer to the optical range in one embodiment image data may refer to the same visual spectrum data that would be generated by a standard digital camera consisting of a 2D photographic pixel map where each pixel represents a visible color. Note that in general color as used herein may refer to all the colors et the visual spectrum or a grayscale spectrum or any other palette of visual colors that are perceptible by the human eye. As used herein color image data refers to visual visible to the human eye image data similar to that captured by a standard consumer digital camera.

 Depth data is less intuitive than color image data. Depth data represents the distance from a sensor to a nearest object in space. show two representations of depth data. The preferred representation of depth data shown in is a 2D bitmap also sometimes referred to as a depth map. However alternate representations are also possible. The value of each x y pixel in the 2D bitmap shown in represents the distance from a common reference plane typically a vertical plane established by the sensor itself with the x axis running horizontally and the y axis running vertically to the closest physical object along a normal ray projected outward from the common reference plane at that x y coordinate. In such a coordinate system since the y axis extends floor to ceiling and the x axis extends to left and right of the sensor it follows that the z axis extends straight out from the sensor into the field of view. 

A 2D depth data bitmap therefore corresponds to a quantized contour or topographic map of the sensor s field of view. Equivalently a pixel value z at position x y in the data bitmap indicates that the surface or edge of a real world object exists at coordinate position x y z in physical space.

A depth bitmap can represent depth data only for aspects of an object that are visible to the sensor any aspects of an object that are out of view of the viewpoint are invisible and not represented in the depth bitmap.

For example if we were to obtain a depth data bitmap of the Moon as taken from standing on the Earth we would find that a collection of pixels in the middle of the bitmap formed the shape of a circle. The pixels in the center would have the lowest distance values they would correspond to the central part of the Moon which is closest to the Earth and the pixels at the edge of the circle would have the highest distance values they would correspond to the edge of the visible face of the Moon . Pixels outside the circle of the Moon representing the void of space would have maximum distance values essentially equivalent to infinity . The dark side of the Moon invisible to us would not be represented in the bitmap at all.

As shown in energy emitter bathes the field of view with energy. As described previously the energy emitted may comprise visible light or non visible light or sound or any other type of energy. The energy emitted may bathe the entire field of view all at once or may bathe different parts of the field in view in turn. Energy sensor gathers the energy that is reflected or received from objects in the field of view. Depth calculation module calculates the distances to objects in the field of view using the information acquired by energy sensor . As described previously such depth calculation may performed using time of flight or LIDAR or pattern deformation or any other method suitable for calculating depth measurements. Depth calculation module supplies depth data where for example depth data may be structured in a form similar to that shown in .

In depth calculation module uses the captured energy data from energy sensor to calculate depth data corresponding to the objects in the field of view. Such calculation may also rely on knowledge of the characteristics of the most recent energy characteristics or energy patterns emitted by energy emitter and or on past energy characteristics or energy patterns emitted by energy emitter or captured by energy sensor or on any other information required to carry out depth calculations.

Sensor portion encapsulates a minimal sot of components required by some embodiment of the present inventive method viz. an energy emitter an energy sensor and a depth calculation module. Because of the similarity to energy sensor optional color image sensor is included for convenience within sensor portion . It is important to note that sensor portion is a label of convenience roughly corresponding to the typical hardware components required for some real world embodiments of the present inventive method and so any components of the present inventive method including all of those for example shown in may be brought in or out sensor portion . For example optional skeleton calculation module could appear inside sensor portion in some embodiments of the present inventive method.

The depth data may be used by optional skeleton calculation module in order to construct optional skeleton data consisting of a set of approximate spatial locations of anatomic joints e.g. the x y z locations of shoulder hip and ankle . The data from depth calculation module may also be used by optional pixel label calculation module in order construct optional so called pixel label data consisting of labeling individual pixels in a depth map such as the depth map shown in that correspond to a human being in the field of view. A wide variety of machine learning methods are known in the art that may be utilized by optional skeleton calculation module and optional pixel label calculation module and are not discussed further here.

Spatial measurement module uses depth data to calculate measurements in space as described further below. Spatial measurement module supplies body measurements . For example a body measurement might be the distance between the most lateral point of an elbow and the ulnar bone of an arm.

It is possible to calculate body measurements using only depth data however the accuracy of the depth pattern or of body measurement calculations derived from depth data alone may insufficient and it may also be difficult to clearly delineate separate objects using depth data alone. Therefore in some applications it may be preferable to also include a standard color image sensor which gathers visual data in the same way as a standard digital camera. Optional color image sensor supplies optional color image data .

For example if two objects in the field of view are close together such that the energy received by energy sensor does not lead to clearly distinguishable depth data their different visual colors received by the color image sensor may be used to help distinguish the objects front each other. However for many applications of system the color image sensor and the color image data are optional.

As noted above it is possible to calculate body measurements using only depth data . However the speed of body measurement calculation may be improved by drawing upon additional calculations performed on depth data . For example optional skeleton data may be calculated from depth data and used to improve the speed of calculating body measurements . For example optional label data may be calculated from depth data and used to improve the speed of calculating body measurements . As described previously optional skeleton data describes the approximate spatial locations of anatomic joints for example the three dimensional x y z locations of shoulder hip and ankle . As described previously optional pixel label data distinguishes which pixels in a depth map if any correspond to a human being and which do not.

In the depth data consists of a set of calculated depth data where such data may conform for example to the representation shown in . The optional color image data consists of a set of image data such data may for example be represented in the way as images that are acquired by a typical everyday consumer digital camera such as by using a pixel array or raster. The optional skeleton data consists of a set of calculated spatial measurements of the approximate locations of portions of a user s body for example shoulders and knees such data may for example be represented by a set of x y z coordinates. The optional pixel label data consists of a set of pixel labels delineating which pixels correspond to a human being in the field of view such data may for example be represented by a pixel array or raster.

Embodiments of the system preferably utilize a combination of depth data optional color image data optional skeleton data and optional pixel label data to conduct measurements of an individual s body surface. The system can utilize depth data alone at the potential cost of decreased accuracy and or speed.

The sensor portion of may alternately utilize more than two image sensors. For example the sensor portion of may be augmented with a third image sensor not shown which may overlap in energy type or frequency with either the energy sensor or the optional color image sensor in order to provide an additional nearby stereoscopic vantage point by which to increase accuracy of depth calculations. Or multiple sensor portions may be combined for example by placing a different sensor portion in several fitting rooms of a store then combining together their collective data to cover a larger area than a single sensor portion is capable of covering.

In optional pattern pre processing module may clean sharpen remove noise from or otherwise modify the information from IR pattern sensor . In optional color image pre processing module may clean sharpen remove noise from or otherwise modify the information from optional color image sensor . Referring again to energy sensor may optionally be accompanied by a pre processing module not shown analogous to optional pattern pre processing module . Referring again to optional color image sensor may optionally be accompanied by a pre processing module not shown analogous to optional color image pre processing module . Alternatively in any pre processing if needed analogous to components and of may be incorporated within respectively energy sensor and optional color image sensor .

In depth calculation module draws on the information transmitted by optional pattern pre processing module or directly on IR pattern sensor if is not present and may optionally also draw on the information transmitted by optional color image pre processing module or optionally directly on optional color image sensor if is not present in order to calculate depth data . The color image itself if present may also be maintained separately as optional color image data . The depth data calculation module does not require any information from color image pre processing module or optional color image sensor but may optionally utilize such information to improve the accuracy of depth data .

The data from any combination of IR pattern sensor optional pattern pre processing module optional color image sensor optional color image pre professing module and depth calculation module may be used by optional skeleton calculation module in order to construct optional skeleton data consisting of as described previously a set of approximate spatial locations of anatomic joints for example the x y z locations of shoulder hip and ankle . Similar to the depth calculation module the skeleton calculation module requires only information from IR pattern sensor and or optional pattern pre processing module and preferably information from depth calculation module .

Although not shown in components analogous to optional pixel label calculation module and optional pixel label data of may be placed in an analogous relationship in as their counterparts in . For example an optional pixel label calculation module in not shown could receive the same inputs as optional skeleton calculation module and produce optional pixel label data not shown as described previously. For brevity does not display such analogs to optional pixel label calculation module and optional pixel label data of .

Once the input data for body measurements depth data optional skeleton data optional color image data and or optional pixel label data not shown are obtained the system may utilize a computer including a processor RAM and ROM to execute a series of operations on the input data in order to produce measurements of the user s body surface as described further below. Alternatively such processing may be performed by dedicated hardware chips and circuits each of which may have their own internal processor.

The resulting body surface measurements may be placed into a data storage device shown on a display device and or transmitted over a communication interface such as the Internet. The system may be operated by the user through user input such input may include hand gestures voice commands keyboard mouse joystick game controller or any other type of user input.

In some embodiments of system the depth calculation module is a component of or calculated by computer rather than sensor portion . In some embodiments of system the optional skeleton calculation module is a component of or calculated by computer rather than sensor portion . In some embodiments of system the optional pixel label calculation module not shown is a component of or calculated by computer rather than sensor portion . In general depth data optional skeleton data and optional pixel label data not shown may be generated by modules at various points within system so that their generation is not limited to sensor portion .

Because system and system perform similar functions and share similar inputs and outputs we will use system herein to refer interchangeably to both of system and system unless otherwise noted. Similarly and for the same reasons sensor portion and sensor portion energy emitter and analogous IR light emitter energy sensor and analogous IR pattern sensor optional color image sensor and depth calculation module and optional skeleton calculation module and depth data and optional skeleton data and optional color image data and win each be referred to interchangeably unless otherwise noted.

The system or may measure the user extremely quickly and with requirements to pose or position the body. In particular for an individual measurement of the user the system requires only a single data snapshot of the user. Thus in some embodiments the user may need to stand relatively still for only a predetermined amount of time for example 0.001 second to 0.1 second which in an optical camera may be determined by the amount of lighting shutter speed and aperture size. Other types of image capture or energy capture devices may operate on a much faster basis so that such capture is substantially instantaneous at least from the perspective of the user.

In other embodiments the user need not necessarily stand in one position or maintain a particular position for any amount of time and may be able to move real time within the field of view of the capture device. Individual measurements from different data snapshots may also be combined or operated upon further for example by adding them or averaging them as described below.

The term data snapshot or snapshot as used herein refers to a single set of depth and or image and or skeleton data and or pixel label data wherein the data are gathered substantially simultaneously with each other. As noted previously a single data snapshot cannot account for any invisible or darkside aspects of objects in the field of view. Where necessary to complete a measurement therefore the system fills in for invisible aspects by using heuristics that may take advantage of the symmetry of the human body for example by doubling a visible half circumference to estimate the full circumference of a limb. This process is described in further detail below.

The original construction of optional skeleton data may utilize multiple calculations on depth and or image data over time. The system is agnostic as to the means by which optional skeleton data are generated. From the point of view of the system a single substantially instantaneous data snapshot of depth and or image and or skeleton data and or pixel label data is sufficient to obtain a particular body surface measurement regardless of the prior post processing that was necessary to generate the content of that data snapshot.

Similarly the original construction of depth data may utilize multiple calculations on data received from either energy sensor or optional color image sensor individually or from both energy and color image sensors and collectively over time. For example a particular image received at one moment in time by either energy sensor or optional color image sensor may serve as a so called reference image at a subsequent moment in time such that two or mote images taken slightly apart in time are used to calculate depth data. Again the system is agnostic as to the means by which depth data including depth data are generated including image processing that may occur over time or different physical methods such as time of flight LIDAR or pattern deformation.

Through the use of a substantially instantaneous snapshot of data gathered from one or more stationary cameras the system avoids the use of a 3D scanner as well as of wearable markings. As is described further below this method also avoids the need for manual intervention in particular the need for a second person to conduct body measurements. Some embodiments of the system may be thought of as draping virtual measuring tapes in three dimensional space on top of different parts of the user s body simultaneously and almost instantly acting as a sort of virtual intelligent tailor. 

In some embodiments of system energy sensor and optional color image sensor may be placed near each other as a substantially co located array rather than being physically dispersed throughout different points on the perimeter of a field of view. Such co location is ideally as close as possible in order to have the field of view be similar for each sensor. The feasible co location separation distance depends upon the size attic physical components. For example if energy sensor and optional color image sensor are instantiated as CMOS chips the chips and their supporting electronics and optics may be placed such that their borders are for example approximately 5 mm apart and the centers of their lenses are for example approximately 2 cm apart.

In general the co located sensors are preferably positioned with a separation distance of millimeters to centimeter although smaller and larger distances are possible. Similarly the angles of view of the co located sensors are preferably within a few degrees of each other. This means that embodiments of the present system and method may be very compact and portable e.g. fitting easily on a shelf or at the base of a television at home.

Depth calculation module optional skeleton calculation module optional pixel label calculation module spatial measurement module and all other modules described herein may be implemented in circuitry as a physical component or processing element whether integrated or discrete or may be implemented to the extent possible in software to be executed by the processor or specialized processing circuitry.

The depth data might be relative instead of absolute that is a depth pixel value of 8 may delineate a distance that is twice as far as a depth pixel value of 4 without specifying how many absolute centimeters in the real world correspond to values of 8 or 4 . However the system necessarily requires a means to measure real world distances. For this reason the system may employ a calibrator. The purpose of the calibrator is to scale depth bitmap pixel distances to real world physical distances. The preferred shape of the calibrator is spherical so that its widest dimension is constant regardless of the angle from which it is viewed.

The calibrator is preferably given either a unique thermal i.e. infrared or color signature e.g. neon green so that it may be easily distinguished from other objects within respectively either a depth or color image bitmap. Because the calibrator is of known physical dimensions its extent along die x and y axes image bitmap and z axis depth bitmap allows physical distances to be mapped to pixel distances along all three axes. These mappings are accomplished using scaling factors referred to herein as calibration metrics . In some embodiments the calibrator may be used while in other embodiments it may be omitted.

Assuming that the calibrator is known to be say 8 cm in diameter it follows that 20 equal to 30 10 pixels along the z axis occupies 4 cm equal to half of the diameter of physical space. This ratio of 20 pixels to 4 cm is the z axis calibration metric. Similar metrics may be derived for the x axis and y axis. Subsequent body surface measurements may then be calibrated using these metrics for example it the user s neck circumference were found to be 200 pixels along the x axis then a calibrator metric of 20 pixels to 4 cm would indicate that the neck circumference was 40 cm in the physical world.

Note that in the X axis is labeled as X . This is because the positive direction of the x axis is to the left of the sensor and the negative direction of the x axis extends to the right of the sensor.

As disclosed in a preferred embodiment the calibrator may be spherical. In some embodiments the calibrator is substantially like a spherical ball used in a sports game e.g. tennis ball golf ball Ping Pong ball or basketball. However many other embodiments of the calibrator are possible. For example the calibrator may be a shallow fence that is placed upon the floor surrounding the user or the calibrator may be one or mote L shaped towers that are arrayed around the user. Some attributes for any calibrator are 1 it is easy to distinguish from other objects in the FOV and 2 it provides calibration metrics alone at least one and preferably alone all three axes x y and z.

Note that if the depth calculation module is inherently able to deliver reliable absolute measurements in physical space then the calibrator may not be needed. For this reason the calibrator is optional. One embodiment of the system makes use of the calibrator due to the difficulty of establishing precise real world depth data from non calibrated 2D bitmaps to the difficulty experienced by an human being eyeing a scene and then trying to judge the absolute size of objects in those scene down to the centimeter level merely by evaluating their relative sizes to each other. In other words the depth data are likely to be reasonably accurate on a relative scale but not on an absolute scale and so the calibrator is intended to compensate accordingly.

For a single measurement certain embodiments of the system requires only a single data snapshot of the user taken from a single point of view. This is because the system may use heuristics such as the inherent symmetry of the human body to fill in or compensate for any invisible depth or image information that is invisible to the sensor portion . Furthermore multiple measurements may be drawn from a single snapshot.

However for a measurement of a body portion to be taken that body portion should be substantially in view of the file sensor portion . As a general rule about half of the body portion is preferably visible to the sensor in order for that body portion to be measured because symmetry or heuristics can be used to deduce the shape of the other half .

For example to measure the volume of the abdomen the user typically substantially faces the sensor if the user presents a back profile equivalent to a back view to the sensor portion then the front of the user is invisible altogether and the abdominal volume cannot be measured. Conversely to measure the volume of the seat aside or back profile of the user may be required because the seat is invisible from a front view. Similarly to measure the length or width of a foot either the foot must be profiled so that the sole of the foot is facing the sensor allowing both measurements to be conducted from the same data snapshot or else the length must be measured on its own front a side profile of the foot and the width measured separately using a front back profile of the foot .

Another reason that multiple data snapshots may be required is due to noise in the system. It the inputs or outputs at any component of sensor portion are noisy that is varying randomly or non randomly due either to inherent aspects of sensor portion or to external environmental conditions then multiple data snapshots may be required to extract improved signal from the noisy background. For example data snapshots may be averaged over time using signal processing methods in order to have noise cancel out and thereby diminish over time while constructively adding together strengthening the valuable signal. If such averaging over time is performed then multiple data snapshots may be required for higher accuracy measurements.

Therefore although any one measurement may require only a single snapshot nonetheless in some embodiments more than one snapshot may be required to obtain a complete set of desired measurements e.g. to size someone for a pair of trousers . It is preferable to minimize the number of data snapshots because the fewer the number of snapshots the quicker and easier is the sizing for the user. To achieve this goal of minimizing the number of snapshots some embodiments of the system may minimize the number of separate profiles or views that are be presented by the user to the sensor portion for processing.

Many additional profiles besides the five listed above are possible for example facing the sensor with arms related at both sides and so the list of profiles above is not intended to be exhaustive. Additional profiles are within the scope of the system . For example a different set of poses is preferable for disabled persons e.g. a set of profiles in which the person would sit instead of stand . For example for shirt sleeve sizing a preferred profile may consist of the user placing hands on hips with elbows bent corresponding to a pose commonly assumed by customers during the sizing oil shirt sleeve by professional tailors. For example for bra sizing a preferred profile may consist of the user facing sensor portion with hands on hips and rotated slightly either left or right in order to allow points on the sides and front of the breasts to be acquired and measured by the system .

The relationship of measurements to the 5 primary profiles is shown in . For each measurement shown in the preferred profile is the first choice profile of the user with which to conduct that measurement and the alternate profile is a backup choice that may be used in place of or in addition to the preferred profile.

The number of data snapshots may be minimized as follows. First a desired collection of measurements is ascertained. For example these might be the collection of measurements required to fit a shirt or blouse. Such collections may be defined ahead of time e.g. by predetermined lookup tables or decided dynamically based on the requirements of the user. Second the system may access a table similar to that shown in to determine the minimum set of profiles to fulfill the entire collection of measurements. For example if the desired measurements are shoulder to wrist length shoulder to shoulder distance and upper leg circumference then the minimum number of profiles is equal to one because all three measurements can be collected from a single snapshot of a front profile of the user.

One way of finding the minimum set of profiles given a collection of measurements is to isolate the rows of that correspond to the desired collection of measurements and then to add up the number of times each profile occurs across both the Preferred and Alternate columns. A comparison of the profile counts versus the total number of measurements gives the minimum number of profiles needed to collect all the measurements. For example if there are three measurements and any profile appears three times across all the columns than that profile alone is the only profile that is needed otherwise if any profile appears two times then that profile and one other are the minimum needed otherwise three profiles may be required. This reasoning may be extended to any arbitrary number of measurements.

For example the user s front profile might be chosen. In Step the user may be prompted to adopt the profile . For example if the front profile was chosen in Step then the user would be prompted to stand facing the sensor with arms extended to the sides. In Step a data snapshot is acquired as previously described. In Step a subset of the collection of body measurements is drawn from the snapshot as described below. In Step the system checks whether all measurements in the collection of measurements have been obtained. If no then Step repeats selecting an unused profile from the set of user profiles that was generated in Step . If yes then the current measurement collection process is complete Step .

Because of the user profile minimization process described previously the user will be prompted to perform the lowest number of poses necessary to collect all the desired measurements and because a single data snapshot is virtually instantaneous this means that embodiments of the present system and method may act very rapidly. For example a measurement of neck circumference e.g. for a necklace may require only a single data snapshot occupying literally a fraction of a second the sizing and fitting equivalent of taking a single photo from a digital camera.

As described above if the system is noisy then some embodiments of the present inventive method may acquire multiple data snapshots in order to better extract signal from the noisy background. In such cases Step checks whether all desired measurements have been acquired according to a desired accuracy or threshold. An example of an accuracy might be continue acquiring and averaging data snapshots until a pre specified standard deviation of the data value is achieved. An example of a threshold might be acquiring 60 data snapshots at a rate of 30 data snapshots per second and averaging depth map data values across hem. Another example of a threshold might be that the user views the results of the data measurement and process and decides whether to continue acquiring additional measurements or not. In general Step allows any type of calculation or decision making process to improve signal extraction from noise.

It is also possible for the system to respond in real time to the user s posture and profile and opportunistically acquire measurements as the user moves around in any order of measurements. Such embodiments of system which enable real time interactivity are described further below and displayed in .

As set forth in and more generally in other embodiments it is possible to perform measurements of not just the user s body surface but of garments that the user is wearing. Step highlights that worn garment measurements may be collected instead of or in addition to user body surface measurements. For example the user could put on a favorite pair of jeans and an accordance with a specific embodiment measurements may be acquired of the now being worn jeans instead of or in addition to the users body surface for example by employing the same or similar steps as shown in .

One reason such worn garment measurements would be valuable is that they could enable new garments to be identified for example from a warehouse or an online store that possessed purchasable garments having similar size and shape characteristics to the user s favorite pair of jeans or any other worn item of clothing . So in general the steps in may apply to either the user s body surface or to garments that the user is wearing at the time of measurement.

Throughout this document for purposes of brevity and clarity we will refer to measurements of the user s body surface but it should be understood that measurements of garments worn by the user also fall in all respects within the scope of the system and method and that all discussions and figures herein pertain both to the measurement of a user s body as well as to measurement of any garments that may be worn by the user at the time of measurement.

Step might be implemented using a queue data structure that is created and initially populated in Step . Step might be implemented using a lookup table similar to but with columns that are body portions e.g. upper arm torso head rather than user profiles.

It should be appreciated that the lists of measurements and of qualitative descriptions shown above are not exhaustive and that the scope of embodiments of the present system and method is not limited to these specific measurements and qualitative descriptions additional types of body surface measurements may be identified and carried out by the system.

Embodiments of the present inventive method may use the identification of landmarks on the human body in order to conduct body measurements. A landmark as used herein is any point or border or in general any distinguishing location or set of locations on the body surface or on worn garments that may be identified and tracked in three dimensional space with accuracy sufficient for the body sizing application at hand. For example in sizing garments examples of landmarks might include the spatial position of the head of the ulna of the right arm for shirt sleeve sizing the lower border of the strap of a worn bra for bra sizing or the upper border of the bridge of the nose for eyeglass sizing . For sizing garments an example of a typical required accuracy might be approximately a half centimeter to a centimeter so that for example a shirt sleeve sizing application might identify and track the 3D spatial location of the head of the ulna for the right arm among other measurements within approximately a centimeter accuracy in real time.

Landmarks are distinguished iron the skeleton data by the precision reproducibility and reliability of landmarks. Skeleton data if present generally consist of approximate locations of nebulously defined portions of the body or collections of anatomic structures. Skeleton data can be thought of as guideposts general regions of the human body. Most often they correspond to joints of the human skeleton such as the shoulder or knee because machine recognition algorithms may be employed to recognize structures that stay relatively constant in shape while moving such as arms and legs and therefore these algorithms may also be used to identify the approximate articulation regions between say arms and legs.

An example of skeleton data would be the approximate 3D spatial location of the right shoulder joint. The right shoulder joint is of nebulous definition both structurally and spatially it consists of multiple anatomic components portions of the arm ribcage surrounding musculature and so forth and cannot be precisely located on the human body only approximately outlined. The skeleton data corresponding to the right shoulder joint therefore cannot be used to precisely locate and track over time a specific portion of the shoulder because these skeleton data do not refer to any particular part of the shoulder joint.

Furthermore skeleton data may be erratic or jitter over time depending on the underlying machine recognition algorithms being employed again because they don t refer to any specific particular location in space. Skeleton data are therefore in general incapable of being used to conduct precise measurements.

Landmarks are further distinguished from the pixel label data by the precision reproducibility and reliability of landmarks. Pixel label data if present consist of labels that may be applied to individual pixels in depth data or to individual pixels in optional color image data . The use of these labels when they are present is to distinguish human beings from each other and from the ambient environment in a field of view.

For example it depth data were represented by a 640 by 480 pixel depth map of a field of view and if the depth pixel at coordinate 400 200 corresponded to a distance to a portion of the body surface of a human being the depth pixel at coordinate 500 300 corresponded to a distance to a portion of the body surface of a different human being and the depth pixel at coordinate 20 50 corresponded to a distance to a door or a wall in the local environment then depth pixel 400 200 might be labeled person 1 depth pixel 500 300 might be labeled person 2 and depth pixel 20 50 might be labeled non person .

Similar reasoning applies to optional color image data . In sum if depth data or optional color image data are represented as pixels for example in an array or raster representation such pixels may be attached with labels that distinguish whether the pixel corresponds to a person or a non person and if a person an arbitrary identifies for the person where such labels are maintained in system as optional pixel label data .

As with optional skeleton data the optional pixel label data generally cannot be used to precisely locate and track over a specific portion of the human body. Optional pixel label data are generally able to signify for example that a specific pixel in a particular data snapshot belongs to a surface of a human body and not the ambient environment or that two different pixels belong to two different human bodies.

Optional pixel label data generally cannot uniquely identify person s identity for example they cannot label that a person is John H. Watson who lives at 221B Baker Street as opposed to person 1 nor can optional pixel label data generally label a portion of a body for example they cannot label that a pixel belongs to person 1 s right shoulder as opposed to just person 1 . Optional pixel label data are therefore equivalent to a type of mask as the term is known in computer science applying this pixel label mask to depth data or to optional color image data highlights which pixels if any correspond to an arbitrarily numbered human being.

Furthermore similar to optional skeleton data optional pixel label data may be erratic or jump over time depending on the underlying machine recognition algorithms being employed or on the noise the overall system . Pixel label data are therefore in general incapable of being used to conduct precise measurements.

A wide variety of methods to calculate skeleton data and or pixel label data as outputs using depth data and or color image data as inputs are known in the art and may draw upon machine learning statistical or other technologies or methods. For example the Microsoft Kinect For Windows Software Development Kit SDK from Microsoft Corp. of Seattle USA provides software routines to calculate skeleton data and pixel label data called player identification in the Kinect for Windows SDK from depth data and or color image data.

For example the OpenNI open source software framework under the auspices of the OpenNI Organization similarly provides software routines to calculate skeleton data called joint data in OpenNI and pixel label data called figure identification in OpenNI from depth data and or color image data. The Kinect for Windows SDK and the OpenNI framework employ different computational methods utilize different APIs have different operating characteristics and represent information differently. They are mentioned here as illustrations of potential methods to calculate skeleton data or pixel label data . The system is agnostic as to the means by which skeleton data or pixel label data are generated. In distinction landmarks as used herein are by definition of sufficient accuracy to conduct body measurements suitable for the particular application at hand including real time applications such as gait analysis. The word terminus as used herein is a special case of landmark a terminus is a landmark that is a single point on the surface of the body as distinguished from for example a border or a curve or a set of locations .

Note that some embodiments the present inventive method use types of energy such as infrared light from IP light emitter that cannot penetrate worn garments. Other embodiments may employ energy patterns that are able to penetrate worn garments. However because suck penetrating radiation may be harmful to human health or may pose privacy hazards some embodiments preferably rely on omitted energy of types such as infrared that do not penetrate worn garments. For many applications such as sizing apparel it is important to be able to measure either the surface of the human body directly or of interposed worn garments that closely approximate the surface of the human body. As a result some embodiments may place constraints on the nature of the clothing worn during execution of a particular application. For example a shirt sleeve sizing application may require the user to wear a relatively tight fitting shirt that does not have collars or cuffs so that the system can discern the correct underlying shape of the human body. Similarly for example a pants sizing application may require the user to forego baggy cargo pants and the like.

In the descriptions and Figures that follow it should be appreciated that often only depth data are required to carry out body measurements. For example depth data alone or optionally a combination of depth data and the skeleton data that are calculated from the depth data may be sufficient to carry out a measurement of shirt sleeve size because such data may enable identification of all necessary body landmarks e.g. points on the shoulder elbow and wrist and measure distances between those landmarks in other cases depth data are preferably combined with color image data or a combination of depth data calculated skeleton data calculated pixel label data and color image data may be preferable. In general identifying the position of a body landmark requires utilizing some combination of depth data optional skeleton data optional pixel label data and optional color image data but the specific combination and the specific requisite calculations carried out on that combination differ from landmark to landmark.

For example a combination of depth data calculated skeleton data and color image data may be preferable for determining bra size because if the user is currently wearing a bra the image data may be more accurate than the depth data for determining some spatial demarcations or borders of the bra. For example the lower border of the bra along the flattened and gradated abdomen may be difficult to precisely locate using only depth data but the color difference between the bra material and the exposed skin color beneath it may readily reveal the border with the use of color image data.

Steps through of refer to additional Figures respectively to pursue each specific type of measurement to conduct.

Step may alternately determine that multiple joints bound the body portion that was determined in Step of . For example the upper arm is bounded by shoulder and elbow joints two joints in total and the torso is bounded by two shoulder joints and two hip joints four joints in total . Step determines the approximate position of each joint again using either skeleton data or image segmentation methods.

In Step the local body surface outline or silhouette is determined around each joint or landmark position. For example if a position corresponds to the elbow then the local silhouette of the elbow is determined. The silhouette may be determined from a combination of depth data and or color image data and or pixel label data using image segmentation methods. The silhouette may be determined from depth data alone in some cases this may result in a degradation of accuracy for example if two body portions overlap too closely . The preferred representation of each outline generated by Step is as a mask or labeling of pixels that is superimposed on the color image data and depth data . Each outline thus describes a set of x y z locations of pixels that correspond to the body surface local to each joint or landmark position.

In Step each outline from Step is assigned a single terminus. The word terminus as used herein refers to a single point that corresponds to a location on the surface of the user s body a terminus may be represented for example as an pixel location in a depth or image bitmap or as an x y z point in space. The assignation of a terminus may be done using heuristic or computational methods. For example the terminus of an elbow outline might be the point on the elbow midline that is furthest away from the ground in a front profile in which profile the arm is extended to the side as described previously .

As another example the terminus of the top of the head might be the point on the surface of the head that is most distant from the ground. Step invokes Step if more than two terminuses were identified. Step reduces the number terminuses to exactly two using heuristic or computational methods. For example if the height of the torso is being measured then the two shoulder terminuses might be collapsed to a single terminus halfway between them and similarly for the two hip terminuses thus reducing the original tour terminuses to just two terminuses.

In Step the straight line spatial distance between the two terminuses of Step or is calculated. In Step this straight line spatial distance is optionally scaled to a real world distance using a calibrator metric as described previously. In Step the straight line spatial distance measurement may be stored for further use and the routine exits at Step .

This determination of Step is preformed in a similar fashion to Step described previously however determines the outline of a single body portion that is bounded by joint or landmark positions rather than as the outline of separate areas that are each local to a joint or landmark. This determination provides an incomplete representation of the surface of the body portion in question because approximately half of the body portion is invisible to the sensor at any one time for example only half of the upper arm is visible to the sensor at any one time.

Step may use heuristic or computational methods to assign one or more x y z terminuses to the outline of the body portion identified in . For example if the upper arm is the body portion of interest one terminus might be assigned to the point on the outline most distant front the ground corresponding to the top of the thickest point of the biceps muscle and the other terminus assigned to the point on the outline directly opposite corresponding to the bottom of the arm directly below the thickest part of the biceps muscle . Another way to assign terminuses would be to select periodically spaced points along the path of steepest curvature following the body portion surface.

Step calculates the distance of the curvature tracking the surface of the user s body that connects together the terminuses of Step . An arbitrary number of terminuses may be so connected in order to better approximate the real world distance along the surface of the body portion of interest.

Step multiplies the distance that was calculated in Step by a so called visibility scaling factor . This factor compensates for the invisible aspect of the body portion. Because a body portion will typically be hall visible to the sensor this factor is preferably simply the number 2 reflecting the approximate symmetry of the human body . The result of Step is a full circumference value.

Step optionally scales the circumference value from Step to a real world distance using a calibrator metric as described previously. In Step the circumference measurement may be stored for further use and the routine exits at Step .

If an angle compared to a spatial axis x y or z is desired then Step calculates the angle between the line equation of Step and the appropriate spatial axis. If an angle compared to another body portion is desired for example the angle between upper arm and lower arm at point of the elbow then Step repeats Steps through to arrive at second line equation corresponding to the second body portion of interest and Step calculates the resultant angle between the two computed line equations. Step may store the angle measurement for future use and the routine exits at Step

The surface model is necessarily unclosed and incomplete because as described previously aspects of the body portion will always be invisible to the sensor portion . For example if the abdomen is viewed from the front then the back part of the abdomen will be hidden from view of the sensor portion . Step artificially closes or completes the surface model using heuristics or approximations such as symmetry. For example if the volume of the abdomen is being measured from the front profile leaving a hole in the back of the surface model where the abdomen is invisible to sensor portion then Step might close the 3D model under the modeling assumption that the back wall of the abdomen is a flat vertical plate.

Step calculates the volume of the now closed surface model and Step may store the volume measurement for future use. Once the volume measurement has been calculated the surface model is no longer needed and may be discarded the system in some embodiments may not store any surface model or portion thereof in order to preserve the privacy of the user. The routine exits at Step .

Of note measurement of a surface area of a portion of the user s body as opposed to a volume measurement may alternately be performed in Step by closing the surface model with itself . In other words if the surface model is envisioned as a very thin sheet or ribbon hugging the surface or the user s body then the volume of the surface model is equivalent to an area of the surface of the body. In this way. can be used to measure an area of the surface of the body as well as a volume of the body.

For a description of male chest e.g. thin fit normal muscular large Steps measure several distances related to the chest and select a description based on the ratios of the distances. For a description at the abdomen a.k.a. stomach e.g. thin normal medium large Steps measure the volume width and height of the abdomen then select the description based on ratios of those measurements. For a description of the seat e.g. normal curved large Steps measure several distances related to the seat and select a description based on the ratios of the distances.

In general for any description as shown in Steps a set of applicable measurements is first gathered and then a description is selected based on various calculations or relationships among those measurements e.g. using ratios . Step optionally adjusts the description based on user demographics e.g. age or gender and Step may store the description measurement for future use. The routine exits at Step .

The measurements described across Steps to are not exhaustive. Additional types of measurements may be undertaken by the system . Examples of additional potential types of measurements include the area of a portion of the body surface e.g. the area that might be occupied by a tattoo the point of steepest radial curvature of a line or surface along the body surface and the minimum cross sectional width or length of a body portion. Embodiments of the present system and method therefore may contemplate or conduct any kind of desired measurements of a user s body and are not limited to the measurements described in .

Step store adjust of transmit the measurements or other parameters. For example transmission of measurements may occur via the internet to a facility that can manufacture a garment of locally to a disk storage so as to retain and chart measurements over time. Measurements or other parameters may also be adjusted for example to match requirements for data structure or for manufacturing intake before being transmitted to a manufacturer. The term parameter herein refers to any aspect of an item of apparel accessory or prosthetic including size shape fabric type color pattern collar shape button shape hem length graphic purchase price purchase date shipping address gift note or any other information concerning an item. Note that in some embodiments color image data depth data and skeleton data are preferably nut retained nor stored by the system in order to preserve the privacy of the user. 

Step combine the measurements to generate new measurements e.g. the height of the user may be calculated by summing the heights of head torso and leg or the length of two contiguous unclosed curves that were obtained in different data snapshots may be added together. For example two approximately orthogonal straight line measurements may be multiplied together to calculate the area of a portion of the body surface.

Step compare different measurements to improve the accuracy of the measuring process. As shown in some measurements may be obtained across multiple user profiles for example upper arm circumference might be measured in a front profile view but also in a side profile view . Step may compare several measurements of the same part of the user s body in order to improve the accuracy of a composite measurement for example averaging two measurements of the same physical object taken from two different data snapshots. Step may also perform an additional calibration cheek on the system as a whole by taking measurements of known objects using different data snapshots and then comparing the measurements to check for consistency.

Step translate measurements into brand specific sizes e.g. the set of body surface measurements obtained for a trousers sizing may be communicated to the user as being closest in fit to say Size 6 Female for the Anne Taylor brand.

Step allow the user to specify or select parameters for an item the term item as used herein refers generally to an apparel accessory or prosthetic item e.g. color fabric collar style pattern hem length preference for form fit vs. loose fit and so on.

Step allow user to customize the display for an item e.g. by selecting or designing a logo or other graphic image to be displayed on a manufactured item.

Step show the user a computer generated view of an item e.g. computer rendered 3D image of the item possibly superimposed on an image or facsimile of the user.

Step enable user to purchase an item preferably online e.g. by gathering address and credit card number then transmitting sizing and payment information to a third party for manufacture and shipping of the item.

The actions listed in may be combined in any number order or sequence and are further not intended to be exhaustive. The scope of the system includes any actions that may be performed upon the gathered measurements.

Step the user s current profile is determined. For example if the user happens to be facing the sensor portion straight on then the current profile is a front profile or if the user happens to be turned sideways to the sensor portion then current profile is a side profile. There are many different ways to determine the user s current profile.

For example one way is to evaluate the relative approximate positions of the user s joints such as shoulders and knees relative to each other and or to the sensor portion . For example another way is to apply facial recognition technologies to find the user s face and if estimate the angle of the face relative to the sensor portion .

Optionally the detected profile may be communicated to the user in Step or at any other point in . For example a screen display may indicate to the user that system has identified the user to be in for example front profile. The user may then respond or adjust to the detected profile. For example if the user intends to present a side profile to system but the system erroneously detects a front profile the user is given an opportunity to become aware of the error and may adjust his her position and stance to aid system in detecting the correct profile.

Once the user s profile has been determined a data snapshot is acquired in Step and a set of measurements is collected in Step . Steps and are equivalent to the like numbered steps in .

Next the measurements in Step are optionally adjusted or updated. For example to measure the shoulder to shoulder width of the user the system might perform a series of measurements over time during which the apparent shoulder to shoulder width may vary widely as the user alternately faced the camera or turned so present a side view to the camera. The process would then retain the largest such measurement under the assumption that the widest shoulder to shoulder measurement acquired by the system would best match the real world shoulder to shoulder distance.

Alternatively the system may calculate a running average of measurements for example by averaging the most recent 100 measurements of the length of the left arm so as to dampen signal noise. The purpose of Step essentially is to compensate for ongoing motions or varied stances of the user so that measurements may be acquired or refined opportunistically even while the user moves about naturally.

In Step the results of Steps and or may be stored for further use. For example if averaging certain measurements over time is desired as described above then Step may be responsible for maintaining a stored series of measurements so that the running average may be calculated.

Optionally the obtained measurements may be communicated to the user in Step or at any other point in . For example a screen display may indicate to the user that system has measured the user s sleeve length to be for example 31 inches. Or for example a screen display may draw rendered virtual measuring tapes superimposed on an image of the user s body thus indicating graphically some of the underlying calculations leading to the obtained measurements. The user may then respond or adjust to ale obtained measurements.

For example if the user notices that the system erroneously placed an end of a virtual measuring tape on the user s finger instead of the correct location on the user s wrist then the user is given an opportunity to become aware of the error and may adjust his her position and stance to aid system in detecting the correct points for the virtual measuring tape to lock onto. Thus the system and the user may adjust and respond to each other interactively real time. This interactivity applies whether the user is moving or stationary as in both cases the system may continue to acquire data snapshots on an ongoing basis for example at a rate of 30 snapshots per second .

If graphical representations are employed by system then to safeguard the user s privacy it may be desirable to avoid displaying an image of the user s face or head while preserving the remainder of the user s body and the communication of measurements. For example if body measurements are communicated to the user graphically by draping virtual measuring tapes onto an image of the user s body then before displaying the graphical representation the system may identify the portion of the user s body that represents the face or the head and blank out or delete the visual information corresponding to that portion. In this way the user s privacy may be safeguarded when needed.

As noted previously in some embodiments the system may not gather any color image information at all. In other embodiments the system may gather color image information only temporarily in order to use the color image information to carry out a set of measurements and then immediately afterward discard the color image information. In general for applications where user privacy is important it is preferable to either gather no color image data at all or if color image data is required for some measurements to gather color image data only as long as needed to determine the measurements and then discard the color image data as soon as possible without further storing or transmitting the color image data.

Step then checks whether all body measurements have been obtained to a desired level of accuracy or threshold and if so Step exits the process. For example Step might transition to exit if the set of measurements in Step remains constant within for example 1 10 of a centimeter during for example 90 contiguous measurements. For example Step might transition to exit it the user views a set of measurements on a display screen and chooses to stop acquiring new measurements. Although not shown in for reasons of brevity it is appreciated that other decision points besides step are possible and would tall within the scope of the present system and method. In some embodiments of the present inventive method Step does not exit but instead may execute indefinitely for example to supply ongoing garment sizing for a queue of users .

For example if the system in following the steps of failed to opportunistically find all necessary body measurements within an elapsed period of time say five minutes which could occur for example if the user did not move about sufficiently to present the prerequisite profiles of to the sensor portion then the system could optionally switch to the processes shown in in which the user would be actively prompted to assume the prerequisite profiles.

The bright white curves or lines are virtual measuring tape indicia that is graphical representations of the system s measurement progress which are updated and displayed to the user in real time. As the user moves about in real time the virtual measuring tapes follow the user s motion also in real time. The right side of shows the phrase Acquiring . . . to show that the exit condition of Step in has not yet been met.

As mentioned earlier embodiments of the present inventive method may be used in a wide variety of applications. For example apparel sizing embodiments of the present inventive method may be employed to carry out the sizing of shirts bras sports coats pants shoes eyeglasses helmets body armor backpacks swimming suits and virtually any other type of garment or worn accessory. These are illustrative examples and do not restrict the scope of the present inventive method.

Returning to the system may be embodied as a system cooperating with computer hardware components and or as computer implemented methods. The system may include a plurality of software modules or subsystems. The modules or subsystems such as the sensor portion and the computer subsystem may be implemented in hardware software firmware or any combination of hardware software and firmware and may or may not reside within a single physical or logical space. For example the modules or subsystems referred to in this document and which may or may not be shown in the drawings may be remotely located from each other and may be coupled by a communication network.

The system of is a high level hardware block diagram of one embodiment of the system used to perform sizing and fitting of an individual for apparel accessories or prosthetics. The system may be embodied as a system cooperating with computer hardware components and or as computer implemented methods. For example the subsystems such as the depth calculation module and all other modules herein may each include a plurality of software modules or subsystems. The modules or subsystems may be implemented in hardware software firmware or any combination of hardware software and firmware and or may not reside within a single physical or logical space. For example the modules or subsystems referred to in this document and which may or may not be shown in the drawings may be remotely located from each other and may be coupled by a communication network.

Additionally the hardware system shown in including the various cameras and sensors in one specific embodiment may be provided by one or more commercially available hardware platforms. For example sensor portion may be provided by the Kinect System available from Microsoft Corporation or by the Xtion device available from Asus Corporation. Such commercially available devices may be used to generate depth data and or color image data and or skeleton data and or pixel label data. For example computer subsystem may be provided by the Xbox System available from Microsoft Corporation or by a personal computer such as one running Microsoft Windows or Apple OS X.

Furthermore displays a hardware block diagram of a system computer that may be used to execute software of logic to implement the measurements of the user and other steps disclosed in this document. The computer or computer subsystem may be a personal computer and may include or connect to various hardware components such as the RAM the ROM the data storage and the like. The computer may include any suitable processor or processing device such as a subsystem computer microprocessor RISC processor reduced instruction set computer CISC processor complex instruction set computer mainframe computer work station single chip computer distributed processor server controller micro controller discrete logic computer and the like as is known in the art.

For example the processing device may be an Intel Pentium microprocessor x86 compatible microprocessor single core processor dual core processor multi core processor or equivalent device and may be incorporated into a server a personal computer server remote computer cloud processing platform or any suitable computing platform.

The RAM and ROM may be incorporated into a memory subsystem which may further include suitable storage components such as RAM EPROM electrically programmable ROM flash memory dynamic memory static memory FIFO first in first out memory LIFO last in first out memory circular memory semiconductor memory bubble memory buffer memory disk memory optical memory cache memory and the like. Any suitable form of memory may be used whether fixed storage on a magnetic medium storage in a semiconductor device or remote storage accessible through a communication link. A user input may be coupled to the computer and may include various input devices such as switches selectable by the system manager and or a keyboard or may be conducted independently of such devices e.g. by using hand gestures or other body gestures or by using voice commands. The user interface also interface also may include suitable display devices such as an LCD display a CRT various LED indicators a printer and or a speech output device as is known in the art.

To facilitate communication between the computer and external sources a communication interface may be operatively coupled to the computer system. The communication interface may be for example a local area network such as an Ethernet network intranet Internet or other suitable network. The communication interface may also be connected to a public switched telephone network PSTN or POTS plain old telephone system which may facilitate communication via the Internet. Any suitable commercially available communication device or network may be used.

The logic circuitry and processing described above may be encoded or stored in a machine readable or computer readable medium such as a compact disc read only memory CDROM magnetic or optical disk flash memory random access memory RAM or read only memory ROM erasable programmable read only memory EPROM or other machine readable medium as for examples instructions for execution by a processor controller or other processing device.

The medium may be implemented as any device that contains stores communicates propagates or transports executable instructions for use by or in connection with an instruction executable system apparatus or device. Alternatively or additionally the logic may be implemented as analog or digital logic using hardware such as one or more integrated circuits or one or more processors executing instructions or in software in an application programming interface API or in a Dynamic Link Library DLL functions available in a shared memory or defined as local or remote procedure calls or as a combination of hardware and software.

In other implementations the logic may be represented in a signal or a propagated signal medium. For example the instructions that implement the logic of an given program may take the form of an electronic magnetic optical electromagnetic infrared or other type of signal. The systems described above may receive such a signal at a communication interface such as an optical fiber interface antenna or other analog or digital signal interface recover the instructions from the signal store them in a machine readable memory and or execute them with a processor.

The systems may include additional or different logic and may be implemented in many different ways. A processor may be implemented as a controller microprocessor microcontroller application specific integrated circuit ASIC discrete logic or a combination of other types of circuits or logic. Similarly memories may be DRAM SRAM Flash or other types of memory. Parameters e.g. conditions and thresholds and other data structures may be separately stored and managed may be incorporated into a single memory or database or may be logically and physically organized in many different ways. Programs and instructions may be parts of single program separate programs or distributed across several memories and processors.

Returning to Step enables the user of the system to purchase an item e.g. of apparel accessory or prosthetic . The size shape or other fitting of this item may be determined by the most recent set of measurements conducted by the system or by any previous set of measurements conducted by the system in the past and then stored for later use or by any set of measurements provided exogenously e.g. through user input or from a tailor or retail store or by any combination of subsets thereof including any combination of individual measurements drawn across different collections of measurements including measurements acquired by the system or supplied by the user or by other sources.

Similarly any other parameters that may be used to specify customize or otherwise select an item for purchase may be stored and combined without limit by the system . Such parameters may include item color item pattern type of fabric collar shape hem length shape of button and so on as described in Step . Additional parameters may allow a user to customize a display for an item such as a logo or other graphic as described in Step . Additional parameters may link a set or measurements to a brand specific size as described at Step or combine or compare measurements across time or across data snapshots as described in Steps and . The system may acquire combine store or delete any and all such parameters in any permutation for indefinite periods of time.

The system may gather specific sets of such parameters and mark or store them as favorite or preferred combinations. This may be desirable for example if the user wishes to re order items having certain characteristics without repeating the process of conducting measurements or selecting parameters for those items.

The system may incorporate an online portal through which the user may select customize and purchase items. The portal may be a web browser portal or a portal that is made available a software download to a videogame system or a portal that is made available through an application download to a tablet computer or a mobile phone or any other type of online shopping interface. Examples commercially available web browsers include Microsoft Internet Explorer Mozilla Firefox Apple Safari and Google Chrome. Examples of commercially available videogame systems include Microsoft Xbox Sony PlayStation 3 and Nintendo Wii. Examples of tablet computers include Apple iPad and Samsung Galaxy Tab. Examples of mobile phone operating systems include Microsoft Windows Phone Apple iPhone iOS and Google Android. Embodiments of the present system and method may incorporate link to network with transmit information to or from or otherwise employ or utilize any kind of online shopping portal whether part of the system or supplied by a third party without limitation.

In Step the system may transmit measurements or other parameters for example to subsystems of system such as data storage device or to external systems or recipients such as a facility for manufacturing garments or an online ordering system for a clothing retailer . The measurements or other parameters may be adjusted in terms of format units e.g. metric vs. imperial or in any way desired. The measurements or other parameters may transmitted to from or via an online portal or to from or via any other system or third party. A recipient of measurements or other parameters may be a clothing manufacturer which utilizes the measurements or other parameters to for example select fabric cut fabric assemble an item of clothing and ship it to the user. A recipient of measurements or other parameters may also be a retail store which utilizes the measurement or other parameters to for example select an item of clothing from inventory and ship it to the user. A recipient of measurements or other parameters may also be a social networking system such as a website or mobile application which may be part of the system or may be provided or via any other system or third party and which may utilize the measurements or other parameters to share the user s preferences or recommendations with other individuals in the user s social network.

While various embodiments of the invention have been described it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the invention. Accordingly the invention is not to be restricted except in light of the attached claims and their equivalents.

