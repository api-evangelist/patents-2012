---

title: View direction determination
abstract: Among other things, one or more techniques and/or systems are provided for defining a view direction for a texture image used to texture a geometry. That is, a geometry may represent a multi-dimensional surface of a scene, such as a city. The geometry may be textured using one or more texture images depicting the scene from various view directions. Because more than one texture image may contribute to texturing portions of the geometry, a view direction for a texture image may be selectively defined based upon a coverage metric associated with an amount of non-textured geometry pixels that are textured by the texture image along the view direction. In an example, a texture image may be defined according to a customized configuration, such as a spherical configuration, a cylindrical configuration, etc. In this way, redundant texturing of the geometry may be mitigated based upon the selectively identified view direction(s).
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09135742&OS=09135742&RS=09135742
owner: Microsoft Technology Licensing, LLC
number: 09135742
owner_city: Redmond
owner_country: US
publication_date: 20121228
---
Many users may interact with image data such as multidimensional images generated by a rendering technique. In an example geometry such as a digital surface model may represent a three dimensional surface of a scene e.g. a scene depicting a city . Initially the geometry may comprise one or more non textured geometry pixels e.g. a pixel with a depth value but not a color value . Accordingly one or more texture images may be used to texture the geometry to create textured geometry e.g. color values may be assigned to geometry pixels within the geometry based upon one or more texture images . In this way the scene may be rendered based upon the textured geometry.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description. This summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Among other things one or more systems and or techniques for defining a view direction for a texture image used to texture geometry are provided herein. That is a geometry may comprise a multi dimensional representation of a scene. It may be appreciated that the scene may illustrate a person a city a surface of the earth a location a business a house a digitally rendered video game character grass water an object etc. Initially geometry pixels within the geometry may comprise depth values but may not comprise texture values such as color values for example. Accordingly the geometry may be textured using one or more texture images that depict the scene from various view directions. It may be advantageous to as provided herein selectively identify one or more view directions from which to texture the geometry such that a number of texture images and or a number of pixels used to texture the geometry may be reduced for example. Reducing texture information such as the amount of texture images and or pixels may result in efficient data storage and or efficient bandwidth utilization during streaming to a client for client side texturing of the geometry to generate a rendered image for example.

As provided herein an initial texture image e.g. a NADIR texture image depicting a city scene from a plumb line view direction such as a top down view with respect to a ground plane is applied to a geometry e.g. a three dimensional representation of the city scene to identify a textured portion of the geometry and or a non textured portion of the geometry. For example depth information associated with a geometry pixel such as a 3D point along a surface of the geometry may be used to project the geometry pixel to a location of a texture pixel within the initial texture image such that a color value of the texture pixel may be assigned to e.g. used to texture the geometry pixel. The textured portion comprises one or more geometry pixels textured within an undersampling threshold e.g. an undersampling threshold of 3 may indicate that a texture pixel of the initial texture image may be stretched to texture e.g. cover up to 3 geometry pixels by the initial texture image. The non textured portion comprises one or more geometry pixels that were not textured within the undersampling threshold by the initial texture image e.g. because the NADIR texture image depicts the city scene from the top down view a fa ade of a building may not be textured by the NADIR texture image and thus may be a non textured portion of the geometry .

Because the initial texture image may not texture the entire geometry thus resulting in the non textured portion one or more additional texture images depicting the scene represented by the geometry from various view directions may be selectively identified for texturing at least a portion of the remaining non textured geometry pixels e.g. the geometry may be textured so that up to at least 90 of the geometry pixels are textured . In an example a first view direction for a first texture image may be defined based upon a first coverage metric associated with an amount of the non texture portion that is textured within the undersampling threshold by the first texture image along the first view direction e.g. the first coverage metric may indicate that the first view direction provides relatively more texturing coverage of the non textured portion relative to one or more other view directions . In an example the first texture image may be defined as a planar texture image a cylindrical texture image a spherical texture image and or other types of texture images that may provide enhanced texture coverage. In this way one or more view directions for one or more texture images may be selectively identified to provide desired texture coverage of the geometry. Because a view direction may be selected based upon a coverage metric a number of texture images and or a number of pixels used to texture the geometry may be reduced because merely those view directions that provide relatively high non overlapping texturing coverage may be selectively used to texture the geometry.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are generally used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide an understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are illustrated in block diagram form in order to facilitate describing the claimed subject matter.

An embodiment of defining a view direction for a texture image used to texture a geometry is illustrated by an exemplary method of . At the method starts. In an example the geometry may represent a three dimensional surface of a scene e.g. a scene depicting a portion of a city . It may be appreciated that although a scene depicting a portion of a city may be referenced on occasion herein the instant application is not to be so limited. For example one or more of the techniques and or systems described herein may be applied globally e.g. to an entire city to the earth to one or more planets etc. and or may be applied locally to objects and or surfaces thereof e.g. a building a tree a sign a car a stone etc. . The geometry may comprise one or more geometry pixels having depth values e.g. at times referred to as 3D points . The geometry may be textured using one or more texture images. In an example an RGB texture image may comprise one or more pixels having color values and or depths values e.g. at times referred to as locations . A 3D point of the geometry may be projected to a location within the RGB texture image during texturing based upon the 3D point and the location having similar depth values. A color value at the location may be assigned to a pixel of the geometry corresponding to the 3D point thus texturing the pixel to generate a textured geometry pixel. In another example a texture image may comprise a virtual image that may be generated based upon overlap associated with a projection of one or more texture images onto the geometry. In this way even though available texture images may not depict the scene from a particular viewpoint a virtual image depicting the scene from that particular viewpoint may be generated e.g. by stitching together portions e.g. one or more pixels of one or more texture images . It may be appreciated that the geometry may be textured using more than one texture image depicting the scene from various view directions where some of the different texture images may overlap with one another at least in part which may result in a substantial amount of e.g. unnecessary storage and or bandwidth utilization during streaming of such texture images to a client for client side texturing. Accordingly as provided herein one or more view directions may be selectively identified to mitigate storage and or transfer of redundant data for example.

At an initial texture image e.g. a NADIR image depicting the scene represented by the geometry from a plumb line view direction such as a top down view may be applied to the geometry to identify a textured portion of the geometry and or a non textured portion of the geometry. The textured portion of the geometry comprises one or more geometry pixels that are textured within an undersampling threshold by the initial texture image. For example the NADIR image may depict the city scene from the top down view such that geometry pixels within the geometry that are not occluded by the top down view e.g. building roof tops roads sidewalks grass etc. may be textured by the NADIR image. The undersampling threshold may specify that a single pixel within the NADIR image is allowed to texture up to a particular number of geometry pixels e.g. a pixel of the initial texture image may be stretched to texture no more than 3 geometry pixels . In this way the non textured portion may comprise one or more geometry pixels that are not textured by the initial texture image within the undersampling threshold e.g. facades of buildings an inside of a covered bridge and or other occluded surfaces of objects . Thus one or more additional texture images e.g. a RBG image comprising depth values and color values a virtual image generated based upon overlap associated with a projection of one or more texture images onto the geometry etc. may be used to texture the non textured portion of the geometry.

At a first view direction for a first texture image may be defined based upon a first coverage metric. The first coverage metric may be associated with an amount of the non textured portion of the geometry that is textured within the undersampling threshold by the first texture image along the first view direction. For example the first coverage metric may indicate that the first texture image oriented according to the first view direction provides relatively more texture coverage e.g. textures more non textured geometry pixels of the non textured portion of the geometry than other view directions. In an example a surface orientation histogram may be used to identify the first view direction. That is the surface orientation histogram may correspond to a histogram of an orientation of a surface normal of untextured geometry e.g. non textured geometry pixels . For example the first view direction may correspond to a theta and a phi that are parameterized for the surface orientation histogram. Theta may represent an azimuthal rotation between 0 to 360 degrees e.g. a rotational angle around an outer periphery or equator of the city scene such that 0 degrees may correspond to an eastern looking view 180 degrees may correspond to a western looking view and 360 degrees may corresponding to the completion of a circumferential trip around the city scene for example . Phi may represent an angle between a z axis e.g. an axis extending from the sky down towards a center portion of the city scene e.g. NADIR or plumb line axis and a horizontal plane perpendicular to the z axis e.g. a ground plane for the city scene . In this way the surface orientation histogram may be used to identify a fraction of remaining surface area of the scene e.g. non textured geometry that is to be textured by a texture image such as the first texture image for example. In an example of utilizing the surface orientation histogram a greedy algorithm may be used to iteratively select view directions that cover e.g. texture a greatest number of non textured geometry pixels e.g. relative to other view directions e.g. identified using the surface orientation histogram and then may update the surface orientation histogram based upon newly textured geometry pixels that were textured by a selected view direction and the process can iterate until a desired number of non textured geometry pixels are textured. A surface of the scene may be triangulated to identify occlusion e.g. portions of geometry that are not depicted by the first texture image along the first view direction . In an example one or more pixels used to texture at least a portion of the non textured portion may be retained within the first texture image while one or more pixels not used for texturing e.g. due to redundant texturing overlap with respect to the initial texture image may be knocked out e.g. in painted from the first texture image to improve compression and or storage efficiency. That is where a geometry pixel of the geometry is textured by a pixel of the initial texture image a pixel of the first texture image that would otherwise e.g. redundantly texture that already textured geometry pixel is knocked out to mitigate data storage and or bandwidth utilization requirements for example.

The first texture image may be defined as a planar texture image a vertical texture image a cylindrical texture image a spherical texture image a virtual image and or other types of texture images based upon a surface configuration of an object depicted within the geometry that is to be textured by the first texture image. In an example a vertical texture image may be used to depict a fa ade of an object e.g. a relatively tall building within the geometry from a substantially parallel view direction relative to the fa ade e.g. a view looking directly at the side or fa ade of the building . In another example a cylindrical texture image may be used to depict a street a first facade of a first building on a first side of the street a second fa ade of a second building on a second side of the street and or other portions of objects that are along a projection path extending outward from a surface of the cylindrical texture image away from a center axis of the cylindrical texture image. In another example a spherical texture image may be used to depict at least a portion of an object within the geometry that is at least partially surrounded by the spherical texture image e.g. a pixel of the spherical texture image may have a projection path that is substantially towards a center point of the spherical texture image .

In an example one or more view directions may be defined for inclusion within a texturing image set based upon the one or more view directions corresponding to texture images that texture the geometry within the undersampling threshold above a total percentage of texture geometry pixels. For example at least 90 of the geometry is to be textured by one or more texture images. The texturing image set may comprise one or more view directions that may provide relatively high non redundant texturing coverage for the geometry e.g. the initial view direction may texture 55 of the geometry the first view direction may texture 20 of the geometry not already textured by the initial view direction a second view direction may texture 10 of the geometry not already textured by the initial view direction and or the first view direction and a third view direction may texture 5 of the geometry not already textured by the initial view direction the first view direction and or the second view direction . For example a second non textured portion of the geometry that is not textured by the initial texture image and or the first texture image may be identified. A second view direction for a second texture image may be defined based upon a second coverage metric associated with an amount of the second non textured portion that is textured within the undersampling threshold by the second texture image along the second view direction e.g. the second view direction may provide relatively greater texturing coverage of the second non textured portion than other view directions . In this way one or more texture images depicting the scene from the selectively identified view directions may be streamed to a client for client side texturing of the geometry to create a rendered image comprising a three dimensional representation of the scene. At the method ends.

The initial texture image may depict the scene from a top down view e.g. a NADIR image depicting the building and the cylindrical tower from a plumb line view direction such that the initial texture image may be capable of texturing a square roof of the building a circular roof of the cylindrical tower and ground surrounding the building and the cylindrical tower. In this way the view direction component may apply the initial texture image to the geometry to identify a textured portion of the geometry and or a non textured portion of the geometry . The textured portion may comprise one or more geometry pixels that are textured within the undersampling threshold by the initial texture image . For example the ground the square roof and the circular roof may be directly textured by the initial texture image while a first portion of a southern side of the building e.g. an upper portion of the southern side and a first portion of an eastern side of the building e.g. an upper portion of the eastern side may be textured by stretching one or more pixels of the initial texture image within the undersampling threshold . The non textured portion may comprise a second portion of the southern side e.g. a lower portion of the southern side a second portion of the eastern side e.g. a lower portion of the eastern side a northern side of the building a western side of the building and a vertical side of the cylindrical tower.

In another example of generating pre textured geometry the texture definition component may generate a second virtual image e.g. stitched together portions of one or more texture images as the second texture image . For example the second texture image may be oriented according to an angle from a ground plane such as at a 45 degree angle. The second texture image may depict at least a portion of the building a second building and or a third building from a view direction extending from a surface normal of the second texture image towards the buildings. It may be appreciated that in this example there is no geometry behind the second texture image e.g. whereas the third building is situated behind the texture image in the example of the preceding paragraph .

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to implement one or more of the techniques presented herein. An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to one or more of the principles set forth herein. In one such embodiment the processor executable computer instructions may be configured to perform a method such as at least some of the exemplary method of for example. In another such embodiment the processor executable instructions may be configured to implement a system such as at least some of the exemplary system of at least some of the exemplary system of at least some of the exemplary system of at least some of the exemplary system of at least some of the exemplary system of and or at least some of the exemplary system of for example. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via a network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Also at least one of A and B and or the like generally means A or B or both A and B.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

