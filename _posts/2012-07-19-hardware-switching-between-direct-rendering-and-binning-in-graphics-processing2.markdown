---

title: Hardware switching between direct rendering and binning in graphics processing
abstract: This disclosure presents techniques and structures for determining a rendering mode (e.g., a binning rendering mode and a direct rendering mode) as well as techniques and structures for switching between such rendering modes. Rendering mode may be determined by analyzing rendering characteristics. Rendering mode may also be determined by tracking overdraw in a bin. The rendering mode may be switched from a binning rendering mode to a direct rendering mode by patching commands that use graphics memory addresses to use system memory addresses. Patching may be handled by a CPU or by a second write command buffer executable by a GPU.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09547930&OS=09547930&RS=09547930
owner: QUALCOMM Incorporated
number: 09547930
owner_city: San Diego
owner_country: US
publication_date: 20120719
---
This application claims the benefit of U.S. Provisional Application No. 61 565 397 filed Nov. 30 2011 which is hereby incorporated by reference in its entirety.

This disclosure relates to techniques for graphics processing and more specifically to techniques for switching between direct rendering and binning in graphics processing.

Visual content for display such as content for graphical user interfaces and video games may be generated by a graphics processing unit GPU . A GPU may convert two dimensional or three dimensional 3D objects into a two dimensional 2D pixel representation that may be displayed. Converting information about 3D objects into a bit map that can be displayed is known as pixel rendering and requires considerable memory and processing power. In the past 3D graphics capability was available only on powerful workstations. However now 3D graphics accelerators are commonly found in personal computers PC as well as in in embedded devices such as smart phones tablet computers portable media players portable video gaming consoles and the like. Typically embedded device have less computational power and memory capacity as compared to conventional PCs. As such increased complexity in 3D graphics rendering techniques presents difficulties when implementing such techniques on an embedded system.

In general this disclosure describes techniques for switching between direct rendering and binning in graphics processing and techniques for determining a rendering mode.

In one example of the disclosure a method of graphics processing comprises generating rendering commands for rendering a frame wherein the rendering commands are for a binning rendering mode tracking the rendering commands that use graphics memory addresses determining one of a plurality of rendering modes for the frame based on rendering characteristics wherein the plurality of rendering modes includes the binning rendering mode and a direct rendering mode and altering the rendering commands that use graphics memory addresses to use system memory addresses in the case that the determined rendering mode is a direct rendering mode.

In another example of the disclosure a method of graphics processing comprises performing a binning operation on primitives of a scene wherein the primitives are divided into bins calculating an overdraw number representing an amount of overdraw of primitives in a region of the scene and determining a rendering mode based on the calculated score.

In another example of the disclosure a method of graphics processing comprises storing operation commands for executing a graphics operation in a first buffer and storing write commands in a second buffer wherein the write commands when executed alter the operation commands in the first buffer to create altered operation commands.

The techniques of this disclosure are also described in terms of an apparatus and a computer readable storage medium storing instructions for causing a processor to perform the techniques. The details of one or more examples are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

This disclosure relates to techniques for graphics processing and more specifically to techniques for determining a rendering mode and switching between rendering modes in a graphics processing system.

Current graphics rendering systems typically utilize a binning rendering mode sometimes called tile based rendering or a direct rendering mode to render a scene. In binning rendering one frame of a 2D or 3D scene is rendered by breaking the frame into smaller parts e.g. rectangular bins or tiles and rendering each of these bins separately. Binning rendering is useful for applications where little dedicated fast graphics memory GMEM is available such as for mobile applications. The size of the tiles can be configured to represent the amount of data that is available in the GMEM. For example if the GMEM is able to store 512 kB the size of a tile may be configured so that that pixel data contained in that tile is less than or equal to 512 kB.

Graphics processing in a direct rendering mode on the other hand does not break a frame into smaller bins. Instead the entirety of a frame is rendered at once. In some graphics processing systems e.g. a graphics processing system on a mobile device there is not enough GMEM to hold an entire frame of pixel data. Instead for a direct rendering mode slower system memory is used to render the frame.

This disclosure presents techniques and structures for determining a rendering mode e.g. a binning rendering mode and a direct rendering mode as well as techniques and structures for switching between such rendering modes.

In one example of the disclosure a method of graphics processing comprises generating rendering commands for rendering a frame wherein the rendering commands are for a binning rendering mode tracking the rendering commands that use graphics memory addresses determining one of a plurality of rendering modes for the frame based on rendering characteristics wherein the plurality of rendering modes includes the binning rendering mode and a direct rendering mode and altering the rendering commands that use graphics memory addresses to use system memory addresses in the case that the determined rendering mode is a direct rendering mode.

In another example of the disclosure a method of graphics processing comprises performing a binning operation on primitives of a scene wherein the primitives are divided into bins calculating an overdraw number representing an amount of overdraw of primitives in a region of the scene and determining a rendering mode based on the calculated score.

In another example of the disclosure a method of graphics processing comprises storing operation commands for executing a graphics operation in a first buffer and storing write commands in a second buffer wherein the write commands alter the operation commands in the first buffer to create altered operation commands.

As illustrated in the example of computing device may include a user input interface a central processing unit CPU a memory controller a system memory a graphics processing unit GPU a graphics memory a display interface a display and buses and . Note that in some examples graphics memory may be on chip with GPU . In some cases all hardware elements show in may be on chip for example in a system on a chip SoC design. User input interface CPU memory controller GPU and display interface may communicate with each other using bus . Memory controller and system memory may also communicate with each other using bus . Buses may be any of a variety of bus structures such as a third generation bus e.g. a HyperTransport bus or an InfiniBand bus a second generation bus e.g. an Advanced Graphics Port bus a Peripheral Component Interconnect PCI Express bus or an Advanced eXentisible Interface AXI bus or another type of bus or device interconnect. It should be noted that the specific configuration of buses and communication interfaces between the different components shown in is merely exemplary and other configurations of computing devices and or other graphics processing systems with the same or different components may be used to implement the techniques of this disclosure.

CPU may comprise a general purpose or a special purpose processor that controls operation of computing device . A user may provide input to computing device to cause CPU to execute one or more software applications. The software applications that execute on CPU may include for example an operating system a word processor application an email application a spread sheet application a media player application a video game application a graphical user interface application or another program. Additionally CPU may execute a GPU driver for controlling the operation of GPU . The user may provide input to computing device via one or more input devices not shown such as a keyboard a mouse a microphone a touch pad or another input device that is coupled to computing device via user input interface .

The software applications that execute on CPU may include one or more graphics rendering instructions that instruct CPU to cause the rendering of graphics data to display . In some examples the software instructions may conform to a graphics application programming interface API such as e.g. an Open Graphics Library OpenGL API an Open Graphics Library Embedded Systems OpenGL ES API a Direct3D API an X3D API a RenderMan API a WebGL API or any other public or proprietary standard graphics API. In order to process the graphics rendering instructions CPU may issue one or more graphics rendering commands to GPU e.g. through GPU driver to cause GPU to perform some or all of the rendering of the graphics data. In some examples the graphics data to be rendered may include a list of graphics primitives e.g. points lines triangles quadrilaterals triangle strips etc.

Memory controller facilitates the transfer of data going into and out of system memory . For example memory controller may receive memory read and write commands and service such commands with respect to memory system in order to provide memory services for the components in computing device . Memory controller is communicatively coupled to system memory via memory bus . Although memory controller is illustrated in as being a processing module that is separate from both CPU and system memory in other examples some or all of the functionality of memory controller may be implemented on one or both of CPU and system memory .

System memory may store program modules and or instructions that are accessible for execution by CPU and or data for use by the programs executing on CPU . For example system memory may store a window manager application that is used by CPU to present a graphical user interface GUI on display . In addition system memory may store user applications and application surface data associated with the applications. System memory may additionally store information for use by and or generated by other components of computing device . For example system memory may act as a device memory for GPU and may store data to be operated on by GPU as well as data resulting from operations performed by GPU . For example system memory may store any combination of texture buffers depth buffers stencil buffers vertex buffers frame buffers or the like. System memory may include one or more volatile or non volatile memories or storage devices such as for example random access memory RAM static RAM SRAM dynamic RAM DRAM read only memory ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

GPU may be configured to perform graphics operations to render one or more graphics primitives to display . Thus when one of the software applications executing on CPU requires graphics processing CPU may provide graphics commands and graphics data to GPU for rendering to display . The graphics data may include e.g. drawing commands state information primitive information texture information etc. GPU may in some instances be built with a highly parallel structure that provides more efficient processing of complex graphic related operations than CPU . For example GPU may include a plurality of processing elements that are configured to operate on multiple vertices or pixels in a parallel manner. The highly parallel nature of GPU may in some instances allow GPU to draw graphics images e.g. GUIs and two dimensional 2D and or three dimensional 3D graphics scenes onto display more quickly than drawing the scenes directly to display using CPU .

GPU may in some instances be integrated into a motherboard of computing device . In other instances GPU may be present on a graphics card that is installed in a port in the motherboard of computing device or may be otherwise incorporated within a peripheral device configured to interoperate with computing device . GPU may include one or more processors such as one or more microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs digital signal processors DSPs or other equivalent integrated or discrete logic circuitry.

GPU may be directly coupled to graphics memory . Thus GPU may read data from and write data to graphics memory without using bus . In other words GPU may process data locally using a local storage instead of off chip memory. This allows GPU to operate in a more efficient manner by eliminating the need of GPU to read and write data via bus which may experience heavy bus traffic. In some instances however GPU may not include a separate memory but instead utilize system memory via bus . Graphics memory may include one or more volatile or non volatile memories or storage devices such as e.g. random access memory RAM static RAM SRAM dynamic RAM DRAM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

CPU and or GPU may store rendered image data in a frame buffer . Frame buffer may be an independent memory or may be is allocated within system memory . Display interface may retrieve the data from frame buffer and configure display to display the image represented by the rendered image data. In some examples display interface may include a digital to analog converter DAC that is configured to convert the digital values retrieved from the frame buffer into an analog signal consumable by display . In other examples display interface may pass the digital values directly to display for processing. Display may include a monitor a television a projection device a liquid crystal display LCD a plasma display panel a light emitting diode LED array such as an organic LED OLED display a cathode ray tube CRT display electronic paper a surface conduction electron emitted display SED a laser television display a nanocrystal display or another type of display unit. Display may be integrated within computing device . For instance display may be a screen of a mobile telephone. Alternatively display may be a stand alone device coupled to computer device via a wired or wireless communications link. For instance display may be a computer monitor or flat panel display connected to a personal computer via a cable or wireless link.

According to one example of the disclosure CPU and or GPU driver may be configured to generate rendering commands for rendering a frame wherein the rendering commands are for a binning rendering mode track the rendering commands that use graphics memory addresses determine one of a plurality of rendering modes for the frame based on rendering characteristics wherein the plurality of rendering modes includes the binning rendering mode and a direct rendering mode and alter the rendering commands that use graphics memory addresses to use system memory addresses in the case that the determined rendering mode is a direct rendering mode.

According to another example of the disclosure CPU and or graphics driver may be configured to perform a binning operation on primitives of a scene wherein the primitives are divided into bins calculate an overdraw number representing an amount of overdraw of primitives in a region of the scene and determine a rendering mode based on the calculated score.

According to another example of the disclosure CPU and or graphics driver may be configured to store operation commands for executing a graphics operation in a first buffer and store write commands in a second buffer wherein the write commands alter the operation commands in the first buffer to create altered operation commands.

Software application may be any application that utilizes the functionality of GPU . For example software application may be a GUI application an operating system a portable mapping application a computer aided design program for engineering or artistic applications a video game application or another type of software application that uses 2D or 3D graphics.

Software application may include one or more drawing instructions that instruct GPU to render a graphical user interface GUI and or a graphics scene. For example the drawing instructions may include instructions that define a set of one or more graphics primitives to be rendered by GPU . In some examples the drawing instructions may collectively define all or part of a plurality of windowing surfaces used in a GUI. In additional examples the drawing instructions may collectively define all or part of a graphics scene that includes one or more graphics objects within a model space or world space defined by the application.

Software application may invoke GPU driver via graphics API to issue one or more commands to GPU for rendering one or more graphics primitives into displayable graphics images. For example software application may invoke GPU driver via graphics API to provide primitive definitions to GPU . In some instances the primitive definitions may be provided to GPU in the form of a list of drawing primitives e.g. triangles rectangles triangle fans triangle strips etc. The primitive definitions may include vertex specifications that specify one or more vertices associated with the primitives to be rendered. The vertex specifications may include positional coordinates for each vertex and in some instances other attributes associated with the vertex such as e.g. color coordinates normal vectors and texture coordinates. The primitive definitions may also include primitive type information e.g. triangle rectangle triangle fan triangle strip etc. scaling information rotation information and the like. Based on the instructions issued by software application to GPU driver GPU driver may formulate one or more commands that specify one or more operations for GPU to perform in order to render the primitive. When GPU receives a command from CPU graphics processing pipeline decodes the command and configures one or more processing elements within graphics processing pipeline to perform the operation specified in the command. After performing the specified operations graphics processing pipeline outputs the rendered data to frame buffer associated with a display device. Graphics pipeline may be configured to execute in one of a plurality of different rendering modes including a binning rendering mode and a direct rendering mode. The operation of the binning rendering mode and the direct rendering mode will be discussed in more detail below.

GPU driver may be further configured to compile one or more shader programs and to download the compiled shader programs onto one or more programmable shader units contained within GPU . The shader programs may be written in a high level shading language such as e.g. an OpenGL Shading Language GLSL a High Level Shading Language HLSL a C for Graphics Cg shading language etc. The compiled shader programs may include one or more instructions that control the operation of a programmable shader unit within GPU . For example the shader programs may include vertex shader programs and or pixel shader programs. A vertex shader program may control the execution of a programmable vertex shader unit or a unified shader unit and include instructions that specify one or more per vertex operations. A pixel shader program may include pixel shader programs that control the execution of a programmable pixel shader unit or a unified shader unit and include instructions that specify one or more per pixel operations. In accordance with some example embodiments of this disclosure a pixel shader program may also include instructions that selectively cause texture values to be retrieved for source pixels based on corresponding destination alpha values for the source pixels.

According to techniques of this disclosure GPU driver may also be configured to track commands generated for rendering in a binning rendering mode that utilize GMEM addresses. For each command that utilizes a GMEM address GPU driver may store a corresponding system memory address that would be used for a direct rendering mode. If the rendering mode is switched from the binning rendering mode to the direct rendering mode GPU driver may patch i.e. alter the rendering commands to replace the GMEM addresses with system memory addresses. Additional techniques for patching GMEM addresses with system memory addresses will be discussed in more detail below.

Graphics processing pipeline may be configured to receive one or more graphics processing commands from CPU via graphics driver and to execute the graphics processing commands to generate displayable graphics images. As discussed above graphics processing pipeline includes a plurality of stages that operate together to execute graphics processing commands. It should be noted however that such stages need not necessarily be implemented in separate hardware blocks. For example portions of geometry processing stage and pixel processing pipeline may be implemented as part of a unified shader unit. Again graphics pipeline may be configured to execute in one of a plurality of different rendering modes including a binning rendering mode and a direct rendering mode.

Command engine may receive graphics processing commands and configure the remaining processing stages within graphics processing pipeline to perform various operations for carrying out the graphics processing commands. The graphics processing commands may include for example drawing commands and graphics state commands. The drawing commands may include vertex specification commands that specify positional coordinates for one or more vertices and in some instances other attribute values associated with each of the vertices such as e.g. color coordinates normal vectors texture coordinates and fog coordinates. The graphics state commands may include primitive type commands transformation commands lighting commands etc. The primitive type commands may specify the type of primitive to be rendered and or how the vertices are combined to form a primitive. The transformation commands may specify the types of transformations to perform on the vertices. The lighting commands may specify the type direction and or placement of different lights within a graphics scene. Command engine may cause geometry processing stage to perform geometry processing with respect to vertices and or primitives associated with one or more received commands.

Geometry processing stage may perform per vertex operations and or primitive setup operations on one or more vertices in order to generate primitive data for rasterization stage . Each vertex may be associated with a set of attributes such as e.g. positional coordinates color values a normal vector and texture coordinates. Geometry processing stage modifies one or more of these attributes according to various per vertex operations. For example geometry processing stage may perform one or more transformations on vertex positional coordinates to produce modified vertex positional coordinates. Geometry processing stage may for example apply one or more of a modeling transformation a viewing transformation a projection transformation a ModelView transformation a ModelViewProjection transformation a viewport transformation and a depth range scaling transformation to the vertex positional coordinates to generate the modified vertex positional coordinates. In some instances the vertex positional coordinates may be model space coordinates and the modified vertex positional coordinates may be screen space coordinates. The screen space coordinates may be obtained after the application of the modeling viewing projection and viewport transformations. In some instances geometry processing stage may also perform per vertex lighting operations on the vertices to generate modified color coordinates for the vertices. Geometry processing stage may also perform other operations including e.g. normal transformations normal normalization operations view volume clipping homogenous division and or backface culling operations.

Geometry processing stage may produce primitive data that includes a set of one or more modified vertices that define a primitive to be rasterized as well as data that specifies how the vertices combine to form a primitive. Each of the modified vertices may include for example modified vertex positional coordinates and processed vertex attribute values associated with the vertex. The primitive data may collectively correspond to a primitive to be rasterized by further stages of graphics processing pipeline . Conceptually each vertex may correspond to a corner of a primitive where two edges of the primitive meet. Geometry processing stage may provide the primitive data to rasterization stage for further processing.

In some examples all or part of geometry processing stage may be implemented by one or more shader programs executing on one or more shader units. For example geometry processing stage may be implemented in such examples by a vertex shader a geometry shader or any combination thereof. In other examples geometry processing stage may be implemented as a fixed function hardware processing pipeline or as a combination of fixed function hardware and one or more shader programs executing on one or more shader units.

Rasterization stage is configured to receive from geometry processing stage primitive data that represents a primitive to be rasterized and to rasterize the primitive to generate a plurality of source pixels that correspond to the rasterized primitive. In some examples rasterization stage may determine which screen pixel locations are covered by the primitive to be rasterized and generate a source pixel for each screen pixel location determined to be covered by the primitive. Rasterization stage may determine which screen pixel locations are covered by a primitive by using techniques known to those of skill in the art such as e.g. an edge walking technique evaluating edge equations etc. Rasterization stage may provide the resulting source pixels to pixel processing pipeline for further processing.

The source pixels generated by rasterization stage may correspond to a screen pixel location e.g. a destination pixel and be associated with one or more color attributes. All of the source pixels generated for a specific rasterized primitive may be said to be associated with the rasterized primitive. The pixels that are determined by rasterization stage to be covered by a primitive may conceptually include pixels that represent the vertices of the primitive pixels that represent the edges of the primitive and pixels that represent the interior of the primitive.

Pixel processing pipeline is configured to receive a source pixel associated with a rasterized primitive and to perform one or more per pixel operations on the source pixel. Per pixel operations that may be performed by pixel processing pipeline include e.g. alpha test texture mapping color computation pixel shading per pixel lighting fog processing blending a pixel ownership text a source alpha test a stencil test a depth test a scissors test and or stippling operations. In addition pixel processing pipeline may execute one or more pixel shader programs to perform one or more per pixel operations. The resulting data produced by pixel processing pipeline may be referred to herein as destination pixel data and stored in frame buffer . The destination pixel data may be associated with a destination pixel in frame buffer that has the same display location as the source pixel that was processed. The destination pixel data may include data such as e.g. color values destination alpha values depth values etc.

Frame buffer stores destination pixels for GPU . Each destination pixel may be associated with a unique screen pixel location. In some examples frame buffer may store color components and a destination alpha value for each destination pixel. For example frame buffer may store Red Green Blue Alpha RGBA components for each pixel where the RGB components correspond to color values and the A component corresponds to a destination alpha value. Although frame buffer and system memory are illustrated as being separate memory units in other examples frame buffer may be part of system memory .

As discussed above graphics processing pipeline may render a graphics image according to a particular rendering mode including a binning rendering mode and a direct rendering mode. When rendering according to a binning rendering mode graphics processing pipeline may receive a batch of primitives i.e. one or more primitives to render into a resulting graphics image. To render the batch of primitives the resulting graphics image may be subdivided into a plurality of smaller portions e.g. tiles of pixels or bins and graphics processing pipeline may render each portion of the graphics image as a separate rendering pass.

While performing a particular rendering pass the pixel data for the bin associated with that particular rendering pass may be stored in a graphics memory sometimes called a bin buffer . After performing the rendering pass graphics processing pipeline may transfer the contents of graphics memory to frame buffer . In some cases graphics processing pipeline may overwrite a portion of the data in frame buffer with the data stored in graphics memory . In other cases graphics processing pipeline may composite or combine the data in frame buffer with the data stored in graphics memory . After transferring the contents of graphics memory to frame buffer graphics processing pipeline may initialize graphics memory to default values and begin a subsequent rendering pass with respect to a different bin.

The preamble execution command in IB1 points to a preamble IB2 that contains preamble commands that are executable by GPU . For example preamble IB2 may include commands that initializes that static state of GPU and sets the initial rendering state of GPU . The static state of GPU includes settings that do not change based on the particular application. The rendering state on the other hand includes GPU settings that may change based on the particular application e.g. an OpenGL application vs. a Direct X application . After the commands in the preamble IB2 are completed control returns to IB1 to perform the next execution command.

The next execution command in IB1 configures the render pass for the rendering mode being employed. Again in the example of the rendering mode is the binning rendering mode using software binning. Next the load bin execution command in IB1 points to the commands in load IB2 . For software binning data for a particular bin is loaded into GMEM Load 2 GMEM . Control then passes back to IB1 and the render bin execution command points to commands in the rendering IB2. Rendering IB2 consists of a series of state commands and draw commands for drawing the triangles in the loaded bin. Each draw command instructs GPU to draw the triangle in accordance with a graphics processing pipeline e.g. including a geometry processing state a rasterization state and or a pixel processing pipeline established by the commands and or GPU hardware. As shown in rendering IB2 each of the draw commands indicates that no visibility stream is used to determine if the specific triangles are actually visible in the bin. Visibility streams are generated in a binning rendering mode that uses hardware binning and will be discussed in more detail with reference to . The state commands in rendering IB2 affect the behavior of the graphics processing pipeline executed by GPU . For example state commands may change the color polygon mode e.g. points instead of solids or lines blending on off depth testing on off texturing on off culling clipping and other logical operations. As shown in rendering IB2 state commands may be issued on a per triangle or per primitive basis. That is the command State Tri A may affect the behavior of GPU when drawing triangle A while the State Tri B1 and State Tri B2 commands may affect the behavior of GPU when drawing triangle B. The State Tri B1 and State Tri B2 commands merely indicate that multiple state commands may be executed for each triangle.

After all command have been executed in rendering IB2 e.g. after all triangles have been drawn control returns to IB1 . The store bin execution command may include a pointer to a store IB2 that includes a command to store the rendered bin from GMEM into memory e.g. frame buffer . The render pass e.g. the execution commands from configure render pass to store bin as shown in IB1 are then repeated for each bin for one or more frames.

The goal of the binning pass is to identify triangles that intersect the current bin. As such only the position of the vertices of the triangle need to be determined to identify if a triangle intersects a particular bin. The binning pass utilizes a simplified vertex shader that only includes instructions that affect the position of the vertices. For example color instructions texture coordinates and other instructions that do not affect the position of triangle vertex may be removed from the simplified vertex shader used for the binning pass. The binning pass also uses coarse rasterization rather than fine rasterization to determine an approximate depth of each triangle. Coarse rasterization calculates a depth value at a lower precision e.g. using a lower number of bits than fine rasterization. Only approximate depth values are necessary to determine if a triangle is visible in the bin. Pixel shaders are not used in the binning pass.

The binning pass then utilizes a depth test on the coarse depth values to determine if a triangle is visible in the bin relative to other triangles in the bin. Based on this depth test a visibility stream is updated. The visibility stream may be a string of bits that indicates whether or not a specific triangle in the rendered bin is visible e.g. 1 indicates a triangle is visible 0 indicates a triangle is not visible .

The commands in rendering IB2 are similar to those of rendering IB in but for the use of the visibility stream. Draw commands e.g. Draw Tri A Draw Tri B Draw Tri C etc. in the rendering IB2 may use the visibility stream generated by the binning pass to determine whether or not it is necessary to draw a specific triangle. For example drawing may be skipped for triangles indicated as not visible by the visibility stream.

As opposed to rendering a frame bin by bin as in a binning rendering mode a direct rendering renders an entire frame in one pass through a graphics pipeline. Direct rendering typically utilizes slower system memory when executed in binning based architectures with a limited amount of graphics memory.

The preamble execution command in IB1 points to preamble IB2 that contains instructions for establishing the static state and the initial rendering state of GPU . These commands act similarly to the commands in preamble IB2 of but setup the rendering state for a direct rendering mode rather than a binning rendering mode.

In accordance with techniques of this disclosure before an application e.g. software application of begins rendering a scene a graphics driver e.g. graphics driver executing on one or more processors e.g. CPU makes a determination a rendering mode e.g. a determination between binning rendering and direct rendering based on heuristic data concerning the desire rendering pass. In some techniques heuristic data concerning a current rendering pass may be gathered from previous rendering passes. However this technique may not always be an optimal way to determine the rendering mode as the application may switch rendering techniques before rendering a new scene. As such this technique may lead to inefficient rendering until enough new data has been accumulated to switch to the proper rendering mode.

Additionally heuristic data concerning past renderings may not always provide for the most optimal rendering mode for the current scene if the current scene is different from previous scenes. For example an application that would optimally use rapidly changing rendering modes may lead to many false predictions using such heuristic analysis. Ideally the graphics driver can determine the rendering load for a given render target and make a rendering mode determination immediately. This disclosure proposes techniques for a more optimal determination of a rendering mode and techniques for switching between rendering modes.

The following techniques are applicable for a graphics processing system using any graphics application program interface API and in particular are suitable for graphics APIs that utilize binning rendering. Examples of such APIs include Microsoft s DirectX9 DX9 DX10 and DX11 as well as open source graphics APIs such as OpenGL and OpenGL ES.

Rendering commands in the binning rendering mode uses special addresses that are written to certain registers so that the fast graphics memory GMEM may be accessed. Since graphics driver initially assumes binning is enabled for all rendering every register which has a choice of GMEM versus system memory will use the GMEM address. Binning rendering mode IB2 in shows a series of commands associated with drawing a triangle Draw Tri where commands and utilize a GMEM address.

When the rendering is to be flushed graphics driver has access to all rendering commands about to be performed. In accordance with techniques of this disclosure graphics driver may be configured to analyze the rendering commands and may take into consideration one or more rendering characteristics i.e. heuristic data concerning the rendering pass . Such rendering characteristics may include the size and type of the render target an indication of whether depth testing is enabled the complexity of the shaders used the number of primitives drawn the number of texture reads the sizes of any textures read and or the micro tiling mode of all surfaces in use.

For example based on the size of a render target GPU driver may determine whether the overhead of binning e.g. the time to perform load store cycle to GMEM plus the binning pass will be offset by positive effects of binning. For example a small render target e.g. 16 16 may execute faster in direct rendering mode even when saving to system memory.

As another example a graphics pipeline that does not utilize depth testing may not utilize advantages of binning rendering mode. Typically when binning is not used a depth test has to be applied to read an existing depth value perform a test and then write the new depth value back to the buffer in system memory. With binning the depth test process is done in GMEM which makes it free i.e. very fast with minimal overhead time . As such when there is no depth testing enabled for a particular graphics pipeline the binning rendering mode would not provide any memory bandwidth saving related to depth testing. As such when depth testing is disabled or not being used GPU driver may determine that direct rendering mode is preferred.

As another example the binning rendering mode provides the most benefit when there is depth complexity e.g. primitives at various depths and overlap between triangles. When the number of primitives drawn is small the benefit from a binning rendering mode may also be small. As such GPU driver may determine that direct rendering mode is preferred when a small number primitives is to be drawn. Likewise GPU driver may determine that binning rendering mode is preferred when a large number of primitives is to be drawn.

As another example when performing texture extra stores and reads to and from system memory has a negative effect on system memory bandwidth. As such when texturing binning rendering mode provides quicker access to memory i.e. most stores and reads are performed with faster GMEM . The number and frequency of texture operations in a scene to drawn might nullify the gain from the binning rendering mode. That is fewer texture operations may suggest that binning rendering mode will provide fewer benefits and that direct rendering mode should be used instead.

The outcome of the analysis of the rendering commands may be computed as a score which may take into account one or more of the various characteristics discussed above e.g. on a weighted or non weighted basis. If this score is below a given threshold the direct rendering mode is used. If this score is above a given threshold the binning rendering mode is used. As such this technique provides for a just in time JIT analysis of a current render target to determine the current rendering mode. Heuristic analysis of past rendering passes is not needed. However heuristic analysis of past rendering passes may be used instead or in conjunction with analysis of a current render target. For example the JIT analysis of the current rendering mode may be used as an indicator that the rendering mode determined from heuristic analysis of accumulated statistics of past renderings is invalid.

According to another example of the disclosure the determination of a rendering mode e.g. a determination between a binning rendering mode and a direct rendering mode may be made using an overdraw tracker in a graphics processing system utilizing hardware binning.

In graphics architectures that utilize binning there are typically 2 phases 1 a binning phase which sorts primitives into screen aligned bins based on their transformed vertex positions and 2 a rendering phase where each of these bins i.e. the primitives in the bin are rendered. In addition to the sorting step some graphics processing architectures also generate a visibility stream per primitive and a coarse grained depth Z value associated with the region e.g. in so called hardware binning . Note however that this hardware binning may not produce direct information about the distribution of the primitives in the bins and the associated overdraw. This disclosure proposes adding an overdraw tracker at the same granularity as that of the coarse grained Z rasterizer i.e. the commands in binning IB2 . For example commands e.g. calculate overdraw and update overdraw tracker may be added to binning IB2 that instructs GPU to calculate an amount of overdraw for each bin and to update an overdraw tracker based on the calculated amount of over draw.

This overdraw may be an integer value per region where the region may be a pixel a portion of a bin a bin or a plurality of bins that represents the overlap between primitives rasterized in that region and hence the benefit of using binning rendering. Graphics driver may have access to the overdraw number and may use the overdraw number to make rendering mode determinations. This technique can then be extended to aggregate this value to all regions in a bin and further to all bins in a scene. This allows a software application and or driver e.g. graphics driver to make an immediate determination when compared against other heuristics on whether binning rendering will be beneficial. In addition these techniques can also be used as a debug tool to visualize regions of activity in a complex rendering scenario.

Returning to based on the score based on an analysis of the rendering commands and or the overdraw tracker graphics driver determines the optimal mode. In conjunction with determining the more optimal rendering mode graphics driver may also be configured to track all binning rendering commands that utilize a GMEM address e.g. Commands and in the example of . Graphics driver may store a corresponding system memory address for each of these commands e.g. in system memory so that the binning rendering commands using GMEM addresses may be altered to use system memory address. If direct rendering is determined to be the more optimal mode graphics driver may patch binning rendering mode IB2 to replace the GMEM addresses with system memory addresses thus producing direct rendering mode IB2 . In this way rendering commands for direct rendering may be created without re creating an entire command structure for a direct rendering mode IB2. Finally at flush time graphics driver adds commands to the IB1 e.g. IB1 of to execute a BLT IB2 and the rendering IB2 in this case the rendering IB2 altered to use system memory addresses and GPU is signaled to start executing the IB1.

In another example of this disclosure each register used for rendering may be implemented in hardware. is a conceptual diagram illustrating rendering mode selection according to this example of the disclosure. A global control register may be used to control which set of registers is used for a given rendering mode e.g. binning rendering mode register or direct rendering mode register . Binning rendering mode register may handle destination surface information i.e. bins address registers for GMEM and visibility stream usage for hardware based binning rendering . Direct rendering mode register will include the addresses to system memory. Global control register controls which version of the above registers is used to populate the commands in rendering IB2 for example based on the JIT analysis of rendering mode as described above. Graphics driver may control global control register to select binning rendering mode register or direct rendering mode register . Rather than patching the IB2 with software as described above this technique uses hardware registers. Global control register may be in IB1.

In another example of the disclosure techniques for patching a command buffer are proposed. is a conceptual diagram illustrating rendering command patching according to this example of the disclosure. The proposed techniques of this example may be used for patching a command buffer when switching from a binning rendering mode to a direct rendering mode. However the following techniques may be utilized in any situation where patching a command buffer is desired. For example commands may be patched to support virtualization of graphics memory to change MIP level of resource level of detail LOD in lower MIPs or to run a correctness scanner before executing a command buffer. The CPU cycles needed to patch a command buffer to switch from binning rendering mode into direct rendering mode can be costly in certain scenarios. This example aims to reduce the CPU overhead.

In general this technique provides a way for graphics driver to use GPU instead of GPU driver to patch a command buffer thereby minimizing CPU overhead. In the example of if graphics driver is to switch between binning and direct rendering graphics driver tracks and patches all of the IB2 commands prior to adding execution commands to an IB1. This example proposes that instead of building a patch list e.g. the patch list shown in system memory of graphics driver builds a separate patching IB2 that contains write commands that alter a command e.g. any general operation command in another IB2. For example the destination of the write commands may be the locations in a binning rendering mode IB2 which need to be altered to use system memory addresses in the case that a direct rendering mode is selected by graphics driver . When graphics driver is ready to flush the commands it has the option of executing the commands in the patching IB2 to enter a direct rendering mode or skipping the patching IB2 and continuing in binning mode. Graphics driver may effect patching IB2 to be executed by adding an execution command Patch Render IB2 to the execution commands in IB1 . In this way GPU will execute the patching commands in IB2 before executing the rendering commands in IB2 . As such GPU itself makes the patches to the rendering IB2 to effect a rendering mode switch rather than having CPU make the patches.

CPU may then determine one of a plurality of rendering modes for the frame based on rendering characteristics wherein the plurality of rendering modes includes the binning rendering mode and a direct rendering mode . The rendering characteristics include at least one of size and type of a render target depth test status complexity of shaders number of primitives drawn number of texture reads size of textures and a micro tiling mode. Determining one of the plurality of rendering modes may include determining one of the plurality of rendering modes based on rendering characteristics of a current frame. In another example determining one of the plurality of rendering modes may include determining one of the plurality of rendering modes based on rendering characteristics of a current frame and previously rendered frames.

CPU may then alter the rendering commands that use graphics memory addresses to use system memory addresses in the case that the determined rendering mode is a direct rendering mode . In the case that the determined rendering mode is the binning rendering mode CPU would not alter the rendering commands.

CPU may be further configured to store execution commands in a first buffer and to store the rendering commands in a second buffer. The execution commands point to the rendering commands. Altering the rendering commands may include patching the second buffer to replace graphics memory addresses with system memory addresses. CPU may further add an execution command to the first buffer that points to the rendering commands in the second buffer. GPU may then execute the execution commands in the first buffer.

In another example CPU may be configured to store binning mode specific information in a first register store direct rendering mode specific information in a second register and utilize a global register to select between the first register and the second register based on the determined rendering mode. The binning mode specific information includes at least one of register addresses that handle destination surface information graphics memory addresses and visibility stream usage and wherein the direct rendering mode specific information includes system memory addresses.

The overdraw number may be calculated for a region of a bin over multiple bins and or for the entire scene. One example technique of calculating an overdraw number for a bin may include calculating an overlap value for each pixel in a bin summing each calculated overlap value for each pixel in the bin to produce a total overlap value and dividing the total overlap value by a number of pixels in the bin to produce the overdraw number. The overlap value is defined as the number of primitives greater than one that touch a pixel.

CPU may be further configured to determine one of a plurality of rendering modes for the frame based on rendering characteristics wherein the plurality of rendering modes includes the binning rendering mode and a direct rendering mode . The rendering characteristics may include at least one of size and type of a render target depth test status complexity of shaders number of primitives drawn number of texture reads size of textures and a micro tiling mode. Determining one of the plurality of rendering modes may include determining one of the plurality of rendering modes based on rendering characteristics of a current frame. In another example determining one of the plurality of rendering modes may include determining one of the plurality of rendering modes based on rendering characteristics of a current frame and previously rendered frames.

CPU may be further configured to cause the write commands in the second buffer to be executed e.g. by GPU in the case that the determined rendering mode is the direct rendering mode .

In one or more examples the functions described above may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored as one or more instructions or code on an article of manufacture comprising a non transitory computer readable medium. Computer readable media may include computer data storage media. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions code and or data structures for implementation of the techniques described in this disclosure. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices flash memory or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and Blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

The code may be executed by one or more processors such as one or more DSPs general purpose microprocessors ASICs FPGAs or other equivalent integrated or discrete logic circuitry. In addition in some aspects the functionality described herein may be provided within dedicated hardware and or software modules. Also the techniques could be fully implemented in one or more circuits or logic elements.

The techniques of this disclosure may be implemented in a wide variety of devices or apparatuses including a wireless handset an integrated circuit IC or a set of ICs e.g. a chip set . Various components modules or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques but do not necessarily require realization by different hardware units. Rather as described above various units may be combined in a codec hardware unit or provided by a collection of interoperative hardware units including one or more processors as described above in conjunction with suitable software and or firmware.

Various examples have been described. These and other examples are within the scope of the following claims.

