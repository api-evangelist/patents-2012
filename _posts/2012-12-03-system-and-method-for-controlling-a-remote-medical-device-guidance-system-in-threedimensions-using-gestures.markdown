---

title: System and method for controlling a remote medical device guidance system in three-dimensions using gestures
abstract: A system for enabling a user to remotely control a robotic medical device system includes a motion capture apparatus to capture motion of a user in a sensing volume and generate indicative output data. The system includes a control unit configured to execute gesture recognition logic that recognizes a user gesture based on analysis of the indicative output data. The control unit executes interpreter logic that is configured to translate the recognized user gesture into a corresponding robotic medical device control command configured to control an aspect of the operation of the robotic medical device system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09439736&OS=09439736&RS=09439736
owner: St. Jude Medical, Atrial Fibrillation Division, Inc.
number: 09439736
owner_city: St. Paul
owner_country: US
publication_date: 20121203
---
This application is a continuation in part of U.S. application Ser. No. 13 208 924 filed 12 Aug. 2011 now pending the 924 application . This application is also a continuation in part of U.S. application Ser. No. 12 507 175 filed 22 Jul. 2009 now allowed the 175 application . This application is also a continuation in part of U.S. application Ser. No. 13 637 401 filed 26 Sep. 2012 now pending the 401 application which is the national stage of international application no. PCT US11 30764 with an international filing date of 31 Mar. 2011 the 764 application which claims priority to U.S. provisional application No. 61 319 795 filed 31 Mar. 2010 the 795 application . The 924 application the 175 application the 401 application the 764 application and the 795 application are all hereby incorporated by reference as though fully set forth herein.

The instant disclosure relates generally to electrophysiology lab integration and more particularly to user interfaces and devices therefore for robotic control of electrophysiology lab diagnostic and therapeutic equipment.

It is known to provide an electrophysiology lab in a medical facility. Such a lab may have use of a wide variety of diagnostic and therapeutic equipment useful in rendering medical service to a patient such as imaging systems e.g. fluoroscopy intracardiac echocardiography etc. an electro anatomic visualization mapping and navigation system ablation energy sources e.g. radio frequency RF ablation generator a recording system e.g. for ECG cardiac signals etc. a cardiac stimulator and the like. In a typical configuration as seen by reference to a procedure room i.e. a sterile environment may have an associated control area or room which is commonly outfitted with one or more control stations . . . that are operated by one or more control technicians. Each control station may include a respective display monitor keyboard and mouse for use by the technician. Depending on the lab setup the control station s may be across the room or outside of the procedure room completely perhaps configured with a common window to allow the technician s to observe the procedure room through the window. These control station s allow access to and may be used to control the diagnostic and therapeutic equipment mentioned above.

In conventional practice an electrophysiology EP physician is scrubbed into a sterile procedure and typically manipulates one or more catheters not shown in a sterile drape covered body of the patient . The physician s sterile gloved hands are typically engaged with the catheter handle and shaft next to the patient and he or she is therefore unable to directly make changes himself to any of the EP systems. The procedure room typically includes one or more monitors e.g. an integrated multi display monitor is shown arranged so that the physician can see the monitor on which is displayed various patient information being produced by the diagnostic and therapeutic equipment mentioned above. In multiple applications for example an electro anatomic mapping application e.g. EnSite Velocity and an EP signal acquisition and recording application direct a visual output to a respective display area of monitor . When changes to an application are needed the physician verbalizes such commands to the control technicians in the control area room who are working at the various control stations . . . . The multiple technicians at multiple control stations use multiple keyboard mouse sets to control the multiple applications. The verbal commands between the physician and the technician occur throughout the procedure.

For example the EP physician can verbally communicate i.e. to the control technician a mapping system operator the desired view of the map to be displayed when to collect points when to separate anatomic locations and other details of creating and viewing an anatomic map. The EP physician can also communicate which signal traces to show the desired amplitude when to drop a lesion marker and when to record a segment to name a few. Where the technician is in a separate room communication can be facilitated using radio.

While some commands are straightforward for example LAO View record that and stop pacing other commands are not as easy to clearly communicate. For example how much rotation of a model the command rotate a little to the right means can be different as between the physician and the technician. This type of command therefore involves a question of degree. Also depending on the physician technician relationship other requests related to the mapping system views and setup can be misinterpreted. For example a request to rotate right may mean to rotate the model right i.e. rotate view left when originating from one physician but can alternatively mean rotate view right i.e. rotate model left when coming from another physician. This type of command therefore involves physician technician agreement as to convention. Furthermore implementation of requests for event markers segment recordings lesion markers and the like can be delayed by the time it takes the technician to hear understand and act on a physician s command. Ambient discussions and or equipment noise in and around the EP lab can increase this delay.

Certain catheter procedures can be performed through the use of a remote catheter guidance system RCGS which employs robotically controlled movement of the catheter. The robotic control can receive input command through a user interface that can include a joystick mouse or the like. However there is a need for an improved user interface to control an RCGS.

The foregoing discussion is intended only to illustrate the present field and should not be taken as a disavowal of claim scope.

One advantage of the methods and apparatuses described depicted and claimed herein is that they provide an EP physician or other user with the capability of directly controlling a robotic catheter system. In an embodiment a system for enabling a user to remotely control a robotic catheter system includes a motion capture apparatus and an electronic control unit. The motion capture apparatus is configured to capture motion of a user in a sensing volume and generate output data indicative of the captured user motion. The electronic control unit includes one or more processors and memory. The system further includes gesture recognition logic stored in the memory and configured to execute on the one or more processors. The gesture recognition logic is configured to recognize a user gesture based on the output data generated by the motion capture apparatus. The system further includes interpreter logic stored in the memory and configured to be executed by the one or more processors. The interpreter logic is configured to translate the recognized user gestures to a corresponding robotic catheter control command wherein the command is configured to control an aspect of the operation of the robotic catheter system. The electronic control unit is configured to communicate the command to the robotic catheter system.

In an embodiment the motion capture apparatus is configured to acquire imaging of the movements of the user. For example only the motion capture apparatus provides the capability of receiving input by way of physician gestures e.g. hand arm leg trunk facial etc. .

In an embodiment the user motion data includes fiducial point tracking data and wherein the gesture recognition logic is configured to identify a start pose based on fiducial point tracking data record the motion a predetermined plurality of fiducial points after the start pose until an end pose is identified based on the fiducial point tracking data compare the recorded motion of the predetermined plurality of fiducial points with a plurality of predefined gestures and output the user gesture when the recorded motion matches one of the plurality of gestures.

The foregoing and other aspects features details utilities and advantages of the present disclosure will be apparent from reading the following description and claims and from reviewing the accompanying drawings.

Various embodiments are described herein to various apparatuses systems and or methods. Numerous specific details are set forth to provide a thorough understanding of the overall structure function manufacture and use of the embodiments as described in the specification and illustrated in the accompanying drawings. It will be understood by those skilled in the art however that the embodiments may be practiced without such specific details. In other instances well known operations components and elements have not been described in detail so as not to obscure the embodiments described in the specification. Those of ordinary skill in the art will understand that the embodiments described and illustrated herein are non limiting examples and thus it can be appreciated that the specific structural and functional details disclosed herein may be representative and do not necessarily limit the scope of the embodiments the scope of which is defined solely by the appended claims.

Reference throughout the specification to various embodiments some embodiments one embodiment or an embodiment or the like means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. Thus appearances of the phrases in various embodiments in some embodiments in one embodiment or in an embodiment or the like in places throughout the specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more embodiments. Thus the particular features structures or characteristics illustrated or described in connection with one embodiment may be combined in whole or in part with the features structures or characteristics of one or more other embodiments without limitation given that such combination is not illogical or non functional.

It will be appreciated that the terms proximal and distal may be used throughout the specification with reference to a clinician manipulating one end of an instrument used to treat a patient. The term proximal refers to the portion of the instrument closest to the clinician and the term distal refers to the portion located furthest from the clinician. It will be further appreciated that for conciseness and clarity spatial terms such as vertical horizontal up and down may be used herein with respect to the illustrated embodiments. However surgical instruments may be used in many orientations and positions and these terms are not intended to be limiting and absolute.

Referring now to the drawings wherein like reference numerals are used to identify identical or similar components in the various views is a diagrammatic overview of an electrophysiology EP laboratory in which embodiments of the present invention may be used. shows a sterile procedure room where an EP physician is set to perform one or more diagnostic and or therapeutic procedures. It should be understood that the separate control area room of not shown in may continue to be used in conjunction with the bedside interface device to be described below. also shows multi display monitor as well as a procedure table or bed . While procedure room may include multiple individual monitors monitor may be a multi display monitor configured to display a plurality of different input channels in respective display areas on the monitor. In an embodiment the monitor may be a commercially available product sold under the trade designation VantageView from St. Jude Medical Inc. of St. Paul Minn. USA which can have a 3840 2160 Quad HD screen resolution with the flexibility to accept up to sixteen 16 digital or analog image inputs while displaying up to eight 8 images on one screen at one time. The procedure table which may be of conventional construction is configured to receive a patient not shown on whom diagnostic and or therapeutic procedure s are to be performed.

The base interface is configured to interpret and or facilitate directing the input acquired by the bedside interface device to the appropriate one or more diagnostic and or therapeutic systems e.g. an electro anatomic mapping system . In an embodiment base interface is centralized as shown wherein all communications with bedside device occur through base interface . In a further embodiment base interface may be functionally distributed wherein interface functions are located within each diagnostic or therapeutic system. In a still further embodiment communications between bedside interface and certain ones of the diagnostic therapeutic systems can be centralized while communications with other ones of the diagnostic therapeutic systems can occur directly i.e. separately .

The means or apparatus addresses a number of the shortcomings of the conventional practice as described in the Background. For example means or apparatus allows the EP physician to directly input levels of degree for example how much to rotate a view as opposed to trying to verbally communicate how much to a control technician. Further the use of means or apparatus avoids the potential confusion that can sometimes occur between the EP physician and the control technician as to convention i.e. does rotate right mean rotate the view or the model . In addition the use of means or apparatus reduces or eliminates the inherent time delay between the time when the EP physician verbally issues a command and the time when the command is understood and acted upon by the technician.

With continued reference to the physician will typically have access to a plurality of diagnostic and or therapeutic systems in order to perform one or more medical procedures. In the illustrative embodiment the physician may have access to a first imaging system such as a fluoroscopic imaging system a second imaging system such as an intracardiac ultrasound or echocardiography ICE imaging system an electro anatomic positioning mapping and visualization system a further positioning system such as a medical positioning system magnetic field based a patient data electrophysiological EP data monitoring and recording system a cardiac stimulator an EP data editing monitoring system and an ablation system . schematically shows a communication mechanism which facilitates communication between and among the various systems described above. It should be understood however that the communications mechanism may not necessarily function to enable communications between each and every system shown.

The fluoroscopic imaging system may comprise conventional apparatus known in the art for example single plane or bi plane configurations. A display area that is shown on monitor corresponds to the display output of fluoroscopic imaging system .

The intracardiac ultrasound and or intracardiac echocardiography ICE imaging system may also comprise conventional apparatus known in the art. For example in one embodiment the system may comprise a commercial system available under the trade designation ViewMate Z intracardiac ultrasound system compatible with a ViewFlex PLUS intracardiac echocardiography ICE catheter from St. Jude Medical Inc. of St. Paul Minn. USA. The system is configured to provide real time image guidance and visualization for example of the cardiac anatomy. Such high fidelity images can be used to help direct diagnosis or therapy during complex electrophysiology procedures. A display area that is shown on monitor corresponds to the display output of the ultrasound imaging system .

The system is configured to provide many advanced features such as visualization mapping navigation support and positioning i.e. determine a position and orientation P O of a sensor equipped medical device for example a P O of a distal tip portion of a catheter . Such functionality can be provided as part of a larger visualization mapping and navigation system for example an EnSite Velocity cardiac electro anatomic mapping system running a version of EnSite NavX navigation and visualization technology software commercially available from St. Jude Medical Inc. of St. Paul Minn. and as also seen generally by reference to U.S. Pat. No. 7 263 397 the 397 patent or U.S. Pat. No. 7 885 707 the 707 patent . The 397 patent and the 707 patent are both hereby incorporated by reference as though fully set forth herein. System can be configured to perform further advanced functions such as motion compensation and adjustment functions. Motion compensation may include for example compensation for respiration induced patient body movement as described in U.S. application Ser. No. 12 980 515 filed 29 Dec. 2010 which is hereby incorporated by reference as though fully set forth herein. System can be used in connection with or for various medical procedures for example EP studies or cardiac ablation procedures.

System is further configured to generate and display three dimensional 3D cardiac chamber geometries or models display activation timing and voltage data to identify arrhythmias and to generally facilitate guidance of catheter movement in the body of the patient. For example a display area that is shown on monitor corresponds to the display output of system can be viewed by physician during a procedure which can visually communicate information of interest or need to the physician. The display area in shows a 3D cardiac model which as will be described below in greater detail may be modified i.e. rotated zoomed etc. pursuant to commands given directly by physician via the bedside interface device .

System is configured to provide positioning information with respect to suitably configured medical devices i.e. those including a positioning sensor . System may use at least in part a magnetic field based localization technology comprising conventional apparatus known in the art for example as seen by reference to U.S. Pat. No. 7 386 339 the 339 patent U.S. Pat. No. 6 233 476 the 476 patent and U.S. Pat. No. 7 197 354 the 354 patent . The 339 patent the 476 patent and the 354 patent are all hereby incorporated by reference as though fully set forth herein. System may comprise MediGuide Technology a medical positioning system commercially offered by MediGuide Ltd. of Haifa Israel and now owned by St. Jude Medical Inc. of St. Paul Minn. USA. System may alternatively comprise variants which employ magnetic field generator operation at least in part such as a combination magnetic field and current field based system such as the CARTO 3 System available from Biosense Webster and as generally shown with reference to one or more of U.S. Pat. Nos. 6 498 944 6 788 967 and 6 690 963 the entire disclosures of each of the foregoing being incorporated herein by reference as though fully set forth herein.

EP monitoring and recording system is configured to receive digitize display and store electrocardiograms invasive blood pressure waveforms marker channels and ablation data. System may comprise conventional apparatus known in the art. In one embodiment system may comprise a commercially available product sold under the trade designation EP WorkMate from St. Jude Medical Inc. of St. Paul Minn. USA. The system can be configured to record a large number of intracardiac channels may be further configured with an integrated cardiac stimulator shown in as stimulator as well as offering storage and retrieval capabilities of an extensive database of patient information. Display areas shown on monitor correspond to the display output of EP monitoring and recording system .

Cardiac stimulator is configured to provide electrical stimulation of the heart during EP studies. Stimulator can be provided in either a stand alone configuration or can be integrated with EP monitoring and recording system as shown in . Stimulator is configured to allow the user to initiate or terminate tachy arrhythmias manually or automatically using preprogrammed modes of operation. Stimulator may comprise conventional apparatus known in the art. In an embodiment stimulator can comprise a commercially available cardiac stimulator sold under the trade designation EP 4 available from St. Jude Medical Inc. of St. Paul Minn. USA. The display area shown on monitor corresponds to the display output of the cardiac stimulator .

EP data editing monitoring system is configured to allow editing and monitoring of patient data EP data as well as charting analysis and other functions. System can be configured for connection to EP data recording system for real time patient charting physiological monitoring and data analysis during EP studies procedures. System may comprise conventional apparatus known in the art. In an embodiment system may comprise a commercially available product sold under the trade designation EP NurseMate available from St. Jude Medical Inc. of St. Paul Minn. USA.

To the extent the medical procedure involves tissue ablation e.g. cardiac tissue ablation ablation system can be provided. The ablation system may be configured with various types of ablation energy sources that can be used in or by a catheter such as radio frequency RF ultrasound e.g. acoustic ultrasound or HIFU laser microwave cryogenic chemical photo chemical or other energy used or combinations and or hybrids thereof for performing ablative procedures. RF ablation embodiments may and typically will include other structure s not shown in such as one or more body surface electrodes skin patches for application onto the body of a patient e.g. an RF dispersive indifferent electrode patch an irrigation fluid source gravity feed or pump and an RF ablation generator e.g. such as a commercially available unit sold under the model number IBI 1500T RF Cardiac Ablation Generator available from St. Jude Medical Inc. .

In the illustrated embodiment the UI logic is configured to present a plurality of application specific user interfaces each configured to allow a user e.g. the EP physician to interact with a respective one of a plurality of diagnostic and or therapeutic systems and their unique interface or control applications . As shown in the UI logic is configured to present on the touch panel surface of computer a plurality of touch sensitive objects i.e. buttons flattened joystick etc. to be described below. In the illustrative embodiment the UI logic produces a first application selection group of buttons designated as group and which are located near the top of the touch panel. Each of the buttons in group are associated with a respective diagnostic and or therapeutic system and control or interface application therefore . For example the six buttons labeled EnSite WorkMate EP4 NurseMate MediGuide ViewMate correspond to electro anatomic mapping system for mapping control EP recording system for patient data recording control stimulator for stimulator control EP data editing and monitoring system for charting and ultrasound imaging system for ultrasound control respectively.

When a user selects one of the buttons in group the UI logic configures the screen display of computer with an application specific user interface tailored for the control of and interface with the particular EP system selected by the user. In the EnSite system is selected so the UI logic alters the visual appearance of the EnSite button so that it is visually distinguishable from the other non selected buttons in group . For example when selected the EnSite button may appear depressed or otherwise shaded differently than the other non selected buttons in group . This always lets the user know what system is selected. The UI logic in an embodiment also maintains the application selection buttons in group at the top of the screen regardless of the particular application selected by the user. This arrangement allows the user to move from system application to system application quickly and control each one independently.

With continued reference to UI logic presents an application specific user interface tailored and optimized for control of and interaction with system . This user interface includes a second common task group of selectable buttons designated group a third view mode group of selectable buttons designated group a fourth view select group of selectable buttons designated group a flattened joystick configured to receive view manipulation input from the user a voice recognition control button and a settings button . Each group will be addressed in turn.

The second group of buttons includes a listing of common tasks performed by an EP physician when interacting with system . Each of the buttons in group are associated with a respective task and resulting action . For example the five buttons in group are labeled Zoom In Zoom Out Add Lesion Freeze Point and Save Point . The Zoom In and Zoom Out buttons allow the user to adjust the apparent size of the 3D model displayed on monitor i.e. enlarging or reducing the 3D model on the monitor .

For example is a view of the monitor of showing multiple inset displays for different applications where the display area window shows the EnSite display output of a 3D electro anatomic model at a first magnification level. is a further view of monitor showing a zoomed in view of the same display area window now designated which has an increased magnification level and thus apparent size. This change of course allows the physician to see details in window that may not be easy to see in window .

Referring again to the Add Lesion button is configured to add a lesion marker to the 3D model. Other commands can be also be executed using the Freeze Point and Save Point buttons. It should be understood that variations are possible.

Each of the buttons in group are associated with a respective display mode which alters the display output of system to suit the wishes of the physician. For example the three selectable buttons labeled Dual View Right View and Map View re configure the display output of system as will appear on monitor .

Each of the buttons in group are associated with a respective viewpoint from which the 3D electro anatomic model is viewed i.e. as shown in window on monitor . Three of the five selectable buttons namely those labeled LAO AP and RAO allow the user to reconfigure the view point from which the 3D electro anatomic model is viewed i.e. left anterior oblique anterior posterior right anterior oblique respectively . The remaining two buttons namely those labeled Center at Surface and Center at Electrode allow the user to invoke respectively the following functions 1 center the anatomy shape in the middle of the viewing area and 2 center the current mapping electrode or electrodes in the middle of the viewing area.

The flattened joystick is a screen object that allows the user to rotate the 3D model displayed in the window . In addition as the point of contact i.e. physician s finger with the joystick object moves from the center or neutral position for example at point towards the outer perimeter e.g. through point to point the magnitude of the input action increases. For example the acceleration of rotation of the model or cursor will increase. While shows the joystick object as having three 3 gradations or concentric bands it should be appreciated that this is for clarity only and not limiting in number. For example in an embodiment a relatively larger number of gradations or bands such as ten 10 may be provided so as to effectively provide for a substantially continuous increase in sensitivity or magnitude as the point of contact moves toward the outer radius. In another embodiment a single gradient may be continuous from the center position point to the outer edge of the joystick object with the centermost portion of the gradient being the brightest in intensity or color and the outermost portion of the gradient being the darkest in intensity or color for example. In yet another embodiment a single gradient may be continuous from the center position point to the outer edge of the joystick object with the centermost portion of the gradient being the darkest in intensity or color and the outermost portion of the gradient being brightest in intensity or color for example.

In a further embodiment UI logic can be further configured to present an additional button labeled Follow Me not shown which when selected by the user configures the electro anatomic mapping system for follow me control. This style of control is not currently available using a conventional keyboard and mouse interface. For follow me control UI logic is configured to receive a rotation input from the user via the touch panel e.g. joystick however the received input is interpreted by system as a request to rotate the endocardial surface rendering the map while maintaining the mapping catheter still or stationary on the display. In an embodiment the physician can set the position and orientation of the mapping catheter where it will remain stationary after the Follow Me button is selected.

Another feature of the touch panel computer is that it incorporates in an embodiment voice recognition technology. As described above computer includes microphone for capturing speech audio and voice recognition logic for analyzing the captured speech to extract or identify spoken commands. The voice recognition feature can be used in combination with the touch panel functionality of computer . The microphone may comprise conventional apparatus known in the art and can be a voice recognition optimized microphone particularly adapted for use in speech recognition applications e.g. an echo cancelling microphone . Voice recognition logic may comprise conventional apparatus known in the art. In an embodiment voice recognition logic may be a commercially available component such as software available under the trade designation DRAGON DICTATION speech recognition software.

In an embodiment computer is configured to recognize a defined set of words or phrases adapted to control various functions of the multiple applications that are accessible or controllable by computer . The voice recognition feature can itself be configured to recognize unique words or phrases to selectively enable or disable the voice recognition feature. Alternatively or in addition to a button such as button in can be used to enable or disable the voice recognition feature. In this regard the enable disable button can be either a touch sensitive button i.e. screen object or can be hardware button.

Voice recognition logic is configured to interact with the physician or other user to train the logic e.g. having the user speak known words so as to improve word and or phrase recognition. The particulars for each user so trained can be stored in a respective voice user profile stored in memory . For example in the currently active voice profile is listed in dashed line box . In an embodiment each user can have unique commands which may also be stored in the respective voice profile. In a further embodiment the language need not be English and can be other languages. This flexibility as to language choice enlarges the audience of users who can use the device . The voice recognition feature presents a number of advantages including the fact that the physician does not have to remove his her hands from the catheter or other medical device being manipulated. In addition the absence of contact or need to touch computer maintains a sterile condition. The voice recognition feature can also be used either alone or in combination with other technologies.

With continued reference to UI logic also presents a Settings button . When the Settings button is selected UI logic generates another screen display that allows the user to adjust and or set reset various settings associated with the application currently selected. In an embodiment the Settings button can also allow adjustment of parameters that are more global in nature i.e. apply to more than one application . For example only through Settings the physician or another user can edit all of the phrases associated with a particular physician or specify a timeout i.e. the elapsed amount of time after which the computer will stop listening or not for voice commands . The physician or another user can also edit miscellaneous parameters such as communication settings and the like.

It should be understood that variations in UI logic are possible. For example certain applications can be linked in software so that multiple applications can be controlled with a single command e.g. the Record command . In another embodiment UI logic can be configured to provide additional and or substitute functions such as without limitation 1 map creation 2 collecting points 3 segmenting regions by anatomy 4 map view rotate and zoom 5 select manipulate a number of maps and view each 6 selection of signal trace display 7 adjust EP signal amplitude 8 sweep speed 9 provide single button or touch multi touch gesture for recording a segment placing an event marker and or placing a lesion marker.

It should be further understood that the screen layouts in the illustrative embodiment are exemplary only and not limiting in nature. The UI logic can thus implement alternative screen layouts for interaction by the user. For example while the screen displays in show an approach that incorporates the top level menu items on every screen multi level menus can also be used. For example the screen layouts can be arranged such that a user descends down a series of screens to further levels of control. To return to upper levels and to the home screen a Back button or the like can be provided. Alternatively a Home button can be provided.

In a still further embodiment UI logic can be configured for bi directional display of information for example on the touch responsive display panel. As one example the EnSite user interface can be configured so that the EnSite model is sent to the computer and displayed on the touch responsive display panel. The user interface provided by UI logic can allow the user to drag his or her finger on the panel to rotate the model. The display of the model provides context with respect to the act of dragging. Other information can be displayed as well such as a waveform. In various embodiments all or a portion of the items windows displayed on monitor see e.g. may be displayed or mirrored on the touch responsive display panel. For example display area or window may be displayed on the touch responsive display panel allowing the physician or other user to directly modify the features of window at the patient s bedside. Other display areas windows such as windows and or see may also be displayed and or modified on the touch panel display panel. One further example involves displaying feedback information or messages originating from the various devices or systems back to the touch responsive display panel. In this regard the UI logic can configure any of the user interfaces to have a message area which can show informational messages warning messages or critical error messages for viewing by the user. The message area feature provides a way to immediately alert the physician to such messages rather than the physician having to watch for messages on multiple displays.

Since the wand system is contemplated as being used in the sterile procedure room multiple embodiments are contemplated for avoiding contamination. In this regard wand system may be configured with a disposable remote control portion with a reusable remote control portion that is contained within an enclosure compatible with sterilization procedures with a reusable remote control portion adapted to be secured in a sterilization compatible wrapper or with a reusable remote control portion that is encased in a sterile but disposable wrapper.

With continued reference to remote control portion may include an optical detector an electronic processor a memory an optional accelerometer and a wireless transmitter receiver . The processor is configured to execute a control program that is stored in memory to achieve the functions described below. The optical emitter is configured to emit a light pattern that can be detected and recognized by optical detector . For example the light pattern may be a pair of light sources spaced apart by a predetermined known distance. The control program in remote can be configured to assess movement of the light pattern as detected by detector e.g. by assessing a time based sequence of images captured by detector . For example in the exemplary light pattern described above processor can be configured to determine the locations of the light sources in pixel space . In an embodiment the control program in remote may only discern the light pattern itself e.g. the locations in pixel space and transmit this information to base interface which in turn assesses the movement of the detected light pattern in order to arrive at a description of the motion of the remote . In a still further embodiment various aspects of the processing may be divided between processor and a processor not shown contained in base interface . The processor communicates with base interface via the wireless transmitter receiver which may be any type of wireless communication method now known or hereafter developed e.g. such as those technologies or standards branded Bluetooth Wi Fi etc. . The processor is configured to transmit wirelessly to interface the detected keypresses and information concerning the motion of the remote control e.g. the information about or derived from the images from the optical detector . In an embodiment the motion of remote control may also be determined or supplemented by readings from accelerometer which may be single axis or multi axis such as a 3 axis accelerometer . In some instances rapid motion may be better detected using an accelerometer than using optical methods. In an embodiment electronic wand system may be similar to but differing in application as described herein a commercially available game controller sold under the trade designation Wii Remote Controller from Nintendo of America Inc.

Either the remote or the base interface or both potentially in some division of computing labor is configured to identify a command applicable to the one of the EP diagnostic therapeutic systems such as electro anatomic mapping system based on the detected motion of the remote . Alternatively the command may be identified based on a key press or a predetermined motion key press combination. Once the remote and or interface identifies the command it is transmitted to the appropriate EP system. In an electro anatomic mapping system embodiment the wireless remote control is configured to allow an EP physician to issues a wide variety of commands for example only any of the commands e.g. 3D model rotation manipulation etc. described above in connection with touch panel computer . By encoding at least some of the control through the wireless remote control that the EP physician controls one or more of the shortcomings of conventional EP labs as described in the Background can be minimized or eliminated. As with touch panel computer electronic wand system can reduce procedure times as the EP physician will spend less time playing hot or cold with the mapping system operator i.e. the control technician but instead can set the display to his her needs throughout the medical procedure.

The motion capture apparatus includes the capability to detect hand arm leg trunk facial motions e.g. gestures of the EP physician or other user and translate the detected patterns into a desired command. Apparatus also includes audio capture and processing capability and thus also has the capability to detect speech and translate the same into desired commands. In an embodiment apparatus is configured to detect and interpret combinations and sequences of gestures and speech into desired commands. The base interface is configured to communicate the commands e.g. rotation zoom pan of a 3D anatomical model to the appropriate EP diagnostic or therapeutic system e.g. the electro anatomic mapping system . In an embodiment the motion capture apparatus may comprise commercially available components for example the Kinect game control system available from Microsoft Redmond Wash. USA. A so called Kinect software development kit SDK is available which includes drivers rich application programming interfaces API s among other things contents that enables access to the capabilities of the Kinect device. In particular the SDK allows access to raw sensor streams e.g. depth sensor color camera sensor and four element microphone array skeletal tracking advanced audio i.e. integration with Windows speech recognition as well as other features.

Since there is no contact contemplated by EP physician during use of motion capture apparatus contamination and subsequent sterilization issues are eliminated or reduced. In addition the lack of contact with apparatus for control purposes allows the EP physician to keep his hands on the catheter or other medical device s being manipulated during an EP procedure. By encoding at least some of the control through the motion capture apparatus with which the EP physician interacts one or more of the shortcomings of conventional EP labs as described in the Background can be minimized or eliminated. As with the previous embodiments the motion capture apparatus can reduce procedure times.

It should be understood that variations are possible. For example the motion capture apparatus can be used in concert with sensors and or emitters in a sterile glove to assist the apparatus to discriminate commands intended to be directed to one of the EP systems versus EP physician hand movements that result from his her manipulation of the catheter or medical device versus other movement in the EP lab in general. In another embodiment the motion capture apparatus may discriminate such commands by being activated by a user when a specific verbal command is issued e.g. motion capture on and then deactivated by the user when another specific verbal command is issued e.g. motion capture off .

It should be understood that variations are possible. For example in a further embodiment primary control by the physician in manipulating or interacting with the mapping system may be through use of voice control alone i.e. a microphone coupled with voice recognition logic apart from its inclusion with other modes or devices for user interaction described above. In a still further embodiment the physician can be equipped with headgear that monitors head movements to determine at what location on the screen monitor the physician is looking. In effect such headgear can act as a trackball to move or otherwise manipulate an image or view of a model on the monitor in accordance with the physician s head movements. In a yet further embodiment the physician can be equipped with headgear that monitors head movements and or also monitors brainwave patterns e.g. to record a user electroencephalogram EEG . Such monitored data can be analyzed to derive or infer user input or commands for controlling an image or view of a model as described above. An EEG based embodiment may comprise conventional apparatus known in the art for example commercially available products respectively sold under the trade designation MindWave headset from NeuroSky Inc. San Jose Calif. USA or the Emotiv EPOC personal interface neuroheadset from Emotiv Kwun Tong Hong Kong. In a still further embodiment the physician can be equipped with an eye tracking apparatus wherein monitored eye movements constitute the user input to be interpreted by the system e.g. the eye movements can be interpreted as a cursor movement or other command .

It should also be appreciated that while the foregoing description pertains to an EP physician manually controlling a catheter through the use of a manually actuated handle or the like other configurations are possible such as robotically actuated embodiments. For example a catheter movement controller not shown described above may be incorporated into a larger robotic catheter guidance and control system for example as seen by reference to U.S. application Ser. No. 12 751 843 filed 31 Mar. 2010 which is hereby incorporated by reference as though fully set forth herein. Such a robotic catheter system may be configured to manipulate and maneuver catheters within a lumen or a cavity of a human body while the bedside interface devices described herein can be used to access and control the EP diagnostic and or therapeutic systems. In at least one embodiment a bedside interface device as described herein may also be used to access and control the robotic catheter system.

With continued reference to base interface includes an electronic control unit having one or more electronic processors and memory . Base interface further includes gesture recognition logic and interpreter logic . Both gesture recognition logic and interpreter logic in an embodiment comprise programmed logic e.g. software that is stored in memory and is configured to be executed by the one or more processors .

Gesture recognition logic is configured to recognize one or more three dimensional 3D user gestures based on an analysis of the output data generated by motion capture apparatus . In an embodiment motion capture apparatus comprises commercially available components for example the Kinect game control system available from Microsoft Redmond Wash. USA. Gesture recognition logic can in an embodiment comprise implementations developed using a Kinect software development kit SDK which includes drivers rich application programming interfaces API s among other things that enables access to the capabilities of the Kinect device. The SDK allows access to raw sensor streams e.g. depth sensor color camera sensor and four element microphone array skeletal tracking advanced audio i.e. integration with Windows speech recognition as well as other features.

Interpreter logic is configured to translate the one or more 3D gestures recognized by gesture recognition logic to one or more corresponding robotic catheter control commands. Such robotic catheter control commands may be configured to control one or more aspects of the operation of a robotic catheter system such as the robotic catheter system described in connection with . For example only such commands can include deflection rotation and or translation of one or more robotically controlled catheters and or sheaths. Interpreter logic in an embodiment may comprise application level code configured to use for example various features available in the Kinect SDK mentioned above.

The user motion data is indicative of the captured user motion. The user motion data may include imaging data as well as other information concerning the 3D posture of various objects in the sensing volume. In this regard it should be appreciated that as updates occur over time the resulting time based series can be used to determine the motion patterns of the objects being tracked. Base interface may be coupled to a robotic catheter system such as robotic control system as shown over a communication mechanism as also described above.

In an embodiment gesture recognition logic is configured to track an object for example a specific body part such as a user s hand. Motion capture apparatus can define the tracked object by one or more fiducial points. For example in an embodiment motion capture apparatus in combination with software functionality as implemented in base interface e.g. via the SDK can recognize and track the time based motion of a person s body or skeleton including the time based tracking of one or more of a plurality of constituent joints . . . where n is an integer. The above mentioned fiducial points may be taken to correspond to the joints . . . . Gesture recognition logic can track the time based positions of these fiducial points. The tracked positions in turn can form the basis of various metrics such as position distance and rotation all to be described below.

In light of the above the output data generated by motion capture apparatus includes fiducial point tracking data associated with a plurality of fiducial points defined with respect to the user. The fiducial point tracking data includes for each fiducial point a respective position. Each position may include a respective three dimensional coordinate in a reference coordinate system for example defined within sensing volume that is monitored by motion capture apparatus . In addition and or in the alternative the output motion data generated by motion capture apparatus may comprise imaging data.

As shown in for example a skeleton shows the respective positions of two fiducial points at and corresponding to the separated hands of the user. Gesture recognition logic is configured to determine the position of the user s hands and also a distance between the user s hands. The position and distance between the user s hands can be translated by interpreter logic to a robotic catheter control command. For example the position and distance between the user s hands can be used to control the degree of extension or retraction of a catheter and or a sheath along a respective translation axis. Thus more generally a robotic catheter control command may have a characteristic that corresponds to the magnitude of the action that is to be initiated by the command. In the example of the magnitude of the action may be defined by the distance between preselected fiducial points. The action may be a catheter extension a catheter retraction a sheath extension and a sheath refraction.

As shown in as a further example a skeleton shows a sequence of time based positions traversed by a single fiducial point joint during the rotation of a user s wrist. The time based positions of the tracked fiducial point joint at times t t t tand tare designated and respectively. Through tracking gesture recognition logic can determine the extent of the rotation as indicated by rotation angle . In an embodiment gesture recognition logic recognizes the rotational motion while interpreter logic translates this gesture into an output command for example only to actuate rotation of a catheter and or a sheath. Interpreter logic can be configured to generate the output rotation command further as a function of the determined rotation angle i.e. the extent of actual catheter and or sheath rotation can be made to correspond to the determined rotation angle . The fiducial point tracking data output from motion capture apparatus therefore includes for each fiducial point a respective time based plurality of positions. Thus more generally a robotic catheter control command may have a characteristic that corresponds to the rotation associated with the action to be initiated by the command. In the example of the rotation may be defined by the rotation angle through which the preselected fiducial point rotates. The action may be a catheter or sheath rotation.

In an embodiment in the case of a gesture involving wrist rotation gesture recognition logic can be additionally configured to identify and track a wand e.g. part or all of electronic wand system described above a baton or a like implement being held in the hand of the user. The use of such implements can improve the ability of the motion capture apparatus to track the user s wrist motion rotation . For example a wand being generally larger and more distinct than a wrist fiducial point joint can be expected to provide a correspondingly larger object in the imaging data and or other data provided by the motion capture apparatus . This effectively provides greater resolution and robustness in the tracking functionality of motion capture apparatus gesture recognition logic .

Gesture recognition logic may be configured to operate as described below to recognize a 3D gesture. First gesture recognition logic is configured to identify a start pose based on the fiducial point tracking data. In an embodiment the start pose may correspond to a start condition where a first set of fiducial points assumes a first relationship therebetween. For example this condition may be satisfied when the fiducial points form a first predetermined constellation . Second gesture recognition logic is configured to record the motion of a predetermined plurality of fiducial points after recognition of the start pose and continue recording until an end pose is identified which identification is also based on the fiducial tracking data. In an embodiment the end pose may correspond to an end condition where a second set of fiducial points assume a second relationship therebetween. For example this condition may be satisfied when the fiducial points form a second predetermined constellation .

Third gesture recognition logic is configured to compare the recorded motion of the predetermined plurality of fiducial points being tracked with a plurality of predefined gestures. Each predefined gesture is itself defined by a respective motion of a respective set of fiducial points. Finally gesture recognition logic is configured to output one of the plurality of predefined gestures as the recognized gesture when the recorded motion matches one of the predefined gestures i.e. the recognized gesture being the one that matches the recorded motion .

System may also include various safety features. As described above motion capture apparatus is generally responsive to activity occurring within sensing volume . In an embodiment motion capture apparatus gesture recognition logic can be configured to be responsive only to activity in a smaller 3D volume included within sensing volume hereinafter an action box . The purpose of the action box is that once it is defined system will only respond to actions that occur within the action box. For example a user can only actuate the robotic catheter system by placing his hands in the action box or otherwise causing some activity to occur in the action box. This arrangement can be expected to reduce the occurrence of unintended actuation thereby improving safety. The action box of sensing volume can be positioned above a patient table see which shows a patient table and patient in a control room for example control area room in or in various other locations.

In an embodiment system can be configured to allow the user to adjust either or both of the size and location of the action box relative to motion capture apparatus . It should be understood that motion capture apparatus will only respond to activities occurring within the action box and ignore all other activity outside the action box. Staff can be trained to never place their hands or any other object into the action box as it is strictly for use by a trained physician because of the potential to actuate functionality of a medical device. In this regard the action box can be delineated by a visible construct such as a frame. The frame can be made of solid material in which case is also presents a physical construct or the outlines of the frame can be illuminated for example via low intensity laser beams.

For additional safety protection system can be configured to include a user actuatable switch such as a dead man switch . Switch may include a normally open state and a user actuatable closed state. System can be configured to be active only when the dead man switch has been closed by the user. System may only respond to user actions gestures when the switch has been actuated. In a further embodiment system may be configured to at least disable communication of a robotic control command to the robotic catheter system unless switch is in the closed state. The dead man switch may comprise a switch on a wand a foot pedal or the like.

Although an embodiment has been described in connection with and other motion capture mechanisms can be used. For example alternatives include an optical based position tracking product e.g. object or fiducial tracking system known by the trade designation as the POLARIS system and a magnetic field based product known by the trade designation as the AURORA system both from Northern Digital Inc.

In the illustrated embodiment of a magnetic positioning system can operate for example by emitting several magnetic fields from an array of field generators . Sensor coils e.g. sensors or located on the glove or stylus can then sense the magnetic field strength emanating from each sensor coil. By selectively energizing each field generator at a different time or frequency a processor can be able to resolve the sensor s position and orientation relative to each field generator or to a fixed reference sensor. Detected changes in the position and orientation of the glove or stylus sensor can then be registered and user motion data can be determined and passed on to gesture recognition logic .

In a still further embodiment a haptic glove not shown with sensors can be provided in order to capture user motion to thereby allow recognition of user gestures as seen by reference to U.S. application Ser. No. 12 507 175 filed 22 Jul. 2009 published as United States patent application publication no. US 2010 0073150 A1 and hereby incorporated by reference as though fully set forth herein. A haptic glove can output data that allows detection of the relative bending of the fingers and joints within the hand. Various motions of the hand can be indicators of desired motion to be input into the robotic catheter system. A haptic glove or similar devices have the potential to detect motion relative to itself but not absolute motion relative to the physical real world. In an embodiment and referring again to a hybrid motion capture system is provided wherein a haptic glove is configured to simultaneously provide relative motion such as finger bending as described above combined with an absolute location device such as motion capture apparatus to form composite motions or gestures using input from both systems . Such composite motions can be provided to gesture recognition logic and interpreter logic to output corresponding robotic catheter control commands for effecting precise motions of the catheter and or sheath of the robotic catheter system.

As described above user provided gestures can also be captured and used to control other electrophysiological systems such an electro anatomic mapping and visualization system e.g. an EnSite Velocity system . In the scenario where user gesture capture is contemplated for controlling multiple different systems such as the robotic catheter system and the Ensite Velocity system system can be configured with context switching functionality. In other words system is configured to determine when a gesture is intended to control one target system such as the robotic catheter system versus another target system such as an electro anatomic mapping and visualization system.

To facilitate making such determinations system is configured to analyze the actions occurring within a context switching box shown in . As illustrated context switching box may be located near the corner of sensing volume . In an embodiment system is configured to detect when the user is tapping in context switching box . Thus when the user taps a point in context switching box system switches context i.e. from the robotic catheter system as the target to the mapping system as the target and thereafter allows user input to control an electro anatomic mapping system target such as the Ensite Velocity system. The act of tapping may involve the user holding his or her hand in a particular location and then ballistically moving the fingers back and forth. This tapping motion when detected by gesture recognition logic causes an electro anatomic system such as system to display a context menu visible to the user. For example such a context menu may have a series of selectable options in a drop down style box.

In operation the user by moving the hand up and or down over the selectable options causes the option over which the hand hovers to become highlighted. Gesture recognition logic can be further configured to recognize a second tapping motion which finalizes the selection and closes the context menu. While the gesture itself can be captured using system other detection mechanisms such as through the use of various sensors as described above e.g. haptic glove accelerometer disposed within a glove a wand etc. can be alternatively used.

Thus in light of the above system may include context switching logic not shown stored in memory and configured for execution in the one or more processors . The context switching logic may be configured to detect a predetermined context switching gesture e.g. the tapping gesture described above based on the output data from motion capture apparatus but only where the context switching gesture occurs in the context switching portion of sensing volume . When the context switching logic detects the context switching gesture it may set a context switch parameter or the like. Interpreter logic is accordingly configured to selectively translate based on the state of the context switch parameter the recognized user gesture into one of either i a robotic catheter control command or ii an electro anatomic mapping system control command.

In another embodiment further visual feedback can be displayed on the display of the electro anatomic system such as on the display area in showing the relative motion of the user s hands and fingers. This feedback can be through the use of a i special purpose mouse pointer in addition to and visibly distinguishable from a primary mouse pointer ii a graphical representation of the hands or the like.

Referring to in another embodiment system can be used in combination with an electro anatomic system and further in combination with a three dimensional 3D display such as that described in U.S. application No. 61 643 667 filed 7 May 2012 and hereby incorporated by reference as though fully set forth herein. This combination of functions allows for a virtual representation of the hands that could be rendered and displayed within a three dimensional 3D window along with representations of the catheters and or sheaths all with respect to a heart model. This 3D window may allow the user to perceive his or her own hands reaching into the heart of the patient. Through this facility the user could grab the catheter and move it to a new location for example to a target location. For example the virtual hands can be moved near the tip of one of the catheters and by pinching on the tip of the catheter the user can grab and pull the catheter in different directions. The target location can be specified as the location to which the rendered catheter is pulled by the user. Once the target location has been specified this information can be passed on to the robotic control system by interpreter logic wherein robotic control system processes this target location as a dynamic waypoint and thereafter automatically move the catheter to such target location. The foregoing combination including a 3D display provides an intuitive way for a user to manipulate a medical device within the heart.

In another embodiment interpreter logic can be configured to generate different commands based on the same user gesture. Interpreter logic is configured to analyze the recognized use gesture in light of and as a function of the orientation of the then visible current view of an anatomical model being displayed by an electro anatomic system such as system . In other words the effect of the user gesture can be view relative such that the same gesture can actuate different relative motions based on the current view angle or orientation displayed by the electro anatomic system . For example the direction of translation can be different based on the current view as shown in the examples in Table 1.

Referring to RCGS can be likened to power steering for a catheter system. The RCGS can be used for example to manipulate the location and orientation of catheters and sheaths in a heart chamber or in another body cavity or lumen. The RCGS thus provides the user with a similar type of control provided by a conventional manually operated system but allows for repeatable precise and dynamic movements. For example a user such as an electrophysiologist can identify locations potentially forming a path on a rendered computer model of the cardiac anatomy. The system can be configured to relate those digitally selected points to positions within a patient s actual physical anatomy and can thereafter command and control the movement of the catheter to the defined positions. Once at the specified target location either the user or the system can perform the desired diagnostic or therapeutic function. The RCGS enables full robotic navigation guidance and control.

As shown in the RCGS can generally include one or more monitors or displays a visualization mapping and navigation including localization system a human input device and control system referred to as input control system an electronic control system a manipulator assembly for operating a device cartridge and a manipulator support structure for positioning the manipulator assembly in proximity to a patient or a patient s bed.

Displays are configured to visually present to a user information regarding patient anatomy medical device location or the like originating from a variety of different sources. Displays can include 1 an EnSite Velocity monitor coupled to system described more fully below for displaying cardiac chamber geometries or models displaying activation timing and voltage data to identify arrhythmias and for facilitating guidance of catheter movement 2 a fluoroscopy monitor for displaying a real time x ray image or for assisting a physician with catheter movement 3 an intra cardiac echo ICE display to provide further imaging and 4 an EP recording system display .

The system is configured to provide many advanced features such as visualization mapping navigation support and positioning i.e. determine a position and orientation P O of a sensor equipped medical device for example a P O of a distal tip portion of a catheter . Such functionality can be provided as part of a larger visualization mapping and navigation system for example an EnSite Velocity system running a version of EnSite NavX software commercially available from St. Jude Medical Inc. of St. Paul Minn. and as described above. System can thus comprise conventional apparatus for example the EnSite Velocity system or other known technologies for locating navigating a catheter in space and for visualization including for example the CARTO visualization and location system of Biosense Webster Inc. the AURORA system of Northern Digital Inc. a magnetic field based localization system such as the MediGuide Technology a system based on technology from MediGuide Ltd. of Haifa Israel and now owned by St. Jude Medical Inc. or a hybrid magnetic field impedance based system such as the CARTO 3 visualization and location system of Biosense Webster Inc. Some of the localization navigation and or visualization systems can involve providing a sensor for producing signals indicative of catheter location and or orientation information and can include for example one or more electrodes in the case of an impedance based localization system such as the EnSite Velocity system running EnSite NavX software which electrodes can already exist in some instances or alternatively one or more coils i.e. wire windings configured to detect one or more characteristics of a low strength magnetic field for example in the case of a magnetic field based localization system such as the MediGuide Technology a system using technology from MediGuide Ltd. described above.

The input control system is configured to allow a user such as an electrophysiologist to interact with the RCGS in order to control the movement and advancement withdrawal of both a catheter and sheath see e.g. U.S. application Ser. No. 12 751 843 filed 31 Mar. 2010 the 843 application and PCT US2009 038597 filed 27 Mar. 2009 the 597 application and published 1 Oct. 2009 under publication no. WO 2009 120982. The 843 application and the 597 application are both hereby incorporated by reference as though fully set forth herein. Generally several types of input devices and related controls can be employed including without limitation instrumented traditional catheter handle controls oversized catheter models instrumented user wearable gloves touch screen display monitors 2 D input devices 3 D input devices spatially detected styluses and traditional joysticks. For a further description of exemplary input apparatus and related controls see for example U.S. application Ser. No. 12 933 063 filed 16 Sep. 2010 the 063 application and U.S. application Ser. No. 12 347 442 filed 31 Dec. 2008 the 442 application . The 063 application and the 442 application are both hereby incorporated by reference as though fully set forth herein. The input devices can be configured to directly control the movement of the catheter and sheath or can be configured for example to manipulate a target or cursor on an associated display.

The electronic control system is configured to translate i.e. interpret inputs e.g. motions of the user at an input device or from another source into a resulting movement of the catheter and or surrounding sheath. In this regard the system includes a programmed electronic control unit ECU in communication with a memory or other computer readable media memory suitable for information storage. Relevant to the present disclosure the electronic control system is configured among other things to issue commands i.e. actuation control signals to the manipulator assembly i.e. to the actuation units electric motors to move or bend the catheter and or sheath to prescribed positions and or in prescribed ways all in accordance with the received user input and a predetermined operating strategy programmed into the system . In addition to the instant description further details of a programmed electronic control system can be found in U.S. application Ser. No. 12 751 843 described above. It should be understood that although the exemplary EnSite Velocity system and the electronic control system are shown separately integration of one or more computing functions can result in a system including an ECU on which can be run both i various control and diagnostic logic pertaining to the RCGS and ii the visualization mapping and navigation functionality of system .

The manipulator assembly in response to such commands is configured to maneuver the medical device e.g. translation movement such as advancement and withdrawal of the catheter and or sheath as well as to effectuate distal end tip deflection and or rotation or virtual rotation. In an embodiment the manipulator assembly can include actuation mechanisms units e.g. a plurality of electric motor and lead screw combinations or other electric motor configurations as detailed below for linearly actuating one or more control members e.g. steering wires associated with the medical device for achieving the above described translation deflection and or rotation or virtual rotation . In addition to the description set forth herein further details of a manipulator assembly can be found in U.S. application Ser. No. 12 347 826 filed 31 Dec. 2008 which is hereby incorporated by reference as though fully set forth herein. Although the manipulator is illustrated and described with respect to the manipulation of a single medical device e.g. a single catheter and sheath combination the manipulator can be configured to manipulate multiple devices such as a cardiac mapping catheter an ablation catheter an imaging catheter such an intracardiac echocardiography ICE catheter or the like as seen by reference to international application no. PCT US12 30697 with an international filing date of 27 Mar. 2012 the 697 application which claims priority to U.S. provisional application No. 61 581 838 filed 30 Dec. 2011 the 838 application . The 697 application and the 838 application are both hereby incorporated by reference as though fully set forth herein.

A device cartridge is provided for each medical device controlled by the RCGS . For this exemplary description of an RCGS one cartridge is associated with a catheter and a second cartridge is associated with an outer sheath. The cartridge is then coupled generally speaking to the RCGS for subsequent robotically controlled movement. In addition to the description set forth herein further details of a device cartridge can be found in U.S. application Ser. No. 12 347 835 filed 31 Dec. 2008 the 835 application and U.S. application Ser. No. 12 347 842 filed 31 Dec. 2008 the 842 application . The 835 application and the 842 application are both hereby incorporated by reference as though fully set forth herein.

In the Figures to follow will show a manipulator assembly will show a manipulation base and will show a device cartridge.

Catheter and sheath manipulator mechanisms are configured to manipulate the several different movements of the catheter and the sheath . First each mechanism is configured to impart translation movement to the catheter and the sheath . Translation movement here refers to the independent advancement and retraction withdrawal as shown generally in the directions designated D and D in . Second each mechanism is also configured to effect deflection of the distal end of either or both of the catheter and sheath . Third each mechanism can be operative to effect a so called virtual omni directional rotation of the distal end portion of the catheter and the sheath . Virtual rotation can be made through the use of independent four wire steering control for each device e.g. eight total steering wires comprising four sheath control wires and four catheter control wires . The distal end movement is referred to as virtual rotation because the outer surface of the sheath or catheter does not in fact rotate in the conventional sense i.e. about a longitudinal axis but rather achieves the same movements as conventional uni planar deflection coupled with axial rotation. In addition to the present description of virtual rotation further details can be found in international application no. PCT US2009 038597 published 1 Oct. 2009 as WO 2009 120982 which is hereby incorporated by reference as though fully set forth herein.

Each manipulator mechanism further includes a respective manipulation base onto which are received catheter and sheath cartridges . Each interlocking base can be capable of travel in the longitudinal direction of the catheter sheath i.e. D D respectively along a track . In an embodiment D and D can each represent a translation of approximately 8 linear inches. Each interlocking base can be translated by a respective high precision drive mechanism . Such drive mechanisms can include for example and without limitation an electric motor driven lead screw or ball screw.

The manipulator mechanisms are aligned with each other such that catheter can pass through sheath in a coaxial arrangement. Thus sheath can include a water tight proximal sheath opening . Overall the manipulator mechanisms are configured to allow not only coordinated movement but also relative movement between catheter and sheath cartridges and thus relative movement between catheter and sheath .

Referring to catheter and sheath cartridges are configured to be secured or locked down onto respective manipulation bases . To couple cartridge and with base and one or more locking pins e.g. in on the cartridge can engage one or more mating recesses in the base see . In an embodiment such recesses can include an interference lock such as a spring detent or other locking means. In an embodiment such other locking means can include a physical interference that can require affirmative positive action by the user to release the cartridge. Such action can include or require actuation of a release lever . Additionally the cartridge can include one or more locator pins not shown configured to passively fit into mating holes on the base e.g. in .

In operation a user first manually positions catheter and sheath with catheter inserted in sheath within the vasculature of a patient. Once the medical devices are roughly positioned in relation to the heart or other anatomical site of interest the user can then engage or connect e.g. snap in the catheter and sheath cartridges into place on respective bases . When a cartridge is interconnected with a base the fingers fit into the recesses formed in the slider blocks. For example with respect to the sheath cartridge and sheath base each of the plurality of fingers or fit into corresponding recesses formed between the distal edge of slider blocks and a lower portion of the cartridge housing best shown in . Each finger can be designed to be actuated in a proximal direction to respectively move each slider block thereby placing the respective steering wire in tension i.e. a pull wire . Translation distal end bending and virtual rotation can be accomplished through the use of the RCGS .

The actuation unit also includes a rotary motor position encoder that is coupled to the motor and is configured to output a signal indicative of the position of the motor . The encoder can comprise an internal optical encoder assembly integral with motor configured to produce a relatively high accuracy output. The motor position sensor can operate in either absolute or relative coordinates. In an embodiment a second motor position sensor not shown can also be provided such as a potentiometer or impedance based configured to provide a varying voltage output proportional to the motor s rotary position. The output of the secondary position sensor can be used as an integrity check of the operating performance of the primary position sensor encoder during start up or initialization of the actuation unit.

Actuation unit also includes one or more local controllers including a bus interface to facilitate exchange of information between actuation unit and electronic control system via the bus . The controller communicates with the main electronic control system via the bus interface and is configured among other things to 1 receive and execute motor actuation commands issued by the electronic control system for controlling the movements of motor and 2 receive and execute a command issued by the electronic control system to take a motor position sensor reading for example from encoder and subsequently report the reading to system .

In accordance with another embodiment an article of manufacture includes a computer storage medium having a computer program encoded thereon where the computer program includes code for acquiring or capturing motion of a user and generating corresponding output data for recognizing a user gesture based on the user motion output data and for translating the recognized user gesture into one or more commands for an EP diagnostic and or therapeutic system including at least a robotic catheter control command or an electro anatomic system command. Such embodiments may be configured to execute one or more processors multiple processors that are integrated into a single system or are distributed over and connected together through a communications network and where the network may be wired or wireless.

It should be understood that while the foregoing description describes various embodiments of a bedside interface device in the context of the practice of electrophysiology and specifically catheterization the teachings are not so limited and can be applied to other clinical settings.

It should be understood that the an electronic control unit as described above may include conventional processing apparatus known in the art capable of executing pre programmed instructions stored in an associated memory all performing in accordance with the functionality described herein. It is contemplated that the methods described herein may be programmed with the resulting software being stored in an associated memory and where so described may also constitute the means for performing such methods. Implementation of an embodiment of the invention in software in view of the foregoing enabling description would require no more than routine application of programming skills by one of ordinary skill in the art. Such a system may further be of the type having both ROM RAM a combination of non volatile and volatile modifiable memory so that the software can be stored and yet allow storage and processing of dynamically produced data and or signals.

Although numerous embodiments of this invention have been described above with a certain degree of particularity those skilled in the art could make numerous alterations to the disclosed embodiments without departing from the spirit or scope of this invention. All directional references e.g. plus minus upper lower upward downward left right leftward rightward top bottom above below vertical horizontal clockwise and counterclockwise are only used for identification purposes to aid the reader s understanding of the present invention and do not create limitations particularly as to the position orientation or use of the invention. Joinder references e.g. attached coupled connected and the like are to be construed broadly and may include intermediate members between a connection of elements and relative movement between elements. As such joinder references do not necessarily infer that two elements are directly connected and in fixed relation to each other. It is intended that all matter contained in the above description or shown in the accompanying drawings shall be interpreted as illustrative only and not limiting. Changes in detail or structure may be made without departing from the spirit of the invention as defined in the appended claims.

Any patent publication or other disclosure material in whole or in part that is said to be incorporated by reference herein is incorporated herein only to the extent that the incorporated materials does not conflict with existing definitions statements or other disclosure material set forth in this disclosure. As such and to the extent necessary the disclosure as explicitly set forth herein supersedes any conflicting material incorporated herein by reference. Any material or portion thereof that is said to be incorporated by reference herein but which conflicts with existing definitions statements or other disclosure material set forth herein will only be incorporated to the extent that no conflict arises between that incorporated material and the existing disclosure material.

