---

title: System and method for building a point-in-time snapshot of an eventually-consistent data store
abstract: A method and system for building a point-in-time snapshot of an eventually-consistent data store. The data store includes key-value pairs stored on a plurality of storage nodes. In one embodiment, the data store is implemented as an Apache® Cassandra database running in the “cloud.” The data store includes a journaling mechanism that stores journals (i.e., inconsistent snapshots) of the data store on each node at various intervals. In Cassandra, these snapshots are sorted string tables that may be copied to a back-up storage location. A cluster of processing nodes may retrieve and resolve the inconsistent snapshots to generate a point-in-time snapshot of the data store corresponding to a lagging consistency point. In addition, the point-in-time snapshot may be updated as any new inconsistent snapshots are generated by the data store such that the lagging consistency point associated with the updated point-in-time snapshot is more recent.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09613104&OS=09613104&RS=09613104
owner: NETFLIX, Inc.
number: 09613104
owner_city: Los Gatos
owner_country: US
publication_date: 20120217
---
Embodiments of the invention generally relate to eventually consistent data stores. More specifically embodiments of the invention relate to systems and methods for building a point in time snapshot of an eventually consistent data store.

Companies involved in e commerce typically maintain one or more datacenters to provide the resources to handle customer s needs on the Internet. A datacenter may consist of hundreds or thousands of server computers in a single building along with high speed communication lines to connect those servers to the Internet. The servers may also be connected to large data stores that consist of thousands of disk drives or other non volatile storage.

Lately a cloud computing model has enabled companies to purchase computing resources on an as needed basis from providers such as Amazon . Cloud computing is the delivery of computing resources as a service over a network such as the Internet. Instead of the company maintaining the datacenter at a facility owned by the company the company can lease use of a virtual data center provided by a third party provider. The provider maintains the hardware at various locations throughout the world which the company can lease and scale to match the companies needs at any given time.

One aspect of cloud services is cloud storage where the provider leases virtual storage space to various companies or individuals. For example Amazon Web Services AWS include Amazon Simple Storage Service S3 that enables a user to store objects e.g. videos documents etc. at datacenters around the world using a web interface. The user can choose in which geographic region an object is stored and choose an amount of redundancy i.e. by storing the object at multiple different datacenters that ensures object availability even if one datacenter goes offline.

An eventually consistent data store is a data store that sacrifices consistency for availability and partition tolerance. In other words a system may store data redundantly in multiple locations in order to ensure that the data is available despite communication failure between nodes partition tolerance however the system cannot then also ensure that the data is consistent across the multiple nodes. Eventually consistent data stores ensure that requests for data are serviced quickly while not ensuring that the data is consistent across every node where that data may be stored.

In order to retrieve a consistent snapshot of data from the distributed data store an administrator must either force a consistent read across all nodes essentially preventing any requests from being processed by the system during this time or read separately from the various nodes and reconcile the data at a later time. The former poses a large load on the data store and in some cases may be impossible to perform given the distributed nature of the data store. The latter requires additional services to be implemented in the data store to generate a snapshot of the state of each individual node and the ability to reconcile the data from every node at a later point in time.

Improved techniques are needed to provide data analysts with a snapshot of the eventually consistent data store at a particular point in time that does not interfere with normal operation of the data store.

One embodiment of the present invention includes a method for building a point in time snapshot of an eventually consistent data store distributed among a plurality of nodes connected by a network. The method includes the steps of receiving a plurality of inconsistent snapshots wherein each inconsistent snapshot includes one or more rows of key value pairs associated with the data store and reflects the contents of at least a portion of the data store stored on a particular node of the plurality of nodes and generating the point in time snapshot by resolving the rows of key value pairs to remove any inconsistent values wherein the point in time snapshot includes a subset of the key value pairs included in the plurality of inconsistent snapshots.

Other embodiments include without limitation a computer readable medium that includes instructions that enable a processing unit to implement one or more aspects of the disclosed methods as well as a system configured to implement one or more aspects of the disclosed methods.

One advantage of such techniques is that a consistent snapshot of the data store may be generated using back up copies of a set of inconsistent snapshots automatically generated by each node of the data store. Each back up copy may be resolved to produce a consistent snapshot of a single node which in the aggregate may be resolved to produce a consistent snapshot of the entire data store. Resolving the back up copies of the inconsistent snapshots may be performed on a related system to generate a point in time snapshot without overloading the data store during normal operation. Thus users of the data store are free to access the data store uninterrupted while data analysts may perform analysis of various metrics using a consistent view of the data store at a point in time in the recent past such as generated once a day .

Embodiments of the invention provide techniques for building a point in time snapshot of an eventually consistent data store. One or more compute nodes collect a plurality of node specific snapshots generated by a plurality of distributed nodes that implements the eventually consistent data store. Each of the node specific snapshots is created at various times in relation to the overall data store such that the individual snapshots may contain inconsistent data. Then one or more compute nodes analyze the plurality of snapshots to generate a consistent snapshot of the entire data store corresponding to a previous point in time. The lagging consistency point of the snapshot may be updated based on additional snapshots generated by the plurality of distributed nodes at various intervals.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances well known features have not been described in order to avoid obscuring the present invention.

Each of the nodes includes a processor CPU a memory a network interface controller NIC and one or more non volatile storage devices such as a hard disk drive a magnetic tape drive optical disk drives a drive array e.g. RAID or the like. Each node may include an operating system e.g. Microsoft Windows Linux Unix etc. as well as one or more applications stored in memory and running on CPU . Some of the applications may provide a software framework for various cloud service architectures such as a distributed database management system like Apache Casandra or distributed application system like Apache Hadoop. In one embodiment each node comprises a blade server where two or more blade servers are housed in a chasis and share certain resources such as common power supplies and cooling systems.

Client computer also includes a processor CPU a memory a NIC and one or more non volatile storage devices . Similar to nodes client computer also includes an operating system as well as one or more applications stored in memory and running on CPU . In one embodiment client computer may be maintained by a data analyst to analyze the distributed computer network . Client computer may communicate with each of the nodes via network through NIC and NICs .

In one embodiment each data center includes three nodes . The first data center includes a first node Node  a second node Node  and a third node Node  . The second data center includes a fourth node Node  a fifth node Node  and a sixth node Node  . The third data center includes a seventh node Node  an eighth node Node  and a ninth node Node  . A group of nodes may be referred to as a cluster. For example a multi data center deployment of a cluster that implements the eventually consistent data store may include all nine nodes . . . shown in . In other embodiments each cluster may be comprised of three or more nodes.

It will be appreciated that the nodes of in the cloud may represent physically distinct computing resources such as individual blade servers or virtual computing resources such as distinct virtual machines that may share access to a pool of physical computing resources. The effect is the same as some physical computing resources are being used to store the data in multiple physical hardware devices likely at locations in separate data centers throughout the world.

Node implements a persistent distributed multi dimensional map i.e. an associative array . In other words node implements a structured key value data store in which each key may map to one or more values. In one embodiment the data store is implemented in the cloud via the Apache Cassandra application framework. In Cassandra multiple values are grouped into tables known as column families . A column family is a container mapping row keys to a sorted list of key value pairs i.e. columns . As shown in node includes one or more column families defined when a Cassandra database is implemented. As key value pairs are added to the data store a row will be added to the column family . Each row includes exactly one key and one or more columns e.g. etc. . Key is a universally unique identifier UUID that associates that key to the values stored for each column. For example the UUID may be a 128 bit value that is generated whenever a new row is added to the data store. In other embodiments the key may be a string identifier. Each column family may be associated with a Column Family Identifier. The identifier may be a string such as Users for example.

Columns e.g. etc. within each column family are associated with an identifier e.g. a string and a timestamp e.g. etc. . Each row in a column family may define a number of different columns that represent various values associated with a particular key . For example in a Users column family column may be associated with a username identifier column may be associated with a password identifier and column may be associated with an address identifier. In some embodiments each row may include a different set of columns. In other words each row may include a subset of all columns associated with the column family . In such embodiments column may be associated with a username identifier while column may be associated with a different identifier such as a password identifier.

Data may be added to the data store by various applications running on client computer or the like such as a mobile phone or tablet computer . For example a user may enter information on a web page and click a submit button. The web page may include a form with text boxes for entering a username password and an address. When the user clicks submit a standard RESTful request message is generated and transmitted to an URL associated with the cloud via network . The message will typically be proxied by a web server and application server to one of the nodes which causes an entry i.e. row to be added to the data store. The node may generate a UUID associated with the request and create a row in the data store to hold the strings entered on the web page. Key may hold the UUID column may include the string entered on the web page in the username textbox column may include the string entered on the web page in the password textbox and column may include the string entered on the web page in the address textbox. As additional users submit information via the web page additional RESTful request messages are sent to the cloud and more rows are added to data store.

In one embodiment data store is persistent meaning that once a value for a particular key is added to data store the value will never be deleted from the data store. In such instances in order to update a value associated with a particular key a new row may be added to data store using the same key . Each column may also include a timestamp e.g. that indicates a particular time at which the corresponding column data e.g. was added to data store. When two rows share the same key columns associated with the same identifier may be inconsistent. In such cases the column associated with the most recent timestamp will hold the most recent value and all other columns associated with that identifier may be discarded for that particular key .

Client computer connects to one of the nodes of cluster such as Node  via network . The node to which client computer connects acts as a coordinator for requests transmitted by client computer to read from or write to the data store. Each request is associated with a particular key and a particular column family . The coordinator node will analyze the key to determine which node of the cluster is configured to store that particular value a process known as partitioning. For example keys may be hashed to generate an MD5 hash value that randomly assigns a particular key to one of the nodes of the cluster . Cluster may also be associated with a replication factor that ensures that data is stored redundantly such that a failure in one node does not stop requests to access the data store from being serviced by the cluster . For example a replication factor of reflects that data is stored on three nodes.

In one embodiment data will be stored on a primary node associated with a particular key a secondary node located on the same rack in the data center as the primary node and a tertiary node located in a different data center from the primary node. As shown in a request received by Node  to store a value associated with a key that corresponds to Node  will cause a row to be added to a column family in Node  a row to be added to a column family in Node  and a row to be added to a column family in Node  . Similarly if a different node received a request related to the same key value then that node would forward the request to Node  Node  and Node .

As data is requested to be added to or retrieved from the data store via one or more client computers attached to the cloud a message is routed to one of the nodes in the cluster . The message may contain a request to write to the data store or read from the data store. For a WRITE request the message may define a number of nodes within the cluster to which the value should be written in order to consider the WRITE successful. A WRITE request may be considered successful when a response is received from a single node within the cluster a quorum of nodes within the cluster or all nodes within the cluster associated with the key specified by the write request. For example based on a cluster associated with a replication factor of 3 writing to a single node requires a response from one of the three nodes associated with a key writing to a quorum of nodes requires a response from two of the three nodes associated with the key and writing to all the nodes requires a response from three of the three nodes associated with the key. It will be appreciated that a quorum WRITE request does not reflect that data is written to a quorum of all nodes within the cluster but merely that data is written to a quorum of the nodes associated with storing that particular key. Similarly a READ request may read a value from a single node within the cluster a quorum of nodes within the cluster or all nodes within the cluster.

Writing to a single node is a fast operation but fails to ensure that a READ request will return the correct data e.g. the READ request may be directed to a different node than the node where the data was written . Writing to all the nodes is a slow operation but ensures that a READ request to a single node will always return the correct data. Writing to a quorum of nodes is a faster operation than writing to all the nodes while also ensuring that in conjunction with issuing a quorum READ request the correct data is always returned to a user even though a READ is only performed on a subset of the nodes associated with that key. Reading a value from a single node is a fast operation but does not ensure that the returned value is correct i.e. the correct value may be stored in a different node . Reading a value from a quorum of nodes is a slower operation than reading from a single node but reading from a quorum of nodes will ensure that the correct value is returned as long as the value was also written to a quorum of nodes. When reading from a quorum of nodes the READ request is forwarded to a quorum of the nodes associated with the given key and the correct value is given by the value that was returned with the highest frequency. In the event of a tie e.g. two queried nodes out of the three nodes associated with the key return different values the value associated with the most recent timestamp etc. is selected as the correct value. Reading a value from all nodes is a slower operation but will always ensure that the correct value is returned regardless of whether the value was written to one node a quorum of nodes or all nodes within the cluster .

Application is configured to store key value pairs in the data store and perform backend operations to ensure that the data store is eventually consistent across every node. As a request is received by a node the request is added to a commit log stored in storage device . The commit log acts like a buffer that allows requests to be processed asynchronously from when the requests arrive at the node. The commit log is stored in storage device so that in the event of a power failure requests may be processed by replaying the requests stored in the commit log ensuring integrity of the data in the data store. In other embodiments requests may be processed as they are received by a node thereby obviating the need for commit log . However in such other embodiments a power failure may result in requests not being processed by a node and data being lost within the data store. These embodiments improve on latency caused by a disk input output operation but sacrifice robustness because pending requests may be lost due to power failure of a single node.

As each node receives a WRITE request application adds a new row to the appropriate column family specified in the WRITE request. Again the row includes a key along with values corresponding to one or more columns e.g. etc. . As shown in Node  includes two column families and . For example the first column family may correspond to a database of distinct users and a second column family may correspond to data associated with various users specified in the rows of the first column family . As Node  receives WRITE requests that specify the first column family application stores the WRITE requests to the commit log . Application also processes requests from the commit log as the processing capacity of CPU allows. When a WRITE request is retrieved from commit log application adds a row to the column family specified by the WRITE request and if necessary transmits a message to the originating node in cluster indicating that the operation was successful where the node did not receive a request directly from a client computer but rather a request that was forwarded from another node in cluster to which the client computer has established a direct communications channel with cluster .

As also shown in Node  includes two column families a first column family that corresponds to the first column family in Node  and a second column family that corresponds to the second column family in Node  . For example the first column family in Node  may contain one or more rows associated with various users. Some of the rows in the first column family in Node  may also be stored in the first column family in Node  . Other rows may only be found in either Node  or Node  due to the eventually consistent nature of the data store. For example a WRITE request may only specify that data be written to a single node and therefore the data may be added to column family but not column family . Similar to Node  and Node  Node  includes two column families and the first column family corresponds to the first column family of Node  and the first column family of Node  and the second column family corresponds to the second column family of Node  and the second column family of Node  .

Column families may become very large. In addition each node may contain a plurality of column families . Thus memory capacity for each node may be insufficient to store all of the data. Although not shown explicitly nodes may implement a backing store in storage device to hold portions of column families . As a column family grows past a threshold value some of the rows of column family may be copied into the storage device and removed from memory . When servicing READ requests node may check the portions of the column family in memory as well as portions of the column family in storage device portions of which may be temporarily read into memory to service the READ request.

As the coordinator node transmits WRITE requests to various nodes associated with a particular key some nodes may not be able to perform the WRITE operation. For example a particular node may be disconnected from the cloud due to a power failure at the data center or a failure in the communications link between nodes. In this case the WRITE will fail and data for a given key will be inconsistent between the various nodes of the cluster . In addition a client computer may request a WRITE operation to only a single node in order to reduce latency sacrificing consistency in the process. In such cases application may be configured to periodically repair the data store to ensure that replicas are consistent between nodes. This operation may be performed in the background by checking that a value associated with a key in a column family is the same as the value stored in a column family on a different node associated with that key. If the values are different then the application will transmit a WRITE request to the node that stores the incorrect data in order to make the nodes consistent across the cluster. Again this operation may be performed in the background to avoid high latencies to be experienced by client computers attempting to access the data store. In other words over time an entry added to a column family in one node will eventually be replicated across a number of redundant nodes even if the data was only written to one node based on the request.

As WRITE requests are processed by the nodes of the cluster the size of each column family increases. Application is configured to periodically flush the entries in column families to a non volatile storage device in a data structure known as an SSTable sorted string table . The SSTable data structure is a persistent data structure of key value pairs that may be associated with a bloom filter. A bloom filter enables application to quickly check whether a particular key is likely included within the SSTable a bloom filter will sometimes return a false positive that a key is included in the table but will never return a negative response when the key is included in the table . SSTables are immutable meaning that once the SSTables are written to storage device those SSTables are never modified but rather additional SSTables are written to storage device . As shown in Node  includes two SSTables a first SSTable that corresponds to the first column family in Node  and a second SSTable that corresponds to the second column family in Node  . Again application is configured to periodically flush column families to non volatile storage in order to permanently store key value pairs in the data store. Once key value pairs in column families have been flushed to storage the requests may be removed from the commit log .

Application may also be configured to merge multiple SSTables associated with a single column family using a process called compaction. In the background application sorts each SSTable and combines rows associated with the same key into a single row in a new SSTable associating only the most recent entries for each column associated with a unique identifier for that row. Once a new combined SSTable has been created the old SSTables may be deleted by application . In the aggregate all SSTables stored in the cluster reflect the data in the eventually consistent data store at a previous point in time. Thus each SStable provides an inconsistent snapshot of the key value pairs associated with a column family for a particular node at a given point in time.

A data analyst may have problems attempting to monitor the state of the data store at a particular point in time because of the distributed nature of the data store. On one hand the data analyst could force a consistent scan across each node in the data store in effect blocking any access to the data store while the consistent scan is taking place. However such a technique may be disruptive to clients attempting to access information in the data store because the nodes will be inaccessible while data is replicated across all nodes and then transmitted to the analyst s computer. Instead the present disclosure describes a method and system to generate a snapshot of the data store that provides a lagging consistency point based on the inconsistent SSTables stored in the various nodes of cluster .

In one embodiment cluster is configured with one master node and a plurality of slave nodes configured to process the SSTables retrieved from data store. The master node is configured to retrieve the SStables generated by each node in cluster . The SSTables may correspond to different points in time and may be inconsistent from node to node. For example two nodes may contain related SSTables that store different values for the same key because a WRITE request was configured to only write a value to a single node. Also an SSTable from one node may be generated before a WRITE request is processed whereas a related SSTable from another node may be generated after the WRITE request is processed leading to an inconsistency in the values stored in the SSTables .

In one embodiment cluster is configured to back up all of the SSTables stored in storage devices of each node to a separate long term storage location. The long term storage location may be among other implementations a drive array connected to a private network coupled to cluster or a virtual storage service such as Amazon S3. Application may be configured to copy SSTables stored in storage device to a location in the long term storage periodically. For example every night at 3 am the nodes of cluster may copy the SSTables in storage device to a bucket in the Amazon S3 cloud storage. Then cluster may be configured to read the copies of SSTables from the back up storage location instead of the individual nodes in cluster . By reading backup copies instead of the primary copies on cluster the administrator may avoid causing disruptions to access of the data store.

As the master node retrieves the SSTables from either cluster or the back up storage location the master node implements a distributed MapReduce operation to process the SSTables and generate a point in time snapshot of the data store. The MapReduce operation splits data into smaller portions for processing and distributes the data to a plurality of processing nodes that perform the same operation on the data. The results from all of the slave nodes are then combined to form the total output. In one embodiment as the master node receives each SSTable the master node splits the SSTable into processing tasks. A processing task includes at least a portion of the rows in one or more SSTables . For example the master node may split the SSTables into 64 MB chunks for distribution to each of the slave nodes . The processing task is then assigned to one of the slave nodes for processing.

As shown in the table includes rows e.g. of data combined from one or more SSTables generated by the various nodes that implement the data store. For example a first row includes a key Bob a first column name Bobby12 a timestamp 1325135486 corresponding to the entry in the first column a second column pass BBCali24 and a timestamp 1325135486 corresponding to the entry in the second column . A second row is associated with the same key as the first row but the second row includes a different value in the second column pass bigboy123 as well as a different timestamp . The second row corresponds to data added to the data store that reflects an operation for changing a password associated with a user Bob stored in the data store. Table also includes a fourth row that is a duplicate of the second row which reflects that the data was written to data store on at least two different nodes e.g. in response to a quorum WRITE request .

It will be appreciated that the rows in the table may be duplicated because replicas of the rows are included in SSTables from different nodes or that multiple rows in the table may map different values to the same key because new values for that key were added to data store at different times to replace old values. The sixteen rows of the table are shown in random order such as the result of a process by which a master node adds each row from an SSTable to the bottom of table . In such a case once the master node has added all data from the SSTables to table the master node may perform a sort of the rows based on the keys associated with the rows to generate a sorted table as shown in . In alternate embodiments the master node may insert each row from an SSTable into a sorted location within table thus maintaining a sorted order as table is generated. However such techniques may not be as efficient as first generating an unordered table and then performing a distributed sort on the resulting data to generate the sorted table . In yet other embodiments the master node may not sort table at all distributing portions of the table to the slave nodes for compaction. In such embodiments master node must perform a further compaction operation on the combined results received from each of the slave nodes in order to ensure that there are no duplicate rows or inconsistent data in the final output.

Once the master node has generated a sorted table the master node performs a MapReduce operation to split the data into smaller portions and distribute the data to the slave nodes for processing. In one embodiment master node splits the sorted table up into processing tasks along boundaries defined by the keys associated with the rows of the sorted table . For example as shown in the master node may split the sorted table up into processing tasks along the boundary formed between the tenth row and the eleventh row ensuring that the key associated with the last row e.g. in a first processing task is not the same as a key associated with the first row e.g. in the next processing task. The master node then distributes each of the processing tasks to the slave nodes to perform the distributed MapReduce operation.

Each of the slave nodes receives a sorted list of rows from table . For example a first slave node may receive a sorted list including rows through from sorted table . Rows through correspond to rows associated with the Bob and Carrie keys. Similarly a third slave node may receive a sorted list including rows through from sorted table . Rows through correspond to rows associated with the Jim and Steve keys. A slave node will process the sorted list of rows to remove any duplicate rows and discard any columns that were replaced by entries associated with a more recent timestamp. For example the first slave node may compact a first processing task i.e. all rows corresponding to keys Bob and Carrie to generate a result that includes two rows a first row selected from one of the third through fifth rows of table and a second row selected from one of the ninth through tenth rows of table . Similarly the third slave node may compact a second processing task to generate a result that includes two additional rows a first row selected from one of the eleventh through thirteenth rows of table and a second row selected from one of the fourteenth through sixteenth rows of table . The resulting compacted lists of non duplicate consistent data is then transmitted back to the master node which combines the output of the slave nodes to generate the point in time snapshot i.e. table as shown in .

In one embodiment the master node converts the point in time snapshot to a JSON JavaScript Object Notation format a text based standard designed for human readable data exchange. A JSON object is an unordered set of name value pairs enclosed in braces and separated by a colon . Multiple sets of name value pairs in the JSON object may be separated by a comma. It will be appreciated that the point in time snapshot may be converted to other types of formats as well both human readable and machine readable encrypted or non encrypted as is known in the art.

As shown the method begins at step where a processing cluster receives one or more inconsistent snapshots of an eventually consistent data store. In one embodiment the cluster implements a distributed compute environment as a service on a set of virtual compute nodes . A master node in cluster retrieves a set of SSTables from a back up data store coupled to the cluster . At step the master node generates a sorted table of key value pairs from the set of inconsistent snapshots. In one embodiment the master node first generates an unsorted list by combining rows from each SSTable associated with the data store into an aggregate table and then sorts the unsorted aggregate table to generate a sorted table .

At step the master node divides the sorted table of key value pairs into one or more processing tasks. A processing task is a subset of rows from the sorted table . In one embodiment the master node divides the sorted table along row boundaries to ensure that rows associated with the same key are directed to the same slave node for processing. At step the master node transmits processing tasks to slave nodes for processing. In one embodiment the slave nodes perform a compaction function on the rows of the processing tasks to generate an output table that includes a single row for each unique key . The slave node selects the most recent columns e.g. etc. associated with each key to include in the output table eliminating any duplicate rows associated with the same key . At step the master node receives the results from the plurality of slave nodes . At step the master node combines the results received from the slave nodes to generate a point in time snapshot of the eventually consistent data store.

Due to the fact that the SSTables produced by cluster are immutable once cluster has created a point in time snapshot up to a certain point the point in time snapshot may be updated by iterating through steps and combining any additional SSTables generated by cluster since a previous point in time corresponding to the snapshot .

Returning now to method continues at step where the master node determines whether to update the previous point in time snapshot . If the previous point in time snapshot should be updated then master node retrieves any SSTables generated by cluster since the previous point in time and repeats steps to generate a new point in time snapshot corresponding to a more recent consistency point. However if the master node determines that the snapshot does not need to be updated at this time then method terminates.

The techniques described herein are implemented using a cloud based virtual computing architecture. However it will be appreciated that these techniques and systems may also be implemented by a single computer in a non distributed manner. In such embodiments steps of method may be replaced by a single step where the server computer performs the compaction operation on the sorted table . For example a server computer may download each of the SSTables from the cloud and generate sorted table locally in a memory or storage device attached to the server computer. Instead of splitting up the sorted table and distributing smaller processing tasks to a plurality of compute nodes the server computer could perform the equivalent of the MapReduce operation locally by compacting the sorted table using a single processor. Although most eventually consistent data stores are very large so as to make such a technique inefficient generating the point in time snapshot with a single processor rather than a distributed compute environment is within the scope of the present invention.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the present invention.

