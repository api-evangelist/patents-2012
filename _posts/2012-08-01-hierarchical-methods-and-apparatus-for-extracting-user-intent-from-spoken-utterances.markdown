---

title: Hierarchical methods and apparatus for extracting user intent from spoken utterances
abstract: Improved techniques are disclosed for permitting a user to employ more human-based grammar (i.e., free form or conversational input) while addressing a target system via a voice system. For example, a technique for determining intent associated with a spoken utterance of a user comprises the following steps/operations. Decoded speech uttered by the user is obtained. An intent is then extracted from the decoded speech uttered by the user. The intent is extracted in an iterative manner such that a first class is determined after a first iteration and a sub-class of the first class is determined after a second iteration. The first class and the sub-class of the first class are hierarchically indicative of the intent of the user, e.g., a target and data that may be associated with the target.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08560325&OS=08560325&RS=08560325
owner: Nuance Communications, Inc.
number: 08560325
owner_city: Burlington
owner_country: US
publication_date: 20120801
---
This application claims the benefit under 35 U.S.C. 120 as a continuation of U.S. patent application Ser. No. 11 216 483 filed Aug. 31 2005 and entitled HIERARCHICAL METHODS AND APPARATUS FOR EXTRACTING USER INTENT FROM SPOKEN UTTERANCES the entire contents of which is incorporated herein by reference.

The present invention relates generally to speech processing systems and more particularly to systems for hierarchically extracting user intent from spoken utterances such as spoken instructions or commands.

The use of a speech recognition system or a voice system to translate a user s spoken command to a precise text command that the target system can input and process is well known. For example in a conventional voice system based in a vehicle a user e.g. driver interacts with the voice system by uttering very specific commands that must be consistent with machine based grammar that is understood by the target system.

By way of example assume that the climate control system in the vehicle is the target system. In order to decrease the temperature in the vehicle the user of a conventional voice system may typically have to utter several predetermined machine based grammar commands such as the command climate control followed by the command air conditioner followed by the command decrease temperature followed by the command five degrees. 

Unfortunately people do not talk or think in terms of specific machine based grammar and may also forget the precise predetermined commands that must be uttered to effectuate their wishes.

One approach that attempts to overcome the machine based grammar problem is to use a single stage front end action classifier that detects a very general subject from the user s speech which is then provided to a human operator for further intent determination. This is typically the approach used in the General Motors OnStar system. However a major problem with this approach is that a human operator is required.

Another approach is to build a full fledged statistical parser which takes the input as transcribed and builds a parse tree which is mined later to extract intent. One major difficulty in this second approach is that statistical parsers are huge in terms of storage requirements. Further they require hand tuning in every step. That is every time data is added the statistical parser requires a tremendous amount of hand tuning and balancing of the new data with the old data.

Accordingly improved techniques are needed that permit a user to employ more human based grammar i.e. free form or conversational input while addressing a target system via a voice system.

Principles of the present invention provide improved techniques for permitting a user to employ more human based grammar i.e. free form or conversational input while addressing a target system via a voice system.

In one aspect of the invention a technique for determining intent associated with a spoken utterance of a user comprises the following steps operations. Decoded speech uttered by the user is obtained. An intent is then extracted from the decoded speech uttered by the user. The intent is extracted in an iterative manner such that a first class is determined after a first iteration and a sub class of the first class is determined after a second iteration. The first class and the sub class of the first class are hierarchically indicative of the intent of the user e.g. a target and data that may be associated with the target.

The multi stage intent extraction approach may have more than two iterations. By way of example only the user intent extracting step may further determine a sub class of the sub class of the first class after a third iteration such that the first class the sub class of the first class and the sub class of the sub class of the first class are hierarchically indicative of the intent of the user.

In a preferred embodiment as will be explained in further detail below the first class may represent a target e.g. topic associated with the user intent the sub class of the first class may represent an action e.g. function associated with the target and the sub class of the sub class of the first class may represent data associated with the action. One or more commands may then be provided to a target system based on the class and sub class determinations.

These and other objects features and advantages of the present invention will become apparent from the following detailed description of illustrative embodiments thereof which is to be read in connection with the accompanying drawings.

While the present invention may be illustratively described below in the context of a vehicle based voice system it is to be understood that principles of the invention are not limited to any particular computing system environment or any particular speech recognition application. Rather principles of the invention are more generally applicable to any computing system environment and any speech recognition application in which it would be desirable to permit the user to provide free form or conversational speech input.

Principles of the invention address the problem of extracting user intent from free form type spoken utterances. For example returning to the vehicle based climate control example described above principles of the invention permit a driver to interact with a voice system in the vehicle by giving free form voice instructions that are different than the precise machine based grammar voice commands understood by the climate control system. Thus in this particular example instead of saying the precise commands decrease temperature and five degrees in accordance with principles of the invention the drivers may say make it cooler. The system interprets it and cooler and associates the phrase with a temperature and asks one or more additional questions to clarify the user intent.

To do this the system detects a dialog domain such as in the following examples the illustrative free form type spoken utterance is to the left of the arrow and the illustrative detected dialog domain is to the right of the arrow 

As will be illustratively explained herein principles of the invention are able to determine intent associated with a spoken utterance of a user by obtaining decoded speech uttered by the user e.g. from a speech recognition engine and extracting an intent from the decoded speech uttered by the user wherein the intent is extracted in an iterative manner such that a first class is determined after a first iteration and a sub class of the first class is determined after a second iteration. The first class and the sub class of the first class are hierarchically indicative of the intent of the user e.g. a target and data that may be associated with the target. Of course the multi stage approach may have more than two iterations. By way of example only the user intent extracting step may further determine a sub class of the sub class of the first class after a third iteration such that the first class the sub class of the first class and the sub class of the sub class of the first class are hierarchically indicative of the intent of the user.

In a preferred embodiment as will be explained in further detail below the first class may represent a target e.g. topic associated with the user intent the sub class of the first class may represent an action e.g. function associated with the target and the sub class of the sub class of the first class may represent data associated with the action. One or more commands may then be provided to a target system based on the class and sub class determinations.

Advantageously principles of the invention provide a multi stage system that extracts more and more information from the same sentence as it goes along.

In another example where the target system is an audio system of the vehicle the free form utterance turn the volume up may result in a detected class Audio after a first stage or first iteration a sub class Audio Volume after a second stage or second iteration and a sub class Audio Volume Up which is a sub class of the sub class Audio after a third stage or third iteration .

In a preferred embodiment this may be accomplished via attribute value pair AVP extraction in a top down fashion. Thus each stage or level in the multi stage system acts as an elemental AVP extractor or semantic analyzer of the sentence. The advantage is that the multi stage system of the invention is not tagging each word with labels as would occur in a statistical parser or attaching a semantic label as would occur in a linguistic parser rather the multi stage system is adding class sub class and sub class of the sub class information which is far simpler to do. Also the methodology is iterative because the same process is applied at each subsequent level with only finer and finer class labels.

Table 1 below is an example of the multi level class labels e.g. hierarchical structure that may be associated with the audio example 

In order to be able to decode or recognize the free form speech an initial training data set may be used. The process is automated wherein a small model is built with a relatively small data set. Then the training process iterates when new data is added using the initial model to label the new data set.

Further the multi stage system can also be employed with lower level parsers or metadata. That is most of the intent determination processing uses the hierarchical action classification approach of the invention. However when the system gets down to some very specific part of the user request e.g. complicated navigation request that has a to city a from city and or some other peripheral information like avoiding the most congested roads this can make the request complicated. Within the hierarchical action classification of the invention while this lower level information in the utterance can be annotated the system can utilize added metadata and or use a simple kind of parser at the lowest stage or level for extracting items such as to and from information. Thus instead of building an entire statistical parser for the entire corpus of data principles of the invention are able to use a smaller domain dependent subset of the data.

Referring initially to a hierarchical system for extracting user intent from a spoken utterance according to an embodiment of the invention is depicted. As shown the system referred to as a dialog domain detection DDE engine comprises conversational system command bus hierarchy manager intent recognition manager question module situation manager audio input speech recognition system and sensors .

Conversational system functions as a dialog manager. Audio input represents the spoken utterances captured by the system that are being processed to determine intent. Conversational system sends the audio input to speech recognition engine which then decodes the audio and returns text representative of what the speech recognition engine recognized back to conversational system . It is to be appreciated that the invention is not limited to any particular speech recognition engine and thus any suitable speech recognition system can be employed. By way of example only the IBM Corporation Armonk N.Y. Embedded ViaVoice engine could be employed.

Hierarchy manager as will be explained in further detail below in the context of imposes the top down iterative structure used by intent recognition manager as will be explained in further detail below in the context of to extract intent from the spoken utterance of the user. For example in the audio example the above described multi level class labels in Table 1 may serve as the imposed hierarchical structure.

That is hierarchy manager sets the number of levels or stages that intent recognition manager will traverse for a given intent determination session. More particularly hierarchy manager dictates at each level the permitted inputs and the permitted results e.g. class labels . Then intent recognition manager traverses top to bottom the hierarchical structure set by the hierarchy manager. As it traverses down the structure intent recognition manager expects hierarchy manager to inform it at this level what structure can be imposed. Thus intent recognition manager keeps referring back to the hierarchy manager.

Intent recognition manager has an additional function. It is also serves as an interface for the logical multi tiered view of the user input sentence. Conversational system may utilize such a logical view of the sentence.

Thus the intent gets clarified as the intent recognition manager walks down the structure. As the hierarchy manager informs that it can provide certain information the intent recognition manager walks down the structure and determines a particular intent at each level from broad to narrow. The particular intent determined at each level is referred to herein as an interpretation. In the audio example the top level intent is going to be the audio system. However this does not mean much since there are any number of actions that can be taken with respect to the audio system. The next level could determine that the user is referring to a radio station. The next level could determine a particular radio station that the user wishes to be selected. Thus instead of saying XM Radio set radio channel and channel the DDE engine of the invention permits the user to say I want to listen to channel . Therefore the intent recognition manager starts with a vague picture or actually with nothing and tries to come up with a highly tuned view of what the intent is.

Question module generates questions that can be asked of the user that may be used to assist the system with determining intent. As is known dialog managers are able to coordinate the asking of questions to a speaker the responses to which further clarify any ambiguity that remains from the previous user input. Thus as is known question module may comprise a text to speech engine capable of generating questions that are audibly output to the user. The responses are processed through the speech recognition engine and provided to the conversational system which coordinates their use with the intent recognition manager. Further when an intent is determined by the system question module could serve to ask the user to confirm that intent before the system sends the appropriate command s to the target system.

Sensors may comprise one or more sensors that describe external situations e.g. weather speed humidity temperature location via a global positioning system etc. and personal characteristics e.g. biometrics voice face characteristics tired sleepiness conditions . This information coordinated by situation manager may also be used to determine intent of the user and or assist in providing a response to the user.

While the invention is not limited to any particular question module architecture or external situation manager architecture examples of techniques that could be employed here are described in U.S. Pat. Nos. 6 092 192 6 587 818 and 6 236 968.

Referring now to a hierarchy manager according to an embodiment of the invention is depicted. As shown hierarchy manager in comprises parser labeler semantic processing module sequencing module topic function and data text input and training module .

Parser receives as input text . It is to be appreciated that text represents the decoded speech i.e. the result of the audio input in being decoded by the speech recognition engine in . The role of parser is to tag the parts of speech of the decoded text e.g. nouns verbs other grammatical terms or phrases. The parser can utilize meta information or even external mark up to describe the tagged portions of the text.

Labeler separates function and non function words in the text. That is it is understood that some words in the text are more valuable function words than other words non function words in determining intent. To do this the words in the text are weighted by the labeler. The weighting may be done by accessing the domain dependent model and scoring the words in the text against all potential words. The importance of the word depends on its score i.e. words with higher scores are considered more important. Words at or above a threshold score may be considered function words while words below a threshold score may be considered non function words.

Semantic processor then interprets the scores assigned by the labeler. For example the semantic processor may determine for a given input sentence that terms associated with audio have more weight than terms associated with climate control. Thus the semantic processor accepts all the interpretations does a relative scoring applies a threshold and decides for example that the top three interpretations should be taken as the most relevant ones.

Interpretation means intent in this context. Thus for each input utterance the labeler produces a list of interpretations and attendant scores. Since this is a statistical approach there are no unambiguously correct labels produced but instead a list of interpretations covering all possible interpretations. The semantic processor applies intelligent thresholding to discard low scores that are possible but of low probability based on prior knowledge or simple thresholding. Prior knowledge can include user knowledge derived from the training data and simple thresholding can includes retaining a fixed number of interpretations e.g. three or retaining all interpretations within a fixed percentage of the best scoring label. These are all parameters that can be made available to an agent deploying the system via operating panels. By way of one example semantic processor may employ techniques disclosed in U.S. Pat. No. 6 236 968.

The interpreted result is a three tuple a group of three sub results . That is in this particular embodiment to understand a command three entities are extracted and analyzed 1 the machine target or topic that is operated upon e.g. Audio. Navigation 2 the action function to be performed e.g. switch turn move and 3 the data that is provided with the action e.g. on off up down left right . By way of example Table 1 above illustrates the hierarchical structure from which the three tuple may be determined. It is to be understood that while hierarchy manager and intent recognition manager are illustrated in as logically separate components the components may be implemented in a single functional module due to their tightly coupled functionality.

Sequencing module is used to apply global rules on which part of the sentence is more important because for example it is first in order in the sentence or because it is the premise of the sentence or because the user used more emphasis on it.

The idea of sequencing or timing here relates to separating within a complex request from the user the primary request from a secondary one. For example where the target system is a navigation system assume a user says Find me a McDonald s with parking. The principal request is find me a McDonald s. The parking is a secondary request. The sequencer informs the semantic processor that the concept of finding a McDonald s should take precedence or is more important than the concept of parking. 

Such sequencing may be determined from any nuances in the user s utterance that guide the search for the correct interpretation. An emphasized word or phrase carries more weight. The speeding up of a phrase within a sentence may carry additional indicators of importance etc. So this module attempts to perform a fine grained analysis of the user s nuances.

Referring now to an intent recognition manager according to an embodiment of the invention is depicted. As shown intent recognition manager in comprises weight computation module pruning module list preparation module feedback and external input .

Weight computation module computes the weights of the different words in the user utterance and applies two kinds of quantitative tests. The first is to compute whether the words in the utterance are above a fixed threshold. This is the rejection mechanism which decides whether to accept the user utterance for analysis or reject it outright as being outside the realm of its capability. Systems built for use in a car are unlikely to understand questions about other general subjects. In other words it has to be able to detect that the user used words that are outside its vocabulary. The rejection mechanism is one way to do this. The second quantitative test is the confidence scores. These are the relative scores of the multiple interpretations of the user utterance.

Pruning module prunes the list from weight computation module . The output from weight computation module nominally will include all possible candidate interpretations. Pruning module decides which ones are worth keeping. Some scores from weight computation module may be too small to consider not relevant or too small in magnitude relative to the top scoring interpretations. A worthiness test may be derived from the training data. Further the pruning module can include a control panel and additional controls that can be adjusted with input from customer satisfaction tests feedback .

List preparation module prepares the final intent list. The search for the interpretation is usually done in a hierarchical fashion with each level in turn revealing the topic function and data. Hence the scoring pruning and list preparing tasks are iterative as the scores are carried from one level to the next. In one embodiment the top three scorers from the top level are expanded to the next level. The top three are appropriate it has been proven from computing with training data that 98.5 of the time the correct interpretation is within the top three results.

In addition external inputs e.g. other intent recognition scores can be utilized to generate the list in .

Referring now to a confidence rejection module according to an embodiment of the invention is depicted. It is to be understood that depicts the confidence score and rejection mechanisms shown in weight computation module of .

More particularly in one embodiment the confidence score for an utterance is the ratio of words in vocabulary to the total number of words in the utterance. Hence if all the words in the utterance are found in the system s vocabulary then the confidence score is 1. If none are it is zero. If the ratio is less than 0.5 then the utterance is rejected. Block computed the confidence score and block applies the rejection mechanism.

This operation can also be understood as follows. The confidence score tries to determine how many of the words are in the system vocabulary versus out of the system vocabulary. If all of the words are in the vocabulary the word scores are accepted as is.

If a fraction of the words are not in the vocabulary then those words are handicapped to the extent they are not in the vocabulary. For example if 75 percent of the words are in the vocabulary every score coming out of the word score computation is handicapped i.e. by multiplying by 0.75 . That cascades down the hierarchy. The siblings are also penalized to that extent.

Referring now to a run time methodology for use in hierarchically extracting user intent from a spoken utterance according to an embodiment of the invention is depicted.

In general the input utterance is applied to the system i.e. applied against the system model and the system will return an interpretation e.g. a three tuple comprising topic function data . Hence an input turn the volume up will generate multiple interpretations 

Each will have a computed score associated with it. shows a flow chart of how these interpretations are generated. An initial model tree created during training contains all possible paths that can yield a result. Traversing down this tree from the top node to a leaf node yields several interpretations per level. So for example nine interpretations from the top level are pruned down to three. Each of the nodes of the tree are expanded to their child nodes. For example Audio above may yield Audio Volume Audio Treble and Audio CD and Climate may yield three more of its children. Similarly Audio Volume will be split into its children. The process stops after three levels. In some cases there may be fewer than three levels simply because there is not adequate data to warrant a third level.

Referring now to a training methodology for use in hierarchically extracting user intent from a spoken utterance according to an embodiment of the invention is depicted.

In general first we decide on the domain in which this system will operate. Data is then collected in that domain rejecting all data that is outside the domain. These data are then carefully divided into multiple topic domains. Within each topic the sentences are further bucketed into sub domains by function and then each function into data. This process of bucketing may be done using a tool that allows for easy tagging of such data in a visual manner. We may then gather more data in sub domains that do not have adequate representation. The more common approach is to build a model run a test with data withheld from the training set. Topics that perform poorly are candidates for adding more sentences. This approach allows for more targeted data collection.

Further we preferably split training data into one set for each node in the hierarchy and build a model for each node.

Referring lastly to a block diagram of an illustrative implementation of a computing system for use in implementing techniques of the invention is shown. More particularly represents a computing system which may implement the user intent extraction components and methodologies of the invention as described above in the context of . The architecture shown may also be used to implement a target system.

In this particular implementation a processor for controlling and performing methodologies described herein is coupled to a memory and a user interface via a computer bus .

It is to be appreciated that the term processor as used herein is intended to include any processing device such as for example one that includes a CPU central processing unit or other suitable processing circuitry. For example the processor may be a digital signal processor DSP as is known in the art. Also the term processor may refer to more than one individual processor. However the invention is not limited to any particular processor type or configuration.

The term memory as used herein is intended to include memory associated with a processor or CPU such as for example RAM ROM a fixed memory device e.g. hard drive a removable memory device e.g. diskette flash memory etc. However the invention is not limited to any particular memory type or configuration.

In addition the term user interface as used herein is intended to include for example one or more input devices e.g. keyboard for inputting data to the processing unit and or one or more output devices e.g. CRT display and or printer for providing results associated with the processing unit. The user interface may also include one or more microphones for receiving user speech. However the invention is not limited to any particular user interface type or configuration.

Accordingly computer software including instructions or code for performing the methodologies of the invention as described herein may be stored in one or more of the associated memory devices e.g. ROM fixed or removable memory and when ready to be utilized loaded in part or in whole e.g. into RAM and executed by a CPU.

In any case it should be understood that the components steps illustrated in may be implemented in various forms of hardware software or combinations thereof e.g. one or more digital signal processors with associated memory application specific integrated circuit s functional circuitry one or more appropriately programmed general purpose digital computers with associated memory etc. Given the teachings of the invention provided herein one of ordinary skill in the related art will be able to contemplate other implementations of the elements of the invention.

Although illustrative embodiments of the present invention have been described herein with reference to the accompanying drawings it is to be understood that the invention is not limited to those precise embodiments and that various other changes and modifications may be made by one skilled in the art without departing from the scope or spirit of the invention.

