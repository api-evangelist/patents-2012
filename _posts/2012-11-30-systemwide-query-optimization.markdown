---

title: System-wide query optimization
abstract: A locally optimized plan for executing a command using a sequence of steps can be determined for a single computing node. However, the locally optimized sequence of steps may not be optimized for a combined system comprising multiple computing nodes, any one of which may be tasked with executing the command. A plan that is optimized for the combined system may be determined by comparing the predicted cost of locally optimized plans for computing nodes in the combined system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09229983&OS=09229983&RS=09229983
owner: Amazon Technologies, Inc.
number: 09229983
owner_city: Seattle
owner_country: US
publication_date: 20121130
---
It is often desirable to implement large databases using many small computers rather than a single server with numerous processors and large memory banks. These small computers are often described as commodity hardware because in contrast with the most powerful servers they are relatively inexpensive easily obtained and readily interchangeable. However despite the advantages of using commodity hardware creating large databases that are scalable and efficient remains a challenging endeavor.

One technique for implementing large database systems on commodity hardware involves utilizing shards. In general terms a shard is a computing system responsible for solving a small portion of a larger computing problem. For example when shards are used in large scale data management systems tables may be divided by row into what are known as horizontal partitions. Each shard manages a partition and responds to requests and commands involving that partition. This approach can reduce costs and have better performance when compared to traditional database systems.

However shard based systems can be difficult to optimize. Each shard may include an independent data management system that has a query optimizer capable of generating an execution plan for a query that runs on that shard. While the execution plan may be locally optimized for execution on that shard it is not necessarily optimized across all shards. Because of differences in performance characteristics and the data managed by each shard a plan that runs efficiently on one shard may run poorly on another.

The following disclosure is directed to the generation of execution plans that are optimized across multiple shards operating as database systems state machines workflow engines and so forth. In various embodiments each shard generates a locally optimized execution plan with an associated cost factor for execution by an execution engine running on the shard. The cost factor may then be adjusted and compared with the cost factor associated with other execution plans to select a plan that is optimized considering its effects on the entire system. The adjustment to the cost factor may be based on statistics collected by the shard that generated the execution plan statistics generated by the other shards and the shard s relative performance characteristics among other things. The comparison of cost factors may be performed by a variety of techniques including sequential comparison voting determination by a central authority and so on.

Other embodiments described herein allow an application to use hints to optimize performance of a shard based system. In one embodiment the system causes the application to include in the queries it sends to a shard instructions that change how the query is executed on the shard. In another embodiment the system might cause the application to include instructions that directly control the execution plan used to execute a query.

Further embodiments provide technical personnel with hints and suggestions for optimizing database performance. For example after receiving a hint regarding a preferred execution plan a software engineer might change application program code to issue modified queries containing suggestions to the query optimizer. These suggestions influence the plan produced by the query optimizer so that it complies with the preferred execution plan.

Various aspects of the disclosure are described herein with regard to certain examples and embodiments which are intended to illustrate but not to limit the disclosure. It should be appreciated that the subject matter presented herein may be implemented as a computer process a computer controlled apparatus a computing system or an article of manufacture such as a computer readable storage medium. While the subject matter described herein is presented in the general context of program modules that execute on one or more computing devices those skilled in the art will recognize that other implementations may be performed in combination with other types of program modules. Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types.

Those skilled in the art will also appreciate that the subject matter described herein may be practiced on or in conjunction with other computer system configurations beyond those described herein including multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers handheld computers personal digital assistants e readers cellular telephone devices special purposed hardware devices network appliances and the like. The embodiments described herein may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

Within the specification references are made to the accompanying drawings that form a part hereof and that show by way of illustration specific embodiments or examples. The drawings herein are not drawn to scale. Like numerals represent like elements throughout the several figures.

The management of large volumes of data is a common computing problem. An approach to this problem involves dividing a large set of data into smaller sets each of which may be managed by a relatively inexpensive computing device. Each computing device may also be responsible for responding to queries operating on the set of data assigned to it. If the data managed by each computing device shares a common layout or schema the same query or semantically equivalent forms of a query may be applied to any or all of the computing devices. In addition the same sequence of steps for resolving the query may be selected for use on all of the computing devices. This sequence which can be referred to as an execution plan describes a set of operations needed to satisfy the query. The sequence may be selected based on its effect on an individual computing device. However the performance of the overall data management system may be improved if the sequence is chosen based on its effect i.e. cost in terms of various factors such as response time working set CPU cycles and so forth on the overall data management system and not just its effect of the sequence on any one computing device.

When designing a large data management system it is often desirable to split workload among a number of smaller computing devices rather than using one or two larger and more expensive devices. Each smaller computing system may be described as a shard because it represents a fragment of the overall system. The shards are grouped into what can be termed a domain which is a collection of shards organized to collectively manage the workload. A shard may be implemented on a wide variety of computing environments such as commodity hardware computers virtual machines computing clusters and computing appliances. Any of these computing devices or environments may for convenience be described as computing nodes.

Typically each shard runs a fully independent execution engine such as a database system that has access to its own dedicated processors memory and storage devices. Systems that employ this type of independent architecture have good scalability and are also more resilient compared to systems that share critical components. The independent architecture allows the system as a whole to continue operating even though individual shards in the domain have ceased to function. However those of ordinary skill in the art will appreciate that deviations from a pure independent architecture are occasionally desirable or necessary. For example the shards that comprise the larger system will often share a common network infrastructure. Although the network in this case represents a single point of failure they are often relatively robust compared to error prone components such as storage subsystems. Therefore use of a common network allows for communication between the shards while retaining most of the advantages of an independent architecture.

A number of possible approaches may be employed to construct a data management system using shard based architecture. In one approach data tables are partitioned by row with each range of rows assigned to a specific shard. The shard handles all requests to retrieve or store data having values that fall within the range of values assigned to the partition. This approach is referred to as horizontal partitioning. As an example consider a table containing customer information. The customer table can be horizontally partitioned based on the customer s last name. In a two shard domain customers whose last names begin with A through M might be assigned to the first shard and customers whose last names begins with N through Z might be assigned to the second.

In some cases all tables maintained by a domain will be horizontally partitioned. However many other configurations are possible. Some tables may be horizontally partitioned while others are replicated between shards. In other cases horizontally partitioned tables are replicated as a means of protecting against hardware failure.

When tables are horizontally partitioned each shard will host a table having identical schema but containing different sets of data. In other words the horizontally partitioned tables hosted on each shard share the same column layout but contain different rows of data. Because the tables on each shard share a common schema queries may be written without regard to which shard or shards the queries will ultimately execute on.

To take advantage of the common schema means are provided for routing queries to the shard or shards that contain the required data multiple shards may be involved if the request involves data that spans more than one horizontal partition. Three non limiting examples of approaches to routing queries to the correct shard are as follows. The first approach involves a centralized host that routes queries to the appropriate shard. When the centralized system receives a query it determines the range of partitions that are potentially involved in the query. It may then forward the query to the shards that host those partitions assemble the results and forward them to the client. In the second approach any shard may receive a request and process it in a manner similar to that just described. Applications may initially send the request to the shard hosting the partition most likely to contain the required data. In the third approach applications are fully aware of both the shards and the partitioning scheme and send separate queries directly to each required shard.

When a data management system executes a query it may perform a series of steps such as table scans index scans and hash table lookups which are the internal operations needed to produce results for the query. Collectively these steps describe the path taken by the data management system to perform the query. More generally they are a set of instructions taken by an execution engine to perform a query and are referred to in this specification by the term execution plan or for brevity by the term plan. In the database context an execution plan may be referred to for example as an access path or a query plan. There are often many different possible execution plans for the same query. Each execution plan is capable of producing the same results but their performance characteristics may vary widely. Note that the term query refers to a request for data or a command to be performed. Furthermore a single query may have many different forms all of which can be executed using the same execution plan. For example the same query may be expressed using a different language varying textual formats or as is often the case may contain parameterized values not supplied until the command is executed. For all of these cases the same execution plan may be used to execute all forms of the query.

Execution plans are also used by other types of execution engines such as state machines or workflow processors. For example a state machine may comprise a series of possible state transitions each with an associated cost. Various paths may be traversed when moving from state A to state Z each of which may have a different cost.

To determine the preferred plan for executing a query on a particular shard a component known as a query optimizer evaluates the predicted cost of following each possible execution plan. Each step in an execution plan is associated with a predicted i.e. estimated cost considering factors such as the time it takes to execute the step or the computing resources it consumes. The total predicted cost of performing an execution plan may be computed based on the costs of its component steps. Branches and loops may be accounted for by considering the likelihood of a particular branch being executed and adjusting the cost factor accordingly. Typically the total predicted cost will be expressed as a unitless scalar value or a time based estimate. Note that the term predicted cost may also be described as an estimated cost and is not necessarily an accurate forecast of the costs that are actually incurred.

Once the predicted costs are known an optimized execution plan may be chosen by selecting the execution plan with the cheapest total cost. Other factors in addition to cost may also be considered. For example it is sometimes desirable to select a plan that returns an initial set of results quickly even if the overall plan is less efficient.

The accuracy of the cost calculation may be improved by using various statistics. These may include values such as the number of rows in a table or the number of unique values in a column. The statistics may also include measurements related to prior executions of the same execution plan. The data may be of a general nature such as the total time spent executing a given execution plan or it may be more granular such as the number of disk reads involved in performing a table scan. Furthermore statistics may reflect which branches of the execution plan are most commonly executed in practice improving the accuracy of cost predictions.

However the efficacy of this approach is limited on shard based systems. Each shard is independent and has its own query optimizer and set of statistics. Therefore on a given shard the query optimizer will produce an execution plan that is locally optimized but not necessarily globally optimized. A globally optimized plan would maximize overall system performance considering factors such as the cost of a given execution plan on each shard and the relative frequency with which it is executed on each shard. However the predicted costs of locally generated plans may be misleading because they only reflect the characteristics of the system they were generated on.

One general approach to identifying a globally optimized execution plan involves producing a locally optimized plan on each shard in a domain and then comparing the costs of each plan to determine which is globally optimized. Various approaches may be used to compare costs such as performing direct comparison of the predicted cost of each plan or other embodiments for comparison disclosed in this specification. Various approaches may also be employed regarding other aspects of determining a globally optimized execution plan such as when each shard generates a locally optimized execution plan how information about plans is shared and how the globally optimized plan is utilized by the other shards.

In one embodiment a shard is designated as the leader and broadcasts information about its locally optimized execution plan. If another shard compares the broadcast plan to its own plan and finds that its own plan is superior it may designate its own plan as the leader and broadcast information about its own plan. This process continues until no shard is able to provide a plan superior to the current leader s plan. The leading plan at the end of the process is considered to be globally optimized.

At operation the shard first determines if it should compare the leading plan with its own locally generated plan. In some cases no local plan will have been generated when information for a leading plan is received. In such cases a number of approaches may be taken. Various non limiting examples include immediately generating a new plan or accepting the leading plan without comparison. In some embodiments the shard may first begin utilizing the leading plan while generating its own plan at some later point and then comparing it to the currently leading plan. Alternatively the shard may be configured to never generate an execution plan for comparison.

If operation determines that a comparison should be performed the shard generates or retrieves its own plan for the query that corresponds to the currently leading plan. The two plans are then compared at operation using one of a variety of means including embodiments for comparing execution plans described herein. If the local plan is superior operation the shard will begin to use or keep using its own locally generated plan operation . The plan is designated as the leader operation and information about the plan is broadcast to other shards operation . Returning to operation if the locally generated plan was not superior the shard adopts the leading plan rather than its own operation .

If operation determines that a comparison should not be performed the shard may immediately begin using the leading plan. This approach may be advantageous because it allows the shard to use a pre existing plan without having to pause query execution while a local plan is generated. The shard may then generate its own plan at a later time such as when the shard would otherwise be idle.

In another embodiment the leader may be selected by sequentially evaluating the execution plans generated by the shards. A shard initially designated as the leader may send execution plan information directly to a second shard which compares the leader s execution plan to its own. If the second shard determines that its plan is superior it designates itself as the leader and sends information about the plan to a third shard. Otherwise the second shard forwards the original execution plan information to the third shard. This process continues until the execution plans held by each shard have been evaluated and the last shard in the sequence designates the final leading plan as the globally optimized plan.

A further embodiment performs global query optimization by a voting process. Each shard may be assigned a number of votes based on a variety of factors and may cast these votes in favor of its own plan being selected as the leader. The factors that may influence the number of votes available to a shard include the cost of the shard s execution plan the frequency with which the respective query is executed and the performance characteristics of the shard s hardware.

In an embodiment vote calculator module is integrated into front end module . Vote calculator module determines the number of votes available by reference to statistics module which in turn may obtain statistics from database and the shard s operating system . In an embodiment the number of votes is determined on a per query basis with reference to one or more of the cost of the query the performance characteristics of the shard s hardware the amount and type of data stored on the shard and the relative frequency with which the query is executed on the shard.

A vote coordinator module initiates the voting process. Although depicted separately in the vote coordinator module may be integrated into any module such as front end module . If so each shard may contain a vote coordinator module but only one is active at any given time.

When the voting process begins each vote casting module obtains the number of votes available from vote calculator module . Vote casting module then sends voting information to the vote coordinator module . The voting information contains sufficient information to allow other shards to subsequently request the execution plan should the vote be successful. This information may comprise a shard identifier an execution plan identifier and a value indicating the number of votes being cast for that execution plan. As noted the number of votes that vote casting module may cast is limited by an amount determined by vote calculator module .

When each vote casting module has cast its vote vote coordinator module selects the query plan with the most votes. In some embodiments two or more vote casting modules may cast votes for the same execution plan. If so their votes may be added together and that value used to determine the winning plan.

After determining the winning plan vote coordinator module notifies each shard of the outcome and provides enough information for the shards to begin using the plan by obtaining plan information via plan information module and forwarding the information to each shard. Other embodiments may utilize different means of notifying the shards of the preferred plan and for initiating use of the preferred plan.

A globally optimized execution plan may also be determined by a central authority. In an embodiment each shard sends information about its execution plan to a central authority that evaluates and compares each plan. The central authority determines the globally optimized plan and broadcasts information about that plan to each shard.

Some of the optimization information may be transmitted at a time prior to the cost comparison. Central authority may actively retrieve the factors from each shard . Alternatively each shard may transmit aspects of optimization information based on a variety of triggering factors. In various embodiments the relevant factors may be transmitted for example periodically or when the information has significantly changed.

In various embodiments a communications mechanism must be employed to distribute information about execution plans. While selection of a globally optimized plan is ongoing it may be preferable to transmit a limited quantity of information about the plan. The transmitted information may therefore be limited to what is needed for comparison between plans. Various means may be employed to transmit the information such as broadcast or point to point communication. After the globally optimized plan has been selected more complete information may be needed to allow the plan to be employed. Both broadcast and point to point communication among other means may be employed to communicate this information. Point to point communication may be preferable however due to the comparatively larger amount of data involved.

A source identifier identifies the source of the execution plan information which may be a shard on which the plan was generated. The identifier may be any type of value that serves to identify the source such as a globally unique identifier uniform resource locator or internet protocol address. In an embodiment when the receiving shard determines that the sender has a preferred plan it may request additional information concerning the plan from the source identified by .

An execution plan identifier identifies the execution plan. It may be of any type of value that serves to identify the execution query plan such as a globally unique identifier and may be used in a request to obtain full information about the identified execution plan from the source identified by .

A query identifier serves to identify the query to which the plan applies. It may be any type of value that serves to identify the query such as a globally unique identifier or the text of the query itself.

A domain identifier indicates the domain to which the shard belongs. In this context the domain refers to a group of shards that participate in determining a globally optimized query. Typically the domain will correspond to all of the horizontal partitions for a given table although other arrangements may be advantageous. The shards that comprise a domain do not necessarily include all of the shards involved in managing a partitioned table.

A cost indicator provides a measurement of the plan s cost. The cost indicator may be a simple scalar value one or more vectors of scalar values or other means of conveying cost information. In an embodiment the cost indicator is a vector of values corresponding to steps in the set of steps that comprise the execution plan.

The data structure may contain an identifier of the source of the execution plan which may be any type of value that serves to identify the source such as a globally unique identifier uniform resource locator or internet protocol address. A second identifier identifies the plan itself and may be any type of value that serves to identify the plan such as a globally unique identifier. A third value identifies the query to which the plan applies. It may be any type of value that serves to identify the query such as a globally unique identifier or the text of the query itself.

In addition the data structure may contain metadata representing the execution plan in detail sufficient to load the execution plan into the shard s query optimizer. This may comprise execution plan details . In some embodiments the metadata may be provided to a database via an application programming interface. The database will process corresponding queries using the supplied execution plan after the programming interface is invoked.

A variety of means may be employed to compare the predicted cost of two execution plans. In some circumstances it may be advantageous to directly compare cost figures provided by the query optimizer without any adjustment. However a variety of factors may make unadjusted cost comparisons misleading. For example relatively fast CPU performance on one of the shards may decrease the cost estimates produced by that shard s query optimizer even though the associated execution plans perform poorly on shards in the domain that have slower processors.

In an embodiment the cost figures for each execution plan are adjusted based on the performance characteristics of the shard that produced the execution plan. A scalar cost figure may be multiplied by an adjustment factor to produce an adjusted cost figure suitable for comparison with other shards. The adjustment factor may be based on the overall performance characteristics of the shard. Numerous performance and database metrics may be employed such as CPU speed memory capacity storage device read performance storage device write performance storage device seek time row count and duplication of data.

Execution plan contains a variety of operation types . Each operation type has an associated unadjusted cost which reflects the total cost of all operations of that type. Each unadjusted cost is adjusted by the use of an associated cost adjustment factor determined with reference to relevant statistics and performance characteristics . The set of statistics and performance characteristics used in the determination may vary according to the operation type with which the adjustment factor is associated. For example an adjustment factor associated with the hash access operation type might be adjusted based only on CPU speed or primarily on CPU speed with working set as a secondary consideration. Many other types of metrics may also be considered. In addition to relatively static measurements such as the amount of physical memory or CPU speed dynamic performance metrics may be collected and used. Various non limiting examples are working set CPU utilization average disk queue depth and so forth. Performance metrics collected by the execution engine may also be considered. In the database context various non limiting examples include cache coherence measurements average number of user sessions and various event log entries.

In various embodiments the optimized execution plan is periodically recalculated. Recalculation may be desirable due to changing conditions on the shards in the domain. For example during operation the shards may store additional data possibly resulting in a changed distribution of data throughout the domain of shards. If so what was once a globally optimized execution plan may have become inefficient and a new determination of a globally optimized execution plan may become desirable.

A new determination of a globally optimized execution plan may proceed in a manner similar to that employed initially. In an embodiment each shard recalculates its own locally optimized execution plan and the globally optimized plan is selected according to the various embodiments described herein. In some cases however it may be desirable to recalculate only a subset of locally optimized plans. In an embodiment each shard may determine a new locally optimized plan only if some set of characteristics such as table size has changed beyond a threshold amount.

The recalculation of the globally optimized execution plan may be triggered by a variety of events or conditions. For example it may be triggered on a periodic basis such as one per week. Alternatively it may be done on an opportunistic basis when one or more of the shards are idle. In one embodiment when a shard is otherwise idle it recalculates its locally optimized execution plan and triggers a recalculation of the globally optimized plan only if the cost of the locally optimized plan has significantly changed. Other trigger events for recalculation of the globally optimized plan include when the amount of data stored on a shard has changed significantly or when a shard s hardware configuration has changed.

One advantage of shard based architectures is that new shards can be added when additional capacity is needed. However the new shard may perform less than optimally while it builds up a cache of statistics and generates new execution plans. It would be advantageous for the new shard to be automatically populated with execution plans already determined to be globally optimized. Subsequently the new shard can calculate locally optimized execution plans and the embodiments described herein for determining globally optimized execution plans can then be performed in conjunction with the new shard.

In some instances a client application will issue queries that are executed more or less evenly across the shards in the system. This tends to occur when the application requests data that is evenly distributed across the horizontal partitions assigned to each shard. In other cases a client application may issue queries heavily skewed towards a single partition. In the latter case overall system performance may be improved by allowing an individual application to override the globally optimized execution plan for queries executed on its behalf.

In other embodiments the system may supply hints to a client application. A hint may include suggestions that influence generation of a execution plan and execution of the query itself. A hint may for example suggest that a full table scan is preferable to an index scan when a particular query is executed. Many other types of hints are both possible and contemplated. The hints supplied to the client application may be determined by a variety of means. In one embodiment potential hints are evaluated based on cost reduction. Hints that optimize the cost of repeated query execution across a domain are made available to the client application. The client may then include the supplied hint when it executes the query. When a shard receives the query it processes the hint and executes the query in a manner consistent with optimized performance of the domain. Those of ordinary skill in the art will recognize that the embodiments just described can be practiced in addition to or instead of other embodiments described in the present application.

Client applications may receive hints in a variety of ways. A broadcast system may be employed so as to send hints to one or more interested client applications. This approach has the advantage of being able to rebroadcast updates as new or different hints are generated. Alternatively each application may directly request available hints. Additional embodiments suitable to the particular hardware and software environment are also contemplated.

In further embodiments hints may be supplied from a shard based system to engineers and other technical staff. In an embodiment a shard may supply a hint indicating that its plan is significantly cheaper than the currently selected globally optimized plan suggesting that a recalculation of the globally optimized plan or an override of it may be desirable. Hints may be transmitted to users in a variety of ways. Non limiting examples include being stored on a hard drive accessible to the intended user sent via email or messaging or placed in a queue for later processing.

In other embodiments the system supplies hints for use by software engineering staff that allows optimization of client application programs. A hint may suggest that the engineer manually modify the queries sent from a client application to a shard based system. The hint may for example suggest that an index scan is preferable to a full table scan for a particular query according to a determination of a globally optimized execution plan. The software engineer might then modify the application causing it to issue queries more likely to conform to the desired globally optimized plan. In other embodiments hints may also be used to change other aspects of executing a query. For example the hints may indicate directly or indirectly that the query should be executed on a particular shard or that a particular shard should be avoided. The hints might also show that the query requires execution across multiple shards suggesting to personnel that a reformulation of the query is desirable.

At operation the shard based system receives and processes a query from a client application. A globally optimized execution plan is then generated at operation . However rather than directly causing the shards to adopt the query the system may send information about the globally optimized execution plan to engineering staff operation . The information may comprise a description or explanation of the execution plan sufficient to allow the engineer to make the desired modifications to the application. It may for example include a description of the optimized execution plan s set of instructions and the associated cost.

At operation the system receives a query modified according to the information provided in operation . A new query plan is then generated for the modified query operation . Because of the modifications made to the query the new execution plan is generated in a manner consistent with the desired globally optimized plan. To explain further a hint may indicate that a globally optimized execution plan would use full table scans instead of index scans even though an unmodified plan results in an index scan when it is processed by the query optimizer. The modified query includes instructions indicating to the query optimizer that full table scans are preferred. Therefore the query optimizer produces a execution plan using a full table scan and the resulting query is consistent with the desired globally optimized plan. After the new plan is generated the query may be executed using that plan operation .

For illustrative purposes some of the embodiments described herein refer to data management systems with horizontally partitioned data. However those of skill in the art will appreciate that aspects of the disclosure may be applied to systems that do not involve conventional databases. Examples include but are not limited to state machines and workflow engines. depicts an embodiment in which the global optimization techniques described herein may be applied. First and second computing nodes are capable of receiving and processing a common command . The command may be of any type provided it can be executed on multiple computing nodes in a domain and can be decomposed into a sequence of steps whose total cost can be estimated. State machines and workflow engines are examples of systems that process commands that fit these criteria. Both are comprised of a set of states with associated transitions. Performing a query comprises a set of transitions from a current state to a state in which the command has been executed. Any shard capable of reaching the command complete state is able to process the command and the cost of doing so may be estimated based on the estimated cost of all transitions required to reach that state. An execution engine may perform the query by causing a desired set of transitions to occur following an optimized or otherwise preferred plan chosen for example by a query optimizer. The data managed by each shard may manage a partition of a partitioned data set so that the domain of shards collectively manages the entire set. The partitions may be overlapping so that some or even all of the data is duplicated between shards. A data set may comprise any type of data including but not limited to tables vectors arrays graphs and so on.

The sequence of steps and the predicted costs are determined by local optimizer . Comparison module compares the predicted cost of the two plans with reference to factors such as execution statistics relative hardware performance characteristics and the relative frequency with which each system executes the common command. The result of the comparison is a preferred execution plan which may be utilized by execution engine as depicted by the connecting arrows between preferred execution plan and execution engine . Other various embodiments for using a preferred plan such as in conjunction with supplying hints to applications or technical support staff may also be employed.

Each of the processes methods and algorithms described in the preceding sections may be embodied in and fully or partially automated by code modules executed by one or more computers or computer processors. The code modules may be stored on any type of non transitory computer readable medium or computer storage device such as hard drives solid state memory optical disc and or the like. The processes and algorithms may be implemented partially or wholly in application specific circuitry. The results of the disclosed processes and process steps may be stored persistently or otherwise in any type of non transitory computer storage such as e.g. volatile or non volatile storage.

The various features and processes described above may be used independently of one another or may be combined in various ways. All possible combinations and subcombinations are intended to fall within the scope of this disclosure. In addition certain method or process blocks may be omitted in some implementations. The methods and processes described herein are also not limited to any particular sequence and the blocks or states relating thereto can be performed in other sequences that are appropriate. For example described blocks or states may be performed in an order other than that specifically disclosed or multiple blocks or states may be combined in a single block or state. The example blocks or states may be performed in serial in parallel or in some other manner. Blocks or states may be added to or removed from the disclosed example embodiments. The example systems and components described herein may be configured differently than described. For example elements may be added to removed from or rearranged compared to the disclosed example embodiments.

It will also be appreciated that various items are illustrated as being stored in memory or on storage while being used and that these items or portions of thereof may be transferred between memory and other storage devices for purposes of memory management and data integrity. Alternatively in other embodiments some or all of the software modules and or systems may execute in memory on another device and communicate with the illustrated computing systems via inter computer communication. Furthermore in some embodiments some or all of the systems and or modules may be implemented or provided in other ways such as at least partially in firmware and or hardware including but not limited to one or more application specific integrated circuits ASICs standard integrated circuits controllers e.g. by executing appropriate instructions and including microcontrollers and or embedded controllers field programmable gate arrays FPGAs complex programmable logic devices CPLDs etc. Some or all of the modules systems and data structures may also be stored e.g. as software instructions or structured data on a computer readable medium such as a hard disk a memory a network or a portable media article to be read by an appropriate drive or via an appropriate connection. The systems modules and data structures may also be transmitted as generated data signals e.g. as part of a carrier wave or other analog or digital propagated signal on a variety of computer readable transmission media including wireless based and wired cable based media and may take a variety of forms e.g. as part of a single or multiplexed analog signal or as multiple discrete digital packets or frames . Such computer program products may also take other forms in other embodiments. Accordingly the present invention may be practiced with other computer system configurations.

Conditional language used herein such as among others can could might may e.g. and the like unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments include while other embodiments do not include certain features elements and or steps. Thus such conditional language is not generally intended to imply that features elements and or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without author input or prompting whether these features elements and or steps are included or are to be performed in any particular embodiment. The terms comprising including having and the like are synonymous and are used inclusively in an open ended fashion and do not exclude additional elements features acts operations and so forth. Also the term or is used in its inclusive sense and not in its exclusive sense so that when used for example to connect a list of elements the term or means one some or all of the elements in the list.

While certain example embodiments have been described these embodiments have been presented by way of example only and are not intended to limit the scope of the inventions disclosed herein. Thus nothing in the foregoing description is intended to imply that any particular feature characteristic step module or block is necessary or indispensable. Indeed the novel methods and systems described herein may be embodied in a variety of other forms furthermore various omissions substitutions and changes in the form of the methods and systems described herein may be made without departing from the spirit of the inventions disclosed herein. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of certain of the inventions disclosed herein.

