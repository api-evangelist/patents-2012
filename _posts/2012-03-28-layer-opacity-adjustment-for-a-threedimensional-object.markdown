---

title: Layer opacity adjustment for a three-dimensional object
abstract: Computer-implemented methods for automatically adjusting an opacity of layers in a three-dimensional (3D) object are provided. In one aspect, a method includes receiving a request to display data for a 3D object having a plurality of layers, and providing, for display, data for a view of the 3D object. An opacity of each of the layers of the 3D object in the view is adjusted based on a position of the view of the 3D object. Systems and machine-readable media are also provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08314790&OS=08314790&RS=08314790
owner: Google Inc.
number: 08314790
owner_city: Mountain View
owner_country: US
publication_date: 20120328
---
The present application claims the benefit of priority under 35 U.S.C. 119 from U.S. Provisional Patent Application Ser. No. 61 469 038 entitled Searchable 3D Object Viewer filed on Mar. 29 2011 the disclosure of which is hereby incorporated by reference in its entirety for all purposes.

The present disclosure generally relates to the visualization of three dimensional objects using a computer.

Current three dimensional 3D rendering systems display 3D objects in a 3D space and allow the objects to be viewed from viewpoints surrounding the 3D object. However these conventional systems typically require the installation of specialized software in order to permit the 3D object to be displayed in the 3D space. Furthermore if the 3D object has many distinct features and or layers it may be very difficult to locate the distinct features or visualize the distinct layers let alone locate distinct features on each distinct layer of the 3D object. For example it is difficult to adjust the opacity of the layers and features of the 3D object in order to easily view a portion of the 3D object.

According to one embodiment of the present disclosure a computer implemented method for automatically adjusting an opacity of layers in a three dimensional 3D object is provided. The method includes receiving a request to display data for a 3D object having a plurality of layers and providing for display data for a view of the 3D object. An opacity of each of the layers of the 3D object in the view is adjusted based on a position of the view of the 3D object.

In certain embodiments of the method an opacity of a layer of the 3D object within the view is adjusted based on the proximity of the layer to the view. In certain embodiments of the method the method further includes providing data for another view of the 3D object in response to a request from a user wherein a transition from the view of the 3D object to the other view of the 3D object includes adjusting an opacity of at least one of the plurality of layers of the 3D object based on the transition. In certain embodiments of the method the opacity of the at least one layer is adjusted during the transition. In certain embodiments of the method the opacity of the at least one layer is adjusted after the transition. In certain embodiments of the method the method further includes providing data for another view of the 3D object in response to a request from a user wherein a transition from the view of the 3D object to the other view of the 3D object includes passing through at least one of the plurality of layers of the 3D object. In certain embodiments of the method during the transition from the view of the 3D object to the other view of the 3D object an opacity of the at least one of the plurality of layers that is passed through is decreased. In certain embodiments of the method another layer that increases in distance from the other view during the transition from the view is increased in opacity. In certain embodiments of the method the method further includes retrieving from storage and displaying within the view of the 3D object at least one identification label associated with at least one portion of the 3D objection within the view based on input received from the user. In certain embodiments of the method the method further includes adjusting a position and an opacity of the identification label within the view based on the input received from the user. In certain embodiments of the method the method further includes providing data for another view of the 3D object in response to a request from a user wherein the position and the opacity of the identification label within the other view is adjusted based on the position of the other view of the 3D object. In certain embodiments of the method the layer of the 3D object that is both within the view and furthest from the view remains substantially opaque and wherein another layer outside of the view becomes substantially transparent. In certain embodiments of the method the method further includes generating for display a layer opacity adjustment interface for the 3D object the interface includes at least one slide indicator receiving a request to move a position of the slide indicator and adjusting an opacity level of the layer of the 3D object based on the position movement of the slide indicator. In certain embodiments of the method the slide indicator is a vertical slide indicator configured to move along a first axis and the position of the vertical slide indicator along the first axis is configured to affect the opacity of each of the layers of the 3D object. In certain embodiments of the method the adjustment interface includes a layer indicator for each layer displayed along the first axis and movement of the vertical slide indicator across a layer indicator includes an adjustment of an opacity level of the layer indicated by the layer indicator. In certain embodiments of the method the opacity adjustment interface further includes a horizontal slide indicator for each layer indicator each horizontal slide indicator is configured to move across the layer indicator along a second axis that is different than the first axis movement of each horizontal slide indicator across a layer indicator along the second axis includes an adjustment of an opacity level of the layer indicated by the layer indicator and the position of each horizontal slide indicator is limited to affecting the opacity of the corresponding layer with which the horizontal slide indicator is associated.

According to another embodiment of the present disclosure a system for automatically adjusting an opacity of layers in a three dimensional 3D object is provided. The system includes a memory that includes data for a 3D object having a plurality of layers and a processor. The processor is configured to receive a request to display data for the 3D object and provide for display data for a view of the 3D object. An opacity of each of the layers of the 3D object in the view is adjusted based on a position of the view of the 3D object. An opacity of at least one layer of the 3D object within the view is adjusted based on the proximity of the at least one layer to the view.

In certain embodiments of the system the processor is further configured to provide data for another view of the 3D object in response to a request from a user wherein a transition from the view of the 3D object to the other view of the 3D object includes the processor being configured to adjust an opacity of at least one of the plurality of layers of the 3D object based on the transition. In certain embodiments of the system the processor is further configured to provide data for another view of the 3D object in response to a request from a user wherein a transition from the view of the 3D object to the other view of the 3D object includes passing through at least one of the plurality of layers of the 3D object. In certain embodiments of the system during the transition from the view of the 3D object to the other view of the 3D object an opacity of the at least one of the plurality of layers that is passed through is decreased. In certain embodiments of the system the processor is further configured to retrieve from storage and display within the view of the 3D object at least one identification label associated with at least one portion of the 3D objection within the view based on input received from the user. In certain embodiments of the system the processor is further configured to provide data for another view of the 3D object in response to a request from a user wherein the position and the opacity of the identification label within the other view is adjusted based on the position of the other view of the 3D object. In certain embodiments of the system the layer of the 3D object that is both within the view and furthest from the view remains substantially opaque and wherein another layer outside of the view becomes substantially transparent. In certain embodiments of the system the processor is further configured to generate for display a layer opacity adjustment interface for the 3D object the interface includes at least one slide indicator receive a request to move a position of the slide indicator and adjust an opacity level of at least one of the layers of the 3D object based on the position movement of the slide indicator. In certain embodiments of the system the slide indicator is a vertical slide indicator configured to move along a first axis and the position of the vertical slide indicator along the first axis is configured to affect the opacity of each of the layers of the 3D object. In certain embodiments of the system the adjustment interface includes a layer indicator for each layer displayed along the first axis and movement of the vertical slide indicator across a layer indicator includes an adjustment of an opacity level of the layer indicated by the layer indicator. In certain embodiments of the system the opacity adjustment interface further includes a horizontal slide indicator for each layer indicator each horizontal slide indicator is configured to move across the layer indicator along a second axis that is different than the first axis movement of each horizontal slide indicator across a layer indicator along the second axis includes an adjustment of an opacity level of the layer indicated by the layer indicator and the position of each horizontal slide indicator is limited to affecting the opacity of the corresponding layer with which the horizontal slide indicator is associated.

According a further embodiment of the present disclosure a machine readable storage medium includes machine readable instructions for causing a processor to execute a method for automatically adjusting an opacity of layers in a three dimensional 3D object is provided. The method includes receiving a request to display data for a 3D object having a plurality of layers and providing for display data for a view of the 3D object. The method also includes providing data for another view of the 3D object in response to a request from a user. A transition from the view of the 3D object to the other view of the 3D object includes adjusting an opacity of at least one of the plurality of layers of the 3D object based on the transition.

According to one embodiment of the present disclosure computer implemented method for adjusting an opacity of layers in a layered three dimensional 3D object is provided. The method includes generating for display a layer opacity adjustment interface for a 3D object having at least one layer wherein the interface includes at least one slide indicator and receiving a request to move a position of the slide indicator. The method also includes adjusting an opacity level of the layer of the 3D object based on the position movement of the slide indicator.

In certain embodiments of the method the 3D object includes multiple layers the slide indicator is a vertical slide indicator configured to move along a first axis and the position of the vertical slide indicator along the first axis is configured to affect the opacity of each of the layers of the 3D object. In certain embodiments of the method the adjustment interface includes a layer indicator for each layer displayed along the first axis and wherein movement of the vertical slide indicator across a layer indicator includes an adjustment of an opacity level of the layer indicated by the layer indicator. In certain embodiments of the method the layer indicators are displayed along the first axis in an order indicative of an order in which the layers are generated for display for the 3D object. In certain embodiments of the method when the vertical slide indicator is positioned at one end of the first axis each of the layers is substantially opaque and when the vertical slide indicator is positioned at the other end of the first axis each of the layers in substantially transparent. In certain embodiments of the method each layer indicator is represented by an image indicative of the associated layer. In certain embodiments of the method the opacity adjustment interface further includes a horizontal slide indicator for each layer indicator each horizontal slide indicator is configured to move across the layer indicator along a second axis that is different than the first axis movement of each horizontal slide indicator across a layer indicator along the second axis includes an adjustment of an opacity level of the layer indicated by the layer indicator and the position of each horizontal slide indicator is limited to affecting the opacity of the corresponding layer with which the horizontal slide indicator is associated. In certain embodiments of the method when a horizontal slide indicator is positioned at one end of the second axis the corresponding layer is substantially opaque and when the horizontal slide indicator is positioned at the other end of the second axis the corresponding layer is substantially transparent. In certain embodiments of the method the adjustment interface is limited to generating a first mode for displaying the vertical slide indicator or a second mode for displaying the horizontal slide indicators. In certain embodiments of the method the adjustment interface includes a switching mechanism for switching between the first mode and the second mode.

According to another embodiment of the present disclosure system for generating an adjustment interface for adjusting an opacity of layers in a layered three dimensional object is provided. The system includes a memory that includes instructions and a processor. The processor is configured to execute the instructions to generate for display a layer opacity adjustment interface for a 3D object includes multiple layers wherein the interface includes at least one slide indicator and receive a request to move a position of the slide indicator. The processor is also configured to execute the instructions to adjust an opacity level of at least one of the layers of the 3D object based on the position movement of the slide indicator.

In certain embodiments of the system the slide indicator is a vertical slide indicator configured to move along a first axis and the position of the vertical slide indicator along the first axis is configured to affect the opacity of each of the layers of the 3D object. In certain embodiments of the system the adjustment interface includes a layer indicator for each layer displayed along the first axis and wherein movement of the vertical slide indicator across a layer indicator includes an adjustment of an opacity level of the layer indicated by the layer indicator. In certain embodiments of the system the layer indicators are displayed along the first axis in an order indicative of an order in which the layers are generated for display for the 3D object. In certain embodiments of the system when the vertical slide indicator is positioned at one end of the first axis each of the layers is substantially opaque and when the vertical slide indicator is positioned at the other end of the first axis each of the layers in substantially transparent. In certain embodiments of the system each layer indicator is represented by an image indicative of the associated layer. In certain embodiments of the system the opacity adjustment interface further includes a horizontal slide indicator for each layer indicator each horizontal slide indicator is configured to move across the layer indicator along a second axis that is different than the first axis movement of each horizontal slide indicator across a layer indicator along the second axis includes an adjustment of an opacity level of the layer indicated by the layer indicator and the position of each horizontal slide indicator is limited to affecting the opacity of the corresponding layer with which the horizontal slide indicator is associated. In certain embodiments of the system when a horizontal slide indicator is positioned at one end of the second axis the corresponding layer is substantially opaque and when the horizontal slide indicator is positioned at the other end of the second axis the corresponding layer is substantially transparent. In certain embodiments of the system the adjustment interface is limited to generating a first mode for displaying the vertical slide indicator or a second mode for displaying the horizontal slide indicators and wherein the adjustment interface includes a switching mechanism for switching between the first mode and the second mode.

According to a further embodiment of the present disclosure machine readable storage medium includes machine readable instructions for causing a processor to execute a method for adjusting an opacity of layers in a layered three dimensional object is provided. The method includes generating for display a layer opacity adjustment interface for a 3D object having multiple layers. The adjustment interface includes a vertical slide indicator configured to move along a first axis wherein the position of the vertical slide indicator along the first axis is configured to affect the opacity of each of the layers of the 3D object and a layer indicator for each layer displayed along the first axis wherein movement of the vertical slide indicator across a layer indicator includes an adjustment of an opacity level of the layer indicated by the layer indicator. The adjustment interface also includes a horizontal slide indicator for each layer indicator that is configured to move across the layer indicator along a second axis that is different than the first axis wherein movement of each horizontal slide indicator across a layer indicator along the second axis includes an adjustment of an opacity level of the layer indicated by the layer indicator and wherein the position of each horizontal slide indicator is limited to affecting the opacity of the corresponding layer with which the horizontal slide indicator is associated. The method also includes receiving a request to move a position of the vertical slide indicator or the horizontal slide indicator and adjusting an opacity level of a layer of the 3D object based on the position movement of the vertical slide indicator or the horizontal slide indicator.

It is understood that other configurations of the subject technology will become readily apparent to those skilled in the art from the following detailed description wherein various configurations of the subject technology are shown and described by way of illustration. As will be realized the subject technology is capable of other and different configurations and its several details are capable of modification in various other respects all without departing from the scope of the subject technology. Accordingly the drawings and detailed description are to be regarded as illustrative in nature and not as restrictive.

In the following detailed description numerous specific details are set forth to provide a full understanding of the present disclosure. It will be apparent however to one ordinarily skilled in the art that the embodiments of the present disclosure may be practiced without some of these specific details. In other instances well known structures and techniques have not been shown in detail so as not to obscure the disclosure.

The disclosed system uses a web browser with integrated e.g. built in 3D modeling and searching capabilities for viewing and searching a 3D image or object such as a web browser pre installed with WebGL. Using the enhanced web browser the user can view search and transcend layers of the 3D image each view having a separate Uniform Resource Locator URL . For example a user viewing a 3D model of the human body can start from an external view of the liver and transcend layer by layer through the liver in order to view a bile duct with each layer automatically adjusting in opacity based on the user s current view. The user can stop at any layer level and investigate in detail the human body and use search queries alphanumeric or otherwise to locate certain details. A user s view of the 3D human body can roam over the surface at a given layer or gradually transcend from one layer to another in a seamless fashion such as by transcending from one layer structure to another by making the current layer structure more transparent as the user leaves that layer structure on the journey to the next layer structure or the user s view can traverse through the layers.

The servers can be any device having an appropriate processor memory and communications capability for hosting the searchable data of the 3D object and related content. The clients to which the servers are connected over the network can be for example desktop computers mobile computers tablet computers mobile devices e.g. a smartphone or PDA set top boxes e.g. for a television video game consoles or any other devices having appropriate processor memory and communications capabilities. The network can include for example any one or more of a personal area network PAN a local area network LAN a campus area network CAN a metropolitan area network MAN a wide area network WAN a broadband network BBN the Internet and the like. Further the network can include but is not limited to any one or more of the following network topologies including a bus network a star network a ring network a mesh network a star bus network tree or hierarchical network and the like.

Each of the clients is configured to receive part or all of the searchable data of the 3D object and display the searchable data to a user of the client for the user to view in a 3D space search edit and annotate. The user can view at varying levels of detail the 3D object from a position at any point outside or inside of the object and can move the position of the view using an input device such as a keyboard mouse or a touchscreen. The user can also to choose adjust the opacity of portions of the 3D object such as by reducing the opacity of a surface layer to zero in order to see through the surface layer and view an inner layer. The user can further search the 3D object by entering a query. For example when the user types lung the opacity of the skin muscular and skeletal layers of a 3D human body is reduced and the position of the view is adjusted so that the user can see a lung. These features will be discussed in more detail herein below.

The searchable data of the 3D object is retrieved by the client from the server using a 3D enhanced application such as a web browser or mobile application. The 3D enhanced web browser includes an integrated 3D modeling and searching capability that is built in to the web browser e.g. a part of the web browser by default as a standard at the time the web browser is downloaded and installed on the client . An exemplary 3D modeling and searching capability is provided by WebGL a 3D graphics application programming interface. Exemplary 3D enhanced web browsers include web browsers pre installed with WebGL.

The server includes a processor the communications module and a memory . The memory includes viewable and searchable data of the 3D object searchable data of the 3D object a web page for instructing a 3D enhanced web browser on how to model and search the 3D object hereinafter object browser web page using the searchable data of the 3D object and user generated content related to the searchable data of the 3D object . The client includes a processor the communications module an input device an output device and a memory . The memory of the client includes the 3D enhanced web browser and optionally includes a local copy of the object browser web page and a local copy of the searchable data of the 3D object . Thus the object browser web page and the searchable data of the 3D object can be locally stored or remotely stored. A determination of whether to store a local copy of the object browser web page and a local copy of the searchable data of the 3D object can be made by the 3D enhanced web browser . For example the 3D enhanced web browser can include a setting of whether to store files in a local cache or the object browser web page itself can determine for example to stream only necessary information from the searchable data of the 3D object to the client and not store it in the memory of the client.

The local copy of the object browser web page and the local copy of the searchable data of the 3D object are loaded into the memory of the client after a user of the client hereinafter simply the user selects the web address for the object browser web page in the 3D enhanced web browser and the 3D enhanced web browser sends a request to the server for the object browser web page and related searchable data of the 3D object . The processor of the server is configured to receive the request from the 3D enhanced web browser and provide to the 3D enhanced web browser of the client in response to the request the searchable data of the 3D object and the object browser web page . The client can then store the local copy of the object browser web page and the local copy of the searchable data of the 3D object in its memory . In the alternative the web browser of the client downloads the searchable data of the 3D object on demand e.g. streaming and or an initial portion of the searchable data of the 3D object is stored locally e.g. as the local copy of the searchable data of the 3D object to begin the display of the 3D object on the output device and the remaining portion of the searchable data of the 3D object is downloaded as requested or needed by the 3D enhanced web browser for display on the output device .

The processor of the client is configured to execute instructions such as instructions physically coded into the processor instructions received from software in memory or a combination of both. For example the processor of the client is configured to execute instructions from the local copy of the object browser web page causing the processor to display in the 3D enhanced web browser on the output device at least a portion of the 3D object based on an initial default view or a user selected view based on a query received from the user using the input device . As discussed herein in more detail a view of the 3D object can include features to provide an opacity of the different portions of the 3D object rotation of the 3D object zoom whether any portion of the 3D object has been selected the state of any interfaces displayed parameters related to customization of the 3D object generated by a user and any annotations on the 3D object. The output device can be a computer display such as a touch screen display. The query can be an alphanumeric input such as liver or 2 for cervical spinal nerve 2 or input from an input device . Similarly the query can be an alphanumeric input indirectly related to a portion of the 3D object e.g. for a human body the entry cirrhosis can map to the liver based on for example pre defined mappings user generated contents or implicit connections such as prior user history. Exemplary input devices include a keyboard mouse or touch screen display. Using the input device the user can view any portion of the 3D object in the 3D enhanced web browser from any angle at any position inside or outside the 3D object. The user can also use the input device to search the 3D object and create edit and delete user generated content related to the 3D object that is displayed on the output device .

Although the block diagram illustrates in the same memory of a single server the searchable data of the 3D object the user generated content and the object browser web page the searchable data of the 3D object the user generated content and the object browser web page can be in different memories and or on different servers as discussed above with reference to .

The process begins by proceeding from step to step when the user of a client loads the 3D enhanced web browser and enters an address such as a Uniform Resource Locator URL for the viewable and searchable 3D object web page. In step the 3D enhanced web browser sends a request to the server for the web page and its related searchable data of the 3D object . In step the server receives the request. A copy of the searchable data of the 3D object is available on the server to provide in response to the request.

The copy of the related searchable data of the 3D object and a copy of web page is provided in step by the server in response to the request from the client to the 3D enhanced web browser on the client . In step the client obtains the copy of the web page and a copy of the searchable data of the 3D object via the 3D enhanced web browser . A local copy of the web page and a local copy of the searchable data of the 3D object are stored in the memory of the client . In step the client uses a monitor to display the exemplary screenshot of an initial default view of the 3D object loaded in the 3D enhanced web browser as shown in and the process ends in step .

Having obtained searchable data of the 3D object at the client from the server using the 3D enhanced web browser illustrates a screenshot of an initial default view of a 3D object as displayed on the output device . In exemplary the 3D object is a human body. The initial default view shows an outer surface of a portion of a 3D object a female human body and more specifically the outside of a clothed female human body including skin. Although a female human body is used in the screenshots a male human body can also be used. Furthermore although a human body is used in the screenshots another 3D object could be used.

The user interface of includes the 3D object an input field for entering a query to be searched a position control for moving the position of the current view a zoom control for adjusting the zoom of the current view and an opacity adjustment interface hereinafter referred to as slider having a movable indicator for adjusting the opacity of the outer surface and or internal structures collectively referred to as layers of the 3D object . As discussed herein the outer surface includes but is not limited to the skin and portions of the body near to or in contact with the external surface of the skin such as eyes hair teeth ears nails and lips. The internal structures include but are not limited to inner anatomical layers biological systems and organs down to the tissues cells and molecular structures such as DNA or proteins.

Any part of the 3D object whether as a whole or in part let alone any part of the outer surface or the internal structures are often referred to herein as portions or items of the 3D object and can be displayed by the 3D enhanced web browser using the searchable data of the 3D object . Furthermore in addition to the displayed user interface controls and the user can use the input device illustrated by cursor to change the position of the view and the level of zoom of the view of the 3D object to view any portion of the 3D object from any angle e.g. not limited to any axis . For example the user can view the heart from the outside of the heart or the inside of the heart. As another example the user can press and hold a button on a mouse input device while dragging the cursor across the screen in any direction in order to rotate the 3D object in that direction.

In certain aspects the 3D object is viewable using a modified axial navigation model. Vertical user camera position control e.g. up and down mouse gestures or keystrokes shifts the 3D object vertically in the view and horizontal user camera position control e.g. left and right mouse gestures or keystrokes rotate the 3D object horizontally. The axial navigation model allows significant visibility of a vertically oriented model without the navigational complexity and disorientation that can occur in 3D displays with more degrees of navigational freedom. As such the 3D object can be a vertically or horizontally oriented model. In order to facilitate viewing of the top or bottom of a vertically oriented 3D object presented axially an additional feature added to the camera view modifies the navigational surface of the 3D object from which the camera view is positioned. Specifically instead of a limited X Y navigation over a notional cylinder the navigational surface of a vertically oriented 3D object is a cylinder with hemispherical ends e.g. at the top and bottom . The modification permits viewing of the top or bottom of a vertically oriented 3D object while retaining the navigational simplicity of the X Y model.

Any internal structure or portion of the 3D object can be rendered by the 3D enhanced web browser and viewed from any position using the searchable data of the 3D object including with reference to a human body inner anatomical layers biological systems organs tissues cells and molecular structures.

The processor of the client is configured to retrieve either from the local copy of the searchable data of the 3D object on the client or the searchable data of the 3D object on the server sufficient searchable data to render the 3D object in response to a query from the user. For example based on the position of the user s cursor and the associated changing of the view of the 3D object the searchable data or is being retrieved from the memory on the client or the memory of the server for processing by the processor and display on the output device . In certain aspects the amount of searchable data or retrieved depends on the position of the cursor e.g. within the 3D space and the current view.

In certain aspects the searchable data of the 3D object is retrieved from the memory of the server for storage on the client all at once as discussed above with reference to . In certain aspects the searchable data of the 3D object is streamed from the memory of the server as needed by the processor of the client for displaying on the output device to render the 3D object in response to a query from the user.

Specifically the level of detail of the displayed portion of the 3D object can be streamed to the client for display by the processor based on the proximity of the user s current view to the portion of the 3D object . In certain aspects lower resolution textures of the 3D object are first downloaded by the client and higher resolution textures are later downloaded if the user s current view increases in proximity to a portion of the 3D object . Furthermore levels of detail need only be downloaded once. For example if a lower resolution texture A is downloaded for a portion of the 3D object and it is followed by a download of a higher resolution texture B for the same portion the higher resolution view of the portion of the 3D object is synthesized incrementally by the higher resolution texture B being limited to the difference from the lower resolution texture A e.g. texture B is added into texture A . This is accomplished using standard web browser image file formats and scripting capabilities.

By way of example the current view in shows the external surface of the 3D object the human body where the human heart would not normally be visible. Accordingly the processor based on instructions from the local copy of the object browser web page can request that only the searchable data for the outer surface of the 3D object be provided to the client in order to render the current view. If the user changes the current view to another view e.g. of the human heart or requests a more detailed rendering of the current view either of which requiring additional searchable data of the 3D object for rendering then that additional searchable data can be streamed from the server to the client for rendering.

In certain aspects the 3D object can be previewed using two dimensional 2D previewing. The server can rotate the 3D object in increments and capture a view from each position as an image. The images can then be appended together for example using a thumbnail strip thumbstrip graphic. The sequence of images can then be provided for presentation in an application that does not have integrated 3D modeling and searching capabilities. The sequence of images when displayed sequentially would appear as a 2D movie of the associated rotation of the 3D object .

The initial default view is associated with the URL displayed http viewableandsearchableobject body.html . The address or URL for each view also referred to as a bookmark is unique to the view and can be shared with other users to allow the other users to see the same view the sharing user sees. The bookmark captures the view of the 3D object in a URL and includes parameters identifying the view such as an amount of time to display the view the opacity of the layers of the 3D object rotation of the 3D object zoom whether any portion of the 3D object has been selected the state of the slider parameters related to customization of the 3D object generated by a user and any annotations on the 3D object . In certain aspects these parameters are included after a hash symbol in the URL . When parameters of the 3D view change e.g. portions are selected deselected portions change opacity the position of the view changes the parameters in the URL are updated. In certain aspects the update occurs after a predetermined amount of time in order to avoid creating a significant number of URL entries e.g. in the URL storage history of the web browser . Such state representation within the URL allows for navigation back to previous views by pressing a previous page view button in the web browser e.g. a practical form of undo without having to implement an undo mechanism .

The bookmark can also be shared with another user by sending a link to the URL e.g. URL to the other user by for example simply copying the URL and pasting it into an email. When the other user loads the shared URL in a 3D enhanced web browser the other user will see the same view seen by the user who shared the URL.

Returning to which illustrates the slider in a global adjustment mode designated by a first selection of the selection mechanism the slider includes a vertical slide indicator configured to move along a y axis. The position of the vertical slide indicator along the y axis jointly affects the opacity of portions of the 3D object . For example when the vertical slide indicator is at an uppermost position as illustrated in all portions of the 3D object are opaque and the view is limited to the external surface of the 3D object . As the vertical slide indicator moves down the y axis of the slider portions of the 3D object become less opaque in order of inward movement e.g. first the skin becomes less opaque then the muscular system becomes less opaque and so on until the nervous system is made less opaque. When the vertical slide indicator moves up the y axis of the slider portions of the 3D object become more opaque in the opposite order that they were made less opaque when the vertical slide indicator moved down the y axis of the slider .

Returning to which illustrates the slider in the individual adjustment mode designated by a second selection of the selection mechanism the slider includes the horizontal slide indicators configured to move along the x axis. The position of the horizontal slide indicators in reflects the specific opacity of their respective 3D human body portions from the screenshot of . In the horizontal slide indicator for the skin the horizontal slide indicator for the muscular system the horizontal slide indicator for the skeletal system the horizontal slide indicator for the organ system the horizontal slide indicator for the circulatory system and horizontal slide indicator for the nervous system are in the rightmost position indicating that the skin the muscular system the skeletal system the organ system the circulatory system and the nervous system of the 3D object are completely opaque. However each of these layers is configured to become less opaque i.e. more transparent as their corresponding horizontal slide indicator moves towards the left. If a horizontal slide indicator is in a leftmost position the corresponding layer is transparent i.e. not opaque . Similarly if a horizontal slide indicator is in an intermediate position between a leftmost position and a rightmost position the corresponding layer would be partially opaque.

In certain aspects not illustrated both the vertical slide indicator and the horizontal slide indicators can be displayed together such that the adjustment of one type of indicator on the slider automatically affects the position of the other type of indicator on the slider . Furthermore although slide indicators are disclosed as being vertical or horizontal slide indicators can be provided in various other directions along various other axes or without a single axes.

The input field is configured to provide the features of navigation via searching autocompletion and instant navigation via autocompletion. With navigation via searching as the user begins entering a query into the input field the current view of the camera is adjusted to display the first term matching the currently entered query in the input field. For example as the user types the query liver the intermediate query 1 identifies the shortest matching term lung and changes the current view to a view of the lung. When the intermediate query becomes li the shortest matching term liver is identified and the current view changes to a view of the liver as illustrated in .

Autocompletion provides the user with suggested or computer generated results displayed below the input field that match the user s currently entered query in the input field . For example as the user types the query liver the intermediate query 1 identifies suggested results in order of word length of lung liver lunate lacriminal lumbrical levator ani lumbar disc longus colli fan ligament and fibrous loop. In certain aspects the suggested results can be listed in order of popularity. If the user cycles through the identified suggested results such as by using the keyboard cursor to select any of these results the current view of the 3D object will change from viewing one identified suggested result to the next e.g. from a view of the liver to a view of the lunate which is known as instant navigation via autocompletion. After the user types i to make the intermediate query li a single suggested result of liver is identified as illustrated in .

When the position of the current view of the 3D object changes in response to a query that is received from the user the position can pass through transverse or transcend through the layers e.g. transcending can include both ascending through a layer or descending through a layer . At the same time the opacity of the layers of the 3D object changes.

For example returning to the exemplary screenshot from the current view is of the outer surface of the 3D object . The layers of the 3D object are completely opaque as illustrated by the position of the indicator on the slider which is at an uppermost position. When the current view transcends from an external layer through the external layer to an internal layer or more specifically from the outer surface of the 3D object through to an internal structure the liver in in response to the query liver the opacity of the layers of the 3D object are automatically changed to facilitate viewing of the liver. During this process the view displays to the user a transcending through the three most external layers the skin the muscular system and the skeletal system as those layers are made less opaque so that the layer at which the liver is present the organ system is more viewable to the user. The processor is configured to adjust based on the position of the user s current view of the 3D object the level of opacity of the layers and the processor is further configured to transcend the current view from a first point on one side of a layer through the layer to a second point on the other side of the layer. The transition does not however require that the view of the 3D object pass through a layer of the 3D object.

An opacity of a layer of the 3D object within the view can be adjusted based on the proximity of the layer to the view. The view transcending to the second point having a second view causes the opacity of the layers of the 3D object to be adjusted based on the transition. The opacity of the at least one layer can be adjusted during the transition or after the transition. The opacity of the layer that is passed through can be decreased as a result of the transition and another layer that increases in distance from the other view during the transition from the view can be increased in opacity. In certain aspects the layer of the 3D object that is both within the view and furthest from the view remains substantially opaque e.g. the inner most layer of the 3D object and wherein another layer outside of the view becomes substantially transparent e.g. a layer outside the current view of the 3D object . The position and opacity of any portion of the 3D object within the view can also be adjusted based on view of the 3D object and also based on a transition from one view of the 3D object to another view of the 3D object .

The opacity configuration of the layers after the transcending through layers is shown by the position of the indicator of the slider in which has moved down in position as compared to the position of the indicator in . The layers in the slider above the position of the indicator are less opaque or not opaque at all and the layers in the slider below the position of the indicator are more opaque or completely opaque.

When a portion of the 3D object is selected it is made more opaque solid than neighboring portions of the 3D object and an appropriate label e.g. in the context of the human body medical label for the selected portion is displayed. In certain aspects multiple portions of the 3D human can be selected either simultaneously or serially. A portion or multiple portions of the 3D object can be selected in response to a query by a user whether the query is a search using the input field or a selection or using a input pointing device e.g. by clicking with a mouse or by using a lasso type pointer or using marquee selection .

In certain aspects the selection of multiple portions of the 3D object can be selected by rendering the portions e.g. model entities of the 3D object in distinct flat colors in an off screen buffer and then checking the pixel color under the cursor position. Multiple levels of selection can exist such as for example when a portion s of the 3D object is selected the remaining portions of the 3D object are made translucent on a first level and the selected portion s are made opaque on a second level. The user can choose between levels of selection via a user interface gesture such as for example by again selecting e.g. via a mouse click the selected portion of the 3D object .

The query by the user can include use of a selection tool that allows selection of one or multiple portions of the 3D object and that can further allow the user to select one or multiple portions of the 3D human body to hide or otherwise reduce the visibility of those portions so as to better view other portions that were obscured by the now hidden portions. In certain aspects a selected portion of the 3D object can be fixed to a certain opacity level e.g. completely opaque or completely transparent by selecting that portion selecting a label associated with that portion and or switching to a pin mode. In pin mode an additional interface can be provided that allows portions of the 3D object to be pinned e.g. fixed to a certain opacity level pinned portions of the 3D object to be highlighted pinned portions of the 3D object to be listed e.g. which checkboxes to pin un pin portions of the 3D object and groups of pinned portions of the 3D object to be unpinned.

In certain aspects the user can select and isolate any portion of the 3D object for viewing. For example the user can select a user defined portion of the forearm of the 3D object using a lasso type tool and make the rest of the 3D object transparent and then view the user defined portion of the forearm from any angle. This is accomplished for example using selection specific navigation. In certain aspects selection specific navigation extends axial model navigation by generating a bounding box around one or more selected entities e.g. selected via search or mouse click . A navigational surface such as a cylindrical or bihemispherical surface is fitted to the bounding box. Thus when a user selects a portion of the 3D object the user is automatically zoomed in to a closer view of the selected portion of the 3D object that centers upon the selected portion. The remaining portions of the 3D object can be made more transparent e.g. invisible thereby allowing the user to focus on the selected portion of the 2D object without increasing the complexity of the axial navigation paradigm. When the user deselects the portion of the 3D object the user can be zoomed out to a farther out view in which the rotational axis of the view passes through the center of the 3D object .

When a portion of the 3D object is selected including by selecting a label associated with that portion the view of the selected portion can be refined and or enhanced by adjusting the opacity of certain portions of the 3D human body as well as adjusting the zoom. The selected portions of the 3D object can be related e.g. in response to a query for rotator cuff the muscles of the rotator cuff the supraspinatus infraspinatus teres minor and subscapularis can be selected together or arbitrary e.g. the user can select any number of portions of the 3D human body by clicking them with a mouse . These selected portions can be identified and stored as a group. The information on the group can be stored remotely in the user generated content database in the memory of the server . The group can be an arbitrary group of body portions or a related group of body portions.

The exemplary screenshot of includes a display of many labels and to identifying portions of the 3D object . The displayed labels and to are selected for display from a larger group of labels reflecting any portion of the object within the bounds of the viewing area of the 3D enhanced browser . The labels and to that are selected for display are selected based on a determination of large structures displayed in the 3D enhanced browser from among the layers of labels that can be displayed and the plurality of structures that are displayed. Thus in certain aspects the selected labels that are displayed are limited to the layer of the body being viewed and limited to a given area of the view e.g. like a flashlight . For example in certain instances labels that are within a certain radius surrounding the current position of the view or a mouse pointer are displayed. With reference to although the spleen and stomach are displayed in the 3D enhanced browser labels for the spleen and stomach are not displayed. On the other hand a costal cartilage label a liver label and a hepatic artery label which are near the spleen and stomach are displayed because the associated costal cartilage liver and hepatic artery are determined to be large structures within the display of the 3D enhanced browser .

In certain embodiments labels can be selected for display based on other determinations such as by weighting. For example based on a current view of a 3D object a determination is made regarding the visibility of portions of the 3D object the size of portions of the 3D object the opacity of portions of the 3D object the proximity of portions of the 3D object to the current view and the order of layers of the 3D object. Heavier weights are assigned to portions of the 3D object that are more visible larger more opaque closer to the current view and nearer to the outermost layer of the 3D object. A determination is then made to display labels for portions have sufficient weight such as a weight greater than or equal to a predetermined threshold weight.

The user can further generate annotations for any portion of the 3D object for display in the 3D enhanced web browser . In certain aspects annotations are a special type of label that otherwise follow the rules for displaying labels disclosed above and are searchable using the input field . Annotations include user defined labels. The user can assign annotations to one or many portions of the body such as by creating an arbitrary group of body parts and assigning the arbitrary group an annotation. These annotations can be shared in and displayed with the bookmarks described above. For example the content location and display parameters of an annotation can be stored as part of the URL of the bookmark. The annotations can be stored in the user generated content database in the memory of the server for accessibility and viewing by other users.

The annotations can include text describing the associated body portion such as a definition of the associated body portion or an explanation of a medical procedure or condition related to the associated body portion. The annotations can be used to teach students such as by providing annotations with definitions or annotations that are examination questions.

In certain embodiments the user can generate an annotation by selecting e.g. via a mouse click a surface of any portion of the 3D object . At the point of selection a visible marker can be displayed on the model and a textual annotation or other form of content e.g. image hyperlink video can be associated with the marker. As the user navigates around the 3D object the annotation is shown floating near the marker with its position continuously updated with any moving of the marker. The annotation can be shown or hidden depending on the presence of other content or the visibility or opacity of the portion or layer of the 3D object with which the annotation is associated. Markers and their associated annotations can additionally be highlighted as part of a textual search on the model.

The user s current view may include content associated with the view. The content can include for example reference articles and community generated and or editable content. The content can be for example content associated with a query from the user related to the user s current view. The content can also be for example content associated with the portions of the 3D object displayed in the user s current view. a view of the human liver also includes an optional display of related content that includes an article on the liver from Wikipedia and a definition of the term liver. The user can further generate or edit content to be displayed in the related content section such as an article related to the liver.

Computer system e.g. clients and servers includes a bus or other communication mechanism for communicating information and a processor e.g. processor and coupled with bus for processing information. By way of example the computer system may be implemented with one or more processors . Processor may be a general purpose microprocessor a microcontroller a Digital Signal Processor DSP an Application Specific Integrated Circuit ASIC a Field Programmable Gate Array FPGA a Programmable Logic Device PLD a controller a state machine gated logic discrete hardware components or any other suitable entity that can perform calculations or other manipulations of information.

Computer system can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them stored in an included memory e.g. memory and such as a Random Access Memory RAM a flash memory a Read Only Memory ROM a Programmable Read Only Memory PROM an Erasable PROM EPROM registers a hard disk a removable disk a CD ROM a DVD or any other suitable storage device coupled to bus for storing information and instructions to be executed by processor . The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

The instructions may be stored in the memory and implemented in one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of the computer system and according to any method well known to those of skill in the art including but not limited to computer languages such as data oriented languages e.g. SQL dBase system languages e.g. C Objective C C Assembly architectural languages e.g. Java .NET and application languages e.g. PHP Ruby Perl Python . Instructions may also be implemented in computer languages such as array languages aspect oriented languages assembly languages authoring languages command line interface languages compiled languages concurrent languages curly bracket languages dataflow languages data structured languages declarative languages esoteric languages extension languages fourth generation languages functional languages interactive mode languages interpreted languages iterative languages list based languages little languages logic based languages machine languages macro languages metaprogramming languages multiparadigm languages numerical analysis non English based languages object oriented class based languages object oriented prototype based languages off side rule languages procedural languages reflective languages rule based languages scripting languages stack based languages synchronous languages syntax handling languages visual languages wirth languages and xml based languages. Memory may also be used for storing temporary variable or other intermediate information during execution of instructions to be executed by processor .

A computer program as discussed herein does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules subprograms or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network. The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output.

Computer system further includes a data storage device such as a magnetic disk or optical disk coupled to bus for storing information and instructions. Computer system may be coupled via input output module to various devices. The input output module can be any input output module. Exemplary input output modules include data ports such as USB ports. The input output module is configured to connect to a communications module e.g. communications module and . Exemplary communications modules include networking interface cards such as Ethernet cards and modems. In certain aspects the input output module is configured to connect to a plurality of devices such as an input device e.g. input device and or an output device e.g. output device . Exemplary input devices include a keyboard and a pointing device e.g. a mouse or a trackball by which a user can provide input to the computer system . Other kinds of input devices can be used to provide for interaction with a user as well. For example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. Exemplary output devices include display devices such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user.

According to one aspect of the present disclosure the client and server can be implemented using a computer system in response to processor executing one or more sequences of one or more instructions contained in memory . Such instructions may be read into memory from another machine readable medium such as data storage device . Execution of the sequences of instructions contained in main memory causes processor to perform the process steps described herein. One or more processors in a multi processing arrangement may also be employed to execute the sequences of instructions contained in memory . In alternative aspects hard wired circuitry may be used in place of or in combination with software instructions to implement various aspects of the present disclosure. Thus aspects of the present disclosure are not limited to any specific combination of hardware circuitry and software.

Various aspects of the subject matter described in this specification can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network and a wide area network.

Computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. Computer system can also be embedded in another device for example and without limitation a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver a video game console and or a television set top box.

The term machine readable storage medium or computer readable medium as used herein refers to any medium or media that participates in providing instructions to processor for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media include for example optical or magnetic disks such as data storage device . Volatile media include dynamic memory such as memory . Transmission media include coaxial cables copper wire and fiber optics including the wires that comprise bus . Common forms of machine readable media include for example floppy disk a flexible disk hard disk magnetic tape any other magnetic medium a CD ROM DVD any other optical medium punch cards paper tape any other physical medium with patterns of holes a RAM a PROM an EPROM a FLASH EPROM any other memory chip or cartridge or any other medium from which a computer can read. The machine readable storage medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more of them.

Systems methods and machine readable media for using a 3D enhanced web browser to view and search a 3D object such as the human body have been described. In certain aspects using the 3D enhanced web browser a user can view search and transcend layers of the 3D human body. The user can further customize the appearance of the 3D human body and share view of the 3D human body using many of the tools and features disclosed.

While this specification contains many specifics these should not be construed as limitations on the scope of what may be claimed but rather as descriptions of particular implementations of the subject matter. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover although features may be described above as acting in certain combinations one or more features can in some cases be excised from the combination and the combination may be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components in the aspects described above should not be understood as requiring such separation in all aspects and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

