---

title: System and method for rule matching in a processor
abstract: In one embodiment, a system includes a format block configured to receive a key, at least one rule, and rule formatting information. The rule can have one or more dimensions. The format block can be further configured to extract each of the dimensions from the at least one rule. The system can further include a plurality of dimension matching engines (DME). Each DME can be configured to receive the key and a corresponding formatted dimension, and process the key and the corresponding dimension for returning a match or nomatch. The system can further include a post processing block configured to analyze the matches or no matches returned from the DMEs and return a response based on the returned matches or nomatches.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09344366&OS=09344366&RS=09344366
owner: Cavium, Inc.
number: 09344366
owner_city: San Jose
owner_country: US
publication_date: 20120802
---
This application claims the benefit of U.S. Provisional Application No. 61 514 344 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 382 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 379 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 400 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 406 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 407 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 438 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 447 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 450 filed on Aug. 2 2011 U.S. Provisional Application No. 61 514 459 filed on Aug. 2 2011 and U.S. Provisional Application No. 61 514 463 filed on Aug. 2 2011. The entire teachings of the above applications are incorporated herein by reference.

The Open Systems Interconnection OSI Reference Model defines seven network protocol layers L1 L7 used to communicate over a transmission medium. The upper layers L4 L7 represent end to end communications and the lower layers L1 L3 represent local communications.

Networking application aware systems can process filter and switch a range of L3 to L7 network protocol layers for example L7 network protocol layers such as HyperText Transfer Protocol HTTP and Simple Mail Transfer Protocol SMTP and L4 network protocol layers such as Transmission Control Protocol TCP . In addition to processing the network protocol layers the networking application aware systems can simultaneously secure these protocols with access and content based security through L4 L7 network protocol layers including Firewall Virtual Private Network VPN Secure Sockets Layer SSL Intrusion Detection System IDS Internet Protocol Security IPSec Anti Virus AV and Anti Spam functionality at wire speed.

Improving the efficiency and security of network operation in today s Internet world remains an ultimate goal for Internet users. Access control traffic engineering intrusion detection and many other network services can be optimized by packet classification which is discrimination of packets based on multiple fields of packet headers.

Internet routers can classify packets to implement a number of advanced internet services such as routing rate limiting access control in firewalls virtual bandwidth allocation policy based routing service differentiation load balancing traffic shaping and traffic billing. To perform these services the router classifies incoming packets into different flows and then performs appropriate actions depending on the classification.

A classifier using a set of filters or rules specifies the flows or classes. For example each rule in a firewall might specify a set of source and destination addresses and associate a corresponding deny or permit action with it. Alternatively the rules might be based on several fields of a packet header including layers 2 3 4 and 5 of the OSI model which contain addressing and protocol information.

On some types of proprietary hardware an Access Control List ACL refers to rules that are applied to port numbers or network daemon names that are available on a host or layer 3 device each with a list of hosts and or networks permitted to use a service. Both individual servers as well as routers can have network ACLs. ACLs can be configured to control both inbound and outbound traffic.

In one embodiment a system includes a format block configured to receive a key at least one rule and rule formatting information. The rule can have one or more dimensions. The format block can be further configured to extract each of the dimensions from the at least one rule. The system can further include a plurality of dimension matching engines DME . Each DME can be configured to receive the key and a corresponding formatted dimension and process the key and the corresponding dimension for returning a match or nomatch. The system can further include a post processing block configured to analyze the matches or no matches returned from the DMEs and return a response based on the returned matches or nomatches.

In one embodiment the format block may further include a start block configured to find rule starts mark invalid or deactivated rules and pre calculate terms of the dimensions. The format block may further include a middle block configured to remove marked rules extract rule format from headers and extract priority from headers. The format block may further include a tween block configured to calculate rule header end position information and rule dimension end position information. The format block may further include a finish block configured to calculate control for the DMEs.

In one embodiment the DMEs may be further configured to match the key to at least one of a a range indicated by a minimum and maximum in the corresponding dimension 2 an exact match indicated by a match value in the dimension 3 a prefix match indicated by a prefix length and a match value in the dimension and 4 a mask indicated by a bit mask and a match value indicated by the dimension.

In another embodiment the DMEs may further include at least one rule data aligner configured to align bits of a match value of the rule of the corresponding dimension to a particular granularity. The DMEs may further include at least one key data aligner configured to align bits of the key to a particular granularity. The DMEs may further include a match unit to compare the key to the match value of the corresponding dimension. The DMEs may further include a DME buffer unit configured to receive portions of a particular dimension in a buffer over a plurality of clock cycles and reassemble the portions into the particular dimension.

In another embodiment the post processing block may be further configured to sort multiple responses from the DMEs for multiple rules. The post processing block may be further configured to return a response representing a Boolean and of the results of each of the at least one rule.

In one embodiment the format block is further configured to receive the at least one rule by receiving at least one line of data each line of data having a particular size. Each line can further store at least one rule and or at least one partial rule that occupies the particular size. The at least one partial rule can continue on a subsequent line of the at least one line or can be continued from a previous line of the at least one line.

In one embodiment a method may include receiving at a format block a key at least one rule and rule formatting information. The at least one rule may have at least one dimension. The method may further include extracting at the format block each of the dimensions from the at least one rule. The method may additionally include receiving at a plurality of dimension matching engines DME the key and a corresponding formatted dimension. The method may further include processing at the plurality of DMEs the key and the corresponding dimension for returning a match or nomatch. The method may also include analyzing at a post processing block the matches or no matches returned from the DMEs and return a response based on the returned matches or nomatches.

The teachings of all patents published applications and references cited herein are incorporated by reference in their entirety.

The core routers are configured to operate in the Internet core or Internet backbone. The core routers are configured to support multiple telecommunications interfaces of the Internet core and are further configured to forward packets at a full speed of each of the multiple telecommunications protocols.

The edge routers are placed at the edge of the Internet core . Edge routers bridge access routers outside the Internet core and core routers in the Internet core . Edge routers can be configured to employ a bridging protocol to forward packets from access routers to core routers and vice versa.

The access routers can be routers used by an end user such as a home user or an office to connect to one of the edge routers which in turn connects to the Internet core by connecting to one of the core routers . In this manner the edge routers can connect to any other edge router via the edge routers and the interconnected core routers 

The search processor described herein can reside in any of the core routers edge routers and access routers . The search processor described herein within each of these routers is configured to analyze Internet protocol IP packets based on a set of rules and forward the IP packets along an appropriate network path.

Likewise the second host processor is an egress host processor. The second host processor receives egress packets to send from the network . The second host processor forwards a lookup request with a packet header or field from the egress packets to the search processor over a second Interlaken interface . The search processor then processes the packet header using a plurality of rule processing engines employing a plurality of rules to determine a path to forward the packets on the network. The second host processor forwards the processed egress packets to another network element in the network.

As an example a packet is received by the line card at the MAC layer . The MAC layer sends the packet to the forwarding table . Then the packet and appropriate forwarding table information is stored in the local buffer memory . The processor card then accesses its routing table to determine where to forward the received packet. Based on the determination the router selects an appropriate line card stores the packet and forwarding information in the local buffer memory of the appropriate line card and forwards the packet out to the network.

The crossbar is coupled with a first supercluster and a second supercluster . Within each supercluster are a plurality of search blocks . Each search block or search cluster is configured to receive a key from a received packet determine and load a set of rules to process the key and output results of the search executed using those rules. The crossbar and the superclusters are part of a lookup cluster complex LCC .

The processor described herein loads one or more rules e.g. matching rules that match a packet. In general a packet may be broken down into parts such as a header a payload and a trailer. The header of the packet or packet header may be further broken down into fields for example. So the processor may further find one or more rules that match one or more parts or fields of the packet.

The processor can execute a lookup request which finds one or more rules matching a packet or parts of a packet. The lookup request first leads to finding one or more matching rules.

From the standpoint of the processor described herein executing a lookup request begins with 1 receiving the lookup request from a host processor. The lookup request includes a packet header and group identifier GID .

2 The GID indexes to an entry in a global definition description table GDT . Each GDT entry includes a n number of table identifiers TID b a packet header index PHIDX and c key format table index KFTIDX .

3 Each TID indexes an entry in a tree location table TLT . Each TLT entry identifies which lookup engine or processor core looks for the one or more matching rules. In this way each TID specifies both which lookup engine or processor core looks for the one or more matching rules and where the particular one or more matching rules are stored.

4 Each TID also indexes an entry in a tree access table TAT . Each TAT entry provides the starting address e.g. a root node in memory of a collection of rules or pointers to rules called a table or tree of rules. The terms table of rules tree of rules table or tree are used interchangeably throughout the Application. In all the TID identifies the TAT which identifies the collection or set of rules in which to look for one or more matching rules.

5 The PHIDX of the GDT entry indexes an entry in a packet header table PHT . Each entry in the PHT instructs the processor how to extract n number of keys from the packet header.

6 The KFTIDX of the GDT entry indexes an entry in a key format table KFT . Each entry in the KFT provides instructions for extracting one or more fields i.e. parts of the packet header from each of the n number of keys extracted from the packet header.

7 The processor looks for subsets of the rules using each of the fields extracted from the packet together with each of the TIDs. Each subset contains rules that may possibly match each of the extracted fields.

8 The processor then compares each rule of each subset against an extracted field. The processor provides rules that mach in responses or lookup responses.

The above description of a lookup request and its enumerated stages are described to present concepts of lookup requests. These concepts may be implemented in numerous ways. For example according to example embodiments of the present invention these concepts may be implemented by a search processor.

As described above the search processor processes a lookup request for a packet. In processing the lookup request the processor can extract a header or field from the packet that is then applied to one or more rules. The header of field can be referred to as a key.

The search processor stores at least one tree of rules. In one embodiment the tree of rules is a memory structure employed by the processor to narrow down a set of rules for a given key and a rule is a test of a value of a key. The tree has a root node or a starting address. The search processor uses a tree walk engine TWE to traverse the tree for a particular key. The TWE eventually reaches a pointer to a memory address in the tree. The pointer can be either to a bucket of rules or a pointer to rules in memory directly.

A bucket of rules is a set of pointers to rules. If the pointer is to a bucket of rules a bucket walk engine BWE determines based on the key and the bucket a pointer to rules in a memory such as an on chip memory. A group of rules in memory is called a chunk. The chunk can be sequentially addressed rules or rules grouped in another manner. If the pointer is to rules in the memory directly the pointer may point directly to the chunk.

Once the processor loads the chunk of rules from memory it sends the key and the chunk of rules to a rule match engine RME . The rule match engine determines whether the key matches rules within the chunk. Then the RME and the search processor can respond to the lookup request with the selected rule and match result.

The search cluster receives a key from the LUF at the TWE . The TWE issues and receives a plurality of tree input output I O accesses to the OCM . Based on the key the TWE walks the tree from a root node to a possible leaf node. If the TWE does not find an appropriate leaf node the TWE issues a nomatch e.g. a no match . Then if the TWE finds an appropriate leaf node the leaf node can indicate a pointer to a bucket. The TWE provides the pointer to the bucket to the BWE . The BWE accesses the OCM by issuing bucket I O accesses to the OCM . The bucket I O accesses retrieve at least one pointer to a chunk to the BWE . The BWE provides the pointer to the chunk to one of the plurality of RMEs . The one of the chosen RMEs also receives the key . Each of the plurality of RMEs are configured to issue rule and or chunk I O accesses to the OCM using the pointer to the chunk to download appropriate rules from the chunk in the OCM to analyze the key . The RMEs then analyze the key using the rules accessed from the OCM and issue a response or nomatch corresponding to whether the key matched the rule or chunk indicated by the tree and bucket stored in the OCM .

The search cluster of the search processor then determines whether the rule or bucket is in the tree by searching for a non null leaf node. If not for instance if the leaf node is nonexistent or null the search cluster returns a nomatch . If the leaf node stores a rule or bucket then the search cluster determines whether the leaf node points to a rule or points to a bucket . If the leaf node points directly to the rule then search cluster loads the rule from an external memory . Then the system provides the rule to the BPP . The system provides the rule to the BPP by either i the BPP pulling the rule from the external memory using the pointer from the leaf node or ii a navigation unit within the search cluster sending a command to the external memory to forward the requested memory addresses to the BPP.

The BPP is a processor similar to the RME that is configured to process a chunk of rules and compare the rules to keys however the BPP is further configured to process rules from the external memory. Loading rules from an external memory is an optional embodiment of the search processor and corresponding search clusters. The search processor can store all of the rules and or chunks of rules on an OCM. Therefore the tree data structure may store pointers to buckets instead of pointers to rules directly. Even in an embodiment where rules and or chunks of rules are stored solely on the OCM the leaf nodes can point directly to the rules and or chunks of rules in the OCM without the use of buckets.

If the leaf node points to a bucket then the search processor loads pointers stored in the bucket . Then the search processor loads the rules that are stored in the OCM where the pointers from the bucket are pointing . Then the system provides the rule s to RMEs .

The formatting block receives chunks of rule and the key . The formatting block based on the chunks of rules rule format info and the key outputs formatted dimensions to the DME block . The format block outputs as many formatted dimensions as there are the DMEs in a particular clock cycle. For example in an RME that includes twelve DMEs the format block can issue twelve formatted dimensions to each of the twelve DMEs . However the RME can contain any number of DMEs. The DMEs receive the formatted dimension and the key . The DMEs process the key comparing it to the formatted dimension and output a respective dimension result . The post processing block receives all of the dimension results and performs of Boolean and of all of the dimension results to output results . Therefore results indicate whether the key matches a particular rule across all of its dimensions.

In other words in one embodiment rules are stored within a chunk. A chunk is a collection of rules that are grouped together. The RME receives the chunk of rules one line of data per clock cycle or beat . In one embodiment the line of data can be 256 bits wide however other embodiments the line of data can be any size.

Each line can contain at least one rule. For example a first line transmitting a chunk may contain three and a half rules that is three complete rules and one partial rule. The one partial rule is cut off because the line of data is too short to store the complete fourth rule. Instead the fourth rule is transmitted on a second line transmitting the chunk.

The second line may contain two and a half rules that is two complete rules and one partial rules. The first rule of the second line of data is the remainder of the partial rule in the first line of data i.e. the fourth rule . The second line of data contains two complete rules i.e. the fifth and sixth rules of the chunk . In another embodiment a line can include two partial rules where the first partial rule is cut off at the beginning of the line and the second partial rule is cut off at the end of the line. However in this embodiment the chunk contains six rules transmitted over two clock cycles as described above.

The format block or first stage formats all dimensions of the received multiple rules and assign each rule to a DME on each clock cycle. In this embodiment in first clock cycle the format block processes three rules because it has received three complete rules i.e. the first second and third rule where the format block does not process the fourth rule because it hasn t been completely received yet. In the second clock cycle the format block processes three more rules i.e. the fourth fifth and sixth rules because all have been received completely at this point.

Every clock cycle the DMEs process the dimensions. Then the post processing block sorts the outputs of DMEs and returns a final response on completion of whole chunk in this embodiment the six rules .

In relation to the format block includes a start block a middle block a tween block and a finish block . The start block has two pipeline stages P and P. The middle block has two pipeline stages P and P. The tween block has one stage P. The finish block has two stages P and P.

The format block receives rule data and rule formatting information at the start block . The start block has three high level functions. First the start block finds starts of the rules within the rule data . Second the start block identifies rules that do not require processing such as a rule with a check rule violation or a rule with a valid bit being set to zero or false . Third the start block precalculates terms for next stage e.g. the middle block processing.

The middle block has three high level functions. First the middle block removes rules that do not need to be processed as identified by the start block . The start block as described above identifies rules that do not require processing such as a rule with a check rule violation or with a valid bit set to zero or false. Second the middle block extracts rule format from headers of the rule data . Third the middle block extracts at least one priority field from headers of the rule data . The priority field of each rule indicates the priority in which the rule is processed.

The tween block has two high level functions. First the tween block calculates rule header and positions. Second the tween block calculates rule dimension and positions.

The finish block has two high level functions. First the finish block calculates control for the multiple DMEs of the DME group . Second the finish block generates control rule and formatting information for the post processing block .

The start block has two pipeline stages P and P. The start block introduces a large delay through combinatorial logic from its inputs. The stages of the start block i.e. P and P are configured to enable stalling or hold information from a stall issued by the middle block or the finish block . The start block also calculates header length information. The start block also identifies rules that do not need to be processed by 1 performing a check rules operation and 2 checking the valid bits of the rules. The start block in some embodiments does not remove the rule but rather identifies flags and or selects the rule to be removed later for instance by the middle block . The start block then determines whether the start block has processed more than a threshold of rules. The start block identifies rules P and P in excess of the threshold for removal. The start block also identifies rules for removal based on each rules validity bit.

The middle block has two pipeline stages P and P. Both stages are configured to stall and hold under a stall from the finish block . Stage P removes invalid rules identified by the start block . Therefore only a rule that passes the check rules test and has its validity bit set e.g. being true or one are sent to the next stage of the middle block e.g. stage P .

Pipeline stage P of the middle block extracts header formatting information in a header processing module . The header processing module processes up to four headers per clock cycle however the actual number of headers processed is dependent on the number of dimensions within the rules. This limits the amount of formatting information the tween block and finish block process during each clock cycle.

In one embodiment the header processing module can process a certain number of headers based on the number of dimensions within each header. For example in an embodiment where the RME includes 12 DMEs the header processing module can process four headers when each header includes 1 3 dimensions. This means that the header processing module processes 4 12 maximum dimensions per cycle which does not overload the twelve DMEs 

The header processing module can process three header paths if each header includes 4 5 dimensions. This allows the RME 12 to 15 maximum dimensions per cycle which occupies the DMEs however with stall conditions the DMEs can process any surplus dimensions in a next clock cycle.

The header processing module can process two header paths when the headers include 6 11 dimensions. This creates 12 22 maximum dimensions per cycle which occupies the DMEs however using stall conditions any surplus dimensions can be processed in a next clock cycle.

Last the header processing module can process one header path when the header includes 12 16 dimensions. The RMEs process 12 16 total dimensions per clock cycle which occupies the DMEs . Surplus dimensions can be processed in a next clock cycle.

The DME group of the RME can include any number of DMEs . Adjusting the number of DMEs can affect the numbers described above. Accordingly the above numbers describe one example embodiment and other combinations of numbers of headers dimensions and DMEs can realize other embodiments.

Further the header processing module can process partial headers. A partial header is a header that straddles across two beats or clock cycles which requires processing during more than one cycle. The straddled header path is stored until the header processing module downloads the complete header. Multi beat headers are discussed in further detail in relation to .

In relation to rule data may contain more headers than described in the embodiments described above. Upon a rule including more headers than in the embodiments described above the RME asserts a stall via the middle block stall signal so that the header processing module and the RME in general can process the additional headers in the rule. The middle block stall signal stalls stages P and P of the start block . Then the RME processes the number of headers based on the number of headers and number of dimensions as described above. Then the RME stores unprocessed data in the middle block to be processed in next clock cycles.

The tween block includes one pipeline stage P. The tween block stalls upon a finish stall stage data signal from the finish block . The tween block is configured to calculate rule header and position. The tween block is further configured to calculate rule dimension and positions from dimension widths. The tween block is further configured to calculate key positions from each dimension from rule formatting data.

The finish block includes two pipeline stages P and P. The finish block includes a FIFO memory structure configured to manage control. The FIFO structure can push and pop or retire a variable number of elements. Elements in the FIFO are positions of headers and dimensions.

The finish block further calculates control for the DMEs . The calculated controls are shift accounts masks or assembly controls e.g. for dimension straddles . In an embodiment where the RME includes 12 DMEs the finish block retires or processes up to 12 dimensions per beat or clock cycle including dimension straddles up to four rules starts per beat parts of up to five rules per beat when the finish block is finishing processing a rule from the previous beat and up to 256 bits of rule data per beat.

The finish block pushes up to four rule end positions e.g. header and dimension end positions and field widths into a FIFO data structure in a rule formatting RFT block . The RFT block also calculates control data for dimension data for the first 16 elements of the FIFO data structure the control data includes a retirement state for the up to four headers and 12 rule dimensions. The finish block uses this control data to retire control and rule data. The formatting data from the RFT block is retired when the corresponding complete rule is sent to the DME group or when all header bits are retired. The RFT block retires data by popping any dimension and or header it sends.

The finish block retires rule data when it is sent to the DME group . When there are more rule bits than can be retired in one clock cycle e.g. more than 12 dimensions and or more than four rules the finish block stalls by issuing a finish block stall signal . The finish block processes as much of the rule data e.g. as many rule bits as possible during the clock cycle and stores the remaining rule data to process in the next cycle.

Further the RFT block can cause the finish block to issue a stall if it stores more than 32 elements stored in its FIFO in one embodiment. The 32 element threshold allows the rule format stall to be independent of the number of elements popped in any cycle because it hides one cycle of the pop through a stall latency from the maximum allowed rule formatting pop count of the finish block .

The finish block calculates control for each of the 12 DMEs through the control information from the rule formatting block . The control information includes 1 shift counts to align rule and key data for the match 2 a mask control to select a number of bits for each match 3 and an assembly control for each of the assembly of dimensions that straddle beat boundaries.

The finish block further calculates control for post processing of the matched results e.g. via post processing control data . The post processing control data includes information that allows the post processing block to identify which dimension results correspond with each rule. Each rule is given a tag which follows each dimension of that rule as it exists in the finish block .

The DME group includes multiple DMEs e.g. 12 DMEs . Each DME can perform a 128 bit match of one of four different types. The four match types are 1 a range match 2 an exact match 3 a prefix match and 4 a mask match. The DMEs can perform more than a 128 bit match of the four different types. For example the DMEs can perform any bit length match in one embodiment.

A range match determines whether a given key is within a minimum value and maximum value as set in a given dimension. An exact match determines whether a given key exactly matches a value as set in a given dimension. A prefix match determines whether a given number of bits as set in the dimensions of a given value as set in the dimension matches first set of a given number of bits in a given key bits. For example a prefix match can match a first eight bits of a key to an eight bit value in the dimension. Therefore the prefix dimension includes both a length and a value to check. A mask match determines whether a given set of bits in a key as indicated in a bit mask in the dimension matches a value as indicated in the mask dimension. Therefore the mask dimension includes both a bit mask and a value for the bit mask to be checked.

As described above a range match and a mask match both employ two rule data operands i.e. range requires a minimum value and a maximum value and mask requires a bit mask and a value . An exact match employs one rule data operand which is the exact match value that searches against the key. A prefix match employs one rule data operand plus a width or a zero kill shift for unused bits. Matching a dimension to a key employs at least one operand of key data.

The single beat header processing modules output processed headers . Further the multi beat header processing module outputs a processed header and a processed multi beat header which combines the header information across the multiple beats. The processed headers and processed multi beat header include header formatting information e.g. beginning and ending of each dimension etc. . Further the processed headers are combined to become processed headers .

The rule formatting block can further issue a rule format stall upon receiving more rule bits than can be retired in one beat or clock cycle . Further the control logic module can issue a dimension stall upon determining that the FIFO stores greater than 32 elements. If either the rule formatting block issues a rule format stall or the control logic module issues a dimension stall the finish block issues a finish stage stall signal .

The match unit includes a first compare unit a second compare unit a combination unit and mask logic . The match unit receives an aligned first dimension data and aligned second dimension data and an aligned key and outputs a dimension match indicating whether the key matches the particular rule.

The aligned first dimension data and aligned second dimension data correspond to the two possible pieces of data accompanying each dimension. For example range matching uses the aligned first dimension data as a minimum and the aligned second dimension data as a maximum. The first compare unit therefore performs a greater than or greater than or equal to operation the second compare unit performs a less than or less than or equal to operation and the combination unit then performs a logical and operation on the results of the first and second compare units to reach the dimension match .

In a mask operation the aligned first dimension data is the value of the dimension and the aligned second dimension is the bit mask. The match unit then performs an exclusive or operation of the aligned first dimension data and the aligned key . Then the match unit performs a bit wise and of the aligned second dimension data e.g. the mask and the results of the exclusive or operation . Then the match unit performs an or operation of all of the bits of the and operation. The mask logic performs the above operations. The dimension match is the result of the final or of the mask logic .

For an exact or prefix match the aligned first dimension data and the aligned second dimension data include the same formatted rule bits. Therefore the exact or prefix match can take the same path through the match unit as the range match.

For mask operations the aligned first dimension data is masked on a nimble granularity. The aligned second dimension data is not masked because masking is not required. The aligned key is masked on a bit granularity to support prefix operations.

If headers are present in the rule data then the format block determines whether there are more headers than a particular limit . If there are not more headers than the predetermined limit then the format block processes all headers in the rule data . Then the format block sends all rule data to the next stage of processing . Then the format block waits to receive new rule data .

However if the RME has received more headers than the predetermined limit the format block processes the number of headers up to the header limit . Then the format block stalls . Then the format block sends process data to the next stage . The format block stores unprocessed data in its current stage . Then the format block determines whether the RME is storing more headers than the predetermined limit and proceeds accordingly.

On the other hand if there are more than 12 dimensions or more than 4 headers in the rule data the format block stalls . Then the format block retires up to 12 dimensions of rule data and formatting . Then the format block sends the retired rule data to the DMEs . Then the format block retires up to 4 headers in the rule data and formatting . Then the format block determines again whether there are more than 12 dimensions or more than 4 headers in the rule data and proceeds accordingly.

The data plane further receives headers at a customer application layer . The headers are received either in a packet header mode or a direct key mode . In either packet header mode or direct key mode the customer application layer generates the lookup request to the data plane . The data plane then looks up the headers in the search processor by employing the binary rules file already loaded into the processor to generate results . The results are sent to the customer application layer which are then outputted as results output .

The mask rule type includes a mask value and a bit mask . The mask value is the value to which the key is compared and the bit mask is the set of bits of the key and the mask which the mask value is compared. A key value matches the mask rule type if the masked bits of the key value match the masked bits of the mask value

The valid bit is a flag that indicates whether the rule is valid or not. If the valid bit is set to one then the rule is processed by the RME or BPP. If the valid bit is set to zero then the rule is screened out and not processed. Setting the validity bit can be a more efficient method to enable and disable rules than deleting or inserting the rule.

Further in one embodiment when the dimension valid bit is set to zero its corresponding dimension value is not stored. Therefore the dimension and therefore rule and chunk occupy less space in memory and further increase efficiency.

The rule length is a 6 bit value that indicates the length of the rule which is useful for rule processing. For example the rule length informs the RME or BPP when to stop processing the rule because the remaining bits of the rule are simply padding to fill out the rest of the rule length. Prefix lengths indicate the length of a prefix field for a given dimension. The PL fields are used for prefix dimension types. The priority field indicates the priority of the rule for instance the priority of the rule within a chunk of rules. The dimensions indicate the actual values of the rule to be processed.

First the rule zero is transferred during beat one . Then during beat zero upper rule one is transferred however rule one does not finish during beat zero . Rule one continues being transferred as lower rule one in beat one . Then chunk padding is transmitted to align the rules to the appropriate bit position. Upper rule two is then transferred during beat one however rule two again does not get to finish completely being transferred during beat one. Therefore lower rule two is transferred during beat two . Then chunk padding is transferred to align the rule to the appropriate bit position. Then rule three is transferred during beat two . Rule three does finish being transferred during beat two and chunk padding is transferred after rule three to align the next rule to the appropriate bit boundary. In this particular example the chunk padding is at the end of beat two so the next rule begins at the beginning of the next beat. Rules of the chunk continue to be stored in the chunk in this manner until rule X . The last beat transfers lower rule X where the upper rule X not shown is transferred in the previous beat. Since rule X is the last rule the last beat is filled with end of chunk padding which is filled with zeros.

Embodiments or aspects of the present invention may be implemented in the form of hardware software or firmware. If implemented in software the software may be any form of software capable of performing operations consistent with the example embodiments disclosed herein. The software may be stored in any non transient computer readable medium such as RAM ROM magnetic disk or optical disk. When loaded and executed by processor s the processor s are configured to perform operations consistent with the example embodiments disclosed herein. The processor s may be any form of processor s capable of being configured to execute operations as disclosed herein.

While this invention has been particularly shown and described with references to example embodiments thereof it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the scope of the invention encompassed by the appended claims.

