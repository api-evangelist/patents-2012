---

title: Network communications over shared links in a virtualized environment
abstract: A method of data processing includes a physical host executing a virtual machine monitor (VMM) that instantiates a plurality of virtual machines (VMs). The VMM supports processing of a virtual link manager (VLM) that deploys and configures a plurality of Layer 2 virtual links sharing bandwidth of a Layer 2 physical link between the physical host and an access switch. The VMM communicates parameters of the plurality of virtual links with the access switch.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08839244&OS=08839244&RS=08839244
owner: International Business Machines Corporation
number: 08839244
owner_city: Armonk
owner_country: US
publication_date: 20120426
---
The present application is a continuation of U.S. patent application Ser. No. 13 006 919 filed on Jan. 14 2011 entitled NETWORK COMMUNICATIONS OVER SHARED LINKS IN A VIRTUALIZED ENVIRONMENT the disclosure of which is hereby incorporated herein by reference in its entirety for all purposes.

The present invention relates in general to data processing and in particular to data processing environments including virtual networks.

In general utility computing refers to a computational model in which processing storage and network resources software and data are accessible to client computer systems and other client devices e.g. mobile phones or media players on demand much like familiar residential utility services such as water and electricity. In some implementations the specific computational resources e.g. servers storage drives etc. allocated for access and use by client devices are specified by service agreements between the utility computing provider and its customers. In other implementations commonly referred to as cloud computing details of the underlying information technology IT infrastructure are transparent to the utility computing customers.

Cloud computing is facilitated by ease of access to remote computing websites e.g. via the Internet or a private corporate network and frequently takes the form of web based resources tools or applications that a cloud consumer can access and use through a web browser as if the resources tools or applications were a local program installed on a computer system of the cloud consumer. Commercial cloud implementations are generally expected to meet quality of service QoS requirements of cloud consumers which may be specified in service level agreements SLAs . In a typical cloud implementation cloud consumers consume computational resources as a service and pay only for the resources used.

Adoption of utility computing has been facilitated by the widespread utilization of virtualization which is the creation of virtual rather than actual versions of computing resource e.g. an operating system a server a storage device network resources etc. For example a virtual machine VM also referred to as a logical partition LPAR is a software implementation of a physical machine e.g. a computer system that executes instructions like a physical machine. VMs can be categorized as system VMs or process VMs. A system VM provides a complete system platform that supports the execution of a complete operating system OS such as Windows Linux AIX Android etc. as well as its associated applications. A process VM on the other hand is usually designed to run a single program and support a single process. In either case any application software running on the VM is limited to the resources and abstractions provided by that VM. Consequently the actual resources provided by a common IT infrastructure can be efficiently managed and utilized through the deployment of multiple VMs possibly from multiple different utility computing customers.

The virtualization of actual IT resources and management of VMs is typically provided by software referred to as a VM monitor VMM or hypervisor. In various implementations a VMM may run on bare hardware Type 1 or native VMM or on top of an operating system Type 2 or hosted VMM .

In a typical virtualized computing environment VMs can communicate with each other and with physical entities in the IT infrastructure of the utility computing environment utilizing conventional networking protocols. As is known in the art conventional networking protocols are commonly premised on the well known seven layer Open Systems Interconnection OSI model which includes in ascending order physical data link network transport session presentation and application layers. VMs are enabled to communicate with other network entities as if the VMs were physical network elements through the substitution of a virtual network connection for the conventional physical layer connection.

Disclosed herein are techniques for enhancing network communication in such virtual computing environments.

A method of data processing includes a physical host executing a virtual machine monitor VMM that instantiates a plurality of virtual machines VMs . The VMM supports processing of a virtual link manager VLM that deploys and configures a plurality of Layer 2 virtual links sharing bandwidth of a Layer 2 physical link between the physical host and an access switch. The VMM communicates parameters of the plurality of virtual links with the access switch.

With reference now to the figures and with particular reference to there is illustrated a high level block diagram of an exemplary data processing environment in accordance within one embodiment. As shown data processing environment which in the depicted embodiment is a cloud computing environment includes a collection of computing resources commonly referred to as a cloud . Computing resources within cloud are interconnected for communication and may be grouped not shown physically or virtually in one or more networks such as private community public or hybrid clouds or a combination thereof. In this manner data processing environment can offer infrastructure platforms and or software as services accessible to client devices such as personal e.g. desktop laptop netbook tablet or handheld computers smart phones server computer systems and consumer electronics such as media players e.g. set top boxes digital versatile disk DVD players or digital video recorders DVRs . It should be understood that the types of client devices shown in are illustrative only and that client devices can be any type of electronic device capable of communicating with and accessing services of computing resources in collection via a packet network.

As depicted cloud includes a physical layer a virtualization layer a service management layer and a workloads layer . Physical layer includes various physical hardware and software components that can be used to instantiate virtual entities for use by the cloud service provider and its customers. As an example the hardware components may include mainframes e.g. IBM zSeries systems reduced instruction set computer RISC architecture servers e.g. IBM pSeries systems IBM xSeries systems IBM BladeCenter systems storage devices e.g. flash drives magnetic drives optical drives tape drives etc. physical networks and networking components e.g. routers switches etc. . The software components may include virtual machine monitor VMM or hypervisor software operating system software e.g. AIX Windows Linux VMware Android etc. network application server software e.g. IBM WebSphere application server software which includes web server software and database software e.g. IBM DB2 database software . IBM zSeries pSeries xSeries BladeCenter WebSphere and DB2 are trademarks of International Business Machines Corporation registered in many jurisdictions worldwide.

The resource of physical layer can be administered across cloud in a unified manner through management software . In the depicted embodiment management software includes platform management PM software that manages the physical computing platforms networks and storage resources of physical layer as well as VMM management VMMM software that manages VMMs deployed on the physical computing platforms. Management software may run for example on a physical computing platform within physical layer that is designated as a management console 

The computing resources residing in physical layer of cloud are virtualized and managed by one or more VMMs. The VMMs present a virtualization layer including virtual entities e.g. virtual servers virtual storage virtual networks including virtual private networks virtual applications and virtual clients. As discussed previously these virtual entities which are abstractions of the underlying resources in physical layer may be accessed by client devices of cloud consumers on demand.

The VMM s also support a service management layer that implements various management functions for cloud . These management functions can be directly implemented by the VMM s and or by one or more management or service VMs running on the VMM s and may provide functions such as resource provisioning metering and pricing security user portal services service level management and SLA planning and fulfillment. The resource provisioning function provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing environment. The metering and pricing function provides cost tracking as resources are provisioned and utilized within the cloud computing environment and billing or invoicing for consumption of the utilized resources. As one example the utilized resources may include application software licenses. The security function provides identity verification for cloud consumers and tasks as well as protection for data and other resources. The user portal function provides access to the cloud computing environment for consumers and system administrators. The service level management function provides cloud computing resource allocation and management such that required service levels are met. For example the security function or service level management function may be configured to limit deployment migration of a virtual machine VM image to geographical location indicated to be acceptable to a cloud consumer. The service level agreement SLA planning and fulfillment function provides pre arrangement for and procurement of cloud computing resources for which a future requirement is anticipated in accordance with an SLA.

Workloads layer which may be implemented by one or more consumer VMs provides examples of functionality for which the cloud computing environment may be utilized. Examples of workloads and functions which may be provided from workloads layer include mapping and navigation software development and lifecycle management virtual classroom education delivery data analytics processing and transaction processing. Of course the workloads present in workloads layer will vary between embodiments depending upon the needs and desires of cloud consumers.

With reference now to there is illustrated a high level block diagram of an exemplary data processing system that can be utilized to implement a physical host computing platform in physical layer of or a client device of . In the illustrated exemplary embodiment data processing system includes one or more network interfaces that permit data processing system to communicate with one or more computing resources in cloud via cabling and or one or more wired or wireless public or private local or wide area networks including the Internet . Data processing system additionally includes one or more processors that process data and program code for example to manage access and manipulate data or software in data processing environment . Data processing system also includes input output I O devices such as ports displays and attached devices etc. which receive inputs and provide outputs of the processing performed by data processing system and or other resource s in data processing environment . Finally data processing system includes data storage which may include one or more volatile or non volatile storage devices including memories solid state drives optical or magnetic disk drives tape drives etc. Data storage may store for example software within physical layer and or software such as a web browser that facilitates access to workloads layer and or service management layer .

Referring now to there is depicted a high level block diagram of a portion of a data processing environment employing virtualization in accordance with one embodiment. For example data processing environment can implement a portion of cloud depicted in .

In the depicted embodiment data processing environment includes a network which may include one or more wired or wireless local area networks LANs or wide area networks WANs such as the Internet. Connected to network is a high performance access switch providing OSI Layer 2 connectivity to network for one or more physical hosts including physical host which is connected to access switch by a high bandwidth physical link . For example physical link may have a bandwidth of 40 Gb s 100 Gb s or more.

Physical host of can be implemented for example utilizing a data processing system as depicted in . For example in the depicted example network interface s of physical host include a Peripheral Component Interconnect Express PCIe Converged Network Adapter CNA . In the depicted embodiment PCIe CNA includes a Virtual Ethernet Bridge VEB coupled to physical link as well as support for a plurality of diverse OSI Layer 2 networks. Thus in this example PCIe CNA includes at least a Fibre Channel Host Bus Adapter FC HBA and a Converged Enhanced Ethernet CEE Network Interface Card NIC .

Physical host executes a VMM which virtualizes and manages the resources of physical host for example under the direction of VMMM executing on a management console within cloud . VMM supports the execution of one or more and potentially thousands of VMs which in the depicted example include VMs . In various embodiments VMs can include VMs of one or more cloud consumers and or a cloud provider. In the depicted embodiment each of VMs has at least one and in some cases multiple of virtual network interfaces which provide network connectivity at least at Layer 2 of the OSI model.

As depicted VMM provides one or more and in the depicted embodiment at least two virtual networks to which its VMs can attach. For example in the depicted embodiment VMM provides a first virtual Layer 2 network through the implementation of a virtual switch VS including a VEB . VMM similarly provides a second virtual network through the implementation of FC N Port Identifier Virtualization FC NPIV . In various embodiments each of the virtual networks supported by VMM can be for example a private network of a particular cloud consumer a collaborative private network shared by multiple cloud consumers and or a cloud provider or a public network.

In the depicted example network interface of VM is connected via VEB to the first virtual network and network interface of VM is connected to the second virtual network via FC NPIV . Similarly network interface of VM is connected via VEB to the first virtual network and network interface of VM is connected to the second virtual network via FC NPIV . VM includes an additional network interface that bypasses the virtual networks supported by VMM and the concomitant overhead and is connected via VMM directly to a stack provided as a virtual function of CEE NIC . As further shown in FC NPIV is connected to FC HBA of PCIe CNA and VEB of VS is connected to CEE NIC . The traffic of FC HBA and CEE NIC converge at VEB of PCIe CNA .

As discussed further below VMM improves the management and utilization of the high bandwidth of physical link by collaboratively managing the physical link as a collection of virtual links VLs also referred to in the art as S channels . The implementation of S channels for edge virtual bridging is described for example in IEEE standard IEEE 802.1ad also known as IEEE 802.1QinQ dated May 26 2006 and in draft standard IEEE P802.1Qbg dated Dec. 20 2010 which are incorporated herein by reference.

With reference now to there is illustrated a second high level logical view of the portion of the exemplary data processing environment depicted in . In particular depicts that VMM of physical host virtualizes physical link to access switch by creating and managing a plurality of virtual links which are formed by tagging the frames of each virtual link with a respective one of a plurality of different provider bridging service tags S Tags . As depicted in VMM may assign each of virtual links to a respective one or multiple of VMs Alternatively VMM may allocate one or more of virtual links on a per cloud customer basis. Further in embodiments in which physical host executes multiple simultaneous VMMs one or more of virtual links may be assigned on a per VMM basis.

As further indicated in virtual links span at least from VMM to access switch meaning that PCIe CNA need not provide explicit support for virtual links . In some embodiments VMs need not and in one preferred embodiment do not have the capability of tagging or untagging frames of network traffic. In alternative embodiments virtual links further extend across VMM to one or more of VMs by enabling at least some of VMs to apply S Tags to their respective frames. In the depicted embodiment in which virtual links span between VMM and access switch VMM applies S Tags to frames originated by VMs by reference to one or more data structures such as forwarding tables of one or more virtual Layer 2 networks implemented by VMM which associate particular source Layer 2 e.g. MAC addresses with corresponding S Tags. Access switch may similarly apply S Tags to frames to be communicated over physical link by reference to forwarding table which associates particular destination Layer 2 addresses with corresponding S Tags.

Configuration and management of virtual links is implemented by a virtual link manager VLM supported by VMM . In the illustrated embodiment VLM includes two components a virtual link management module VL MM providing an external management interface e.g. an application programming interface API and or command line interface CLI and a virtual link control module VL CM that implements and monitors virtual links in accordance with VL management commands received from VL MM . It should be appreciated that VLM need not include a distinct management module i.e. VL MM and can alternatively be implemented monolithically either within VMM or as a management process running on top of VMM .

In one preferred embodiment the management functions supported by VLM and implemented for example via input s to the interface s of VL CM include those summarized in Table I below.

In response to receipt of an input signifying a management function VLM preferably collaborates with access switch to implement the desired allocation of and manage frame transmission on physical link on a per virtual link basis. For example in one preferred embodiment VLM discovers the VL capabilities of access switch exchanges configuration parameters with access switch and configures VL parameters utilizing the VL Control Protocol VLCP . In this preferred embodiment VLCP which runs over virtual links i.e. protocol frames are tagged with S Tags using the Edge Control Protocol ECP defined by IEEE 802.1Qbg as the transport protocol and employs the Type Length Value TLV specification defined in IEEE 802.1ab incorporated by reference herein to enable configuration parameter exchange and configuration between VLM and access switch .

Assuming that the VLM and access switch agree on parameters for the virtual links VLM records the parameters as VL configuration parameters VL CP which can conveniently be organized in some type of data structure such as a table. Referring now to there is depicted one exemplary embodiment of VL CP implemented as a table. In the exemplary embodiment VL CP includes a plurality of entries each corresponding to a respective one of virtual links spanning physical link . Each entry includes a S Tag field specifying the S Tag utilized to define the associated virtual link and identify the frames thereof as well as a bandwidth field specifying the share of the bandwidth of physical link allocated to the associated virtual link expressed for example as a percentage of the total link bandwidth or as an absolute value. Bandwidth field may further indicate whether the provisioned bandwidth is fixed or can be varied up and or down based on dynamic bandwidth utilization by other virtual links . Each entry additionally includes a Quality of Service QoS class field which may indicate for example packet delay characteristics packet drop characteristics e.g. lossy versus lossless and a VL priority for prioritizing service in a resource constrained system. Entry may optionally further include a QoS algorithm field specifying a QoS algorithm utilized to compute the QoS for the associated virtual link and a notes field for documenting one or more additional parameters of the associated virtual link .

With reference now to there is depicted a high level logical flowchart of the operation of VLM in accordance with one embodiment. The process begins at block which depicts VMM initializing VLM to configure manage and control virtual links implemented over physical link . Thereafter the process proceeds to block which depicts VLM monitoring the state statistics and performance of virtual links while awaiting an occurrence of an event. The monitoring at block includes monitoring for per link compliance with the parameters recorded in VL CP .

In response to detection of an event at block VLM determines the type of the event at block . In response to a determination that the detected event is a VL error event indicating occurrence of an error the process proceeds from block to block which depicts VLM terminating the virtual link for which error the error was detected logging the error and freeing resources associated with the terminated virtual link . The freed resources include for example resources utilized to monitor the terminated virtual link and the associated entry in VL CP . The process then returns from block to block which has been described.

Referring again to block in response to a determination that the detected event is a VL manage event representing receipt of a input via VL MM the process proceeds from block to block . Block depicts VLM invoking the exchange of proposed virtual link parameters for a particular virtual link between VMM and access switch . The proposed virtual link parameters can implement any of the VL management functions summarized in Table I supra including provisioning or tearing down a virtual link allocating or reallocating bandwidth to a virtual link determining QoS or security parameters for a virtual link etc. As described above the proposed virtual link parameters can be communicated for example utilizing VLCP.

As noted above the payload of the exemplary ECPDU is an ULPDU field containing a VLCP TLV as defined by IEEE 802.1ab. In the depicted embodiment VLCP TLV includes a TLV type field identifying the type of TLV in this example Type 0 signifying the end of a PDU a TLV information string length field specifying a length of the TLV e.g. in octets a bandwidth share field specifying a bandwidth share for the relevant virtual link expressed for example as a percentage or absolute value a QoS class field specifying a QoS class for the virtual link an algorithm ID field specifying an identifier of an algorithm utilizing to allocate and measure bandwidth utilization and QoS for the virtual link and a reserved field .

Returning to following transmission of the proposed virtual link parameters to access switch at block VLM determines at block whether or not the proposed virtual link parameters were agreed to by access switch . The determination shown at block can be made for example based upon whether access switch acknowledged the virtual link parameters transmitted at block for example by responding with a ECPDU of the general form depicted in containing an ECP acknowledgment. In response to a determination at block that the proposed virtual link parameters were not acknowledged by access switch meaning that the configuration of the virtual link was unsuccessful the process proceeds to block which depicts VLM terminating the virtual link for which configuration was attempted and freeing any resources associated with the terminated virtual link . Thereafter the process returns to block which has been described. If however VLM determines at block that the proposed virtual link parameters were acknowledged by access switch meaning that the configuration of the virtual link was successful the process proceeds to block which depicts VLM implementing the proposed virtual link configuration for the relevant virtual link and recording the virtual link parameters in the relevant entry of VL CP . Thereafter the process shown in returns to block which has been described.

Returning now to block in response to a determination at that the event type of the detected event is VL enforce meaning that VLM has detected a deviation of the monitored statistics of a virtual link from VL CP the process proceeds from block to block . Block depicts VLM enforcing VL CP for the relevant virtual link . For example if the detected deviation resulted from a virtual link utilizing a greater bandwidth share than allocated to the virtual link then VLM may for example impose a queuing delay on one or more VMs associated with the virtual link either internally to VMM or through messaging with one or more VMs . If on the other hand the detected deviation from VL CP was a lower QoS than specified by VL CP then VLM may enforce the QoS specified for the virtual link by VL CP for example by increasing the QoS priority of frames of the relevant virtual link . Following block the process of returns to block which has been described.

With reference now to there is illustrated an exemplary state machine that may be implemented per virtual link by VLM to implement the process of in accordance with one embodiment. In the depicted embodiment state machine begins in INIT initialization state in which the associated virtual link is idle and no associated configuration has been established.

State machine then proceeds from INIT state to ST VL PROCESSING Station Virtual Link Processing state in response to an input enabling the associated virtual link . In ST VL PROCESSING state VLM transmits proposed virtual link parameters TxTLV sysCfg to access switch as discussed above with reference to block of and and then initializes and invokes an acknowledgement timer ACKTimer . If the acknowledgment timer times out prior to receipt by VLM of an acknowledgement of the proposed virtual link parameters then the virtual link is idled and state machine returns to INIT state . If however access switch confirms by an acknowledgment message the proposed virtual link parameters prior to expiration of the acknowledgment timer state machine proceeds to ST VL OPER Station Virtual Link Operating state .

While state machine is in ST VL OPER state the associated virtual link is in the operating OPER state and employs a configuration operCfg mutually agreed upon by VLM and access switch . In response to receipt of an input disabling the virtual link state machine returns from ST VL OPER state to INIT state which is described above.

Referring now to there is depicted an exemplary state machine that may be implemented per virtual link by access switch to support the process of in accordance with one embodiment. In the depicted embodiment state machine begins in INIT initialization state in which the associated virtual link is idle and no associated configuration has been established.

State machine then proceeds from INIT state to BR VL PROCESSING Bridge Virtual Link Processing state in response to an input enabling the associated virtual link and proposed virtual link parameters as discussed above with reference to block of and . In response to a determination by access switch not to implement the proposed virtual link parameters access switch does not send an acknowledgment of the proposed virtual link parameters and state machine returns to INIT state . If however access switch makes a determination to implement the proposed virtual link parameters state machine proceeds to BR VL OPER Bridge Virtual Link Operating state .

When state machine transitions to BR VL OPER state access switch confirms its implementation of the proposed virtual link parameters by transmitting an acknowledgment message txTLV . The associated virtual link thereafter remains in the operating OPER state and employs a configuration operCfg mutually agreed upon by VLM and access switch until an input is received disabling the virtual link . When such an input is received state machine returns from BR VL OPER state to INIT state .

As has been described in some embodiments a physical host executes a virtual machine monitor VMM that instantiates a plurality of virtual machines VMs . The VMM supports processing of a virtual link manager VLM that deploys and configures a plurality of Layer 2 virtual links sharing bandwidth of a Layer 2 physical link between the physical host and an access switch. The VMM communicates parameters of the plurality of virtual links with the access switch for example by utilizing ECP to transport a VLCP TLV.

While the present invention has been particularly shown as described with reference to one or more preferred embodiments it will be understood by those skilled in the art that various changes in form and detail may be made therein without departing from the spirit and scope of the invention. For example it should be understood that although the detailed description provided herein provides multiple embodiments of cloud computing environments the teachings disclosed herein are not limited to cloud computing environments. Rather embodiments can be implemented in any other type of computing environment now known or later developed including client server and peer to peer computing environments.

Further although aspects have been described with respect to computer systems executing program code that direct the functions described herein it should be understood that embodiments may alternatively be implemented as a program product including a storage medium e.g. data storage storing program code that can be processed by a data processing system to cause the data processing system to perform one or more of the described functions.

