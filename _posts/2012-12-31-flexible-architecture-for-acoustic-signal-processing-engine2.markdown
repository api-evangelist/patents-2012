---

title: Flexible architecture for acoustic signal processing engine
abstract: A disclosed speech processor includes a front end to receive a speech input and generate a feature vector indicative of a portion of the speech input and a Gaussian mixture (GMM) circuit to receive the feature vector, model any one of a plurality of GMM speech recognition algorithms, and generate a GMM score for the feature vector based on the GMM speech recognition algorithm modeled. In at least one embodiment, the GMM circuit includes a common compute block to generate feature a vector sum indicative of a weighted sum of differences squares between the feature vector and a mixture component of the GMM speech recognition algorithm. In at least one embodiment, the GMM speech recognition algorithm being modeled includes a plurality of Gaussian mixture components and the common compute block is operable to generate feature vector scores corresponding to each of the plurality of mixture components.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09653070&OS=09653070&RS=09653070
owner: Intel Corporation
number: 09653070
owner_city: Santa Clara
owner_country: US
publication_date: 20121231
---
Disclosed subject matter relates to acoustic signal processing and in particular the processing of speech and other acoustic signals using a Gaussian mixture model.

Automated electronic processing of speech and other acoustic signals is challenging due in part to the wide variety of pronunciations accents and speech characteristics of individual speakers. Constraints such as language models and acoustic models are used to make decisions about the words the user speaks but acoustic models are often mathematically intensive. What is needed is a flexible efficient and robust way of achieving speech recognition in a device such as a mobile phone tablet or other computing device.

Embodiments of the invention pertain to a technique for providing speech recognition using a Gaussian mixture model GMM . An advantage of using GMMs to perform acoustic signal processing is that GMMs are capable of representing a large class of sample distributions in an overall population. A powerful attribute of a GMM is its ability to form smooth approximations of arbitrarily shaped densities. In one embodiment a disclosed speech recognition technique includes a GMM whereas in other embodiments other models may be used. In one embodiment a speech recognition technique includes logic to support large vocabulary continuous speech recognition for mobile or other computing devices.

In one embodiment acoustic modeling of speech includes establishing statistical representations of feature vector sequences computed from a speech waveform. In one embodiment acoustic modeling includes pronunciation modeling wherein a sequence of multi sequences of fundamental speech units are used to represent larger speech units such as words or phrases which are the object of speech recognition. In some embodiments acoustic modeling may also include the use of feedback information from the recognizer to reshape the feature vectors of speech.

At least one embodiment includes a flexible architecture for implementing a GMM to support multiple speech recognition algorithms. In at least one embodiment the GMM architecture may be at least partially implemented as logic in a semiconductor device such as a general purpose microprocessor system on a chip audio signal processing or other device. In at least one embodiment GMM logic may be integrated within an execution core of a processor while in other embodiments the GMM logic may be implemented as an accelerator or coprocessor. In still other embodiments GMM logic may be implemented in an I O device in communication with an I O hub or chipset device.

In at least one embodiment disclosed GMM scoring logic is suitable for use in a mobile platform that may include a system on chip embedded or other type of mobility optimized processor. In at least one embodiment GMM scoring logic may be implemented as an I O or peripheral device in communication with a system s process via a chipset or other intermediary. These embodiments may include application program software and or driver software to access the GMM scoring logic.

In at least one embodiment disclosed GMM scoring logic includes an input to receive a feature vector indicative of a portion of speech or another acoustic signal and logic to model any one of a plurality of GMM speech recognition algorithms and generate a GMM score for the feature vector based on the GMM speech recognition algorithm modeled. In at least one embodiment the GMM circuit includes a common compute block to generate a vector sum indicative of a weighted sum of differences squared between the feature vector and a mixture component of the applicable GMM speech recognition algorithm. In at least one embodiment the GMM speech recognition algorithm being modeled includes a plurality of Gaussian mixture components each having an associated mean and variance and the common compute block is operable to generate feature vector scores corresponding to each of the plurality of mixture components.

In at least one embodiment GMM scoring logic includes a score selection block to receive feature vector scores and algorithm inputs implement the modeled GMM speech recognition algorithm based on the algorithm inputs and generate the GMM score for the modeled speech recognition algorithm based on the feature vector scores. In at least one embodiment the GMM scoring logic supports algorithms that employ logarithmic summation as well as algorithms that employ a maximum algorithm inputs include a logarithmic summation mode input indicative of whether the applicable GMM speech recognition algorithm implements a logarithmic summation calculation to determine the GMM score.

In at least one mobile platform embodiment a mobile device such as a tablet device or a smartphone device includes a processing core to execute instruction set instructions machine readable storage to store instructions executable by the processing core and a power manager to receive power from a battery and provide power to the processing core and other components of the mobile device platform. The mobile device embodiment may further include a radio frequency transceiver to establish a wireless communication transport a touchscreen display to receive touch input and an audio coder decoder to receive audio input and generate a feature vector comprising a digital representation the audio input. In at least one embodiment the mobile device includes GMM scoring logic to receive algorithm inputs indicating which of a plurality of supported GMM speech recognition algorithms is selected. The GMM scoring logic may generate a GMM score for the feature vector based on the GMM speech recognition algorithm indicated by the algorithm inputs. In at least one embodiment the mobile device is operable to initiate a search for text based on the GMM scoring logic by the GMM scoring logic. In at least one embodiment the mobile device transmits the GMM score via the wireless communication transport to a remote search engine.

In at least one embodiment the GMM scoring logic includes a sum of differences squared circuit to receive the feature vector and generate a GMM sum indicative of a weighted sum of differences squared between the feature vector and a mixture component of the applicable GMM speech recognition algorithm. In at least one embodiment the speech recognition algorithm includes a plurality of mixture components and the sum of differences squared circuit is invoked once for each mixture component to generate a plurality of GMM sums corresponding to the feature vector. In at least one embodiment the GMM scoring logic includes score processing logic to determine the GMM score based on the plurality of GMM sums received from the sum of differences squared. In at least one embodiment the score processing logic supports logarithmic summation score processing techniques as well as maximum minimum score processing and the score processing logic receives configuration inputs to indicate the score processing technique associated with the application GMM speech recognition algorithm.

In at least one embodiment a disclosed processor includes a processing core to execute instruction set instructions an audio interface to receive feature vector data where the feature vector includes a digital representation of a speech sample and a GMM scoring logic to generate a GMM score corresponding to the feature vector. The GMM scoring logic may include weighted sum of differences squared SODS logic to compute a GMM sum indicative of differences between elements of the feature vector and corresponding elements of a GMM component mixture. At least one embodiment of the GMM scoring logic includes algorithm selection logic to select a first GMM scoring algorithm from a plurality of supported GMM scoring algorithms including a logarithmic summation scoring algorithm and a maximum summation scoring algorithm. In at least one embodiment the SODS logic includes a plurality of stages and each of the stages includes a plurality of circuits to determine a squared value of a difference between two inputs from a preceding stage and a weighting to apply to the squared value.

In at least one embodiment a disclosed hardware assisted speech recognition application program is implemented as a computer readable storage medium that includes processor executable instructions which when executed by the processor cause the processor to provide algorithm selection inputs indicative of a first speech recognition algorithm to GMM scoring logic detect a feature vector comprising a digital representation of an interval of speech invoke the GMM scoring logic to generate a GMM score for the feature vector based on the first speech recognition algorithm and initiate a search for text based on the GMM score. In at least one embodiment the instructions to initiate the search include instructions to transmit the GMM score wirelessly to a remotely located speech recognition database and to receive a wirelessly transmitted search result including search result text. In at least one embodiment the instructions further include instructions to display the text on a display device for use in conjunction with a speech to text application. The application program may further include instructions to select the display text for use in conjunction with other features such as email text messaging and social network features.

In at least one embodiment a disclosed tangible machine readable medium includes a set of information stored on the medium representing hardware logic circuits which if used by a machine causes the machine to fabricate hardware logic circuits that include first logic to receive a feature vector and compute a sum of weighted differences squared value based on the feature vector and a mixture vector that includes a mean vector and a variance vector. The logic circuits may also include second logic to receive from the first logic the sum of weighted differences squared values for each of a plurality of mixture vectors associated with a Gaussian mixture mode implementation. The second logic generates based on a Gaussian mixture mode scoring algorithm a Gaussian mixture mode score. In at least one embodiment the hardware logic circuits support multiple GMM scoring algorithms and the second logic is operable to receive or access scoring algorithm values and computes the GMM score based on a scoring algorithm indicated by the scoring algorithm values.

Throughout this disclosure a hyphenated form of a reference numeral refers to a specific instance of an element and the un hyphenated form of the reference numeral refers to the element generically or collectively. Thus for example widget refers to an instance of a widget class which may be referred to collectively as widgets and any one of which may be referred to generically as a widget .

Referring now to the drawings illustrates elements of one embodiment of an acoustic signal processing engine that employs Gaussian mixture model scoring. In the embodiment acoustic signal processing engine includes an input to receive audio input that is digitized with an analog to digital converter ADC . Samples from the output of ADC are provided to audio processing hardware and or software referred to herein as front end to perform pre emphasis framing windowing and computations to extract ceptral coefficient feature vectors from digitized samples . In at least one speech recognition embodiment of acoustic signal processing engine a feature vector provided to GMM scoring logic is a numerical representation of an interval of speech input where the interval of speech may be on the order of approximately 10 ms. In the embodiment feature vectors generated by front end are provided to a GMM scoring block .

The embodiment of GMM scoring block may compute scores for sub phonetic context dependent units based on feature vectors . The embodiment of GMM scoring block includes sum of weighted differences squared SOWDS logic and score selection logic . The SOWDS logic and score selection logic are used to compute or otherwise obtain a GMM score corresponding to each feature vector . In the embodiment depicted in GMM scores are provided to a back end search . Back end search may use GMM score as the basis for a search for text corresponding to the GMM score. The search performed by back end search may include a search of a locally stored database referred to as active GMM database . Active GMM database may function analogous to a cache memory by storing results of recently performed searches. Back end search may also initiate a remote search by wirelessly or otherwise transmitting GMM score to a remotely located search engine not depicted in . The embodiment of back end search generates text output corresponding to GMM score .

In at least one embodiment back end search is implemented at least partially in software to identify a spoken utterance corresponding to GMM score by recursively finding a most likely hidden Markov model HMM state trajectory through a series of HMMs. Back end search may in some embodiments map the log likelihoods from GMM scoring logic to HMM states that model context dependent phonemes. A maximum likelihood state trajectory may then be determined via a Viterbi algorithm. HMM to HMM transition weightings may be determined according to a pronunciation dictionary that defines a target vocabulary. Word to word transition weightings may then be determined according to a statistical language model. Eventually a back trace of the most likely path may be provided to determine a set of N best word sequences.

As indicated previously the embodiment of acoustic signal processing engine maintains a cache of search results in active GMM database . In this embodiment acoustic signal processing engine may refer to active GMM database instead of initiating a remote search. Based on the back end search performed in software the hardware supports the ability to reduce the search space by reducing the number of GMM s to be scored on the next invocation of the hardware through an active GMM list . This feature may be optionally disabled to force GMM scoring logic to computer a GMM for each feature vector and to provide the GMM score to back end search .

Referring now to an embodiment of SOWDS logic of GMM scoring logic is illustrated. The embodiment of SOWDS logic includes an input to receive a feature vector X extracted by the front end block and inputs and to access or receive a vector referred to herein as a mixture vector corresponding to a component of a Gaussian mixture model. In the embodiment a mixture vector is represented by the combination of a mean vector M and a variance vector V . In the embodiment feature vector X mean vector M and variance vector V are all vectors having n elements. In some embodiments all n elements of variance vector V may have the same value.

The embodiment of SOWDS logic includes resources to receive the n elements of feature vector X and mean vector M in parallel and includes a 5 stage pipeline for performing sum of weighted differences squared values in a pair wise fashion until a final weighted sum of differences squared value is produced by adder circuit . In theory feature vector may include any number of vector elements but based on known algorithms a feature vector having elements or less is typical with 24 to 96 vector elements being common. If the number of vector elements exceeds the number of vector component inputs that SOWDS logic can accommodate SOWDS logic may require multiple clock cycles to receive an entire feature vector and a corresponding mixture vector. If for example input of SOWDS logic includes 48 vector component inputs and feature vector X has less than 48 elements an entire feature vector X and an entire corresponding mixture vector including mean vector M and variance vector V can be received in each clock cycle. If the number of feature vector elements is greater than 48 two or more cycles would be necessary to receive the entire feature vector and its corresponding mixture vector. For the embodiment assuming n is less than or equal to 48 the depicted implementation of SOWDS logic illustrates the computation or generation of a final sum in five clock cycles and the generation of one subsequent final sum value every clock cycle thereafter.

The embodiment of SOWDS logic includes n instances of sum of differences squared SODS logic in stage of the pipeline demarcated by the first stage latches to compute n SODS values for the n elements of feature vector X and the corresponding n elements of mean vector M i.e. x m for i 1 to n. In the embodiment each instance of SODS logic includes a difference circuit that computes the difference between a feature vector element and a corresponding element of the mean vector an absolute value circuit a multiplier and a latch . In some embodiments the absolute value circuit may be omitted.

In the embodiment of stage the SODS value from first stage latch is multiplied by the output from multiplexer in multiplier and provided to the SOWDS value to stage latch . Depending upon an value of a variance bypass input parameter BYPASS VAR multiplexer provides either the applicable element of variance vector V or a value of 1 i.e. no weighting to multiplier . The outputs of adjacent pairs of second stages latches e.g. latches and are then summed by adders e.g. adder . The outputs of adjacent pairs of adders only one adder of the pair is shown are then summed by adders e.g. adder . The outputs of adjacent pairs of adders are then summed in adders and the outputs of adders are provided to respective stage latches . In stage outputs of adjacent pairs stage latches are summed in adders and the outputs of adjacent pairs of adders are summed in adders . In the embodiment only one adder is needed because there is only one adjacent pair of adders . In the embodiment the output of adder is added to the output of the unpaired adder in adder and the output of adder is provided to stage latch . The output of stage latch which is the output from SOWDS logic is FINAL SUM . While depicts SOWDS logic as being implemented in 5 pipelines stages the number of stages is an implementation detail influenced by the number of input components i.e. the number of elements in a feature vector X as well as the speed of the logic elements. For example FIG. represents stage and stage as being able to complete three consecutive summations in a single clock cycle but other embodiments may be capable of more or less than three consecutive summations per clock cycle and the number of stages required may change accordingly.

A Gaussian mixture model typically includes multiple mixtures and each mixture is characterized by a mean and a variance. SOWDS logic generates a final sum for each mixture. If for example a Gaussian mixture model includes 6 Gaussian mixtures and the number of elements in feature vector X permits receiving an entire feature vector per clock cycle SOWDS logic will generate 6 final sum values when for each feature vector is provided. Qualitatively each final sum represents a probabilistic similarity between the feature vector X and the applicable Gaussian mixture.

Referring now to an embodiment of the score selection logic of is depicted. A variety of algorithms are used in conjunction with generating GMM scores for observed objects and the different algorithms may generated significantly different results for the same input. The embodiment beneficially employs a flexible architecture to provide hardware based support for a variety of different algorithms including algorithms that employ a logarithmic summation of the final sum values and algorithms that employ a maximum minimum selection.

In the embodiment score selection logic receives or obtains values for a number of input parameters that define the algorithm to be used. The score selection logic determines GMM score from the sets of final sum values generated by SOWDS logic . In the embodiment of score section logic the inputs include but are not limited to LOG THRESHOLD LOG SCALING GCONST LRD WEIGHT FINAL SUM BEST SCORE INIT LOGADD MODE BYPASS VAR and GRAND VAR .

By using some of these input parameters as control signals for multiplexer circuits the embodiment of score selection logic determines a GMM score based on either a logarithmic summation technique represented by logarithmic summation logic and a MAXMIX logic . The LOGADD MODE input for example provides the control function for a number of multiplexers including multiplexers and while the variance bypass parameter BYPASS VAR provides input to multiplexer and multiplexers .

In the embodiment an intermediate value labeled in as GAUSCORE is generated based on the final sum from SOWDS logic and either an LRD parameter or a GCONST input depending upon the algorithm in use. GAUSCORE is provided either to a logarithmic summation logic identified as logarithmic summation logic or maximum minimum logic identified as MAXMIX logic . The outputs of logarithmic summation logic and MAXMIX logic are latched in latches and and thereafter provided to multiplexer which selects one of the two values based on the values of LOGADD MODE parameter .

Referring now to an embodiment of a MAXMIX score selection logic is depicted. The embodiment of MAXMIX logic includes receives GAUSCORE and an initial value BEST SCORE INIT . Subtraction logic generates a control input SIGN for multiplexer which selects between the current maximum and the current value of GAUSCORE as the NEW BEST SCORE . This process is performed recursively for each final sum produced in SOWDS block resulting in a final value of NEW BEST SCORE which becomes the GMM Score depending on the variance bypass signal.

Referring now to an embodiment of logarithmic summation logic is depicted. The operation performed in logarithmic summation logic represents a summation of an average and a correction factor composed of a constant and a term based on a difference between the input arguments. In the embodiment GAUSCORE from is provided to difference block to compute a difference between GAUSCORE and BEST SCORE IN . BEST SCORE IN is selected by multiplexer from BEST SCORE INIT and BEST SCORE OUT .

In flexible log add approximation block block checks to determine if the difference found in block is greater than LOG SCALING while block checks to determine if the difference is less than LOG THRESHOLD . The output of block is provides a control input to multiplexer which selects between two values as BEST SCORE OUT .

Referring now to a flow diagram illustrates an embodiment of a speech processing method . Method may represent operations performed by a processor executing a sequence of processor executable program instructions. The instructions may be stored in a computer readable storage medium. Although shown in a particular sequence or order unless otherwise stated the order of actions can be modified. is a flow diagram illustrating a method for a flexible and programmable Gaussian mixture model scoring architecture used in speech recognition system

In the embodiment a feature vector X and a set of M Gaussian mixture mean vectors M and variance vectors V are received operation by GMM scoring logic . A sum of weighted differences squared computation is then performed operation by SOWDS logic to calculate a set of M final sums one for each mixture . The M final sums are then processed operation using a GMM scoring algorithm determined by values of algorithm specific parameters to obtain a GMM score corresponding to the feature vector . The GMM score is then provided block to a speech recognition search engine to obtain a text corresponding to the GMM score as a search result.

If parameters supplied to score selection logic indicate an algorithm that employs MAXMIX then the flow proceeds to process block and a MAXMIX computation is performed. In the parameters indicate a logarithmic summation approximation the appropriate computation is performed.

The GMM scoring logic may be implemented in various types of systems and platforms including a mobile device platform that might include a tablet device and or a smartphone device. Referring now to a block diagram of selected elements of at least one embodiment of a mobile device employing GMM scoring logic as described herein is depicted. The embodiment of mobile device features a processing core implemented in a System on Chip device a system controller implemented on a processing hub and integrated power management and radio frequency functions. The embodiment of mobile device is representative of a mobile device suitable for incorporating a GMM scoring engine as described above. However it will be apparent to one skilled in the art that other embodiments may include more less or different hardware and software elements illustrated in .

In the embodiment mobile device includes a system on chip device a platform controller hub and a radio frequency integrated circuit . The system on chip device includes a processor and integrated features including a graphics display adapter a memory controller a video encoder and a video decoder . The platform controller hub includes a system controller and various features I O interfaces including an image processor suitable for use with a digital camera not depicted a touchscreen controller audio codecs and a general purpose I O block . In the embodiments I O block includes a USB controller and an HDMI controller . An SSD controller is operable to interface with persistent storage . The embodiment SOC depicted in further includes a display touchscreen element and system memory . A power management integrated circuit interfaces with processor and system controller to reduce power consumption in mobile device .

Radio frequency integrated circuits as depicted include support for various wireless interfaces including a Wi Fi interface and one or more cellular interfaces that provide support for various wireless cellular interfaces including as examples 3G LTE WiMAX and 4G. Radio frequency integrated circuit as shown further includes Bluetooth support and a global positioning system GPS capable receiver .

The embodiment of processor may include dedicated L1 instruction and data caches a shared L2 cache and dual instances of function centric execution clusters to support execution of two threads. In at least one embodiment suitable for mobile and other battery based platforms processor may include any one or more of a number of power conservation features.

The embodiment of device supports a wake on speech feature that employs a microcontroller connected to a microphone represented in by a micro electrical mechanical MEMs microphone . MEMs microphone is connected in the depicted embodiment to microcontroller via a serial bus. In the embodiment the serial bus is a USB bus supported by USB host controller .

Microcontroller may be implemented as a configurable extensible core that uses a subset of a more general purpose instruction set e.g. a subset of an x86 instruction set . The core of microcontroller in one embodiment can be customized with new instructions for accelerating a target workload since it is flexible. Microcontroller may be configured for efficient operation that can be used in ultra low power devices and system on chip subsystems.

In at least one embodiment microcontroller executes a stored program identified in as wake on speech application . Embodiments of wake on speech application group audio samples from MEMs microphone into overlapping blocks and performs feature extraction on them. Microcontroller may then store data indicative of extracted feature vectors in system memory or another data store resource. Microcontroller may then invoke GMM scoring circuit by for example accessing control registers to initiate GMM scoring. GMM scoring circuit may then calculate scores for a speech model and a background model and store the scores to a suitable storage medium. In some embodiments GMM scoring circuit notifies microcontroller that the scoring is complete. Microcontroller may then compare scores to a threshold and declares the audio to be speech or non speech. Microcontroller may then then write the result to a GPIO pin not depicted used to wake a DSP not depicted for further analysis of the voice signal. In this manner the combination of MEMs microphone microcontroller and wake on speech application program provide a low power discrete system to perform wake up on speech activity.

Referring now to an embodiment of a processor architecture suitable for the mobile device platform of includes a front end cluster to fetch decode and issue instructions to the execution clusters. The embodiment of front end cluster includes an instruction cache that receives an address generated by branch prediction unit and outputs instruction code to prefetch buffers and . Each prefetch buffer feeds an instruction length decoder that support a variable length instruction architecture. A microcoding unit translates the architected instructions into microcode instructions executable in the execution clusters.

Microcoded instructions generated by microcoding unit are provided to per thread instances of instruction issue queues . A front end cluster communicates with issue queues over dual channels that support two instructions issued per cycle. In at least one low power embodiment processor is an in order processor in which instructions are issued and executed in program order. In order instruction execution beneficially eliminates the requirement for relatively complex and power consuming circuitry needed to support out of order execution.

The execution clusters of the embodiment of processor include a complex execution cluster an integer execution cluster and a memory access cluster . In at least one embodiment front end cluster generates two instructions per cycle and provides the issued instructions to one of the instruction queues . In embodiments that include at least some power awareness complex execution cluster employs a power aware design in which special purpose execution units are leveraged to process simpler instructions. The embodiment of processor may employ for example its SIMD integer multiplier to execute instructions that would require otherwise require a dedicated scalar integer multiplier or employ its floating point multiplier to execute instructions that would otherwise require a dedicated integer divider.

The embodiment of complex execution cluster includes a floating point register file a complex instruction unit and a floating point adder . The complex instruction unit depicted in that includes a floating point multiplier a floating point divider a floating point store unit and a single instruction multiple data SIMD multiplier as well as a integer ALU to support operation of the complex execution units. Similarly floating pointer adder The embodiment of floating point unit also includes a single instruction multiple data SIMD multiplier to support common graphics and multimedia operations.

An integer register file communicates with address generation units AGUs and in memory access cluster . Addresses generated by AGUs are routed to dual ported tag array in data cache which exchanges data with integer execution cluster . communicates to an integer execution cluster . The embodiment of data cache is supported by a data prefetcher a translation lookaside buffer to translate virtual or linear addresses to physical address for presentation to a tag array not expressly depicted of data cache and a fill buffer that buffers in flight cache line fills via a bus cluster . The depicted embodiment of bus cluster includes an L2 cache a bus interface unit and an advanced program programmable interrupt controller . Bus interface unit as depicted in communicates with a front side bus suitable for interfacing with an appropriate I O chipset device.

For example at least one embodiment of processor is implemented as an in order processor which instructions are issued and executed substantially in program order. Some embodiments may support inter threaded execution in which front end cluster opts to provide two instructions from the same thread in a single cycle but issue and execution is otherwise in order.

While and emphasize a mobile device platform depicts elements of a platform for a multiprocessor system . The embodiment of system includes a first processor a second processor and an I O hub referred to herein as near hub . Near hub communicates with processor over a point to point interconnect connected between a point to point interface of near hub and a point to point interface of processor . Similarly near hub communicates with processor via point to point interconnect between point to point interface of near hub and point to point interface of processor . In the embodiment near hub also includes a graphics interface to communicate with a graphics adapter over a dedicated graphics bus which may be a PCI Express or other suitable type of interconnection. Multiprocessor system may further include a point to point interconnect not depicted between processor and processor . The point to point interconnects depicted in include a pair of uni directional interconnections with one of the interconnects communicating data from the applicable processor to near hub and the other interconnection communicating data from near hub to the processor .

The processors may be described as including a core portion and an uncore portion . The core portions of the processors include multiple processor cores referred to herein simply as cores through . Each core may include logic implemented in hardware firmware or a combination thereof that provides as examples an execution pipeline suitable for fetching interpreting and executing instructions and storing or otherwise processing results of those instructions. Uncore portions of the processors may include a system memory controller MC a cache memory referred to herein as the last level cache and an interrupt controller . Each system memory interface may perform various memory controller functions. Last level cache may be shared among each of the cores of processor . Interrupt controller may include features of conventional interrupt controllers to manage and prioritize interrupts.

The multiprocessor system employs a distributed or non uniform system memory architecture in which the system memory as a whole is implemented as a plurality of system memory portions with each system memory portion being directly connected to a processor via a corresponding memory interconnect and system memory interface . In this distributed memory configuration each processor may interface directly with its corresponding system memory portion via its local system memory interface . In addition any processor e.g. processor may read from or write to a memory portion e.g. system memory portion associated with a different processor e.g. processor but the originating processing may need to go through one or more point to point interfaces to do so. Similarly the last level cache of each processor may cache data from its own processor s system memory portion or from another processor s system memory portion.

Although depicts a distributed memory configuration other embodiments may employ a uniform memory architecture in which for example the entire system memory is connected to a memory controller implemented in near hub rather than having multiple system memory portion each connected to a corresponding processor specific memory controller implemented in the uncores of each processor . Such a system is described below with respect to . Moreover although depicts a point to point configuration in which processors communicate with each other and with near hub via dedicated point to point interconnections other embodiments may employ a shared system bus to which each of the processors and near hub is connected.

In the embodiment of system near hub includes an I O interface to communicate with a far hub over an I O interconnection . Far hub may integrate within a single device adapters controllers and ports for various interconnection protocols to support different types of I O devices. The depicted implementation of far hub includes as an example an expansion bus controller that supports an expansion bus that complies with PCI PCI Express or another suitable bus protocol. Examples of functions that may be provided via expansion bus include a network adapter an audio controller and a communications adapter . Network adapter may enable communication with an IEEE 902.11 family or other type of wireless data network a Gigabit Ethernet or other type of wire line data network or both. Audio controller may include or support high definition audio codecs. Communications adapter may include or support modems and or transceivers to provide wireless or wire line telephony capability. Bus controller may further recognize a bus bridge that supports an additional expansion bus where expansion bus and expansion bus have the same protocol or different protocols. Far hub may further include a high bandwidth serial bus controller that provides one or more ports of a Universal Serial Bus USB or other suitable high bandwidth serial bus .

The far hub further includes a storage adapter that supports a persistent storage interconnect such as an Integrated Drive Electronics IDE interconnect a Serial ATA interconnect a SCSI interconnect or another suitable storage interconnect to a storage drive that controls persistent storage . Far hub may further include a Low Pin Count LPC controller that provides an LPC bus to connect low bandwidth I O devices including as examples a keyboard a mouse a parallel printer port not depicted and an RS232 serial port not depicted . Multiprocessor system as depicted in employs a Super I O chip to interface keyboard and mouse with LPC controller .

In at least one embodiment the emulated speech processing functionality described herein is suitable employed in a system that includes some or all of various system features. The embodiment of system emphasizes a computer system that incorporates various features that facilitate handheld or tablet type of operation and other features that facilitate laptop or desktop operation. In addition the embodiment of system includes features that cooperate to aggressively conserve power while simultaneously reducing latency associated with traditional power conservation states.

The embodiment of system includes an operating system that may be entirely or partially stored in a persistent storage . Operating system may include various modules application programming interfaces and the like that expose to varying degrees various hardware and software features of system . The embodiment of system includes for example a sensor application programming interface API a resume module a connect module and a touchscreen user interface . System as depicted in may further include various hardware firm features include a capacitive or resistive touch screen controller and a second source of persistent storage such as a solid state drive .

Sensor API provides application program access to one or more sensors not depicted that may be include in system . Examples of sensors that system might have include as examples an accelerometer a global positioning system GPS device a gyrometer an inclinometer and a light sensor. The resume module may be implemented as software that when executed performs operations for reducing latency when transition system from a power conservation state to an operating state. Resume module may work in conjunction with the solid state drive SSD to reduce the amount of SSD storage required when system enters a power conservation mode. Resume module may for example flush standby and temporary memory pages before transitioning to a sleep mode. By reducing the amount of system memory space that system is required to preserve upon entering a low power state resume module beneficially reduces the amount of time required to perform the transition from the low power state to an operating state. The connect module may include software instructions that when executed perform complementary functions for conserving power while reducing the amount of latency or delay associated with traditional wake up sequences. For example connect module may periodically update certain dynamic applications including as examples email and social network applications so that when system wakes from a low power mode the applications that are often most likely to require refreshing are up to date. The touchscreen user interface supports a touchscreen controller that enables user input via touchscreens traditionally reserved for handheld applications. In the embodiment the inclusion of touchscreen support in conjunction with support for keyboard mouse and the enable system to provide features traditionally found in dedicated tablet devices as well as features found in dedicated laptop and desktop type systems.

Referring now to a representation for simulation emulation and fabrication of a design implementing the disclosed techniques. Data representing a design may represent the design in a number of manners. First as is useful in simulations the hardware may be represented using a hardware description language or another functional description language which essentially provides a computerized model of how the designed hardware is expected to perform. The hardware model may be stored in a storage medium such as a computer memory so that the model may be simulated using simulation software that applies a particular test suite to the hardware model to determine if it indeed functions as intended. In at least one embodiment the simulation software is not recorded captured or contained in the medium.

Additionally a circuit level model with logic and or transistor gates may be produced at some stages of the design process. This model may be similarly simulated sometimes by dedicated hardware simulators that form the model using programmable logic. This type of simulation taken a degree further may be an emulation technique. In any case re configurable hardware is another embodiment that may involve a tangible machine readable medium storing a model employing the disclosed techniques.

Furthermore most designs at some stage reach a level of data representing the physical placement of various devices in the hardware model. In the case where conventional semiconductor fabrication techniques are used the data representing the hardware model may be the data specifying the presence or absence of various features on different mask layers for masks used to produce the integrated circuit. Again this data representing the integrated circuit embodies the techniques disclosed in that the circuitry or logic in the data can be simulated or fabricated to perform these techniques.

In any representation of the design the data may be stored in any form of a tangible machine readable medium. An optical or electrical wave modulated or otherwise generated to transmit such information a memory or a magnetic or optical storage such as a disc may be the tangible machine readable medium. Any of these mediums may carry the design information. The term carry e.g. a tangible machine readable medium carrying information thus covers information stored on a storage device or information encoded or modulated into or on to a carrier wave. The set of bits describing the design or the particular part of the design are when embodied in a machine readable medium such as a carrier or storage medium an article that may be sold in and of itself or used by others for further design or fabrication.

To the maximum extent allowed by law the scope of the present disclosure is to be determined by the broadest permissible interpretation of the following claims and their equivalents and shall not be restricted or limited to the specific embodiments described in the foregoing detailed description.

