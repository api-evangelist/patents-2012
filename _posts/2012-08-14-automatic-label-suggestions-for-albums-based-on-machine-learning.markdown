---

title: Automatic label suggestions for albums based on machine learning
abstract: Methods and apparatus for suggesting image, video, and image album titles are presented. A machine-learning service executing on a mobile platform receives feature-related data. The feature-related data includes image-related data related to one or more images received from an application executing on the mobile platform and platform-related data received from the mobile platform. The image-related data and the platform-related data differ. The machine-learning service generates a title related to the one or more images by performing a machine-learning operation on the feature-related data. The machine-learning service sends the title related to the one or more images to the application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08886576&OS=08886576&RS=08886576
owner: Google Inc.
number: 08886576
owner_city: Mountain View
owner_country: US
publication_date: 20120814
---
This application claims priority to U.S. Patent App. No. 61 663 402 entitled Automatic Label Suggestions for Albums Based on Machine Learning filed Jun. 22 2012 the contents of which are fully incorporated by reference herein for all purposes.

Unless otherwise indicated herein the materials described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.

Mobile devices are ubiquitous in modern communication networks. Many of these mobile devices are smart phones capable of running one or more applications while acting as a communication device. The applications and or the smart phone itself can have a number of settings subject to user control such as volume settings network addresses names contact data and calendar information.

A smart phone user can change some or all of these settings based on their context such as location and activity. For example the user can turn down a ringing volume and or mute a ringer prior to watching a movie at a movie theater. After the movie theater completes the user can the turn up the ringing volume and or un mute the ringer.

In one aspect a method is provided. A machine learning service executing on a mobile platform receives data related to a plurality of features. The machine learning service determines at least one feature in the plurality of features based on the received data. The machine learning service generates an output by performing a machine learning operation on the at least one feature of the plurality of features. The machine learning operation is selected from among an operation of ranking the at least one feature an operation of classifying the at least one feature an operation of predicting the at least one feature and an operation of clustering the at least one feature. The machine learning service sends the output.

In another aspect a method is provided. A machine learning service executing on a mobile platform receives feature related data related to a plurality of features. The feature related data includes data related to a first plurality of features received from an application executing on the mobile platform and data related to a second plurality of features received from the mobile platform. The first plurality of features and the second plurality of features differ. The machine learning service determines at least one feature among the first plurality of features and the second plurality of feature based on the feature related data. The machine learning service generates an output by performing a machine learning operation on the at least one feature. The machine learning service sends the output to the application.

In even another aspect an article of manufacture is provided. The article of manufacture includes a non transitory computer readable storage medium having instructions stored thereon that when executed on by a processor cause the processor to perform functions. The functions include a receiving data related to a plurality of features b determining at least one feature in the plurality of features based on the received data c generating an output by performing a machine learning operation on the at least one feature of the plurality of features where the machine learning operation is selected from among an operation of ranking the at least one feature an operation of classifying the at least one feature an operation of predicting the at least one feature and an operation of clustering the at least one feature and d sending the output.

In yet another aspect a mobile platform is provided. The mobile platform includes a processor and a non transitory computer readable storage medium configured to store instructions that when executed by the processor cause the mobile platform to perform functions. The functions include a receiving data related to a plurality of features b determining at least one feature in the plurality of features based on the received data c generating an output by performing a machine learning operation on the at least one feature of the plurality of features where the machine learning operation is selected from among an operation of ranking the at least one feature an operation of classifying the at least one feature an operation of predicting the at least one feature and an operation of clustering the at least one feature and d sending the output.

In a second aspect a method is provided. A context identification system executing on a mobile platform receives data comprising context related data associated with the mobile platform and application related data received from the mobile platform. The context identification system identifies at least one context using the context related data associated with the mobile platform and or the application related data received from the mobile platform. Based on at least one context identified the context identification system predicts a communicative action associated with the mobile platform by performing a machine learning operation on the received data. An instruction is received to execute the communicative action associated with the mobile platform.

In another aspect an article of manufacture is provided. The article of manufacture includes a non transitory computer readable storage medium having instructions stored thereon that when executed on by a processor cause the processor to perform functions. The functions include a receiving data at a context identification system executing on a mobile platform where the received data includes context related data associated with the mobile platform and application related data received from the mobile platform b identifying a context using the context related data associated with the mobile platform and or the application related data received from the mobile platform c based on at least one context identified predicting a communicative action associated with the mobile platform by performing a machine learning operation on the data received and d receiving an instruction to execute the communicative action associated with the mobile platform.

In yet another aspect a mobile platform is provided. The mobile platform includes a processor and a non transitory computer readable storage medium configured to store instructions that when executed by the processor cause the mobile platform to perform functions. a receiving data at a context identification system executing on a mobile platform where the received data includes context related data associated with the mobile platform and application related data received from the mobile platform b identifying a context using the context related data associated with the mobile platform and or the application related data received from the mobile platform c based on at least one context identified predicting a communicative action associated with the mobile platform by performing a machine learning operation on the data received and d receiving an instruction to execute the communicative action associated with the mobile platform.

In a third aspect a method is provided. A machine learning service executing on a mobile platform receives feature related data. The feature related data includes image related data related to one or more images received from an application executing on the mobile platform and platform related data received from the mobile platform. The image related data and the platform related data differ. The machine learning service generates a title related to the one or more images by performing a machine learning operation on the feature related data. The machine learning service sends the title related to the one or more images to the application.

In another aspect an article of manufacture is provided. The article of manufacture includes a non transitory computer readable storage medium having instructions stored thereon that when executed on by a processor cause the processor to perform functions. The functions include i receiving feature related data that includes image related data related to one or more images and platform related data where the image related data and the platform related data differ ii generating a title related to the one or more images by performing a machine learning operation on the feature related data and iii sending the title related to the one or more images.

In yet another aspect a mobile platform is provided. The mobile platform includes a processor and a non transitory computer readable storage medium configured to store instructions that when executed by the processor cause the mobile platform to perform functions. The functions include i receiving feature related data that includes image related data related to one or more images and platform related data where the image related data and the platform related data differ ii generating a title related to the one or more images by performing a machine learning operation on the feature related data and iii sending the title related to the one or more images.

In a fourth aspect a method is provided. A machine learning service executing on a mobile platform receives feature related data. The feature related data includes communications related data related to one or more searches for establishing electronic communications received from an application executing on the mobile platform and platform related data received from the mobile platform. The communications related data and the platform related data differ. The machine learning service determines whether the machine learning service is trained to perform machine learning operations related to predicting outcomes of searches for establishing electronic communications. In response to determining that the machine learning service is trained a the machine learning service receives a request for a predicted outcome of a search for establishing an electronic communication b the machine learning service generates the predicted outcome by performing a machine learning operation on the feature related data and c the predicted outcome is sent to the application.

In another aspect an article of manufacture is provided. The article of manufacture includes a non transitory computer readable storage medium having instructions stored thereon that when executed on by a processor cause the processor to perform functions. The functions include a receiving feature related data at a machine learning service where the feature related data includes communications related data related to one or more searches for establishing electronic communications and platform related data received from the mobile platform and where the communications related data and the platform related data differ b determining whether the machine learning service is trained to perform machine learning operations related to predicting outcomes of searches for establishing electronic communications c in response to determining that the machine learning service is trained i receiving at the machine learning service a request for a predicted outcome of a search for establishing an electronic communication ii generating the predicted outcome by the machine learning service performing a machine learning operation on the feature related data and iii sending the predicted outcome.

In yet another aspect a mobile platform is provided. The mobile platform includes a processor and a non transitory computer readable storage medium configured to store instructions that when executed by the processor cause the mobile platform to perform functions. The functions include a receiving feature related data at a machine learning service where the feature related data includes communications related data related to one or more searches for establishing electronic communications and platform related data and where the communications related data and the platform related data differ b determining whether or not outcomes of searches for establishing electronic communications can be predicted c in response to determining that the outcomes of searches for establishing electronic communications can be predicted i receiving a request for a predicted outcome of a search for establishing an electronic communication ii generating the predicted outcome by performing a machine learning operation on the feature related data and iii sending the predicted outcome.

In a fifth aspect a method is provided. A machine learning service executing on a mobile platform receives feature related data. The feature related data includes usage related data about one or more time spans that the mobile platform is activated and platform related data received from the mobile platform. The usage related data and the platform related data differ. The machine learning service determines whether the machine learning service is trained to perform machine learning operations related to predicting a time span that the mobile platform will be activated. In response to determining that the machine learning service is trained a the machine learning service receives a request for a predicted time span that the mobile platform will be activated b the machine learning service determines the predicted time span by performing a machine learning operation on the feature related data and c the predicted time span is sent to the application.

In another aspect an article of manufacture is provided. The article of manufacture includes a non transitory computer readable storage medium having instructions stored thereon that when executed on by a processor cause the processor to perform functions. The functions include a receiving feature related data at a machine learning service where the feature related data includes usage related data about one or more time spans and platform related data received from the mobile platform and where the usage related data and the platform related data differ b determining whether the machine learning service is trained to perform machine learning operations related to predicting a time span c in response to determining that the machine learning service is trained i receiving at the machine learning service a request for a predicted time span ii determining the predicted time span by the machine learning service performing a machine learning operation on the feature related data and iii sending the predicted time span.

In quite another aspect a mobile platform is provided. The mobile platform includes a processor and a non transitory computer readable storage medium configured to store instructions that when executed by the processor cause the mobile platform to perform functions. The functions include a receiving feature related data at a machine learning service where the feature related data includes usage related data about one or more time spans that the mobile platform is activated and platform related data and where the usage related data and the platform related data differ b determining whether the machine learning service is trained to perform machine learning operations related to predicting a time span that the mobile platform will be activated c in response to determining that the machine learning service is trained i receiving a request for a predicted time span that the mobile platform will be activated at the machine learning service ii determining the predicted time span by the machine learning service performing a machine learning operation on the feature related data and iii sending the predicted time span.

In a sixth aspect a method is provided. A machine learning service executing on a mobile platform receives feature related data. The feature related data includes volume related data about one or more volume related settings for the mobile platform and platform related data received from the mobile platform. The volume related data and the platform related data differ. The machine learning service determines whether the machine learning service is trained to perform machine learning operations related to predicting a change in the one or more volume related settings for the mobile platform. In response to determining that the machine learning service is trained a the machine learning service receives a request for predicting the change in the one or more volume related settings b the machine learning service determining the predicted change in the one or more volume related settings by performing a machine learning operation on the feature related data and c sending the predicted change in the one or more volume related settings.

In another aspect an article of manufacture is provided. The article of manufacture includes a non transitory computer readable storage medium having instructions stored thereon that when executed on by a processor cause the processor to perform functions. The functions include a receiving feature related data at a machine learning service executing on the processor where the feature related data includes volume related data about one or more volume related settings and platform related data and where the usage related data and the platform related data differ b determining whether the machine learning service is trained to perform machine learning operations related to predicting a change in the one or more volume related settings c in response to determining that the machine learning service is trained i receiving at the machine learning service a request for predicting the change in the one or more volume related settings ii determining the predicted change in the one or more volume related settings by the machine learning service performing a machine learning operation on the feature related data and iii sending the predicted change in the one or more volume related settings.

In yet another aspect a mobile platform is provided. The mobile platform includes a processor and a non transitory computer readable storage medium configured to store instructions that when executed by the processor cause the mobile platform to perform functions. The functions include a receiving feature related data at a machine learning service executing on the processor where the feature related data includes volume related data about one or more volume related settings and platform related data received from the mobile platform and where the usage related data and the platform related data differ b determining whether the machine learning service is trained to perform machine learning operations related to predicting a change in the one or more volume related settings for the mobile platform c in response to determining that the machine learning service is trained i receiving at the machine learning service a request for predicting the change in the one or more volume related settings ii determining the predicted change in the one or more volume related settings by the machine learning service performing a machine learning operation on the feature related data and iii sending the predicted change in the one or more volume related settings.

Most mobile platforms such as mobile phones do not adapt to the person s using the platform rather the person s adapt to use the mobile platform. Typically customization of the mobile platform and the applications utilizing the mobile platform is often limited based on implementation decisions.

A machine learning service or machine learning and adaptation service can support automatic adaptation of preferences of person s using the mobile platform. The machine learning service is software running on the mobile platform that provides the necessary functionality for software applications to learn from interactions of person s using the mobile platform.

The machine learning service can communicate with software applications via an Application Program Interface API . The API provides access to several commonly used machine adaptation techniques. For example the API can provide access to interfaces for ranking clustering classifying and prediction techniques. Also a software application can provide one or more inputs to the machine learning service. For example a software application controlling a volume setting of a speaker can provide volume setting values as an input to the machine learning service.

The API can also utilize data that the software application does not and perhaps cannot access. For example a volume setting application may not have access to location data for the mobile platform. However the volume setting application could request the machine learning service to predict the volume setting of the speaker based on location. The machine learning service need only provide the predictions not the locations to the volume setting application. As such the machine learning service can encapsulate the use of sensitive data.

The machine learning service can include a data aggregation and representation engine DARE that constantly receives and stores input data perhaps from multiple sources. The stored input data can be aggregated to discover features within the data such as location labels based on actions and times e.g. Home Work School etc.

The machine adaptation techniques used by the machine learning service can be implemented to work best within the processing memory and other resource constraints of a mobile platform. For example the machine adaptation techniques can use incremental learning algorithms that require limited or no historical information for training and thus may reduce the total amount of memory needed by the machine learning service.

In some embodiments the machine learning service can utilize network support functionality to access non private and or anonymized data aggregated across multiple mobile platforms. The aggregated data can be stored in one or more servers or other devices other than the mobile platform and downloaded as needed. For example aggregated data can be used to train and or set initial values for the machine adaptation techniques used by the machine learning service.

Predicting a duration of a mobile session before the mobile session starts based on location time calendar entries prior behavior etc.

Predicting a phone number to be dialed at the onset of utilizing a phone dialing application based on location time calendar entries prior behavior etc.

Predicting speaker and or mute settings for the mobile platform based on location time calendar entries prior behavior etc.

Generating example photo names and photo album names for a camera application utilizing the mobile platform.

By providing application access to a number of machine adaptation techniques designed to operate on and learn about user behavior of a mobile platform the machine learning service can make mobile platforms easier to use more efficient from a user s point of view and save users time and effort in utilizing the variety of applications available on the mobile platform.

Turning to the figures is a flow chart of method in accordance with an example embodiment. In some embodiments part or all of method can be executed using one or more mobile platforms e.g. mobile platform and or one or more computing devices e.g. computing device .

Method begins at block where a machine learning service executing on a mobile platform can receive data related to a plurality of features. In some embodiments the received data can include data aggregated from a plurality of mobile platforms.

At block the machine learning service can determine at least one feature in the plurality of features based on the received data.

At block the machine learning service can generate an output by the performing a machine learning operation on the at least one feature of the plurality of features. The machine learning operation can be selected from among an operation of ranking the at least one feature an operation of classifying the at least one feature an operation of predicting the at least one feature and an operation of clustering the at least one feature.

In some embodiments generating the output by the machine learning service can include selecting a machine learning algorithm to perform the machine learning operation. In particular embodiments selecting the machine learning algorithm to perform the machine learning operation can include the machine learning service selecting the machine learning algorithm.

In some of the particular embodiments selecting the machine learning algorithm to perform the machine learning operation can include receiving a selection related to the machine learning algorithm from an application executing on the mobile platform where the application differs from the machine learning service. In specific of the particular embodiments receiving a selection related to the machine learning algorithm from the application can include receiving a selection related to the machine learning algorithm from the application via an Application Programming Interface API of the machine learning service.

At block the machine learning service can send the output. In some embodiments the received data can include data related to a plurality of features related to communication signals and locations where the mobile platform is located at a first location and where the output includes an indication of whether to search for the communications signal at the first location.

In other embodiments the received data can include data related to a plurality of features related to durations of communication sessions and the output can include a prediction of a duration of a new communication session. In still other embodiments the received data can include data related to features of telephone calls originated by the mobile platform and the output can include a called party of a telephone call to be originated by the mobile platform. In even other embodiments the received data can include data related to volume and mute settings of the mobile platform and the output can include a prediction of a volume setting and or a mute setting of the mobile platform. In yet other embodiments the received data can include data related to one or more images and the output can include a name related to at least one image of the one or more images.

In some embodiments method can further include i storing the at least one feature and the output for use by the machine learning service ii receiving second data related to a second plurality of features at the machine learning service iii determining at least a second feature in the second plurality of features based on the second data iv generating a second output by the machine learning service performing the machine learning operation on the at least the second feature and the stored at least one feature and output and v sending the second output from the machine learning service.

Method begins at block where a machine learning service executing on a mobile platform can receive feature related data. The feature related data can include data related to a first plurality of features received from an application executing on the mobile platform and data related to a second plurality of features received from the mobile platform. The first plurality of features and the second plurality of features can differ.

In some embodiments the first plurality of features can include a feature selected from among a time a location a duration a signal strength a power level a party of a telephone call an e mail address a contact and a calendar entry. In other embodiments the second plurality of features can include a feature selected from among an image related feature and a speech related feature.

At block the machine learning service can determine at least one feature from among the first plurality of features and the second plurality of features based on the feature related data.

At block the machine learning service can generate an output by performing a machine learning operation on the at least one feature of the plurality of features.

Application processes such as system application and user application can execute using mobile platform system . System application can be an application provided by a provider of part or all of mobile platform system . User application can be an application provided by an entity other than a provider of part or all of mobile platform system

Machine learning and adaptation service can be configured to provide the functionality of a machine learning service. shows that machine learning and adaptation service can communicate with both mobile platform system and applications via feature related data FRD and machine learning operation output MLOO .

Feature related data can be built in or provided by mobile platform system e.g. as feature related data . Built in feature related data can include but are not limited to times dates locations settings for mobile platform hardware ringing volume mute settings ring tones brightness levels power battery data etc. calling data calling party called party dialed digits calling state etc. power battery data communication network data addresses networks login password information signal strengths etc. current application s being executed and user preference information.

Machine learning and adaptation service can determine one or more features from feature related data . For example suppose that feature related data includes the text of a Short Message Service SMS message stating I m outta here. Machine learning and adaptation service can generate features represented as feature vectors. An example feature vector for SMS messages can be a pair. Using the example SMS message text a set of corresponding example feature vectors can be 

As another example suppose a list of suggested labels W1 W2 W3 . . . Wn were provided to a user with a request to click on the one best representing the user s current location. The user clicked on label W4 to select W4 as the closest representation. Then perhaps as part of a training exercise the list of suggested labels can be provided as features to machine learning and adaptation service . An example feature can be a feature vector and as applied to the list of suggested labels the following feature vectors can be determined . . . . Many other examples of features feature vectors and feature related data are possible as well.

In some embodiments feature related data can include commands to machine learning and adaptation service such as a command to train or learn about input data and perform one or more machine learning operations on the learned input data. For example machine learning and adaptation service can receive a command to cluster a series of locations which can be provided as latitude longitude pairs perhaps using cluster labels such as Work Home School and Gym . Then once trained machine learning and adaptation service can output one or more machine learning operation outputs . Continuing the location example mentioned above given an input latitude longitude pair as part of feature related data the corresponding machine learning operation output can be a cluster label.

Machine learning and adaptation service can also train with and utilize feature related data provided by system application as feature related data and or feature related data provided by user application as feature related data . Then upon receiving input data machine learning and adaptation service can provide machine learning operation output s to system application as machine learning operation output and or provide machine learning operation output s to user application as machine learning operation output . That is machine learning and adaptation service need not have detailed information about feature related data a priori rather machine learning and adaptation service can utilize incremental learning techniques to generate a model of feature related data and update the model as needed based on feature related data .

Additionally machine learning and adaptation service need not have detailed information about applications a priori. Rather applications can use interface s to machine learning and adaptation service to permit use of machine learning and adaptation service as a toolkit of machine learning techniques.

Machine learning and adaptation service API provides interfaces to access a number of machine learning and adaptation techniques and to exchange data with machine learning and adaptation service . In some embodiments models for machine learning and adaptation can be saved and loaded via machine learning and adaptation service API .

Machine learning and adaptation engine performs the machine learning and adaptation techniques of machine learning and adaptation service . In some embodiments machine learning and adaptation engine can learn data from one or more sources and then classify cluster rank and or predict data from given input data.

Classifying data involves putting data with a number N of possible values into one of C1 pre determined categories where C1 is finite. For an example with C1 2 a mobile platform can be classified for each value T of a set of times into one of two categories either powered up or not powered up . As another example with C1 3 a location specified as a latitude longitude pair or via another technique can be classified into one of three categories having a strong accessible Wi Fi signal having an adequate accessible Wi Fi signal or having little or no accessible Wi Fi signal. Many other examples are possible as well.

Classification can be performed using one or more statistical classification techniques such as but not limited to linear classifiers support vector machines quadratic classifiers kernel estimation decision trees neural networks Bayesian techniques and or networks hidden Markov models binary classifiers and or multi class classifiers.

Clustering data involves putting data with a number N of possible values into one of C2 clusters where C2 is finite and where the clusters are not necessarily pre determined. Generally each data item in a given cluster is more similar to each other than to data item s in other cluster s . For example a mobile platform can track its location throughout the day to find clusters of locations where the mobile platform can be commonly found such as work location s home location s shopping location s entertainment location s and other location s . Location clusters can vary from person to person an attorney who works at a law office and then frequents a restaurant may consider the law office as a work location and the restaurant as an entertainment location but chef may consider the law office as an other location and the restaurant as a work location. 

Clustering can be performed using one or more clustering algorithms such as but not limited to connectivity based clustering hierarchical clustering centroid based clustering distribution based clustering density based clustering and partitioning algorithms.

Ranking a set of data items of size S involves applying a ranking function RF to the S data items and returning the highest or lowest N ranked data items where 0

Let the ranking function RF rank the N 10 team players listed in Table 1 from 1 to N based on points scored. For this example RF Pat 1 RF Chris A 2 and RF Lucky 10.

Another ranking example is ranking documents based on a query of one or more keywords. The ranking of a document D out of a total of N documents can express the relative relevance of document D to the query. In some embodiments rankings can have two or more partitions or levels. For example given a query with keywords K1 K2 . . . Kn documents can first be ranked as relevant or irrelevant based on keywords K1 Kn. Then a second ranking function can rank the subset of relevant documents perhaps in more detail.

Ranking can be performed using one or more ranking algorithms such as but not limited to instance ranking algorithms label ranking algorithms subset ranking algorithms rank aggregation algorithms bipartite k partite ranking algorithms and learning to rank algorithms.

Predicting data can involve determining a predicted value given a previous pattern of values. For example given that the previous N 20 values were 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 and 2 the predicted value may be 1. Prediction can be performed using one or more prediction algorithms such as but not limited to minimax decision tree algorithms classification tree algorithms linear regression polynomial regression statistical regression curve fitting interpolation and maximum likelihood estimation algorithms.

Data aggregation and representation engine aggregates or combines data from applications and the mobile platform system and stores the aggregated data in a model accessible to machine learning and adaptation engine . In some scenarios aggregation of data enables discovery of new inferences based on the combined data that were difficult to observe in the raw data. For example suppose a mobile platform is located in the labeled locations listed in Table 2 below 

Assuming a large amount of the Other location time is time spent driving these data indicate that the mobile platform is at work home or traveling. That is the mobile platform spends 80 of the time at work and home and more than 90 of the time at work home or likely in a vehicle. Based on this information the mobile platform likely has easy access to commercial electrical power at least 80 of the time and so battery life may not be as important to this mobile platform as compared to say being able to recharge a battery of the mobile phone from commercial electrical power and while driving.

Service manager can manage learning session s or instances of one or more machine learning and adaptation models for the application s utilizing machine learning and adaptation service . Service manager can also coordinate permissions for access and or display of data. In some embodiments service manager can prioritize learning sessions and or resources used by machine learning and adaptation service

Machine learning and adaptation service network support can provide back end support to access non private and or anonymized data that has been authorized to be gathered from a plurality of mobile platforms. In some scenarios the non private and or anonymized data can be resident on mobile platform while in other scenarios part or all of the non private and or anonymized data can reside on other devices such as servers and or other mobile platforms. In the other scenarios mobile platform may temporarily or permanently store the non private and or anonymized data perhaps depending on the access to the non private and or anonymized data provided to mobile platform and or machine learning and adaptation service .

As the non private and or anonymized data is administered by machine learning and adaptation service network support the non private and or anonymized data can be used by machine learning and adaptation service but not shared or hidden from applications. In some embodiments not shown in a built in manager can enable access to built in features for machine learning and adaptation service while hiding some or all built in features from applications.

As shows just below learning sessions built in features can provide various types of data to service manager and more generally to machine learning and adaptation service . shows examples of data provided by built in features such as location location labels application statistics people related features calling information battery power data network information and historical usage information. Locations can be specified in terms of latitude longitude pairs latitude longitude altitude triples street addresses intersections and or using other location specifying data. Location labels can include names such as the Locations shown in Table 2 above e.g. work home stores etc.

Application statistics can include a time T an application App was last executed a location loc an application was last executed a probability P App T that the application App is executing at a given time a probability P App loc that App is executing at a given location and a probability P App T loc that App is executing at a given location at a given time. The above mentioned application statistics can be generated by statistical software operating on data regarding application execution times and locations. Other statistics can be determined as application statistics as well or instead.

Information about people can be determined from contact information calendar information social networking accounts and pages and from other sources. As part of built in features information such as but not limited to a person s name address phone number s e mail address es social networking account information can be provided to machine learning and adaptation service .

Calling information can include per call information such as calling party dialed digits called party information call duration call start time and call end time. In some cases calling information can also or instead include contact information such as a name and or Caller ID data associated with a called party and or historical calling information for a number of previous calls NPC where NPC 0.

In embodiments not shown in other types of communication information can be provided as part of built in features . Examples of other types of communication information include but are not limited to e mail information SMS information blog information and social networking messaging information.

Battery power information can include but is not limited to information about batteries and or power for the mobile platform such as battery levels battery status e.g. operating disconnected charging commercial power status e.g. connected charging disconnected time s of connection s to and or disconnection s from commercial power. Network information can include but is not limited to information about telecommunications networks local area networks other networks network addresses connection time s disconnection time s and network status e.g. connecting connected acquiring address es communicating data idle disconnecting disconnected .

Historical usage information can include but is not limited to information about previous usage of machine learning and adaptation service . Example information includes a number of features pushed or provided to machine learning and adaptation service a number of items pulled or requested from machine learning and adaptation service a number of applications currently using machine learning and adaptation service a number of applications that have used machine learning and adaptation service in a unit period of time e.g. a number of application using machine learning and adaptation service per hour or per day and maximum and or minimum numbers of applications currently using machine learning and adaptation service .

Learning API can include at least the functions shown in getService RankerInterface PredictionInterface ClassificationInterface and ClusteringInterface . In some embodiments more or fewer functions can be part of learning API . An application can call the getService function to initialize and start a learning session e.g. initialize and create a learning session thread. The getService function can return a learning session key that can specify a specific learning session.

An application can call the RankerInterface function to initialize and generate a ranking model of machine learning and adaptation service . The ranking model can be used to order or rank a set of data items of size S by applying a ranking function RF to the S data items and returning the highest or lowest N ranked data items such as discussed above in the context of . An application can call the PredictionInterface function to initialize and generate a prediction model of machine learning and adaptation service . The prediction model can be used to determine a predicted value given a previous pattern of values such as discussed above in the context of .

An application can call the ClassificationInterface function to initialize and generate a classification model of machine learning and adaptation service . The classification model can be used to put data with a number N of possible values into one of C1 pre determined categories where C1 is finite such as discussed above in the context of . An application can call the ClusteringInterface function to initialize and generate a clustering model of machine learning and adaptation service . The clustering model can be used to put data with a number N of possible values into one of C2 clusters where C2 is finite and where the clusters are not necessarily pre determined such as discussed above in the context of .

In some embodiments an application can use only one learning interface per learning session while in other embodiments the application can use multiple learning interfaces per learning session.

Each of the learning interfaces shown in learning API can include at least the functions of example learning interface . shows learning interface with five functions Push Pull Notify Save and Load . In some embodiments more or fewer functions can be part of learning interface .

The Push function can enable an application to provide data to a learning session. The Pull function can enable an application to request and receive information such as inference s and or prediction s from a learning session.

The Notify function can enable an application to receive information such as inference s and or prediction s from a learning session without requesting the information. For example suppose a learning session is informed about an event of interest to the application and consequently uses its learning model to generate a prediction for use by the application. In this example the application has not requested the prediction i.e. the application did not call the Pull function. Therefore the learning session can provide the prediction to the application using the Notify function.

The Save function can save learning model data needed to start restart a learning model and provide a copy of the learning model data to the application. The Load function can take a copy of learning model data from the application and to start restart a learning model with the learning model data.

Session information can include information about each learning session conducted by machine learning and adaptation service . Example session information can include but is not limited to a learning session key for the learning session information about the application such as an application name application addressing information type s of learning interface s used in the learning session e.g. RankerInterface PredictionInterface usage information for the learning interface s and perhaps data stored by the learning model for the learning session such as a learning model cache.

As mentioned above service manager can manage learning session s for the application s utilizing machine learning and adaptation service . Specifically as shown in service manager can enable communications between applications data aggregation and representation engines and learning session threads . As each application is associated with one respective learning session thread service manager can ensure that information from a given application is directed to the corresponding learning session thread and not routed to another learning session thread and vice versa. One technique to ensure that information from a given application is directed to the corresponding learning session thread is to verify that a learning session key is common to both the given application and the corresponding learning session thread. In some embodiments session information can include a mapping between session keys applications and learning session threads.

Each of data aggregation and representation engines aggregates or combines data from applications and the mobile platform system and stores the aggregated data in a model accessible to appropriate learning session thread s such as discussed above in the context of .

Each of learning session threads and implements a learning model. shows that learning session threads and each respectively include machine learning and adaptation engine MLAE feature buffer . and context . Each of machine learning and adaptation engines performs the machine learning and adaptation technique discussed above in the context of and this figure . Each of feature buffers stores feature s used to train and or perform functions for the corresponding machine learning and adaptation engines 

Each of contexts and stores a learning model that embodies classifications predictions clusterings or rankings learned by the corresponding machine learning and adaptation engines . A respective context can be saved by the application using the Save function of learning interface and the respective context can be loaded using the Load function of learning interface .

Manual microphone setting includes a slider bar that enables a user to set a microphone output setting between a minimum setting of 0 which effectively mutes the microphone and a maximum setting of 100 which provides the maximum output volume a.k.a. maximum gain for a given input. shows manual microphone setting set to 53 or approximately halfway between the minimum and maximum settings.

As shown in smart microphone setting can learn and set microphone volume based on called party and can be set to either enabled or disabled. When smart microphone setting is disabled dialer application can instruct a microphone application not shown in to use manual microphone setting to determine output volume for a microphone of mobile platform . When smart microphone setting is enabled dialer application can use a learning service of machine learning and adaptation service to perform a machine learning operation to provide setting values for the microphone setting. Then upon receiving a setting value dialer application can provide the setting value to the microphone application which can then determine output volume for the microphone of mobile platform using the setting value. In scenario and as shown in smart microphone setting is set to enabled.

In scenario continues with dialer application calling the getService function of learning model via communication . In response learning model provides a session key S1 via communication to dialer application . Session key S1 is included for subsequent communications between dialer application and learning model to permit addressing the subsequent communications to the correct learning model e.g. learning model and correct application e.g. dialer application for a learning session keyed by S1.

Scenario continues with dialer application calling the Load function via communication to provide stored learning model data e.g. a context stored in a DialerModel variable passed as a parameter of the Load function to learning model . Upon receipt of communication learning model can load a context and perhaps other data stored in the DialerModel variable into a learning session thread that can be utilized by learning model . In some scenarios not shown in learning model can provide a response to communication such as a return value to the Load function and or a communication providing a status of the Load function e.g. LoadOK or LoadFail.

Dialer application can instruct learning model via communication to set up a prediction interface. As shown in communication includes a PredictionInterface call with three parameters session key S1 an input source reference of CalledParty and a requested output prediction of microphone volumes as shown in using the predefined MIC VOL value.

In response learning model sends communication to built in features to request a built in feature ReqBI of microphone values as shown in by passing the predefined MIC VOL value to built in features . Built in features can include at least the functionality of built in features discussed above. In response built in features returns a built in session key BI1 via communication . Built in session key BI1 is included with subsequent communications between learning model and built in features to permit addressing the subsequent built in related communications to the correct learning model.

Scenario continues with dialer application sending communications and to learning model . Communication uses the Push function to inform learning model that a call is being made to a called party Boss. Communication requests via the Pull function a predicted value for the MIC VOL microphone volume setting.

In response to communication learning model predicts a microphone volume setting of 37 based on data a stored in the DialerModel variable and loaded as a consequence of communication and b learned from communications particularly communications and which relate to calls to a called party of Boss. Subsequently learning model can send a Pull Response PullResp as communication to dialer application providing the predicted microphone volume setting of 37. In some embodiments the Pull Response can be a return value of the Pull function of communication . In response to communication dialer application instructs microphone application to set the microphone volume to 37 via a SetMicVol function communicated in communication

In some scenarios learning model can communicate to an application such as dialer application once the learning model has been trained and is ready to perform machine learning operations such as predicting microphone volume levels. In other scenarios learning model is not trained sufficiently to provide a prediction in response to communication . In these scenarios learning model can inform the application that the learning model is insufficiently trained to perform machine learning operations such as predicting microphone volume settings. In still other scenarios microphone application can provide a response such as a function return value or communication e.g. SetMicVolOK or SetMicVolFail to the SetMicVol command.

Scenario concludes with dialer application call Save function via communication to request that learning model save a context and perhaps other data of a learning session thread in the DialerModel variable. In some scenarios not shown in learning model can provide a response to communication such as a return value to the Save function and or a communication providing a status of the Save function e.g. SaveOK or SaveFail.

Manual microphone setting includes a slider bar that enables a user to set a microphone output setting to between a minimum setting 0 which effectively mutes the microphone and a maximum setting of 100 which provides the maximum output volume a.k.a. maximum gain for a given input. shows manual microphone setting set to 48 or approximately halfway between the minimum and maximum settings.

As shown in smart microphone setting can be set to either enabled or disabled and used to learn and set microphone volume based on called party. When smart microphone setting is disabled microphone application can use manual microphone setting to determine an output volume for a microphone of mobile platform . When smart microphone setting is enabled microphone application can use a learning service of machine learning and adaptation service to perform a machine learning operation to provide setting values. Upon receiving a setting value microphone application can determine output volume for the microphone of mobile platform . In scenario and as shown in smart microphone setting is set to enabled.

In communications in scenario begin with microphone application calling the getService function of learning model via communication . In response learning model provides a session key S2 via communication to microphone application . Session key S2 is included for subsequent communications between microphone application and learning model to permit addressing the subsequent communications to the correct learning model e.g. learning model and the correct application e.g. microphone application for a learning session keyed by S2.

Microphone application can instruct learning model via communication to set up a prediction interface. As shown in communication includes a PredictionInterface call with three parameters session key S1 an input source reference MicVol and a requested output prediction of microphone volumes as shown in using the predefined MIC VOL value. The requested output prediction of microphone volumes is based on called parties as indicated by the fourth parameter CALLED PARTY to the PredictionInterface function. As with the MIC VOL value the value of CALLED PARTY can be predefined. In other scenarios not shown in the Figures the output prediction can be based on multiple values as requested via the PredictionInterface function.

In response learning model sends communication to built in features BIFs to request built in feature ReqBI of called party values as shown in by passing the predefined CALLED PARTY value to built in features . Built in features can include at least the functionality of built in features discussed above. In response built in features returns a built in session key BI2 to learning model via communication . Built in session key BI2 is included with subsequent communications between learning model and built in features to permit addressing the subsequent built in feature related communications to the correct learning model.

Scenario continues with learning model receiving communication from built in features . Communication informs learning model that a call is being made to a called party Boss. 

In response to communication learning model predicts a microphone volume setting of 40 based on data learned from communications particularly communications and which relate to calls to a called party of Boss. Subsequently learning model can send communication including the Notify function to indicate the predicted microphone volume setting of 40 to microphone application . In response to communication microphone application can perform function to set the microphone volume to 40.

Scenario continues with learning model receiving communication from built in features which informs learning model that a call is being made to a called party Grandpa. In response to communication learning model predicts a microphone volume setting of 82 based on data learned from communications particularly communications and which relate to a call to a called party of Grandpa. Subsequently learning model can send communication including the Notify function to indicate the predicted microphone volume setting of 82 to microphone application . In response to communication microphone application can perform function to set the microphone volume to 40.

Method begins at block where a context identification system executing on a mobile platform can receive data. The received data can include context related data associated with the mobile platform and application related data received from the mobile platform. In some instances the context related data and the application related data can differ.

In some embodiments context related data can be received from a network. Further in some instances the network can include a server a cloud based server and or a database with context related data stored dynamically among other possibilities to provide context related data. Further in some instances a mobile platform can connect to such a network to receive context related data continuously and or periodically possibly by executing a network connection application. Yet further in some instances context related data can be received by a network with multiple programmable devices sitting on different nodes of the network possibly as described with respect to . In such instances context related data can be received through the network from multiple other programmable devices communicating with the network.

In addition in some embodiments the context related data can be received and or generated by a context identification system CIS executing on an exemplary mobile platform. In particular embodiments the CIS can be configured to extract context related data from information streaming to the mobile platform possibly from a network as described above. In practice the CIS may be initiated by a context related application executed on the mobile platform. An exemplary context identification system is further described with respect to .

In some embodiments a context related application may be executed to cause the CIS to stream context related data associated with mobile platform and identify a context. For example the mobile platform may be turned off before a flight to Chicago and then turned back on after the flight arriving in Chicago. After turning on the mobile platform the context related application may cause the CIS to receive and or generate context related data. Further certain context signals associated with the context related data may be extracted such as a the location of the mobile platform i.e. Chicago O Hare International Airport b the time zone based on the location of the mobile platform i.e. Central Time zone and or c the weather of the area near the mobile platform e.g. rainy at 58 F. among other possibilities. In some instances such context signals may be used to determine that the user has just arrived at Chicago O Hare International airport via an airplane flight.

Yet further in some embodiments context related data can be directly received and or generated by sensors associated with the mobile platform and or components provided inside the mobile platform. In some instances sensors can be external to the mobile platform and capable of receiving and or generating context related data. By way of example and without limitation sensors could be any one or more of a motion detector e.g. a gyroscope an accelerometer and or a shock sensor a camera a proximity sensor an impact sensor a contact sensor e.g. capacitive sensing device a location determination device e.g. a GPS device a magnetometer and or an orientation sensor e.g. a theodolite among other possibilities.

In some embodiments application related data can include data related to an exemplary mobile platform. For example application related data can include data associated with operating the mobile platform. In some instances application related data can include a dialing indication for opening a phone dialing application and or a received call indication indicating a new call has been received at the mobile platform. Further a user can enter one or more digits of a phone number to be dialed using the phone dialing application e.g. entering the digit 5 for the number 555 555 5555 . In some instances received call indications can include digits of a phone number from another phone calling the mobile platform and or a phone number from another phone that has called the mobile platform in the past. In addition an indication can include a digit of the mobile platform s phone number. Further in some instances a user can vocalize a command while using voice recognition to dial the phone number e.g. verbally reciting call my wife in the vicinity of the mobile platform .

In some embodiments application related data can include a messaging indication for opening a messaging application a short message service SMS text messaging application for example. Further a user may enter one or more text characters of a message to be sent using the messaging application e.g. entering h or hey for hey you want to play golf today . The messaging application may receive a messaging indication for an incoming text message with incoming text e.g. Golf sounds great which course . Yet further a user can vocalize a command and or part of a command while using voice recognition to send a message using the phone messaging application e.g. verbally reciting part of hey you want to play golf today In some instances a contact indication for opening a contact may be provided through a user interface of the mobile platform. In other instances an application indication for executing an application on the mobile platform may be provided through the user interface of the mobile platform.

Further in some embodiments application related data may include how an application is executed opened and or interacted with. For example in some instances an application may be opened quickly in parallel with other applications e.g. a phone dialing application and in some instances an application may be opened sequentially after performing other operations e.g. opening other applications with the mobile platform. Yet further in some instances an application may be executed remotely from a mobile platform perhaps using a laptop and or a tablet computer. Other examples are possible as well.

At block the context identification system may identify at least one context using the context related data associated with the mobile platform and or the application related data received from the mobile platform.

Generally identifying a context may be identified based on context related data. Further in some embodiments context related data may include one or more context signals. Accordingly an exemplary mobile platform may be configured to identify a context by determining various context signals and or acquiring context signals from other sources such as the external sensors and or networks perhaps as mentioned above.

A context signal may be any signal that provides a measurement of or otherwise provides information pertaining to the state or the environment associated with a certain subject e.g. with a certain person device event etc. . Many types of information from many different sources may be used to establish context signals and or provide information from which context signals may be determined. In some instances a context identification system CIS may be used to receive and or generate one or more context signals.

By way of example and without limitation context signals may include a the current time b the current date c the current day of the week d the current month e the current season f a time of a future event or future user context g a date of a future event or future user based context h a day of the week of a future event or future context i a month of a future event or future user context j a season of a future event or future user based context k a time of a past event or past user based context l a date of a past event or past user based context m a day of the week of a past event or past user based context n a month of a past event or past user based context o a season of a past event or past user based context ambient temperature near the user or near a monitoring device associated with a user p a current future and or past weather forecast at or near a current location possibly based on the location of the mobile platform q a current future and or past weather forecast at or near a location of a planned event in which a user and or a user s friends plan to participate r a current future and or past weather forecast at or near a location of a previous event in which a user and or a user s friends participated s information on user s calendar such as information regarding events or statuses of a user or a user s friends t information accessible via a user s social networking account such as information relating a user s status statuses of a user s friends in a social network group a user s relationship with the user s friends and or communications between the user and the user s friends u noise level or any recognizable sounds detected by the mobile platform and or a monitoring device v items that are currently detected by the mobile platform and or a monitoring device w items that have been detected in the past by the monitoring device x items that other devices associated with a monitoring device e.g. a trusted monitoring device are currently monitoring or have monitored in the past y information derived from cross referencing any two or more of information on a user s calendar information available via a user s social networking account and or other context signals or sources of context information z health statistics or characterizations of a user s current health e.g. whether a user has a fever or whether a user just woke up from being asleep and aa a user s recent context as determined from sensors on or near the user and or other sources of context information e.g. whether the user is walking running and or jogging among other possibilities bb a current location of the user and or the mobile platform cc a past location of the user and or the mobile platform and dd a future location of the user and or the mobile platform. Those skilled in the art will understand that the above list of possible context signals and or sources of context information is not intended to be limiting and that other context signals and or sources of context information are possible in addition or in the alternative to those listed above.

Some context signals may take the form of discrete measurements. For example a temperature measurement or a current GPS location may be received as a context signal. On the other hand context signals may also be received over time or may even be a continuous signal stream. For instance an exemplary mobile platform may use the current volume of a continuous audio feed from an ambient microphone as one context signal and the volume of a continuous audio feed from a directional microphone as another context signal.

In some embodiments a context may be identified by extracting and or interpreting context signals from other types of data e.g. weather forecast data satellite data GPS coordinates etc. . Further in some embodiments a machine learning operation may cluster the one or more context signals by grouping one or more context signals. In addition a machine learning operation may categorize or classify the context by assigning a label to one or more context signals possibly after grouping them. For example one or more context signals may take the form of data indicative of the environment or state information. As such context signals may be categorized or classified as at home at work outside in a car outdoors indoors inside outside free and or in a meeting among other possibilities.

Furthermore a context may be a qualitative or quantitative indication that is based on one or more context signals. In addition a context may be identified by extracting specific context signals from an aggregation of context signals. For example context signals may indicate a change in time to 6 30 AM on a weekday possibly setting off an alarm set by a mobile platform . The user may be located at their home and such information may be used to categorize or classify contexts such that the user went from sleeping to awake. In some instances a context may simply be reflected in a context related database as getting ready for work. 

In some embodiments a context may be identified by a mobile platform. For example a mobile platform may determine based on GPS location signals that it has changed its location from one city to another different city. As such the mobile platform may determine the context to be changing locations from in Los Angeles to in Chicago. Many other examples are also possible. In yet another example a context may include data indicating changes to the environment or state information such as moving from home to at work from outside to in a car from outdoors to indoors from inside to outside and or from free to in a meeting among other possibilities. Further in some instances a context may indicate going to work getting in the car going inside going outside and or going to a meeting among other possibilities.

Further in addition to and or alternatively the context identification system may identify a context based on application related data. For example a user operating an exemplary mobile platform may provide an indication of a current context. In particular after receiving a text message via the mobile platform s text messaging application the user may respond in a text message reciting Can t talk in a meeting. In a further example the user may update their status on a social networking site by stating I am so excited about this all day meeting. In addition the user may have accepted a meeting invite to the all day meeting set in the user s calendar such that the context identification can identify the context of attending a meeting. 

Yet further a context may be identified by a user indication. For example a dialing indication may be generated by opening up a phone dialing application on the mobile platform. In some instances a dialing indication can be received by the phone dialing application e.g. a dialing indication for an incoming phone call. In such instances the dialing indication may be used to identify a context for calling co worker. Further entering the first digit of the co worker s phone number may further provide an indication for the calling co worker context.

Yet additionally a messaging indication may be generated by opening up the messaging application on the mobile platform. In some instances a messaging indication can be received by the messaging application e.g. a messaging indication for an incoming text message. In such instances the messaging indication may be used to identify a context for messaging co worker. Further selecting and or opening up the messaging co worker s contact may further provide an indication for such contexts directed to communicating with the messaging co worker. Other examples are possible as well.

At block based on at least one context identified the context identification system can predict at least one communicative action associated with the mobile platform by performing a machine learning operation on the received data.

In some embodiments the user may manually provide the context by entering the text going to office in a context field of the mobile platform s user interface. In addition as noted a context may be classified by assigning a label to one or more context signals. In some embodiments a machine learning operation may be performed to assign such labels. For example the mobile platform may determine the context from subway to office when the user leaves the subway station and arrives to their office.

Further the context identified may provide an indication of a communicative action. By way of example and without limitation a communicative action may include any of the following dialing a phone number using the mobile platform ending a current call using the mobile platform sending a message using the mobile platform opening a contact on the mobile platform executing an application on the mobile platform updating a status on social networking site and or sending communication via email among other possibilities.

In some embodiments identifying a context may help predict at least one communicative action. For instance an exemplary mobile platform may store context signals associated with leaving for work driving to work driving home from work and arriving home. Further the mobile platform may track previously called phone numbers associated with such contexts possibly storing the previously called phone numbers with their respective contexts in a context related database. For example if the mobile platform identifies the leaving for work context the mobile platform may display e.g. on its user interface a phone number for the leaving for work context taken from a list of all previously stored phone numbers called associated with the leaving for work context. Other possibilities may also exist.

In some embodiments there may be more than one phone number associated with a given context identified. In such instances a machine learning operation may be performed to rank the phone numbers associated with the given context. For example the mobile platform may have stored three phone numbers associated with the driving home from work context 1 a son s phone number 2 a daughter s phone number and 3 a wife s phone number. In some instances the mobile platform may be able to determine its velocity possibly consistent with the movement of the user s car. For example the mobile platform may be able to detect if it is moving toward the son s location the daughter s location and or the wife s location.

Based on the location and or velocity of the mobile platform the mobile platform may change the rankings of the three phone numbers stored. In this example the mobile platform s location and velocity may indicate the mobile platform is traveling toward the son s location. Given the mobile platform s current direction toward the son s location and possibly as the mobile phone s location gets closer to the son s location the mobile platform may suggest the user call the son perhaps by displaying the son s phone number as a Suggested Call and or Suggested Number on the phone dialing application s user interface.

Further identifying changes in context may allow a mobile platform to intelligently predict communicative actions e.g. a phone number to dial . In some instances the mobile platform may determine that a current context matches a context that corresponds to a previously dialed phone number. In such instances the mobile platform may suggest the user to call the previously dialed phone number. This aspect is discussed in greater detail below with reference to . Other examples are possible as well.

At block an instruction can be received to execute at least one communicative action associated with the mobile platform.

In some embodiments the instruction may be provided from a user of the mobile platform. For example the mobile platform may provide a prompt on its user interface with a suggested number to call. In some instances the suggested number to call may be provided based on a prediction using the machine learning operation. Further the user may use an instruction input on the mobile platform s user interface to initiate the call to the suggested number.

Further in another example the mobile platform may identify the leaving work and going home context as the user is driving their car from the workplace after a day at work. In such instances the mobile platform may prompt the user with a computerized voice communication stating Would you like to text your wife that you are leaving work and going home Utilizing voice recognition capabilities the user may respond Yes and a text message may be sent to the user s wife indicating that the user is leaving work and going home. As such the user is able to send text messages without making physical contact with the phone and or making visual contact with the phone possibly to refrain from distracting the user from driving.

In some embodiments the instruction may be provided from the context identification system CIS . For example the CIS may identify a context associated with arriving to the office and provide an instruction to dial into a conference call as done regularly upon identifying the arriving to the office context. In some instances previously stored data may indicate a pre determined instruction to dial into the conference call upon identifying the arriving to the office context. In other scenarios pre determined instructions can enable the CIS to automatically originate other phone calls generate and send text messages and or other communicative actions Many other examples are possible as well.

Further shows context identification perhaps based on receiving context related data. For example mobile platform may receive multiple context signals such as the date time temperature and or weather as shown by context related data .

Context identification may illustrate the identified context 3 12 2012 8 05 AM Chicago O Hare Airport Arrival by accessing a pre stored entry in the user s calendar indicating when the user is scheduled to land in Chicago. Yet in some instances mobile platform may detect a recent operation for turning on the power of mobile platform and use a GPS locator to detect the location of mobile platform . In such instances mobile platform may make a prediction that the user has arrived at Chicago O Hare Airport perhaps after a flight. In other instances mobile platform may access the user s itinerary stored in mobile platform s memory to identify that the user has arrived at Chicago O Hare Airport after a flight. Other possibilities may exist.

In addition shows suggested contact as Limo Driver. In such instances the user may press the Limo Driver button to see further information regarding the Limo Driver and possibly view other options for text messaging the Limo Driver. In some embodiments multiple suggestions can be provided and the user can press the circle enclosing a downward facing triangle within suggested contact to view additional suggestions. For example pressing the circle may provide a list of other contacts possibly including local taxi services rental car services airport bus services and or other contacts that the user may want view and or call based on the context identified. Other possibilities may also exist.

In some embodiments airport arrival data record may include context related data corresponding to the date time temperature and or weather as shown by context related data in . Further in consider the scenario such that the save button is pressed in context identification . Referring back to context related data may be updated to include additional data corresponding to a recent operation for turning on the power of mobile platform and the GPS location data of mobile platform indicative of the arrival at Chicago O Hare Airport after a flight.

As part of airport arrival data record further illustrates limo driver data with its corresponding phone number data contact data and context related data . In addition user s son data may include its corresponding phone number data contact data and context related data . Further user s daughter data may include its corresponding phone number data contact data and context related data . Yet further user s wife data may include its corresponding phone number data contact data and context related data .

In some embodiments context related data and may be stored in airport arrival data record to predict a communicative action by a user of mobile platform . As such context related data may include mobile platform s call history e.g. contacts called most frequently information corresponding to the user s relationships with other contacts e.g. people that the user has spoken to the most over a given period in time and or browsing history of an internet browser application indicative of the user s interests. Other possibilities may also exist.

In phone number data and may include information regarding each respective person s phone number. Further phone number data and may also include more than one phone number for a given person if the person has more than one phone number e.g. cell phone number office number and or pager number among other possibilities . For example phone number data may correspond to the limo driver s phone number 555 555 5555 shown as suggested phone number in . Further contact data and may correspond to each person s availability possibly incorporating work schedules historical data indicative of when each person has answered or has not answered after calling them during certain times and or other possible alternative contacts to reach the person among other possibilities.

Further in context related data and may correspond to context signals detected when each respective person has been called by mobile platform and or when each person has called mobile platform . For example context related data may correspond to context signals indicating an operation for turning on the power of mobile platform and the GPS location data of mobile platform indicative of an arrival at Chicago O Hare Airport after a flight. Context related data and may also correspond to context signals indicative of the GPS location at Chicago O Hare Airport. However context related data and may not include data suggestive of a recent operation turning on the power of mobile platform indicative of an after flight arrival. For example it may be possible that the son the daughter and the wife were previously called just prior to the user s departure from Chicago O Hare Airport.

A current context identified with mobile platform may closely match context related data . Further context related data may match most closely with context related data as compared to context related data and . As such limo driver data may be ranked higher than user s son data user s daughter data and user s wife data indicating that the user is more likely to call the Limo Driver. Thus a prediction can be made that the user will want to contact the Limo Driver using phone number data .

In some embodiments contact data and may establish a weighting factor to further predict who the user may want to call. For example contact data may indicate that the limo service does not open until 9 00 AM on Mar. 12 2012. Thus although context related data may match most closely with context related data limo driver data may fall in the rankings since the limo driver is probably not available. In such instances user s son data may be next in line to prompt the user with a suggested phone number corresponding to phone number data .

In some embodiments application related data corresponding to the user s indications on the mobile platform may adjust the weighting factor. For example as noted in instruction input provides a Cancel button to not call the Limo Driver at all. Provided that the user presses the Cancel button a weighting factor may be applied to lower limo driver data in the rankings perhaps eliminating limo driver data from the rankings and or eliminating limo driver data from airport arrival data record . Other examples are possible as well.

Context identification of CIS can receive context signals such as but not limited to a a current time b a current date c a current day of the week d a current month e a current season f a time of a future event or future context g a date of a future event or future context h a day of the week of a future event or future context i a month of a future event or future user context j a season of a future event or future context k a time of a past event or past context l a date of a past event or past context m a day of the week of a past event or past context n a month of a past event or past context o a season of a past event or past context p ambient temperature q a current future or past weather forecast at a current location r a current future or past weather forecast at a location of a planned event s a current future or past weather forecast at or near a location of a previous event t information on a calendar associated with a user profile u information accessible via a user s social networking account v noise level or any recognizable sounds detected by a device w devices that are currently available to communicate with the mobile platform x devices in proximity to the mobile platform y devices that are available to receive instruction from the mobile platform z information derived from cross referencing at least one of information on the user s calendar information sent to the user and or information available via the user s social networking account aa health statistics or characterizations of the user s current health bb a user s recent context as determined from sensors on or near the user and or other sources of context information associated with the mobile platform cc a current location of the mobile platform dd a past location of the mobile platform and ee a future location of the mobile platform.

For some or all of the context signals received context identification can copy and or extract data from context signals to identify one or more contexts. The context identified can be output from context identification as a vector.

Classifier function of CIS can receive the context vector as input classify contexts into a CC context classification CC 0 and output classification indications. For an example with CC 3 a context may be classified as work home and travel based on an activity a state of the user an arrival a departure context signal s etc. Many other classifications are possible as well.

A classification indication can include the classification of a context possibly using a predetermined classification scheme. For example suppose classifier function determines a recurring context indicative of the user going on their lunch break at noon. In this example classifier function can output a classification indication assigning a label going out to lunch. Many other possible classification indications are possible as well.

Recognition function can receive the classification indications and recognize certain functions. For example upon receiving the classification indication of the mobile platform moving towards the pizza parlor recognition function can recognize previous phone calls made in the context of moving towards the pizza parlor. For example in some prior instances perhaps the user made a call to the pizza parlor to make reservations. Then recognition function can recognize these previous phone calls and generate a predicted communication e.g. phone call e mail or text message to the pizza parlor.

Recognition function can be performed using software and data solely resident and executing on a mobile platform while in other embodiments recognition function can be performed using software and data both resident and executing on the mobile platform and on other computing devices such as one or more servers configured to recognize contexts.

Application related data can include data generated by and or related to an application executed on the mobile platform. Examples of application related data can include but are not limited to interacting with applications initiating programs on the mobile platform and or executing communicative actions such as dialing phone numbers among other possibilities. Additional examples of application related data are discussed above in the context of among other figures as well. Further application related data can differ from context related data context vector s extracted by context identification classification indications from classifier function and recognized contexts from recognition function .

In some instances user model can take recognized contexts from recognition function and application related data to predict and or suggest communicative actions such as possible phone numbers to dial. For example suppose that the mobile platform recognizes a context such that the user is on their lunch break and is at their office continuing to work. Further application related data may indicate that the user is initiating a phone dialing application and or a restaurant browsing application. The mobile phone may predict that the user may want to order food and provide a phone number to a local restaurant possibly a previously called restaurant for making such a food order.

As shown in context related data including context signals and recognized contexts and application related data can be provided to collective learner . Collective model can take recognized contexts provided by collective learner to suggest communicative actions to execute such as possible phone numbers to dial and or addresses for text messages and or emails to be sent.

For example a user using communication address suggestion UI can view one or more suggested user specific communication addresses and perhaps provide additional feedback such as dismissing the suggestion i.e. refusing to use the suggested communication address . Information about the suggested communication address and any additional feedback can be respectively provided as feedback to user model and collective model . Based on this feedback user model and collective model can adapt to the feedback such as by increasing probabilities that the next communication address suggested by the other model will be accepted by the user. Continuing this example user model can examine feedback facilitate collective model s prediction for another communication address to be used and increase the probability that the next communication address provided to communication address suggestion communication address UI will be accepted going forward. Additionally or instead collective model can examine feedback facilitate user model s prediction for another communication address to be used and increase the probability that the next communication address provided to communication address suggestion user UI will be accepted going forward.

Mobile platforms such as mobile phones can include one or more cameras to capture images. Frequently the images are named perhaps with a brief description of the image. For example an image named Sunset 18 Mar 2012 can be a picture of a sunset captured on Mar. 18 2012. Labeling a large number of pictures can take a great deal of time in reviewing the image determining a title for the image and then naming the image with the determined title.

An image identification system IIS based on the learning models described above can suggest image and album titles based on image content and other data. The other data can include social signals such as social networking messages postings comments tags e mail and other messages other persons social signals and social status indicators calendar data locations and times. The IIS can learn a collective model that represents the collective data from at least one person and their images. The collective model can be learned stored and executed on the mobile platform alone or in some embodiments on the mobile platform and one or more other computing devices such as servers.

The IIS can also be configured with image feature recognition and detection capabilities such as facial recognition modules object recognition modules landmark recognition models and modules to recognize features in images such as lines edges patches of color shapes object areas volumes and other features. The IIS can detect features in one image a sequence of images and or a video file or stream for a sequence of one or more images.

The IIS and or collective model can include or otherwise be associated with a personalized model perhaps using data stored solely on the mobile platform. The personalized model can be equipped to adapt to feedback from a user of the mobile platform. For example for a given image IMG1 the personalized model can suggest three titles T1 T2 and T3. Then if the user decides to entitle IMG1 with title T2 the personalized model can increase the probability that title T2 and or titles similar to title T2 are suggested in the future. In response to selection of title T2 in this example the personalized model can decrease the probabilities that unselected titles T1 and T3 and or titles similar to title T2 are suggested in the future

Method begins at block where a machine learning service executing on a mobile platform can receive feature related data. The feature related data can include image related data related to one or more images received from an application executing on the mobile platform and platform related data received from the mobile platform. The image related data and the platform related data can differ.

In some embodiments the image related data can be generated by an image identification system IIS executing on the mobile platform. In particular embodiments the IIS can be configured to extract image related features from the one or more images. In more particular embodiments the IIS can be configured to classify at least one image related feature of the image related features. In even more particular embodiments the IIS can be configured to recognize the at least one classified image related feature and or object s and or scene s that include the at least one classified image related feature.

In some of the even more particular embodiments the at least one classified image related feature can include a feature related to a face of a person and the IIS can be configured to recognize the face of the person. In other of the even more particular embodiments the at least one classified image related feature can include a feature related to a landmark and the IIS can be configured to recognize the landmark. In still other of the even more particular embodiments the at least one classified image related feature can include a feature related to an object and the IIS can be configured to recognize the object.

At block the machine learning service can generate a title related to the one or more images. The title can be generated by the machine learning service performing a machine learning operation on the feature related data.

In some embodiments the title related to the one or more images can include at least one datum from the image related data and at least one datum from the platform related data. In particular embodiments the at least one datum from the image related data can include at least one datum selected from among a name of a person a name of a landmark and or a name of an object and the at least one datum from the platform related data includes at least one datum selected from among a date a time a calendar entry a social networking message and a location.

At block the machine learning service can send the title related to the one or more images from the machine learning service to the application.

Classifier function of IIS can receive the feature vector as input classify features into one of IC image classifications IC 0 and output classification indications. For an example with IC 3 the features can be classified as a face a landmark or an object. Many other classifications are possible as well.

A classification indication can include the classification of a recognized feature and an indication of a range of pixels that include the classified feature. For example suppose classifier function determines an image of a face is depicted by a rectangle of pixels whose upper left hand corner has pixel coordinates 10 10 and whose lower right hand corner has pixel coordinates 90 100 . In this example classifier function can output a classification indication of to indicate an image of a face can be located within the rectangle having pixel coordinates from 10 10 to 90 100 . As another example a classification indication of can indicate an image of a landmark can be found within the rectangle having pixel coordinates from 1 100 to 400 400 . Many other possible classification indications are possible as well.

Recognition function can receive the classification indications and recognize the feature in the classification indication. For example upon receiving the classification indication recognition function can attempt to recognize the face in the image. Recognition function can be performed using software and data solely resident and executing on a mobile platform while in other embodiments recognition function can be performed using software and data both resident and executing on the mobile platform and on other computing devices such as one or more servers configured to recognize image features.

Platform related data can include data generated by and or related to a mobile platform. Examples of platform related data include but are not limited to times dates locations calendar entries social networking messages and other messages. Additional examples of platform related data are discussed above as built in feature related data in the context of at least . Other examples are possible as well. Feature related data can differ from image related data that includes image feature vector s extracted by feature extraction function classification indications from classifier function and recognized features from recognition function .

User model can take recognized features from recognition function and platform related data to generate titles for images and or collections of images a.k.a. albums . For example suppose an image I1 had three recognized features recognized faces of Alice and Bob and a recognized object of a bottle and that the platform related data indicated that I1 was taken at 9 AM on Mar. 18 2012 at Alice and Bob s home. Platform related data authorized by Bob to examine his calendar entries can include a calendar entry of St. Pats Party 2012 that was held starting at 7 PM on Mar. 17 2012. Based on this information user model can generate example titles for image I1 such as 

Similarly if images I2 I3 and I4 are taken in succession all of which include images of Alice Bob and the bottle the above generated example titles can be used for a photo album that includes images I1 I2 I3 and I4. Further the above generated example titles could be used for a video clip of Bob Alice and the bottle taken at 9 AM on Mar. 18 2012 that includes images I1 I2 I3 and I4. Images I1 I4 can reside on a mobile platform e.g. Alice s mobile platform and or on a server configured to store data such as images I1 I4.

As shown in image related data including images and recognized features and platform related data can be provided to collective learner . Collective model can take recognized features provided by collective learner to generate titles for images and or collections of images a.k.a. albums .

For example a user using image album title suggestion UI can select one of user specific titles and perhaps provide additional feedback such as a rating of the title. Information about the selected title and any additional feedback can be respectively provided as feedback to user model and collective model . Based on this feedback user model and collective model can adapt to the feedback such as by increasing probabilities of titles generated by the other model. Continuing this example user model can examine feedback determine that collective model generated the selected title and increase the probability that titles similar to the selected title are provided to image album title suggestion UI going forward. Additionally or instead collective model can examine feedback determine that user model generated the selected title and increase the probability that titles similar to the selected title are provided to image album title suggestion UI going forward.

In some embodiments use of the Edit button to change album suggestion and or title suggestion can generate feedback to user model and or feedback to collective model . Feedback can include the originally suggested title and the title as edited. Feedback can be provided to the user model and or collective model in response to use of the Save button to save an edited album suggestion and or title suggestion .

In scenario image has recently been captured. Image is an image of two people Ann and John pictured beneath the marquee of the landmark Chicago Theater. Image has been provided to photo album title application which in turn used an image identification system such as IIS CIIS or FAIIS to generate the suggested image title and image album names discussed above and shown in .

In some embodiments not explicitly shown in the Figures photo album title application can operate in the background if so authorized e.g. photo album title application operates without displaying suggested album title dialog . Then when an image is captured such as image album title application can provide the captured image to photo album title application and generate suggested image title and image album names perhaps after enough images have been captured and or named to train learning model . Once the suggested image title and image album names are generated album title application can generate a notification such as a pop up dialog that presents the suggested image title and or image album names.

Timing and or display of the notifications can depend on user response. For example album title application can use threshold times to determine relatively quick and relatively slow response. For example if a user responds to a notification within a relatively quick threshold period of time e.g. within five seconds of notification display album title application can continue to generate notifications as soon as suggested image title and or image album names are available. As another example if a user does not respond to a notification within a relatively slow threshold period of time e.g. within sixty seconds of notification display album title application can either generate notifications less frequently and or stop generating notifications in favor of waiting for album title application to be returned to the foreground and then provide suggested image title and or image album names via suggested album title dialog . Other values for threshold periods of time are possible.

Photo album title application initiates communications in scenario by calling the getService function for learning model via communication . In response learning model provides a session key S3 via communication to photo album title application . Session key S3 is included for subsequent communications between photo album title application and learning model to permit addressing the subsequent communications to the correct learning model e.g. learning model and to the correct application e.g. photo album title application for a learning session keyed by S3.

Photo album title application can instruct learning model via communication to set up a ranking interface. As shown in communication includes a RankingInterface call with three parameters session key S3 and requests for ranked lists of photo titles and album names as shown in using the predefined PHOTO TITLE and PHOTO ALBUM values.

In response learning model sends communication to IIS to request identification of image features such as faces objects and landmarks. As shown in learning model requests identifications using the RankingImageProc function with three parameters requests to identify faces objects and landmarks using the respective pre defined values of FACES OBJS and LANDMARKS. In response IIS sends an image identification session key of IP1 via communication .

Scenario continues with learning model sending communication to built in features to request retrieval one or more images stored on a mobile platform as shown in by passing the predefined STORED IMAGES parameter in a ReqBI function call to built in features . In response built in features returns a built in session key BI3 via communication to learning model . If authorized to provide stored images by the user owner of the mobile platform built in features can provide an image stored on the mobile platform to learning model via communication . Communication includes a Push function call with three parameters built in session key BI3 identification of a stored image using the predefined value STORED IMAGES and a reference I1 to the stored image.

Upon receiving the stored image learning model provides the stored image to IIS via communication to determine image related features related to the stored image. Communication includes a Push function call with three parameters image identification session key IP1 identification of a stored image using the predefined value STORED IMAGES and a reference I1 to the stored image.

Scenario continues with IIS determining image related data for the image referenced by I1 and returning the image related data to learning model via communication . Communication includes a Push function call with five parameters image identification session key IP1 a reference I1 to the stored image image related data for faces in F1 image related data for objects in O1 and image related data for landmarks in L1.

Scenario continues with built in features continuing to provide images stored on the mobile platform to learning model which in turn provides each stored image to IIS to generate image related data for faces objects and landmarks for each stored image.

Learning model then requests platform related data from built in features via communication . Communication includes a ReqBI function call with five parameters built in session key BI3 a predefined value of SOCIAL MEDIA requesting all authorized social networking messages stored on the mobile platform a predefined value of NAMES requesting all authorized contact names stored on the mobile platform a predefined value of EVENTS requesting all authorized calendar entries and or events stored on the mobile platform and IMAGE COMMENTS requesting all authorized comments on the STORED IMAGES previously requested. In other scenarios more or less information can be requested by learning model as platform related data.

As shown in in response to communication built in features deliver a name referred to as Name1 via communication to learning model . Built in features can use additional Push function calls to provide additional requested and authorized feature related data to learning model .

Scenario continues with photo album title application providing an image Image1 to learning model via communication . Photo album title application then requests a list of three suggested photo album names related to Image1 from learning model via communication .

In response to communication learning model generates a list of three suggested photo album names related to Image1 and provides the requested list as the Album 3 parameter of the Pull response shown in communication .

Some mobile platforms can search to connect with available communication networks. In Wi Fi systems the mobile platform can turn on a transmitter to send one or more probe request messages requesting connection information and or turn on a receiver to listen for a beacon signal. If a network is available the mobile platform either receives a probe response signal to a sent probe message or receives a listened for beacon signal. The mobile platform can establish a Wi Fi connection with the network after performing authenticated and associated procedures. If no network is available the mobile station does not receive a signal e.g. either a probe request signal or beacon signal and so can determine that no network is available.

Thus to search for a network the mobile platform has to turn on a radio receiver to listen for signals and if sending probe messages perhaps also turn on a radio transmitter to send probe messages. In some embodiments mobile platforms can continue searching until an available network is found and a Wi Fi connection is established. This searching procedure can take a relatively large amount of power thereby reducing power available for other mobile platform tasks such as voice and or data communication.

To save power the mobile platform can train and use a machine learning service to predict whether or not a search to connect with available communication networks will succeed. The machine learning service can be trained using a number of features including but not limited to mobile platform location mobile platform velocity time signal characteristics such as signal strength device usage time since a last search for wireless communication service was performed and outcome of the last search for wireless communication service. By predicting search outcomes rather than performing actual searches the mobile platform can save power and reduce the amount of signaling used in attempting to connect with communication networks.

As part of training the machine learning service the mobile platform can carry out a number of searches to connect with available communication networks. At least while training the mobile platform can store the above mentioned features along with an outcome of each search to connect e.g. success or failure. The outcome of each search can be treated as a fact or ground truth. In one embodiment the machine learning service can include a binary classifier that predicts a likelihood of a finding an available communication network a.k.a. predicts a result of a search to connect with available communication networks.

In another embodiment the machine learning service can include a tri nary classifier that predicts a likelihood of a finding an available communication network or indicates that the service cannot predict the outcome of a search. For example if the machine learning service were trained to look for communications networks in north eastern Illinois only and the mobile platform was moved to central California the machine learning service can output that it cannot predict the outcome of a search to connect with available communication networks as the current set of features especially location do not match any features used to train the machine learning service.

In still another embodiment the machine learning service can get features and communication search outcomes from other mobile platforms either via direct communication with other mobile platforms or via communication with one or more intermediate computing devices such as servers storing feature and outcome data. In the above example of a mobile platform going from north eastern Illinois to central California the mobile platform can download feature and outcome data from mobile platforms in central California and use the California based data to predict search outcomes. In still other embodiments the machine learning service can learn about and generate predictions regarding connections with communication networks along with or instead of Wi Fi networks such as but not limited to Wi Max GSM CDMA TDMA 3G 4G Bluetooth and Zigbee networks.

Turning to the figures is a flow chart of a method in accordance with an example embodiment. In some embodiments part or all of method can be executed using one or more mobile platforms e.g. mobile platform and or one or more computing devices e.g. computing device .

Method begins at block where a machine learning service executing on a mobile platform can receive feature related data. The feature related data can include communications related data related to one or more searches for establishing electronic communications received from an application executing on the mobile platform and platform related data received from the mobile platform. The communications related data and the platform related data can differ.

At block the machine learning service can determine whether or not the machine learning service is trained to perform machine learning operations related to predicting outcomes of searches for establishing electronic communications.

In some embodiments the searches for establishing electronic communications can include a search to establish a wireless local area network connection. In particular embodiments the search to establish the wireless local area network connection can include a search to establish the wireless local area network connection based on an Institute of Electrical and Electronics Engineers IEEE 802.11 standard.

In other embodiments in response to determining that the machine learning service is not trained additional feature related data can be received at the machine learning service where the additional feature related data can include additional communications related data related to one or more searches for establishing electronic communications received from the application and additional platform related data from the mobile platform and where the communications related data additional communications related data platform related data and additional platform related data all differ. After receiving the additional feature related data determining whether the machine learning service is now trained to perform machine learning operations related to predicting outcomes of searches for establishing electronic communications.

At block in response to determining that the machine learning service is trained i the machine learning service can receive a request for a predicted outcome of a search for establishing an electronic communication ii the machine learning service can generate the predicted outcome by performing a machine learning operation on the feature related data and iii the predicted outcome can be sent to the application perhaps by the machine learning service.

In particular embodiments the machine learning service can generate the predicted outcome by performing a machine learning operation on the feature related data without receiving the request for the predicted outcome of the search i.e. the machine learning service can generate the predicted outcome of the search without being prompted by the request.

In some embodiments method can further include in response to determining that the machine learning service is trained a communication indicating that the machine learning service is trained can be sent to the application perhaps by the machine learning service.

In other embodiments method can further include in response to the predicted outcome indicating a search for establishing electronic communications would be successful a wireless interface of the mobile platform can be activated. In still other embodiments in response to the predicted outcome indicating a search for establishing electronic communications would not be successful deferring activation of a radio of the mobile platform. In particular of the still other embodiments after receiving the predicted outcome indicating the search for establishing electronic communications would be not successful the application can start a periodic request for the predicted outcome of the search for establishing the electronic communication.

In more particular of the still other embodiments the application starting the periodic request for the predicted outcome of the search for establishing an electronic communication can include sending the request for the predicted outcome of the search for establishing the electronic communication to the machine learning service receiving the predicted outcome from the machine learning service in response to the predicted outcome indicating a search for establishing electronic communications would not be successful waiting at least a pre determined amount of time and in response to the predicted outcome indicating a search for establishing electronic communications would be successful stopping the periodic request for the predicted outcome and attempting establishment of the electronic communications.

In even other embodiments method can further include in response to the predicted outcome indicating failure to predict a search for establishing electronic communications conducting the search to establish electronic communications determining an outcome of the search and sending an indication of the outcome of the search to the machine learning service.

The top portion of depicts a twelve block map. The four north south streets shown in are numbered from 1St. on the left or west side 2St. just to the east of 1St. 3St. to east of 2St. and 4St. which is the right most or east most north south street. The three east west avenues shown in going from north to south are Apple Ave Berry Ave. and Cherry Ave.

Several of the blocks shown in have wireless communications transmitters specifically shown as transmitters . Transmitter generates network 4thApple with a range shown using circle . Similarly transmitters respectively generate networks ApBer FanSar Books Zone3 C2 and BearClaw with respective ranges shown using circles .

During scenario the mobile platform travels from location A shown in as an octagon surrounding the letter A that is just north of Apple Ave near 2St through locations B C D E F and G. At each of locations A B C D E F and G the mobile platform attempts to connect wirelessly with a wireless network such as wireless network conducted using an IEEE 802.11 standard a.k.a. a Wi Fi network or perhaps using another communications protocol. After each attempt to connect wirelessly the mobile platform stores data related to the attempt in a log shown in as log .

In scenario log shows that the mobile platform was at location A at time 17 00 on Tuesday and attempted to connect to a wireless network. The outcome of the attempt was unsuccessful. At 17 00 on Tuesday the mobile platform had been used for two minutes and it had been five minutes since the last attempt to connect to a wireless network.

As another example log shows that the mobile platform was at location B just south of the intersection 2St. and Apple Ave. at time 17 10 on Tuesday and attempted to connect to a wireless network. The outcome of the attempt was successful. In particular the mobile platform connected to the ApBer network with a signal strength of 40 out of 100. At 17 10 on Tuesday the mobile platform had been used for twelve minutes and it had been ten minutes since the last attempt to connect to a wireless network.

Information for attempts made by the mobile platform at locations C D E F and G is also shown in . At locations D the intersection of 2St. and Cherry Ave. E just northwest of the intersection of 3St. and Cherry Ave. and G on the north side of Apple Ave. just east of 2St. the mobile platform was able to connect to respective networks C2 Zone3 and ApBer with respective signal strengths of 25 80 and 12. However at locations C midway between 1and 2Streets and midway between Berry and Cherry Ayes. and F on the northeastern corner of 3St. and Berry Ave. the mobile platform was unable to connect at location C the mobile platform was able to detect the C2 network but was unable to connect perhaps due to the low signal strength of 3 out of 100. At location F no network was detected.

Each of predictions shown in indicates a prediction for connecting to a wireless network. For examples prediction indicates that mobile platform is likely to connect to the ApBer Network prediction indicates that the Wi Fi Predictor indicates that mobile platform is unlikely to connect to the C2 Network and prediction indicates that mobile platform is unlikely to connect to the FanSarBooks Network 

Each of predictions shown in additionally enables a user of Wi Fi Predictor Dialog to attempt to connect with the network mentioned in the prediction. For example by clicking on the check mark box underneath the word Connect on the right side of prediction mobile platform can attempt to connect to the ApBer network.

Wi Fi application requests service from learning model using the getService function in communication . In response learning model sends a learning model session key of S10 to Wi Fi application using communication . Session key S10 is included for subsequent communications between Wi Fi application and learning model to permit addressing the subsequent communications to the correct learning model e.g. learning model and correct application e.g. Wi Fi application for a learning session keyed by S10.

Wi Fi application can instruct learning model via communication to set up a classification interface. As shown in communication includes a ClassificationInterface call with five parameters session key S10 an input source reference of Conns and a requested outputs of Wi Fi signal strengths Wi Fi Network names and Wi Fi search outcomes as shown in using the predefined WIFI SIG STR WIFI NTWK and WIFI OUTCOME values.

In embodiments not shown in an application can request a similar prediction for a non Wi Fi network such as but not limited to a Wi Max GSM CDMA TDMA 3G 4G Bluetooth or Zigbee network.

In response learning model then requests platform related data from built in features via communication . Communication includes a ReqBI function call with five parameters a predefined value of LOC requesting a current location of the mobile platform a predefined value of VEL requesting a current velocity of the mobile platform a predefined value of CLOCK TIME requesting a current clock time a predefined value of USAGE requesting a current usage value such as uptime of the mobile platform a and a predefined value of LAST WIFI SEARCH TIME requesting a time of a last search for a Wi Fi network. In other scenarios more or less information can be requested by learning model as platform related data. In response built in features returns a built in session key BI10 via communication .

Scenario continues with the mobile platform moving to location A and searching for Wi Fi service. As shown in at location A the mobile platform is unable to connect to a Wi Fi network. shows Wi Fi Application providing information about searching for Wi Fi networks at location A via communication which includes a Push function call with five parameters. The five parameters are a session key S10 an input source reference of Conns a Wi Fi signal strength value of 0 a Wi Fi Network name of 0 to indicate no network was found and a Wi Fi search outcome of NO to indicate the search was unsuccessful.

In response to the Push function call of communication learning model can send communication with a Push function to built in features to request platform related data. The Push function sent via communication has six parameters a built in session key of BI10 a location parameter L1 a velocity parameter V1 a clock time parameter CT1 a usage parameter U1 and a last Wi Fi search time parameter LWST1. In response built in features can send a Push function via communication with values for the parameters requested using communication . As shown in communication includes a Push function with a built in session key of BI10 a location value of A indicating location A as shown in a velocity value of 2 MPH a clock time value of 1700 a usage value of 2 minutes and a last Wi Fi search time value of 5 minutes.

In response to communication learning model and or built in features can log part or all of the information provided by Wi Fi Application and or built in features such as shown in log of .

Scenario continues with the mobile platform moving to location B and searching for Wi Fi service. As shown in at location B the mobile platform is able to connect to the ApBer network. shows Wi Fi Application providing information about searching for Wi Fi networks at location B via communication which includes a Push function call with five parameters. The five parameters are a session key S10 an input source reference of Conns a Wi Fi signal strength value of 40 a Wi Fi Network name of ApBer to indicate that the ApBer network was found and a Wi Fi search outcome of YES to indicate the search was successful.

In response to the Push function call of communication learning model can send communication with a Push function to built in features to request platform related data. The Push function sent via communication has six parameters a built in session key of BI10 a location parameter L1 a velocity parameter V1 a clock time parameter CT1 a usage parameter U1 and a last Wi Fi search time parameter LWST1. In response built in features can send a Push function via communication with values for the parameters requested using communication . As shown in communication include a Push function with a built in session key of BI10 a location value of B indicating location B as shown in a velocity value of 3 MPH a clock time value of 1710 a usage value of 12 minutes and a last Wi Fi search time value of 10 minutes.

In response to communication learning model and or built in features can log part or all of the information provided by Wi Fi Application and or built in features such as shown in log of .

Scenario continues with the mobile platform traveling to locations C D E and F as shown in . At each location the mobile platform searches to find one or more Wi Fi networks. The resulting communication search data and platform related data are shown in log of but are not shown in to save space.

Scenario then continues with the mobile platform traveling to location G and searching for Wi Fi service. As shown in at location G the mobile platform is able to connect to the ApBer network. shows Wi Fi Application providing information about searching for Wi Fi networks at location G via communication which includes a Push function call with five parameters. The five parameters are a session key S10 an input source reference of Conns a Wi Fi signal strength value of 12 a Wi Fi Network name of ApBer to indicate that the ApBer network was found and a Wi Fi search outcome of YES to indicate the search was successful.

In response to the Push function call of communication learning model can send communication with a Push function to built in features to request platform related data. The Push function sent via communication has six parameters a built in session key of BI10 a location parameter L1 a velocity parameter V1 a clock time parameter CT1 a usage parameter U1 and a last Wi Fi search time parameter LWST1. In response built in features can send a Push function via communication with values for the parameters requested using communication . As shown in communication include a Push function with a built in session key of BI10 a location value of G indicating location G as shown in a velocity value of 2 MPH a clock time value of 2002 a usage value of 122 minutes and a last Wi Fi search time value of 17 minutes.

In response to communication learning model and or built in features can log part or all of the information provided by Wi Fi Application and or built in features such as shown in log of .

In scenario learning model is trained after receiving the data from communications and . shows that learning model indicates it is trained by sending communication to Wi Fi Application with a Notify function call including two parameters a session key S10 and a predefined value of LM TRAINED to indicate that learning model is now trained.

Scenario continues with the mobile platform traveling to location H and requesting a prediction of a Wi Fi search outcome. To request the prediction of the Wi Fi search outcome Wi Fi Application can send communication with a Pull function call. As shown in the Pull function call has two parameters a session key S10 and a pre defined value WIFI SEARCH indicating that Wi Fi Application is requesting a prediction of an outcome of search for Wi Fi networks from learning model .

In some embodiments not shown in the Pull function call as sent in communication can have more than two parameters. For example a third parameter specifying a network name e.g. Zone3 can be interpreted by learning model as a request for a prediction for a search of wireless communications with the specified network. As another example a third parameter specifying a location e.g. location D can be interpreted by learning model as a request for a prediction for a search of wireless communications at the specified location. Combining these examples parameters specifying both a network name and a location can be interpreted by learning model as a request for a prediction for a search of wireless communications at the specified location for the specified network. Many other possible requests for prediction of searches for wireless communication are possible as well.

In response to communication learning model can send communication with a Push function to built in features to request platform related data. The Push function sent via communication has six parameters a built in session key of BI10 a location parameter L1 a velocity parameter V1 a clock time parameter CT1 a usage parameter U1 and a last Wi Fi search time parameter LWST1. In response built in features can send a Push function via communication with values for the parameters requested using communication . As shown in communication includes a Push function with a built in session key of BI10 a location value of H indicating location H as shown in a velocity value of 0 MPH a clock time value of 2005 a usage value of 125 minutes and a last Wi Fi search time value of 3 minutes.

Learning model can then classify the data received from built in features into one of two possible predicted outcomes a prediction that a search for a Wi Fi network will be successful and a prediction that a search for a Wi Fi network will be unsuccessful. In some embodiments a third possible outcome that the learning model is unable to predict the outcome perhaps because the learning model is not trained to generate a prediction given the current data is possible as well. In still other embodiments other predictions are possible as well.

In scenario learning model can predict that a search for a Wi Fi connection at location H is unlikely to succeed perhaps based on recent data from nearby location A. Learning model can send communication to inform Wi Fi Application of the prediction. shows that communication includes a PullResp function call with five parameters a session key S10 a input source reference Conns a predicted Wi Fi signal strength of 0 a predicted Wi Fi network of none indicated using the predefined value of NO NTWK and a predicted Wi Fi search outcome of no network found indicated using the predefined value of PRED NO.

In response to the prediction of a search for a Wi Fi connection Wi Fi Application can determine that the wireless interface WI activation to search for and or connect to a Wi Fi network can be deferred as shown in box of as learning model has predicted the search and or attempt to connect would be unsuccessful. Wi Fi Application can save power for the mobile platform by deferring wireless interface activation and making fewer unsuccessful searches for Wi Fi connections.

In some embodiments in response to the unsuccessful prediction Wi Fi Application can make one or more additional requests for predictions of searches for Wi Fi connections. For example Wi Fi Application can periodically request predictions of searches for Wi Fi connections such as requesting one prediction every N seconds where N 0. In other embodiments Wi Fi Application can request another prediction of a search for Wi Fi connections when the mobile platform has moved more than a threshold amount from a location of an unsuccessful search. For example if the threshold amount is 100 yards then Wi Fi Application can request another predicted search when mobile platform moves more than 100 yards from location H. Other responses to unsuccessful predictions are possible as well.

Scenario continues with the mobile platform traveling to location I and requesting a prediction of a Wi Fi search outcome. To request the prediction of the Wi Fi search outcome Wi Fi Application can send communication with a Pull function call. As shown in the Pull function call has two parameters a session key S10 and a pre defined value WIFI SEARCH indicating that Wi Fi Application is requesting a prediction of an outcome of search for Wi Fi networks from learning model .

In response to communication learning model can send communication with a Push function to built in features to request platform related data. The Push function sent via communication has six parameters a built in session key of BI10 a location parameter L1 a velocity parameter V1 a clock time parameter CT1 a usage parameter U1 and a last Wi Fi search time parameter LWST1. In response built in features can send a Push function via communication with values for the parameters requested using communication . As shown in communication includes a Push function with a built in session key of BI10 a location value of I indicating location I as shown in a velocity value of 3 MPH a clock time value of 2015 a usage value of 135 minutes and a last Wi Fi search time value of 13 minutes.

In scenario learning model can determine that learning model is unable to predict an outcome of a search for a Wi Fi connection at location I. For example learning model can determine that training data does not apply to locations velocities clock times usage values and or last search times as provided in communication and so determine that learning model is unable to predict an outcome of a search for a Wi Fi connection at location I moving at 3 MPH at 20 15 with 135 minutes of usage and with 13 minutes since a last Wi Fi search for a Wi Fi connection.

Learning model can send communication to inform Wi Fi Application of the inability of learning model to make a prediction. shows that communication includes a PullResp function call with five parameters a session key S10 a input source reference Conns a predicted Wi Fi signal strength of 0 a predicted Wi Fi network of none indicated using the predefined value of NO NTWK and a predicted Wi Fi search outcome of an unknown outcome as indicated using the predefined value of PRED UNK. Upon observing the predefined value of PRED UNK Wi Fi Application can then determine that learning model to unable make a prediction.

In response to the unknown prediction of a search for a Wi Fi connection Wi Fi Application can determine that activating the wireless interface to search for and or connect to a Wi Fi network can be deferred as learning model has not predicted the search and or attempt to connect would be successful.

In some embodiments not shown in in response to the unknown prediction Wi Fi Application can activate the wireless interface search for Wi Fi connections and provide search result data to learning model such as performed via communications and . Other responses to prediction unavailability are possible as well.

Scenario continues with the mobile platform traveling to location J and requesting a prediction of a Wi Fi search outcome. To request the prediction of the Wi Fi search outcome Wi Fi Application can send communication with a Pull function call. As shown in the Pull function call has two parameters a session key S10 and a pre defined value WIFI SEARCH indicating that Wi Fi Application is requesting a prediction of an outcome of search for Wi Fi networks from learning model .

In response to communication learning model can send communication with a Push function to built in features to request platform related data. The Push function sent via communication has six parameters a built in session key of BI10 a location parameter L1 a velocity parameter V1 a clock time parameter CT1 a usage parameter U1 and a last Wi Fi search time parameter LWST1. In response built in features can send a Push function via communication with values for the parameters requested using communication . As shown in communication includes a Push function with a built in session key of BI10 a location value of J indicating location J as shown in a velocity value of 18 MPH a clock time value of 2022 a usage value of 142 minutes and a last Wi Fi search time value of 20 minutes.

In scenario learning model can predict that a search for a Wi Fi connection at location J is likely to succeed perhaps based on recent data from nearby location B. Learning model can send communication to inform Wi Fi Application of the prediction. shows that communication includes a PullResp function call with five parameters a session key S10 a input source reference Conns a predicted Wi Fi signal strength of 36 a predicted Wi Fi network name of ApBer and a predicted Wi Fi search outcome a network found indicated using the predefined value of PRED YES.

In response to the prediction of a successful search for a Wi Fi connection Wi Fi Application of mobile platform can activate the wireless interface as shown in box of . Once the wireless interface is activated mobile platform can search for and or connect to a Wi Fi network as learning model has predicted the search and or attempt to connect would be successful. Other responses to successful predictions are possible as well.

A usage session for a mobile platform is the span of time between when the mobile platform is awakened or perhaps powered up and when the mobile platform is put to sleep or perhaps powered down. The time span or duration of the usage session is the amount of time between the awakening of the mobile platform and putting the mobile platform to sleep. For example if a mobile platform is powered up at 8 00 AM and powered down at 8 05 AM the time span of the usage session starting at 8 00 AM is five minutes.

The machine learning service can predict a time span of a usage session either numerically or via classification. An example numerical prediction would be that a usage session will be six minutes long. An example classification of the duration of the usage session can be short e.g. less than five minutes medium e.g. between five and ten minutes or long greater than five minutes . In an example utilizing these classifications the machine learning service can predict a usage session will be either short medium or long.

A software application can use a predicted session duration or time span to guide the application s behavior. For example suppose a user powers up a mobile platform and then starts a jukebox application to play random audio and or video files. The jukebox application can send a request to the machine learning service to predict a time span for the current usage session. In this example the machine learning service predicts a medium 5 10 minute time span for the usage session. Based on the predicted medium time span the jukebox application can initially select only audio video and or audio video files that cumulatively take ten minutes or less to play based on the predicted medium time span.

Further suppose the jukebox application first plays an audio video and or audio video file that takes three minutes. Then in selecting a second audio video and or audio video file the jukebox application can select files that take no more than seven minutes long based on a ten minute long maximum duration of the usage session with three minutes already consumed by playing the first file. Many other examples of application requests and using predicted session durations and or time spans are possible as well.

Turning to the figures is a flow chart of a method in accordance with an example embodiment. In some embodiments part or all of method can be executed using one or more mobile platforms e.g. mobile platform and or one or more computing devices e.g. computing device .

At block feature related data can be received at a machine learning service executing on a mobile platform. The feature related data can include usage related data and platform related data. The usage related data can include data about one or more time spans that the mobile platform is activated. The platform related data can be received from the mobile platform. The usage related data and the platform related data can differ.

At block the machine learning service can determine whether the machine learning service is trained to perform machine learning operations related to predicting a time span that the mobile platform will be activated.

In other embodiments the machine learning operations can include a regression operation. In particular embodiments the regression operation can include a linear regression operation. In other particular embodiments the predicted time span can include a predicted amount for the predicted time span.

At block in response to determining that the machine learning service is trained the machine learning service can receive a request for a predicted time span that the mobile platform will be activated determine the predicted time span by performing a machine learning operation on the feature related data and send the predicted time span.

In particular embodiments the machine learning service can determine the predicted time span by performing a machine learning operation on the feature related data without receiving the request for the predicted time span i.e. the machine learning service can generate the predicted time span without being prompted by the request.

In some embodiments the predicted time span can include a predicted classification of the time span. In particular embodiments the predicted classification of the time span can be selected from among a short time span a medium time span and a long time span. In other embodiments method can include selecting one or more media files based on the predicted time span and presenting the selected one or more media files using the mobile platform such as discussed above in the context of the example jukebox application.

Semantic labels such as the location label and time span label can be part of usage log . For example the first row of usage log corresponds to an eight minute long usage session starting at 8 08 AM 0808 at location 1 also known as Home and the time span of medium duration. For the entries in usage log a usage session with a time span of zero to five minutes is labeled short a usage session with a time span of five to ten minutes is labeled medium and a usage session with a 10 minute time span is labeled long. In some embodiments more fewer and or other semantic labels for time spans can be used. In other embodiments other ranges of times can be used for short medium and or long time spans.

Additionally locations can have semantically labels. As shown in seven separate locations are listed both numerically using the numbers one through seven and with semantic labels. shows location 1 with a semantic location label of Home location 2 with a semantic location label of Work location 3 with a semantic location label of Random1 location 4 with a semantic location label of Groceries location 5 with a semantic location label of Lunch Rest. abbreviating Lunch Restaurant location 6 with a semantic location label of Movie for a movie theater and location 7 with a semantic location label of Random2. 

Usage log also includes a Start column with starting times for usage sessions shown in military time notation and a Mins column with starting times for usage sessions shown in terms of the number of minutes since midnight. For example the first row of usage log in the Start column is for a usage session of 17 minutes duration that started at 17 59 where the time 17 59 17 60 59 1 079 minutes after midnight.

The linear regression model shown in is based on the TS and Mins column data. Mins column data were used instead of Start column data as the Mins column data covers a single range of integers from 0 corresponding to 0000 military time of 0000 to 1439 corresponding to 2359 military time while the set of military time values involve 24 separate ranges of integers 0000 0059 0100 0159 . . . 2300 2359 .

Specifically the linear regression model shown is based on the equation y mx b where m is approximately 0.04 and b is approximately 61. While Mins column data were used to determine the linear regression model the x or Start axis of graph is labeled using military time labels for convenience. For example the x axis label 0600 shown in represents the time 6 00 AM.

The linear regression model can predict numerical values for time spans. For example suppose the machine learning model was requested to predict a time span of a usage session for the mobile platform at location Groceries at 6 PM or 1800 military time. The machine learning service can use the linear regression model shown in to predict a time span of 18.85 minutes for the usage session starting at 1800.

Classification diagram begins at node where a location is determined. shows locations using the some of the semantic labels shown in such as Home used in node Work used in node Groceries used in node and Lunch Rest. used in node . Node uses a label of Single Session Locs. to group all of the locations involved in one usage session as recorded in usage log . Node include data generated for locations with semantic labels Movie Random and Random2 in usage log . In other embodiments numeric locations can replace the use of semantic location labels in classification diagram .

In the example shown in a short time span can range from zero to five minutes a medium time span can range from six to ten minutes and a long time span ranges longer than eleven minutes. Specifically node shows an analysis of usage session time spans from usage log at location Home indicating that at location Home six of sixteen of total sessions or 37.5 had a short time span seven of sixteen total sessions or 43.8 had a medium time span and three of sixteen total sessions or 18.8 had a long time span. In some embodiments more fewer and or other semantic labels for time spans can be used. In other embodiments other ranges of times can be used for short medium and or long time spans.

Node shows an analysis of usage session time spans at location Work indicating that at location Work ten of twelve total sessions or 83.3 had a short time span two of twelve total sessions or 16.7 had a medium time span and zero sessions had a long time span.

Only one semantic time label is shown as being utilized for each of nodes and . For node representing location Groceries all four usage sessions had long time spans. Node regarding location Lunch Rest. indicates that both usage sessions at that location had short time spans. Node reflecting data from the Single Session Locations indicates that all three usage sessions at those locations had short time spans.

At the Home and Work locations multiple possible classifications of time spans are possible. In that case the data for those locations can be additionally analyzed. For example node shown connected to node in classification diagram indicates a result of further analysis of usage sessions for location Home based on both usage session time spans and time of day. In node times of day are classified as either before work BW during work DW or after work AW . For example the BW times of day can range from midnight to 8 59 AM the DW times of day can range from 9 00 AM to 5 00 PM and the AW times of day can range from 5 01 PM to 11 59 PM. In some embodiments more fewer and or other semantic labels for times of day can be used. In other embodiments other ranges of times can be used for the BW DW and AW time spans. In still other embodiments times of day can be used without classifications.

Node of shows that a three of seven usage sessions before work at location Home have short time spans and four usage sessions at location Home have medium time spans b no usage sessions were made at location Home during work and that c equal numbers of short medium and long duration usage sessions were made at location Home after work. Using the information shown in node if a prediction is requested while the mobile platform is at location Home one prediction is that the call is slightly more likely to be of medium duration than short duration before work and that all durations are equally likely either during work or after work. As there are data for after work calls additional analysis may be performed to better refine the after work call estimate that all durations are equally likely e.g. use additional time span and or time of day classifications for after work calls.

For node times of day are classified as either AM for morning work hours e.g. between 9 01 AM and 11 59 AM Meal or during a meal a.k.a. lunch or dinner e.g. between 12 00 PM and 12 59 PM and PM for post meal afternoon work hours e.g. between 1 00 PM and 4 59 PM. In some embodiments more fewer and or other semantic labels for times of day can be used. In other embodiments other ranges of times can be used for the AM Meal and PM times of day. In still other embodiments times of day can be used without classifications. Node of shows that a all AM time usage sessions have short time spans b all Meal time usage sessions have short time spans and c it is somewhat more likely that short time span usage sessions will be made during the PM times of day than medium time span usage sessions.

Classifications and classification diagram can be used to generate numerically valued predictions. For example using the data in node if a usage session is begun at location Home 37.5 of all usage sessions are short 43.8 of all usage sessions are medium and 18.8 of all usage session are long. To generate a numerical prediction one set of assumptions that can be used is that the mid point value of a given range is chosen to represent usage sessions in the range and a long time span usage session is arbitrarily chosen to have a 20 minute long time span.

Under these assumptions and for the data in node a predicted time span PT for a usage session at location Home can be determined as short percent short midpoint medium percent medium midpoint long percent long arbitrary value 37.5 2.5 minutes 43.8 8 minutes 18.8 20 minutes 0.94 3.50 3.76 8.20 minutes.

Other techniques for generating numerically valued predictions from classifications and classification diagrams are possible as well.

A jukebox application can be configured to request the machine learning service to predict a time span of a usage session and then select media including but not limited to audio video and audio video files to play during the predicted duration. In scenario the jukebox application generates jukebox application display which includes prediction dialog media list dialog play list button and close button .

Prediction dialog shows the usage session time span predicted by the machine learning service of 10 minutes perhaps based on the feature related data shown in feature related display such as the displayed location date and time. Prediction dialog includes two buttons a Change button to permit the user to change the usage session time span from the predicted value and a Dismiss button to close prediction dialog .

As shown in media list dialog displays a media list selected by the jukebox application. The media list includes three media files to be played Two Minute News with a duration of 2 03 a Favorite Song 1 with a duration of 4 32 and Now Future Tools with a duration of 3 11.

In scenario and as shown in the Now Future Tools media is selected as shown in using a grey background for the Now Future Tools media list item and the bold font for the Now Future Tools media list entry. As such selected media and controls operate on the Now Future Tools media. Selected media and controls include a Play button to play the selected media immediately a Delete button to delete the selected media from the media list a Move button to enable movement of the selected media within the media list and a New . . . button to permit addition of new media item s to the media list. Other dialogs and controls are possible as well.

Usage information shows the total duration of the three media files is 9 minutes 46 seconds 9 46 and the current usage or amount of time mobile platform has been activated is 3 seconds 0 03 . In scenario the media shown in media list dialog were selected in part to play less in total less than the predicted session time span. In scenario and as shown in the total duration of the three media files is 14 seconds less than the predicted duration of 10 minutes.

Play list button can be used to play the media items in the order shown in media list dialog . Close button can be used to close user interface . In some embodiments media files played using the jukebox application can be played in the background to permit the user of mobile platform to interact with other applications during the usage session. In particular embodiments when the jukebox application is in the background and is about to play a video or audio video file the jukebox application can attempt to become a foreground application to permit the user to view the video or audio video file.

Volume settings for mobile platforms such as ring tone volume mute and vibrate settings are often changed according to predictable patterns. For example before attending meetings a mobile platform user can use a mute setting to turn off a telephone ringer. At that time the user may set the mobile platform to a vibrate mode where a user of the mobile platform is alerted to an incoming telephone call by use of a haptic or vibration system rather than the telephone ringer.

Once the meeting is complete the user may un mute the mobile platform so to turn on the telephone ringer. At that time the user may also set the vibrate mode to off so to turn off the haptic or vibration system and thus rely on the telephone ringer to alert the user of an incoming telephone call. The user may perform similar actions at other places than meetings where silence is often expected such as at movie theaters libraries schools lecture halls live performances and similar situations.

The machine learning service can be trained to learn patterns in changing volume settings for a mobile platform. Once trained the machine learning service can generate predictions for the volume settings. The predictions can be used to have the mobile platform directly or indirectly change the volume settings. For example the machine learning service can provide the predicted settings to a dialer application or other application that changes the settings to the predicted setting values. As another example the machine learning service can generate a prompt with the predicted setting values perhaps with a reminder to the user to change the volume settings.

By predicting volume settings for mobile platforms the mobile learning service can save the user the effort and time involved in repeatedly setting and resetting volume settings. Additionally if the mobile platform is configured to prompt the user to change volume settings when predicted the user can be reminded to change volume settings before attending an event where silence is often expected and thus avoid the embarrassment of having the mobile platform sound off during the event.

Turning to the figures is a flow chart of a method in accordance with an example embodiment. In some embodiments part or all of method can be executed using one or more mobile platforms e.g. mobile platform and or one or more computing devices e.g. computing device .

At block feature related data can be received at a machine learning service executing on a mobile platform. The feature related data can include volume related data and platform related data. The volume related data can include data about one or more volume related settings for the mobile platform. The platform related data can be received from the mobile platform. The volume related data and the platform related data can differ.

In some embodiments the one or more volume related settings can include a mute setting a vibration setting and a setting for ringer volume. In other embodiments the feature related data can include data related to a location of the mobile platform a current time a call termination time a calling party and a calendar event. In still other embodiments the platform related data can include data about devices proximate to the mobile platform.

At block the machine learning service can determine whether the machine learning service is trained to perform machine learning operations related to predicting a change in the one or more volume related settings for the mobile platform.

At block in response to determining that the machine learning service is trained the machine learning service can receive a request for predicting the change in the one or more volume related settings determine the predicted change in the one or more volume related settings by performing a machine learning operation on the feature related data and send the predicted change in the one or more volume related settings.

In particular embodiments the machine learning service can determine the predicted change in the one or more volume related settings by performing a machine learning operation on the feature related data without receiving the request for the predicted outcome of the search for establishing the electronic communication i.e. the machine learning service can generate the predicted outcome without being prompted by a request.

In some embodiments method can further include determining one or more semantic labels for the platform related data. In particular of the some embodiments determining one or more semantic labels for the platform related data can include determining the one or more semantic labels for the current time where the semantic labels include an at home time label a work time label a sleep time label a traveling time label and a meal time label.

In other particular of the some embodiments determining one or more semantic labels for the platform related data includes determining the one or more semantic labels for the current location where the semantic labels include a home location label a work location label a sleep location label a traveling location label and a meal location label.

In still other embodiments method can further include determining whether the predicted change in the one or more volume related settings can include a prediction that at least one of the one or more volume related settings change. In response to determining that the predicted change in the one or more volume related settings includes the prediction that the at least one of the one or more volume related settings changes a prompt to change the at least one of the one or more volume related settings can be generated.

In even other embodiments method can further include determining whether the predicted change in the one or more volume related settings can include a prediction that at least one of the one or more volume related settings change. In response to determining that the predicted change in the one or more volume related settings includes the prediction that the at least one of the one or more volume related settings changes the at least one of the one or more volume related settings can be changed. The volume related settings can be changed by the mobile platform without additional input perhaps by a dialer application executing on the mobile platform that receives the at least one of the prediction that the one or more volume related settings from the machine learning service and sets the volume related settings according to the prediction.

Manual volume settings includes a slider bar that enables a user to set a microphone output setting between a minimum setting of 0 which effectively mutes a ringer that outputs the ringtone and a maximum setting of 100 which provides the maximum output volume for the ringtone. In scenario as shown in manual ringtone volume setting is set at 51.

Manual volume settings also includes check boxes for a mute setting and a vibrate setting. The mute setting when active or checked inhibits ringer output a.k.a. mutes the ringer and stops ringtone output. The vibrate setting when active or checked allows a haptic output for the ringer a.k.a. the mobile platform can vibrate or produce other haptic output when the mobile platform is in a ringing state. As shown in both the mute and vibrate settings are not active or checked. In scenario when manual volume settings are allowed the mute setting is not active and so the slider bar sets the volume for the ringer. Also no haptic output is generated when the mobile platform is in the ringing state.

As shown in smart volume setting can learn and predict ringer volume mute and vibrate settings. When smart volume setting is disabled dialer application can use manual volume settings to determine output volume for a ringer of mobile platform and whether or not haptic output will be provided when mobile platform is in the ringing state.

When smart volume setting is enabled dialer application can use a machine learning service to perform machine learning operation s to predict volume settings such as ringtone volume mute and vibrate settings. Then upon receiving predicted volume setting value s dialer application can use the predicted settings values according to predicted usage setting .

In scenario and as shown in smart volume setting is set to enabled and predicted usage setting is set to apply. When predicted usage setting is set to apply predicted volume setting value s such as ringtone volume mute and or vibrate setting values received by dialer application are used to set the ringtone volume mute and vibrate settings. That is when predicted usage setting is set to apply mobile platform and or dialer application can set the ringtone volume mute and or vibrate settings using the predicted volume setting values s without additional input such as user input. In some embodiments when predicted usage setting is set to apply mobile platform and or dialer application can generate a dialog or other prompt to indicate to a user that the ringtone volume mute and or vibrate settings have been changed to the predicted volume setting values s .

When predicted usage setting is set to prompt predicted volume setting value s received by dialer application are displayed audibly output and or otherwise prompted to a user of mobile platform . Upon being displayed the user can use volume dialog to set the ringtone volume mute and vibrate settings as desired perhaps using the prompted predicted volume setting value s .

Dialer application can instruct learning model via communication to set up a prediction interface. As shown in communication includes a PredictionInterface call with four parameters session key S11 and three parameters for requested output predictions ring tone volume settings mute settings and vibration settings as shown in using the respective predefined RING VOL MUTE SET and VIB SET values.

In response learning model sends communication to built in features with a ReqBI function call requesting built in features. As shown in learning model uses the ReqBI call to request using input source descriptor bid current location values clock times calendar related events and numbers of local or proximate devices by passing the respective predefined LOC CLOCK TIME CAL EVENTS and NUM LOC DEVS values to built in features . Built in features can include at least the functionality of built in features discussed above. In response built in features returns a built in session key BI11 via communication . Built in session key BI11 is included with subsequent communications between learning model and built in features to permit addressing the subsequent built in related communications to the correct learning model.

Scenario continues with learning model sending communication to dialer application with a Notify function call. In scenario learning model is trained after receiving the data from communications and . shows that learning model indicates it is trained by sending communication to dialer application with a Notify function call including two parameters a session key S11 and a predefined value of LM TRAINED to indicate that learning model is now trained.

Scenario continues with dialer application sending communication to learning model . Communication includes the Pull function call to request a prediction of ringer volume mute and vibration settings from learning model using respective pre defined values of RING VOL MUTE SET and VIB SET as parameters the Pull function call. Communication includes feature data from built in functions with a location of Work a time of 2 28 PM 1428 a calendar event of Meet230PM and a number of local devices of 5. Learning model can apply machine learning operations to predict the requested volume settings. Scenario continues with learning model sending the prediction to dialer application using PullResp in communication . shows that the prediction of communication includes a ringtone volume setting of 0 a mute setting of NO and vibration setting of YES.

In scenario built in features sends communication to learning model where communication includes a Push function call to inform learning model that mobile platform is at Work at 12 57 PM 1257 with a calendar event of Meeting1PM and no other local mobile platforms present. In response to communication learning model can apply machine learning operations to predict volume settings based on the information provided via communication . Scenario continues with learning model sending a Notify function call in communication to dialer application predicting a ringtone volume setting of 0 a mute setting of YES and vibration setting of YES. Upon reception of communication mobile platform and or dialer application can prompt a user of mobile platform of recently predicted volume settings and or apply the predicted volume settings perhaps based on settings of smart volume setting and prediction usage setting .

Scenario concludes with dialer application call Save function via communication to request that learning model save a context and perhaps other data of a learning session thread in a VolSetModel variable. In some scenarios not shown in learning model can provide a response to communication such as a return value to the Save function and or a communication providing a status of the Save function e.g. SaveOK or SaveFail.

Although only shows three programmable devices distributed application architectures may serve tens hundreds or thousands of programmable devices. Moreover programmable devices and or any additional programmable devices may be any sort of computing device such as an ordinary laptop computer desktop computer network terminal wireless communication device e.g. a cell phone or smart phone and so on. In some embodiments programmable devices and may be dedicated to the design and use of software applications. In other embodiments programmable devices and may be general purpose computers that are configured to perform a number of tasks and need not be dedicated to software development tools.

Server devices can be configured to perform one or more services as requested by programmable devices and or . For example server device and or can provide content to programmable devices . The content can include but is not limited to web pages hypertext scripts binary data such as compiled software images audio and or video. The content can include compressed and or uncompressed content. The content can be encrypted and or unencrypted. Other types of content are possible as well.

As another example server device and or can provide programmable devices with access to software for database search computation graphical audio video World Wide Web Internet utilization and or other functions. Many other examples of server devices are possible as well.

Generally user interface module is configured to send data to and or receive data from external user input output devices. For example user interface module can be configured to send and or receive data to and or from user input devices such as a keyboard a keypad a touch screen a computer mouse a track ball a joystick a camera a voice recognition module and or other similar devices. User interface module can also be configured to provide output to user display devices such as one or more cathode ray tubes CRT liquid crystal displays LCD light emitting diodes LEDs displays using digital light processing DLP technology printers light bulbs and or other similar devices either now known or later developed. User interface module can also be configured generate audible output s through device s such as a speaker speaker jack audio output port audio output device earphones telephone ringers and or other similar devices. In some embodiments user interface module can be configured to provide haptic and or tactile feedback using one or more vibration devices tactile sensors actuators including haptic actuators tactile touchpads piezo haptic devices piezo haptic drivers and or other similar devices.

Network communications interface module can include one or more wireless interfaces and or one or more wireline interfaces that are configurable to communicate via a network such as network shown in . Wireless interfaces can include one or more wireless transmitters receivers and or transceivers such as a Bluetooth transceiver a Zigbee transceiver a Wi Fi transceiver a WiMAX transceiver and or other similar type of wireless transceiver configurable to communicate via a wireless network. Wireline interfaces can include one or more wireline transmitters receivers and or transceivers such as an Ethernet transceiver a Universal Serial Bus USB transceiver or similar transceiver configurable to communicate via a twisted pair wire a coaxial cable a fiber optic link or a similar physical connection to a wireline network.

In some embodiments network communications interface module can be configured to provide reliable secured and or authenticated communications. For each communication described herein information for ensuring reliable communications i.e. guaranteed message delivery can be provided perhaps as part of a message header and or footer e.g. packet message sequencing information encapsulation header s and or footer s size time information and transmission verification information such as CRC and or parity check values . Communications can be made secure e.g. be encoded or encrypted and or decrypted decoded using one or more cryptographic protocols and or algorithms such as but not limited to DES AES RSA Diffie Hellman and or DSA. Other cryptographic protocols and or algorithms can be used as well or in addition to those listed herein to secure and then decrypt decode communications.

Processors can include one or more general purpose processors and or one or more special purpose processors e.g. digital signal processors application specific integrated circuits etc. . Processors can be configured to execute computer readable program instructions that are contained in the data storage and or other instructions as described herein.

Data storage can include one or more computer readable storage media that can be read and or accessed by at least one of processors . The one or more computer readable storage media can include volatile and or non volatile storage components such as optical magnetic organic or other memory or disc storage which can be integrated in whole or in part with at least one of processors . In some embodiments data storage can be implemented using a single physical device e.g. one optical magnetic organic or other memory or disc storage unit while in other embodiments data storage can be implemented using two or more physical devices.

Data storage can include computer readable program instructions and perhaps additional data. In some embodiments data storage can additionally include storage required to perform at least part of the herein described methods and techniques and or at least part of the functionality of the herein described devices and networks.

In some embodiments data and services at server devices and or can be encoded as computer readable information stored in non transitory tangible computer readable media or computer readable storage media and accessible by programmable devices and and or other computing devices. In some embodiments data at server device and or can be stored on a single disk drive or other tangible storage media or can be implemented on multiple disk drives or other tangible storage media located at one or more diverse geographic locations.

In some embodiments each of the computing clusters and can have an equal number of computing devices an equal number of cluster storage arrays and an equal number of cluster routers. In other embodiments however each computing cluster can have different numbers of computing devices different numbers of cluster storage arrays and different numbers of cluster routers. The number of computing devices cluster storage arrays and cluster routers in each computing cluster can depend on the computing task or tasks assigned to each computing cluster.

In computing cluster for example computing devices can be configured to perform various computing tasks of server device . In one embodiment the various functionalities of server device can be distributed among one or more of computing devices and . Computing devices and in computing clusters and can be configured similarly to computing devices in computing cluster . On the other hand in some embodiments computing devices and can be configured to perform different functions.

In some embodiments computing tasks and stored data associated with server devices and or can be distributed across computing devices and based at least in part on the processing requirements of server devices and or the processing capabilities of computing devices and the latency of the network links between the computing devices in each computing cluster and between the computing clusters themselves and or other factors that can contribute to the cost speed fault tolerance resiliency efficiency and or other design goals of the overall system architecture.

The cluster storage arrays and of the computing clusters and can be data storage arrays that include disk array controllers configured to manage read and write access to groups of hard disk drives. The disk array controllers alone or in conjunction with their respective computing devices can also be configured to manage backup or redundant copies of the data stored in the cluster storage arrays to protect against disk drive or other cluster storage array failures and or network failures that prevent one or more computing devices from accessing one or more cluster storage arrays.

Similar to the manner in which the functions of server devices and or can be distributed across computing devices and of computing clusters and various active portions and or backup portions of these components can be distributed across cluster storage arrays and . For example some cluster storage arrays can be configured to store the data of server device while other cluster storage arrays can store data of server device . Additionally some cluster storage arrays can be configured to store backup versions of data stored in other cluster storage arrays.

The cluster routers and in computing clusters and can include networking equipment configured to provide internal and external communications for the computing clusters. For example the cluster routers in computing cluster can include one or more internet switching and routing devices configured to provide i local area network communications between the computing devices and the cluster storage arrays via the local cluster network and ii wide area network communications between the computing cluster and the computing clusters and via the wide area network connection to network . Cluster routers and can include network equipment similar to the cluster routers and cluster routers and can perform similar networking functions for computing clusters and that cluster routers perform for computing cluster

In some embodiments the configuration of the cluster routers and can be based at least in part on the data communication requirements of the computing devices and cluster storage arrays the data communications capabilities of the network equipment in the cluster routers and the latency and throughput of local networks the latency throughput and cost of wide area network links and and or other factors that can contribute to the cost speed fault tolerance resiliency efficiency and or other design goals of the moderation system architecture.

The above detailed description describes various features and functions of the disclosed systems devices and methods with reference to the accompanying figures. In the figures similar symbols typically identify similar components unless context dictates otherwise. The illustrative embodiments described in the detailed description figures and claims are not meant to be limiting. Other embodiments can be utilized and other changes can be made without departing from the spirit or scope of the subject matter presented herein. It will be readily understood that the aspects of the present disclosure as generally described herein and illustrated in the figures can be arranged substituted combined separated and designed in a wide variety of different configurations all of which are explicitly contemplated herein.

With respect to any or all of the ladder diagrams scenarios and flow charts in the figures and as discussed herein each block and or communication may represent a processing of information and or a transmission of information in accordance with example embodiments. Alternative embodiments are included within the scope of these example embodiments. In these alternative embodiments for example functions described as blocks transmissions communications requests responses and or messages may be executed out of order from that shown or discussed including substantially concurrent or in reverse order depending on the functionality involved. Further more or fewer blocks and or functions may be used with any of the ladder diagrams scenarios and flow charts discussed herein and these ladder diagrams scenarios and flow charts may be combined with one another in part or in whole.

A block that represents a processing of information may correspond to circuitry that can be configured to perform the specific logical functions of a herein described method or technique. Alternatively or additionally a block that represents a processing of information may correspond to a module a segment or a portion of program code including related data . The program code may include one or more instructions executable by a processor for implementing specific logical functions or actions in the method or technique. The program code and or related data may be stored on any type of computer readable medium such as a storage device including a disk or hard drive or other storage medium.

The computer readable medium may also include non transitory computer readable media such as computer readable media that stores data for short periods of time like register memory processor cache and random access memory RAM . The computer readable media may also include non transitory computer readable media that stores program code and or data for longer periods of time such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. A computer readable medium may be considered a computer readable storage medium for example or a tangible storage device.

Moreover a block that represents one or more information transmissions may correspond to information transmissions between software and or hardware modules in the same physical device. However other information transmissions may be between software modules and or hardware modules in different physical devices.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope and spirit being indicated by the following claims.

