---

title: System and method for detecting errors in audio data
abstract: An application programming interface (API) executed by a first processing unit combines audio data samples with error code values generated for those samples. The API then causes a data stream to be opened having sufficient bandwidth to accommodate combined samples made up of audio data samples and corresponding error code values. The combined samples are then transmitted to a decoder and validation unit within a second processing unit that receives the combined data, strips the error code values and validates the audio data based on the error code values. When the error code values indicate that the audio data has been compromised, the second processing unit terminates the output of sound derived from the audio data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09009561&OS=09009561&RS=09009561
owner: NVIDIA Corporation
number: 09009561
owner_city: Santa Clara
owner_country: US
publication_date: 20120801
---
The present invention generally relates to audio hardware and more specifically to a system and method for detecting errors in audio data.

A conventional media player application such as a Blu Ray player application streams audio data to hardware that processes the audio data and then causes speakers to output sound derived from that audio data. The hardware could be for example a graphics processing unit GPU that includes audio processing circuitry.

When the media player application streams the audio data to hardware the data passes through an operating system OS layer to an audio driver. The audio driver is a software application executing within the OS layer that is capable of communicating directly with the hardware. When the audio data passes through the OS layer to the audio driver that data may become modified or even compromised before reaching the audio hardware. For example some OSs append invalid NULL values to the end of the audio data in order to fill a playback buffer thereby introducing errors into that data. The audio data may also become compromised by random bit flips or other unpredictable data altering events. Another instance of data becoming comprised occurs when the OS is heavily loaded and audio data is not written to a given location before audio hardware reads from that location causing the hardware to fetch stale data.

Problems arise because conventional audio hardware may not be able to detect that the audio data has been compromised and may attempt to output sound derived from that audio data despite the data being compromised. Sound derived from compromised audio data may be full of noise and unintelligible or worse yet noisy and unpleasant to the ears of the user of the media player application. Providing an unpleasant user experience is unacceptable to providers of media player applications as well as to manufacturers of hardware that supports media players such as GPU manufacturers.

Accordingly what is needed in the art is a more effective technique for detecting errors in audio data.

One embodiment of the present invention sets forth a computer implemented method for embedding error code values into data samples streamed from a first hardware unit to a second hardware unit the method including receiving an M bit data sample from a software application executing on the first hardware unit M being an integer generating an N bit error code value by performing an error analysis on the M bit data sample N being an integer generating an M N bit augmented data sample by combining the M bit data sample with the N bit error code value and opening an M N bit data stream to the second hardware unit where the second hardware unit is configured to receive the M N bit augmented data sample via the M N bit data stream reproduce the M bit data sample and the N bit error code value based on the M N bit augmented data sample and identify errors in the M bit data sample based on the N bit error code value.

An advantage of the techniques described herein is that when audio hardware receives compromised audio data the audio hardware is capable of determining that the audio data has been compromised and is able to stop outputting sound derived from the compromised audio data. Accordingly the audio hardware preserves the user experience by ensuring that unintelligible or unpleasant sounds caused by compromised audio data are not output to the user.

In the following description numerous specific details are set forth to provide a more thorough understanding of the present invention. However it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances well known features have not been described in order to avoid obscuring the present invention.

In one embodiment the parallel processing subsystem incorporates circuitry optimized for graphics and video processing including for example video output circuitry and constitutes a graphics processing unit GPU . In another embodiment the parallel processing subsystem incorporates circuitry optimized for general purpose processing while preserving the underlying computational architecture described in greater detail herein. In yet another embodiment the parallel processing subsystem may be integrated with one or more other system elements such as the memory bridge CPU and I O bridge to form a system on chip SoC .

It will be appreciated that the system shown herein is illustrative and that variations and modifications are possible. The connection topology including the number and arrangement of bridges the number of CPUs and the number of parallel processing subsystems may be modified as desired. For instance in some embodiments system memory is connected to CPU directly rather than through a bridge and other devices communicate with system memory via memory bridge and CPU . In other alternative topologies parallel processing subsystem is connected to I O bridge or directly to CPU rather than to memory bridge . In still other embodiments I O bridge and memory bridge might be integrated into a single chip. Large embodiments may include two or more CPUs and two or more parallel processing systems . The particular components shown herein are optional for instance any number of add in cards or peripheral devices might be supported. In some embodiments switch is eliminated and network adapter and add in cards connect directly to I O bridge .

Referring again to in some embodiments some or all of PPUs in parallel processing subsystem are graphics processors with rendering pipelines that can be configured to perform various tasks related to generating pixel data from graphics data supplied by CPU and or system memory via memory bridge and bus interacting with local parallel processing memory which can be used as graphics memory including e.g. a conventional frame buffer to store and update pixel data delivering pixel data to display device and the like. In some embodiments parallel processing subsystem may include one or more PPUs that operate as graphics processors and one or more other PPUs that are used for general purpose computations. The PPUs may be identical or different and each PPU may have its own dedicated parallel processing memory device s or no dedicated parallel processing memory device s . One or more PPUs may output data to display device or each PPU may output data to one or more display devices .

In operation CPU is the master processor of computer system controlling and coordinating operations of other system components. In particular CPU issues commands that control the operation of PPUs . In some embodiments CPU writes a stream of commands for each PPU to a pushbuffer not explicitly shown in either or that may be located in system memory parallel processing memory or another storage location accessible to both CPU and PPU . PPU reads the command stream from the pushbuffer and then executes commands asynchronously relative to the operation of CPU .

Referring back now to each PPU includes an I O unit that communicates with the rest of computer system via communication path which connects to memory bridge or in one alternative embodiment directly to CPU . The connection of PPU to the rest of computer system may also be varied. In some embodiments parallel processing subsystem is implemented as an add in card that can be inserted into an expansion slot of computer system . In other embodiments a PPU can be integrated on a single chip with a bus bridge such as memory bridge or I O bridge . In still other embodiments some or all elements of PPU may be integrated on a single chip with CPU .

In one embodiment communication path is a PCIe link in which dedicated lanes are allocated to each PPU as is known in the art. Other communication paths may also be used. An I O unit generates packets or other signals for transmission on communication path and also receives all incoming packets or other signals from communication path directing the incoming packets to appropriate components of PPU . For example commands related to processing tasks may be directed to a host interface while commands related to memory operations e.g. reading from or writing to parallel processing memory may be directed to a memory crossbar unit . Host interface reads each pushbuffer and outputs the work specified by the pushbuffer to a front end .

Each PPU advantageously implements a highly parallel processing architecture. As shown in detail PPU includes a processing cluster array that includes a number C of general processing clusters GPCs where C 1. Each GPC is capable of executing a large number e.g. hundreds or thousands of threads concurrently where each thread is an instance of a program. In various applications different GPCs may be allocated for processing different types of programs or for performing different types of computations. For example in a graphics application a first set of GPCs may be allocated to perform tessellation operations and to produce primitive topologies for patches and a second set of GPCs may be allocated to perform tessellation shading to evaluate patch parameters for the primitive topologies and to determine vertex positions and other per vertex attributes. The allocation of GPCs may vary dependent on the workload arising for each type of program or computation.

GPCs receive processing tasks to be executed via a work distribution unit which receives commands defining processing tasks from front end unit . Processing tasks include indices of data to be processed e.g. surface patch data primitive data vertex data and or pixel data as well as state parameters and commands defining how the data is to be processed e.g. what program is to be executed . Work distribution unit may be configured to fetch the indices corresponding to the tasks or work distribution unit may receive the indices from front end . Front end ensures that GPCs are configured to a valid state before the processing specified by the pushbuffers is initiated.

When PPU is used for graphics processing for example the processing workload for each patch is divided into approximately equal sized tasks to enable distribution of the tessellation processing to multiple GPCs . A work distribution unit may be configured to produce tasks at a frequency capable of providing tasks to multiple GPCs for processing. By contrast in conventional systems processing is typically performed by a single processing engine while the other processing engines remain idle waiting for the single processing engine to complete its tasks before beginning their processing tasks. In some embodiments of the present invention portions of GPCs are configured to perform different types of processing. For example a first portion may be configured to perform vertex shading and topology generation a second portion may be configured to perform tessellation and geometry shading and a third portion may be configured to perform pixel shading in screen space to produce a rendered image. Intermediate data produced by GPCs may be stored in buffers to allow the intermediate data to be transmitted between GPCs for further processing.

Memory interface includes a number D of partition units that are each directly coupled to a portion of parallel processing memory where D 1. As shown the number of partition units generally equals the number of DRAM . In other embodiments the number of partition units may not equal the number of memory devices. Persons skilled in the art will appreciate that dynamic random access memories DRAMs may be replaced with other suitable storage devices and can be of generally conventional design. A detailed description is therefore omitted. Render targets such as frame buffers or texture maps may be stored across DRAMs allowing partition units to write portions of each render target in parallel to efficiently use the available bandwidth of parallel processing memory .

Any one of GPCs may process data to be written to any of the DRAMs within parallel processing memory . Crossbar unit is configured to route the output of each GPC to the input of any partition unit or to another GPC for further processing. GPCs communicate with memory interface through crossbar unit to read from or write to various external memory devices. In one embodiment crossbar unit has a connection to memory interface to communicate with I O unit as well as a connection to local parallel processing memory thereby enabling the processing cores within the different GPCs to communicate with system memory or other memory that is not local to PPU . In the embodiment shown in crossbar unit is directly connected with I O unit . Crossbar unit may use virtual channels to separate traffic streams between the GPCs and partition units .

Again GPCs can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying laws of physics to determine position velocity and other attributes of objects image rendering operations e.g. tessellation shader vertex shader geometry shader and or pixel shader programs and so on. PPUs may transfer data from system memory and or local parallel processing memories into internal on chip memory process the data and write result data back to system memory and or local parallel processing memories where such data can be accessed by other system components including CPU or another parallel processing subsystem .

A PPU may be provided with any amount of local parallel processing memory including no local memory and may use local memory and system memory in any combination. For instance a PPU can be a graphics processor in a unified memory architecture UMA embodiment. In such embodiments little or no dedicated graphics parallel processing memory would be provided and PPU would use system memory exclusively or almost exclusively. In UMA embodiments a PPU may be integrated into a bridge chip or processor chip or provided as a discrete chip with a high speed link e.g. PCIe connecting the PPU to system memory via a bridge chip or other communication means.

As noted above any number of PPUs can be included in a parallel processing subsystem . For instance multiple PPUs can be provided on a single add in card or multiple add in cards can be connected to communication path or one or more of PPUs can be integrated into a bridge chip. PPUs in a multi PPU system may be identical to or different from one another. For instance different PPUs might have different numbers of processing cores different amounts of local parallel processing memory and so on. Where multiple PPUs are present those PPUs may be operated in parallel to process data at a higher throughput than is possible with a single PPU . Systems incorporating one or more PPUs may be implemented in a variety of configurations and form factors including desktop laptop or handheld personal computers servers workstations game consoles embedded systems and the like.

Each of processing units and could be e.g. a CPU a GPU a PPU or any combination of devices capable of processing data. The different elements within in various embodiments could be stand alone elements in a computer system or could be integrated within a system on a chip SoC . In one embodiment processing unit is implemented by parallel processing subsystem shown in or PPU shown in and processing unit is implemented by CPU shown in . Processing units and may support a variety of different audio architectures including e.g. a High Definition Audio HDA architecture. In various embodiments processing units and may included within a mobile device such as a cell phone a smart phone a tablet computer and the like or within any type of larger computer system or network.

I O devices may include input devices such as a keyboard a mouse a touchpad a microphone a video camera and so forth as well as output devices such as a screen a speaker a printer a projector and so forth. In addition I O devices may include devices capable of performing both input and output operations such as a touch screen an Ethernet port a universal serial bus USB port a serial port etc. In one embodiment I O devices are configured to output HDA.

Each of memories and may include a hard disk one or more random access memory RAM modules a database one or more software and or hardware registers and so forth. In general any technically feasible unit that is capable of storing data may implement either of memories and .

As also shown in memory includes a media player application an application programming interface API audio data error code augmented audio data a format tag and an audio driver . Media player application is a software application capable of causing data to be streamed to processing unit . For example media player application could be a Blu Ray player application that reads data from a Blu Ray disc and streams that data to processing unit . The data could be among others video data or audio data such as audio data or augmented audio data . Audio data could be HDA data or another type of audio data made up of individual samples. As discussed herein audio data has a sample size of M bits per sample.

API is a set of software routines that may be used by media player application to manipulate audio data such as e.g. audio data open audio data streams to processing unit and perform various other tasks related to streaming audio data to processing unit . In one embodiment API is integrated into media player application .

When streaming audio data to processing unit API is configured to first perform an error checking procedure with audio data to produce error code . Error code includes a collection of N bit error code values where each N bit error code value corresponds to a different M bit audio data sample within audio data . Error code could be the results of a cyclic redundancy check CRC a counter value for each sample within audio data or another type of error detection and or correction code that produces an N bit value for each of the M bit samples within audio data . Those skilled in the art will understand that API may implement any technically feasible type of error detection correction code to generate the error code values within error code .

Upon generating error code API combines audio data with error code to produce augmented audio data . More specifically API combines each of the M bit samples within audio data with a corresponding N bit value within error code to produce a collection of M N bit samples. Accordingly M of the bits within a given M N bit sample are derived from an M bit sample within audio data and N of the bits within a given M N bit sample are derived from a corresponding N bit value with error code . In one embodiment API also compresses and or encrypts audio data prior to combining audio data with error code .

Once API generates augmented audio data API selects a format tag that indicates the format of augmented audio data . The format tag could indicate for example that each sample of augmented audio data includes an M bit portion representing a sample of audio data and an N bit portion representing an error code value associated with that sample. In embodiments where API compresses and or encrypts audio data prior to generating augmented audio data API selects a format tag that indicates the compression and or encryption algorithm used to compress and or encrypt audio data .

After augmented audio data has been generated and API has selected format tag API opens an audio data stream to processing unit . In general when API opens audio data streams API may open that stream by interacting with an operating system not shown executing on processing unit and may open a given audio data stream with a particular number of channels a particular sample size and a particular sample rate. For example API could open an audio data stream with anywhere between 2 and 8 channels with 16 or 24 bit samples at an 192 kilohertz kH or 768 kH sampling rate. When augmented audio data includes a collection of M N bit samples as discussed herein API is configured to open an M N bit data stream to processing unit M bits to accommodate the audio data portion and N bits to accommodate the error code portion .

Once API has opened an audio data stream having sufficient bandwidth to stream augmented audio data API passes augmented audio data and format tag to audio driver .

Audio driver is a software application that may be executed by processing unit to allow processing unit to interact with audio hardware included within processing unit . In one embodiment audio driver is derived from device driver shown in . After API has opened an audio data stream to processing unit audio driver receives augmented audio data and format tag from API . Based on format tag audio driver transmits a signal to processing unit that indicates the format of augmented audio data . Audio driver may then stream augmented audio data to processing unit via the opened audio data stream i.e. transmit individual M N bit samples to processing unit .

In alternative embodiments the functionality performed by processing unit as described above may be performed by any other type of hardware unit that is capable of generating augmented audio data using software applications included within memory . The hardware unit performing the functionality of processing unit in this embodiment could be e.g. a hard disk drive a printed circuit board or a video card among other types of hardware devices.

As discussed in greater detail below in conjunction with processing unit is configured to receive augmented audio data decode that data into an audio data component and an error code component and then verify the integrity of the data component based on the error code component.

Decoder and validation unit is a hardware element embedded within processing unit and could be implemented by an application specific integrated circuit ASIC an embedded processor a collection of logic gates or any other type of hardware element. Decoder and validation unit is configured to receive from processing unit a signal that indicates the format of augmented audio data shown in as well as augmented audio data itself. Based on the received signal decoder and validation unit is configured to decode augmented audio data into separate audio and error code components i.e. separate each received sample into an audio sample and an error code value.

As discussed above augmented audio data includes a collection of M N bit samples where each sample includes an M bit audio data sample and an N bit error code value. When decoder and validation unit receives a given M N bit sample decoder and validation unit decodes the received sample into an M bit audio sample and an N bit error code value based on the received signal indicating the format of that M N bit sample. For example when augmented audio data includes 16 8 bit samples then decoder and validation unit could decode a given augmented audio data sample into a 16 bit audio data sample and an 8 bit error code value.

For a given M N bit sample decoder and validation unit is configured to verify that the N bit error code value does not indicate any errors associated with the M bit audio data sample. If decoder and validation unit does not detect any errors within the N bit error code value decoder and validation unit may store audio data in memory and or cause I O devices to output sound derived from the corresponding M bit audio data sample.

Decoder and validation unit may also buffer M bit audio data samples in memory as audio data . Memory could be e.g. memory local to processing unit . When all of the M N bit samples associated with augmented audio data have been received and each M bit audio data sample has been written to audio data audio data may be nearly identical to audio data shown in . In embodiments where the M bit audio data portion of augmented audio data is compressed and or encrypted prior to being incorporated into augmented audio data decoder and validation unit decompresses and or de encrypts each M bit audio data sample prior to causing I O devices to output sound derived from that sample and or storing that sample within audio data .

After decoding a given M N bit sample of augmented audio data if validation unit detects errors within associated N bit error code value then decoder and validation unit may notify processing unit that the augmented audio data being streamed to processing unit includes compromised data and that processing unit should regenerate and resend augmented audio data. In situations where decoder and validation unit identifies NULL values appended to augmented audio data decoder and validation unit may forgo notifying processing unit and simply output sound derived from those NULL values. Additionally decoder and validation unit may also terminate any sound output by I O devices derived from augmented audio data . Through this technique decoder and validation unit is capable of preserving the user s experience by preventing sound derived from compromised audio data from being output to the user.

In one embodiment the functionality of processing unit may be performed by any type of hardware unit that includes decoder and validation unit and is capable of causing I O devices to output sound derived from decoded audio data.

Persons skilled in the art will recognize that the techniques described herein although directed towards audio data and audio data processing are equally applicable to other types of data and data processing. For example API could generate error code values for video data and combine those error code values with the video data to be streamed to processing unit . Then decoder and validation unit could decode and validate the received data before rendering the video data to a display device. Additionally the techniques described herein could also be applied to embedding error code data into additional channels of data or additional samples of data. For example data with a given number of channels could be augmented with error code data embedded within one or more additional channels or data with a given sample rate could be augmented with error code data embedded within extra samples made available by increasing the sample rate of the data.

As shown the method begins at step where API generates an N bit error code for M bit audio data. The N bit error code could be e.g. error code while the M bit audio data could be e.g. audio data . The N bit error code could represent for example the results of a CRC a counter value for each sample within the M bit audio data or another type of error detection and or correction code that produces an N bit value for each of the M bit samples within the M bit audio data. Those skilled in the art will understand that API may implement any technically feasible type of error detection correction code to generate the N bit error code.

At step API generates M N bit augmented audio data by combining the M bit audio data with the N bit error code. More specifically API combines each of the M bit samples within the M bit audio data with a corresponding N bit value within the N bit error code to produce a collection of M N bit samples. In one embodiment API also compresses and or encrypts the M bit audio data prior to combining that data with the N bit error code.

At step API selects a format tag that indicates the format of the M N bit augmented audio data generated at step . The format tag may indicate for example the different values of M and N as well as compression and or encryption information related to the M bit audio data.

At step API opens an M N bit data stream to processing unit . The M N bit data stream is capable of streaming a collection of M N bit samples such as those included in the M N bit augmented audio data to processing unit . In one embodiment API interacts with an OS executing on processing unit to open the M N bit data stream.

At step audio driver receives the M N bit augmented audio data and the selected format tag and transmits a signal to processing unit that indicates the format of the M N bit augmented audio data. At step audio driver causes the M N bit augmented audio data to be transmitted to processing unit via the M N bit data stream opened at step i.e. audio driver transmits individual M N bit samples to processing unit . The method then ends.

As shown the method begins at step where decoder and validation unit within processing unit receives a signal from processing unit audio driver within processing unit indicating the format of M N bit augmented audio data that is to be received by processing unit .

At step decoder and validation unit receives M N bit audio data from processing unit that is associated with an M N bit audio data stream. Decoder and validation unit could for example receive one or more M N bit samples associated with augmented audio data shown in .

At step decoder and validation unit decodes the M N bit augmented audio data into N bit error code values and M bit audio data samples based on the format indicated by the received signal. For example decoder and validation unit could decode a single 24 bit sample into a 16 bit audio data sample and an 8 bit error code value.

At step decoder and validation unit determines whether the N bit error code data indicates that the decoded M bit audio data is valid. If decoder and validation unit determines that the decoded M bit audio data is not valid then the method proceeds to step where decoder and validation unit causes output devices such as I O devices currently outputting sound associated with the M N bit audio data stream to terminate the output of sound derived from that M N bit audio data stream. In one embodiment decoder and validation unit simply causes output devices to output silent audio samples. At step decoder and validation unit notifies media player shown in that the received M bit audio data was compromised. As mentioned above in conjunction with media player application may then regenerate and resend augmented audio data to decoder and validation unit .

At step if decoder and validation unit determines that the decoded M bit audio data is valid then the method proceeds to step where processing unit causes output devices within I O devices to output sound derived from the decoded M bit audio data. The method then ends.

Persons skilled in the art will recognize that the method may be repeated for each M N bit sample of augmented audio data received from processing unit via an M N bit audio data stream. When processing unit streams augmented audio data in the form of individual M N bit samples the method may be implemented to identify errors within a single sample thereby allowing processing unit to terminate the audio data stream before sound derived from that compromised audio data is output to a user.

In sum an application programming interface API executed by a first processing unit combines audio data samples with error code values generated for those samples. The API then causes a data stream to be opened having sufficient bandwidth to accommodate combined samples made up of audio data samples and corresponding error code values. The combined samples are then transmitted to a decoder and validation unit within a second processing unit that receives the combined data strips the error code values and validates the audio data based on the error code values. When the error code values indicate that the audio data has been compromised the second processing unit terminates the audio output i.e. the sound derived from the audio data.

Advantageously when audio hardware receives compromised audio data the audio hardware is capable of determining that the audio data has been compromised and is able to immediately stop outputting sound derived from the compromised audio data. Accordingly the audio hardware preserves the user experience by ensuring that unintelligible or unpleasant sounds caused by compromised audio data are not output to the user.

One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored.

The invention has been described above with reference to specific embodiments. Persons skilled in the art however will understand that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

