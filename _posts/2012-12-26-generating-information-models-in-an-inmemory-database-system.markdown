---

title: Generating information models in an in-memory database system
abstract: Various embodiments of systems and methods for generating information models in an in-memory database system by importing data foundation from existing Semantic layer files are described herein. The method includes specifying a type of information view to be generated to model content data. Further the method includes invoking the content data from existing semantic layer files using an import option of a content data editor interface. Subsequent to selecting one or more semantic layer files, automatically extracting table objects corresponding to the selected semantic layer files along with data foundation objects from a file source.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09519701&OS=09519701&RS=09519701
owner: SAP SE
number: 09519701
owner_city: Walldorf
owner_country: DE
publication_date: 20121226
---
The field relates generally to generating information views to model business data. More specifically the field relates to generating information models in an in memory database system by importing data foundation from existing semantic layer files.

Recent developments in in memory technology have implemented in memory databases in analytic data processing systems in place of the traditional database management systems DBMS . An example of an in memory data processing system is the In memory Appliance HANA from SAP AG. An in memory data processing system may perform both transactional and analytic data processing due to the speed available from storing the data in main memory as opposed to the disk storage of non in memory database systems .

In memory data processing systems enable organizations to analyze their business operations using huge volumes of detailed information while the business is running. In memory computing technology allows the processing of massive quantities of data in main memory to provide immediate results from analysis and transaction. The data to be processed is ideally real time data that is data that is available for processing or analysis immediately after it is created . This enables organizations to instantly explore and analyze all of its transactional and analytical data in real time.

In memory data processing systems may consist of several parts including an in memory database e.g. SAP HANA database and database administration and development tool e.g. SAP HANA studio . In memory databases may have column and row store capabilities which allows high performance processing and analysis of data already on the database and therefore prevents the necessity to transfer data from the database to on application server. Further the in memory database allows for modeling data as tables and views. Tables are tabular data structures each row identifying a particular entity and each column having a unique name. Views are combinations and selections of data from tables modeled to serve a particular purpose.

The database administration and development tool also referred to as database modeler is a graphical data modeling tool which allows you to design analytical models and analytical privileges that govern the access to those models. The information model designing process in the database modeler involves building data foundation for creating information models. The data foundation is a schema that defines the relevant tables and relationships from one or more relational databases.

On the other hand semantic based information design tools e.g. SAP Business Objects information Design Tool involve a data abstraction layer called a semantic layer which is a collection of classes and objects data foundation . Semantic layer based data foundation consists of subject area specific data foundation objects that are large with tables relationships and cardinality. However current users of semantic based information design tools who want to adopt in memory computing technology have to manually re create the entire data foundation of tables and relationships by understanding the existing semantic layer data foundation.

Various embodiments of systems and methods for generating information models in an in memory database system by importing data foundation from existing semantic layer files are described herein. In an embodiment the method includes defining a space in a repository of the system to store the generated information models. The defined space is created as a node also referred to as a package on the modeler view of the database modeler main window. In an aspect a type of information view to be generated to model content data is specified by navigating a context menu of the defined package. In another aspect the content data that is to be modeled according to the selected type of information view is invoked using an import option in a content data editor interface. Selecting the import option launches a file explorer to invoke semantic layer files stored in a file source. In yet another aspect selecting one or more of the invoked semantic layer files automatically extracts table objects corresponding to the selected semantic layer files which are then populated on a modeler canvas of the modeler main window. Further the relationships and connections between the extracted table columns are automatically identified from the file source and populated into the content data editor. Also the cardinality between the table columns are automatically read from the file source and populated into the content data editor. In yet another aspect the selected view is activated from the context menu of the defined package.

A computer system may operate to implement the method described above. The computer system may store execute or be otherwise controlled by one or more computer programs that control the computer system to implement the method described above.

A non transitory computer readable medium may store instructions to control a computer system to perform the method described above. The instructions may include an in memory database component a processing component and an output component.

The following detailed description and accompanying drawings provide a better understanding of the nature and advantages of the present disclosure.

Embodiments of techniques for generating information models in an in memory database system by importing data foundation from existing semantic layer files are described herein. In the following description numerous specific details are set forth to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize however that the embodiments can be practiced without one or more of the specific details or with other methods components materials etc. In other instances well known structures materials or operations are not shown or described in detail.

Reference throughout this specification to one embodiment this embodiment and similar phrases means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the one or more embodiments. Thus the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more embodiments.

An in memory database is a relational database whose tables can be stored in memory. This particular storage method is completely transparent for the designer who will see the usual logical representation of tables as rows and columns of data. As a normal relational database the in memory database has the concepts of tables joins keys and SQL views. The in memory database can be accessed via ODBC and JDBC drivers and its tables can be defined and queried with SQL language.

Some of the components and administration tools of in memory data processing system include an In Memory Computing Engine IMCE Server and a suite of tools for modeling which includes an information modeler. The database administration and development tool is an eclipse based interface that provides in memory computing engine administrators with easy to use data management tools and business centric data modeling tools information modeler . The information modeler allows technical users to create new or modify existing models of data. Tables are managed by the database administration and development tool to build business or calculation models on the tables. For example SAP s HANA Studio is a tool for developers who wish to create data models and stored procedures or manipulate tables and issue queries interactively. These models are called Information models and they are also interchangeably referred to as Information views column views in memory database views in memory database models or in memory database cubes. These models can provide a dimensional representation of the data and in some circumstances can be compared to OLAP cubes.

Information views are created to model various slices of data stored in an in memory database. Information views used various combinations of content data that is non metadata to model a business use case. Content data can be classified as Attributes and Measures. An Attribute represents descriptive data such as customer ID city country and the like. Attributes are individual non measurable analytical elements. Whereas a Measure represents the quantifiable data such as revenue quantity sold counters and the like. Measures are simple measurable analytical elements. Measures are derived from analytic and calculation views. Information views are often used for analytical use cases such as operational data mart scenarios or multidimensional reporting on revenue profitability etc. There are at least three types of information views namely Attribute view Analytic view and Calculation view. All three types of information views are non materialized views.

Attribute view An attribute view is used to model an entity based on the relationships between attribute data contained in multiple source tables. Attribute view describes the dimensions of a data model and can be hierarchical e.g. the Customer dimension the Geography dimension dimensions might have zero to many associated hierarchies . For example customer ID is the attribute data that describes measures that is who purchased a product . However customer ID has mach more depth to it when joined with other attribute data that further describes the customer customer address customer relationship customer status customer hierarchy and so on . An attribute view can be created to locate the attribute data and to define the relationships between the various tables to model how customer attribute data for example will be used to address business needs. Attribute views can later be joined to tables that contain measures within the definition of an analytic view or calculation view to create virtual star schema on the in memory database data.

Analytic view An Analytic view is used to model data that includes measures. An Analytic view describes the facts related to some dimensions. Those facts come from a single fact table e.g. the Actual revenue and cost . For example an operational data mart representing sales order history would include measures for quantity price and the like. The data foundation of an analytic view can contain multiple tables. However measures that are selected for inclusion in an analytic view must originate from one of these tables. Analytic views can be simply a combination of tables that contain both attribute data and measure data.

Calculation view A calculation view is used to define more advanced slices on the data in in memory database. Calculation view renders complex models that can combine multiple analytic views i.e. to create a multi fact cube or that can be defined programmatically using the SQL script language. Calculation views are typically used when the business use case requires advanced logic that is not covered in the previous types of information views. For example calculation views can have layers of calculation logic can include measures sourced from multiple source tables can include advanced SQL logic and so on. The data foundation of the calculation view can include any combination of tables column views attribute views and analytic views.

Typically the various information views are modeled in the information modeler tool following the steps as shown with reference to . As shown in the steps of the modeling process include 1 importing the table definitions i.e. source system metadata into the modeler perspective 2 after the table definitions are imported the physical tables are loaded with content data 3 further information models are created based on the content data in the tables 4 the created views are deployed by creating and activating the information views and 5 the created information views are consumed using client tools such as SAP s Business Intelligence Consumer Services BICS and Multi Dimensional eXpressions MDX .

In more detail the prerequisites for performing the modeling process include installing the information modeler tool on a workstation computer obtaining user credentials and obtaining access to the in memory appliance running on a host named e.g. tool.mynetwork.com from the workstation via TCP IP. Once the prerequisites are fulfilled the mode of operation known as perspective is selected from the upper right corner of the modeler window which is the graphical user interface of the information modeler tool. The two main perspectives offered by information modeler tool are Information Modeler Perspective and the Administration Console Perspective.

As an initial step the perspective is switched to Information Modeler perspective. The Information Modeler perspective offers features to create and edit data models and stored procedures that can be used by analytics application such as Business Objects Explorer analytics application and certified products which support MDX SQL or BICS. The artifacts created by the Modeler are stored directly in the in memory database tables as XML documents design time objects . Once in the modeler perspective a system node is added wherein to create content objects for analytical purposes according to the following procedure 

As shown in a newly added system node JOS System is added to the Navigator pane . The expanded system node shows two sub nodes Catalog and Content under the Navigator view. The Catalog sub node represents information modeler tool s data dictionary i.e. all data structures tables and data which can be used. The sub node Content represents the design time repository which holds all models crated within the Information Modeler.

Subsequently table definitions source system metadata are imported from a specified source system location. These table definitions are used for creating various content models such as attribute analytic and calculation views. Based on the requirement the table definitions can be imported in mass i.e. all table definitions are imported from a source system or selectively i.e. importing only selected table definitions from a source system.

Once the table definitions are imported the process involves loading data into the table definitions from a source such as a source ERP system according to the following procedure 

Once the data is loaded into the table definitions the tables appear in a schema node System of the catalog sub node . All the tables that were imported will be listed under the Tables node. However it should be noted that the tables appear in the schema even as early as when the table definitions are imported for further processing.

After loading data into the table definitions the process involves creating the appropriate informational views that are required to create and deploy the content. In addition to creating the information views additional objects such as packages for organizing content procedures for SQL routines that need to be called repeatedly and analytic privileges for applying restrictions on which data users can see as appropriate can be created.

In an example an analytic view is generated to define a multidimensional view e.g. OLAP cube based on database tables attribute views and facts of a specific table. The analytic view is generated according to the following procedure as shown in 

As shown in when a new analytic view is set to be created using one of the sub steps in Table 1 a modeler canvas labeled with the specified name package appears in the main window of the modeler. The canvas is initially empty until the tables to be used in modeling the analytic view are defined. In order to add tables in the Navigator view the required table is identified under Catalog SYSTEM Tables and dragged and dropped onto the empty modeler canvas. The modeler canvas then displays a tabular structure having the table s name and all of its attributes and columns in the data foundation view of the canvas. The logical view tab at this stage is empty since none of the attributes in the table are defined. The table attributes can be selectively defined in the data foundation view tab as attributes key attributes or measures in order to view only those attributes of interest in the generated attribute view.

Once the attributes and measures in the table are defined the correspondence of attributes and measures appear in the logical view tab on the canvas . Also the attributes and measures defined in the data foundation tab correspondingly create a new node in the output table under the defined type of attributes and measures.

Similarly an Attribute view is created to model descriptive attribute data that does not contain measures using attributes according to the following procedure 

Once a new attribute view is set to be created using one of the sub steps in Table 2 in the main view a modeler canvas labeled with the specified name package appears. The canvas is initially empty until the tables to be used in modeling the attribute view are defined. In order to add tables in the Navigator view the required table is identified under Catalog SYSTEM Tables and dragged and dropped onto the empty modeler canvas. The modeler canvas then displays a rectangular box having the table s name and all of its attributes and columns under the tab data foundation. The logical view tab at this stage is empty since none of the attributes in the table are defined. The table attributes can be selectively defined from the data foundation tab as view attributes key attributes or measures in order to view only those attributes of interest in the generated attribute view.

Once the attributes and measures in the table are defined the correspondence of attributes selected and defined appears in the logical view tab on the canvas. The logical view can be thought of as a black box view of the model being generated. Also the attributes and measures defined in the data foundation tab correspondingly create a new node in the output table under the defined type of attributes and measures. The created model attribute view is then saved by choosing File Save from the top pull down menu or through Ctrl S command. The new attribute view appears in the Navigator view as a node in the created package. An icon marked with a gray diamond indicates that the model has been saved in the repository but has not been activated yet i.e. no run time object in Schema SYS BIC has been created. The analytic view can be activated by right clicking on Navigator node for the created attribute view and selecting an Activate option. The gray diamond will disappear to signal a successful activation.

Similarly one or more attribute views and analytic views can be generated. The different views can then be joined into a star schema with the attribute view as one arm of the star and the data foundation table used for creating the analytic view as its center. The data preview option can be invoked on the analytic view to see that the attribute view has been linked into the attributes of the data foundation table used for creating the analytic view.

According to an embodiment of the inventive concept the information model generation process involves importing data foundation from Semantic layer files e.g. Universe files into in memory information modeler tool e.g. SAP HANA Studio in order to build information models.

The semantic based information design tool e.g. SAP Business Objects Information Design Tool is a metadata design environment that enables a designer to extract define and manipulate metadata from relational and OLAP sources to create and deploy semantic layers e.g. SAP BusinessObjects Universes . A semantic layer is an organized collection of metadata objects that enable business users to analyze and report on corporate data in a non technical language. These metadata objects include dimensions measures hierarchies attributes pre defined calculations functions and queries. The metadata object layer called the business layer is built on a relational database schema or an OLAP cube so the objects map directly to the database structures via SQL or MDX expressions. A semantic layer includes connections identifying the data sources so queries can be run on the data.

The role of the semantic layer is to provide the business user with semantically understandable business objects. The user is free to analyze data and create reports using relevant business language regardless of the underlying data sources and structures.

To enable the designer to create semantic layers the information design tool provides the resources necessary to do the following 

A data foundation in the semantic layer is a schema that defines the relevant tables and joins from one or more relational database objects. The data foundation can be enhanced by adding derived tables alias tables calculated columns additional joins contexts prompts lists of values and other SQL definitions. The data foundation becomes the basis of one or more business layers. Data foundations are stored in the local project as .dfx files.

The process of importing semantic layer data foundation into in memory information modeler tool is described with reference to . shows an exemplary flow of the process of generating information models in an in memory database system. The method implemented by a computer or any other electronic device having processing capabilities includes at least the following process illustrated with reference to process blocks . The model generation process is initiated by switching the perspective to the Information Modeler perspective using options provided in the graphical data modeling tool of the in memory database system. The Information Modeler perspective offers features to create and edit data models and stored procedures. In the modeler perspective the process at block involves selecting a type of information view by which content data is to be modeled. The term content data as used herein refers to non metadata data that is characterized descriptively or quantitatively. At process block the content data for generating the information model according to the selected type of information view is obtained by invoking semantic layer files. In an aspect the semantic layer files are created in an existing semantic based information model. The semantic layer files are invoked using an import option of a content data editor interface. The content data editor interface is received in response to providing a selection for the type of information view.

At process block the process involves selecting one or more of the invoked semantic layer files that contain content data required to be modeled. At process block the table objects corresponding to the selected one or more semantic layer files are extracted and populated on a modeler canvas of the modeling tool. The extracted table objects also include information relating to the connections and relationships between the tables and the cardinality between the columns of the tables. Further the one or more columns of the extracted table objects are defined as attributes and measures. In an aspect only those columns of the table objects which are required to be modeled are defined as attributes or columns. The generated view is then saved and activated. Saving the table objects triggers a validation check.

In more detail the process of generating information models in an in memory database system is described with reference to . The method implemented by a computer or any other electronic device having processing capabilities includes at least the following process illustrated with reference to process blocks . The information model generation process involves defining a space in a repository of the system wherein to store the generated information models. The defined space is created as a node also referred to as a package on the modeler view of the information modeler tool s main window. At process block in response to receiving a selection of a type of information view a user interface a dialogue window is rendered on the modeler main window to receive an input specifying a source of table objects for building content data for modeling the selected information view. At process block upon determining that an Import option is selected from the dialogue window a file explorer is launched for identifying and invoking semantic layer files. In an aspect the semantic layer files are identified as files having .unv or .unx file extensions.

At process block in response to receiving a selection of one or more of the identified semantic layer files automatically extracting and rendering table objects corresponding to the selected semantic layer files on the modeler canvas of the modeler main window at process block . The extracted table objects also include relationships and connections between table columns and cardinality between the table columns. Further at process block the selected information view is activated after receiving an input to activate the selected information view. However in order to activate an information view by saving the information model in the repository.

The imported semantic layer data foundation can be saved which in turn triggers a validation on the Table existence. At the end of validation the user may be provided with an option to either accept the creation of missing objects that are part of the data foundation using the information available on the file source and the data foundation metadata or proceed to save the data foundation anyways without creating the missing parts. However the downside of ignoring the tool s suggestion to create the missing objects during validation is that the information model cannot be activated although the tools allows for the model to be built.

In an aspect user can build the required information model by either removing unwanted data foundation objects or can keep the data foundation as it is and only define the required columns as attributes and measures to complete the required information model. User will be allowed to reuse the file source for building multiple information models in which user has to follow the above described steps each time.

The information model generation process in the in memory modeler is described in more detail with reference to . In an embodiment the information view generation process is similar to the process described with reference to up until the step of initiating the information view creation process. Referring to the example used with reference to the attribute view is set to be created according to the procedure 

Computer system may be coupled via bus to a display such as a cathode ray tube CRT or liquid crystal display LCD for displaying information to a computer user. An input device such as a keyboard and or mouse is coupled to bus for communicating information and command selections from the user to processor . The combination of these components allows the user to communicate with the system. In some systems bus may be divided into multiple specialized buses.

Computer system also includes a network interface coupled with bus . Network interface may provide two way data communication between computer system and the local network . The network interface may be a digital subscriber line DSL or a modem to provide data communication connection over a telephone line for example. Another example of the network interface is a local area network LAN card to provide a data communication connection to a compatible LAN. Wireless links is also another example. In any such implementation network interface sends and receives electrical electromagnetic or optical signals that carry digital data streams representing various types of information.

Computer system can send and receive information including messages or other interface actions through the network interface to an Intranet or the Internet . In the Internet example software components or services may reside on multiple different computer systems or servers and across the network. A server may transmit actions or messages from one component through Internet local network and network interface to a component on computer system .

The computer system and network may be configured in a client server manner. For example the computer system may implement a server. The client may include components similar to those of the computer system .

More specifically as described above the computer system may implement an in memory database system. The computer system may implement the information model generation process described above. Alternatively the server may implement the information model generation process and may present the generated information models to the computer system which case the server may be considered a component of the in memory database system. The server may implement the BW system.

Some embodiments may include the above described methods being written as one or more software components. These components and the functionality associated with each may be used by client server distributed or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as functional declarative procedural object oriented lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively the components maybe implemented in server and client applications. Further these components may be linked together via various distributed programming protocols. Some example embodiments may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level e.g. a graphical user interface . These first and second computer systems can be configured in a server client peer to peer or some other configuration. The clients can vary in complexity from mobile and handheld devices to thin clients and on to thick clients or even other servers.

The above illustrated software components are tangibly stored on a computer readable storage medium as instructions. The term computer readable storage medium should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term computer readable storage medium should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store encode or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described represented or illustrated herein. Examples of computer readable storage media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROMs DVDs and holographic devices magneto optical media and hardware devices that are specially configured to store and execute such as application specific integrated circuits ASICs programmable logic devices PLDs and ROM and RAM devices. Examples of computer readable instructions include machine code such as produced by a compiler and files containing higher level code that are executed by a computer using an interpreter. For example an embodiment may be implemented using Java C or other object oriented programming language and development tools. Another embodiment may be implemented in hard wired circuitry in place of or in combination with machine readable software instructions.

A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases such as relational transactional hierarchical multi dimensional e.g. OLAP object oriented databases and the like. Further data sources include tabular data e.g. spreadsheets delimited text files data tagged with a markup language e.g. XML data transactional data unstructured data e.g. text files screen scrapings hierarchical data e.g. data in a file system XML data files a plurality of reports and any other data source accessible through an established protocol such as Open DataBase Connectivity ODBC produced by an underlying software system e.g. ERP system and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams broadcast data and the like. These data sources can include associated data foundations semantic layers management systems security systems and so on.

In the above description numerous specific details are set forth to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize however that the embodiments can be practiced without one or more of the specific details or with other methods components techniques etc. In other instances well known operations or structures are not shown or described in detail.

Although the processes illustrated and described herein include series of steps it will be appreciated that the different embodiments are not limited by the illustrated ordering of steps as some steps may occur in different orders some concurrently with other steps apart from that shown and described herein. In addition not all illustrated steps may be required to implement a methodology in accordance with the one or more embodiments. Moreover it will be appreciated that the processes may be implemented in association with the apparatus and systems illustrated and described herein as well as in association with other systems not illustrated.

The above descriptions and illustrations of embodiments including what is described in the Abstract is not intended to be exhaustive or to limit the one or more embodiments to the precise forms disclosed. While specific embodiments of and examples for the one or more embodiments are described herein for illustrative purposes various equivalent modifications are possible within the scope as those skilled in the relevant art will recognize. These modifications can be made in light of the above detailed description. Rather the scope is to be determined by the following claims which are to be interpreted in accordance with established doctrines of claim construction.

