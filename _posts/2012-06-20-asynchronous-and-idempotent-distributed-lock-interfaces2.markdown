---

title: Asynchronous and idempotent distributed lock interfaces
abstract: Methods and apparatus for distributed locking interfaces are disclosed. A state manager implements programmatic interfaces for distributed locking operations. In response to a queue-for-lock request for a registry element received via an interface, the state manager provides to the requester, a reference to a first asynchronous computation. The first asynchronous computation comprises an insertion of a lock request into a queue of waiters for a lock on the element. In response to a request for a result of the computation, the state manager transmits, after the lock request has been inserted into the queue of waiters, a notification of the insertion of the request. The notification in turn includes a reference to a second asynchronous computation. The second asynchronous computation comprises a grant of the lock on the particular element to the requester.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09578130&OS=09578130&RS=09578130
owner: Amazon Technologies, Inc.
number: 09578130
owner_city: Reno
owner_country: US
publication_date: 20120620
---
Implementing computing systems that manage large quantities of data and or service large numbers of users often presents problems of scale. For example as demand for various types of computing services grows it may become difficult to service that demand without increasing the available computing resources accordingly. To facilitate scaling in order to meet demand a particular computing service might be implemented as a distributed application that executes on a number of instances of computing hardware. For example a number of different software processes executing on different computer systems may operate cooperatively to implement the computing service. When more service capacity is needed additional hardware or software resources may be deployed.

However implementing distributed applications may present its own set of challenges. For example in a geographically distributed system it is possible that different segments of the system might become communicatively isolated from one another e.g. due to a failure of network communications between sites. As a consequence the isolated segments may not be able to coordinate with one another. If care is not taken in such circumstances inconsistent system behavior might result e.g. if the isolated segments both attempt to modify data that they would ordinarily coordinate access to .

More generally the larger the distributed system the more difficult it may be to coordinate the actions of various actors within the system e.g. owing to the difficulty of ensuring that many different actors that are potentially widely distributed have a consistent view of system state . Depending on the granularity at which state information is shared among different components of distributed systems the networking and computation overheads associated with sharing state information using traditional techniques such as polling may potentially grow to unsustainable levels. Problems may also arise in distributed systems as a result of the way remotely executed tasks may get re ordered e.g. one component of a distributed application may submit respective requests for a set of operations in a certain order but the requests may not be handled by a remote server in the same order.

While embodiments are described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that embodiments are not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the claims. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to.

Various embodiments of methods and apparatus for supporting application state management in a distributed system are described including for example techniques for asynchronous and idempotent locking of state information establishing reliable and efficient watch mechanisms for state change notification and versioned read only snapshots of shared state. Distributed software applications may comprise multiple concurrent and often autonomous processes communicating with one another and or with shared resources across one or more networks. For example a distributed computing application or a distributed storage service may include multiple concurrent processes. Various ones of these processes may be executing on different physical and or logical e.g. virtual resources or platforms at any given time and the number of resources involved in the application or service may change over time. In a distributed storage service for example processes e.g. software servers on different machines may each expose a programmatic interface to clients which the clients may use to access a single virtual file system that may be implemented across multiple storage resources.

In order for the concurrent processes of a distributed application to cooperate successfully it may sometimes be necessary for one or more of the processes to gain exclusive access to a given shared resource for a given period of execution. The shared resource may include for example administrative or data state information of the distributed application. In one example scenario a distributed application may store group membership records in a shared repository such as a respective record for each currently running worker node of the application. If one or more worker nodes fail or lose communication with the other nodes corrective action may need to be taken such as adding replacement worker nodes and or initiating repair of the failed nodes . Initiating the corrective actions may itself be a distributed function e.g. any of a number of monitoring nodes or processes may be able to initiate the corrective actions. In order to perform the corrective actions effectively e.g. to avoid duplicating corrective actions a consistent view of the group membership records may be required for the monitoring nodes. In addition to administrative information application data for distributed applications may also require consistency mechanisms. For example a given process may require exclusive read and or write access to a shared file database database entry variable and or various other shared data in order to perform a series of accesses to the shared data atomically with respect to the other concurrent processes of the distributed application.

To facilitate consistent sharing of administrative and or data state among the multiple concurrent processes of a distributed application the distributed application may employ the services of a state manager SM . A state manager may implement a repository or registry in which various types of state information of the distributed application may be stored. Each of the constituent processes of the distributed application may be deemed a client process of the state manager in some embodiments. The term client may be used synonymously with the term client process herein. Each client process may interact with the state manager to update various elements of the state information and to coordinate access to state information shared with other constituent processes. In some embodiments the state manager may support a number of different types of locking operations allowing client processes to request locks on desired elements of state information and ensure that each lock is held by at most one client process of the distributed application at any given time. For example the registry may be used to store indications of each lock and the identity of a process if any that is currently holding the lock. In various embodiments the registry may also contain other types of elements such as lockable data entries i.e. software objects containing data values representing shared state information and or session objects representing currently active interactions between the client processes and the state manager. A session object may be used for example to track the most recent time a communication was received from a particular client process and may thus serve as an indicator of the health state of the client process. In some embodiments locks may be advisory in that the state manager may not actually attempt to enforce locks. Instead the state manager may rely upon client processes to cooperate with one another and to respect lock semantics. To perform various access operations e.g. reads writes to shared resources such as data entries and or session elements of the registry a client process may first acquire the shared resource s respective lock in some embodiments.

In different embodiments the client processes of a distributed application may adhere to various locking protocols. For example in some embodiments processes not holding a given lock may only access resources associated with that lock in a read only manner while in other embodiments a process may be forbidden from accessing shared resources at all unless the process holds the lock associated with that shared resource. In various embodiments the state manager may be configured to dispense read locks write locks read write locks and or various other types of locks to facilitate various locking protocols.

In some embodiments at least a portion of a state manager may itself be implemented as multiple processes or nodes executing across multiple systems as a distributed state manager application. Such a state manager may be referred to herein as a distributed state manager DSM . A DSM may provide various benefits over a non distributed state manager such as higher availability and or throughput. For example a DSM implemented on a cluster of computers may allow a client process to interact with any of a plurality of the computers in order to acquire and or release locks. Thus the DSM may be more resilient in case of a hardware and or software malfunction. Additionally a DSM may facilitate higher throughput of lock acquisition release operations by utilizing collective resources from multiple machines. In addition to locking related functions a DSM may also provide a number of other types of functions in some embodiments such as for example monitoring client application nodes state information cache enablement data transfers or replication and the like. A state manager that is used mainly or exclusively for its locking functionality may be referred to as a lock manager and a DSM that is used mainly or exclusively for its locking functionality may be referred to as a distributed lock manager or DLM. A number of different types of computing devices may be used singly or in combination to implement the nodes of a DSM in different embodiments including general purpose or special purpose computer servers storage devices networking devices and the like. The repository in which state information is stored may be implemented using a number of different techniques in various embodiments including for example as a logical or virtual object managed collectively by the nodes of the DSM in some embodiments as described below in further detail.

In at least some embodiments client processes may interact with the nodes of a DSM using client side library components of the DSM e.g. libraries that may be installable on computing devices where the client processes run and that expose state management application programming interfaces or APIs supported by the DSM. In such embodiments the nodes of the DSM to which communication from the client processes may be enabled via the client side library components may be referred to as server nodes of the DSM. A DSM may thus comprise server side nodes as well as client side library components in some embodiments. The server nodes of a DSM may use various protocols such as consensus based protocols in which a plurality of server nodes collectively make decisions to ensure that updates to state information from various client processes are managed appropriately as also described below in further detail.

According to at least one embodiment a DSM may implement a set of programmatic interfaces such as application programming interfaces APIs defining various types of asynchronous locking operations accessible to the client processes. One of the interfaces in such an embodiment may allow a client process that wishes to acquire a lock on a registry element to submit one of at least two different types of requests to the DSM a queue for lock QFL request or a lock request. The queue for lock request may differ from the lock request in the number and manner of asynchronous notifications to the submitting client process in such an embodiment. In the case where a QFL request specifies a target registry element that is currently locked by some other client the QFL submitter may be provided two distinct asynchronous notifications by the DSM a first notification when and if a lock request on behalf of the submitter client process is successfully inserted in a queue of waiters for the lock on the target registry element and a second notification when and if the submitting client is granted the lock. In at least some embodiments each of the notifications may be provided after a consensus based decision is reached by the server nodes e.g. after a first decision as to whether to queue a lock request the first notification may be provided and after a second decision to grant the lock the second notification may be provided. In the case of a straightforward lock request in contrast the submitter may only be notified when the lock is granted and not when the lock request is queued . The two step notification may be especially helpful for client processes that wish to ensure that lock cancellation or release requests are handled correctly and safely. For example because of the distributed nature of the system it may be in general possible for a lock cancellation request to be processed by the DSM before the corresponding lock request is actually queued or granted in such a case the DSM may simply ignore the cancellation release request as it may determine that there is nothing to cancel or release. If the DSM ignores a release request and then later processes the lock request that the client process intended to cancel the client process may proceed to do some operations assuming that it does not have the requested lock when it actually has been granted the lock. This may lead to various problems such as potential deadlock situations between different client processes. Being notified of the fact that its lock request was successfully queued using the first notification received in response to a QFL request may allow the client process to determine that it is now safe to submit a cancellation release request should the client process wish to submit such a request.

In at least some embodiments a number of variations on the asynchronous locking operations such as queue for lock may be implemented. For example in some implementations if a client process already has a lock or is already queued for a lock and submits another lock or QFL request for the same registry element the DSM may normally return an error indication e.g. by throwing an exception. In some embodiments the DSM may support idempotent versions of the lock and or queue for lock operations which simply ignore such additional or duplicate lock requests without providing error indications. In such embodiments the client process code may be simplified by eliminating the need to respond to these kinds of error indications. In another variant the DSM may support maximum queue lengths for specified locks e.g. if a lock request or a QFL request specifying a desired maximum queue depth is received for a registry element for which no lock object currently exists the DSM may create a lock object with the specified maximum queue depth in one embodiment. In such an embodiment if a lock request is received later for the registry element and the queue for the lock is full i.e. the number of waiters equals the maximum queue depth the lock request may be rejected by the DSM. Limiting lock queue depth in this fashion may be helpful in ensuring for example that client processes do not have to wait for excessive periods when locks are heavily contended which may be useful for some types of applications. Further details regarding the different types of lock and QFL requests that may be supported in different embodiments are provided below.

For some types of distributed applications it may be useful for the constituent processes of the applications to keep track of updates to portions of the application state information maintained in the registry. For example for a distributed storage service the registry may include mappings between storage object names and the storage devices on which the objects data is located and the mappings may change as data is modified by users of the distributed storage service as storage devices fill up or are reorganized over time. In order to retrieve data from or store data to the right storage device a client process implementing a portion of the distributed storage service may need the most recent set of mappings. A number of different approaches may be taken to keep the client processes up to date regarding registry updates. In some cases the client processes may be responsible for polling the DSM to retrieve the latest version of the registry contents. However polling based approaches may not be very efficient either computationally or in terms of the network traffic that may be generated. Accordingly in some embodiments the DSM may support a transactional watch mechanism allowing client processes to indicate registry elements of interest and receive notifications when any of the elements are changed.

In at least one such embodiment a client process may submit a watch establishment request WER to the DSM comprising a specification of one or more target elements of the registry for which update notifications are to be provided and an indication of a notification destination such as a queue created by the client process or an executable notification handler set up by the client process . In response to the WER the DSM may determine based at least in part on a registry logical timestamp indicative of changes of the registry a watch establishment timestamp value to be associated with the WER. In addition the DSM may initiate a sequence of update notifications to the notification destination corresponding to each update to the one or more target elements completed after the value of the registry logical timestamp reaches the watch establishment timestamp value wherein a the order in which the update notifications of the sequence are provided to the notification destination matches the order in which the corresponding updates are applied to the one or more target elements b the sequence includes exactly one update notification for a given update to the one or more target elements and c the sequence excludes update notifications for elements of the registry other than the one or more target elements. The watch mechanism in such an embodiment may support at least four invariants even in the presence of DSM node failures or network partitioning validity i.e. no updates are lost and the client process is provided notifications of all committed updates monotonicity i.e. notifications for all updates are provided and processed in order uniqueness i.e. no update results in a duplicate notification and selectivity i.e. notifications for only the elements specified by the client process in the WER are provided.

The DSM may also provide support for client side versioned read only snapshots or caches of designated registry elements in some embodiments. In one such embodiment the DSM may implement a number of caching related APIs defining operations to access a read only cache of registry entries to be maintained on behalf of client processes. In response to a cache setup request from a particular client process e.g. via an API call the DSM may designate one or more elements of the registry as a cache data set and provide a reference to an asynchronously updated cache object comprising contents of the cache data set to the client process. The client process may be provided read only access to the cache object in some embodiments i.e. the client process may read registry elements from the cache but may not write directly to the cache object instead any updates that the client wishes to make to the registry elements may be transmitted to the DSM and the cache may be updated when and if the DSM commits the requested write. After the client process is provided the asynchronously updated cache object the DSM may initiate a sequence of asynchronous update notifications to the particular client process wherein each asynchronous update notification includes a updated contents of one or more elements of the cache data set and b a cache version identifier based at least in part on a registry logical timestamp value indicative of a time at which the element was updated. Thus once a cache is set up the client process may be able to read registry contents from a consistent automatically and efficiently updated cache without having to for example establish any additional connections to the DSM server nodes. In some embodiments the DSM may utilize the transactional watch mechanism described above to implement the read only cache. In at least some embodiments the registry may only support a limited set of object types and as part of the cache functionality the DSM may convert the registry objects to a data type specified by the client. A number of additional programmatic interfaces e.g. various API methods may be implemented for both the transactional watch mechanism and the versioned cache functionality. Further details regarding such interfaces and about the watch and cache mechanisms in general are provided below.

According to the illustrated embodiment a client process may communicate with DSM server cluster to for example submit asynchronous locking requests of various types to establish and use transactional watch mechanisms or to set up and receive notifications for versioned read only caches as described below in further detail. In some embodiments each node of the DSM server cluster may be implemented using a different physical and or virtual machine. In other embodiments two or more of nodes may be different software instances or processes executing on the same physical or virtual machine. The set of server nodes may be referred to as a collective in some embodiments.

A given client process may communicate with the collective via one of the nodes in the depicted embodiment. Different client processes may communicate with different nodes in some embodiments. The particular node chosen by a client process may depend on the identity of the client the type of request and or other factors. In some embodiments a client process may maintain affinity to a given node once communication and or another relationship has been established. It may also be possible for a client process that has established affinity with a first node of the DSM collective to switch to another node at any time. This may be done arbitrarily in response to a node failure in response to the node becoming overloaded in response to a scheduler component indicating that the client should switch to another node and or in response to various other events. As shown in the illustrated embodiment the various nodes may communicate with one another via network connections . These network connections may be implemented using various types of networks e.g. Myrinet Ethernet Gigabit Ethernet etc. in various topologies e.g. ring grid Torus bus etc. .

For simplicity of explanation many of the embodiments described herein comprise a DSM implemented on a fully connected cluster of computers where each node is a different physical machine in the cluster executes a separate instance of the DSM node software and can communicate directly with every other node in the collective via a network connection. However those skilled in the art will appreciate that various other configurations are possible using different physical and or virtual machines connected by different network types and or topologies as described above.

According to nodes of the collective may work together to maintain a shared state e.g. for various client applications in a logical registry . The logical registry may not necessarily be implemented as a separate physical entity but rather as a logical entity that may be implemented across multiple nodes of the DSM. For example in the depicted embodiment each node may keep a respective local copy e.g. local copy A for node A local copy B for node B and so on of the logical registry . Through a consensus protocol the nodes may agree on state transitions for each node to apply to its local registry copy thereby collectively maintaining a single logical registry . Each node may thus maintain a cached copy of the registry that is valid as of the last registry transition i.e. update known at the node. In some embodiments each transition may be associated with a registry logical timestamp such as in a monotonically increasing 64 bit integer or counter agreed upon by the collective . This timestamp may be a physical or logical time in different embodiments and may be referred to as the DSM time herein. In embodiments where the DSM time is maintained as a counter it may be incremented each time the registry is updated in some implementations e.g. each change to the logical registry may result in a change to the DSM time and each change in the DSM time may indicate that at least one element of the registry was updated. Each node may maintain its own registry logical timestamp e.g. logical timestamp A for node A logical timestamp B for node B and so on indicative of the most recent transition of the logical registry that is reflected in the local registry copy at that node. At any point in time in some implementations the value of the local logical registry timestamp at a given node may differ from the value of the local logical registry timestamp of another node however if and when two nodes have the same local logical registry timestamp values the data in their respective local registry copies may be identical i.e. both local copies of the registry may be guaranteed to have applied the same set of updates . In at least some implementations each node may also maintain an independent system clock separate from the registry logical timestamps.

Logical registry may include information that may be accessed in a consistent manner by a plurality of the nodes . In some embodiments the logical registry may include several types of elements and associated metadata such as lock objects data entries session objects representing connections to client processes and the like. Some or all of the registry elements may be used to represent application state of the distributed client applications . In some embodiments the DSM may maintain multiple logical registries. In such embodiments each logical registry may be identified by a unique name. Different logical registries may be used to store data relevant to a corresponding client application or set of client applications in some embodiments. For example different distributed applications may use respective logical registries separate from one another. In other embodiments a single logical registry may include elements representing state information of a plurality of client applications. In some embodiments each of the elements of a given registry such as locks data entries and or sessions may be identified by a respective pathname e.g. registry1 companyA departmentB objectC within a namespace e.g. each element may be identified via a string concatenated from substrings where each substring represents a respective hierarchical component named using a directory like naming convention starting with a root substring e.g. registry1 in the case of the element with the identifier registry1 companyA departmentB objectC .

Each lock managed using the logical registry may be identified by a respective path in the registry namespace. The logical registry may also include various data entries each also identified with a respective path. Data entries may comprise information stored to the logical registry by client processes such as information to be shared with other client processes. For example when creating a lock a client process may wish to write some metadata describing the lock into a data entry. In some embodiments such entries may include a name value creation time and or a modification time. The time related information stored in the registry such as creation time or modification time may be expressed using DSM time in some embodiments and or using system clock time in other embodiments. In some embodiments a logical registry may also list named client processes and or client sessions e.g. representations of connections between client processes and the server cluster recognized by the DSM. Such listings may also include configuration parameters for those client processes and or sessions. For example in some embodiments a named client process may be alternatively listed as either registered revoked or forgotten.

The DSM server cluster may act as a mediator between the client processes and one or more logical registries . The client process may interact with a logical registry by submitting transactions to the DSM server cluster which may interact with the logical registry on behalf of the client process. Through a read transaction a client process may read information such as locks entries or sessions from the logical registry . Using a write transaction a client process may update information in the logical registry . In some embodiments the DSM server cluster may also execute checks or check operations on behalf of a client process. In a check operation the DSM server cluster may determine whether the context of a transaction that includes the check operation is what the client process expected. For example optimistic writes may be implemented by checking that an entry has not been modified since a specified DSM time.

Each transaction may have different possible outcomes. In some embodiments these outcomes may correspond to success write success read abort and fail. A success write outcome may indicate that a transaction that includes at least one write operation was executed successfully any checks included in the transaction passed and the registry has been updated. A success read outcome may indicate that the transaction executed successfully but did not make any changes to the logical registry. An abort outcome may indicate that the transaction was aborted for some reason other than the particular contents of the transaction. In various embodiments the DSM may abort and or reattempt a transaction for different reasons. A fail outcome may indicate that the transaction failed for example because one or more checks in the transaction failed a lock creation failed because the lock already exists the request contained a syntax error and or for various other reasons.

The DSM may determine the outcome of various transactions and route event notifications e.g. as indicated by the arrows labeled in indicating the outcomes to interested client processes . Client processes may register to receive some or all events in some events in some embodiments e.g. using the transactional watch mechanism described below in further detail. In some embodiments the DSM may be configured to forward all event notifications to every client by default but to allow each client to set up various filters to indicate the types of events in which it is interested. In some embodiments each event notification may be labeled with a physical and or logical timestamp from which the client process may be able to infer bounds on the age of the event.

As indicated above in some embodiments client processes may use transactions to read insert remove and or modify data stored in the logical registry . In some embodiments a transaction may be specified using a stack based language. Such a transaction may be specified in terms of data tokens and operations where the data tokens are pushed directly onto a stack and the operations read their inputs from the stack and push results to the stack. After such a transaction is complete the resulting stack may be sent to the client process.

In some embodiments the DSM may execute a failure detection service to detect failures among different nodes . For example if a given node crashed or became otherwise unresponsive the failure detection service may determine this. In some embodiments a failure detection service may be executed across the server cluster in a distributed manner. In some embodiments the failure detection service may also determine whether particular client processes have become unresponsive for example by monitoring heartbeat messages from various client processes. In at least some embodiments if connectivity is lost between a client process and a given DSM node the client library component of the client process may automatically attempt to establish a connection to a different node. In at least some implementations the client process may not be aware of the identity of the node to which it is connected.

Upon receiving the wrapped transaction the node may unwrap the message and insert the encoded transaction into a queue in a transaction pipeline as shown in element . The pipeline may represent an ordered processing of transaction requests in some implementations. In some embodiments several or all of the nodes of a DSM collective may share the same transaction pipeline. The transaction pipeline may then receive and parse the encoded transaction as shown in element . If the transaction does not contain any write operations to the logical registry as indicated by the negative exit from element then the DSM node may process the transaction directly as indicated in element and reply to the client with a status message and or any data requested as shown in element .

If however the transaction does contain write operations as indicated by the affirmative exit from element then the DSM may modify the logical registry . A transaction that includes writes may be referred to herein as a modifying transaction . Since multiple DSM nodes collectively maintain the registry the DSM node that received the transaction request may apply the writes by initiating a consensus protocol e.g. Paxos among these multiple nodes of the collective as shown in element before replying to the client with the result as shown in element . The nodes involved in the collective decision as to whether to apply a write may be termed a jury herein. Many variations may be possible for executing write operations to the shared logical registry using consensus protocols. In some embodiments the receiving node may first execute the transaction locally without applying the write operations to the logical registry and then only after all writes of the transaction are known apply the changes to the shared registry via a consensus protocol. For example as the node executes a transaction the node may create a change request in addition to the normal stack. The change request may include a list of logical registry items read by the transaction execution i.e. the read set and a list of writes to perform i.e. the write set . When the node finishes executing the transaction and the write set is complete then the modifications in the write set may be made to the logical registry via a consensus protocol. In some embodiments the DSM may also confirm that various data items in the read set have not been modified before committing the changes in the write set.

In some embodiments performing the writes via a consensus protocol may include passing the completed change request to a predetermined one of the DSM nodes which may be termed a primary or primus node herein directly or via a queue for processing. For example the primus may accept a completed change request and act as the leader in a Paxos protocol to reach consensus on committing the changes to the shared logical registry. In some embodiments apart from its role in coordinating consensus protocol activities e.g. in receiving change requests proposing changes to the jury as described below and or communicating jury decisions the primus may be otherwise similar or identical to other nodes of the DSM. In various embodiments the primus may be selected from any of the nodes according to any suitable protocol such as nomination or self nomination with or without election. If a primus fails during DSM operation a new primus may be selected in some embodiments.

The DSM node that receives the transaction message may decode the transaction and insert it into a queue maintained for its transaction pipeline e.g. transaction pipeline A for node A or transaction pipeline B for node B . In some embodiments if the transaction happened to be read only the values of the various registry elements to be read may be obtained from the local copy of the registry and returned to the client without any further interactions with the other nodes of the server cluster. Thus the receiving DSM node may commit read only transactions independently of other nodes and may assign a commit timestamp e.g. the value of the local copy of the registry logical timestamp or DSM time to the transaction. In the illustrated example however each transaction comprises at least one write update delete operation. Because the transaction received via message A includes a modifying operation a change list A may be constructed and populated for the transaction. For example node A may first construct an empty stack and an empty change list A and initiate a transaction processor. The processor may execute the operations of the transaction in sequence popping each parameter from the stack reading information from the local copy of the registry and pushing results back to the stack. During this transaction processing phase the node may avoid writing directly to the registry since the collective must agree upon changes to the registry. Instead the node may write state changes into the change list A that it may submit to the entire collective later. The change list A may also include check operations to ensure for example that the context of the transaction remains as expected e.g. to ensure that values of registry elements that are included in a read set of the transaction have not been changed as a result of other modifying transactions . Similarly a change list B may be constructed for client process B s transaction at node B.

In different instances the processing may terminate in different states. For example the transaction processing may terminate in an error state indicating that the transaction failed. Alternatively the transaction processing may terminate in a failed state indicating that a check failed e.g. data in the read set was modified . For modifying transactions the transaction processing may complete in a pending state indicating that the operations of the transaction were completed successfully but the change list is not empty.

If the transaction processing completes in a pending state then to complete the transaction the DSM collective must agree to modify the logical registry according to the change list in some embodiments. A given DSM node such as A may attempt to get the DSM collective to agree to commit the changes to the logical registry by initiating a consensus protocol. The node may initiate the consensus protocol by sending the change list to a DSM node in the collective that has been predetermined as the leader. In the illustrated embodiment a node K is designated as the current primary or primus node and the change list A may be placed in a routing pipeline A for transmission to the primus node K. Similarly change list B may be placed in a routing pipeline B for transmission to the primus node K. The primus node K may have its own pipeline in which change lists from various other nodes are enqueued and processed. The primus may then propose the changes in a given change list to other nodes in the collective via a consensus protocol such as Paxos. In some embodiments the primus may propose the change to only a subset of the nodes in the collective which may be referred to herein as the collective jury . Once the collective e.g. either all the nodes or a subset of the nodes that forms the jury decides on whether to make the change s of a change list to the logical registry e.g. when a consensus based commit or abort decision is reached the primus may notify the particular node from which the change list was received of the outcome. In other embodiments the node that sent the change list may discover the result by reading its updated copy of the registry rather than by receiving an explicit indication from the primus node. The node may then return one or more results of the transaction to the corresponding client process and may indicate the commit time of the transaction e.g. the DSM time when the transaction s changes were committed to the logical registry . In some embodiments the transaction results may also be encoded using a stack based language and decoded by the client library component of the client process. In at least some embodiments in the event a given transaction does not get committed the transaction may be retried either by the receiving node the node that received the transaction message from the client process or by the client process resubmitting the transaction. Different retry policies may be in effect in different embodiments governing for example if when and by which entities transactions are to be re attempted.

In some embodiments a client process may only be permitted to perform certain modifying transactions e.g. acquiring a lock if it has been explicitly identified and permitted to do so by the DSM collective. For example the DSM collective may require that in order to hold a lock a client process must first identify itself to the DSM collective and or be allocated a client name from the logical registry. Clients that have been allocated a name may be referred to herein as named clients while those that have not may be referred to as anonymous clients. In some embodiments while both named and anonymous clients may read and write entries only named clients may hold locks. At various times each lock may be associated with a respective list of named clients currently waiting on that lock. Various possibilities may exist for how a client name may be assigned. For example in some embodiments a client process may first choose a client stem as an identifier. When the client process registers for a name with a DSM node the DSM node may construct a client name from the client stem and the DSM time of the node s local registry. The DSM node may then propose the name to the DSM collective in order to enter the name into the logical registry .

In several embodiments the techniques described above for processing read only and modifying transactions using collective decision making may be employed to implement several features described below such as various types of asynchronous locking capabilities transactional watch mechanisms and versioned read only caches.

As described above processing of modifying client requests such as acquiring or releasing of locks may involve various queueing steps pipelines and network messages at different nodes of the DSM. At least in some cases requests transmitted from a given client process may not be processed in the order expected by the client which may potentially lead to some problems. illustrates an example of a sequence of client and server operations that includes a lock cancellation request being processed out of order according to at least some embodiments. In the sequencing of client side operations is shown along client timeline and the sequencing of DSM server node operations is shown along server timeline . The client and server timelines shown are intended to represent relative clock times. 

At client time CT1 a particular client e.g. a client process C1 submits a lock request for path P1 of the logical registry . Later at client time CT2 the client C1 decides it does not need the lock and submits a release request for the lock indicating that C1 s lock request should be removed from a lock queue for P1 or that if the lock for P1 was already granted to C1 the lock should be released . In the illustrated example at server time ST1 server node happens to schedule the processing of the release request before the processing of the lock request. This may occur due to any of a number of reasons in a distributed system e.g. due to longer network delays encountered by the lock request the release request may have been received earlier than the lock request. Since C1 neither holds a lock on P1 nor is C1 queued for a lock on P1 the server may simply ignore the release request or return a success indicator to the client C1 for the release request e.g. at time ST2. The client C1 may e.g. at time CT3 perform operations assuming that it does not hold the lock on path P. For example the client C1 could submit another request to lock a different path P2 which may be held by a different client C2. Thus at server time ST3 client C1 s lock request for P2 may be placed in a queue of waiters for P2. Meanwhile some time after the release request was processed the server may process the lock request and grant the lock on path P1 to client C1. At this stage C1 is waiting for a lock held by C2 and is holding a lock on P1. If at server time ST4 a request to lock P1 is received from C2 the server may place C2 s lock request in a queue for P1. Thus C1 and C2 may both be waiting for each other to release a respective lock i.e. a deadlock may have arisen.

One approach to avoiding the type of problem illustrated in may be to for client processes to ensure that they do not issue lock release requests until their lock requests are either a placed in a queue for the lock or b granted. Accordingly the DSM may support one or more queue for lock QFL APIs in some embodiments so that client processes may be notified when their lock requests are queued and can therefore be assured that any release or cancel request after such a notification would be processed correctly i.e. either the server would remove the lock request from the queue or free the lock if it had already been granted . In at least some embodiments the DSM may implement queue for lock using a two stage asynchronous notification process a first notification to the client when its lock request is queued and a second notification when the lock is granted.

In at least one embodiment in response to a QFL request specifying a target registry element to be locked the submitter of a QFL request may be provided a reference to a first asynchronous computation e.g. using a programming construct implementing functionality similar to that provided by the Java language Future interface java.lang.concurrent.Future where the first asynchronous computation comprises an insertion of a lock request on behalf of the submitter into a queue of waiters for a lock on the target element The first asynchronous computation may be referred to as Future1 herein for implementations using the Future interface or its logical equivalent. The QFL submitter process may then proceed to other computations as desired until it wishes to determine the result of the first asynchronous computation i.e. to determine whether the lock request got queued on its behalf . The decision as to whether to queue the submitter s lock request may be made by the server nodes of the DSM in some embodiments e.g. using a consensus protocol as described earlier. The QFL submitter client process may submit a blocking request for a result of the first asynchronous computation e.g. using the equivalent of a blocking Future1.get method. In response to the blocking request for the result the DSM may provide a notification to the client process after the lock request has been successfully queued on behalf of the client process thus indicating to the client process that a cancellation request if desired may be safely submitted . When the asynchronous computation associated with a Future construct completes the Future is termed to have become redeemable and the get method on the Future returns successfully i.e. a client thread that issued the get waiting for a result is unblocked . Similarly the phrase the DSM makes the Future F redeemable may be used herein to indicate that the DSM completes the asynchronous operation associated with F so that if and when the client issues F.get the get call returns e.g. either an object of a specified type may be returned from the get or a void .

The first notification provided by the DSM in turn may comprise a reference to a second asynchronous computation e.g. a second Future Future2 in some embodiments where the second asynchronous computation comprises an acquisition of the lock on the target element by the client process. The client process may then proceed to other activities and submit a second blocking request e.g. Future2.get when it wishes to obtain the result of the second asynchronous computation. If the second asynchronous operation succeeds e.g. Future2.get returns successfully or Future2 becomes redeemable as a result of a DSM decision that may also rely on a consensus protocol this indicates that the client process now owns the desired lock. One example implementation using two Futures for a single QFL request may be represented by the following pseudocode.

If a lock for the specified path P does not exist as determined in element the DSM may create a lock for that path and grant the lock to the requesting client C1 element . No indication of a maximum supported lock queue depth may be stored for the newly created lock in the depicted embodiment since a maximum queue depth was not specified in the request . In implementations where a Future mechanism or its logical equivalent is being used the DSM may make two futures redeemable i.e. a get operation on the first future F1 intended to notify the client when its request was successfully queued if queueing were needed may succeed returning the second Future F2 and a get on the second Future may also succeed indicating to the client that the lock has been acquired. It is noted that the F1 future is made redeemable even though a client lock request does not have to be queued in element thus in this scenario making F1 redeemable may be indicative of the DSM checking whether queueing is required and determining that queueing is not required rather than F1 being indicative of a request actually being queued.

If a lock for P1 does exist and the requesting client either a already holds the lock or b is already enqueued for the lock i.e. another request on behalf of C1 has already been placed in a queue of waiters for the lock as determined in element of the DSM may in some embodiments return an error indication such as an exception to the client C1 element . In some implementations an error or exception code or message provided to the client may indicate the reason for the failure of the QFL request e.g. a meaningful error message LOCK ALREADY HELD or LOCK REQUEST ALREADY QUEUED may be provided. It is noted that as discussed below if an idempotent version of QFL were submitted by the client such an error indication may not be provided and the DSM may simply ignore the duplicate request. 

If the lock exists and C1 is neither already queued nor a holder of the lock the DSM may determine whether the lock is currently held by another client C2 element . If the lock is available i.e. no other client holds it C1 may be granted the lock element . As in the operations illustrated in element in implementations where Futures or Future equivalent constructs are used both futures may be made redeemable.

If the lock exists and is currently held by another client C2 in the illustrated embodiment the DSM may determine whether a maximum queue depth was specified for the lock when it was created. If such a maximum queue depth was specified and the current queue depth equals the maximum as determined in element the DSM may reject C1 s QFL request and provide an error indication element . In some implementations a meaningful error message e.g. MAXIMUM LOCK QUEUE DEPTH EXCEEDED may be provided.

If either a no maximum queue depth was specified or b a maximum queue depth was specified and the current queue depth is less than the maximum as also determined in element the DSM may place C1 s lock request in the queue of waiting lock requests for P element and notify C1 that the request has been queued. In implementations employing Futures or their logical equivalent the first Future F1 may be made redeemable i.e. if the client C1 issues a F1.get call the second future F2 may be returned. The fact that F1 is redeemable may indicate to the client that it is now safe to submit a lock cancel release request should such a request be needed. After C1 s request has been placed in the lock queue the DSM may wait until there are no other requests ahead of C1 s request and the lock is released by the then current owner element . When the lock becomes available and assuming that no cancellation request was received in the interim the DSM may grant the lock to C1 element . In some implementations the Future F2 may become redeemable at this point and the requested lock may be returned in response to F2.get . It is noted that as with other modifying operations handled by the DSM at least a portion of the computation and or a subset of the decisions involved in responding to the QFL request may be performed collectively by a plurality of the nodes in some embodiments e.g. using a consensus protocol. Thus at least in some implementations the QFL request may represent a modifying transaction that may be handled using the kinds of approaches illustrated in and the decisions as to whether to place a lock request in a wait queue on behalf of the client or as to whether to grant the lock to the client may be made using the consensus based protocol.

As described above implementing each of the QFL APIs may involve providing two asynchronous notifications to the requesting client in some embodiments. In some environments some users of the DSM may not be concerned about the potential problems associated with out of order lock cancellations that are made easier to avoid by using QFL APIs but may still be interested in the types of idempotency and maximum queue depth features described above. Accordingly the DSM may support idempotency and or maximum lock queue depths for non QFL lock requests in some embodiments in addition to or instead of the similar QFL features. In at least some implementations a single step asynchronous notification process may be used for non QFL requests in which for example the client is notified when the lock is granted not when the lock request is queued as in the QFL cases . A single Future construct may be used in some implementations instead of the two Futures F1 and F2 discussed with respect to . illustrate functionality of the DSM to support four types of non QFL asynchronous lock APIs.

If a lock for the specified path P does not exist as determined in element the DSM may create a lock for that path and grant the lock to the requesting client C1 element . No indication of a maximum supported lock queue depth may be stored for the newly created lock in the depicted embodiment since a maximum queue depth was not specified in the request . In implementations where a Future mechanism or its logical equivalent is being used the DSM may make one future F3 redeemable i.e. a get operation on the future F3 may succeed indicating to the client that the lock has been acquired.

If a lock for P1 does exist and the requesting client either a already holds the lock or b is already enqueued for the lock i.e. another request on behalf of C1 has already been placed in a queue of waiters for the lock as determined in element of the DSM may in some embodiments return an error indication such as an exception to the client C1 element . In some implementations an error or exception code or message provided to the client may indicate the reason for the failure of the lock request e.g. a meaningful error message LOCK ALREADY HELD or LOCK REQUEST ALREADY QUEUED may be provided. It is noted that as discussed below if an idempotent version of the lock request were submitted by the client such an error indication may not be provided and the DSM may simply ignore the duplicate request. 

If the lock exists and C1 is neither already queued nor a holder of the lock the DSM may determine whether the lock is currently held by another client C2 element . If the lock is available i.e. no other client holds it C1 may be granted the lock element . As in the operations illustrated in element in implementations where Futures or Future equivalent constructs are used the future F3 may be made redeemable.

If the lock exists and is currently held by another client C2 in the illustrated embodiment the DSM may determine whether a maximum queue depth was specified for the lock when it was created. If such a maximum queue depth was specified and the current queue depth equals the maximum as determined in element the DSM may reject C1 s QFL request and provide an error indication element . In some implementations a meaningful error message e.g. MAXIMUM LOCK QUEUE DEPTH EXCEEDED may be provided.

If either a no maximum queue depth was specified or b a maximum queue depth was specified and the current queue depth is less than the maximum as also determined in element the DSM may place C1 s lock request in the queue of waiting lock requests for P element . In contrast to the corresponding QFL case no explicit notification may be provided at this stage in the depicted embodiment. After C1 s request has been placed in the lock queue the DSM may wait until there are no other requests ahead of C1 s request and the lock is released by the then current owner element . When the lock becomes available and assuming that no cancellation request was received in the interim the DSM may grant the lock to C1 element . In some implementations the Future F3 may become redeemable at this point and the requested lock may be returned in response to F3.get . It is noted that as with other modifying operations handled by the DSM at least a portion of the computation and or decisions involved in responding to the L request may be performed collectively by a plurality of the nodes in some embodiments e.g. using a consensus protocol. Thus at least in some implementations the L request may represent a modifying transaction that may be handled using the kinds of approaches illustrated in .

Some distributed applications may use the DSM for managing metadata that is read fairly frequently and is updated less frequently. For example a DSM may be used to manage group membership e.g. the number of application instances that are currently active or dynamic configuration information e.g. platform configurations for a quality assurance QA or performance test organization . In the dynamic configuration management use case for a QA or test organization for example if a platform configuration is changed or if a new test scenario is identified and corresponding updates are stored in the registry some new tests may need to be added to the test suite. In the group membership use case one or more client processes may attempt to monitor all active DSM sessions which may indicate the state of application instances or locks to keep track of the membership changes or member state changes. Another traditional approach may involve polling the DSM at some intervals and assuming that the registry does not change significantly between successive polling operations. However such polling and monitoring approaches may have several drawbacks. First there may be a delay between when the registry gets updated and when the client process learns about the change which may affect the correctness or accuracy of the decisions made by the client. Second depending on the number of registry elements of interest polling or monitoring the entire set of elements may be slow. Thirdly substantial overhead may be incurred at the server nodes along network paths between the clients and the servers and at the client processes themselves.

Accordingly in some embodiments the DSM may provide support for efficient transactional watch mechanisms that may alleviate the need for expensive polling operations. Clients may establish watches by specifying a set of registry elements of interest e.g. as one or more exact paths or parent paths whose descendant elements are to be watched and a notification destination such as a watch or a queue. Once a watch is established the DSM may ensure that notifications for all subsequent updates are provided to the client that requested the watch until the client decides to stop or terminate the watch. The watch mechanism may provide at least four invariants in some embodiments a validity b monotonicity c uniqueness and d selectivity. The validity invariant may imply that no updates are lost even if a given DSM node crashes or connectivity to a given node is lost from the client as long as the client can connect to at least one DSM server successfully. The monotonicity invariant may indicate that notifications for all updates are provided to the client in the order in which the updates occurred e.g. in the order of the DSM logical timestamp associated with the updates . The uniqueness invariant may imply no duplicate update notifications i.e. that one and only one update is sent to the client for each update. The selectivity invariant may imply that updates for only those registry paths specified by the client are provided.

Clients e.g. client processes may specify the set of registry elements of interest using filter constructs in some embodiments where a given filter may specify one or more registry paths and one or more filters may be applied to a given watch. Clients may specify any of several types of supported notification destinations for the watch updates in different embodiments e.g. as executable handler threads to which notifications are passed or as queues into which notification objects are placed. In at least some embodiments a client may be able to choose whether to a include a watch establishment request WER in a transaction submitted to the DSM where the transaction includes one or more read or write operations other than the WER itself or b submit the watch establishment request independently of any other reads writes. In the case where the WER is submitted as part of a transaction the DSM may use the transaction processing techniques described earlier e.g. including the use of a consensus based protocol to determine a commit timestamp of the transaction the DSM time at which the transaction is committed and set the watch establishment time to the commit time of the transaction. In the case where a WER is submitted separately from any other read write operation the DSM may in some implementations generate a transaction comprising one or more operations involved in establishment of the watch such as an instantiation of an executable thread or threads responsible for transmitting updates to the client and set the watch establishment time to the commit time of the internally generated transaction. In other implementations the establishment time of the watch may be determined by the DSM based on other factors.

Once a watch establishment time WET has been determined for the watch requested the DSM may ensure that notifications for any registry updates with commit times at or after the WET are transmitted to the client in accordance with the invariants discussed above until the client explicitly removes the watch or the client exits. A number of APIs associated with setting up and using the watch mechanism may be implemented in various embodiments and exposed to the clients via the client library components of the DSM as described below in further detail. For example in one implementation operations corresponding to the following pseudocode may be performed to set up a watch independently of a transaction.

5. client requests watch setup with specified filter and destination queue on a particular logical connection established with the DSM

It is noted that in line of the above example pseudocode the installWatch method returns a reference to an asynchronous operation similar in concept to a Future . The get method invoked on the installWatch may represent a blocking operation i.e. the client submitting the watch request may have to block until the DSM sets up the watch and allows the get to return.

The following pseudocode may represent a watch established as part of a transaction that includes a read operation according to some embodiments.

In the above example the DSMconnection.submit call implicitly submits a transaction request to the DSM including the read and the watch establishment request even though no specific startTransaction API is provided. The DSMconnection.submit .get call may also represent a blocking call i.e. the client process may have to wait until the DSM commits or aborts the transaction before the client can proceed to other activities.

Once the watch is established either as part of a transaction or independently the destination specified by the client process e.g. a queue in the above pseudocode may start receiving update notifications from the DSM. In at least some embodiments for each registry element updated the DSM may provide any combination of several values e.g. the new value of the element the old value of the element the DSM timestamp indicating the commit time of the update and or the DSM timestamp of the DSM node i.e. the value of the local registry logical timestamp at the node that is providing the update . In some implementations one or more of these values e.g. the old value of the element or the DSM timestamp of the DSM node may not be included in an update notification.

A DSM server node to which the client process has a connection established may receive the request element and determine a watch establishment timestamp WET e.g. based on the commit DSM time of the transaction in the case where the watch was submitted as part of a transaction. The DSM collective may be involved in the determination of the WET e.g. using a consensus based protocol as described with reference to . The DSM may then notify the client e.g. by making a Future redeemable or some other asynchronous notification mechanism that the watch is ready to submit notifications to the specified destination for any updates with commit times after the WET element . The client process may receive the notification element . The DSM may then start transmitting a sequence of update notifications to the destination with the four invariants described earlier validity monotinicity uniqueness and selectivity. The contents of each update notification may vary in different embodiments. In one embodiment a given notification may include for a given registry element an old value a new value an update commit timestamp and a DSM time of the node e.g. the local copy of the registry logical timestamp at the node . In other embodiments some subset of these values such as the new value and the update commit timestamp may be included in the notification. In some embodiments a single notification may include information about changes to several registry elements e.g. update notifications may be bundled together for several registry elements. The notification destination specified by the client in the WER may receive the sequence and the client process may take appropriate actions if any in response to the notifications as desired.

In some embodiments clients may optionally stop the notifications by submitting a watch remove request element of . In response to the watch remove request the DSM may stop transmitting the update notifications element . In some embodiments the filtering of updates may be performed at the DSM server node to which the client s connection that is being used for the watch is established in other embodiments some or all of the filtering may be performed at the client library component being used by the client process . The guarantees regarding the four invariants associated with the watch mechanism may be enforced by logic implemented in the various DSM nodes . For example for any given watch in some implementations a corresponding thread of execution may be set up at one or more server nodes configured to ensure that no duplicate notifications are sent and that notifications are sent in the correct order. In some implementations each watch may be restricted to communicating with a single client process e.g. if two client processes wish to be notified of updates to the same set of registry paths two independent watches may be set up.

The server may receive the transaction parse it and determine whether the other operations included are read only or not element . If the other operations are read only the transaction may be committed by the receiving node without consulting other nodes of the collective element . If there was at least one modifying operation in the transaction a consensus based protocol as discussed earlier may be used by the collective to determine whether to commit the transaction element . If the collective decides to abort the transaction or the transaction fails for some other reason as determined in element the client may be notified that the transaction failed and that the watch was not established element . If the transaction was committed either by the receiving node alone in the case of read only operations or by the collective the watch establishment timestamp may be set to the commit time of the transaction element . After the watch is established the client may start receiving notifications for updates committed at or after the watch establishment time element .

In some embodiments after a watch is created with a specified set of filters indicating the registry elements to be covered by the watch the DSM may not allow the filters to be modified. Clients may be able to obtain the list of filters of a watch by invoking a getFilters API as shown in elements and . If a client submits a getEstablishmentTime API request element the watch establishment timestamp may be returned in the depicted embodiment element indicating the lower boundary on the update commit timestamps of the updates for which notifications are sent. Thus if a client wishes to determine whether a watch it has set up covers an update that has a commit DSM timestamp T the client may check whether the establishment time of the watch was less than or equal to T. If the watch establishment time was less than or equal to T then the client may be assured that a notification of such an update would be provided to the notification destination set up for the watch.

In the depicted embodiment a client may use a getCurrentLogicalTimestamp API element to determine the timestamp of the most recent update notification that has been processed e.g. by the client library component as shown in element . The getFutureAt API element may be used by a client process to receive a reference to an asynchronous computation e.g. a Future on which the client process can block e.g. using a Future.get call until updates with commit timestamps less than or equal to a specified value FT have been processed at the client e.g. by the client library component. Such an API may be useful for a client process A to synchronize with another client process B in some embodiments. E.g. clients C1 and C2 could both set up watches for the same registry elements. If client C1 wants client C2 to wait until it has seen an update with a commit time of FT C1 may send a message to C2 specifying the target time FT and C2 may issue a blocking getFutureAt FT .get call to wait until C2 s watch has processed all the updates with commit timestamps less than or equal to FT. After it has responded to any one of the illustrated APIs the DSM may handle the next API call that is received element . At least in some embodiments the DSM may be able to handle multiple API calls in parallel.

A number of different variants of the types of APIs shown in may be implemented in different embodiments. In some embodiments additional watch related APIs beyond those shown in may be implemented including for example a remove API to discontinue or terminate a watch. The watch mechanism may be used to provide efficient implementations of the queue for lock functionality described earlier in at least one embodiment e.g. a watch may be established on the lock for the requested path so that updates to the lock state e.g. changes in the size of the waiter queue are transparently provided to the requesting client process. In at least some implementations constructs similar to the Future constructs representing asynchronous computations described earlier may be used to implement portions of the watch mechanism.

At some later time connectivity to node N1 may be lost element e.g. either the node N1 may crash or some network problem may be encountered. Using an API such as the getCurrentLogicalTimestamp API discussed above the client either the user code or a library component may determine the timestamp of the last update that was processed by the watch i.e. at the client end of the connection element . This last update timestamp LUT may be used to limit the number of updates received when the watch is reestablished for example. The client library component may then choose another DSM server node Nk and establish a connection to Nk element . The client may then submit a watch reestablishment request to node Nk with the same set of filters as the original watch. In some embodiments the watch reestablishment request may specify the last update timestamp in the watch reestablishment request element so the node Nk can start providing updates starting after that timestamp element . In other embodiments different responses to connectivity loss may be implemented than those shown in .

As noted earlier many types of distributed client applications such as applications that need to keep track of dynamically changing group membership or dynamically changing configuration information may need to track state change information that is stored in the DSM registry. Using the watch mechanism described above some client applications may implement their own custom caches that are updated as the watch provided notifications arrive. In some embodiments the DSM may provide a cache abstraction layer to further simplify the tasks that the client applications have to perform. For example the DSM may provide client library components that implement for a set of registry elements specified by a client process a consistent versioned asynchronously updated read only cache for the client process. In such embodiments the client user code may not need to explicitly establish a watch i.e. the watch used for the cache may be created by the client library component that implements the cache mechanism. Furthermore the cache functionality supported by the DSM may also provide object type transformations in at least some embodiments. The DSM registry may only be configured to store objects of a few types in some embodiments e.g. raw data entries a sequence of bytes locks and sessions which may contain information about DSM clients that are currently connected to the DSM . The client application may wish to use the registry to store more structured data of different types than supported by the registry and to be able to read the data in the structured form from its cache. The cache mechanism supported by the DSM may allow the client user code to specify a transformation function to be used for converting the data stored in the registry i.e. using the limited object types supported by the registry into the object types of interest to the application and at least in some embodiments to transform user defined objects into registry objects . The DSM may then configure the cache to automatically perform the type transformations so that the client user code does not need to perform such transformations itself.

In response to the cache setup request the DSM may establish a watch using the logical connection . As described earlier the logical connection may be established e.g. by the client library component of the DSM between the client process and some node of the DSM server cluster where the node may be selected based on different criteria or policies in different embodiments. For example in some embodiments the client library component may select a random node from among the currently active nodes of the DSM server cluster or the node to which it most recently established another connection or the node to which it least recently established another connection. Once the watch is set up a sequence of update notifications may be provided by the DSM server cluster to the client library as described earlier maintaining the invariants of validity monotonicity uniqueness and selectivity. Each update notification may comprise an update timestamp e.g. based on the registry logical timestamp corresponding to the commit of the update where the commit itself may be determined based on a consensus based protocol as described earlier . The client library may construct a cache comprising objects of the registry types using the update notifications. When the client user code submits a read request for some portion or all of the cache the transformation function may be applied to the raw registry data to convert it to the desired type. In some implementations the transformations may be applied prior to the read e.g. as soon as the updates are received i.e. in such implementations a cache of objects of the user defined types may be maintained. In some implementations a version number based on the latest update s timestamp may be maintained for the cache. In some embodiments the cache e.g. either the cache of registry elements or the cache of user specified types or both may be maintained in volatile memory e.g. in the main memory of a computer system where the client process runs.

For example in response to a cache setup request element the DSM may designate one or more elements of the registry as a cache data set and provide to the client a reference to an asynchronously updated cache object comprising contents of the cache data set element . The client may be provided read only access to the cache object e.g. no write APIs to the cache may be implemented in some embodiments. The DSM may initiate a sequence of asynchronous update notifications to the cache object where each asynchronous update notification includes updated contents of at least one element of the cache data set and a cache version identifier based at least in part on a registry logical timestamp value indicative of a time at which the element was updated. The cache version identifier may also be referred to herein as the cache version timestamp.

In some embodiments the DSM may provide several different cache setup APIs. For example in one embodiment distinct cache setup APIs may be provided for several of the one or more registry element types. In one such embodiment to set up a cache specifically for session registry elements stored under a registry directory with path directoryPath for example a client may invoke an asynchronous API such as the following 

In the above example the client process may block until the DSM server sets up the requested cache and the get call returns. All the elements of the registry whose paths start with the prefix indicated by directoryPath may form the cache data set in the example shown for example if new session entries are added to the registry within the same directory or one of its subdirectories the new sessions may also be included in the cache. Similarly an API such as the following may be invoked to set up a cache for lock objects stored under a registry directory path directoryPath in one embodiment 

According to one embodiment a third API may be invoked to set up a cache for arbitrary data registry entries whose contents are to be converted into objects of a type specified by the client. In the following example pseudocode the client wishes to convert registry data entry contents for entries stored under a registry directory with path directoryPath into the objects of type Integer and provides a transformation function apply to be used to implement the transformation.

Returning to a number of other APIs in addition to the cache setup APIs may be supported in the depicted embodiment. For example once the cache has been set up the client code may issue an API call to read a subset or all of the cache data set element of and in response may be provided the current values of the cached objects specified by the pathname s parameters of the API element . These read APIs may also be asynchronous and or blocking calls in some implementations. A single read API may be used to obtain values of multiple elements of the cache data set in some embodiments.

In response to a getStaleness API call element the DSM may provide a measure or estimate to the client of the time delay or lag in real time between the time that an event such as an update was committed at the DSM server and the time that the update was processed at the client process element . The DSM may use the client heartbeats illustrated by arrows of to estimate the lag or delay associated with the logical connection being used for the cache in some implementations. The client may obtain the current cache version identifier or version timestamp using a getCurrentVersionTimestamp API or a version query in some embodiments element .

In at least some embodiments the client process may wish to wait or block until the cache version timestamp reaches some specified value i.e. until some set of updates have been applied to the cache . A getFutureAt API specifying the future timestamp FT may be used element for this purpose in response the DSM may provide a reference to an synchronous computation e.g. a Future on which the client process may block e.g. using a Future.get call until the cache version timestamp reaches FT element . In at least some implementations a timestamp may also be maintained for the underlying logical connection indicating for example the most recent update that has been placed on the logical connection by a DSM server node. Since the client library receiving the notifications via the connection may take some time to process each update at least at some points in time it may be possible that the cache version timestamp which indicates the latest update available in the cache may differ from the connection timestamp which indicates the latest update sent by the DSM server in such an implementation. A syncWithConnection API may be provided element in one embodiment allowing a client process to receive a reference to an asynchronous computation e.g. a Future on which the process may block e.g. using a Future.get call or wait until the cache version timestamp catches up with the connection timestamp as of the time that the syncWithConnection call was issued element . For example consider a scenario where monotonically increasing integer values are used as timestamps and versions the cache version is 655665 when the syncWithConnection call is issued and the logical connection timestamp is 655700 when the syncWithConnection call is issued. In such a scenario the DSM may return a Future F1 to the client process and if the client process then issues an F1.get blocking call F1.get will return when the cache version reaches 655700. Note that by the time F1.get returns in this example the logical connection timestamp may have advanced further e.g. to some value such as 655710 because more updates may have occurred in the interim. In the depicted embodiment the DSM may turn its attention to the next API call as soon as it processes the current one i.e. return to element . Various other cache related APIs not shown in may be implemented in some embodiments and some of the illustrated APIs may not be implemented in some embodiments. A DSM may be able to respond to several cache API calls in parallel in at least some embodiments.

As noted earlier the cache may be maintained in main memory e.g. in heap storage of a Java virtual machine JVM being used for the client process in some implementations. In some embodiments when setting up the cache the client may specify a maximum size of the cache e.g. in the number of registry entries or in absolute units such as megabytes and or an eviction or replacement policy to be used to decide which cache elements are to be discarded when the cache becomes full. For example a least recently used policy may be specified for cache replacement. In other embodiments the DSM may not support replacement of cache entries e.g. the entire cache data set may be retained in the cache. If the DSM cannot maintain the entire cache data set in memory the client may be informed that the cache cannot be set up in some such embodiments. In at least some implementations when the cache is initially set up the entire cache data set may be loaded which may take some time e.g. tens of seconds depending on the size of the cache data set . In at least some implementations constructs similar to the Future constructs representing asynchronous computations described earlier may be used to implement portions of the cache mechanism.

At some point in the illustrated example client C1 may wish to update a registry element whose path is included in the cache data set. As shown in element C1 may update the element by issuing a non blocking write request. As noted earlier the cache itself may not be updated directly by the client since it is a read only cache . Instead the client may submit the update to a DSM server node as part of a transaction as shown in and . Unlike some other cache implementations no cache invalidations may be required instead writes may be propagated to the various client processes as part of the update watch mechanism s notifications. Once the DSM collective has determined that the write is to be committed e.g. as a result of a use of the consensus protocol discussed earlier the value of that element may be communicated back to the client cache via the underlying watch and C1 may learn the commit timestamp CT for that update.

C1 may wish to notify other client processes such as C2 that the other client processes need to wait until they see the update in their caches. Accordingly C1 may send a cache synchronization message to C2 asking C2 to wait until C2 s cache version timestamp reaches CT element . C1 may then proceed to other operations as desired element . Upon receiving the cache synchronization message element C2 may block e.g. using the equivalent of a blocking cache getFutureAt .get method of the getFutureAt API shown in until its cache has received the update requested by C1. C2 may then proceed to other operations as desired element . In this way different client processes may coordinate their work in some embodiments ensuring for example that the same consistent view of shared state is seen before certain critical operations are performed at the various processes of the client application.

If connectivity to N1 is lost or N1 crashes element in the depicted embodiment the latest cache version timestamp CVT may be determined at C1 either the user code or the client library component may determine CVT in various embodiments element . A connection to a different server node Nk may then be established element e.g. automatically by the client library. A cache reestablishment message may then be sent to Nk element indicating the latest cache version timestamp CVT seen at the client before N1 became unreachable. Providing the CVT may help the node Nk reduce the number of update notifications it has to send. Once the cache is reestablished C1 may start receiving updates with commit timestamps later than CVT element .

The techniques described above of supporting various types of asynchronous idempotent and queue depth limited locking mechanism transactional watches and versioned read only caches may be very useful in a number of different scenarios. The queue for lock mechanism for example may allow cleaner implementation of distributed applications so that application writers can be assured that their lock release or cancel requests are handled safely. Idempotent versions of lock and queue for lock requests may also lead to simpler and cleaner application code in that clients may be able to avoid having to handle certain types of exceptions or errors. Maximum queue depths for locks may allow application designers to distribute work more effectively. For example in some applications each lock may protect a stream of incoming tasks of a certain type and the designers may wish to ensure that no more than X worker processes are dedicated to handling jobs of type Y. If in such a scenario a particular worker process fails to acquire a lock for task type Y because the lock s wait queue is full this may mean that enough worker processes are already assigned for tasks of type Y.

Watches and read only caches that rely on watches may be used for a number of different types of applications. Client applications that need to have a consistent view of configuration metadata such as the mappings of storage object unique identifiers or keys to underlying storage locations or addresses may be helped substantially by the use of such mechanisms. Registry entries may for example store metadata such as object key physical storage location for various storage objects. And such metadata may be cached at the various servers of a storage service to which customers of the storage service may send reads and writes. In another application a range of values representing resource identifiers of resources to be leased to customers by a set of lease managers may be dynamically redistributed among various lease manager servers. The number of active lease manager servers may change over time. If the lease application intends that no more than one lease manager is to be designated for a particular resource identifier each lease manager may wish to retain a consistent view of the mapping between the range of resource identifiers and the set of active lease managers. Similarly in a software test environment a DSM registry may be used to maintain information about tested configurations. Whenever a new test configuration is added some action may need to be taken so the watch mechanism may be used in such an application e.g. to avoid the need for polling.

In at least some embodiments a server that implements a portion or all of one or more of the technologies described herein including the functionality of the various server nodes of the DSM the client library components of the DSM and user components of client processes may include a general purpose computer system that includes or is configured to access one or more computer accessible media. illustrates such a general purpose computing device . In the illustrated embodiment computing device includes one or more processors coupled to a system memory via an input output I O interface . Computing device further includes a network interface coupled to I O interface .

In various embodiments computing device may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store instructions e.g. code and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above are shown stored within system memory as code and data . In at least some embodiments one or more software clocks may be maintained e.g. as a respective logical timestamp associated with one or more logical entities such as the caches watch mechanisms connections registries and the like described above. In some embodiments a software clock may simply be implemented as a 64 bit number that is incremented when the state of the corresponding entity such as a cache maintained at a client changes.

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor . Computing device may include one or more hardware clocks in some embodiments output from which may be used to determine a time of day for the computing device as a whole to generate timestamps or software clock values and so on.

Network interface may be configured to allow data to be exchanged between computing device and other devices attached to a network or networks such as other computer systems or devices as illustrated in for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet network for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer accessible medium configured to store program instructions and data as described above for for implementing embodiments of the corresponding methods and apparatus. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer accessible media. Generally speaking a computer accessible medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computing device via I O interface . A non transitory computer accessible storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc that may be included in some embodiments of computing device as system memory or another type of memory. Further a computer accessible medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface . Portions or all of multiple computing devices such as that illustrated in may be used to implement the described functionality in various embodiments for example software components running on a variety of different devices and servers may collaborate to provide the functionality. In some embodiments portions of the described functionality may be implemented using storage devices network devices or special purpose computer systems in addition to or instead of being implemented using general purpose computer systems. The term computing device as used herein refers to at least all these types of devices and is not limited to these types of devices.

Various embodiments may further include receiving sending or storing instructions and or data implemented in accordance with the foregoing description upon a computer accessible medium. Generally speaking a computer accessible medium may include storage media or memory media such as magnetic or optical media e.g. disk or DVD CD ROM volatile or non volatile media such as RAM e.g. SDRAM DDR RDRAM SRAM etc. ROM etc as well as transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as network and or a wireless link.

The various methods as illustrated in the Figures and described herein represent exemplary embodiments of methods. The methods may be implemented in software hardware or a combination thereof. The order of method may be changed and various elements may be added reordered combined omitted modified etc.

Various modifications and changes may be made as would be obvious to a person skilled in the art having the benefit of this disclosure. It is intended to embrace all such modifications and changes and accordingly the above description to be regarded in an illustrative rather than a restrictive sense.

