---

title: Systems and methods for semantic inference and reasoning
abstract: A method and system for analyzing a corpus of data artifacts is disclosed. The method comprises obtaining, by a computer, a semantic representation of the data artifacts, where the semantic representation indicates (1) entities identified in the data artifacts, and (2) semantic relationships among the entities as indicated by the data artifacts. The method further comprises clustering the data artifacts into clusters of semantically related data artifacts based on the semantic representation and inferring additional semantic relationships between pairs of the entities. The inferring comprises applying, on a cluster-by-cluster basis, a multi-tiered network of inference engines to a portion of the semantic representation corresponding to the cluster, where the multi-tiered network of inference engines includes a domain-independent inference tier and a domain-specific inference tier.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09015080&OS=09015080&RS=09015080
owner: Orbis Technologies, Inc.
number: 09015080
owner_city: Annapolis
owner_country: US
publication_date: 20120316
---
The present invention relates to systems and methods for searching a large corpus of data to identify contextually relevant search results.

As the amount of available digital data has exploded so too has the need for more effective search and retrieval systems. Traditional search and retrieval systems often referred to as search engines typically operate by receiving a textual query of terms and or phrases the search terms comparing the search terms against a body of searchable content the corpus and returning the data items in the corpus that are most relevant to the keywords the results . The classic example of a search engine is an Internet search engine which indexes web pages and returns the most relevant ones in response to search term queries.

Search and retrieval alone is insufficient to fully understand and utilize the data in a corpus. Traditional keyword search techniques consider only the text of searchable documents in the corpus and ignore other semantically relevant documents that may not include the keywords directly. Accordingly keyword searching alone may be unable to identify all semantically relevant documents.

Semantic reasoners overcome problems with traditional keyword searching by applying inference algorithms to the content and or metadata of corpus documents to infer logical consequences. Thus semantic reasoners can expose connections that are invisible to traditional search engines and thereby allow users to find more relevant content. For example a semantic reasoner may be able to identify relevant documents in the corpus that do not contain the given search terms but are nevertheless semantically related to disambiguate entities in the data that have the same or different textual names reduce the number of results to which a user is exposed preserve linguistic flexibility in search terms and enable accurate ranking of query results by trust in source etc.

Although semantic reasoners provide powerful advantages over traditional search engines such reasoners have remained impractical for large corpuses such as Internet content intelligence report databases corporate document databases and the like. The inference algorithms applied by traditional semantic reasoners can significantly inflate the already large volume of corpus data which requires prohibitive storage and or computing resources. Furthermore inference algorithms are often brittle and lose accuracy when applied to large volumes of documents that span beyond a single narrow domain i.e. the frame problem .

According to various embodiments a semantic reasoning method and system is designed to overcome the shortcomings of traditional reasoners by employing a novel multi stage approach.

In accordance with a first aspect of the present invention a method for analyzing a corpus of data artifacts is disclosed. The method comprises obtaining by a computer a semantic representation of the data artifacts where the semantic representation indicates 1 entities identified in the data artifacts and 2 semantic relationships among the entities as indicated by the data artifacts. The method further comprises clustering the data artifacts into clusters of semantically related data artifacts based on the semantic representation and inferring additional semantic relationships between pairs of the entities. The inferring comprises applying on a cluster by cluster basis a multi tiered network of inference engines to a portion of the semantic representation corresponding to the cluster where the multi tiered network of inference engines includes a domain independent inference tier and a domain specific inference tier.

In some embodiments obtaining the semantic representation may comprise applying natural language processing techniques to extract the entities and relationships from natural language content contained of the data artifacts.

In some embodiments obtaining the semantic representation comprises determining that the same entity is identified in the artifacts using different identifiers and disambiguating the entity by replacing one or more of the different identifiers with a common identifier for the entity.

In some embodiments clustering the data artifacts may comprises performing a semantic analysis to determine semantic interrelatedness of the data artifacts based on respective ones of the entities and relationships in the data artifacts and or performing a syntactic analysis to determine syntactic interrelatedness of the data artifacts based on syntactic overlap of respective content of the data artifacts.

In some embodiments applying the multi tiered network of inference engines may comprise applying two or more inference engines sequentially in parallel or iteratively according to a static or dynamic schedule which may be defined in one or more runtime configuration files. In some embodiments applying the multi tiered network of inference engines may comprises applying a plurality of domain independent inference engines in the domain independent tier and subsequently applying a plurality of inference engines in the domain specific tier.

In some embodiments the clustering and inferring may be implemented using a parallel programming and execution model such as a MapReduce framework.

In accordance with a second aspect of the present invention a system for analyzing a corpus of data artifacts is disclosed. The system comprises a parallel processing facility comprising a plurality of computer processing cores and one or more memories coupled to the computer processing cores and storing program instructions executable by the processing cores to implement a semantic inference and reasoning engine. The semantic inference and reasoning engine may be configured to analyze a corpus of data artifacts by 1 obtaining a semantic representation of the data artifacts where the semantic representation indicates a entities identified in the data artifacts and b semantic relationships among the entities as indicated by the data artifacts 2 clustering the data artifacts into clusters of semantically related data artifacts based on the semantic representation and 3 inferring additional semantic relationships between pairs of the entities. The inferring may comprise applying on a cluster by cluster basis a multi tiered network of inference engines to a portion of the semantic representation corresponding to the cluster where the multi tiered network of inference engines includes a domain independent inference tier and a domain specific inference tier.

In some embodiments the system may include a distributed storage facility coupled to the parallel processing facility and storing the corpus of data artifacts. The storage facility may comprise a distributed file system.

In some embodiments the parallel processing facility may comprise at least one of a compute cluster a superscalar supercomputer a desktop grid or a compute cloud. The memories may further store program instructions executable to implement a parallel computation scheduling framework for executing the semantic inference and reasoning engine on the parallel processing facility using a MapReduce pattern.

The above and other aspects and embodiments of the present invention are described below with reference to the accompanying drawings.

According to various embodiments of the present invention a semantic reasoning method and system is designed to overcome the shortcomings of traditional reasoners by employing a novel multi stage approach. In some embodiments a corpus of data artifacts e.g. natural language documents may be ingested into the system and converted to a suitable semantic representation such as a Resource Description Framework document RDF . For purposes of clarity natural language documents and RDF are used as examples throughout this disclosure. However it should be understood that in various embodiments the input may be any data artifacts e.g. text semantic document etc. and the semantic representation may be described in RDF or in any other suitable semantic representation language.

The input documents may be analyzed to extract entities and their semantic interrelationships which may be added to the RDF representation. For example a corpus of natural language intelligence reports may be analyzed via natural language processing to produce an RDF document that identifies people places activities and or other entities discussed in the document and the semantic relationships among those entities.

In some embodiments the RDF may then be analyzed to identify clusters of semantically related documents. The clustering may be based on the entities and semantic inter relationships in the RDF. Thus documents that are more semantically related to one another are grouped into the same cluster. Semantic relatedness for the purpose of clustering may be measured in various dimensions such that in some instances a data artifact e.g. document may be part of multiple clusters.

Once the documents are clustered the system may infer additional semantic relationships by executing various inference algorithms on each document cluster i.e. on the semantic data corresponding to the documents in the cluster . The system may apply any number of domain independent and domain dependent inference techniques sequentially in parallel and or iteratively to infer new relationships between entities. The system may add the new inferences to the semantic representation of the data.

After analyzing the data as described above the system may store the data for later query. The semantic data may be stored as RDF in a relational database and or in any other format. The semantic data store may be referred to generally herein as the semantic database without limitation to a particular implementation.

After the semantic database is created the system may later respond to a query for data relating to one or more entities by identifying one or more document clusters that are related to the queried entities based on the identified and or inferred semantic relationships.

The system and techniques described herein overcome the shortcomings of traditional reasoners by solving the data explosion problem and the frame problem. The system may mitigate both problems by actively managing data volume through clustering by applying a network of inference techniques to smaller semantically related document clusters. Furthermore by using a variety of inference techniques rather than only one the inference process can be made less brittle and users can be given additional control over the inference workflow. Thus the system can produce inferences with higher confidence and accuracy by organizing components and inference algorithms into layers that work on different levels of granularity.

According to system implements a client server model where a plurality of clients connect to one or more servers via network . As illustrated client hardware may correspond to any computing device such as mobile device desktop computer or laptop computer

Each of clients may include software for accessing servers via network . The particular software necessary may depend on the protocols of network and or on the interface of servers . For example in some embodiments clients may utilize web browsers browser plugins e.g. widgets and or standalone applications to access web pages or web services provided by servers . Software executing on clients may permit clients to form requests for data from the corpus to receive the requested data and or to view the data e.g. as visualizations etc. .

In various embodiments network may be implemented by the Internet or any other combination of one or more electronic communication networks including local area networks LAN and or wide area networks WAN . The networks may use various protocols including wireless networking protocols e.g. WiFi wired networking protocols e.g. Ethernet radio networking protocols e.g. GSM LTE etc. and can be arranged in any configuration e.g. point to point broadcast etc. .

Servers may comprise any number of physical and or virtual machines capable of executing one or more software servers. In some embodiments servers may be configured to execute software web servers that host one or more web applications and or one or more web services e.g. RESTful . The web servers may make such applications and or services accessible by clients via network . For example servers may expose a web application with a browser accessible interface that can be delivered to web browsers on clients . In some embodiments servers may host web services accessible by widgets and or standalone applications executing on clients .

System further includes SIRE compute cluster . Compute cluster provides storage and computing resources for creating and maintaining the semantic database that stores and analyzes the corpus. Although a cluster is illustrated the necessary computational and storage resources may be provided by various other architectures for parallel computation and or storage such as one or more supercomputers desktop grids distributed clusters and or other systems.

Cluster may be configured as a commodity cluster which includes a set of commodity computers networked via an interconnect. The cluster may be controlled by scheduling software such as by a MapReduce framework e.g. Hadoop to perform parallel computations necessary for ingestion and inference computations described herein. The cluster may also be controlled by distributed database and or file system software such as Hadoop Distributed File System to implement a distributed file system on which the semantic data i.e. semantic database may be stored. Although servers are illustrated as separate from compute cluster in various embodiments computers on compute cluster may be used to implement web server functionality.

According to system includes one or more web servers which are configured to host various web applications and or services . Web servers and web applications services may execute on servers and or on computer cluster of .

As described above web servers may be configured to receive queries regarding various entities and in response to query the semantic database for data that is most relevant to the queries.

System further includes job control flow scheduling framework . Scheduling framework may be executed on one or more nodes of cluster and may be configured to control how orkflow and or parallel job execution on the cluster is handled. For example scheduling framework may be implemented by the Hadoop MapReduce framework. Such a framework may handle the splitting of jobs into smaller jobs and executing the smaller jobs in parallel across the nodes of the cluster. For instance in MapReduce jobs may be split into smaller jobs that are executed in parallel across the different nodes of the cluster to produce an intermediate result i.e map step and the intermediate results are then redistributed by key and consolidated according to a given function i.e. reduce .

System includes inference engine which may be executed on one or more nodes of cluster . Inference engine may be configured to ingest and process documents into an RDF representation. For example inference engine includes ingestion tier for receiving and or retrieving documents e.g. intelligence reports emails etc. document based resolution tier for identifying clusters of semantically relevant documents entity based resolution tier for inferring additional relationships based on entity relationships and domain based resolution tier for inferring additional relationships based on domain specific knowledge such as by applying expert systems. By layering the components of inference engine into tiers that first cluster semantically similar documents before inferring relationships the system is able to handle large volumes of data e.g. petabytes or greater without becoming too brittle.

System includes a data access layer for storing semantic data ingested documents intermediate data e.g. data produced during inference activities and or other types of data. For example the tiers of inference engine may communicate input and output data via data access layer .

In various embodiments data access layer may be implemented by storage devices associated with and or coupled to cluster . For example the storage provided by data access layer may be provided in whole or in part by the individual hard drives or solid state storage of the computers in the cluster by a separate storage cluster by cloud storage and or by any special purpose storage devices such as tape backup large scale magnetic storage large scale solid state storage etc.

In some embodiments data access layer may implement a distributed file system such as a Hadoop Distributed File System HDFS which may facilitate fast access to semantic database. In some embodiments the semantic database stored in data access layer may be a managed database including a query engine for facilitating query of and access to the semantic data. The semantic database may be implemented as files on the distributed file system.

According to the illustrated embodiment ingestion tier includes a document gathering module . Document gathering module may be configured to receive documents in any format such as natural language or a structured format e.g. XML.

In some instances the document gathering module may be configured to actively search for and pull documents from remote sources such as by crawling the web or searching through an email database a company file system a backup storage facility and or any other type of document repository for ingestible documents. For example the document gathering module may be configured to periodically scan an email repository for new intelligence reports and to ingest those reports into the semantic database.

In other instances the document gathering module may be configured to passively receive documents from another component though a programmatic interface. The interface may be invoked by one or more other components to add documents to the semantic database. For example the document gathering module may expose an interface for ingesting email messages and an email system may be configured to invoke the interface each time an email message is received.

Ingestion tier further includes a document cleansing module which may be configured to normalize document content. In various embodiments the cleansing module may strip extra white space extraneous formatting and or other superfluous data from a document being ingested. For example if document gathering module ingests a document encoded in HTML and another in Word format the document cleansing module may normalize the two documents to use a common encoding without extraneous formatting or other metadata. The particular normalized formatting may depend on the particular implementation.

Ingestion tier also includes a corpus pattern analyzer CPA for extracting entities and relationships from ingested documents. The CPA may employ complex natural language processing techniques to identify entities described in each document and to determine semantic relationships between those entities.

The extracted entities may correspond to any real world entities such as people places companies organizations and the like. The extracted relationships may correspond to any semantic relationship between two or more of the entities. For example suppose the ingested document is a memorandum reporting that Steve who is a banker at UBC was seen meeting with Terry at the Blue Parrot Inn. The CPA may extract the entities Steve UBC Terry and Blue Parrot Inn from the memorandum. The CPA may then identify relationships between the entities. For example the CPA may create a unidirectional works at relationship between Steve and UBC a bidirectional met with relationship between Steve and Terry and respective unidirectional met at relationship between Steve and the Blue Parrot Inn and or with Terry and the Blue Parrot Inn. In some embodiments some relationships may be denoted as attributes of entities or relationships e.g. the met with relationship between Steve and Terry may be decorated by the attribute place blue parrot inn. .

CPA may be configured to create a structured representation of the extracted entities and relations. The structured representation may include indications of the ingested documents particular sentences within the ingested documents metadata for the documents and or the extracted entities and relationships. The structured representation may be stored in the data access layer e.g. data access layer and thus passed to the document based resolution tier for further processing.

According to the illustrated embodiment document tier includes format mapping services FMS . FMS may be configured to convert the structured representation output by the ingestion tier into RDF data and to normalize that data for analysis by the semantic inference and reasoning engine. For example in a MapReduce based implementation the FMS may read the structured representation output by the ingestion tier and convert it to RDF. Next the FMS may then normalize the RDF by repackaging it for MapReduce e.g. by creating a sequence file of n tuples and optimizing the representation by disambiguating key values.

Document tier includes statistics module which may be configured to gather statistics about the ingested documents and thereby make meta inferences. For example statistics module may be configured to count the number of entities and or relationships defined in each ingested document in order to determine their relative importance to the corpus. A document concerning many entities and relationships may be more important to the corpus than one that concerns very few. Accordingly more important documents may warrant extra processing grouping into multiple groups and or other unique treatment.

Document tier also includes syntactic analyzer and semantic analyzer . Analyzers and may be configured to determine semantically related clusters of documents based on the entity relationship data previously identified. Documents that appear to be highly semantically interrelated may be grouped together as a single cluster. For example if the ingested documents include emails and other documents concerning three different events planned by a wedding planning company the syntactic and semantic analyzers and may group the documents based on their entities and relationships into three groups one for each event. The semantic analyzer and syntactic analyzer may be executed sequentially or in parallel.

Syntactic analyzer may be configured to identify related documents based on the particular text of the documents. For example if syntactic analyzer discovers that a group of documents contain some number of sentences or phrases in common the analyzer may conclude that the documents are syntactically related to one another and therefore likely semantically related. By further analyzing metadata e.g. date of document creation the syntactic analyzer may identify the nature of particular relationships between the documents e.g. a sentence was copied from an earlier document to a subsequently created document .

Semantic analyzer may be configured to identify related documents based on the particular entities and semantic relationships represented in the document. For example if semantic analyzer discovers that the entities and or relationships mentioned in a group of documents overlap significantly the semantic analyzer may conclude that those documents are semantically related. In various embodiments the semantic analyzer may employ various data mining and or machine learning techniques such as named entity recognition and or linguistic extraction.

Document tier also includes high level analytics module which may be configured to analyze each cluster of documents to produce cluster level metadata. Analytics module may analyze a cluster to determine various metadata such as the number of entities and or relationships within the cluster number of documents within the cluster level of entity interconnectedness within a cluster the most important entities relationships within the cluster and or various other cluster level metadata. The cluster level metadata may be used for analysis by subsequent tiers and or for query and visualization of query results.

Entity tier may be applied to each cluster of documents separately. By limiting the inference activity to a single group of semantically related documents at a time the technique enables the system to manage data size and framing problems described above.

According to the embodiment of entity tier may comprise an ecosystem of different domain independent inference components each configured to infer new semantic relationships between entities in a cluster based on the existing semantic relationships. The ecosystem may comprise various inference engines known in the art such as rules engines description logic engines and or First Order logic FO logic engines. For example in the illustrated embodiment entity tier includes a rules engine which applies a rules based system described in rule store e.g. a rules database . Entity tier further includes a description logic engine which is based on T Box reasoning and A Box reasoning . Entity tier further includes an FO logic engine based on ontology . In various embodiments entity tier may include fewer and or additional types of domain independent inference algorithms such as forward chaining techniques backward chaining techniques Bayesian reasoning and or others.

In some embodiments the entity tier may employ the various inference engines e.g. each according to respective tuning parameters. Such parameters may be set in one or more configuration files which may be read by the system at runtime.

In various embodiments entity tier may employ the inference engines in any order i.e. according to any static or dynamic schedule including sequentially in parallel and or iteratively. A static schedule may refer to a schedule in which the individual inference engines are applied in a pre defined order. A dynamic schedule may refer to a schedule where the decision of which inference engine to apply next is made based on runtime conditions such as the results of one or more previous inference engine executions.

Like entity tier domain tier may be applied to each cluster of documents separately. Accordingly by limiting the inference activity to a single group of semantically related documents at a time the technique enables the system to manage data size and framing problems described above.

According to the embodiment of domain tier may comprise an ecosystem of different domain specific inference components each configured to infer new semantic relationships between entities in a cluster based on the existing semantic relationships. Like entity tier the ecosystem of reasoners in domain tier may comprise various reasoners known in the art such as domain specific logic engines e.g. expert systems and or graph based reasoning engines. For example in the illustrated embodiment domain tier includes domain specific logic engine which is configured to infer new relationships based on heuristics in heuristic store e.g. database configuration file s etc. . Such a domain specific logic engine may correspond to an expert system configured to deduce new relationships based on domain specific rules e.g. if Steve is an employee of company C and Steve has been spotted entering building B every weekday at 8 am and leaving a 5 pm then company C has an office in building B . The particular heuristics in heuristic store may be domain specific and determined by domain experts. Domain tier also includes graph based reasoning engine which may be configured to infer new relationships based on probabilistic graph matching techniques such as sub graph isomorphism matching to determine if two differently organized graphs are indeed referring to the same real world entity.

As with the entity tier the domain tier may apply its inference engines according to different input parameters and in any order including sequentially in parallel and or iteratively. Such an order may be static e.g. according to a predefined script and or dynamic iterative based on the results of previous inferences . For example a dynamic schedule my choose which one or more inference engines if any to execute next based on the results of previous inference engine runs e.g. do not rerun an inference engine if no new relationships have been inferred since the previous time the engine was run .

In various embodiments the inference activities of entity tier and domain tier including the particular inference engines within each tier may be executed in any order e.g. parallel sequential iterative and according to any static or dynamic schedule. Runtime parameters and the static or dynamic schedule may be set by the system administrator using one or more system configuration files.

According to the illustrated embodiment method first receives documents as in . As discussed above the receiving of may be performed by active retrieval e.g. crawling a document repository and or by passive receiving e.g. receiving email reports .

Method next comprises extracting entities and relationships from the received documents as in . As described above the ingestion tier may receive the documents and extract entities and relationships into a structured representation using CPA.

Method next comprises creating a semantic representation e.g. RDF of the ingested documents based on the extracted entities and relationships as in . As described above the document tier may create the RDF and ensure that it is normalized for use with the execution framework e.g. MapReduce .

In the documents are clustered into semantically related document clusters based on the extracted entities and relationships. The clustering step of may be executed by the document tier e.g. as described above.

In a variety of inference algorithms are applied to each cluster to infer new relationships between the entities in the cluster based on the existing relationships. The inference step of may comprise applying entity based inference algorithms as in and or domain based inference algorithms as in to infer new relationships. The entity based and domain based algorithms may be executed by entity tier and or by domain tier according to any execution parameters and or in any order e.g. according to a static and or dynamic schedule . As discussed above the parameters and or schedules may be specified by the system administrator in configuration files. Thus an administrator may use configuration files may specify which inference engines to use the static and or dynamic workflow for those engines and the parameters for those engines.

In some embodiments the configuration parameters for each inference engine may be provided in a manner corresponding to a static schedule. For example the parameters for the inference engines in a static schedule may be provided as a vector where the ielement in the vector corresponds to a set of parameters for the iinference engine in the static schedule. Components scheduled to be executed in parallel may be sorted by secondary criteria such as lexicographically by engine name. In some embodiments a pre tested schedule and set of configuration parameters may be provided. However because the optimal configuration parameters and schedules may vary with domain or deployment users may modify the configuration parameters and or schedule to suit particular data sets or deployments.

In the new relationships inferred in may be added to the RDF representation created in . Thus the entity relationships indicated in the RDF database may become richer each time an inference algorithm is applied in . Because new relationships may be added in the method may comprise iteratively executing the inference algorithms of according to a static and or dynamic schedule as indicated by the feedback loop from to .

Once the inference components have finished inferring and adding new relationships to the RDF the RDF database is ready to be queried. In some embodiments the ingestion and inference steps e.g. may be executed regularly as a background process. Thus documents may be regularly ingested and incorporated into the RDF database. In some embodiments the execution may be structured as a MapReduce execution and may be controlled by the MapReduce scheduling software such as scheduler of . In addition to the ingestion and inference steps of the system may be configured to optimize the RDF database for query such as by creating various indices around entities relationships documents etc.

In the system receives a data request. The data request may come from a client e.g. clients of and be received by a web server interface such as by server of . In some embodiments the data request may come from one of the servers e.g. in response to a client request and be received by a query engine coupled with the semantic database. For example a server may be configured to respond to client requests for data by formulating a query in a structured query language e.g. SPARQL a structured query language for RDF . In various embodiments different semantic representations and query languages may be used. For example in other embodiments this aspect of the invention ay be implemented by a NoSQL query and database.

The data request of may specify one or more entities relationships documents and or any other items in the RDF. For example the request may be for all documents relevant to a given person. In another example the request of may be for all entities with a given relationship e.g. resides in to a particular another entity e.g. Chicago .

In response to receiving the data request the system queries the semantic database i.e. semantic representation for semantically relevant data as in . Because the semantic database includes both semantic relationships that were indicated by the ingested document and those that were inferred from those documents the query may be satisfied by both indicated and or inferred relationships.

In the results of the query are returned. The returned results may depend on the document clustering performed in . For example results may be visualized and or otherwise presented according to the document clusters. Examples of such visualizations are shown in .

Method begins in by receiving documents to be ingested. As described above the receiving may be performed as an active retrieving step e.g. crawling a document repository or a passive step e.g. receiving a document via an invocation of an exposed ingest interface . The received documents may be in natural language text structured language and or in any other format.

In the documents are cleaned. As described above the cleaning may involve stripping formatting stripping extraneous characters and or spaces converting one encoding to another etc.

In entities and relationships are extracted from the documents. As described above the entities and relationships may be extracted by the ingestion tier using CFA techniques and or other natural language processing. The extracted entities and relationships may include syntactic structures such as sentences.

In a structured representation of the documents entities relationships entities etc. is created. The structured representation may be annotated with various attributes and or metadata. For example a document may be annotated with various document metadata such as word counts date of creation file name author and so forth.

In the structured representation is stored in the data access layer. Thus a result of the ingestion method is a structured representation of the ingested documents including content and metadata.

In some embodiments the ingestion method may ingest structured data e.g. in RDF directly which may obviate many of the steps described in for such documents. In such an example a document ingested in RDF may be directly passed to the data access layer for processing by subsequent tiers. Documents ingested directly in RDF may include schemas and or ontologies that may also be ingested to enable more in depth processing by subsequent analysis tiers.

Method begins in where the document tier accesses the data access layer to read the structured representation created by the ingestion tier. In the document tier converts the structured representation to RDF. In other embodiments the system may use a semantic language other than RDF.

In the RDF is normalized for processing. Normalization may entail manipulating the RDF into a format that can be used by the processing framework e.g. MapReduce to identify clusters and or infer new semantic relationships. For example in the illustrated embodiment the RDF is normalized for execution in a MapReduce framework. Accordingly the method of normalizing may include steps such as creating n tuples representing the data as in disambiguating entities by asserting equivalence relationships between entities in the RDF such that two textual names for the same entity are consolidated into one as in filtering the entities to remove sentences that are known to be non indicative of semantic relationships e.g. headers footers boilerplate language other jargon etc. as in and packaging the RDF into a sequence file as in which is a format that can be input into a MapReduce program. The particular steps of normalizing the RDF for processing may vary when other types of computational frameworks are used.

In the RDF is analyzed to evaluate relative document importance. The results of step may be used in subsequent steps to direct analysis to particularly important documents.

In clusters are identified via semantic analysis e.g. and or syntactic analysis e.g. . For example a document tier such as may utilize semantic analyzer to group entities and or documents based on the semantic relationships in the RDF. The same document tier may utilize syntactic analyzer to group entities and or documents based on the syntactic e.g. sentence overlap relationships between documents in the RDF.

In various embodiments the semantic analysis and syntactic analysis may be performed sequentially in parallel and or iteratively. For example each type of analysis may be implemented by a MapReduce program and executed on a compute cluster such as cluster . The particular workflow used to create the grouping may be parameterized e.g. using a configuration file . Thus an administrator may be able to tweak the method of identifying clusters for different domains and or datasets.

In each cluster is analyzed to calculate per cluster analytics. As described above the analytics may identify important entities relationships and or documents. In some embodiments the analytics may provide summaries of the cluster and or the documents within the cluster. Such summaries may be presented to a user to facilitate speedy understanding of the cluster and its elements. As with any of the analysis steps the per cluster analytics may be calculated in parallel such as by a MapReduce program.

A result of document based resolution method is a semantic database e.g. in RDF where documents have been grouped into semantically relevant clusters. As shown in method the grouping may comprise converting the ingested documents to analyzable RDF and analyzing the RDF through parallel execution e.g. using MapReduce programs .

According to the illustrated embodiment method begins by receiving the RDF of document clusters as in . The RDF may be retrieved from the data access layer where it was stored by the document tier.

In the system decides whether it should apply another inference algorithm in an attempt to infer new relationships in the RDF. The decision may be informed by a static or dynamic schedule which may be specified in the one or more configuration files. As described above a static schedule may dictate a particular workflow of inference engines and or an order in which they are applied. A dynamic schedule may provide parameters for deciding which inference engine to apply next and or the runtime parameters of those inference engines. Such decisions may be based on which inference engines were executed previously and what inferences those previous executions added. For example if no new inferences have been added since the previous execution of a given inference engine then it may not be productive to re execute the same inference engine with the same parameters.

If the system determines that another inference engine should be applied as indicated by the affirmative exit from then the system chooses which inference engine to apply as in and executes that inference engine to generate new relationships as in .

As described above the choice of which inference engine s to apply next and or what parameters to use for each engine may be a product of a static or dynamic schedule defined by the system configuration. By providing customizable configuration administrators may fine tune the system for particular domains. In some instances the system may decide to execute multiple inference engines in parallel.

As described above the particular inference engines to be applied may be domain independent e.g. entity based and or domain dependent. Various examples of such inference engines were described above with relation to .

Once a chosen inference engine has executed the inferred relationships are added to the RDF in . Although the relationship addition step of is illustrated separately from execution step it should be understood that in various embodiments the relationships may be added to the RDF as part of execution step .

Inferred relationships may correspond to those that were not explicit in the ingested documents but which nevertheless could be inferred from the ingested documents. For example if an ingested document includes the sentence Steve works in Chicago the semantic works in relationship between the entities Steve and Chicago is said to be explicit. Explicit relationships may be identified and incorporated into the RDF without an inference engine. However if a group of ingested documents indicate that Terry has been in an office building in Chicago every weekday from morning and until early evening but not on weekends or nights an inference engine e.g. an expert system may be able to infer that Terry works in Chicago. Accordingly the inference engine may create an inferred works in relationship between the entity Terry and the entity Chicago. Such relationships are said to be inferred. 

After the newly inferred relationships have been added as in the method loops back to the decision of whether to apply another inference engine as in . When no more inference engines are to be applied as indicated by the negative exit from inference method ends.

A result of inference method is that the RDF database includes some number of inferred relationships in addition to the explicit ones. Queries to the RDF may therefore rely on explicit and inferred relationships to provide richer more relevant results and deeper analysis than typical keyword searches.

In some embodiments the ingestion clustering and inference methods e.g. may be executed periodically to maintain the semantic database. For example the method may be executed on SIRE compute cluster nightly or on some other schedule. In some embodiments a system administrator may initiate processing of the semantic database i.e. ingestion clustering and or inference on demand.

According to the illustrated embodiment query method begins with the client e.g. receiving a request for data as in . For example the request may be to search for all ingested documents that are relevant to a particular person.

The request may be specified by a user using a graphical user interface. The graphical user interface may be provided as part of a web application e.g. via a browser as part of a stand alone application or through some other means.

In response to receiving the request for data in the client may invoke a semantic search web service as in .

In a server e.g. web server receives the web service invocation sent by the client in . According to the illustrated embodiment the server prepares a query for data in the semantic database that matches the search request as in . The query may be articulated in a structured query language such as SPARQL an RDF query language . The query is then sent to a data access layer e.g. for execution as in .

In the data access layer receives the query and executes it in . The data access layer then returns the results to the server in . The server may subsequently return the results to the client.

In various embodiments query execution in may be handled by a query execution engine. The results obtained from the semantic database may be further processed at any point in the chain of return from the data access layer to the server the client. Such processing may be necessary to repackage the results in a format acceptable to the recipient.

In response to receiving the results of the data request software executing on the client may visualize the results and or otherwise present the results. and illustrate two example visualizations that client software may be configured to present to a user in response to a query.

In various embodiments other types of visualization maybe possible. Co pending U.S. application Ser. No. 13 097 662 provides various other examples of querying retrieving and visualizing semantic data. The contents of application Ser. No. 13 097 662 are incorporated herein by reference.

As shown in computer may include a data processing system . In some embodiments data processing system may include any number of computer processors any number of which may include one or more processing cores. In some embodiments any of the processing cores may be physical or logical. For example a single core may be used to implement multiple logical cores using symmetric multi threading.

Computer also includes network interface for receiving messages e.g. messages transmitted from a clients and transmitting messages over network and a data storage system which may include one or more computer readable mediums. The computer readable mediums may include any number of persistent storage devices e.g. magnetic disk drives solid state storage etc. and or transient memory devices e.g. Random Access Memory .

In embodiments where data processing system includes a microprocessor a semantic inference and reasoning computer program product may be provided. Such a computer program product may include computer readable program code which implements a computer program stored on a computer readable medium . Computer readable medium may include magnetic media e.g. a hard disk optical media e.g. a DVD memory devices e.g. random access memory etc. In some embodiments computer readable program code is configured such that when executed by data processing system code causes the processing system to perform steps described above.

In other embodiments computer may be configured to perform steps described above without the need for code . For example data processing system may consist merely of specialized hardware such as one or more application specific integrated circuits ASICs . Hence the features of the present invention described above may be implemented in hardware and or software. For example in some embodiments the functional tiers described above may be implemented by data processing system executing computer instructions by data processing system operating independent of any computer instructions or by any suitable combination of hardware and or software.

Additionally while the processes described above and illustrated in the drawings are shown as a sequence of steps this was done solely for the sake of illustration. Accordingly it is contemplated that some steps may be added some steps may be omitted the order of the steps may be re arranged and some steps may be performed in parallel.

The semantic inference and reasoning engine SIRE described above offers many novel advantages over traditional systems. SIRE is able to manage the problems of scale in the reasoning process by applying a novel multi tier approach. The multitier approach may include clustering semantically related data artifacts and applying a network of inference engines to each cluster according to a static or dynamic schedule that manages data size maximizes inferences and minimizes error. The disclosed system is therefore uniquely positioned to address the search result problems that arise in cloud and or Internet scale data spaces such as cloud scale reasoning semantic disambiguation of entities search engine enhancement semantic alerts based on incoming data multi granular semantic pattern detection trend analysis intelligence data mining medical diagnosis industrial competitive intelligence analysis social network analysis and other uses.

While various embodiments of the present invention have been described above it should be understood that they have been presented by way of example only and not limitation. Thus the breadth and scope of the present invention should not be limited by any of the above described exemplary embodiments.

As used herein the term semantic representation may refer to any format that indicates entities and relationships. Although many examples are described herein using RDF other semantic representations are possible in different embodiments.

As used herein the term data artifact may be used to refer to any unit of content that can be included in and analyzed as part of the corpus regardless of its particular form. For example the data artifact may be a natural language document e.g. email report or itself a semantic representation.

As used herein the term MapReduce may be used to refer to a family of software frameworks for supporting distributed computing on large datasets according to the MapReduce pattern i.e. distributing and performing work in parallel according to the map and reduce functions known in functional programming . The term MapReduce may refer to any software framework for implementing a MapReduce system such as the open source Hadoop package. Examples of implementing semantic reasoning using a MapReduce framework can be found in co pending U.S. application Ser. No. 13 097 662 which is incorporated in its entirety herein by reference.

