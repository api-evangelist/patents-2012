---

title: Scalable 3-stage crossbar switch
abstract: Systems and methods are presented relating to a three stage crossbar based switching system and a scheduling method for transmission of data packets and associated request and grant tokens. The first stage and third stage portions of the switching system contain TDM crossbars, which are interconnected by a middle stage set of crossbars. In an embodiment, the system switching module is a m×m crossbar switch comprising m inputs and m outputs. The switch has a size m×mformed from m×m crossbar modules. Scheduling of data packet servicing is on a frame by frame basis relating to selection based on port addresses and port address groups. Further, time slot interchange is utilized to address time slot mismatch.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09166928&OS=09166928&RS=09166928
owner: THE HONG KONG UNIVERSITY OF SCIENCE AND TECHNOLOGY
number: 09166928
owner_city: Kowloon
owner_country: HK
publication_date: 20120927
---
This patent application claims priority to U.S. Provisional Patent Application No. 61 541 401 filed on Sep. 30 2011 entitled PGM A SCALABLE 3 STAGE CROSSBAR SWITCH the entirety of which is incorporated herein by reference.

The subject specification relates generally to communication systems and methods and in particular a scalable crossbar based switching system and associated architecture.

A communication router is typically comprised of two parts a modular electronic circuit such as a line card s and an interconnecting architecture such as a switch fabric where the switch fabric provides the interconnecting function for a plurality of line cards. Further to facilitate data communication across a router a variable length data packet s is often divided into fixed length cells in a line card prior to forwarding to a switch and ultimately on to a device associated with the switch e.g. a memory device or other component.

As illustrated in in a shared memory switch the port processor on line card writes data packet s into and reads data packet s from memory where memory is shared by all the port processors via lines e.g. a serial link comprising the switch architecture . A problem with a switch architecture of this nature is that memory must operate at a speed M times the link rate to satisfy the demand s placed on memory by any or all of line cards and or port processors where M is the number of input output ports of the switch. As the required M increases e.g. more line cards added constructing memory becomes costly. Further the power consumption of moving data packets in and out of a shared memory switch is also high.

A crossbar based switch system as illustrated in comprises a plurality of line cards A Y and respective port processors A Y connected to a crossbar switch and a scheduler with multiple m m m inputs and m outputs data lines heavy line running in parallel and control lines narrow line running in parallel. Data packets are transmitted between port processors to crossbar switch via data lines paths are typically called the data path and control packets are exchanged between port processors and scheduler paths are typically called the control path where request s received at and grant s generated by scheduler are utilized to control transmission of respective data packets across any of data paths . Typically the bandwidth requirement for a data path will be much greater than for a control path . With a crossbar based switch when a data packet arrives at a line card for transport by crossbar switch a request token is sent to scheduler by a port processor . A request by a particular output port processor e.g. any of is recorded in a counter inside scheduler . Once scheduling is determined scheduler returns a grant token to the requesting port processors via the control path. Upon receipt of a grant token a port processor transmits a data packet s corresponding to a destination in crossbar switch defined in the received grant token . In general with a crossbar switch system data packet s will be moved in and out of the port processor at a speed comparable to the link rate supportable on data lines . In contrast a shared memory switch as illustrated in has to move data in and out of port processor at a speed M times the link rate. Typically crossbar switches do not buffer data packets and comprise minimal logic. Hence a crossbar switch consumes significantly less power than a shared memory switch.

However single stage switches have a scalability problem. Every line card in a single stage switch architecture requires at least one high speed link terminating on a shared memory chip or a crossbar chip or the scheduler chip but the number of high speed serial links is limited by available technology.

In response to the scalability problem 3 stage switches have been proposed as a possible solution. illustrates a switch using a three stage Benes Clos topology. Adoption of Benes topology in 3 stage switches enables the construction of an m m minput ports and moutput ports switch out of single stage switch modules of size m m. Conventionally crossbar based architectures have limited if any application in 3 stage switches because there is no simple way to design a scheduler able to control traffic over the respective crossbar switches. Commercial 3 stage products such as routers provided by JUNIPER and CISCO are all based on a shared memory architecture e.g. a buffered network . However a buffered approach can lead to out of sequence transmissions over a 3 stage switching fabric because there are m m N paths in the switch and data packets are randomly routed through these paths. Attempting to re sequence packets at 40 or even 100 Gbps can be a substantial task. To overcome the random routing of data packets a large amount of memory for data packet re sequencing is required. Furthermore a buffered architecture also has a problem with high power consumption and is not compatible with optical switching technologies where such optical switching technologies are un buffered in nature.

Some multiple stage crossbar switches have been proposed to address the foregoing issues. In one instance an optical banyan network has been proposed as a packet switch for local area networks LANs . Since a banyan network is non blocking for a round robin RR connection pattern a time division multiplexing TDM banyan network can be utilized where each input is connected to all outputs in a round robin manner. While a scheduler component is not required for such a TDM banyan network a problem with this approach is that a TDM crossbar has poor performance unless traffic is uniformly distributed among the outputs which is generally not the case in a packet network. Further a cascade approach comprising two TDM crossbars with virtual output queue VOQ buffers inserted therebetween has been proposed in the load balanced switch. The first TDM crossbar evenly distributes packets to its output ports and creates a uniform traffic pattern for the second TDM crossbar. The cascade approach addresses a problem with an assumption of invalid uniform traffic. However the cascade approach creates out of sequence transmissions in a similar manner to that of a buffered multi stage switch. Hence packet re sequencing at the speed of 100 Gbps may be as challenging as designing the scheduler for a large switch.

The following discloses a simplified summary of the specification in order to provide a basic understanding of some aspects of the specification. This summary is not an extensive overview of the specification. It is intended to neither identify key or critical elements of the specification nor delineate the scope of the specification. Its sole purpose is to disclose some concepts of the specification in a simplified form as a prelude to the more detailed description that is disclosed later.

The various exemplary non limiting embodiments presented herein relate to a three stage crossbar based switching system and a scheduling method for transmission of data packets and associated request and grant tokens. The switching system comprises a plurality of line cards and associated port processors at least one scheduler and a switch fabric comprising respective first second middle and third stages with each stage comprising at least one switch. The first stage and third stage portions of the switching system contain TDM crossbars which are interconnected by a middle stage set of crossbars. In an exemplary non limiting embodiment the fundamental switching module of the system is an m m crossbar switch where the crossbar switch comprises m inputs and m outputs . Hence in a further exemplary non limiting embodiment the various aspects presented herein facilitate construction of a switch with the size m mout of the basic m m crossbar modules while achieving very high data packet throughput in the order of 100 .

A further exemplary non limiting embodiment relates to design of a scheduler for the three stage crossbar based switching system. In an aspect scheduling of data packet servicing is performed in a frame by frame basis. In a further exemplary non limiting embodiment for any given slot in a frame the scheduling consists of two phases. During the first phase matching is performed between groups of input ports ports are divided into m groups and m ports in each group and groups of output ports. As presented herein the various embodiments enable construction of a scheduler having much lower complexity than that of a conventional scheduler constructed to perform port scheduling. During the second phase the port address of each port group is selected. Both the first phase and the second phase are performed by a scheduler associated with the second stage switches.

A further exemplary non limiting embodiment relates to design of the crossbar system. A TSI time slot interchange of m memory slots m is the frame size is added to each input link of the crossbar. Utilizing a TSI prevents potential problems regarding time slot mismatch created during the group matching performed by a scheduler of the second stage.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It can be evident however that the claimed subject matter can be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

The subject innovation presents various systems and methods relating to a switching system that while being scalable also addresses issues relating to simple scheduler design out of sequence transmissions etc. encountered with conventional approaches as described in the Background. By utilizing a switch comprising a first stage set of crossbar switches a third stage set of crossbar switches and a second stage set of crossbar switches with schedulers a system fabric topology can be designed to facilitate highly efficient transmission and receipt of requests and grants for data packet transfer and thus a corresponding efficiency in transfer of data packets. By utilizing a simple approach to facilitate determination by a scheduler of a data path to be utilized to transfer a data packet a data path can be readily identified the data packet transferred with minimal impact on decision making regarding defining a transmission path for a subsequent data packet to use.

As previously mentioned an incoming data packet can be subdivided chopped into a plurality of data packets or cells having a fixed length where such subdivision can be performed prior to submission of the data packet to the switch fabric e.g. by a line card port processor. The various exemplary non limiting embodiments presented herein operate in a cell mode i.e. all data packets being transmitted through the switch fabric have the same packet length while the terms packet data packet and cell are used interchangeably herein. By utilizing data packets of defined length the data packets can be efficiently directed to a plurality of switches for final recombination at a third stage switch as necessary.

It is to be appreciated that the terms second stage and middle stage are used interchangeably throughout to present elements relating to operation of crossbar switches schedulers counters etc. Mx 2 etc. associated with switches operating in the second middle stage of system to indicate components operations being undertaken between the middle stage and either of the first stage or the second stage.

Further as previously mentioned with regard to operation of the crossbar based switch illustrated in port processors e.g. A Y act as the interface between respective line cards e.g. A Y and the switch fabric e.g. and . Port processors receive cells from line cards and send request tokens e.g. essentially short control packets to the scheduler e.g. . Grant tokens e.g. are returned by the scheduler after scheduling is performed. As previously mentioned scheduler and links utilized for transmission of request tokens and grant tokens are referred to as the control path and the crossbars and links for transmitting data packets are called the data path . Typically the bandwidth of a control path is only a fraction that of a data path.

Returning to the illustrated traffic pattern at switch comprises of traffic at an input port being evenly spread amongst all the output ports as indicated by traffic e.g. 0.15a 0.15b 0.15c and 0.15d at the third input port which means that 15 of traffic goes to output a b c and d respectively. Thus traffic is equally distributed amongst the output ports A D the so called o uniform pattern. For such traffic pattern as shown in system round robin scheduling can be utilized as an input port e.g. will be connected to all output ports e.g. A D with the same level of preference across all of the output ports. This approach results in the provision of a time division multiplexing TDM crossbar with a round robin connection pattern. This TDM crossbar does not require a scheduler component. illustrates an exemplary non limiting embodiments of a 4 4 TDM crossbar e.g. any of configurations A D of which the interconnection pattern of each slot can be described as shown in equation 1 

where m is the TDM frame size and k where k 0 k m 1 is the slot number within a frame e.g. for a frame size of m 4 then k 0 3 .

However as illustrated in the exemplary non limiting embodiment presented in a different form of uniform traffic flow can be configured in comparison with the conventional o uniform approach illustrated in . illustrates a switch where all input ports have identical traffic patterns. In the four outputs are a b c d and the load on each link is the same 0.1a 0.24b 0.15c 0.2d indicating 10 of all traffic goes to output a 24 goes to output b 15 goes to output c and 20 goes to output d. From an output port s perspective e.g. any of output ports A D all of the traffic being subsequently forwarded by an output port is uniformly distributed among all input ports. To provide distinction between the respective approaches depicted in the conventional uniform traffic pattern illustrated in as previously mentioned is termed herein o uniform indicating the traffic is uniformly spread to the outputs ports. While the pattern illustrated in is termed herein i uniform indicating traffic destined for an output is uniformly spread among all input ports. An i uniform traffic pattern also means that

A TDM crossbar can also be utilized where traffic is i uniform. Hence a switch circuit can be constructed comprising TDM crossbar switches in situations where i uniform and o uniform circumstances exist as described further herein.

In the exemplary non limiting embodiment each link input link and or output link is specified by a two tuple address group member . The group address is the number or address of the crossbar to which the link is attached and the member address is the link address within the crossbar. It is to be noted that the input link i j and output link i j are connected to the same port where each port has one input link going into a switch and one output link coming from the switch so that it can send traffic to other ports as illustrated in port and switch .

Operation of a first stage crossbar e.g. any of Mx 1 and a third stage crossbar e.g. any of Mx 3 in system can be defined with reference to according to the following properties and proofs 

Property 1 In a three stage Benes Clos network the traffic pattern of a first stage crossbar switch can be treated as o uniform.

Proof 1 The function of a first stage crossbar e.g. any of the switches Mx 1 in the vertical column under First Stage illustrated in is to distribute traffic evenly to middle stage crossbars e.g. any of the switches Mx 2 in the vertical column under Second Stage .

Property 2 In a three stage Benes Clos network the traffic pattern of a third stage crossbar switch can be treated as i uniform.

Proof 2 The input patterns of any two switches A and B are said to be link by link identical if the i th input link of switch A carries the same traffic pattern as the i th input or output link of switch B. The same definition can also be used for describing the output traffic patterns of a pair of switches. As shown with reference to the function of a first stage switch e.g. M0 1 is distributing traffic equally to each of the second stage switches e.g. equally amongst M0 2 M1 2 M2 2 and M3 2 as indicated by the unbroken linkage line. The traffic patterns of its output links are identical. These output links are distributed to middle stage switches at the same location. Thus the input traffic patterns of any two middle stage switches are link by link identical. All schedulers of the second stage use the same scheduling algorithm. Thus the output traffic patterns of any two middle stage switches are also link by link identical. By the connection pattern of the switch this implies that all input links of any third stage switch have identical traffic pattern. By definition this means that the traffic pattern of a third stage switch is i uniform.

Therefore both the first stage switches e.g. Mx 1 and the third stage switches e.g. Mx 3 of system can be implemented with TDM crossbars with a frame size m . The first stage and the third stage TDM crossbars are interconnected with the middle stage crossbars where a scheduling function matches requests between port groups e.g. with each crossbar in the first stage or the third stage representing a port group as opposed to requests solely between ports. Further the group matching is performed by all of the schedulers comprising middle stage switches e.g. respective schedulers associated with each of Mx 2 operating in parallel. The operation of switch matching by group in a parallel fashion is termed herein a parallel group matching PGM switch.

It is to be appreciated that the PGM switch depicted in has mports but only m port groups. For example 4 input switches e.g. M0 1 M1 1 M2 1 and M3 1 with a total of 16 input links or 4 output switches e.g. M0 3 M1 3 M2 3 and M3 3 with a total of 16 output links. In another aspect the group size does not have to be m. For example for a 16 16 switch a group size 4 can be selected and has a corresponding member address between 0 3. However it is also possible to select a group size of 8 resulting in two groups each with a member address of 0 7. Hence the various embodiments presented herein are not restricted to a group size of m but other group sizes are equally applicable. Accordingly by virtue of operation of a PGM switch the complexity of the matching algorithm in a PGM switch is much less than the complexity of the matching algorithm for a single stage m mcrossbar.

The first stage schedulers as described further herein with reference ti component s are just TDM crossbars. The core of a PGM architecture is its second stage scheduler s . A conventional scheduler of a crossbar requires Vvirtual output queue VOQ counters where V is the size of the switch. In the implementation of system the operation of the schedulers e.g. any of Sch  in the first stage is straightforward. The function of a Sch  scheduler is to distribute the request tokens evenly to the second stage schedulers e.g. any of respective Sch  and to relay grant tokens returned from the second stage schedulers back to the port processors associated with the Sch  scheduler. Such operation can be performed utilizing just two TDM crossbars a first TDM crossbar for distributing requests and a second TDM crossbar for relaying grants. Such operation results in a port only being able to perform either of dispatch a request token to or receive a grant token from a second stage scheduler in any given frame. However owing to there being a plurality m schedulers e.g. M0 2 to M3 2 in the second stage operating in parallel a port processor associated with a line card can process up to m request tokens and or grant tokens for any destination port within one frame of operation.

With reference to the function of the third stage scheduler can be incorporated into the function of a first stage scheduler illustrated in . Note that as in the respective schedulers can be integrated into their corresponding data path crossbars. For example any of first stage schedulers Sch  integrated with Mx 1 or second stage schedulers Sch  integrated with Mx 2.

In any of the links between a crossbar switch in one stage and crossbar switch in another are utilized to carry request tokens and grant tokens as presented in . Hence any link e.g. link is identified can be utilized to convey a request token between a first stage crossbar switch e.g. switch and a second stage crossbar switch e.g. switch . Similarly a link can be utilized to transport a grant token between a second stage crossbar switch e.g. switch and a first stage crossbar switch e.g. switch . Further to facilitate understanding of various concepts herein a plurality of line cards and are shown interfacing with switch while each line card has a port processor and respectively associated therewith. Further each switch comprising the first stage has an associated scheduling processor and each switch comprising the second stage has an associated scheduler component and counter component and .

An exemplary non limiting operation of a second stage scheduler depicted in is further described. As part of a VOQ implementation the number of request tokens for each input output ij combination is recorded in a separate VOQ counter which can reside in a scheduler e.g within scheduler . Accordingly a middle stage scheduler comprises m m m VOQ counters.

An exemplary non limiting embodiment for a middle stage scheduler is illustrated in B and C. B and C depict an exemplary non limiting embodiment as further described below where A depicts a high level view of a Port request bit map array comprising mblocks which in this embodiment m 4 and labeled B B. depicts the mblock array further broken down into blocks comprising m m inputs and outputs for each block B B where exemplary counter bit ris identified. Further depicts a Group request bit map block comprising a plurality of counter bits either in a nonzero state darkened or a zero state.

The scheduling operation is performed on a frame by frame basis. For each slot in a frame scheduling comprises of two phases 

Phase 1 A matching algorithm uses s to perform group matching for example to establish up to m connections between input groups and output groups i.e. between a first stage and a third stage crossbar . The complexity of a matching algorithm to perform Phase 1 is much lower than that required for a single stage crossbar because the size of a group to be matched by matching algorithm is only m m compared with a m mgroup as utilized in a conventional switch such as using Benes topology for example.

Phase 2 The matching algorithm uses r to perform member selection selecting m input ports and m output ports to use the connection established during Phase 1. In an exemplary scenario a connection is set up for input group i and output group j during Phase 1. Then any nonzero element in the block B e.g. block B can be selected to use this connection where Bis a subset of r that consists of all request bits from input group i to output group j. Continuing the exemplary scenario bit rof B e.g. bit rof B is selected to use the connection. Such selection results in input f and output g not being able to be selected again within the same frame. This leads to the entire row f and the entire column g in r to be blocked during the remaining slots of the current frame.

At the end of Phase 2 a grant token carrying i the destination port address and ii the slot number during which the matching is performed will be sent back by the scheduler to the selected input port.

A concern when designing switching systems is the provision of short term fairness in responding equally to requests e.g. request token pertaining to input ports or output ports even where fairness can be maintained over the long term.

As previously mentioned B e.g. any subblock B contains melements. Each row in subblock Brepresents an input port and each column in subblock Brepresents an output port. Hence with a system comprising m 4 switches subblock Bcomprises m 16. Simply selecting an element from Bin a row by row manner or column by column manner does not provide the required short term fairness for input ports or output ports although long term fairness can be maintained. To address this issue a two dimensional round robin scheme can be utilized as described further below.

In an exemplary non limiting embodiment as illustrated in elements comprising a block can be further divided into frames. The total melements in B e.g. elements comprising block can be divided into m segments and also referred to as frames where each segment comprises m elements. For example the first segment comprises elements 0 0 1 1 2 2 3 3 which as depicted in both the first segment and only comprises the diagonal elements of B. If one element is selected from segment from top to bottom each input and each output e.g. each row and column comprising will only be selected once in m slots. Left shifting the elements of first segment leads to the second segment . By repeating the left shifting operation m 1 times e.g. to advance through each of segments each and every segment comprising all of the m segments of Bare selected. Selecting an element in Bis performed in a sequential segment by segment manner and within each segment with the selection being performed in a top to bottom manner. The approach is in effect is a two dimensional round robin approach and can maintain short term fairness in selecting a VOQ counter for using a connection established during the first phase of the scheduling.

In one TDM frame a port processor can receive up to m grant tokens e.g. grant token for the same destination e.g. a port on a third stage switch from a plurality of different schedulers. A port processor has to determine the order in which the grant tokens are serviced to ensure that cells arrive at the output port in order. Assume that the member field address of a destination port address is k where 0 k m 1. By virtue of the topology of the Benes Clos network as previously described with reference to and the round robin scheme used by the data TDM crossbars as illustrated in cells data packets destined for output address k from the m middle stage switches will be in accordance with the sequence presented in Equation 2 1 mod 2 mod . . . 1 mod 2 

Each number above represents the crossbar number in the middle stage. The selection of grant tokens with destination k issued by different middle stage schedulers is to follow the order of Equation 3 below.

In an exemplary non limiting embodiment a grant token e.g. grant token can include a the destination port address and b the slot number during which the matching is performed. Suppose a grant token with destination j slot number is sent to input port i by a middle stage scheduler e.g. scheduler . This means that this data cell should arrive at the corresponding middle stage switch in slot of the coming frame. However due to the connection pattern of a round robin crossbar input i and output j may not be connected to the second stage switch during slot of the next frame. The lack of concurrent connection can give rise to a problem of time slot mismatch.

As shown in the exemplary non limiting embodiments illustrated in a time slot mismatch can be addressed with a time slot interchange TSI with m memory slots m is the RR frame size as previously discussed with reference to is added to each input link of a second stage switch e.g. any switch Mx 2 illustrated in and switches comprising the second stage in system . A TSI is a two port e.g. and memory device that can support read and write operations simultaneously. The various exemplary non limiting embodiments herein can support random write and sequential read operations. An incoming cell e.g. received on or associated with crossbar includes a slot number inside the grant. TSI control hardware will write the cell into the corresponding slot. It will then be read out during the same slot of the incoming frame. It is to be appreciated that the speed of the TSI is the same as the link speed while the speed of the memory used in a shared memory switch is m times the link speed.

In another exemplary non limiting embodiment another TSI can be added to each link of a third stage data crossbar. As mentioned previously all second stage schedulers work independently and the scheduled cells will not collide at the destination. This is because each middle stage scheduler can issue to an input port only one grant destined for a particular output port in a frame. In total there can be at most m such grants issued to an input port by the m middle stage schedulers. The m corresponding data cells will arrive from m different middle stage switches. But based on the round robin pattern the destination output can only be connected to a middle stage switch in a specific slot. This slot may be different from the slot carried by the grant token. This is again a slot mismatched problem. By adding a TSI to each link of a third stage switch the problem of time slot mismatch is solved.

where 1 is the middle stage switch that sends back the grant token and k is the member field of the destination address. With TSIs added to the data crossbars all second stage schedulers can operate independently and in parallel with destination collisions no longer being a concern. As illustrated in an exemplary non limiting embodiment illustrated in a data packet or cell can comprise of the following format and components data a port address a third stage slot number and a second stage or middle stage slot number . As shown in the two TSI slot numbers and are carried in the cell header.

An exemplary non limiting embodiment for time slot matching is illustrated in . As shown a data packet is conveyed through the switching system which is a 16 16 switch with frame size 4. The input ports and output ports are numbered from 0 to 15. The input port of the data packet is 1 and output port is 2. The grant signal for this packet is sent by switch of the second stage switch . Further The scheduler at the second stage matches input port with output port for conveyance of data packet and the slot number during which the matching was performed is 2. Therefore the slot number field in will be set to 2. The slot number for the third stage i.e. filed 830 will be computed with Eq. 3. In this case k 2 1 2. Thus the slot number 0.

At a third stage of the three stage switching circuit is defined wherein one or more switches are configured to be a time division multiplexing TDM crossbar e.g. any of switches Mx 3 illustrated in . As mentioned previously owing to the one or more switches can be configured as i uniform owing to the traffic pattern of a switch in the third stage for an output port is uniformly spread among all of the input ports per .

At a middle stage or second stage of the three stage switching circuit is defined wherein the middle stage comprises one or more switches e.g. any of switches Mx 2 illustrated in which are located to receive data packets and requests from one or more switches comprising the first stage forward the data packets to the one or more switches comprising the third stage and transmit grants to the one or more switches in the first stage. The one or more switches in the middle stage are crossbar switches.

At a scheduler e.g. scheduler associated with the one or more middle stage switches is configured to facilitate transmission of the data packets through the switching circuit.

At in an embodiment the scheduler can receive requests e.g. for processing from one or more first stage switches.

At determine a processing schedule and data path for processing of the data packet associated with the request s .

At based on a determined processing schedule and data path for conveyance of the data packets generate request grants e.g. to comprising instruction for one or more first stage switches to forward packet data across the three stage switching circuit.

At for a given output port a two tuple address group member is assigned. The group address is the address of the third stage switch e.g. any of Mx 3 to which the output port belongs and the member is the address of the link within the third stage switch to which the output port is connected.

At for each slot e.g. slots in a frame a second stage scheduler e.g. any scheduler associated with Mx 2 will execute a matching algorithm to identify at most m input group output group pairs where an input group and output group can only appear once and m is the number of groups.

At an input member from each input group is identified and an output member from each input group output group pair is also identified.

At a grant token is generated comprising the input and output port addresses and the slot number during which the grant is issued.

At the grant token is sent to the input port. As mentioned the input and output port selected in step will not be selected again by the second stage scheduler which issued the grant until the beginning of the next frame. Flow returns to for identification of another input group output group pairing.

In addition it should be appreciated that while the methodologies provided above are shown and described as a series of acts for purposes of simplicity such methodologies are not limited by the order of acts as some acts can in accordance with one or more aspects occur in different orders and or concurrently with other acts from that shown and described herein. For example those skilled in the art will understand and appreciate that a methodologies could alternatively be represented as a series of interrelated states or events such as in a state diagram. Moreover not all illustrated acts may be required to implement a methodology in accordance with one or more aspects.

As used in this application the terms component system platform layer controller terminal station node interface are intended to refer to a computer related entity or an entity related to or that is part of an operational apparatus with one or more specific functionalities wherein such entities can be either hardware a combination of hardware and software software or software in execution. For example a component can be but is not limited to being a process running on a processor a processor a hard disk drive multiple storage drives of optical or magnetic storage medium including affixed e.g. screwed or bolted or removably affixed solid state storage drives an object an executable a thread of execution a computer executable program and or a computer. By way of illustration both an application running on a server and the server can be a component. One or more components can reside within a process and or thread of execution and a component can be localized on one computer and or distributed between two or more computers. Also components as described herein can execute from various computer readable storage media having various data structures stored thereon. The components may communicate via local and or remote processes such as in accordance with a signal having one or more data packets e.g. data from one component interacting with another component in a local system distributed system and or across a network such as the Internet with other systems via the signal . As another example a component can be an apparatus with specific functionality provided by mechanical parts operated by electric or electronic circuitry which is operated by a software or a firmware application executed by a processor wherein the processor can be internal or external to the apparatus and executes at least a part of the software or firmware application. As yet another example a component can be an apparatus that provides specific functionality through electronic components without mechanical parts the electronic components can include a processor therein to execute software or firmware that provides at least in part the functionality of the electronic components. As further yet another example interface s can include input output I O components as well as associated processor application or Application Programming Interface API components. While the foregoing examples are directed to aspects of a component the exemplified aspects or features also apply to a system platform interface layer controller terminal and the like.

What has been described above includes examples of the subject innovation. It is of course not possible to describe every conceivable combination of components or methodologies for purposes of describing the disclosed subject matter but one of ordinary skill in the art may recognize that many further combinations and permutations of the subject innovation are possible. Accordingly the disclosed subject matter is intended to embrace all such alterations modifications and variations that fall within the spirit and scope of the appended claims.

In particular and in regard to the various functions performed by the above described components devices circuits systems and the like the terms including a reference to a means used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. a functional equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary aspects of the disclosed subject matter. In this regard it will also be recognized that the disclosed subject matter includes a system as well as a computer readable medium having computer executable instructions for performing the acts and or events of the various methods of the disclosed subject matter.

In addition while a particular feature of the disclosed subject matter may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes and including and variants thereof are used in either the detailed description or the claims these terms are intended to be inclusive in a manner similar to the term comprising .

As used herein the terms to infer and inference refer generally to the process of reasoning about or inferring states of the system environment and or user from a set of observations as captured via events and or data. Inference can be employed to identify a specific context or action or can generate a probability distribution over states for example. The inference can be probabilistic that is the computation of a probability distribution over states of interest based on a consideration of data and events. Inference can also refer to techniques employed for composing higher level events from a set of events and or data. Such inference results in the construction of new events or actions from a set of observed events and or stored event data whether or not the events are correlated in close temporal proximity and whether the events and data come from one or several event and data sources.

In addition the term or is intended to mean an inclusive or rather than an exclusive or. That is unless specified otherwise or clear from the context the phrase X employs A or B is intended to mean any of the natural inclusive permutations. That is the phrase X employs A or B is satisfied by any of the following instances X employs A X employs B or X employs both A and B. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from the context to be directed to a singular form.

Furthermore the term set as employed herein excludes the empty set e.g. the set with no elements therein. Thus a set in the subject disclosure includes one or more elements or entities. As an illustration a set of controllers includes one or more controllers a set of data resources includes one or more data resources etc. Likewise the term group as utilized herein refers to a collection of one or more entities e.g. a group of nodes refers to one or more nodes.

In this application the word exemplary is used to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion.

