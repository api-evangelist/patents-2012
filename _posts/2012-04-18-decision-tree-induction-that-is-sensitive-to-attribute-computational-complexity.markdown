---

title: Decision tree induction that is sensitive to attribute computational complexity
abstract: A decision tree for classifying computer files is constructed. Computational complexities of a set of candidate attributes are determined. A set of attribute vectors are created for a set of training files with known classification. A node is created to represent the set. A weighted impurity reduction score is calculated for each candidate attribute based on the computational complexity of the attribute. If a stopping criterion is satisfied then the node is set as a leaf node. Otherwise the node is set as a branch node and the attribute with the highest weighted impurity reduction score is selected as the splitting attribute for the branch node. The set of attribute vectors are split into subsets based on their attribute values of the splitting attribute. The above process is repeated for each subset. The tree is then pruned based on the computational complexities of the splitting attributes.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08495096&OS=08495096&RS=08495096
owner: Symantec Corporation
number: 08495096
owner_city: Mountain View
owner_country: US
publication_date: 20120418
---
This application is a continuation of prior application Ser. No. 12 560 298 filed Sep. 15 2009 which is incorporated by reference herein.

The disclosure generally relates to the field of computer science in particular to decision tree induction for purposes including identifying rules for detecting malicious software.

A wide variety of malicious software malware can attack modern computers. Malware threats include computer viruses worms Trojan horse programs spyware adware crimeware and phishing websites. Malicious entities sometimes attack servers that store sensitive or confidential data that can be used to the malicious entity s own advantage. Similarly other computers including home computers must be constantly protected from malicious software that can be transmitted when a user communicates with others via electronic mail when a user downloads new programs or program updates and in many other situations. The different options and methods available to malicious entities for attack on a computer are numerous.

Conventional techniques for detecting malware such as signature string scanning are becoming less effective. Modern malware is often targeted and delivered to only a relative handful of computers. For example a Trojan horse program can be designed to target computers in a particular department of a particular enterprise. Such malware might never be encountered by security analysts and thus the security software might never be configured with signatures for detecting such malware. Mass distributed malware in turn can contain polymorphisms that make every instance of the malware unique. As a result it is difficult to develop signature strings that reliably detect all instances of the malware.

Newer techniques for detecting malware apply rules that make an inference about whether a target computer file is malicious by examining attributes of the target file. The rules are typically derived from decision trees that are developed using decision tree induction algorithms which develop decision trees based on attributes of a training set. The cost associated with determining an attribute value often referred to as the computational complexity of the attribute varies among the attributes used in the decision trees. For example it is less expensive to determine if a file is digitally signed than it is to monitor some aspect of its run time behavior. Existing decision tree induction algorithms do not take into account such complexity in constructing decision trees and assume that all attributes are equally accessible. Therefore the decision trees generated by the existing induction algorithms may rely heavily on a few attributes that are effective but very expensive to determine thereby causing the system performance to suffer. Accordingly there is a need for techniques that can construct decision trees taking into account computational complexity of attributes used in the decision trees.

Embodiments of the present disclosure include methods and corresponding systems and computer program products for constructing a decision tree that takes into account attribute computational complexity.

One aspect of the present disclosure is a computer implemented method for constructing a decision tree for classifying computer files that takes into account computational complexities of attributes of the files comprising creating a plurality of attribute vectors for a plurality of training files of known classification each attribute vector comprising values of a predetermined set of attributes for an associated training file determining a complexity score for each attribute in the predetermined set of attributes the complexity score measuring a cost associated with determining a value of an associated attribute for a file and growing a decision tree based on the plurality of attribute vectors comprising 1 setting the plurality of attribute vectors as a current set 2 determining a weighted impurity reduction score for at least one attribute of the predetermined set of attributes based on the complexity score of the attribute the weighted impurity reduction score quantifying a cost benefit tradeoff for an associated attribute in classifying the current set 3 selecting a splitting attribute from the at least one attribute of the predetermined set of attributes 4 splitting the current set into subsets using the splitting attribute and 5 repeating steps 2 through 4 for each of the subsets as the current set.

Another aspect of the present disclosure is a computer system for constructing a decision tree for classifying computer files that takes into account computational complexities of attributes of the files comprising a computer readable storage medium comprising executable computer program code for an attribute complexity determination module for creating a plurality of attribute vectors for a plurality of training files of known classification each attribute vector comprising values of a predetermined set of attributes for an associated training file and determining a complexity score for each attribute in the predetermined set of attributes the complexity score measuring a cost associated with determining a value of an associated attribute for a file and a decision tree construction module for growing a decision tree based on the plurality of attribute vectors comprising 1 setting the plurality of attribute vectors as a current set 2 determining a weighted impurity reduction score for at least one attribute of the predetermined set of attributes based on the complexity score of the attribute the weighted impurity reduction score quantifying a cost benefit tradeoff for an associated attribute in classifying the current set 3 selecting a splitting attribute from the at least one attribute of the predetermined set of attributes 4 splitting the current set into subsets using the splitting attribute and 5 repeating steps 2 through 4 for each of the subsets as the current set.

Still another aspect of the present disclosure is a computer readable storage medium encoded with executable computer program code for constructing a decision tree for classifying computer files that takes into account computational complexities of attributes of the files the computer program code comprising program code for creating a plurality of attribute vectors for a plurality of training files of known classification each attribute vector comprising values of a predetermined set of attributes for an associated training file determining a complexity score for each attribute in the predetermined set of attributes the complexity score measuring a cost associated with determining a value of an associated attribute for a file and growing a decision tree based on the plurality of attribute vectors comprising 1 setting the plurality of attribute vectors as a current set 2 determining a weighted impurity reduction score for at least one attribute of the predetermined set of attributes based on the complexity score of the attribute the weighted impurity reduction score quantifying a cost benefit tradeoff for an associated attribute in classifying the current set 3 selecting a splitting attribute from the at least one attribute of the predetermined set of attributes 4 splitting the current set into subsets using the splitting attribute and 5 repeating steps 2 through 4 for each of the subsets as the current set.

The features and advantages described in the specification are not all inclusive and in particular many additional features and advantages will be apparent to one of ordinary skill in the art in view of the drawings specification and claims. Moreover it should be noted that the language used in the specification has been principally selected for readability and instructional purposes and may not have been selected to delineate or circumscribe the disclosed subject matter.

The Figures FIGS. and the following description describe certain embodiments by way of illustration only. One skilled in the art will readily recognize from the following description that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles described herein. Reference will now be made in detail to several embodiments examples of which are illustrated in the accompanying figures. It is noted that wherever practicable similar or like reference numbers may be used in the figures and may indicate similar or like functionality.

The client system is an electronic device that can host malicious software. In one embodiment the client system is a conventional computer system executing for example a Microsoft Windows compatible operating system OS Apple OS X and or a Linux distribution. In another embodiment the client system is another device having computer functionality such as a personal digital assistant PDA mobile telephone video game system etc. The client system typically stores numerous computer files that can host malicious software.

Malicious software sometimes called malware is generally defined as software that executes on the client system surreptitiously or that has some surreptitious functionality. Malware can take many forms such as parasitic viruses that attach to legitimate files worms that exploit weaknesses in the computer s security in order to infect the computer and spread to other computers Trojan horse programs that appear legitimate but actually contain hidden malicious code and spyware that monitors keystrokes and or other actions on the computer in order to capture sensitive information or display advertisements.

The client system executes a security module for detecting the presence of malware. The security module can be for example incorporated into the OS of the computer or part of a separate comprehensive security package. In one embodiment the security module is provided by the entity that operates the security system . The security module can communicate with the security system via the network for classification logic e.g. a decision tree for determining whether a file is malware.

The security module determines whether a file is malicious by traversing a decision tree. A decision tree is a classifier in the form of a tree structure that includes branch nodes and leaf nodes. Each branch node specifies an attribute splitting attribute and a test splitting test to be carried out on the value of the splitting attribute and branches out to other nodes for all possible outcomes of the splitting test. The branch node that is the root of the decision tree is called the root node. Each leaf node represents a classification e.g. whether a file is malware or legitimate file . The leaf nodes can also contain additional information about the represented classification such as a confidence score that measures a confidence in the represented classification i.e. the likelihood of the classification being accurate . For example the confidence score can be a continuous value ranging from 0 to 1 which a score of 0 indicating a very low confidence e.g. the indication value of the represented classification is very low and a score of 1 indicating a very high confidence e.g. the represented classification is almost certainly accurate . A file can be classified by traversing down the decision tree based on outcomes of the splitting tests of the branch nodes on the path until a leaf node is reached which provides a classification of the file. The decision tree can be received from the security system .

The security system is a hardware device and or software program configured to construct or induce a decision tree for deciding whether a file is malware and provide the generated decision tree to the client systems . An example of the security system is a web based system providing security software and services allowing the security module to detect and remediate malware on the client systems .

The security system constructs the decision tree based on attribute values of a set of training files known to be legitimate or malware. Examples of the attributes include the existence of digital signature whether the file displays a visible window whether the file attempts to modify the hosts file whether the file makes a specific application programming interface API call and whether the file attempts to access the network . To simplify the issue the values of all attributes are assumed to be binary even though the present disclosure also works with non binary attributes.

There is a cost associated with determining the value of an attribute also called attribute value for a computer file. Such cost hereinafter called the computational complexity of the underlying attribute varies among attributes. For example it is less expensive e.g. consumes less time to determine whether an application is digitally signed than it is to monitor some aspect of its run time behavior such as whether the file attempts to modify the hosts file. This is because the former can be performed without executing the application while the latter involves waiting for the application to do something. The security system takes into account the computational complexity of the attributes in constructing the decision tree by requiring that a more expensive attribute be used as a splitting attribute only if its benefits sufficiently outweigh the benefits of using a less expensive attribute.

The network enables communications between the client system and the security system . In one embodiment the network uses standard communications technologies and or protocols. Thus the network can include links using technologies such as Ethernet 802.11 worldwide interoperability for microwave access WiMAX 3G digital subscriber line DSL asynchronous transfer mode ATM InfiniBand PCI Express Advanced Switching etc. Similarly the networking protocols used on the network can include multiprotocol label switching MPLS the transmission control protocol Internet protocol TCP IP the User Datagram Protocol UDP the hypertext transport protocol HTTP the simple mail transfer protocol SMTP the file transfer protocol FTP etc. The data exchanged over the network can be represented using technologies and or formats including the hypertext markup language HTML the extensible markup language XML etc. In addition all or some of links can be encrypted using conventional encryption technologies such as secure sockets layer SSL transport layer security TLS virtual private networks VPNs Internet Protocol security IPsec etc. In another embodiment the entities can use custom and or dedicated data communications technologies instead of or in addition to the ones described above. Depending upon the embodiment the network can also include links to other networks such as the Internet.

The entities shown in are implemented using one or more computers. is a high level block diagram illustrating an example computer . The computer includes at least one processor coupled to a chipset . The chipset includes a memory controller hub and an input output I O controller hub . A memory and a graphics adapter are coupled to the memory controller hub and a display is coupled to the graphics adapter . A storage device keyboard pointing device and network adapter are coupled to the I O controller hub . Other embodiments of the computer have different architectures.

The storage device is a computer readable storage medium such as a hard drive compact disk read only memory CD ROM DVD or a solid state memory device. The memory holds instructions and data used by the processor . The pointing device is a mouse track ball or other type of pointing device and is used in combination with the keyboard to input data into the computer system . The graphics adapter displays images and other information on the display . The network adapter couples the computer system to one or more computer networks.

The computer is adapted to execute computer program modules for providing functionality described herein. As used herein the term module refers to computer program logic used to provide the specified functionality. Thus a module can be implemented in hardware firmware and or software. In one embodiment program modules are stored on the storage device loaded into the memory and executed by the processor .

The types of computers used by the entities of can vary depending upon the embodiment and the processing power required by the entity. For example the security system might comprise multiple blade servers working together to provide the functionality described herein. As another example the client system might comprise a mobile telephone with limited processing power. The computers can lack some of the components described above such as keyboards graphics adapters and displays .

The communication module communicates with the security system to request and receive a decision tree for detecting malware. The decision tree can be received in a variety of forms such as a set of rules e.g. if then else statements derived from the decision tree a computer program module implementing the decision tree textual description of the decision tree in an XML file or any ASCII file format.

The file monitor module monitors computer files within the client system and collects information related to the attributes used in the decision tree e.g. the splitting attributes of the branch nodes . The file monitor module examines a computer file e.g. system properties metadata to determine values of attributes such as whether the file is digitally signed. The file monitor module also monitors the run time behaviors of the file to determine values of attributes such as whether the file attempts to modify the hosts file and whether the file attempts to access the network . In one embodiment the file monitor module collects information for a specific attribute of a specific file as requested by the security analysis engine . In another embodiment the file monitor module continuously monitors a predetermined set of attributes for computer files within the client system and stores collected information in the data store .

The security analysis engine determines whether a computer file is malicious by traversing down the decision tree according to values of the splitting attributes on the path. In one embodiment the security analysis engine makes the determination for a file when a suspicious behavior e.g. an attempt to write to the system registry is observed for that file. Starting from the root node of the decision tree the security analysis engine repeatedly determines the value of the splitting attribute for the file by making inquiry to the file monitor module and determines the branch to take for the branch node until a leaf node is reached. The security analysis engine makes the determination based on the classification represented by the leaf node. In one embodiment the security analysis engine also considers other factors such as the confidence score for the represented classification and the local security policy in making the determination.

The data store stores data used by the client system . Examples of such data include information related to the computer files resided on the client system e.g. attribute values behavior descriptions metadata system properties the decision tree and information about the security system e.g. IP address . The data store may be a relational database or any other type of database.

The attribute complexity determination module determines the computational complexities of a predetermined set of attributes hereinafter called candidate attributes . The attribute complexity determination module creates a set of attribute vectors for a set of training files with known classification e.g. legitimate or malware and associates a label with each attribute vector indicating the classification of the corresponding training file. The attribute vector includes values of the candidate attributes for the corresponding training file such as whether the file is digitally signed and whether the file attempted to modify the hosts file.

The attribute complexity determination module quantifies the computational complexity of each candidate attribute by assigning a complexity score to the attribute. The complexity score of an attribute measures the cost associated with determining the value of the attribute for a computer file. For example the complexity score can be a continuous value ranging from 0 to 1 which a score of 0 indicating a very high cost e.g. it takes substantial resources such as time memory processing power and network bandwidth to determine the attribute value and a score of 1 indicating a very low cost e.g. the attribute value is readily available . The complexity score can be manually assigned e.g. based on human knowledge or automatically generated e.g. based on statistical data .

The decision tree construction module constructs a decision tree based on the set of attribute vectors created for the training files while taking into account the computational complexities of the attributes in the attribute vectors. As shown the decision tree construction module includes a growth sub module and a pruning sub module .

The growth sub module grows the decision tree by recursively applying a decision tree induction procedure that takes into account the computational complexities of the candidate attributes and the benefits that the attributes provide. The computational complexity of an attribute is measured by its complexity score. The benefits an attribute provides is quantified by an impurity reduction score which measures how well the attribute separates a set of applicable attribute vectors according to their labels i.e. legitimate or malware . Entropy is used as a measure of the impurity in the set of applicable attribute vectors. The entropy for a set S is defined as Entropy loglog. 1 In all calculations involving entropy 0 log 0 is defined to be 0. The impurity reduction score is the expected reduction in entropy caused by splitting the set of attribute vectors based on values of the underlying attribute. The impurity reduction score for an attribute A that splits a set S into two subsets Sand Sis defined as 

The growth sub module starts the growing process by establishing a root node and selecting a splitting attribute for the root node from the set of candidate attributes. The goal for the growth sub module is to select the attribute with the best benefit cost tradeoff that is the attribute that provides substantial benefits in separating the applicable attribute vectors and is relatively inexpensive to determine. According to one embodiment the growth sub module calculates a weighted impurity reduction score for each candidate attribute and selects the attribute with the highest weighted impurity reduction score as the splitting attribute for the root node. The splitting attribute splits the set of attribute vectors into two subsets according to their values of the splitting attribute.

A weighted impurity reduction score is a measure that quantifies a cost benefit tradeoff for an attribute in classifying a set of attribute vectors. In one example the weighted impurity reduction score for an attribute A to classify a set S is defined as Weighted IR Score IR Score Complexity Score . 3 Accordingly the attribute with the highest impurity reduction score is not necessarily the attribute with the highest weighted impurity reduction score. Another attribute which may not reduce impurity as much but is much cheaper to compute much higher complexity score may well have a higher weighted impurity reduction score.

The growth sub module also determines whether a predetermined stopping criterion is met. Stopping criteria are designed to prevent over analysis of the training files. Examples of the stopping criteria include 1 if the number of applicable attribute vectors is below a first predefined numeric threshold value then stop and 2 if the impurity reduction scores for all candidate attributes are below a second predefined numeric threshold then stop. When a stopping criterion is met the growth sub module sets the current node as a leaf node. The represented classification of the leaf node is the classification of a majority of the applicable attribute vectors. The confidence score of the represented classification is the fraction of the majority in all applicable attribute vectors. For example if there are 10 applicable attribute vectors and 6 of which are malware then the leaf node would represent a classification of malware and has a confidence score of 0.6.

The growth sub module recursively applies the decision tree induction procedure at each subset of attribute vectors to create nodes that branch off from the branch node associated with the parent set. For example if the splitting attribute for the root node is whether the file is digitally signed then the left branch considers only those attribute vectors with an attribute value NO for this attribute i.e. training files that are not digitally signed and the right branch considers the rest i.e. training files that are digitally signed . This procedure continues for the remaining subsets until all subsets are represented by a node in the decision tree.

The growth sub module gives more weight to the impurity reduction scores of those attributes that are relatively inexpensive to determine low computational complexity high complexity score . Thus the growth sub module selects a less expensive attribute as the splitting attribute so long as the resulting sacrifice in impurity reduction is not that much worse comparing to using a more expensive attribute. Therefore nodes associated with less complex attributes are more likely placed higher up in the decision tree. As a result traversing the decision tree in the field e.g. by the security module tends to be faster because the splitting attributes along the way are likely inexpensive to determine .

In one embodiment rather than using the complexity score as the weight of the associated attribute across the board the growth sub module calculates a weight value for the attribute by applying a weight function to the associated complexity score and uses the weight value to determine the weighted impurity reduction score. The weight value measures a significance of the complexity score for an attribute as it applies to the node at issue and the applicable attribute vectors. The weight function takes into account factors such as the depth of the node at issue and the size of the applicable attribute vectors. The weight function assigns low weights to attributes with low complexity scores because their values are expensive to determine e.g. time consuming . The resulting weight value becomes less sensitive to the complexity score as the depth of the current node grows. The deeper a node is located in the decision tree the longer it takes to travel to the node from the root node because more time will be spent for determining the values of the splitting attributes for the branch nodes along the way. As a result the benefit of balancing the cost and benefits of attributes at that node is reduced. The resulting weight also becomes less sensitive to the complexity score as the number of applicable attribute vectors decreases. A small set of applicable attribute vectors suggests that the chance the node is visited to classify a file is low. Thus utilizing a more expensive attribute in such a node would not have much impact on the overall efficiency of the decision tree. By using the weight function the growth sub module beneficially modifies the weight values for candidate attributes as the procedure proceeds and thereby growing a better decision tree.

The pruning sub module prunes the decision tree grown by the growth sub module to prevent over fitting on the training files. The pruning sub module prunes a branch node i.e. replacing it with a leaf node if the error associated with the pruned tree is no greater than the error associated with the unpruned tree where the error is measured with respect to a set of examining files independent from the training files. The examining files are selected to represent real world files that the decision tree will be used to examine in field e.g. in the client system . The pruning sub module also helps to make the decision tree more compact.

In one embodiment the pruning sub module considers the computational complexity of the splitting attributes when determining whether to prune sub trees rooted at the corresponding branch nodes such that branch nodes of expensive attributes are more likely pruned. For example if the weighted impurity reduction score of a splitting attribute is below a predetermined numeric threshold value the pruning sub module prunes the corresponding branch node i.e. replacing the branch node with a leaf node .

The communication module receives requests from the security modules running on the client systems and provides the constructed decision tree to the security modules . The decision tree can be used in the security module for general purpose malware detection.

The data store stores data used by the security system . Examples of such data include the set of training files and associated attribute vectors the set of examining files and associated attribute vectors the constructed decision tree and associated information e.g. splitting attributes splitting tests weighted impurity reduction scores and client systems to name a few. Similar to the data store the data store may be a relational database or any other type of database.

Initially the security module running on the client system receives a decision tree from the security system via the network . The security module identifies a target computer file for security scrutiny. For example the security module monitors files residing on the client system observes an attempt to perform a suspicious activity by one of the monitored files and identifies that file as the target file for security scrutiny.

The security module traverses down the received decision tree based on attribute values of the target file. Starting at the root node of the decision tree the security module determines the attribute value of the splitting attribute of the branch node and traversing down the decision tree based on the attribute value until a leaf node is reached. The values of some of the attributes can be determined without executing the target file while others involve monitoring the run time behavior. The security module determines whether the target file is malware based on the classification represented by the leaf node the associated confidence score and optionally the local security policy. For example if the client system has low security policies in place e.g. computers in an Internet caf then the security module can rely entirely on the represented classification to make the determination and disregard the confidence score. On the other hand if the client system enforces stringent local security policies then the security module may only consider the represented classification in making the determination if the confidence score exceeds a predetermined numeric threshold value.

The security system examines a set of training files with known classification e.g. legitimate or malware creates an attribute vector for each of the training files and associates a label with the attribute vector indicating the classification of the associated training file. The attribute vector includes values of a predetermined set of candidate attributes of the associated training file. The security system determines complexity scores for candidate attributes and grows a decision tree using the attribute vectors. The growing step is illustrated in and described in detail below.

Referring now to a flow diagram illustrating a process for the security system to grow a decision tree by recursively applying a decision tree induction procedure for a current set of attribute vectors according to one embodiment. As shown the security system initially sets the attribute vectors created for the set of training files as the current set and creates a node for the current set of attribute vectors hereinafter called the current node . The security system determines an impurity reduction score for each candidate attribute to measure how well the attribute separates the current set of attribute vectors according to their labels. The security system also determines a weight value for each candidate attribute by applying a weight function to the complexity score of the candidate attribute and the current set of attribute vectors and a depth of the current node in the decision tree. The security system determines a weighted impurity reduction score for each candidate attribute based on the impurity reduction score and the weight value of the attribute.

The security system determines whether a stopping criterion is satisfied by examining the current set and the weighted impurity reduction scores. If no stopping criterion is satisfied the security system sets the current node as a branch node and selects a candidate attribute with the highest weighted impurity reduction score as the splitting attribute of the branch node. The security system splits the current set of attribute vectors into subsets based on their attribute values of the splitting attribute. The security system sets one of the subsets of attribute vectors as the current set and repeats the process by creating a current node for the current set. In one embodiment the security system removes the selected attribute from the set of candidate attributes for the subsets.

If a stopping criteria is satisfied the security system sets the current node as a leaf node and determines the represented classification and confidence score of the leaf node by examining the current set of attribute vectors. The security system then determines whether there is any subset of attribute vectors not yet represented by a node in the decision tree. If such a subset exists the security system sets it as the current set and repeats the process by creating a current node for the current set. Otherwise the security system determines that the decision tree is completely grown and the process ends.

Referring back to the security system prunes the decision tree by applying the decision tree to a set of examining files with known classification and replacing a branch node with a leaf node when the entropy of the attribute vectors applicable at the node exceeds the entropy of the examining files applicable at the node. The decision tree can then be sent to security modules running on the client system to be used to detect malware.

The above approach beneficially requires that a more expensive attribute be used in a branch node of a decision tree only if its benefits sufficiently outweigh the benefits of using a less expensive and perhaps less beneficial attribute. As a result expensive attributes are pushed down the decision tree and thereby improves the performance of the decision tree.

Some portions of above description describe the embodiments in terms of algorithmic processes or operations. These algorithmic descriptions and representations are commonly used by those skilled in the data processing arts to convey the substance of their work effectively to others skilled in the art. These operations while described functionally computationally or logically are understood to be implemented by computer programs comprising instructions for execution by a processor or equivalent electrical circuits microcode or the like. Furthermore it has also proven convenient at times to refer to these arrangements of functional operations as modules without loss of generality. The described operations and their associated modules may be embodied in software firmware hardware or any combinations thereof.

As used herein any reference to one embodiment or an embodiment means that a particular element feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

Some embodiments may be described using the expression coupled and connected along with their derivatives. It should be understood that these terms are not intended as synonyms for each other. For example some embodiments may be described using the term connected to indicate that two or more elements are in direct physical or electrical contact with each other. In another example some embodiments may be described using the term coupled to indicate that two or more elements are in direct physical or electrical contact. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other. The embodiments are not limited in this context.

As used herein the terms comprises comprising includes including has having or any other variation thereof are intended to cover a non exclusive inclusion. For example a process method article or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process method article or apparatus. Further unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by any one of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

In addition use of the a or an are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the disclosure. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.

Upon reading this disclosure those of skill in the art will appreciate still additional alternative structural and functional designs for a system and a process for constructing a decision tree that takes into account attribute computational complexity. Thus while particular embodiments and applications have been illustrated and described it is to be understood that the present invention is not limited to the precise construction and components disclosed herein and that various modifications changes and variations which will be apparent to those skilled in the art may be made in the arrangement operation and details of the method and apparatus disclosed herein without departing from the spirit and scope as defined in the appended claims.

