---

title: Techniques for storage network bandwidth management
abstract: Techniques for storage network bandwidth management are disclosed. In one particular exemplary embodiment, the techniques may be realized as a method for storage network bandwidth management comprising sampling, using at least one computer processor, application Input/Output (I/O) requests associated with the unit of storage during a specified period of time, determining a maximum latency value based on the sampling of the application Input/Output (I/O) requests, comparing the maximum latency value with a current latency value, and throttling administrative I/O requests in the event that the current latency value exceeds the maximum latency value.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09135191&OS=09135191&RS=09135191
owner: Symantec Corporation
number: 09135191
owner_city: Mountain View
owner_country: US
publication_date: 20120615
---
The present disclosure relates generally to managing computer storage networks and more particularly to techniques for storage network bandwidth management.

Logical volume management may provide storage virtualization and offers storage flexibility to allow partition concatenating striping resizing movement or other partition operations. Such volume management operations may be carried out without interruption to operations. However such volume management operations may require significant administrative I O. Such I O transactions may be unrelated to I O transactions of applications using the corresponding partitions. For example if a volume is striped by a logical volume manager such striping may not interrupt I O operations of an application using the volume being striped. However the administrative I O may cause a significant delay and may impair performance of the application. Attempts to manage the administrative I O requests may also impact the I O requests of the application.

In view of the foregoing it may be understood that there may be significant problems and shortcomings associated with current computer storage network management technologies.

Techniques for storage network bandwidth management are disclosed. In one particular exemplary embodiment the techniques may be realized as a method for storage network bandwidth management comprising sampling using at least one computer processor application Input Output I O requests associated with the unit of storage during a specified period of time determining a maximum latency value based on the sampling of the application Input Output I O requests comparing the maximum latency value with a current latency value and throttling administrative I O requests in the event that the current latency value exceeds the maximum latency value.

In accordance with other aspects of this particular exemplary embodiment the techniques may further include periodically sampling application Input Output I O requests to determine a new maximum latency value.

In accordance with further aspects of this particular exemplary embodiment the techniques may further include increasing administrative Input Output I O requests in the event the current latency value is a specified level below the maximum latency value.

In accordance with additional aspects of this particular exemplary embodiment the first unit of storage may comprise a volume.

In accordance with additional aspects of this particular exemplary embodiment the first unit of storage may comprise a disk.

In accordance with additional aspects of this particular exemplary embodiment the first unit of storage may comprise a disk array.

In accordance with additional aspects of this particular exemplary embodiment the techniques may further include comparing the current latency value with a maximum latency value associated with a second unit of storage wherein throttling administrative I O requests may comprise throttling administrative I O requests in the event that the current latency value exceeds either the maximum latency value of the first unit of storage or the maximum latency value of the second unit of storage.

In accordance with additional aspects of this particular exemplary embodiment the comparison may be based upon an administrative operation occurring which requires writing from the first unit of storage to the second unit of storage.

In accordance with additional aspects of this particular exemplary embodiment throttling administrative I O requests may be implemented using a sliding window protocol.

In accordance with additional aspects of this particular exemplary embodiment the periodic sampling may result in a plurality of stored maximum latency values used to identify bandwidth utilization trends.

In accordance with additional aspects of this particular exemplary embodiment I O requests of an application may be differentiated from administrative I O requests based on a field in a packet header of administrative I O request packets.

In accordance with additional aspects of this particular exemplary embodiment the techniques may be realized as at least one non transitory processor readable storage medium for storing a computer program of instructions configured to be readable by at least one processor for instructing the at least one processor to execute a computer process for performing a method.

In another particular exemplary embodiment the techniques may be realized as an article of manufacture for storage network bandwidth management. The article of manufacture may comprise at least one non transitory processor readable medium and instructions stored on the at least one medium. The instructions may be configured to be readable from the at least one medium by at least one processor and thereby cause the at least one processor to operate so as to sample application Input Output I O requests associated with the unit of storage during a specified period of time determine a maximum latency value based on the sampling of the application Input Output I O requests compare the maximum latency value with a current latency value and throttle administrative I O requests in the event that the current latency value exceeds the maximum latency value.

In yet another particular exemplary embodiment the techniques may be realized as a system for storage network bandwidth management comprising one or more processors communicatively coupled to a network. The one or more processors may be configured to sample application Input Output I O requests associated with the unit of storage during a specified period of time determine a maximum latency value based on the sampling of the application Input Output I O requests compare the maximum latency value with a current latency value and throttle administrative I O requests in the event that the current latency value exceeds the maximum latency value.

In accordance with additional aspects of this particular exemplary embodiment the one or more processors may be further configured to periodically sample application Input Output I O requests to determine a new maximum latency value.

In accordance with additional aspects of this particular exemplary embodiment the one or more processors may be further configured to increase administrative Input Output I O requests in the event the current latency value is a specified level below the maximum latency value.

In accordance with additional aspects of this particular exemplary embodiment the first unit of storage may comprise at least one of a volume a disk and a disk array.

In accordance with additional aspects of this particular exemplary embodiment the one or more processors may be further configured to compare the current latency value with a maximum latency value associated with a second unit of storage wherein throttling administrative I O requests comprises throttling administrative I O requests in the event that the current latency value exceeds either the maximum latency value of the first unit of storage or the maximum latency value of the second unit of storage.

In accordance with additional aspects of this particular exemplary embodiment the comparison may be based upon an administrative operation occurring which requires writing from the first unit of storage to the second unit of storage.

In accordance with additional aspects of this particular exemplary embodiment throttling administrative I O requests may be implemented using a sliding window protocol.

The present disclosure will now be described in more detail with reference to exemplary embodiments thereof as shown in the accompanying drawings. While the present disclosure is described below with reference to exemplary embodiments it should be understood that the present disclosure is not limited thereto. Those of ordinary skill in the art having access to the teachings herein will recognize additional implementations modifications and embodiments as well as other fields of use which are within the scope of the present disclosure as described herein and with respect to which the present disclosure may be of significant utility.

The description below describes network elements computers and or components of a system and method for storage network bandwidth management that may include one or more modules. As used herein the term module may be understood to refer to computing software firmware hardware and or various combinations thereof. Modules however are not to be interpreted as software which is not implemented on hardware firmware or recorded on a processor readable recordable storage medium i.e. modules are not software per se . It is noted that the modules are exemplary. The modules may be combined integrated separated and or duplicated to support various applications. Also a function described herein as being performed at a particular module may be performed at one or more other modules and or by one or more other devices instead of or in addition to the function performed at the particular module. Further the modules may be implemented across multiple devices and or other components local or remote to one another. Additionally the modules may be moved from one device and added to another device and or may be included in both devices.

With reference to computer system of modem network interface or some other method may be used to provide connectivity from one or more of client systems N to network . Client systems N may be able to access information on server A or B using for example a web browser or other client software. Such a client may allow client systems N to access data hosted by server A or B or one of storage devices A N B N and or N .

Networks and may be local area networks LANs wide area networks WANs the Internet cellular networks satellite networks or other networks that permit communication between client systems N servers and other devices communicatively coupled to networks and . Networks and may further include one or any number of the exemplary types of networks mentioned above operating as a stand alone network or in cooperation with each other. Networks and may utilize one or more protocols of one or more clients or servers to which they are communicatively coupled. Networks and may translate to or from other protocols to one or more protocols of network devices. Although networks and are each depicted as one network it should be appreciated that according to one or more embodiments networks and may each comprise a plurality of interconnected networks.

Storage devices A N B N and or N may be network accessible storage and may be local remote or a combination thereof to server A or B. Storage devices A N B N and or N may utilize a redundant array of inexpensive disks RAID magnetic tape disk a storage area network SAN an internet small computer systems interface iSCSI SAN a Fibre Channel SAN a common Internet File System CIFS network attached storage NAS a network file system NFS optical based storage or other computer accessible storage. Storage devices A N B N and or N may be used for backup or archival purposes.

According to some embodiments client systems N may be a smartphone PDA desktop computer a laptop computer a server another computer or another device coupled via a wireless or wired connection to network . Client systems N may receive data from user input a database a file a web service and or an application programming interface.

Servers A and B may be application servers archival platforms backup servers network storage devices media servers email servers document management platforms enterprise search servers or other devices communicatively coupled to network . Servers A and B may utilize one of storage devices A N B N and or N for the storage of application data backup data or other data. Servers A and B may be hosts such as an application server which may process data traveling between client systems N and a backup platform a backup process and or storage. According to some embodiments servers A and B may be platforms used for backing up and or archiving data.

Client systems N may contain storage network bandwidth management module . Storage network bandwidth management module may provide storage network bandwidth management services for a plurality of units of storage. Storage network bandwidth management module may determine or be configured for a particular unit of storage. According to some embodiments a unit of storage may be one or more of a volume a disk and a disk array. Storage network bandwidth management module may non disruptively sample application Input Output I O requests associated with the unit of storage during a specified period of time. According to some embodiments administrative I O requests may be differentiated from application I O requests based on a field in a packet header of administrative I O request packets. Storage network bandwidth management module may determine a maximum latency value for the sampling period. For example a maximum latency value may be specified as a percentage of an average observed latency during a sampling period e.g. 120 . A maximum latency value may also be specified in another manner e.g. a table mapping sampled latency ranges to maximum latency values a table mapping a number of I O requests to a maximum latency value etc. Storage network bandwidth management module may periodically measure latency of I O requests and may compare the maximum latency value with a current latency value. If a current latency value exceeds a maximum latency value then storage network bandwidth management module may throttle administrative I O requests. According to one or more embodiments throttling administrative I O requests may be implemented using a sliding window protocol. In the event a currently latency value is a specified level below a maximum latency value storage network bandwidth management module may increase administrative Input Output I O requests. Increases in administrative Input Output I O requests may be proportional to an amount a currently observed application I O latency falls below a maximum specified I O latency. For example if application I O latency is twenty percent below a specified maximum application I O latency then administrative I O requests may be increased by twenty percent. According to some embodiments a margin may be left e.g. the administrative I O may be increased by only 10 and a 10 safety margin may be left . Increases in administrative I O requests may also be calculated using other factors e.g. a mapping table a cap etc. 

According to one or more embodiments storage network bandwidth management module may consider the latency values of more than one unit of storage when managing administrative I O bandwidth use. For example storage network bandwidth management module may compare a current latency value with a maximum latency value associated with a second unit of storage. Throttling administrative I O requests may include throttling administrative I O requests in the event that the current latency value exceeds either the maximum latency value of the first unit of storage or the maximum latency value of the second unit of storage. Storage network bandwidth management module may compare latency of one or more units of storage with one or more latency values based upon an administrative operation occurring which writes from the first unit of storage to the second unit of storage. Storage network bandwidth management module may throttle administrative I O requests of operations involving a plurality of units of storage to address a lowest latency value of the plurality of units of storage.

Storage network bandwidth management module may throttle administrative I O requests using one or more methods. For example storage network bandwidth management module may use tokens or a sliding window weighted queuing and or a weighted round robin methodology.

Throttling administrative I O requests in the event that a current latency value exceeds the maximum latency value may include decreasing administrative I O requests at a rate proportional to a rate at which the current latency value exceeds the maximum latency value. For example if a current latency value exceeds a maximum latency value by ten percent administrative I O requests may be decreased by ten percent. Throttling administrative I O requests may also use other calculations such as for example mapping a current latency value to a specified number of administrative I O requests.

Storage network bandwidth management module may periodically sample application Input Output I O requests to determine a new maximum latency value. For example a maximum latency value may be specified as a percentage of an average observed latency during a sampling period e.g. 120 . A maximum latency value may also be specified in another manner e.g. a table mapping sampled latency ranges to maximum latency values a table mapping a number of I O requests to a maximum latency value etc. According to some embodiments storage network bandwidth management module may sample I O requests every three hours to determine a new maximum latency value. According to some embodiments Storage network bandwidth management module or logical volume management software may trigger sampling if an I O intensive administrative operation has been triggered. According to one or more embodiments statistics may be maintained of different periods or trends of I O levels and corresponding latency.

Bus allows data communication between central processor and system memory which may include read only memory ROM or flash memory neither shown and random access memory RAM not shown as previously noted. The RAM may be the main memory into which the operating system and application programs may be loaded. The ROM or flash memory can contain among other code the Basic Input Output system BIOS which controls basic hardware operation such as the interaction with peripheral components. Applications resident with computer system may be stored on and accessed via a computer readable medium such as a hard disk drive e.g. fixed disk an optical drive e.g. optical drive a floppy disk unit or other storage medium. For example storage network bandwidth management may be resident in system memory .

Storage interface as with the other storage interfaces of computer system can connect to a standard computer readable medium for storage and or retrieval of information such as a fixed disk drive . Fixed disk drive may be a part of computer system or may be separate and accessed through other interface systems. Modem may provide a direct connection to a remote server via a telephone link or to the Internet via an internet service provider ISP . Network interface may provide a direct connection to a remote server via a direct network link to the Internet via a POP point of presence . Network interface may provide such connection using wireless techniques including digital cellular telephone connection Cellular Digital Packet Data CDPD connection digital satellite data connection or the like.

Many other devices or subsystems not shown may be connected in a similar manner e.g. document scanners digital cameras and so on . Conversely all of the devices shown in need not be present to practice the present disclosure. The devices and subsystems can be interconnected in different ways from that shown in . Code to implement the present disclosure may be stored in computer readable storage media such as one or more of system memory fixed disk optical disk or floppy disk . Code to implement the present disclosure may also be received via one or more interfaces and stored in memory. The operating system provided on computer system may be MS DOS MS WINDOWS OS 2 OS X UNIX Linux or another known operating system.

Power manager may monitor a power level of battery . Power manager may provide one or more APIs Application Programming Interfaces to allow determination of a power level of a time window remaining prior to shutdown of computer system a power consumption rate an indicator of whether computer system is on mains e.g. AC Power or battery power and other power related information. According to some embodiments APIs of power manager may be accessible remotely e.g. accessible to a remote backup management module via a network connection . According to some embodiments battery may be an Uninterruptable Power Supply UPS located either local to or remote from computer system . In such embodiments power manager may provide information about a power level of an UPS.

Referring to there is shown a storage network bandwidth management module in accordance with an embodiment of the present disclosure. As illustrated the storage network bandwidth management module may contain one or more components including I O measurement module reference determination module I O throttling module and error handling module .

I O measurement module may non disruptively sample application Input Output I O requests associated with the unit of storage during a specified period of time. According to some embodiments administrative I O requests may be differentiated from application I O requests based on a field in a packet header of administrative I O request packets. I O measurement module may determine a maximum latency value for the sampling period. For example a maximum latency value may be specified as a percentage of an average observed latency during a sampling period e.g. 120 . A maximum latency value may also be specified in another manner e.g. a table mapping sampled latency ranges to maximum latency values a table mapping a number of I O requests to a maximum latency value etc. I O measurement module may periodically measure latency of I O requests and may compare the maximum latency value with a current latency value.

According to one or more embodiments I O measurement module may consider the latency values of more than one unit of storage when managing administrative I O bandwidth use. For example I O measurement module may compare a current latency value with a maximum latency value associated with a second unit of storage. I O measurement module may compare latency of one or more units of storage with one or more latency values based upon an administrative operation occurring which writes from the first unit of storage to the second unit of storage.

I O measurement module may periodically sample Input Output I O requests to determine a new maximum latency value. For example according to some embodiments I O measurement module may sample I O requests every three hours to determine a new maximum latency value. According to some embodiments I O measurement module or logical volume management software may trigger sampling if an I O intensive administrative operation has been triggered. According to one or more embodiments statistics may be maintained of different periods or trends of I O levels and corresponding latency.

If a current latency value exceeds a maximum latency value then I O throttling module may throttle administrative I O requests. According to one or more embodiments throttling administrative I O requests may be implemented using a sliding window protocol. In the event a currently latency value is a specified level below a maximum latency value I O throttling module may increase administrative Input Output I O requests.

Increases in administrative Input Output I O requests may be proportional to an amount a currently observed application I O latency falls below a maximum specified I O latency. For example if application I O latency is twenty percent below a specified maximum application I O latency then administrative I O requests may be increased by twenty percent. According to some embodiments a margin may be left e.g. the administrative I O may be increased by only 10 and a 10 safety margin may be left . Increases in administrative I O requests may also be calculated using other factors e.g. a mapping table a cap etc. 

I O throttling module may throttle administrative I O requests of operations involving a plurality of units of storage to address a lowest latency value of the plurality of units of storage. Throttling administrative I O requests may include throttling administrative I O requests in the event that the current latency value exceeds either the maximum latency value of the first unit of storage or the maximum latency value of the second unit of storage.

Throttling administrative I O requests in the event that a current latency value exceeds the maximum latency value may include decreasing administrative I O requests at a rate proportional to a rate at which the current latency value exceeds the maximum latency value. For example if a current latency value exceeds a maximum latency value by ten percent administrative I O requests may be decreased by ten percent. Throttling administrative I O requests may also use other calculations such as for example mapping a current latency value to a specified number of administrative I O requests.

I O throttling module may throttle administrative I O requests using one or more methods. For example I O throttling module may use tokens or a sliding window weighted queuing and or a weighted round robin methodology.

Error handling module may handle one or more errors with storage network bandwidth management including but not limited to errors with I O measurement administrative I O throttling and periodic I O sampling.

Referring to there is depicted a method for storage network bandwidth management in accordance with an embodiment of the present disclosure. At block the method may begin.

At block a portion of I Os attributable to one or more units of storage. Logical volume management software and or a storage network bandwidth management module may be configured to identify administrative I O requests attributable to particular units of storage. This may allow management of bandwidth such as throttling of administrative I O requests in response to a heavy I O load on one or more particular units of storage. Throttling of I O requests may allow an application using a particular unit of storage to avoid degraded performance. According to some embodiments a particular level of service may be specified for an application and administrative I Os may be throttled accordingly. A level of service may specify peak and off peak times allowing I O intensive actions to be scheduled accordingly. Storage network bandwidth management services may be provided for a plurality of units of storage. According to some embodiments a unit of storage may be one or more of a volume a disk and a disk array.

At block application Input Output I O requests associated with the unit of storage may be non disruptively sampled during a specified period of time. A sample may be a specified number of packets a specified percentage of packets or another criteria designed to be of sufficient size to reasonably estimate latency of response times to I O requests for an application associated with the unit of storage. According to some embodiments administrative I O requests may be differentiated from application I O requests based on a field in a packet header of administrative I O request packets. Sampling may be configured so as to avoid degrading performance further.

At block a maximum latency value for the sampling period may be determined. For example a maximum latency value may be specified as a percentage of an average observed latency during a sampling period e.g. 120 . A maximum latency value may also be specified in another manner e.g. a table mapping sampled latency ranges to maximum latency values a table mapping a number of I O requests to a maximum latency value etc. 

At block a maximum latency value may be compared with a current latency value. If a current latency value exceeds a maximum latency value then method may continue at block . If a current latency value is below a maximum latency value then method may continue at block .

At block in the event a current latency value is a specified level below a maximum latency value administrative Input Output I O requests may be increased.

Increases in administrative Input Output I O requests may be proportional to an amount a currently observed application I O latency falls below a maximum specified I O latency. For example if application I O latency is twenty percent below a specified maximum application I O latency then administrative I O requests may be increased by twenty percent. According to some embodiments a margin may be left e.g. the administrative I O may be increased by only 10 and a 10 safety margin may be left . Increases in administrative I O requests may also be calculated using other factors e.g. a mapping table a cap etc. 

According to some embodiments if a current latency value is below a maximum latency value the method may continue at block without increasing administrative I O requests.

At block administrative I O requests may be throttled. According to one or more embodiments throttling administrative I O requests may be implemented using a sliding window protocol.

According to one or more embodiments the latency values of more than one unit of storage when managing administrative I O bandwidth use. For example a current latency value of a second unit of storage may be compared with a maximum latency value associated with a second unit of storage. Throttling administrative I O requests may include throttling administrative I O requests in the event that the current latency value exceeds either the maximum latency value of the first unit of storage or the maximum latency value of the second unit of storage. Latency of one or more units of storage may be compared with one or more current latency values based upon an administrative operation occurring which writes from the first unit of storage to the second unit of storage. Administrative I O requests of operations involving a plurality of units of storage may be throttled to address a lowest latency value of the plurality of units of storage e.g. administrative I O requests associated with migration of data from a first disk array to a second disk array may be throttled to the lowest acceptable maximum latency of the two disk arrays .

Throttling administrative I O requests in the event that a current latency value exceeds the maximum latency value may include decreasing administrative I O requests at a rate proportional to a rate at which the current latency value exceeds the maximum latency value. For example if a current latency value exceeds a maximum latency value by ten percent administrative I O requests may be decreased by ten percent. Throttling administrative I O requests may also use other calculations such as for example mapping a current latency value to a specified number of administrative I O requests.

Throttling administrative I O requests may use one or more methods. For example tokens or a sliding window weighted queuing and or a weighted round robin methodology may be used.

At block it may be determined whether a sampling period has expired. For example threshold or reference latencies may be determined by sampling periodically e.g. every three hours . According to some embodiments an administrative user may trigger a sampling of application I O requests in order to determine a threshold e.g. if a large migration is occurring . If a sampling period has expired the method may return to block . If a sampling period has not expired the method may wait at block .

At this point it should be noted that storage network bandwidth management in accordance with the present disclosure as described above typically involves the processing of input data and the generation of output data to some extent. This input data processing and output data generation may be implemented in hardware or software. For example specific electronic components may be employed in a storage network bandwidth management module or similar or related circuitry for implementing the functions associated with storage network bandwidth management in accordance with the present disclosure as described above. Alternatively one or more processors operating in accordance with instructions may implement the functions associated with storage network bandwidth management in accordance with the present disclosure as described above. If such is the case it is within the scope of the present disclosure that such instructions may be stored on one or more processor readable storage media e.g. a magnetic disk or other storage medium or transmitted to one or more processors via one or more signals embodied in one or more carrier waves.

The present disclosure is not to be limited in scope by the specific embodiments described herein. Indeed other various embodiments of and modifications to the present disclosure in addition to those described herein will be apparent to those of ordinary skill in the art from the foregoing description and accompanying drawings. Thus such other embodiments and modifications are intended to fall within the scope of the present disclosure. Further although the present disclosure has been described herein in the context of a particular implementation in a particular environment for a particular purpose those of ordinary skill in the art will recognize that its usefulness is not limited thereto and that the present disclosure may be beneficially implemented in any number of environments for any number of purposes. Accordingly the claims set forth below should be construed in view of the full breadth and spirit of the present disclosure as described herein.

