---

title: Method, system, and device for dynamic energy efficient job scheduling in a cloud computing environment
abstract: A method, system, and device for energy efficient job scheduling in a datacenter computing environment includes a master node. The master node can periodically receive energy data from slave nodes and dynamically assign computing tasks to be executed by the slave nodes based on the energy data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09342376&OS=09342376&RS=09342376
owner: Intel Corporation
number: 09342376
owner_city: Santa Clara
owner_country: US
publication_date: 20120627
---
 Cloud computing often refers to the provision of computing resources as a service usually by a number of computer servers that are networked together at location s that are remote from the location from which the services are requested. A cloud datacenter refers to a physical arrangement of servers that make up a cloud e.g. racks rooms etc. . In some cases a particular portion of a datacenter may be implemented as a cluster or grid. 

A cloud or cluster server or portions of its resources may be allocated physically or logically according to workload requirements. As an example computing jobs that involve very large data sets and or numerous computational tasks such as big data analytics may be distributed among multiple physical servers in a cluster and or among multiple processes on the same server.

A scheduling system refers to computer software e.g. middleware used to allocate computing jobs among server resources in a cloud cluster or grid. For example some scheduling systems designate one server as the master node of a cluster that includes a number of slave nodes where the master node schedules tasks to be processed by its cluster in response to periodic heartbeat signals it receives from the slave nodes in its cluster.

While the concepts of the present disclosure are susceptible to various modifications and alternative forms specific embodiments thereof have been shown by way of example in the drawings and will herein be described in detail. It should be understood however that there is no intent to limit the concepts of the present disclosure to the particular forms disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives consistent with the present disclosure and the appended claims.

In the following description numerous specific details such as logic implementations opcodes means to specify operands resource partitioning sharing duplication implementations types and interrelationships of system components and logic partitioning integration choices are set forth in order to provide a more thorough understanding of the present disclosure. It will be appreciated by one skilled in the art however that embodiments of the disclosure may be practiced without such specific details. In other instances control structures gate level circuits and full software instruction sequences have not been shown in detail in order not to obscure the description of the of the concepts described herein. Those of ordinary skill in the art with the included descriptions will be able to implement appropriate functionality without undue experimentation.

References in the specification to one embodiment an embodiment an example embodiment etc. indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may not necessarily include the particular feature structure or characteristic. Moreover such phrases are not necessarily referring to the same embodiment. Further when a particular feature structure or characteristic is described in connection with an embodiment it is submitted that it is within the knowledge of one skilled in the art to effect such feature structure or characteristic in connection with other embodiments whether or not explicitly described.

Embodiments of the concepts described herein may be implemented in hardware firmware software or any combination thereof. Embodiments implemented in a computer system may include one or more point to point or bus based interconnects between components. Embodiments of the concepts described herein may also be implemented as instructions carried by or stored on one or more machine readable or computer readable storage media which may be read and executed by one or more processors. A machine readable or computer readable storage medium may be embodied as any device mechanism or physical structure for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable or computer readable storage medium may be embodied as read only memory ROM device s random access memory RAM device s magnetic disk storage media optical storage media flash memory devices mini or micro SD cards memory sticks and others.

In the drawings specific arrangements or orderings of schematic elements such as those representing devices modules instruction blocks and data elements may be shown for ease of description. However it should be understood by those skilled in the art that the specific ordering or arrangement of the schematic elements in the drawings is not meant to imply that a particular order or sequence of processing or separation of processes is required. Further the inclusion of a schematic element in a drawing is not meant to imply that such element is required in all embodiments or that the features represented by such element may not be included in or combined with other elements in some embodiments.

In general schematic elements used to represent instruction blocks may be implemented using any suitable form of machine readable instruction such as software or firmware applications programs functions modules routines processes procedures plug ins applets widgets code fragments and or others and that each such instruction may be implemented using any suitable programming language library application programming interface API and or other software development tools. For example some embodiments may be implemented using Java C and or other programming languages. Similarly schematic elements used to represent data or information may be implemented using any suitable electronic arrangement or structure such as a register data store table record array index hash map tree list graph file of any file type folder directory database and or others.

Further in the drawings where connecting elements such as solid or dashed lines or arrows are used to illustrate a connection relationship or association between or among two or more other schematic elements the absence of any such connecting elements is not meant to imply that no connection relationship or association can exist. In other words some connections relationships or associations between elements may not be shown in the drawings so as not to obscure the disclosure. In addition for ease of illustration a single connecting element may be used to represent multiple connections relationships or associations between elements. For example where a connecting element represents a communication of signals data or instructions it should be understood by those skilled in the art that such element may represent one or multiple signal paths e.g. a bus as may be needed to effect the communication.

Referring now to an illustrative system for dynamic energy efficient scheduling of computing jobs among a number of slave nodes of a cluster or grid referred to hereinafter as simply a cluster for ease of discussion of a cloud datacenter environment is managed by a master node . An energy efficient job scheduler embodied in the master node communicates with slave agents of the slave nodes to determine which of the slave nodes may be the most energy efficient node to perform a given type of computing job or task. As explained in detail below the energy efficient job scheduler assigns computing jobs or tasks to the slave nodes based on information about the incoming job or task and energy and availability information provided to the master node periodically by the slave agents in real time. In this way the energy efficiency of the cluster and indeed the cloud datacenter environment can be improved by matching computing jobs or tasks with the most appropriate energy efficient nodes for the particular type of job or task.

The illustrative cluster is embodied as a collection of commodity computing devices that are connected to one another via the network to function as a large multiprocessor. Further the cluster is embodied as a heterogeneous cluster. That is the cluster comprises a number 1 . . . N of slave node servers X where N is a positive integer and X represents one type of hardware configuration e.g. processor memory etc. and the cluster comprises a number 1 . . . M of slave node servers Y where M is a positive integer and Y represents another type of hardware configuration that is not the same as X. One example of a heterogeneous cluster is a datacenter that has multi generation hardware.

As illustrated the slave nodes are separate physical servers managed by the master node server but it should be appreciated by those skilled in the art that any or all of the nodes may be logical rather than physical. That is each physical server may have one or more slave agents e.g. or a portion thereof running on it using virtualization. In addition the master node server may host both the energy efficient job scheduler and one or more slave agents using virtualization in some embodiments. The servers are in communication with one another via the network as described in further detail below.

The cluster is just one of many such groupings of computing devices that can make up the datacenter environment . In other words the datacenter environment may include a number of heterogeneous clusters such as the cluster a number of homogeneous clusters e.g. similar hardware and or other computing devices. In the illustrative embodiments the job scheduling for each cluster is managed by a master node such as the master node server . For illustration purposes the cluster is described herein as supporting distributed computing and more particularly distributed computing on large data sets sized in the petabytes range in some examples and or highly distributable computations using a large number of server nodes numbering in the thousands in some examples . As such the illustrative cluster is described in the context of a software framework that is capable of processing highly distributable and or data intensive problems e.g. big data analytics . For instance in some embodiments the cluster may be embodied using an implementation of a MapReduce framework such as an APACHE HADOOP open source implementation. However it should be appreciated by those skilled in the art that the aspects of the present disclosure are in no way limited to HADOOP implementations or even to MapReduce frameworks more generally. Rather the present disclosure can be applied in any job scheduling context in which computing jobs and or tasks can be dynamically assigned to various hardware resources and where power and or energy metrics are available.

In the illustrative embodiments each of the node servers is shown as having a similar or analogous hardware configuration. So as not to obscure the disclosure the following description is presented in the context of the master node server but applies equally to the corresponding elements of each of the node servers having the same names as shown in . The illustrative master node server includes at least one processor memory an input output I O subsystem an energy counter application programming interface API and or software development toolkit SDK the energy efficient job scheduler at least one data storage device a job queue communication circuitry slot availability data a slave agent and energy data . The master node server may be embodied as any suitable type of server computer or other computing device capable of performing the functions and features described herein as being performable by the master node server or any of its components. For example the master server may be embodied as a computer a personal computer PC a desktop computer a laptop computer a notebook computer a handheld computer a server a server array or server farm a web server a network server an enterprise server an Internet server a work station a mini computer a main frame computer a supercomputer a network appliance a web appliance a distributed computing system multiprocessor system processor based system or combination of any of the foregoing.

The illustrative processor includes at least one processor core and one or more energy counters . The illustrative energy counters monitor and output in real time information about the amount of power and or energy currently being used by the processor and or the core e.g. the number of watts used and the processor s current frequency e.g. in megahertz or gigahertz . While in the illustrative embodiments the energy counters are available in the processor it should be understood by those skilled in the art that in some embodiments the requisite energy and or power data may be obtained via special purpose tools or instrumentation available on the motherboard and or by other devices that may be coupled to the processor .

In addition to an amount of cache memory the processor includes or is otherwise communicatively coupled to the memory . The memory may be embodied as any type of suitable memory device such as a dynamic random access memory device DRAM synchronous dynamic random access memory device SDRAM double data rate dynamic random access memory device DDR SDRAM and or other volatile memory device.

The processor is also communicatively coupled to the I O subsystem . While not specifically shown the illustrative I O subsystem may include a memory controller e.g. a memory controller subsystem or northbridge an input output controller e.g. an input output controller subsystem or southbridge and a firmware device. Of course in other embodiments I O subsystems having other configurations may be used. For example in some embodiments the I O subsystem may form a portion of a system on a chip SoC and be incorporated along with the processor and other components of the servers on a single integrated circuit chip. As such it will be appreciated that each component of the I O subsystem may be located on a common integrated circuit chip in some embodiments.

The I O subsystem is communicatively coupled to the energy counter API SDK the energy efficient job scheduler the data storage device the communication circuitry and the slave agent . The energy counter API SDK is embodied as one or more computerized programs logic and or instructions e.g. software and or firmware functions libraries drivers operating system gadgets and or others that enable software applications to import and export data generated by the energy counters . For example some portions of the energy counter API SDK are configured to process the power and or energy data generated by the energy counters and convert it into energy metrics that can be used by software applications running on the master node server . Some examples of energy metrics include processor average power Watts cumulative energy consumed joules and instantaneous frequency. In the illustrative embodiments the energy counter API SDK generates a CPU related energy efficiency metric performance per watt perf watt where performance is defined as the reciprocal of task completion time 1 completion time and generates an I O related energy efficiency metric I O operations per second IOPS per watt. The energy counter API SDK supplies these energy efficiency metrics to the corresponding slave agent on a periodic basis as described below. In addition the energy efficiency metrics may be stored over time in the corresponding energy data .

The energy efficient job scheduler is embodied as one or more computerized programs logic and or instructions e.g. software and or firmware that are configured to process incoming computing jobs and or tasks store the incoming jobs tasks in the job queue and assign the jobs and or tasks to the slave nodes or a slave node running on the master node server based on the energy efficiency data and slot availability data associated with the slave nodes and energy requirements associated with the particular job or task. Details relating to the operation of the energy efficient job scheduler are described below with reference to .

The slave agents are each embodied as one or more computerized programs logic and or instructions e.g. software and or firmware that are configured to periodically send heartbeat signals to the energy efficient job scheduler . Each heartbeat signal includes the current energy data and slot availability data associated with the server issuing the heartbeat signals.

Portions of the data storage device may be embodied as any suitable device for storing data and or computer instructions such as disk storage e.g. hard disks a network of physical and or logical storage devices and or others. In the illustrative embodiment the job queue slot availability data and energy data reside in the corresponding data storage device . In addition portions of the energy counter API SDK the energy efficient job scheduler and or the slave agent may reside in the corresponding data storage device . Portions of the energy counter API SDK the energy efficient job scheduler and or the slave agent may be copied to the corresponding memory during operation for faster processing or other reasons.

The communication circuitry may be embodied as one or more devices and or circuitry configured to enable communications between or among the master node server the slave node server s and or the slave node server s via the communication network . For example the communication circuitry may include one or more wired and or wireless network interfaces or cards to facilitate communications over the wired and or wireless portions of the network .

Although not specifically shown the I O subsystem may be communicatively coupled to one or more peripheral device s such as a display touchpad keypad microphone speaker and or others depending upon for example the intended use of the respective server . Further it should be appreciated that the master node server and or any of the slave node servers may include other components sub components and devices not illustrated in for clarity of the description.

The network may be embodied as any type of wired and or wireless telecommunications network. For example the network may be embodied as or otherwise include one or more public or private cellular networks telephone Digital Subscriber Line DSL or cable networks local or wide area networks publicly available global networks e.g. the Internet or any combination thereof. For example in some embodiments the network may be embodied as or otherwise include a Global System for Mobile Communications GSM cellular network. Additionally the network may include any number of additional devices as needed to facilitate communication between or among the master node server and or the slave node servers such as routers switches intervening computers and or others. Any suitable communication protocol e.g. TCP IP may be used to effect communication over the network depending on for example the particular type or configuration of the network .

In general the components of the master node server and the slave node servers are communicatively coupled as shown in by one or more signal paths. Such signal paths may be embodied as any type of wired or wireless signal paths capable of facilitating communication between the respective devices. For example the signal paths may be embodied as any number of wires printed circuit board traces via bus point to point interconnects intervening devices and or the like. Also generally speaking some of the components of the computing devices described above may be incorporated on a motherboard while other components may be communicatively coupled to the motherboard via for example a peripheral port.

Referring now to in an embodiment of the system each of the illustrative energy efficient job scheduler and the slave agents is embodied as one or more computerized modules e.g. software and or firmware . The energy efficient job scheduler periodically receives computing jobs or tasks e.g. from client applications running on end user computing devices and or other computing devices connected to the network . One example of a job or task that may be received from a client application is a web search that is initiated by an end user at a computing device that is connected to the network via the Internet. Some other examples of jobs that may be handled by the energy efficient job scheduler include web crawling text tokenizers page ranking document processing and clickstream analysis.

In the illustrative embodiment a job z where z is a positive integer can be broken down by the energy efficient job scheduler into a number of tasks 1 . . . N where N is a positive integer. Each of the tasks 1 . . . N can be classified as a certain type of task e.g. T T . In addition the tasks 1 . . . N that make up the job z can be distributed among multiple slave nodes for execution. In the web search illustration the job of searching the web for a specific combination of search terms input by a user may be broken down into smaller tasks where each task involves searching a particular domain of the Internet or conducting a search on a specific permutation of the search term for example.

In the context of the illustrative MapReduce framework input data associated with a job e.g. data that may be used by the job and or one or more tasks which may reside in a file system such as the file system known as the HADOOP File System or HDFS is split and distributed among the cluster nodes. The job is divided into a number of tasks based on the size of the input data. Each task can be classified as either a map task or a reduce task. Generally speaking map tasks are smaller sub tasks that can be distributed to the slave nodes and performed thereby while reduce tasks are tasks that collect and combine the results of all of the map tasks to form the output resulting from completion of the job. As such map tasks are typically computation intensive while reduce tasks tend to be more I O intensive. The number of map tasks and the number of input splits may have a 1 1 correspondence.

More generally that is irrespective of the framework on which the energy efficient job scheduler may be based any job may have tasks or sub portions that can be classified similarly as computation intensive I O intensive or using any other suitable classification scheme. In other words the number of task types may be determined and tasks may be classified in any number of ways according to the requirements of a particular design and or implementation of the system .

As noted above the slave agents X N and Y M send periodic heartbeat signals to the energy efficient job scheduler . In the illustrative embodiments each heartbeat signal includes a data structure containing the current energy efficiency data for the server issuing the heartbeat signal as well as the server s slot availability data . In some MapReduce implementations the slot availability data includes information relating to the number of slots that are available at the server issuing the heartbeat signal to receive map tasks and the number of slots that are available to receive reduce tasks. More generally in other embodiments the slot availability data simply includes data that gives an indication of the corresponding server s capacity to accept new jobs or tasks. In response to a heartbeat signal the energy efficient job scheduler traverses the job queue in priority order and determines which tasks to assign to the server from which the current heartbeat signal was received.

Referring now to an illustrative method executable as computerized logic and or instructions by the various modules of the energy efficient job scheduler is shown. At block the method receives a heartbeat signal from one of the slave agents . As noted above the heartbeat signal includes the energy efficiency metrics e.g. records per joule and IOPS watt and slot availability data associated with the server slave node i on which the slave agent is running.

Different types of computing tasks may have different energy efficiency characteristics as mentioned above. At block the method determines a given type of computing task T to use as a basis for evaluating the energy efficiency of the slave node i . In the illustrative method two task types T or T e.g. map or reduce are shown. However in other embodiments incoming tasks may be classified as one of any number of task types. For each heartbeat signal the method processes tasks of one of the tasks types e.g. T or map tasks first and then processes tasks of the other task type s in the illustrative embodiments. In some embodiments the processing of at least some tasks by the method may be prioritized in other ways not prioritized at all or performed concurrently rather than sequentially. Block deals with a particular task type T e.g. T or T depending on the task type that is selected for processing.

At block the method determines whether the current slave node node i that is the node from which the method received a heartbeat signal at block is the most energy efficient node for the task type determined at block . If the node i is not the most energy efficient node for the task type or does not have any slots available for that task type then the method returns to block without scheduling any tasks to the node i . As an example if the task type T relates to map tasks or tasks that are computation intensive and the node i has a good e.g. high value for the energy efficiency metric for computation intensive tasks e.g. a high number of records per joule then the node i may be considered the most energy efficient node for the task type. Conversely if the task type T is map but the node i has a high value for the energy efficiency metric for I O intensive tasks e.g. a high number of IOPS watt but a lower value for the energy efficiency metric for computation intensive tasks then the node i may not be considered the most energy efficient node for the task type. In determining whether a node i is the most energy efficient node for a task type T the method uses a greedy heuristic algorithm e.g. a strategy of looking for the best or optimal choice on a local level e.g. within the cluster rather than on a global level e.g. across clusters or within the entire datacenter environment . In addition at block the method determines from the slot availability data whether the node i has the capacity e.g. available slots to accept tasks of the task type T.

If the node i is the most energy efficient node for the task type T and the node i has the capacity to accept tasks of the task type T then the method determines a number of tasks to schedule to the node i based on the slot availability data for the node i and proceeds to schedule tasks of type T to that node until the node i is no longer the most energy efficient node e.g. until the value of the node i s energy efficiency metric is no longer considered the best value for the task type T or the node i no longer has the capacity to accept tasks of task type T. If the node i is not the most energy efficient node for the task type T or does not have available slots for the task type T the method returns to block .

At block the job queue which contains data relating to the runnable jobs that have been received by the energy efficient job scheduler and the number of running tasks associated with each job is sorted to give higher priority to those jobs that have a higher number of running tasks e.g. for fairness . At block a job j and data relating to its associated tasks is read from the top of the job queue . At block the method determines whether the job j has any unlaunched tasks t e.g. tasks that are runnable but not yet running that need to be scheduled. If the job j does not have any unlaunched tasks t the method returns to block and begins processing of the next job j in the job queue . If the job j does have unlaunched tasks t the method processes tasks t that are of task type T first and then processes tasks t that are of task type T. So if the method is currently processing tasks of task type T determined at block the method proceeds to block . If the method is not currently processing tasks of task type T determined at block the method proceeds to block where it is determined whether tasks of type T are currently being processed.

If tasks of task type T are currently being processed then at block the method determines whether any of the unlaunched tasks t of the current job j are of the task type T and if so evaluates the data locality of each of the unlaunched tasks t that are of the task type T. The data locality analysis can be used to assign tasks to nodes on which the associated input data e.g. split is already located to avoid unnecessary data transfer I O operations or for other reasons. In some embodiments the data locality analysis may consider not only node level locality but also rack level and off rack locality. For instance considering rack level locality even if the input data for a task is not located on the node i but is located on another node within the same rack as the node i the method may schedule the task to the node i in some embodiments. In other embodiments the data locality analysis may require tasks to be assigned to the node that contains the associated input split e.g. ignoring rack and off rack locality . As should be appreciated by those skilled in the art the degree to which data locality is considered by the method can be varied according to the requirements of a particular design or implementation of the method .

Referring to blocks and the method first assigns the tasks t of task type T that meet the data locality criteria as determined at block for execution by the node i at block and then at block assigns any other tasks t of task type T to the node i according to the number of slots remaining available at the node i . Once all of the tasks t of task type T have been processed at block the method schedules tasks t of task type T to the node i in accordance with the energy efficiency of the node i and available slots for the task type T. While described herein as being performed in a more or less sequential manner it should be understood that the scheduling of tasks of types T and T may be done concurrently in some embodiments.

Illustrative examples of the devices systems and methods disclosed herein are provided below. An embodiment of the devices systems and methods may include any one or more and any combination of the examples described below.

In an example a master node for use in a datacenter computing environment comprising a communication network and a plurality of slave nodes includes an energy efficient job scheduler to periodically receive energy data from the slave nodes periodically receive computing jobs including one or more unlaunched computing tasks determine a task type for an unlaunched computing task and assign the unlaunched computing task to a slave node in response to the energy data received from the slave node based on the task type.

In an example the energy efficient job scheduler may be embodied as middleware of the master node and the master node may be embodied as a server computer. In an example the energy data received from a slave node by the energy efficient job scheduler may indicate whether the slave node is more energy efficient for processor intensive tasks or for input output intensive tasks. In an example the energy efficient job scheduler may assign the unlaunched computing task to a first slave node that is more energy efficient for processor intensive tasks in response to determining that the task type is a first task type and may assign the unlaunched computing task to a second slave node that is more energy efficient for input output intensive tasks in response to determining that the task type is a second task type different than the first task type. In an example the energy efficient job scheduler may implement a MapReduce framework where the first task type is Map and the second task type is Reduce. In an example the energy efficient job scheduler may determine whether data associated with the unlaunched computing task is local to a slave node or a rack containing the slave node and may assign the unlaunched computing task to the slave node in response to determining that data associated with the unlaunched computing task is local to the slave node or the rack containing the slave node. In an example the energy efficient job scheduler may maintains a job queue including computing jobs having unlaunched computing tasks and may periodically receive slot availability data from the slave nodes where the slot availability data may indicate a number of slots a slave node has available for unlaunched computing tasks and may determine a number of unlaunched computing tasks to assign to the slave node in response to the number of available slots. In an example the energy efficient job scheduler may periodically receive from the slave nodes first slot availability data indicating a first number of slots a slave node has available for unlaunched tasks of a first task type and second slot availability data indicating a second number of slots the slave node has available for unlaunched tasks of a second task type and may assign the unlaunched computing tasks to the slave nodes based on the task type and the first and second slot availability data. In an example the plurality of slave nodes may include a heterogeneous cluster of computing devices and the energy efficient job scheduler may selectively assign the unlaunched computing tasks to computing devices in the heterogeneous cluster.

In another example a slave node for use in a datacenter computing environment including a communication network and a master node configured to assign computing tasks to a plurality of slave nodes includes a slave agent to periodically send energy data to the master node and receive unlaunched computing tasks from the master node for execution by the slave node in response to the energy data sent by the slave node to the master node where the received unlaunched computing tasks each have a task type that corresponds to the energy data sent by the slave node to the master node. In an example the master node and the slave node may be embodied as server computers. In an example the master node and the slave node may be embodied as virtual nodes running on the same server computer. In an example the energy data may include a first energy metric including records per joule and a second energy metric including input output operations per second per watt. In an example the slave agent may be configured to periodically send slot availability data for each task type to the master node and receive unlaunched computing tasks from the master node for execution by the slave node in response to the slot availability data.

In another example a system for energy efficient job scheduling in a datacenter computing environment includes a plurality of slave nodes each comprising a slave agent and a master node comprising an energy efficient job scheduler to periodically receive energy data from the slave agents and assign unlaunched computing tasks each having a task type to the slave nodes in response to the energy data received from the slave agents and based on the task type.

In an example the plurality of slave nodes may be embodied as a heterogeneous cluster of computing devices comprising at least one first computing device that is more energy efficient for processor intensive computing tasks and at least one second computing device that is more energy efficient for input output intensive computing tasks. In an example the master node may assign unlaunched computing tasks of a first task type to slave nodes embodied as at least one computing device that is more energy efficient for processor intensive computing tasks. In an example the master node may receive locality data associated with the unlaunched tasks from the slave agents and may assign unlaunched computing tasks of the first type to slave nodes based on the locality data. In an example the master node may assign unlaunched computing tasks of a second task type to slave nodes embodied as at least one computing device that is more energy efficient for input output intensive computing tasks. In an example the master node may execute a greedy heuristic algorithm to assign the unlaunched computing tasks to the slave nodes.

In another example a method for scheduling a plurality of unlaunched computing tasks to be executed by one or more slave nodes in a datacenter computing environment includes periodically receiving at a master node of the datacenter computing environment energy and availability data from each of the slave nodes and in response to receiving energy and availability data from one of the slave nodes determining whether the slave node is an energy efficient node for a first type of computing task.

In an example the method may include in response to determining that the slave node is an energy efficient node for the first type of computing task determining a number of unlaunched computing tasks of the first type to assign to the slave node based on the availability data for the slave node. In an example the method may include assigning the determined number of unlaunched tasks of the first type to the slave node according to locality data associated with each of the determined number of unlaunched tasks of the first type. In an example the method may include in response to determining that the slave node is not an energy efficient node for the first type of computing task determining whether the slave node is an energy efficient node for a second type of computing task. In an example the method may include in response to determining that the slave node is an energy efficient node for the second type of computing task determining a number of unlaunched tasks of the second type to assign to the slave node based on the availability data for the slave node. In an example the method may include assigning the determined number of unlaunched tasks of the second type to the slave node. In an example the method may include repeating the determining whether the slave node is an energy efficient node for a first type of computing task and assigning the determined number of unlaunched tasks of the first type to the slave node until it is determined that the slave node is no longer an energy efficient node for the first type of computing task.

In another example at least one machine accessible storage medium includes a plurality of instructions that in response to being executed result in a computing device periodically receiving at a master node of the datacenter computing environment energy and availability data from each of the slave nodes and in response to receiving energy and availability data from one of the slave nodes determining whether the slave node is an energy efficient node for a first type of computing task.

In an example the at least one computer accessible storage medium may include in response to determining that the slave node is an energy efficient node for the first type of computing task determining a number of unlaunched computing tasks of the first type to assign to the slave node based on the availability data for the slave node. In an example the at least one computer accessible storage medium may include assigning the determined number of unlaunched tasks of the first type to the slave node according to locality data associated with each of the determined number of unlaunched tasks of the first type. In an example the at least one computer accessible storage medium may include in response to determining that the slave node is not an energy efficient node for the first type of computing task determining whether the slave node is an energy efficient node for a second type of computing task. In an example the at least one computer accessible storage medium may include in response to determining that the slave node is an energy efficient node for the second type of computing task determining a number of unlaunched tasks of the second type to assign to the slave node based on the availability data for the slave node and assigning the determined number of unlaunched tasks of the second type to the slave node. In an example the at least one computer accessible storage medium may include repeating the determining whether the slave node is an energy efficient node for a first type of computing task and assigning the determined number of unlaunched tasks of the first type to the slave node until it is determined that the slave node is no longer an energy efficient node for the first type of computing task.

While the concepts of the present disclosure have been illustrated and described in detail in the drawings and foregoing description such an illustration and description is to be considered as exemplary and not restrictive in character it being understood that only illustrative embodiments have been shown and described and that all changes and modifications consistent with the disclosure and recited claims are desired to be protected.

