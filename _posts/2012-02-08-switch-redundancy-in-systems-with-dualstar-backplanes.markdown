---

title: Switch redundancy in systems with dual-star backplanes
abstract: Backplane redundancy is provided for a system including multiple nodes that communicate packets through first and second switches. Assuming that the first switch is initially assigned to an active state and the second switch to a standby state, the nodes communicate the data packets through physically enabled first backplane links to the first switch. The nodes physically enable second backplane links that are in a condition to communicate the data packets to the second switch. A messageless failover process is initiated by temporarily disabling, at the first switch, the first backplane links between the first switch and the nodes. In response to the nodes detecting the disabled first backplane links to the first switch, the nodes reconfigure themselves to communicate the data packets through the second backplane links to the second switch and to stop communicating the packets through the first backplane links to the first switch.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08711681&OS=08711681&RS=08711681
owner: Radisys Corporation
number: 08711681
owner_city: Hillsboro
owner_country: US
publication_date: 20120208
---
This disclosure relates to distributed computing systems that incorporate switching for backplane communications. In particular this disclosure relates to methods systems and computer readable media for initiating and coordinating active standby failovers in a switching system with a dual star backplane topology via link state changes.

Certain computing architectures use redundant switching to ensure reliable communication between a network and a plurality of processing nodes. Some systems may use a dual star backplane for interconnecting processing nodes within the system. In Advanced Telecommunications Computing Architecture ATCA for example there are two dual star backplanes which are called the Base and Fabric Ethernet interfaces. Such a topology provides a redundant Ethernet network for data path traffic which passes between the switches and a plurality of node modules on the backplane. If one Ethernet network fails on the Base or the Fabric interface the traffic is switched over to the other Ethernet network on the Base interface or the Fabric interface. However there is no standard for system level coordination of redundancy using this hardware based topology.

Redundancy methods based on messaging protocols generally have problems with latency and reliability. Typical redundancy methods such as multiple spanning tree protocol MSTP or other layer 2 protocols are difficult to configure produce non optimal forwarding paths and result in slow failover times.

In one embodiment a method coordinates backplane redundancy in a system including a plurality of nodes configured to communicate data packets through a first switching hub and a second switching hub within the system. The method includes assigning the first switching hub to an active state and the second switching hub to a standby state such that the plurality of nodes communicate the data packets through physically enabled first backplane links to the first switching hub. The plurality of nodes physically enables second backplane links so that they are in a condition to communicate the data packets to the second switching hub. The method also includes detecting a failover condition and in response to the detected failover condition triggering a messageless failover process to change the second switching hub to the active state and the first switching hub to the standby state. The messageless failover process includes temporarily disabling at the first switching hub the first backplane links between the first switching hub and the plurality of nodes. Each of the plurality of nodes independently detects the disabled first backplane links to the first switching hub. In response to detecting the disabled first backplane links each of the plurality of nodes independently configures itself to communicate the data packets through the second backplane links to the second switching hub and to stop communicating the packets through the first backplane links to the first switching hub.

In certain embodiments after a predetermined period of time the method includes re enabling the first backplane links such that the first backplane links are in a condition to communicate the data packets between the plurality of nodes and the first switching hub.

In certain embodiments assigning the first switching hub to an active state and the second switching hub to a standby state includes a system initialization process for selecting the first switching hub for the active state and the second switching hub for the standby state temporarily disabling at the second switching hub the second backplane links between the second switching hub and the plurality of nodes detecting at the plurality of nodes the disabled second backplane links to the second switching hub and in response to detecting the disabled second backplane links triggering a messageless failover so as to configure the plurality of nodes to communicate the data packets through the first backplane links to the first switching hub and to stop communicating the packets through the second backplane links to the second switching hub.

Additional aspects and advantages will be apparent from the following detailed description of preferred embodiments which proceeds with reference to the accompanying drawings.

Messageless triggering embodiments disclosed herein are used for initiating and coordinating active standby failovers in a switching system with a dual star backplane topology. Rather than use messaging protocols disclosed embodiments use link state changes to initiate and coordinate active standby backplane redundancy across processing nodes. The link state changes include physically disabling and or enabling links i.e. at the physical layer .

The embodiments disclosed herein may be used for switch redundancy in any type of switching system with dual star backplanes. For illustrative purposes and not by way of limitation example embodiments disclosed herein use an Ethernet based backplane such as those included in ATCA or other bladed systems. However those skilled in the art will recognize from the disclosure herein that any type of dual star backplane or dual switching topology may be used. Further this disclosure is not limited to bladed systems and the disclosed embodiments may be applied to any distributed system modular computer or other system using redundant switches.

In certain embodiments a backplane redundancy manager is implemented in an Ethernet switch of one or both hub blades of a bladed system. As discussed below the backplane redundancy manager may be a logical entity including for example distributed software modules e.g. backplane redundancy modules located in each hub blade. The backplane redundancy manager is responsible for coordinating backplane redundancy and failovers across the node blades within the bladed system by using link state changes initiated from the hub blades. The backplane redundancy manager coordinates the alignment of the node blades to one of the hub blades as the active hub blade and the other hub blade as the standby hub blade. Thus the backplane redundancy manager controls the system to provide an active backplane data path between communicating resources in the bladed system. The backplane redundancy manager uses link status changes for such coordination.

An active hub blade means that data path traffic e.g. comprising Ethernet packets is transferred or forwarded between resources in the system over the backplane network implemented by the active hub blade and its Ethernet switching device s . A standby hub blade means that there is no data path traffic between resources in the system being transferred between resources in the system over the backplane network implemented by the standby hub blade and its Ethernet switching device s . However the switching device s and links on the standby hub blade are physically enabled and are capable and ready to accept traffic during a failover. Failover is the process in which the standby hub blade is promoted to an active state. A failover process may commence when a fault is detected by the active hub blade on one of its ports if the active switch blade is detected to no longer be operational or as a result of an administrative operation to request that the failover be performed e.g. for testing or maintenance .

During system initialization the backplane redundancy manager ensures that the node blades use the designated active hub blade as the active backplane path by temporarily disabling the backplane links on the standby hub blade. Likewise in a failover or switchover mode the backplane redundancy manager temporarily disables the backplane links on the formerly active hub blade. The node blades detect the loss of backplane link on the formerly active hub blade to trigger or initiate failover of their respective backplane links so as to locally align on the newly active hub blade. After a short duration e.g. in a range between about 1 second and about 3 seconds the backplane links on the standby hub blade i.e. the formerly active hub blade are re enabled so that a future failover can occur with minimal latency or traffic loss.

To support the redundancy process according to certain embodiments the node blades are configured for active standby bonding of the links to the dual star backplane such that one of the node s backplane links is used for data path traffic while the other backplane link is in standby mode and is in a state that is ready to be quickly promoted to active mode. During normal operation e.g. other than during system initialization failover or switchover modes both active and standby links are physically enabled from a switching perspective and a physical link perspective.

Although the node blades independently determine active standby links using bonding the backplane redundancy manager uses link state toggling for backplane Ethernet links as the messageless triggering mechanism for the node blades to select the appropriate active hub blade. The disclosed systems and methods reduce latency as compared to systems that use a protocol for creating transmitting receiving and processing messages. The disclosed systems and methods are also less complex as compared to other redundancy systems because they do not need to use a complex messaging protocol and service.

Reference is now made to the figures in which like reference numerals refer to like elements. For clarity the first digit of a reference numeral indicates the figure number in which the corresponding element is first used. In the following description numerous specific details are provided for a thorough understanding of the embodiments disclosed herein. However those skilled in the art will recognize that the embodiments can be practiced without one or more of the specific details or with other methods components or materials. Further in some cases well known structures elements materials or operations are not shown or described in detail in order to avoid obscuring aspects of the invention. Furthermore the described features structures or characteristics may be combined in any suitable manner in one or more embodiments.

Embodiments may include various steps which may be embodied in machine executable instructions to be executed by a general purpose or special purpose computer or other electronic device . Alternatively the steps may be performed by hardware components that include specific logic for performing the steps or by a combination of hardware software and or firmware.

Embodiments may also be provided as a computer program product including a non transitory machine readable medium having stored thereon instructions that may be used to program a computer or other electronic device to perform the processes described herein. The machine readable medium may include but is not limited to hard drives floppy diskettes optical disks CD ROMs DVD ROMs ROMs RAMs EPROMs EEPROMs magnetic or optical cards solid state memory devices or other types of media computer readable medium suitable for storing electronic instructions.

In this example both hubs include a respective backplane redundancy module including respective switches . The switches are Ethernet switches with ports for establishing backplane links with a plurality of node blades shown as node blade X node blade Y and node blade Z within the chassis of the bladed system . In this example the backplane redundancy manager comprises the backplane redundancy modules . Although the backplane redundancy modules are shown within the respective hubs skilled persons will recognize from the disclosure herein that the backplane redundancy modules may comprise a single instance of the backplane redundancy module. Further the backplane redundancy modules may be distributed among the hubs and the node blades .

The node blades may be configured for example as central processing units CPUs graphic processing units GPUs digital signal processors DSPs or network processing units NPUs including servers and other networking devices or appliances. The node blades may be configured to perform a wide variety of services or applications such as mobile network applications wireless core network applications voice over IP VOIP applications conferencing applications other media services involving voice video and data and services associated with deep packet inspection. The switches also include input and output I O ports for establishing respective external I O links with an external network or client device not shown . For example the external I O links may be used to communicate packets between the bladed system and a local area network the Internet and or other bladed systems as part of a data center computing center and or switching center.

The backplane redundancy modules implement redundancy while leveraging the dual star topology of the bladed system . The backplane redundancy modules establish an active standby relationship between the two hubs and their respective switches . The switches and the backplane links are physically enabled except as part of failover processing . The active standby dataplane use of the hubs is overlaid on top of the physically enabled switches and backplane links . The active hub e.g. hub provides the Ethernet paths through the bladed system for data path traffic. The switches in both hubs are always operating so as to contribute to fast failover times of about 250 milliseconds ms or less. In addition or in other embodiments the backplane redundancy modules monitor the external I O links and couple them with backplane failovers.

In certain embodiments the backplane redundancy modules run simultaneously on their respective hubs and communicate with one another as indicated by arrow in for active standby coordination. In one embodiment the backplane redundancy modules negotiate the active standby relationship between them based on which hub has the highest number of active backplane links. For example if the hub currently has a higher number of active or physically enabled backplane links than the number of active backplane links of the hub then the backplane redundancy modules select the hub as active and the hub as standby. In the event of a tie the hub e.g. either the hub or the hub in the lower numbered slot of the bladed system takes priority according to one embodiment and becomes active.

Once the active standby relationship between the backplane redundancy modules is established the backplane redundancy modules on the hubs each monitor the health e.g. switching and control module faults of its peer by sending periodic messages e.g. heartbeating over either a directly connected communication link as indicated by arrow or an independent path through a network. The backplane redundancy module on the active and standby hubs also monitor any backplane link changes e.g. faults on the backplane links .

In certain embodiments the backplane redundancy modules initiate a failover if one or more of the following conditions occur the standby hub has a higher number of active backplane links than those of the active hub the active hub does not respond to messages sent to it by the standby hub and or an administrator forces a failover e.g. using a remote application programming interface API of an optional system manager . In certain embodiments the backplane redundancy modules also take into account the number of active external I O links and or the total number of active links backplane plus external I O of the respective hubs . It should be noted however that the backplane redundancy modules do not monitor the failures in the node blades because such failures are not backplane failures and are generally processed in other ways e.g. through the optional system manager .

Continuing with the example of the hub being active just before a failover the active backplane redundancy module temporarily disables the backplane links of the hub . The node blades detect the loss of link on the formerly active hub which triggers or initiates failover of their respective backplane interfaces so as to locally align to the backplane links of the new active hub . After a short duration e.g. a few seconds the backplane links on the new standby hub are re enabled so that a future failover can occur with minimal latency or traffic loss.

As shown in the node blades each include two backplane interfaces for communicating with both the hub and the hub . The node blades monitor their backplane links and ensure that traffic is sent only via the active hub e.g. either the hub or the hub . To enable backplane redundancy according to certain embodiments the node blades include respective link bonding modules to bond the two backplane interfaces together on each node blade . In certain embodiments the link bonding modules include for example a Linux bonding driver configured in an active backup mode to achieve the bonding. In such embodiments the Linux bonding driver detects link faults and automatically performs a failover if the active link fails. Other bonding drivers e.g. other than Linux based may also be used.

In other embodiments the backplane redundancy modules and the link bonding modules run a bonding management application that uses virtual local area networks VLANs to ensure that traffic is routed to the active hub. The bonding management application creates VLANs on the hubs and the node blades . The interface to the active hub is added to all VLANs in use on the active hub while the interface to the standby hub does not participate in the VLANs. In the event of a failover VLAN participation is moved to the newly active interface and removed from the other interface.

The bladed system may include a dual star Ethernet backplane for both a Base interface e.g. operating at about 1 Gbps for management traffic and a Fabric interface e.g. operating at about 10 Gbps or 40 Gbps for user or network client traffic . In certain embodiments the backplane redundancy modules may be selectively configured by a user to monitor the Base interface the Fabric interface or both the Base interface and the Fabric interface. To simultaneously monitor both the Base interface and the Fabric interface for example the user may select a coupled mode wherein a failover in one interface causes a failover in the other interface. In a decoupled mode a failover in one interface does not affect the other interface. For coupled monitoring only one instance of the backplane redundancy module runs e.g. for both interfaces . For decoupled monitoring separate instances of the backplane redundancy module run for the two interfaces.

As indicated in certain embodiments of the backplane redundancy modules include I O link monitoring support and I O redundancy support. The backplane redundancy modules may allow users to selectively couple I O port redundancy with backplane redundancy. For example the backplane redundancy modules may be configured on a per I O port basis. As discussed below the backplane redundancy modules may provide I O redundancy support with I O link monitoring or without I O link monitoring.

In certain embodiments the user may select which of the external I O links of the active hub to monitor. It may be useful for example to monitor those external I O links that provide communication between the bladed system and another bladed system not shown such as within a data center computing center and or switching center. In one embodiment the backplane redundancy module of the active hub monitors the backplane links and the external I O links in a coupled fashion such that failovers in either domain cause both domains to failover.

In one embodiment the backplane redundancy module changes VLAN participation of the monitored external I O links based on link status using the virtual router redundancy protocol. The backplane redundancy module monitors the external I O links and the backplane links together and routes dataflows through the active hub e.g. as shown by arrows in . In this embodiment VLANs join interfaces from external routers not shown to the active and the standby hubs . The virtual router redundancy protocol provides redundancy between the VLAN route interfaces.

The backplane redundancy modules provide redundancy support for the unmonitored I O ports. In one embodiment the backplane redundancy modules use the spanning tree protocol to provide redundancy on the external I O links and on the hub to hub interswitch link . In another embodiment the backplane redundancy modules use the virtual router redundancy protocol wherein VLANs join interfaces from external routers not shown to the active and the standby hub . The virtual router redundancy protocol provides redundancy between VLAN route interfaces.

The method also includes querying whether a failover condition has occurred. In response to detecting the failover condition the method includes triggering a messageless failover process by temporarily disabling at the first switching hub the first backplane links. Triggering the messageless failover process changes the second switching hub to the active state and the first switching hub to the standby state and as discussed in below causes the plurality of nodes to stop communicating through the first backplane links with the first switching hub and to start communicating through the previously enabled second backplane links with the second switching hub.

In addition or in other embodiments the method may include querying whether a predetermined time has elapsed. The predetermined time period starts upon detecting the failover condition and ends after the plurality of nodes are configured to communicate the data packets through the second backplane links. After the predetermined time period has lapsed the method includes re enabling the first backplane links. However the plurality of nodes continues to communicate the data packets only through the second backplane links e.g. until the next failover condition is detected .

It will be understood by those having skill in the art that many changes may be made to the details of the above described embodiments without departing from the underlying principles of the invention. The scope of the present invention should therefore be determined only by the following claims.

