---

title: Hardware convolution pre-filter to accelerate object detection
abstract: Systems, apparatus, articles, and methods are described related to a hardware-based convolution pre-filter to accelerate object detection.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09342749&OS=09342749&RS=09342749
owner: Intel Corporation
number: 09342749
owner_city: Santa Clara
owner_country: US
publication_date: 20121218
---
Object detection has a wide range of applications. For example face detection may be used in human computer interaction photo album management biometric authentication video surveillance automatic focus imaging and a variety of other vision systems. Human detection may be used in video surveillance advanced driver assistance systems and the like. Other object detection examples include traffic monitoring automated vehicle parking character recognition manufacturing quality control object counting and quality monitoring.

In some existing object detection systems the Viola Jones cascade detection framework is used. In the Viola Jones cascade detection framework an input image is scanned with a sliding window to probe whether or not a target exists in the window using a cascade classifier. Such methods are computationally intensive. Software and hardware based implementations have been proposed however there are limitations to the existing implementations especially as image and video resolution increase. In software implementations it may be impossible to realize real time object detection. In graphics processing unit GPU implementations such methods may consume most or all of the computing resources such that resources are not available for other tasks. Other hardware implementations such as field programmable gate array FPGA and digital signal processor DSP implementations may not be re configurable when the hardware is fixed.

Since object detection may be used in such a wide variety of applications it may be desirable to make object detection execute more efficiently.

One or more embodiments or implementations are now described with reference to the enclosed figures. While specific configurations and arrangements are discussed it should be understood that this is done for illustrative purposes only. Persons skilled in the relevant art will recognize that other configurations and arrangements may be employed without departing from the spirit and scope of the description. It will be apparent to those skilled in the relevant art that techniques and or arrangements described herein may also be employed in a variety of other systems and applications other than what is described herein.

While the following description sets forth various implementations that may be manifested in architectures such system on a chip SoC architectures for example implementation of the techniques and or arrangements described herein are not restricted to particular architectures and or computing systems and may be implemented by any architecture and or computing system for similar purposes. For instance various architectures employing for example multiple integrated circuit IC chips and or packages and or various computing devices and or consumer electronic CE devices such as set top boxes smart phones etc. may implement the techniques and or arrangements described herein. Further while the following description may set forth numerous specific details such as logic implementations types and interrelationships of system components logic partitioning integration choices etc. claimed subject matter may be practiced without such specific details. In other instances some material such as for example control structures and full software instruction sequences may not be shown in detail in order not to obscure the material disclosed herein.

The material disclosed herein may be implemented in hardware firmware software or any combination thereof. The material disclosed herein may also be implemented as instructions stored on a machine readable medium which may be read and executed by one or more processors. A machine readable medium may include any medium and or mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other forms of propagated signals e.g. carrier waves infrared signals digital signals etc. and others.

References in the specification to one implementation an implementation an example implementation etc. indicate that the implementation described may include a particular feature structure or characteristic but every implementation may not necessarily include the particular feature structure or characteristic. Moreover such phrases are not necessarily referring to the same implementation. Further when a particular feature structure or characteristic is described in connection with an implementation it is submitted that it is within the knowledge of one skilled in the art to effect such feature structure or characteristic in connection with other implementations whether or not explicitly described herein.

Systems apparatus articles and methods are described related to a hardware based convolution pre filter to accelerate object detection.

As described above object detection has a wide range of applications. However current implementations of object detection are computationally intensive and have limitations such as not realizing real time object detection and or recognition consuming a large portion or all of available computational resources and being power intensive.

As described in greater detail below a hardware based convolution pre filter may accelerate object detection and provide greater efficiency such that real time object detection and or object recognition may be attained and computational resources and power may be saved. For example a convolution of an input image and a pre trained convolution kernel may provide for a filtered image. A threshold may be applied to the filtered image to generate a masked image including masked and unmasked pixels. The masked pixels may be discarded as likely not containing the object of interest. For the unmasked pixels which may have passed the convolution and threshold pre filter a cascade filter may be applied. The cascade filter may include several sequential stages. An individual unmasked pixel may go to the first stage and if it passes the stage continue to the second stage. If the pixel does not pass the stage it may be discarded. In such a manner passing pixels may be tested at sequential stages. Pixels that pass all the stages may be related to regions object detection regions that may be likely to contain an object or a portion of an object of interest. In general an object detection region may be a region related to a passing pixel such that the process or system may have detected an object or a portion of an object in the region. In some examples the region may be a number of pixels e.g. 32 by 32 pixels around the passing pixel with the passing pixel being at the center of the region. The object detection regions may optionally be merged and passed along for further processing such as object recognition processing.

In general object detection as discussed herein may include detecting where in an input image an object i.e. an object of a category of interest may be in the input image. For example in facial detection detection may include detecting a face. Further object recognition as discussed herein may include recognizing a particular object i.e. an individual of the category of interest . For example in facial recognition recognition may include identifying which person is associated with a detected face. The described hardware based convolution pre filter may provide a fast reliable and low computing and power cost process for object detection and or recognition implementations.

As is discussed further below system may also include a merge module and or an object recognition module which are not shown in for the sake of clarity. Further in some examples system may include additional items that have not been shown in for the sake of clarity. For example system may include a radio frequency type RF transceiver a display an antenna a speaker a microphone an accelerometer memory a router network interface logic etc.

In some examples system may perform object detection operations or object detection pre filter operations. For example system may receive an input image which may include one or more objects of interest . In general input image may be any suitable image or video data such as for example an image file or a video frame or the like. Object of interest may generally include any object for which object detection and or recognition may be desired such as for example a face an eye a landmark a written character a human or an automobile or the like. In facial detection and or recognition is used as an illustrative example. As will be appreciated in some examples input image may not include an object of interest.

As shown in at convolution module of hardware convolution of input image and a convolution kernel may be performed to generate a filtered image . In general convolution may provide a modified version i.e. filtered image of input image . For example convolution may provide an overlap between input image and convolution kernel as a function of the translation of input image . In some examples convolution of input image may be performed on a pixel by pixel basis. Convolution kernel may include any suitable kernel or template for generating filtered image via convolution . For example convolution kernel may include a pre designed convolution kernel or a pre trained convolution kernel. A pre trained convolution kernel may be generated by using a linear classifier trained by a large scale training set. The training set may include a number of images containing the object and a number of images not containing the object for example. As discussed above convolution module may be implemented via hardware . In various implementations hardware may include a digital signal processor a field programmable gate array a graphics processing unit or other hardware accelerator or the like.

As shown in a threshold module may apply a threshold to filtered image to generate a masked image . In general threshold module may apply the threshold to filtered image in any suitable manner such as for example on a pixel by pixel basis. The applied threshold may include for example a pre determined threshold a pre trained threshold a convolution results pre trained threshold or the like. Masked image may include a number of masked pixels and a number of unmasked pixels. In general the masked pixels may be deemed to likely not include an object of interest or a portion of an object of interest while the unmasked pixels may be deemed to be likely to or at least require further processing to determine whether they may include an object of interest or a portion of an object of interest. In general the masked pixels may be discarded. Such discarding of masked pixels and thereby portions or areas of input image may greatly reduce subsequent processing requirements since cascade filter module will not need to process the rejected or discarded pixels. Or as will be appreciated cascade filter module may thereby only process those pixels i.e. unmasked pixels that are likely to be of interest and generate regions likely to have an object of interest or a portion of an object of interest.

The masked and unmasked pixels of masked image may be represented in any suitable manner such as for example identifying masked pixels by a value of 1 and identifying unmasked pixels by a value of 0. Further in some implementations the size of the image may not have changed such that for example input image filtered image and masked image may be the same size.

Cascade filter module may apply a cascade filter to individual pixel s of the unmasked pixels of masked image to determine one or more object detection regions as shown. In some examples cascade filter may be applied to all of the unmasked pixels of masked image . The object detection regions may be related to one or more passing pixels i.e. pixels that passed all stages of cascade filter . Object detection regions may include regions in which an object has been detected for example. In some examples object detection regions may be candidate regions for object recognition such that they may be termed object recognition candidate regions. In general individual unmasked pixel s of masked image may be processed through cascade filter as implemented by cascade filter module . As shown cascade filter may include any number of stages illustrated as stage 1 stage 2 and stage N . In an illustrative example cascade filter may be a seven stage cascade filter. At stages of cascade filter an unmasked pixel may be tested to determine whether it passes the stage. In general the stage may include a true false test. If a pixel passes the stage e.g. the test with respect to the pixel is determined to be true illustrated as T in the pixel may be transferred to the next stage. If the pixel fails the stage e.g. the test with respect to the pixel is determined to be false illustrated as F in the pixel may be rejected discarded and or labeled as rejected .

In general the test implemented at the various stages of the cascade filter may include a determination of whether pixels surrounding the pixel being tested may include the object of interest. An example of such a test may be illustrated as follows 

As discussed cascade filter may include any suitable type of cascade filter such as for example a Viola Jones cascade filter or framework see e.g. Paul Viola Michael Jones Rapid Object Detection using a Boosted Cascade of Simple Features CVPR 2001 and or PCT CN2010 000997 by Yangzhou Du Qiang Li entitled TECHNIQUES FOR FACE DETECTION AND TRACKING filed Dec. 10 2010 . Such object detection techniques may allow object detection and or recognition to include face detection landmark detection face alignment smile blink gender age detection face recognition detecting two or more faces and or the like. In some examples cascade filter may include a boosted cascade filter.

In other examples the cascade filter may include a Speeded Up Robust Features SURF cascade filter or framework see e.g. Bay et al. Surf Speeded up robust features Computer Vision and Image Understanding CVIU 110 3 pages 346 359 2008 and or PCT CN2011 081642 by Jianguo Li Yimin Zhang entitled OBJECT DETECTION USING EXTENDED SURF FEATURES filed Nov. 1 2011 . Such object detection techniques may also allow object detection and or recognition to include face detection landmark detection face alignment smile blink gender age detection face recognition detecting two or more faces and or the like.

As discussed the unmasked pixel s if any which passed the stages of cascade filter may have a related object detection region . In general object detection region may be a region surrounding and including the unmasked passing pixel e.g. the unmasked passing pixel may be at the center of the object detection region which passed cascade filter . Object detection region may have any size or shape such as for example a square shape having a size of 32 pixels by 32 pixels or 15 pixels by 15 pixels or the like. In other examples object detection region may be rectangular or circular.

As discussed above and described further below system may include a merge module. A merge module may merge two or more object detection regions to form merged object detection regions. Such merging may consolidate regions for simplified processing such that merged region may contain more of or possibly an entirety of an object of interest.

Further system may also include an object recognition module. An object recognition module may perform object recognition on an object detection region object detection regions or merged detection region s . Such object recognition may include identifying one or more objects of interest in those regions.

In some implementations the resulting object detection region s from cascade filter module or the optional merge module may be determined to include the object of interest and no further object detection processing may be performed. In some implementations e resulting object detection region s from cascade filter module may be further processed to determine whether the region s include an object of interest.

As will be discussed in greater detail below system or other systems discussed herein may be used to perform some or all of the various functions discussed below in connection with or the functions previously discussed with respect to .

Process may be utilized as a computer implemented method for object detection and or recognition. Process may begin at block PERFORM VIA HARDWARE A CONVOLUTION OF AN INPUT IMAGE AND A CONVOLUTION KERNEL TO GENERATE A FILTERED IMAGE where a filtered image may be generated by performing via hardware a convolution of an input image and a convolution kernel. For example the filtered image may be generated by a convolution of an input image and a pre trained convolution kernel via hardware or a portion of hardware e.g. a digital signal processor a field programmable gate array a graphics processing unit or other hardware accelerator dedicated to or at least partially dedicated to perform the convolution.

Processing may continue from operation to operation APPLY A THRESHOLD TO THE FILTERED IMAGE TO GENERATE A MASKED IMAGE HAVING MASKED PIXELS AND UNMASKED PIXELS where a masked image may be generated by applying a threshold to the filtered image. For example the masked image may include a number of masked pixels e.g. those pixels deemed to likely not include an object of interest or a portion of an object of interest and a number of unmasked pixels e.g. those more likely to include an object of interest or a portion of an object of interest .

Processing may continue from operation to operation APPLY A CASCADE FILTER TO INDIVIDUAL PIXELS OF THE UNMASKED PIXELS TO DETERMINE ONE OR MORE OBJECT DETECTION REGIONS RELATED TO ONE OR MORE PIXELS PASSING THE CASCADE FILTER where a cascade filter may be applied to individual pixels of the unmasked pixels to determine one or more if any object detection regions related to one or more if any pixels passing the cascade filter. For example the cascade filter may be a multi stage cascade filter.

The resulting object detection regions if any may be optionally merged. They may also be further processed by performing object recognition on the regions to identify an object of interest or a potion of an object of interest in the regions.

Some additional and or alternative details related to process may be illustrated in one or more examples of implementations discussed in greater detail below with regard to .

In the illustrated implementation system may include modules the like and or combinations thereof. For example modules may include convolution module threshold module cascade filter module merge module object recognition module or the like and or combinations thereof. Convolution module may be implemented in hardware and may be configured to perform a convolution of an input image and a convolution kernel to generate a filtered image. Threshold module may be configured to apply a threshold to the filtered image to generate a masked image having a plurality of masked pixels and a plurality of unmasked pixels. Cascade filter module may be configured to perform for individual pixels of the plurality of unmasked pixels a cascade filter to determine one or more object detection regions related to one or more pixels passing the cascade filter. Merge module may be configured to merge a two or more object detection regions to form a merged object detection region. Object recognition module may be configured to perform object recognition on object detection regions and or merged object detection regions. As discussed convolution module may be implemented via hardware . Threshold module cascade filter module merge module and object recognition module may be implemented in various implementations as is discussed further herein and in particular with respect to .

Process may be utilized as a computer implemented method for object detection and or recognition. Process may begin at block RECEIVE AN INPUT IMAGE where an input image may be received. For example an input image may be received at convolution module . The input image may be received by any suitable techniques and may be received by system from another device or may be generated internally at system and transferred from another module of system to convolution module .

Processing may continue from operation to operation PERFORM CONVOLUTION OF INPUT IMAGE AND A CONVOLUTION KERNEL where a convolution of the input image and a convolution kernel may be performed by convolution module to generate a filtered image. For example the convolution may be performed based on a pre trained convolution kernel. For example the convolution module may be maintained in memory and may be updated or trained over time.

Processing may continue from operation to operation TRANSFER FILTERED IMAGE where the filtered image may be transferred from convolution module to threshold module .

Processing may continue from operation to operation APPLY THRESHOLD TO FILTERED IMAGE where a threshold may be applied by threshold module to the filtered image to form a masked image. For example the masked image may include unmasked pixels which may be of interest for further processing and masked pixels which may be disregarded for further processing.

Processing may continue from operation to operation TRANSFER MASKED IMAGE where the masked image may be transferred from threshold module to cascade filter module .

Processing may continue from operation to operation APPLY CASCADE FILTER where a cascade filter may be applied by cascade filter module to the unmasked pixels of the masked image. For example a multi stage cascade filter may be applied to the unmasked pixels to determine passing pixels i.e. pixels which passed all stages of the cascade filter . A passing pixel may be related to an object detection region which may be region surrounding and including the passing pixel for example. Pixels which do not pass any stage of the cascade filter may be rejected and or discarded.

Processing may continue from operation to operation or both labeled TRANSFER OBJECT DETECTION REGIONS where one or more object detection regions may be transferred to merge module and or object recognition module . As discussed in some examples any determined object detection regions may be merged. In other examples any determined object detection regions may be passed directly to object recognition module .

Processing may continue from operation to operation MERGE where any received object detection regions may be merged by merge module to form one or more merged object detection regions.

Processing may continue from operation to operation TRANSFER MERGED REGIONS where any formed merged object detection regions may be transferred from merge module to object recognition module .

Processing may continue from operation or operation to operation IDENTIFY OBJECTS OF INTEREST where object recognition module may perform object recognition on received object detection regions and or received merged object detection regions. Object recognition module may identify any objects which may include for example a face an eye a landmark a written character a human or an automobile or the like.

Process may be utilized as a computer implemented method for object recognition. Process may begin at block RECEIVE INPUT IMAGE where an input image may be received. For example an image file or a video frame or the like may be received for processing.

Processing may continue from operation to operation PERFORM CONVOLUTION OF INPUT IMAGE AND CONVOLUTION KERNEL TO GENERATE FILTERED IMAGE where a convolution of the input image and a convolution kernel may be performed via hardware as discussed herein to generate a filtered image. Operation may be performed at convolution module for example.

Processing may continue from operation to operation APPLY THRESHOLD TO PIXEL OF FILTERED IMAGE where a threshold may be applied to a pixel of the filtered image. The threshold may include for example a pre determined threshold a pre trained threshold a convolution results pre trained threshold or the like. The threshold may be applied to a pixel of the filtered image to determine whether the pixel is a masked or unmasked pixel. Operation may be performed at threshold module for example.

Processing may continue from operation to operation UNMASKED where it may be determined whether the pixel is masked or unmasked based on the application of the threshold. If the pixel is determined to be masked i.e. it is deemed unlikely the pixel includes an object of interest or a portion of an object of interest processing may continue from operation to operation REJECTED PIXELS where the pixel may be rejected.

If the pixel is determined to be unmasked processing may continue from operation to operation PROBE PIXEL WITH STAGE K where the pixel may be probed or tested by a stage of a cascade filter. As will be appreciated an unmasked pixel may be deemed to have passed a convolution and threshold pre filter and may warrant further processing. In general the pixel and or a region surrounding the pixel may be deemed as likely at this stage of processing to include an object of interest or a portion of an object of interest. The pixel may be probed or tested at the current stage of the cascade filter using any of the techniques discussed herein for example.

Processing may continue from operation to operation STAGE K PASSED where it may be determined whether the pixel passes stage K of a cascade filter. Operations and may be performed by cascade filter module for example. If the pixel failed stage K processing may continue from operation to operation REJECTED PIXELS where the pixel may be rejected as unlikely to contain the object of interest or a portion of the object of interest. Processing may continue from operation to operation as is discussed further below.

If the pixel passed stage K processing may continue from operation to operation NEXT STAGE K K 1 where the cascade filter stage count may be increased to the next stage number or a number higher than the last stage indicating all the stages may be complete . As discussed herein a cascade filter may contain any suitable number of stages. As will be appreciated the first time through operation the pixel may be tested at stage 1 the second time through at stage 2 and so on until the pixel passes all the stages or fails a stage and may be rejected.

Processing may continue from operation to operation ALL STAGES PASSED where it may be determined whether all the stages of the cascade filter may have been passed by the pixel. If not the pixel may be processed by one or more additional stages of the cascade filter and processing may continue from operation to operation PROBE PIXEL WITH STAGE K as discussed above.

If the pixel has passed all the stages of the cascade filter processing may continue from operation to operation PASSING PIXEL S where the pixel may stored as a passing pixel. As discussed herein a passing pixel may be related to a object detection region which may include and surround the passing pixel.

Processing may also continue from operation to operation MERGE where passing pixels and or object detection regions related to the passing pixels may be merged to form for example merged object detection region s . Depending on the configurations of the object detection regions they may be merged into a single merged object detection region or multiple object detection regions. The merge operation may be performed by merge module for example. In some examples the merge operation may be performed after all of the pixels have been evaluated i.e. either rejected or passed .

Processing may also continue from operation to operation OBJECT RECOGNITION where object recognition may be performed on object detection regions or merged object detection regions. As discussed object recognition processing may include identifying objects in the regions. The object recognition operation may be performed by object recognition module for example.

Further if the pixel passed all the stages processing may continue from operation to operation ALL PIXELS COMPLETE . As discussed processing may also continue at operation from operation . At operation it may be determined whether all of the unmasked pixels have been evaluated by the process. If more pixels require processing processing may continue from operation to operation APPLY THRESHOLD TO PIXEL OF FILTERED IMAGE as discussed above. If all the pixels are complete processing may continue from operation to operation END where the process may end.

In operation processes and the operations discussed with respect to may provide for object recognition and or a pre filter for object recognition. The pre filter may include for example a convolution of an input image and a convolution kernel to form a filtered image and applying a threshold to the filtered image. The pre filter may also include a cascade filter. The pre filter may accelerate object detection such as facial detection. In general the pre filter may be considered a region filter or a pixel filter such that regions or pixels of a received input image may be rejected and subsequent processing may be avoided on those regions or pixels. Subsequent processing may instead focus on target regions i.e. those regions likely to include the object or face being sought . Such techniques may allow for real time object or face detection particularly as resolutions increase to Full High Definition 1920 1080 and Ultra High Definition 3840 2160 .

Using facial recognition as an illustrative example hardware supporting 15 15 convolutions and using a face template of 32 32 a convolution kernel of 30 15 may be used. Such a convolution kernel may require the use of two neighborhood 15 15 convolutions for example. As will be appreciated the noted sizes are for example purposes only and in particular future hardware may support larger convolutions such as for example 31 31 convolutions. A convolution kernel may be trained from a data set such as for example a data set with 16 000 cropped faces and 300 000 cropped non faces using a linear classifier e.g. a support vector machine a logistic regression or the like . Further a cascade filter may be trained with results from a pre filter combining convolution results and a threshold to form a masked image as discussed above.

Such an implementation may be compared to an implementation having a cascade filter only. Such a cascade filter may be trained with for example 16 000 cropped faces and 19 000 cropped non faces. As will be appreciated such a pre trained cascade filter pre trained with cropped and non cropped faces will be different from the cascade filter trained with results from a pre filter combining convolution results and a threshold to form a masked image as discussed immediately above i.e. a convolution pre trained cascade filter based on their differing trainings.

To compare the two implementations the false positive rate per window FPPW is evaluated. The following table illustrates the results 

The results in Table 1 illustrate implementations using a Speeded Up Robust Features SURF cascade filter as discussed above. Similar results may be expected for other cascade filters such as for example Viola Jones based cascade filters or the like.

The shown theoretical acceleration shown in Table 1 may be determined as follows. A hardware convolution of size 15 15 may run at 0.5 pixel clock if the template is of the uint8 elements of an array converted into unsigned 8 bit integers type or at 0.125 pixel clock if the template is of the int16 elements of an array converted into 16 bit integers type. An unsigned 8 bit type may be assumed meaning one convolution at one pixel may require 2 clocks. The convolution and threshold pre filter may require 2 convolutions and 1 threshold operation meaning an individual pixel position may require 5 clocks. In comparison a single instruction multiple data SIMD implementation of a first stage of a cascade filter may require more than 25 clocks at 256 bits.

The convolution and threshold pre filter may filter more than 86 of the pixels in an image see Table 1 . In comparison a first stage of a cascade filter may filter only 75 of the pixels in an image. Therefore the convolution and threshold pre filter technique may be 5 much faster requiring 5 clocks instead of 25 clocks or more and more effective. Further the convolution and threshold pre filter technique along with the 7 stage cascade filter may have fewer weak classifiers than a standard 8 stage cascade filter 204 v. 251 see Table 1 .

As discussed the convolution and threshold pre filter techniques along with cascade filter techniques discussed herein may have many advantages in object detection implementations. First as just described the techniques may provide acceleration up to 5 or more . Further as discussed the convolution module may be implemented in hardware as may other modules which may provide less power consumption. Such advantages may be especially important in battery operated and or mobile devices. Also the implementations discussed may leave valuable computing resources e.g. at the central processing unit s and or graphics processing unit s available for other simultaneous computing requirements such as for example video decoding Open Graphics Library OpenGL rendering or the like.

While implementation of example processes and processes discussed with respect to may include the undertaking of all blocks shown in the order illustrated the present disclosure is not limited in this regard and in various examples implementation of processes and may include the undertaking only a subset of the blocks shown and or in a different order than illustrated.

In addition any one or more of the blocks of and processes discussed with respect to may be undertaken in response to instructions provided by one or more computer program products. Such program products may include signal bearing media providing instructions that when executed by for example a processor may provide the functionality described herein. The computer program products may be provided in any form of computer readable medium. Thus for example a processor including one or more processor core s may undertake one or more of the blocks shown in

As used in any implementation described herein the term module refers to any combination of software firmware and or hardware configured to provide the functionality described herein. The software may be embodied as a software package code and or instruction set or instructions and hardware as used in any implementation described herein may include for example singly or in any combination hardwired circuitry programmable circuitry state machine circuitry and or firmware that stores instructions executed by programmable circuitry. The modules may collectively or individually be embodied as circuitry that forms part of a larger system for example an integrated circuit IC system on chip SoC and so forth.

As shown in and discussed above convolution module may be implemented via hardware . Further in various examples cascade filter module may be implemented via hardware central processing units or graphics processing units . Also in various examples merge module may be implemented via central processing units or graphics processing units . Similarly in various examples object recognition module may be implemented via central processing units or graphics processing units .

As discussed hardware may include for example a digital signal processor or a field programmable gate array or other suitable hardware accelerator. Hardware may be a hardware module implementing convolution module via dedicated hardware i.e. a portion of hardware dedicated to a convolution function which may implement the convolution of an input image and a convolution kernel as discussed herein . In various embodiments the implementations of threshold module cascade filter module merge module and or object recognition module may be include hardware implementations and or software implementations. For example modules implemented via central processing units may be implemented via software. Modules implemented via graphics processing units may be implemented via hardware if available or via software if applicable for example.

Central processing units may include any suitable implementation including for example microprocessor s multicore processors application specific integrated circuits chip s chipsets or the like. Further graphics processing units may include any suitable implementation including for example processor s multicore processors application specific integrated circuits programmable logic devices graphics cards integrated graphics general purpose graphics processing unit s or the like. In addition memory stores may be any type of memory such as volatile memory e.g. Static Random Access Memory SRAM Dynamic Random Access Memory DRAM etc. or non volatile memory e.g. flash memory etc. and so forth. In a non limiting example memory stores may be implemented by cache memory. In various examples system may be implemented as a chipset or as a system on a chip.

As will be appreciated the implementation of is similar to the implementation of with the exception that convolution module may be implemented via graphics processing units as shown. Graphics processing units may implement convolution module via dedicated hardware i.e. a portion of graphics processing units dedicated to a convolution function which may implement the convolution of an input image and a convolution kernel as discussed herein . In general convolution module may be a hardware based implementation via graphics processing units . Further in various examples threshold module may be implemented via graphics processing units . Also in various examples cascade filter module may be implemented via central processing units or graphics processing units . In various examples Merge module may be implemented via central processing units or graphics processing units . Similarly in various examples object recognition module may be implemented via central processing units or graphics processing units .

As discussed in various embodiments the implementations of threshold module cascade filter module merge module and or object recognition module may be include hardware implementations and or software implementations. For example modules implemented via central processing units may be implemented via software. Modules implemented via graphics processing units may be implemented via hardware if available or via software if applicable for example. Also as discussed central processing units may include any suitable implementation including for example microprocessor s multicore processors application specific integrated circuits chip s chipsets or the like. Further graphics processing units may include any suitable implementation including for example processor s multicore processors application specific integrated circuits programmable logic devices graphics cards integrated graphics general purpose graphics processing unit s or the like. In addition memory stores may be any type of memory such as volatile memory e.g. Static Random Access Memory SRAM Dynamic Random Access Memory DRAM etc. or non volatile memory e.g. flash memory etc. and so forth. In a non limiting example memory stores may be implemented by cache memory. In various examples system may be implemented as a chipset or as a system on a chip.

In various implementations system includes a platform coupled to a display . Platform may receive content from a content device such as content services device s or content delivery device s or other similar content sources. A navigation controller including one or more navigation features may be used to interact with for example platform and or display . Each of these components is described in greater detail below.

In various implementations platform may include any combination of a chipset processor memory storage graphics subsystem applications and or radio . Chipset may provide intercommunication among processor memory storage graphics subsystem applications and or radio . For example chipset may include a storage adapter not depicted capable of providing intercommunication with storage .

Processor may be implemented as a Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors x86 instruction set compatible processors multi core or any other microprocessor or central processing unit CPU . In various implementations processor may be dual core processor s dual core mobile processor s and so forth.

Memory may be implemented as a volatile memory device such as but not limited to a Random Access Memory RAM Dynamic Random Access Memory DRAM or Static RAM SRAM .

Storage may be implemented as a non volatile storage device such as but not limited to a magnetic disk drive optical disk drive tape drive an internal storage device an attached storage device flash memory battery backed up SDRAM synchronous DRAM and or a network accessible storage device. In various implementations storage may include technology to increase the storage performance enhanced protection for valuable digital media when multiple hard drives are included for example.

Graphics subsystem may perform processing of images such as still or video for display. Graphics subsystem may be a graphics processing unit GPU or a visual processing unit VPU for example. An analog or digital interface may be used to communicatively couple graphics subsystem and display . For example the interface may be any of a High Definition Multimedia Interface Display Port wireless HDMI and or wireless HD compliant techniques. Graphics subsystem may be integrated into processor or chipset . In some implementations graphics subsystem may be a stand alone card communicatively coupled to chipset .

The graphics and or video processing techniques described herein may be implemented in various hardware architectures. For example graphics and or video functionality may be integrated within a chipset. Alternatively a discrete graphics and or video processor may be used. As still another implementation the graphics and or video functions may be provided by a general purpose processor including a multi core processor. In further embodiments the functions may be implemented in a consumer electronics device.

Radio may include one or more radios capable of transmitting and receiving signals using various suitable wireless communications techniques. Such techniques may involve communications across one or more wireless networks. Example wireless networks include but are not limited to wireless local area networks WLANs wireless personal area networks WPANs wireless metropolitan area network WMANs cellular networks and satellite networks. In communicating across such networks radio may operate in accordance with one or more applicable standards in any version.

In various implementations display may include any television type monitor or display. Display may include for example a computer display screen touch screen display video monitor television like device and or a television. Display may be digital and or analog. In various implementations display may be a holographic display. Also display may be a transparent surface that may receive a visual projection. Such projections may convey various forms of information images and or objects. For example such projections may be a visual overlay for a mobile augmented reality MAR application. Under the control of one or more software applications platform may display user interface on display .

In various implementations content services device s may be hosted by any national international and or independent service and thus accessible to platform via the Internet for example. Content services device s may be coupled to platform and or to display . Platform and or content services device s may be coupled to a network to communicate e.g. send and or receive media information to and from network . Content delivery device s also may be coupled to platform and or to display .

In various implementations content services device s may include a cable television box personal computer network telephone Internet enabled devices or appliance capable of delivering digital information and or content and any other similar device capable of unidirectionally or bidirectionally communicating content between content providers and platform and display via network or directly. It will be appreciated that the content may be communicated unidirectionally and or bidirectionally to and from any one of the components in system and a content provider via network . Examples of content may include any media information including for example video music medical and gaming information and so forth.

Content services device s may receive content such as cable television programming including media information digital information and or other content. Examples of content providers may include any cable or satellite television or radio or Internet content providers. The provided examples are not meant to limit implementations in accordance with the present disclosure in any way.

In various implementations platform may receive control signals from navigation controller having one or more navigation features. The navigation features of controller may be used to interact with user interface for example. In embodiments navigation controller may be a pointing device that may be a computer hardware component specifically a human interface device that allows a user to input spatial e.g. continuous and multi dimensional data into a computer. Many systems such as graphical user interfaces GUI and televisions and monitors allow the user to control and provide data to the computer or television using physical gestures.

Movements of the navigation features of controller may be replicated on a display e.g. display by movements of a pointer cursor focus ring or other visual indicators displayed on the display. For example under the control of software applications the navigation features located on navigation controller may be mapped to virtual navigation features displayed on user interface for example. In embodiments controller may not be a separate component but may be integrated into platform and or display . The present disclosure however is not limited to the elements or in the context shown or described herein.

In various implementations drivers not shown may include technology to enable users to instantly turn on and off platform like a television with the touch of a button after initial boot up when enabled for example. Program logic may allow platform to stream content to media adaptors or other content services device s or content delivery device s even when the platform is turned off. In addition chipset may include hardware and or software support for 8.1 surround sound audio and or high definition 7.1 surround sound audio for example. Drivers may include a graphics driver for integrated graphics platforms. In embodiments the graphics driver may comprise a peripheral component interconnect PCI Express graphics card.

In various implementations any one or more of the components shown in system may be integrated. For example platform and content services device s may be integrated or platform and content delivery device s may be integrated or platform content services device s and content delivery device s may be integrated for example. In various embodiments platform and display may be an integrated unit. Display and content service device s may be integrated or display and content delivery device s may be integrated for example. These examples are not meant to limit the present disclosure.

In various embodiments system may be implemented as a wireless system a wired system or a combination of both. When implemented as a wireless system system may include components and interfaces suitable for communicating over a wireless shared media such as one or more antennas transmitters receivers transceivers amplifiers filters control logic and so forth. An example of wireless shared media may include portions of a wireless spectrum such as the RF spectrum and so forth. When implemented as a wired system system may include components and interfaces suitable for communicating over wired communications media such as input output I O adapters physical connectors to connect the I O adapter with a corresponding wired communications medium a network interface card NIC disc controller video controller audio controller and the like. Examples of wired communications media may include a wire cable metal leads printed circuit board PCB backplane switch fabric semiconductor material twisted pair wire co axial cable fiber optics and so forth.

Platform may establish one or more logical or physical channels to communicate information. The information may include media information and control information. Media information may refer to any data representing content meant for a user. Examples of content may include for example data from a voice conversation videoconference streaming video electronic mail email message voice mail message alphanumeric symbols graphics image video text and so forth. Data from a voice conversation may be for example speech information silence periods background noise comfort noise tones and so forth. Control information may refer to any data representing commands instructions or control words meant for an automated system. For example control information may be used to route media information through a system or instruct a node to process the media information in a predetermined manner. The embodiments however are not limited to the elements or in the context shown or described in .

As described above system may be embodied in varying physical styles or form factors. illustrates implementations of a small form factor device in which system may be embodied. In embodiments for example device may be implemented as a mobile computing device having wireless capabilities. A mobile computing device may refer to any device having a processing system and a mobile power source or supply such as one or more batteries for example.

As described above examples of a mobile computing device may include a personal computer PC laptop computer ultra laptop computer tablet touch pad portable computer handheld computer palmtop computer personal digital assistant PDA cellular telephone combination cellular telephone PDA television smart device e.g. smart phone smart tablet or smart television mobile internet device MID messaging device data communication device and so forth.

Examples of a mobile computing device also may include computers that are arranged to be worn by a person such as a wrist computer finger computer ring computer eyeglass computer belt clip computer arm band computer shoe computers clothing computers and other wearable computers. In various embodiments for example a mobile computing device may be implemented as a smart phone capable of executing computer applications as well as voice communications and or data communications. Although some embodiments may be described with a mobile computing device implemented as a smart phone by way of example it may be appreciated that other embodiments may be implemented using other wireless mobile computing devices as well. The embodiments are not limited in this context.

As shown in device may include a housing a display an input output I O device and an antenna . Device also may include navigation features . Display may include any suitable display unit for displaying information appropriate for a mobile computing device. I O device may include any suitable I O device for entering information into a mobile computing device. Examples for I O device may include an alphanumeric keyboard a numeric keypad a touch pad input keys buttons switches rocker switches microphones speakers voice recognition device and software and so forth. Information also may be entered into device by way of microphone not shown . Such information may be digitized by a voice recognition device not shown . The embodiments are not limited in this context.

Various embodiments may be implemented using hardware elements software elements or a combination of both. Examples of hardware elements may include processors microprocessors circuits circuit elements e.g. transistors resistors capacitors inductors and so forth integrated circuits application specific integrated circuits ASIC programmable logic devices PLD digital signal processors DSP field programmable gate array FPGA logic gates registers semiconductor device chips microchips chip sets and so forth. Examples of software may include software components programs applications computer programs application programs system programs machine programs operating system software middleware firmware software modules routines subroutines functions methods procedures software interfaces application program interfaces API instruction sets computing code computer code code segments computer code segments words values symbols or any combination thereof. Determining whether an embodiment is implemented using hardware elements and or software elements may vary in accordance with any number of factors such as desired computational rate power levels heat tolerances processing cycle budget input data rates output data rates memory resources data bus speeds and other design or performance constraints.

One or more aspects of at least one embodiment may be implemented by representative instructions stored on a machine readable medium which represents various logic within the processor which when read by a machine causes the machine to fabricate logic to perform the techniques described herein. Such representations known as IP cores may be stored on a tangible machine readable medium and supplied to various customers or manufacturing facilities to load into the fabrication machines that actually make the logic or processor.

While certain features set forth herein have been described with reference to various implementations this description is not intended to be construed in a limiting sense. Hence various modifications of the implementations described herein as well as other implementations which are apparent to persons skilled in the art to which the present disclosure pertains are deemed to lie within the spirit and scope of the present disclosure.

In one example a computer implemented method for object detection may include performing via hardware a convolution of an input image and a convolution kernel to generate a filtered image. A threshold may be applied to the filtered image to generate a masked image having masked pixels and unmasked pixels. A cascade filter may be applied to individual pixels of the unmasked pixels of the masked image to determine one or more object detection regions related to one or more pixels passing the cascade filter.

In one example a computer implemented method for object recognition may include performing via hardware a convolution of an input image and a convolution kernel to generate a filtered image. A threshold may be applied to the filtered image to generate a masked image having masked pixels and unmasked pixels. A cascade filter may be applied to individual pixels of the unmasked pixels of the masked image to determine one or more object detection regions related to one or more pixels passing the cascade filter. Further the image may be received. Object recognition may be performed on the one or more object regions such that performing the object recognition may include identifying an object in an object region. The object may a face an eye a landmark a written character a human or an automobile. Further two or more object regions may be merged to form a merged object region. The input image may include an image file or a video frame. The hardware may include a digital signal processor a graphics processing unit or a field programmable gate array. The convolution kernel may include a designed convolution kernel or a pre trained convolution kernel or a linear classifier trained by a large scale training set the large scale training set including images containing the object and images not containing the object. Applying the threshold to the filtered image may include applying a pre trained threshold or applying a convolution results pre trained threshold. Performing the convolution may include performing the convolution of the input image on a pixel by pixel basis. Applying the threshold to the filtered image may include applying the threshold to the filtered image on a pixel by pixel basis. The input image the filtered image and the masked image may be the same size. The masked pixels may be identified by a value of 1 and the unmasked pixels may be identified by a value of 0. Applying the cascade filter may include applying a seven stage cascade filter. Applying the cascade filter may include determining for a first stage of the cascade filter whether a first unmasked pixel of the plurality of unmasked pixels passes the first stage and if the first unmasked pixel passes the first stage transferring the first unmasked pixel to a second stage of the cascade filter or if the first unmasked pixel fails the first stage rejecting the first unmasked pixel. An object detection region may be related to a passing pixel the first object region may have a size of 32 pixels by 32 pixels and the first passing pixel may be in the center of the first object region. The cascade filter may include a Viola Jones cascade filter or a boosted cascade filter.

Further applying the threshold to the filtered image may include applying the threshold to the filtered image via the digital signal processor the graphics processing unit or the field programmable gate array. Applying the cascade filter may include applying the cascade filter via the graphics processing unit or a central processing unit. Performing object recognition on the object detection regions may include performing object recognition on the object regions via the central processing unit. Merging the two or more object detection regions may include merging the two or more object detection regions via the central processing unit.

In other examples a system for object recognition on a computer may include one or more processors one or more memory stores a hardware module a threshold module and a cascade filter module and or combinations thereof. The one or more processors may be communicatively coupled to the hardware module. The one or more memory stores may be communicatively coupled to the one or more processors. The hardware module may be configured to perform a convolution of an input image and a convolution kernel to generate a filtered image. The threshold module may be configured to apply a threshold to the filtered image to generate a masked image having masked pixels and unmasked pixels. The cascade filter module may be configured to perform for individual pixels of the unmasked pixels a cascade filter to determine object regions related to pixels passing the cascade filter.

In another example the system for object recognition on a computer may further include a graphics processing unit a merge module and an object recognition module. The graphics processing unit may be communicatively coupled to the one or more processors. The merge module may be configured to merge two or more object regions to form a merged object region. The object recognition module may be configured to perform object recognition on the object regions or a merged object region.

In another example the system may further include the object including a face an eye a landmark a written character a human or an automobile. The input image may include an image file or a video frame. The hardware module may include a digital signal processor a graphics processing unit or a field programmable gate array. The convolution kernel may include a designed convolution kernel or a pre trained convolution kernel or a linear classifier trained by a large scale training set the large scale training set including images containing the object and images not containing the object. The threshold module may be further configured to apply at least one of a pre trained threshold or a convolution results pre trained threshold. The hardware module may be further configured to perform the convolution of the input image on a pixel by pixel basis. The threshold module may be further configured to apply the threshold to the filtered image on a pixel by pixel basis. The input image the filtered image and the masked image may be a same size. The masked pixels may be identified by a value of 1 and the unmasked pixels are identified by a value of 0. The cascade filter module may include a seven stage cascade filter. The cascade filter module may be further configured to perform the cascade filter by determining for a first stage of the cascade filter whether a first unmasked pixel passes the first stage and if the first unmasked pixel passes the first stage transferring the first unmasked pixel to a second stage of the cascade filter or if the first unmasked pixel fails the first stage rejecting the first unmasked pixel. An object region may be related to a passing pixel the first object region may have a size of 32 pixels by 32 pixels and the first passing pixel may be in the center of the first object region. The cascade filter may include a Viola Jones cascade filter or a boosted cascade filter.

In a further example at least one machine readable medium may include a plurality of instructions that in response to being executed on a computing device causes the computing device to perform the method according to any one of the above examples.

In a still further example an apparatus may include means for performing the methods according to any one of the above examples.

The above examples may include specific combination of features. However such the above examples are not limited in this regard and in various implementations the above examples may include the undertaking only a subset of such features undertaking a different order of such features undertaking a different combination of such features and or undertaking additional features than those features explicitly listed. For example all features described with respect to the example methods may be implemented with respect to the example apparatus the example systems and or the example articles and vice versa.

