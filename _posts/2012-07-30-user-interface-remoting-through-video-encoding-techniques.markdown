---

title: User interface remoting through video encoding techniques
abstract: Methods, techniques, and systems for user interface remoting using video streaming techniques are provided. Example embodiments provide User Interface Remoting and Optimization System (“UIROS”), which enables the efficient remoting of pixel-oriented user interfaces on behalf of their guests using generic video streaming techniques, such as H.264, to send compressed user interface image information in the form of video frame encoded bitstreams. In one embodiment, the UIROS comprises server side support including a UI remoting server, a video encoder, and rendering support and client side support including a UI remoting client, a video decoder, and a display. These components cooperate to implement optimized UI remoting that is bandwidth efficient, low latency and CPU efficient.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09277237&OS=09277237&RS=09277237
owner: VMware, Inc.
number: 09277237
owner_city: Palo Alto
owner_country: US
publication_date: 20120730
---
The present disclosure relates to methods techniques and systems for user interface remoting and in particular to methods techniques and systems for efficient remoting of interactive user interfaces using video streaming and or video encoding technologies.

The computing industry is evolving to a model of computing where the bulk of storage and computing occur at a datacenter or in the cloud e.g. networked Internet accessible storage and rich user experiences can be remoted to the user s location using client devices of many different form factors. Significant advancements in virtualization infrastructure networking infrastructure as well as the diversity and proliferation of highly capable and portable client devices have made such remote access highly viable and desirable. For example it is not uncommon for employees especially of large organizations to work remotely and still desire and or require use of their desktops and applications at their home offices. This has become possible through virtualization technology that allows a user s desktop and applications to be run in a datacenter while the actual user interface the input output I O to the desktop and applications is mimicked on a remote client device. Mimicking of the user interface is accomplished by remoting the user interface that is directing e.g. sending forwarding transmitting communicating or the like screen output to the remote device for example to a display associated with the client device and receiving input device data from the remote device for example through keyboard mouse touch or other device input . The entire desktop for example the user interface of an operating system running on a host computing system or virtualization server or a single application running on the desktop may be remoted on devices such as smart phones tablets notebook personal computers PCs desktop PCs smart TVs other form factor computing devices and the like.

Some challenges including the latency of data arriving to and from such client devices which impact the user experience remain. Latency may be a result of limitations of the client devices and or the networks connecting the client devices to the servers where the desktops and or applications are running or hosted . In addition some networks and or client devices have bandwidth limitations that can make it difficult to present a rich user interface experience in a responsive way. The more data that needs to be transferred quickly to a client device the more likely latency and bandwidth limitations are encountered.

Embodiments described herein provide enhanced computer and network based methods techniques and systems for user interface remoting using video streaming techniques. As used herein the phrase user interface remoting refers to either remoting an entire desktop and or an application user interface unless noted otherwise. Example embodiments provide a User Interface Remoting and Optimization System UIROS which enables virtualization environments to efficiently remote user interfaces on behalf of their guests guest operating systems and or guest applications using generic video streaming techniques such as the well known H.264 video encoding standard to send compressed user interface image information in the form of video frame encoded bitstreams. A generic video stream technique e.g. format codec or the like refers broadly to one not specifically optimized or designed for user interface remoting and thus may include formats that can be decoded for example by off the shelf proprietary standardized or other video decoders e.g. generic video decoders . This enables a client device with a generic often hardware or embedded video decoder to perform user interface UI remoting without being specifically or specially programmed to do so.

The UIROS exploits user interface semantics to take advantage of the high frame coherency that user interfaces commonly exhibit. That is for many user interface operations only a small portion of pixels change between consecutive frames frames as defined by the video streaming protocol used . Commonly for example in user activities such as scrolling window moves uncovering regions and the like a set of pixels which have already been transferred to a client device are re positioned e.g. moved to a new location in the target frame but not changed otherwise. This allows client devices to cache and reuse pixel information on the client side receiving only information relating to how the pixel information has moved in the target frame and any new information that needs to be rendered. Example embodiments of the UIROS advantageously send only these updates as video frame encoded bitstreams so that client devices receive more compact and faster updates thereby increasing the overall efficiency of remoting user interfaces and thus decreasing UI latency. Client devices may include any type of device that supports the video streaming protocol employed such as for example smart phones tablets notebook computers desktop computers smart televisions TVs and the like.

In addition by using generic video streaming protocols such as H.264 otherwise known as Advanced Video Coding H.265 Microsoft s VC 1 or Google s VP8 the UIROS can exchange optimized user interface remoting data with client devices without need for a specialized potentially high cost proprietary device driver or specialized hardware installed on the client. This is because many client devices are shipped already with hardware accelerators that support video decoding using these standards and most popular web browsers such as Internet Explorer Google and Chrome are now configured or in the near future will be configured to use HTML 5 which supports a tag for providing a standard network protocol for transmitting a video stream such as H.264 over TCP IP which may be passed through to a resident hardware accelerated decoder if available. The H.264 standard described further below defines the syntax of an encoded video bitstream in addition to the techniques for decoding the bitstream. Although described with reference to H.264 it is to be understood that the techniques methods and systems described herein also will operate with any other generic video standard and that H.264 VC1 and VP8 are simply examples thereof. Note that the techniques methods and systems described herein will operate with proprietary as well as standardized or public video formats for example those approved by a standardization organization or publicly available however one of the desired outcomes of these techniques is to operate with standard web browsers executing on unmodified client devices that include generic video decoders in order to make optimized user interface remoting viable for everyone on all sorts of client devices. Using a generic protocol and directing updates to a web browser or the native video driver that provides built in support for video streaming in client devices eliminates a need to create specialized client devices with specialty device support for UI remoting.

In typical video streaming different techniques including exhaustive searching are used to determine motion estimation to determine how pixels change from frame to frame. Motion estimation is the process of finding similar blocks of pixels of a defined size for example 16 16 or 4 4 to a target block of pixels. Similarity is defined in different ways by different algorithms. If a similar block of pixels is found then only movement and or difference data needs to be transmitted e.g. communicated forwarded sent or the like and a reference to the similar block of pixels instead of all of the pixels. Exhaustive searching techniques for determining motion estimation are CPU intensive and sometimes prohibitive.

As described in detail below using video streaming techniques for UI remoting presents opportunities for optimization that do not use such exhaustive searching techniques. Because of the frame coherency of many user interface activities the UIROS can more easily locate similar frames during the motion estimation process. For example the UIROS may determine pixel reusability by examining one or more of the following the frame buffer used by the guest in addition to analyzing user input device movement the graphics commands sent by the guest to the virtualization support code such as the virtualization logic or a component thereof or to the host computing system and commands invoked by a guest application using an applications programming interface API directed to this purpose as described further below. This examination process may provide a fingerprint of activities that result in or should result in reusable blocks. The UIROS may also analyze feedback information about client load and network conditions to adjust e.g. calibrate tune etc. the timing and or content of the video encodings and streaming.

In the embodiment illustrated host hardware platform may comprise a computer memory one or more central processing units CPU a frame buffer FB and one or more network connections accessible for example via network interface card NIC . In addition the host hardware platform may optionally comprise other components such as one or more displays graphics processing units GPU input output I O devices e.g. keyboard mouse CRT or LCD display etc. or other computer readable media .

Virtualization logic is loaded into memory of host hardware platform and may execute on one or more CPUs . Virtualization logic may alternatively be implemented in software hardware or firmware or some combination thereof. Virtualization logic includes one or more virtual machine monitors VMM and VMX processes which can support multiple virtual machines VM which can concurrently be instantiated and executed. As used herein a virtual machine or VM is an abstraction representing the execution space that a guest operating system and applications the guest may execute within such as VM . Each virtual machine may include a guest operating system guest OS e.g. guest OSes and one or more corresponding applications e.g. guest applications running on each respective guest OSes . In one example embodiment each VM when executing is made accessible to a different user who is remotely connected from a different client connection. The number of VMs supported by any particular host may vary for example based on aspects such as the hardware capabilities virtualization logic configurations and desired performance. Other code may also execute on virtualization logic .

Each VM may require virtualization of one or more aspects implemented by the virtualization logic and or the host hardware platform . That is the virtualization logic may provide emulated hardware and drivers to each VM. For example through the VMX processes and the VMMs the virtualization logic may provide one or more of a virtual CPU VCPU a virtual memory VMEM virtual device drivers VDD a virtual file system and virtual disks virtual network capabilities and virtual graphics capabilities such as virtual graphics adaptors drivers and command emulation and the like. Each virtualization environment may function as an equivalent of a standard x86 hardware architecture platform such that any operating system e.g. Microsoft Windows Linux Solaris 86 NetWare FreeBSD etc. may be installed as a guest OS e.g. guest OS to execute applications in an instantiated virtual machine. Note that in other embodiments virtualization of other hardware architectures may be supported.

In one embodiment the virtualization logic provides virtualized storage support through a distributed VM file system storage stack and device drivers that communicate with the physical data drives and . In addition the virtualization logic provides virtualized network support through a virtual switch and network stack to communicate with NIC of the host hardware platform . This support may be used to provide the TCP IP connections at the virtualization logic level referred to elsewhere herein. Also the virtualization logic provides virtualized graphics support through the SVGA or VGA graphics adaptor implementations which use the server graphics API such as OpenGl Xserver implementations etc. to communicate with graphics drivers that manage and fill frame buffer of the host hardware using graphics commands. In certain embodiments the graphics capabilities of the host hardware platform may be accelerated through the use of one or more GPUs .

In some embodiments the virtualization execution environments are provided through both a process executing at USER less privileged mode referred to as the VMX process e.g. VMX processes and the VMM executing in a more privileged state e.g. VMMs . Each VM effectively executes in the process space of its respective VMX process that is its memory is mapped to each respective VMX process . A VMX process for example processes may comprise an MKS mouse keyboard screen thread e.g. thread for processing input and output from the respective VM e.g. VMs . In one example UIROS this is where the UI remoting logic and support resides and executes as will be described in detail below. A VMX process also includes USER mode graphics level support such as a virtual SVGA driver . Each VMX process and VMM pair cooperate to provide the effective and isolated virtualization execution environment for each VM to run. In general operation the virtualization logic receives requests from the virtualized device drivers implemented by the VMMs and VMX processes translates or otherwise transfers forwards sends or communicates these requests to corresponding requests to real device drivers or that communicate with real devices resident in the host hardware platform such as frame buffer NIC etc. .

The various terms layers categorizations components used to describe the virtualization server computing system of may be referred to differently without departing from their functionality or the spirit of this disclosure. Also one or more of the components may not be present in any specific implementation. For example the virtual components shown as part of virtualization logic that are not included in each VMM for example one or more of components or the like may be considered in other embodiments to be part of the VMMs . In addition in some embodiments no VMX process is used and the MKS thread capabilities including the UI remoting and virtual graphics adaptor support are integrated instead into the VMMs or into other parts of the virtualization logic . Also in some embodiments the VMMs may be considered to be separate from or part of the VM . Embodiments of the UIROS may be practiced in other virtualized computing environments such as hosted virtual machine systems where the virtualization logic is implemented on top of an operating system executing on host hardware platform instead of directly on the host hardware.

Furthermore in some embodiments some or all of the components of the virtualization server computing system may be implemented or provided in other manners such as at least partially in firmware and or hardware including but not limited to one or more application specific integrated circuits ASICs standard integrated circuits controllers executing appropriate instructions and including microcontrollers and or embedded controllers field programmable gate arrays FPGAs complex programmable logic devices CPLDs and the like. Some or all of the components and or data structures may also be stored as contents e.g. as executable or other machine readable software instructions or structured data on a computer readable medium e.g. a hard disk memory network other computer readable medium or other portable media article to be read by an appropriate drive or via an appropriate connection such as a DVD or flash memory device such as computer readable medium to enable the computer readable medium to execute or otherwise use or provide the contents to perform at least some of the described techniques.

In an example embodiment the server side support includes a UI remoting server a video encoder and rendering support . In some embodiments these components execute as part of the VM Support for example as part of a process e.g. the VMX process in VMware s virtualization environment that executes on virtualization logic which is hosted by host server computing system . For example these components may execute as part of an MKS mouse keyboard screen handling thread which executes as part of VMX processes as described with reference to . In other embodiments these components may be implemented in other parts of the virtualization environment such as part of each VMM virtual machine monitor e.g. VMMs or as other parts of virtualization logic . The rendering support is responsible for receiving the virtual graphics device commands from guest guest applications executed from the desktop using the guest operating system and carrying them out through the graphics stack shown in as graphics API and graphics drivers to the graphics hardware associated with the host such as frame buffer . The video encoder is responsible for encoding the user interface updates as will be described in detail further herein when invoked by the user interface remoting UIR server . The UIR server can transmit user interface updates to a connected client device through a TCP IP connection in the VM support virtualization logic or host or through a TCP IP connection in the guest operating system guest OS for some client device interfaces that may be optimized to receive UI remoting from the guest OS instead of from the virtualization support or .

The client device receives the UI display updates through its TCP IP connection and user interface remoting UIR client . The UI display updates may be initially received through web browser code connected through the TCP IP connection which passes the information e.g. redirects forwards communicates or sends it to the UIR client and or the video decoder . For example in some embodiments the UI display updates are handled by the web browser code s implementation of a tag for example as available under the HTML 5 standard to send the updates to the video decoder . In other embodiments for example those that use an intermediary such as UIR client the web browser code may pass the video bitstream to the UIR client . The UIR client may be implemented for example as Javascript downloaded to the client device upon connection to the VM or at other times to meter how the video is processed as opposed to using whatever implementation the browser code supports for the tag. The video decoder is then invoked e.g. by the web browser code or by the UIR client to reconstruct the bitstream e.g. from a previous cached frame on a move scroll expose region or similar operation and sends e.g. forwards transmits communicates etc. the data stream to be rendered on display .

In example embodiments the components of the server side support and client side support of a UIROS are implemented using standard programming techniques. In general a range of programming languages known in the art may be employed for implementing such example embodiments including using object oriented functional scripting and declarative languages. In addition in other embodiments the functionality of the different components may be distributed amongst themselves in different ways or distributed in other ways yet still achieve the functions of a UIROS.

As mentioned in some embodiments the UIR server UIR client video encoder and video decoder utilize video streaming and compression techniques defined by the H.264 standard although other streaming and compression techniques may be substituted. is a block diagram of an overview of example video streaming using an example generic video streaming protocol. In this example a video source is encoded and transmitted to generate video output using techniques that minimize updates based upon recognizing that previous data can be used to generate a current frame. In particular the video source is examined by prediction logic e.g. code component block program task etc. using a process known as motion estimation to determine to which other data the current block to be rendered corresponds. In some embodiments other data in the current frame is used to predict the data in the current block intraframe prediction . In other embodiments data from a block in a prior transmitted frame is used to predict the data in the current block interframe prediction . For video a variety of motion estimation algorithms may be used including exhaustive searching. When using the H.264 standard blocks of different sizes may be used including 16 16 pixel blocks down to 4 4 pixel blocks. Once the prediction block is selected and it is determined how the block is to be relocated to result in the current desired block to be rendered the data is transformed by transform component e.g. module logic block code program task etc. according to techniques of the streaming and compression protocol and then encoded and typically compressed into a bitstream by encode component . The encoded bitstream is then transmitted or stored in an appropriate syntax to be delivered to a target e.g. client device based upon the video format. When received on the client device the encoded and typically compressed bitstream is then decoded by decode component and then an inverse transform is conducted on the information in the bitstream using transform component to resurrect information for building the block to be rendered. The transform data along with other data from the bitstream for example a pointer reference etc. to a prediction block is then used by the reconstruct component to produce video output for rendering.

When using the H.264 standard the UIROS determines a prediction block called a prediction macroblock and calculates a motion vector encoding how that block is to be moved to efficiently represent many user interface activities addressed in UI remoting. depicts an overview of an example video encoding technique performed according to the H.264 video streaming protocol. The example depicted utilizes interframe prediction using a previously encoded and transmitted frame to perform encoding. That is a prior frame I is used to find a macroblock that is similar to a macroblock in the current frame I 1 to be encoded and transmitted. Prediction macroblock in a past transmitted frame is depicted as containing the exact same pixel data that is to be presented in the macroblock which is being encoded. The motion vector in the current frame being encoded captures the movement of that macroblock from its prior position to its destination position . According to the H.264 standard a residual macroblock is computed that contains differences between the prediction macroblock and the target macroblock being encoded. Due to the nature of UI encoding bit blit operations the residual macroblock is typically null empty because the information is not changed just moved. The H.264 standard specifies how the prediction macroblock is encoded along with motion vector so that the decoder can reuse an already received block of cached pixel data move it to the position indicated by motion vector and apply any information contained in the residual macroblock to render the resultant macroblock . The H.264 standard specifies how all of this information is encoded into a compressed bitstream that is compact and efficient. More information on the H.264 standard is described in kin Richardson 264 VCcodex 2002 2011 and in lain Richardson 264 Vcodex OnceCodec 2007 2011 incorporated herein by reference in their entireties.

When used with UI remoting the UIR server e.g. UIR server of incorporates knowledge of user interface activities to perform motion estimation to determine an appropriate prediction macroblock for each block being encoded and transmitted to the client device. For example when a user scrolls a document or moves something on the desktop for example a window the UIR server can compute what pixels remain the same and what is the new content additional pixels for the client device to render. Using H.264 or any other similar video encoding the UIR server can send to the client device indications of predictive macroblocks and their motion vectors to correspond to the portions of the user interface that are still to be rendered but in a different location. The UIR server then only needs to encode as new data the pixels that are now to appear on the display screen be rendered by the client device .

Although the examples described herein often refer to remoting a user interface desktop and such actions as scrolling moving grabbing pinching and exposing regions or pixels the techniques described herein can also be used to render any type of display presentation. In addition the concepts and techniques described are applicable to other video encoding techniques including other types of video encoding technologies and browsers that support the same. Also although certain terms are used primarily herein other terms could be used interchangeably to yield equivalent embodiments and examples. In addition terms may have alternate spellings which may or may not be explicitly mentioned and all such variations of terms are intended to be included.

Example embodiments described herein provide applications tools data structures and other support to implement a User Interface Remoting and Optimization System to be used to remote UIs using video encoding technology. In the following description numerous specific details are set forth such as data formats and code logic sequences etc. in order to provide a thorough understanding of the described techniques. The embodiments described also can be practiced without some of the specific details described herein or with other specific details such as changes with respect to the ordering of the logic different logic etc. Thus the scope of the techniques and or functions described are not limited by the particular order selection or decomposition of aspects described with reference to any particular routine module component and the like. For example given the time criticality of the actions involved in UI remoting the decomposition into multiple sequences as depicted in may not likely to be reflected in a live implementation but is so depicted for ease of description.

In block the logic analyzes the user interface subject to remoting for reusable pixel information in the portion of the user interface that has changed. This analysis is described in detail with respect to . In overview the UIR server determines whether the UI command is one that results in a bit blit operation a block transfer of pixel data of already transferred pixel data to a possibly modified location. If so then the operation is likely one that can be represented by an optimized P frame using the video encoding techniques described. If not then the operation may encode the changed regions by sending one or more macroblocks with new pixel data. The reusable pixel techniques described with respect to are performed relative to the portion of the UI that has changed the dirty region or changed portion of the display . The portions of the UI that have not changed may be encoded using video encoding techniques by reusing macroblocks from prior frames or in some embodiments by indicating unchanged regions in the video stream e.g. by using a construct that indicates what macroblocks can be skipped over .

In block the logic calibrates generation of the video stream to be produced. The UIR server tries to generate frames to send to the client device just at the right frequency and point in time so that they make it to the client device in a timely manner and are not stale in the pipe in the case of overloaded network queues. To do this the UIR server logic calibrates generation of the video stream before and potentially while it is being delivered to the client device. Calibration may occur for example as a result of obtaining feedback information from a client device over for example a backchannel regarding network conditions and client load. Feedback may include network latency and bandwidth information as well as client overload conditions. The UIR server may use this information along with other information about the client device such as the device type model etc. to calibrate its synthetic and real time generation of the video stream. When the UIR server determines that the network is overloaded e.g. the transmit buffer is getting overloaded the UIR server may compress harder e.g. more compression of the encodings or slow down the generation of the video frames. In some embodiments depending upon the encoding decoding when bandwidth is limited the UIR may utilize residual frames to deliver progressive enhancements that the client may render accumulatively thus leveraging the additive construct of residual frames. When on the other hand the UIR server determines that the client device not the network is overloaded the UIR server may transmit fewer frames. Similarly when the UIR server determines that there is abundant bandwidth to deliver data to the client device the UIR server may compress lighter to reduce the CPU processing on the host server needed to provide compression of pixel data. Other calibrations may be similarly incorporated. The logic of block may be performed at a variety of times but is typically performed prior to transmitting the video encoding to the client device in block .

In block if the analysis of block returned an indication that such a bit blit operation of previously transferred data is occurring e.g. due to a move scroll expose or other UI operation then the logic continues in block otherwise the logic continues in block .

In block the logic computes the encoding according to the video encoding protocol for example H.264 described above and continues in block . An example of the computation of the video encoding is described further in and accounts for reusable pixel information as well as the data that needs to be sent anew.

In block when the analysis of block returned an indication that an operation related to previously transferred data is not occurring then the logic determines whether an operation to play video has been indicated. If so the logic continues in block otherwise continues in block .

In block the logic computes an encoding for remoting the indicated video playback and then continues in block . This operation may occur for example when a user is using a video on demand application such as YouTube or a video conferencing application like Skype. In this case the logic attempts to leverage the source video stream in constructing the remoted video stream. Such an approach is significantly more CPU efficient than decoding the video stream into pixels only to re encode it onto another video stream as part of the UI. If for some reason the client device is not capable of decoding the original video stream or the available bandwidth to the client device is insufficient to receive the source video stream or for other reasons then the logic transcodes the source stream into a proper form to remote. In some embodiments the motion vector information and macroblocks from the original video stream can be reused at least in part to speed up the transcoding process so that at least a portion of the original video encoding can be leveraged. For example the coordinate system for the area of the UI reserved for the video stream may be different from the coordinate system used for the UI remoting as a whole however the calculations of the new motion vectors may still be informed by the calculations of the motion vectors of the video stream.

In block if the logic has determined that some other UI operation has occurred that requires remoting but for which no motion estimation algorithm is used or is not effective then the logic continues to encode pixel data using standard procedures for example using macroblocks with new data when data has changed or to reuse macroblocks from prior frames or to skip macroblocks when data is unchanged as appropriate and continues in block .

In block the logic transmits the encoded data in an encoded bitstream as dictated by the video protocol employed to the UI remoting code e.g. UIR client in client device in . In some embodiments this is accomplished using a network connection e.g. TCP IP connection in the virtualization logic or host to the web browser not shown running on the client device which has previously established an authenticated connection to the server s TCP IP connection. The web browser can act as a thin veneer and passes the video stream straight to the video decoder often hardware assisted for example video decoder which then renders the data on the display of the client device. In some embodiments code is downloaded to the client device for example as Javascript to meter the feeding of the video stream to the tag processing by the browser so as to control the speed of processing of the video stream. In other embodiments the TCP IP connection to the web browser operates through the guest OS such as TCP IP connection in guest OS . In still other embodiments the encoded data is sent over TCP IP directly to a driver not shown for the video decoder native to the client device. Other embodiments may employ other networking protocols other than TCP IP. depicts these different connections as UIR protocol. 

In block the logic inspects a frame buffer to detect whether a scrolling or move type event has occurred looking for a scrolling or move fingerprint and to determine the reusable pixel information therefrom. In some embodiments this is done by detecting a bit blit by comparing the frame buffer content to a previous frame buffer content upon receiving mouse movement arrow keys scroll dial events and other user input that would indicate a move of previously visible pixels. If a bit blit has been detected appropriate prediction macroblocks and their corresponding motion vectors are generated. Here the frame buffer is typically the virtual frame buffer utilized by the VM that corresponds to the executing application. Other constructs such as blitmap structures not shown such as those implemented by a virtual video adapter driver may be used to support determining whether there are regions in the frame buffer that have changed during some time interval or as a result of certain operations. A description of the creation and other use of a blitmap structure is provided in Byford et al. US 2010 0271379 entitled Method and System for Copying a Framebuffer for Transmission to a Remote Display published on Oct. 28 2010. Also in some systems a prior state of the frame buffer in part or in whole may be cached for comparison to determine reusable pixel information. The logic then continues in block to determine additional possible optimizations keeping track of the ones it has already generated.

In block the logic inspects the guest s graphics command stream to detect move scroll expose or other type of relevant UI events by for example pattern matching particular commands . If so appropriate prediction macroblocks and their corresponding motion vectors are generated for example using information from the previously encoded frames maintained by for example the video encoder of . The logic then continues in block to determine additional possible optimizations keeping track of the ones it has already generated.

In block the logic determines whether it has received notification through for example an API of any UI semantics that reuse pixel information. In some embodiments the logic supports an API that enables applications to take advantage of UI coherence information and knowledge that its UI may be remoted for example in a virtualization environment. An application having awareness of UI remoting may opportunistically cache pixel information for example a next new block of content of scroll pixels or a next photo in a slide show before it is to be rendered on a display screen. For example applications or other components that aid in UI remoting may leverage H.264 decoder frame caching to pre load pixel information to provide a type of lookahead to decrease UI latency on the client device.

If the logic determines it has received notification of UI semantics then the logic continues in block otherwise continues to block . In block the logic determines whether the received notification pertains to one of these commands and if so continues in block otherwise continues to block . In block the logic generates appropriate reusable pixel and or other information as described below and then continues to block .

In block the logic returns the generated pixel information including the prediction macroblocks and their corresponding motion vectors. If no optimizations are possible then new pixel information one or more macroblocks are returned.

In block the logic determines one or more prediction macroblocks from a prior transmitted frame that may be reused as indicated from the analysis of the logic of and as described in . This is done for whatever portions of the display are being remoted since in some examples the entire display screen may or may not be remoted. The results of the motion estimation of will indicate what rectangles are reusable. For example when a document is being scrolled there are some portions of the changed regions of the display e.g. macroblocks that are determined to be reusable and other portions of the changed regions that must be sent as new data e.g. new macroblocks .

In block the logic determines the one or more corresponding motion vectors applicable to the prediction macroblocks as indicated from the analysis of the logic of and as described in .

In block the logic encodes the remaining rectangles of the changed regions as new macroblocks since no reusability has been determined for this pixel information.

In block the logic encodes the unchanged regions of the portion of the display being remoted. As described above this may be performed by referencing existing macroblocks previously transmitted by indicating which macroblocks may be skipped or by other mechanisms.

In block the logic compresses and encodes the one or more prediction macroblocks their corresponding motion vectors and the remaining macroblocks and information and transforms and compresses this information into a bitstream according to the requirements of the video encoding protocol. The encoded bitstream is returned at block .

In block the logic receives an encoded bitstream e.g. from the UIR client via a web browser over a TCP IP connection .

In block the logic decompresses and decodes the bitstream according to the video stream protocol to determine the one or more prediction macroblocks and their associated motion vectors and residual macroblocks. This may include performing an inverse transform to recreate the residual macroblock information.

In block the logic computes the pixels to render by locating the cached pixel information based upon the indicated prediction macroblocks moves the pixels according to their respective motion vectors and adds any difference information encoded in the residual macroblock information. Note that in the typical case bit blits do not result in changed information so that the residual macroblock information is non existent or zero . In some embodiments for example those in which bandwidth is scarce the residual macroblocks are used for progressive refinements. In some cases I Frames key frames are encoded compressed and transmitted and thereby rendered as is.

In block the computed pixel information is rendered on a display device associated with the client device.

All of the above U.S. patents U.S. patent application publications U.S. patent applications foreign patents foreign patent applications and non patent publications referred to in this specification and or listed in the Application Data Sheet are incorporated herein by reference in its entirety.

From the foregoing it will be appreciated that although specific embodiments have been described herein for purposes of illustration various modifications may be made without deviating from the spirit and scope of the present disclosure. For example the methods techniques and systems for performing video encoding for UI remoting discussed herein are applicable to other architectures other than an x86 architecture. Also the methods and systems discussed herein are applicable to differing protocols communication media optical wireless cable etc. and devices such as wireless handsets electronic organizers personal digital assistants portable email machines tablets notebooks game machines pagers navigation devices such as GPS receivers etc. .

