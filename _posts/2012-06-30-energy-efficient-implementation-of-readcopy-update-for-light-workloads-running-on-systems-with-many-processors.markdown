---

title: Energy efficient implementation of read-copy update for light workloads running on systems with many processors
abstract: A technique for determining if a processor in a multiprocessor system implementing a read-copy update (RCU) subsystem may be placed in a low power state. The technique may include performing a first predictive query of the RCU subsystem to request permission for the processor to enter the low power state. If permission is denied, the processor is not placed in the low power state. If permission is granted, the processor is placed in the low power state for a non-fixed duration. Regardless whether permission is denied or granted, a second confirming query of the RCU subsystem is performed to redetermined whether it is permissible for the processor to be in the low power state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08938631&OS=08938631&RS=08938631
owner: International Business Machines Corporation
number: 08938631
owner_city: Armonk
owner_country: US
publication_date: 20120630
---
The present disclosure relates to computer systems and methods in which data resources are shared among data consumers while preserving data integrity and consistency relative to each consumer. More particularly the disclosure concerns an implementation of a mutual exclusion mechanism known as read copy update in a computing environment wherein processors that need to perform callback processing are capable of assuming low power states.

By way of background read copy update also known as RCU is a mutual exclusion technique that permits shared data to be accessed for reading without the use of locks writes to shared memory memory barriers atomic instructions or other computationally expensive synchronization mechanisms while still permitting the data to be updated modify delete insert etc. concurrently. The technique is well suited to both uniprocessor and multiprocessor computing environments wherein the number of read operations readers accessing a shared data set is large in comparison to the number of update operations updaters and wherein the overhead cost of employing other mutual exclusion techniques such as locks for each read operation would be high. By way of example a network routing table that is updated at most once every few minutes but searched many thousands of times per second is a case where read side lock acquisition would be quite burdensome.

The read copy update technique implements data updates in two phases. In the first initial update phase the actual data update is carried out in a manner that temporarily preserves two views of the data being updated. One view is the old pre update data state that is maintained for the benefit of read operations that may have been referencing the data concurrently with the update. The other view is the new post update data state that is seen by operations that access the data following the update. In the second deferred update phase the old data state is removed following a grace period that is long enough to ensure that the first group of read operations will no longer maintain references to the pre update data. The second phase update operation typically comprises freeing a stale data element to reclaim its memory. In certain RCU implementations the second phase update operation may comprise something else such as changing an operational state according to the first phase update.

It is assumed that the data element list of is traversed without locking by multiple readers and occasionally updated by updaters that delete insert or modify data elements in the list. In the data element B is being referenced by a reader r1 as shown by the vertical arrow below the data element. In an updater u1 wishes to update the linked list by modifying data element B. Instead of simply updating this data element without regard to the fact that r1 is referencing it which might crash r1 u1 preserves B while generating an updated version thereof shown in as data element B and inserting it into the linked list. This is done by u1 acquiring an appropriate lock to exclude other updaters allocating new memory for B copying the contents of B to B modifying B as needed updating the pointer from A to B so that it points to B and releasing the lock. In current versions of the Linux kernel pointer updates performed by updaters can be implemented using the rcu assign pointer primitive. As an alternative to locking during the update operation other techniques such as non blocking synchronization or a designated update thread could be used to serialize data updates. All subsequent post update readers that traverse the linked list such as the reader r2 will see the effect of the update operation by encountering B as they dereference B s pointer. On the other hand the old reader r1 will be unaffected because the original version of B and its pointer to C are retained. Although r1 will now be reading stale data there are many cases where this can be tolerated such as when data elements track the state of components external to the computer system e.g. network connectivity and must tolerate old data because of communication delays. In current versions of the Linux kernel pointer dereferences performed by readers can be implemented using the rcu dereference primitive.

At some subsequent time following the update r1 will have continued its traversal of the linked list and moved its reference off of B. In addition there will be a time at which no other reader process is entitled to access B. It is at this point representing an expiration of the grace period referred to above that u1 can free B as shown in .

In the context of the read copy update mechanism a grace period represents the point at which all running tasks e.g. processes threads or other work having access to a data element guarded by read copy update have passed through a quiescent state in which they can no longer maintain references to the data element assert locks thereon or make any assumptions about data element state. By convention for operating system kernel code paths a context switch an idle loop and user mode execution all represent quiescent states for any given CPU running non preemptible code as can other operations that will not be listed here . The reason for this is that a non preemptible kernel will always complete a particular operation e.g. servicing a system call while running in process context prior to a context switch.

In four tasks 0 1 2 and 3 running on four separate CPUs are shown to pass periodically through quiescent states represented by the double vertical bars . The grace period shown by the dotted vertical lines encompasses the time frame in which all four tasks that began before the start of the grace period have passed through one quiescent state. If the four tasks 0 1 2 and 3 were reader tasks traversing the linked lists of or none of these tasks having reference to the old data element B prior to the grace period could maintain a reference thereto following the grace period. All post grace period searches conducted by these tasks would bypass B by following the updated pointers created by the updater.

Grace periods may synchronous or asynchronous. According to the synchronous technique an updater performs the first phase update operation blocks waits until a grace period has completed and then implements the second phase update operation such as by removing stale data. According to the asynchronous technique an updater performs the first phase update operation specifies the second phase update operation as a callback then resumes other processing with the knowledge that the callback will eventually be processed at the end of a grace period. Advantageously callbacks requested by one or more updaters can be batched e.g. on callback lists and processed as a group at the end of an asynchronous grace period. This allows asynchronous grace period overhead to be amortized over plural deferred update operations.

More recently RCU grace period processing has been adapted to account for processor low power states such as on Intel processors the C1E halt state or the C2 or deeper halt states . Operating systems can take advantage of low power state capabilities by using mechanisms that withhold regular timer interrupts from processors in a low power state unless the processors need to wake up to perform work. The dynamic tick framework also called dyntick or nohz in recent versions of the Linux kernel is one such mechanism. In recent RCU implementations designed for low power applications in the Linux kernel the scheduler places a processor in dyntick idle mode using a function called tick nohz stop sched tick . Before actually changing the processor s mode this function invokes another function called rcu needs cpu to check whether the processor has any callback processing work that needs to be performed even if none needs to be done immediately. Historically if the processor had pending callbacks it was not permitted to enter dyntick idle mode. The reason for this is because grace period and callback detection processing is normally driven by the scheduling clock interrupt and such processing will not be performed when the scheduling clock tick is suppressed. Unfortunately keeping the processor out of dyntick idle mode to wait for callbacks to be invoked can cause the processor to remain in a high power mode for many milliseconds following the time its power level could have otherwise been reduced.

Commonly owned U.S. patent application Ser. No. 13 225 425 filed on Sep. 3 2011 hereinafter the 425 application discloses a technique that improves upon the foregoing processing by modifying the rcu needs rcu function in order to provide an energy efficient read copy update implementation for light workloads running on systems with many processors or for workloads that generate many RCU callbacks. In the Linux kernel an embodiment of the disclosed technique is implemented by the RCU FAST NO HZ configuration option. According to the disclosed technique when an operating system scheduler attempts to place a processor in dyntick idle mode or some other low power state that withholds scheduling clock interrupts the modified rcu needs cpu function does several things. During an initial hold off period the rcu needs cpu function notes if the processor has pending callbacks and returns without the processor being placed in dyntick idle mode reporting the callback status to the caller. Once the hold off period is over the processor will be prevented from entering a low power state only in the event that there are one or more RCU callbacks that are ready for invocation or if the processor needs to perform an action that helps advance RCU s grace period machinery and there are also one or more pending callbacks even if they are not ready to be invoked . In either case an operation known as callback flush loop processing will be performed for a specified number of passes. This processing results in alternating attempts to 1 advance the RCU grace period machinery and 2 process the callbacks in a clean environment such as the Linux kernel s softirq context . In particular a function called rcu process callbacks is invoked within the softirq environment to advance the callbacks on the callback lists and process any that are ready to be invoked. At the end of callback processing the rcu process callbacks function re invokes the rcu needs cpu function which then causes the rcu process callbacks function to be re invoked in a separate softirq context and so on until there are hopefully no callbacks. Each hand off between the rcu needs cpu function initially called by the scheduler attempting to place a processor in dyntick idle mode and the rcu process callbacks function called within softirq context represents one pass through the callback flush loop. Callback flush loop processing is continued for a specified number of passes e.g. five or until all of the processor s callbacks have been processed whichever occurs sooner . If the callback flush operations are successful at removing all pending callbacks within a specified number of passes through the loop the processor will be placed in dyntick idle mode.

The technique disclosed in the 425 application allows a processor to be placed in a low power state even if there are pending RCU callbacks provided none require immediate invocation and the processor is not needed for grace period advancement processing. Under this condition callbacks that will not be ready for invocation until one or more grace periods in the future will not prevent a processor from entering a low power state. Such pending callbacks will merely be noted so that the processor can be subsequently reawakened when the callbacks become ready. This can be done by setting a per processor callback flag which may be given a name such as rcu have callbacks that is cleared when the callbacks are eventually processed or when the processor leaves its low power state.

The number of passes through the callback flush loop as well as the hold off period that is observed before entering the loop may be selected using per processor state variables. When RCU ends a grace period a check may be performed to see if there are any other low power state processors with their rcu have callbacks flag set. If so the corresponding processors may be sent interprocessor interrupts IPIs to force them out of their low power state to process their callbacks.

Although the technique disclosed in the 425 application works well the Linux kernel s RCU API can now reliably detect transitions of tasks to and from the idle loop. This allows the decision making rules implemented by rcu needs cpu to be relaxed in favor of allowing low power states to be entered more frequently. Also the use of IPIs to awaken low power state processors to perform RCU processing at the end of grace periods can result in undesirable overhead if the target processor was already awakened for some other reason. Finally applicant has determined that it would be desirable to address a design feature of current implementations of the Linux kernel that restricts RCU to processing a limited number of RCU callbacks at a time e.g. 10 unless there is an excessive number of RCU callbacks to be processed e.g. 10 000 or more . This restriction is useful for limiting RCU s impact on scheduling latency but applicant submits that such limiting may not always be necessary. What is needed is a way for RCU to determine when there is no latency penalty for invoking larger batches of RCU callbacks at a time.

A method system and computer program product are provided for determining if a processor in a multiprocessor system implementing a read copy update RCU subsystem may be placed in a low power state. In an example embodiment the disclosed technique includes performing a first predictive query of the RCU subsystem to request permission for the processor to enter the low power state. If permission is denied the processor is not placed in the low power state. If permission is granted the processor is placed in the low power state for a non fixed duration. Regardless whether permission is denied or granted a second confirming query of the RCU subsystem is performed to redetermine whether it is permissible for the processor to be in the low power state.

In an example embodiment the permission is granted if the processor has no pending callbacks or is not in a holdoff period following a previous invocation of the second confirming query. The permission is denied only if the holdoff period is in effect.

In an example embodiment the second confirming query includes 1 maintaining the processor in its current power state if the processor has no pending RCU callbacks 2 maintaining the processor in its current power state if the processor has pending RCU callbacks and the holdoff period is in effect 3 maintaining the processor in its current power state if the processor has pending RCU callbacks but they are not ready for invocation if the holdoff period is not in effect and if the processor has no other RCU work to perform this operation further including setting a low power state time limit such that if the processor is in a non fixed duration low power state the low power state becomes a fixed duration low power state and 4 performing callback flush loop processing if a holdoff period is not in effect and if the processor has pending RCU callbacks that are ready for invocation or has other RCU work to perform.

In an example embodiment the low power state time period is set using a programmed timer. The timer may be set to a first timer value if there are non lazy RCU callbacks and a second timer value that is longer than the first timer value if only lazy RCU callbacks are present. As used herein the term lazy RCU callbacks refers to RCU callbacks whose only job is to free memory. The term non lazy RCU callbacks refers to RCU callbacks that do something other than or in addition to freeing memory such as waking something up.

In an embodiment the RCU subsystem may processes an unlimited number of RCU callbacks in a single invocation if the processor has no other work to perform. The processor may be determined to have no other work to perform if it is in an idle state with no pending scheduling change and no other immediate processing that needs to be performed by the processor.

The present disclosure provides an improved energy efficient RCU implementation for light workloads running on systems with many processors. The new implementation differs from the technique disclosed in the 425 application discussed in the Background section above. In particular the operations performed by the rcu needs cpu function have been modified and split into two separate operations that separate the decision to allow a processor to enter dyntick idle mode or other low power state from the callback flush processing that accelerates the processor s entry into a low power state. The rcu needs cpu function is now a very minimal function that a scheduler uses to query RCU to request permission to place a processor in a low power state. If rcu needs cpu predicts that the processor can safely enter a low power state the scheduler will disable the scheduling clock interrupt for that processor and place it in a low power state. Then the scheduler invokes a new function which may be called rcu prepare for idle in order to verify that the low power state was properly entered and if not to have the processor perform whatever work is needed by RCU so that the processor may resume its low power state. The result returned by the new rcu needs cpu function is in the nature of a prediction insofar as a full determination of whether the low power state was appropriately entered is not made until a subsequent time when the rcu prepare for idle function is invoked. If rcu needs cpu incorrectly predicts that the processor can enter a low power state then the processing performed by rcu needs cpu will force RCU core processing to execute which has the side effect of the processor exiting the low power state. On the other hand if rcu needs cpu incorrectly predicts that the processor cannot enter the low power state the event that invalidates the prediction will provide the processor another chance to enter this state. An example event is an interrupt that invokes RCU core processing that in turn invokes all callbacks for this processor. In that case the interrupt exit code will attempt to enter a low power state which will succeed because the prediction in the absence of RCU callbacks will be that the processor can in fact enter the low power state. Nevertheless a good prediction record is beneficial since failed predictions result in redundant reprogramming of the hardware that generates the scheduling clock interrupt.

1. Does the processor have any RCU callbacks If not then the processor is predicted to be able to enter a low power state regardless of the second factor 

2. Is the processor in a holdoff period due to having recently repeatedly and unsuccessfully tried to enter a low power state If not then the processor is predicted to be able to enter the low power state regardless of the first factor.

Thus a processor is predicted to be unable to enter a low power state only if it both has RCU callbacks and has recently repeatedly and unsuccessfully tried to enter a low power state.

The implementation of the present disclosure further differs from the technique disclosed in the 425 application in that the latter an IPI at grace period end to awaken processors that entered a low power state with RCU callbacks pending. This can result in needless IPIs in the case where the target processor was awakened for some other reason in the meantime. The present disclosure instead uses a per processor high resolution timer hrtimer that is set for the duration of a typical grace period e.g. 6 jiffies or normal intervals between scheduling clock interrupts in current implementations of the Linux kernel . An advantage of using an hrtimer over an IPI is that the processor can quickly and efficiently cancel the hrtimer should it awaken for any reason. Because the processor awakens when the timer goes off the timer is always canceled. Its handler never actually executes. This is permissible because the hrtimer s job is done when it awakens the processor. If desired the hrtimer may be programmed with first timer value if there are non lazy RCU callbacks and a second timer value that is longer than said first timer value if only lazy RCU callbacks are present.

As another added feature of the implementation presented in the present disclosure RCU s callback processing batch limitation may be relaxed if it is determined that the processor performing the callback processing has nothing else to do. The RCU callback processing batch size limit is used to avoid degrading operating system responsiveness including real time response in the presence of large numbers of RCU callbacks. However if the processor has nothing else to do continuing to invoke RCU callbacks cannot degrade responsiveness. Instead of exiting RCU callback processing when more than a given number of RCU callbacks have been invoked such processing may be continued as long as 

Turning now to the figures wherein like reference numerals represent like elements in all of the several views illustrates an example multiprocessor computer system in which the grace period processing technique described herein may be implemented. In a computer system includes multiple processors . . . a system bus and a program memory . There are also cache memories . . . and cache controllers . . . respectively associated with the processors . . . . A conventional memory controller is again associated with the memory . As shown the memory controller may reside separately from processors . . . e.g. as part of a chipset . Alternatively the memory controller could be provided by plural memory controller instances respectively integrated with the processors . . . as is known in the art .

The computer system may represent any of several different types of computing apparatus. Such computing apparatus may include but are not limited to general purpose computers special purpose computers portable computing devices communication and or media player devices set top devices embedded systems and other types of information handling machines. The term processor as used with reference to the processors . . . encompasses any program execution unit capable of executing program instructions including but not limited to a packaged integrated circuit device such as a microprocessor a processing core within a packaged integrated circuit device such as a microprocessor core or a hardware thread comprising one or more functional units within a processing core such as an SMT thread . Each such execution unit may be referred to as a CPU central processing unit . The processors . . . may be situated within a single computing device or node e.g. as part of a single node SMP system or they may be distributed over plural nodes e.g. as part of a NUMA system a cluster or a cloud . The memory may comprise any type of tangible storage medium capable of storing data in computer readable form for use in program execution including but not limited to any of various types of random access memory RAM various flavors of programmable read only memory PROM such as flash memory and other types of primary storage i.e. program memory . The cache memories . . . may be implemented in several levels e.g. as level 1 level 2 and level 3 caches and the cache controllers . . . may collectively represent the cache controller logic that supports each cache level. As illustrated the memory controller may reside separately from processors . . . for example as part of a discrete chipset. Alternatively the memory controller could be provided by plural memory controller instances that are respectively integrated with the processors . . . .

Each CPU embodied by a given processor is operable to execute program instruction logic under the control of a software program stored in the memory or elsewhere . As part of this program execution logic update operations updaters may execute within a process thread or other execution context hereinafter task on any of the processors . Each updater runs periodically to perform updates on a set of shared data that may be stored in the shared memory or elsewhere . In reference numerals . . . illustrate individual data updaters that respectively execute on the several processors . . . . As described in the Background section above the updates performed by an RCU updater can include modifying elements of a linked list inserting new elements into the list deleting elements from the list and other types of operations. To facilitate such updates the processors are programmed from instructions stored in the memory or elsewhere to implement a read copy update RCU subsystem as part of their processor functions. In reference numbers . . . represent individual RCU instances that may periodically execute on the several processors . . . . Any given processor may also execute a read operation reader . Each reader runs from program instructions stored in the memory or elsewhere in order to periodically perform read operations on the set of shared data stored in the shared memory or elsewhere . In reference numerals . . . illustrate individual reader instances that may respectively execute on the several processors . . . . Such read operations will typically be performed far more often than updates this being one of the premises underlying the use of read copy update. Moreover it is possible for several of the readers to maintain simultaneous references to one of the shared data elements while an updater updates the same data element.

During operation of the computer system an updater will occasionally perform an update to one of the shared data elements . In accordance the philosophy of RCU a first phase update is performed in a manner that temporarily preserves a pre update view of the shared data element for the benefit of readers that may be concurrently referencing the shared data element during the update operation. Following the first phase update the updater may register a callback with the RCU subsystem for the deferred destruction of the pre update view following a grace period second phase update . As described in the Background section above this is known as asynchronous grace period processing. Alternatively the updater may request a synchronous expedited grace period.

The grace period processing performed by the RCU subsystem entails starting new grace periods and detecting the end of old grace periods so that the RCU subsystem knows when it is safe to free stale data or take other actions . Grace period processing may further entail the management of callback lists that accumulate callbacks until they are ripe for batch processing at the end of a given grace period.

Turning now to example components of the RCU subsystem are shown. These components include RCU subsystem data structures some of which are replicated for each of the processors . . . as per processor RCU data structures . The per processor data structures include a set of per processor callback lists a callback flush loop counter a callback flush loop holdoff counter and a low power state timer structure for managing an hrtimer. The manner in which the per processor data structures are used is described in more detail below. Note that the first of these data structures i.e. the callback lists represents prior art because such lists are found in many conventional RCU implementations typically as separate list portions segments of a single linked list. The callback flush loop counter and the callback flush loop holdoff counter also represent prior art because they are used for callback flush loop processing in the Linux RCU FAST NO HZ configuration option described in the Background section above. The low power state timer control structure is new. Although this data structure is shown as a per processor variable in it could also be stored in a leaf rcu node structure in a hierarchical RCU implementation. It should be further noted that a production read copy update implementation will typically include many additional data structures that are not shown in . A discussion of such data structures is omitted for ease of description and in order to focus attention on the particular RCU technique disclosed herein.

The components of the RCU subsystem also include several RCU subsystem support functions namely an RCU reader API Application Programming Interface an RCU updater API a set of RCU core processing functions and a set of low power state processing functions .

As shown in the RCU reader API comprises a reader registration component A and a reader unregistration component B. These components are respectively invoked by readers as they enter and leave their RCU read side critical sections. This allows the RCU subsystem to track reader operations and determine when readers are engaged in RCU protected read side critical section processing. In an example embodiment the reader registration component A and the reader unregistration component B may be respectively implemented using the rcu read lock and rcu read unlock primitives found in existing read copy update implementations.

The RCU updater API comprises a register callback component A. The register callback component A is used by updaters to register a callback following a first phase update to a shared data element . A call to the register callback component A initiates processing that places the callback on one of the RCU callback lists associated with the processor that runs the updater . This starts an asynchronous grace period so that the callback can be processed after the grace period has ended as part of second phase update processing to remove stale data or perform other actions . In an example embodiment the register callback component A may be implemented using the existing call rcu primitive found in conventional read copy update implementations.

In the preceding paragraph it was noted that the register callback component A places a callback on one of the RCU callback lists for a given processor . In an example embodiment the RCU callback lists for each processor . . . may comprise four separately identified list portions of a single RCU callback list. These list portions may be referred to as done current next ready and next. Each of these callback list portions may be processed in separate stages in conjunction with separate grace periods. This allows new callbacks to safely accumulate while other callbacks are being processed. For example at the end of a given grace period all callbacks on the done list portion will be ready for immediate invocation. Callbacks on the current list portion will be invoked at the end of the next following grace period. New callbacks are placed on the next list portion and will not be ready to be invoked until the end of the second grace period that follows the current grace period. The next ready list portion provides an optimization that allows for the fact that different processors have different ideas of the current grace period.

The component of the RCU subsystem that actually processes callbacks is a callback handler A which is one of the RCU core processing functions . The callback handler could be and usually is executed in a deferred manner in a separate environment such as in softirq context in the Linux kernel . The RCU core processing functions also include a quiescent state tracker B which tracks processor quiescent states and RCU grace periods.

The low power state processing functions include a low power state permission query function A and a low power state enter callback flush function B. The low power state permission query function A embodies the modified rcu needs cpu function described in the Introduction section above. The low power state enter callback flush function B embodies the new rcu prepare for idle function described in the Introduction section. The operations of these functions are described in more detail below in connection with .

With reference now to example operations that may be performed by the low power state permission query function A are shown. This function is invoked by the scheduler s low power state subsystem A in order to quickly place one of the processors . . . in a low power state in which the scheduling clock interrupt is suppressed such as dyntick idle mode . The low power state subsystem A uses the low power state permission query function A as a way of predicting whether the RCU subsystem can tolerate the anticipated low power state and either enter or not enter that state based on the prediction. If the RCU subsystem does not object the scheduler s low power state subsystem A will immediately place the processor in a low power state. If the RCU subsystem does object the low power state subsystem A will defer such processing to a later time. As described in the Introduction section the effect of incorrectly predicting that a processor may enter a low power state is mitigated by the fact that the processing performed by the low power state enter callback flush function B will force RCU core processing to execute which has the side effect of the processor exiting the low power state. On the other hand the effect of incorrectly predicting that the processor cannot enter the low power state is mitigated by the fact that the event which invalidates the prediction will provide the processor another chance to enter this state.

In block a check is made to determine whether the target processor has any pending callbacks. If it does block a further check is made to determine whether the processor is in a holdoff period following a failed attempt by the power state enter callback flush function B to place the processor in a low power state using the flush loop processing described in more detail below . If a holdoff period is in effect the low power state permission query function A returns to its caller in block reporting a status value indicating that permission to place the target processor in a low power state is denied. If block determines there are no pending callbacks or if block determines that a holdoff period is not in effect the low power state permission query function A returns to its caller in block reporting a status value indicating that permission to place the target processor in a low power state is granted. Note that a holdoff period will not be in effect if a low power state processing effort is currently underway or if the holdoff period has elapsed. The low power state permission query function A thus grants permission to place a processor in a low power state if either 1 There are no callbacks on the processor 2 the processor has not yet attempted to enter a low power state or 3 the processor is currently in the process of attempting to enter a low power state. Otherwise if an attempt to place the processor in a low power state has been recently tried and failed permission to retry will be refused until the holdoff period elapses .

Turning now to example operations that may be performed by the low power state enter callback flush function B are shown. This function runs with interrupts disabled. The function is initially invoked by the scheduler s low power state subsystem A during the idle mode of one of the processors . . . in order to initiate an attempt to place the processor in a low power state in which the scheduling clock interrupt is suppressed such as dyntick idle mode . The function is thereafter called one or more times by the callback handler A during callback flush loop processing in order to implement a new pass through the callback flush loop.

The low power state enter callback flush function B determines if there is any RCU callback processing work that needs to be done by the target processor and if so schedules softirq context processing to get it done. The goal is for the target processor to clear out all work required by the RCU subsystem for the current grace period so that this processor can be permitted to enter a low power state. In some cases the target processor will need to be awakened from the low power state at the end of a grace period by whatever processor ends the grace period. This allows the processor to go into a low power state more quickly and to reduce the number of wakeups by a modest integer factor. The callback flush loop counter see controls the sequencing.

With reference now to example operations that may be performed by the low power state enter callback flush function B are shown. In block a check is made to determine whether the target processor has any pending RCU callbacks. If not the low power state enter callback flush function B returns to its caller in block . Typically because the previous invocation of the low power state permission query function A will have resulted in the target processor being placed in a low power state the return to caller in block will result in the processor remaining in a low power state. In block the callback flush holdoff counter see is sampled to determine if a holdoff period is in effect. If it is the low power state enter callback flush function B returns to its caller in block . Typically because the previous invocation of the low power state permission query function A will have resulted in the target processor being held out of a low power state the return to caller in block will result in the processor remaining at full power. If block determines that a holdoff period is not in effect block checks whether this is the first pass through the callback flush loop. If so block initializes the callback flush loop counter see .

If this is not the first pass through the callback flush loop a check is made in block whether the current processor has any RCU work to be done meaning that there callbacks requiring invocation or the processor needs to perform some action to advance the RCU subsystem s grace period machinery. In an example embodiment the operation of block may be implemented using the rcu pending function found in current RCU implementations in the Linux kernel. Block may thus check whether 1 there are any callbacks on the donelist portion of the processor s callback lists i.e. callbacks ready for immediate invocation 2 the processor is unaware of the beginning or end of a grace period and needs to update its state accordingly 3 the processor needs to inform the RCU subsystem of a recent passage through a quiescent state 4 the processor needs another grace period but the RCU subsystem has gone idle and 5 a grace period has lasted too long such that other processors may need to be awakened. If block determines that none of these conditions is present it means that the processor does not have any RCU callbacks that are ready for invocation and the RCU subsystem does not require any grace period advancement processing from the current processor . In that case the processor may be safely placed in a low power state in block . However before taking that action it may be desirable to make one or more additional passes through the callback flush loop processing that includes block in order to increase the probability of successfully flushing the callbacks that are present. Block also updates the callback flush loop counter and the callback flush holdoff counter . This updating entails setting the flush loop counter to a value signifying the end of flush loop processing and setting the holdoff counter to a value signifying that no holdoff period is in effect. Block also sets the processor s low power state timer see that determines when the processor will be awakened out of the low power state. The low power state timer may be set to different timeout values depending on whether there are lazy RCU callbacks or non lazy RCU callbacks. As previously discussed lazy RCU callbacks are non urgent RCU callbacks that do nothing more than freeing memory. Such RCU callbacks may usually be safely deferred for some time on an idle processor . Non lazy RCU callbacks are RCU callbacks that perform other processing and are considered to be more urgent. If non lazy RCU callbacks are present the low power state timer may be set to a timeout value that is rough estimate of a typically RCU grace period for example six jiffies. If only lazy RCU callbacks are present the low power state timer may be set to a much larger timeout value for example six seconds rather than six jiffies. Once the low power state timer is started the low power state enter callback flush function B returns to its caller in block . Typically because the previous invocation of the low power state permission query function A will have resulted in the target processor being placed in a low power state the return to caller in block will result in the processor remaining in a low power state. However whereas the initial low power state was of non fixed duration setting the low power state timer will result in the low power state being a fixed duration low power state.

If block determines that there is RCU work to be done block decrements the callback flush loop counter and block checks whether a callback flush loop limit has been reached. If this limit has been reached block resets the processor s callback flush holdoff counter to start a holdoff period invokes the RCU subsystem and returns to its caller. Typically because the previous invocation of the low power state permission query function A will have resulted in the target processor being placed in a low power state the invocation of the RCU subsystem in block will result in the low power decision being reevaluated. If block determines that the callback flush loop limit has not been reached block rechecks for callbacks on the processor . If any callbacks are detected block records a quiescent state for the processor and attempts to force a quiescent state on any other processors that may be delaying the end of a grace period. Block then issues a request to the RCU subsystem for deferred invocation of the callback handler A see in softirq context or in some other safe environment . The actual commencement of the callback handler A thus will not occur until some time following block . The job of the callback handler A is to invoke any callbacks that are ready for immediate invocation and advance any callbacks that may not be ready for immediate invocation. The callback handler A also advances the RCU subsystem s grace period machinery. At the end of such processing the callback handler A reinvokes the low power state permission query function A and then reinvokes the low power state enter callback flush function B for a possible further pass through the callback flush loop.

With reference now to a few example operations that may be performed by the callback handler A with as part of its callback processing functionality are shown. In particular the illustrated operations focus only on that portion of the callback handler s operations that determine how many callbacks are to be processed in a single invocation. In block a determination is made whether a scheduling change is pending on the target processor . If no scheduling change is pending block determines whether the callbacks will be processed on an idle processor . If so block checks to see that there no are other pending softirq handlers. If that is the case block allows callback processing to proceed with no limit on the number of callbacks. On the other hand if block determines there is a pending scheduling change or if block determines that the target processor is not idle or block determines there are other pending softirq handlers block imposes a limit on the number of callbacks to be processed.

Accordingly a technique for has been disclosed for implementing read copy update in an improved energy efficient manner for light workloads running on systems with many processors and in other environments. It will be appreciated that the foregoing concepts may be variously embodied in any of a data processing system a machine implemented method and a computer program product in which programming logic is provided by one or more machine useable storage media for use in controlling a data processing system to perform the required functions. Example embodiments of a data processing system and machine implemented method were previously described in connection with . With respect to a computer program product digitally encoded program instructions may be stored on one or more computer readable data storage media for use in controlling a computer or other digital machine or device to perform the required functions. The program instructions may be embodied as machine language code that is ready for loading and execution by the machine apparatus or the program instructions may comprise a higher level language that can be assembled compiled or interpreted into machine language. Example languages include but are not limited to C C assembly to name but a few. When implemented on a machine comprising a processor the program instructions combine with the processor to provide a particular machine that operates analogously to specific logic circuits which themselves could be used to implement the disclosed subject matter.

Example data storage media for storing such program instructions are shown by reference numerals memory and cache of the computer system of . The system may further include one or more secondary or tertiary storage devices not shown that could store the program instructions between system reboots. A further example of storage media that may be used to store the program instructions is shown by reference numeral in . The storage media are illustrated as being portable optical storage disks of the type that are conventionally used for commercial software sales such as compact disk read only memory CD ROM disks compact disk read write CD R W disks and digital versatile disks DVDs . Such storage media can store the program instructions either alone or in conjunction with an operating system or other software product that incorporates the required functionality. The storage media could also be provided by other portable storage media such as floppy disks flash memory sticks etc. or storage media combined with drive systems e.g. disk drives . As is the case with the memory and the cache of the storage media may be incorporated in data processing platforms that have integrated random access memory RAM read only memory ROM or other semiconductor or solid state memory. More broadly the storage media could comprise any electronic magnetic optical infrared semiconductor system or apparatus or device or any other tangible entity representing a machine manufacture or composition of matter that can contain store communicate or transport the program instructions for use by or in connection with an instruction execution system apparatus or device such as a computer. For all of the above forms of storage media when the program instructions are loaded into and executed by an instruction execution system apparatus or device the resultant programmed system apparatus or device becomes a particular machine for practicing embodiments of the method s and system s described herein.

Although various example embodiments have been shown and described it should be apparent that many variations and alternative embodiments could be implemented in accordance with the disclosure. It is understood therefore that the invention is not to be in any way limited except in accordance with the spirit of the appended claims and their equivalents.

