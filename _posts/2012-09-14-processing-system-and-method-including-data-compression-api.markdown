---

title: Processing system and method including data compression API
abstract: Memory system operations are extended for a data processor by an application programming interface API, including a set of operations and parameters for the operations, which provides for data compression and decompression during or in conjunction with processes for moving data between memory elements of the memory system. The set of operations can be configured to use the parameters and perform the operations of the API. The API can support moves between memory having a first access latency, such as memory integrated on the same chip as a processor core, and memory having a second access latency that is longer than the first access latency, such as memory on a different integrated circuit than the processor core.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09158686&OS=09158686&RS=09158686
owner: Altera Corporation
number: 09158686
owner_city: San Jose
owner_country: US
publication_date: 20120914
---
This application claims benefit of U.S. Provisional Patent Application No. 61 618 463 filed on 30 Mar. 2012 entitled PROCESSING SYSTEM AND METHOD INCLUDING DATA COMPRESSION API.

This application is related to U.S. Patent Application No. 61 618 534 filed on 30 Mar. 2012 entitled DATA COMPRESSION FOR DIRECT MEMORY ACCESS TRANSFERS and is also related to U.S. Patent Application No. 61 618 509 filed on 30 Mar. 2012 entitled CONVERSION AND COMPRESSION OF FLOATING POINT AND INTEGER DATA all of which are incorporated by reference.

The present invention relates to computer system operation including data transfer operations among the elements of a memory system that include data compression and decompression.

In some computer systems including multicore processors systems and graphical processor systems memory is organized hierarchically. The memory hierarchy can include a relatively small first level L1 cache memory and a larger second level L2 cache memory on the same integrated circuit as the processor core circuitry along with off chip large scale memory implemented often using dynamic random access memory. In some configurations a third level L3 cache can be included on chip. Other memory can be used for sharing data among processor cores such as shared cache memory and message passing memory. Additional memory in the hierarchy can include persistent stores such as flash memory magnetic disk drive memory network attached storage and so on. Given the variety of memory technologies the organization of memory systems is very diverse.

Also there are many varieties of computer system architectures each of which can include different memory system configurations. My co pending U.S. patent application Ser. No. 12 891 312 entitled ENHANCED MULTI PROCESSOR WAVEFORM DATA EXCHANGE USING COMPRESSION AND DECOMPRESSION filed 27 Sep. 2010 US 2011 0078222 which is incorporated by reference as if fully set forth herein describes several computer system architectures and demonstrates the variety architectures and memory configurations being commonly deployed.

As processor performance has improved processors are executing programs over larger and larger data sets. Also one processor or group of processors may concurrently execute many programs each of which requires access to different sizes and types of data sets. For example broad varieties of application programs acquire collect process and display numerical data. Numerical data includes a variety of data types such as integers floating point numbers image data video data and graphics objects. Numerical data can be accumulated in large files or acquired at high speeds and movement of such data among elements of processor system memory hierarchies can cause bottlenecks in system performance.

Thus the amount of memory available in terms of the number of bytes at each element of a memory system for a given computer system and the bandwidth of the data channels among the elements of the memory system can limit the efficiency and speed with which a given program can be executed. Given the variant computer systems architectures and variant memory system configurations the control of data flow among the memory elements is often implemented in a platform specific manner. This platform specific memory management interferes with users ability to individually manage data flow to improve the efficiency of the utilization of memory resources in a given computer system.

It is desirable to provide technologies that can be employed to improve efficiency of memory system operations in computer systems.

Memory system operations are extended for a data processor by an application programming interface API including a set of operations and parameters for the operations which provides for data compression and decompression during or in conjunction with processes for moving data between memory elements of the memory system. The set of operations can be implemented in the data processor using software implemented functions which can be hardware assisted configured to use the parameters and perform the operations of the API. The API can support moves between memory having a first access latency such as memory integrated on the same chip as a processor core and memory having a second access latency that is longer than the first access latency such as memory on a different integrated circuit than the one including a processor core or cores. In such data move operations any added latency associated with the compression or decompression can be absorbed with less impact on access by the processor core to mission critical data.

Parameters of the API can include indicators of data type size of a sample set and compressed data location destination for a compression operation source for a decompression operation uncompressed location destination for a decompression operation source for a compression operation and a selected compression mode such as lossless fixed rate or fixed quality modes. Operations of the API include engines that move data between the compressed data location and the uncompressed location in conjunction with which one of compression and decompression is performed as specified by parameters of the API. Data in an uncompressed location as the term uncompressed is used herein can refer to data which can be provided as input to a compression engine or as data output from a decompression engine including never compressed data or previously compressed and then decompressed data. A set of different algorithms can be included in the operations of the API and parameters of the API can identify a selected one of the different algorithms to be applied for compression and decompression operations in a particular data move operation. The set of different algorithms can include algorithms specialized for data types identified in the parameters of the API including for example algorithms for compression of floating point numbers algorithms for compression of integers algorithms for compression of image data and so on. Also the set of different algorithms can include algorithms specialized for compression qualities as identified in the parameters of the API such as lossless compression lossy compression of different types compression to achieve specified compression ratios algorithms that maintain specified limits on compression quality in terms of loss of data and so on.

A data processor is described that includes an API which provides for compression and decompression in conjunction with processes that move data between memory elements of a memory system deployed in or otherwise accessible by the data processor. The data processor can execute user application programs that utilize the API. Users can develop user application programs that rely on the API without being burdened by the specific configuration of a hardware platform on which the user application is to be executed.

Other aspects and advantages of the present invention can be seen on review of the drawings the detailed description and the claims which follow.

The peripheral devices may include a storage subsystem comprising a memory subsystem and a file storage subsystem user interface input devices user interface output devices and a network interface subsystem . The input and output devices allow user interaction with data processor . Network interface subsystem provides an interface to outside networks including an interface to communication network and is coupled via communication network to corresponding interface devices in other computer systems. Communication network may comprise many interconnected computer systems and communication links for example Ethernet or Infiniband wired links. These communication links may be wireline links optical links wireless links or any other mechanisms for communication of information. While in one embodiment communication network is the Internet communication network may be any suitable computer network.

User interface input devices may include a keyboard pointing devices such as a mouse trackball touchpad or graphics tablet a scanner a touchscreen incorporated into the display audio input devices such as voice recognition systems microphones and other types of input devices. In general use of the term input device is intended to include all possible types of devices and ways to input information into data processor or onto communication network .

User interface output devices may include a display subsystem a printer a fax machine or non visual displays such as audio output devices. The display subsystem may include a cathode ray tube CRT a flat panel device such as a liquid crystal display LCD a projection device a retinal display or some other mechanism for creating a visible image. The display subsystem may also provide non visual display such as via audio output devices. In general use of the term output device is intended to include all possible types of devices and ways to output information from data processor to the user or to another machine or computer system.

Storage subsystem stores the basic programming and data constructs that provide the functionality described herein including application programs and an API compliant compression decompression library. A compression decompression library is considered API compliant if it uses some or all of the parameters of the API and implements some or all of the operations of the API.

Embodiments of the technology may include an entire library enabling programs for full compliance with a specified API for the underlying hardware configuration or only those components of the library linked to or that can be called by the programs to be executed using the system. These software modules are generally executable and executed by processor s that may optionally include some form of hardware acceleration.

Memory subsystem typically includes a number of memories including a main random access memory DRAM for storage of instructions and data during program execution and a read only memory ROM in which fixed instructions are stored. In some systems flash memory can be used in addition to or in the alternative to the ROM . File storage subsystem provides persistent storage for program and data files and may include a hard disk drive a floppy disk drive along with associated removable media a CD ROM drive an optical drive or removable media cartridges such as flash drives having a USB interface. The databases and modules implementing the functionality of certain embodiments may be stored by file storage subsystem . As mentioned above the processor s may also include one or more levels of cache memory and other memory on the same integrated circuit as the processor core or cores of the processor s .

Bus subsystem provides a mechanism for allowing the various components and subsystems of data processor to communicate with each other as intended. Although bus subsystem is shown schematically as a single bus typical embodiments of the bus subsystem use multiple busses.

Data processor itself can be of varying types including a personal computer a portable computer a workstation a computer terminal a network computer a television a mainframe a supercomputer a graphics card or accelerator or any other data processing system or user device. Due to the ever changing nature of computers and networks the description of data processor depicted in is intended only as a specific example for purposes of illustrating the preferred embodiments. Many other configurations of data processor are possible having more or less components than those depicted in .

The data processor is capable of using the processor s for executing a plurality of application programs and of allocating a plurality of threads of each application program concurrently to one or more processor cores of the processor s . The multiprocessing environment creates varying needs for compression and decompression resources that can be satisfied utilizing an API as described herein that includes parameters and operations that can fit the varying needs. Thus the parameters and operations of the API support a plurality of data types a plurality of compression modes and a plurality of types of source and destination memory elements.

In one embodiment the API compliant compression decompression library is used by providing library access to a compiler which links the application programs to the components of the library selected by the programmer. Access to the library by a compiler can be accomplished using a header file for example a file having a .h file name extension that specifies the parameters and operations of the API and corresponding library file for example a file having a .lib file name extension a .obj file name extension for a Windows operating system or a file having a .so file name extension for a Linux operating system that use the parameters and implement the operations. The components linked by the compiler to applications to be run by the computer are stored as all or part of the API in the computer system memory possibly as compiled object code for execution as called by the application. In other embodiments the library can include components that can be dynamically linked to applications and such dynamically linkable components are stored in the computer system memory as all or part of the API possibly as compiled object code for execution as called by the application.

In my co pending U.S. patent application Ser. No. 12 891 312 entitled ENHANCED MULTI PROCESSOR WAVEFORM DATA EXCHANGE USING COMPRESSION AND DECOMPRESSION filed 27 Sep. 2010 US 2011 0078222 incorporation of compression and decompression resources in a variety of computer system architectures is described. For the purposes of the present description illustrates a representative configuration of such systems and of other systems.

The compression decompression technology including a compression decompression API can accelerate compression and decompression in a broad variety of software and hardware applications that acquire collect process store and display numerical data. Numerical data consists of integers floating point numbers imaging video and graphics objects.

Also the API can implement a data type or file format for use in support of the compression decompression functions such as described below.

One example set of operations of an API for compression and decompression includes functions that support DMA operations such as used for moving data from a fast memory like on chip L2 cache memory and registers on the same integrated circuit as a processor core to a relatively slower but larger scale memory like off chip SDRAM or DDR DRAM main memory using an on chip memory controller. This example can be understood with reference to the following description beginning with .

The compression and decompression acceleration logic in the memory controller block can comprise supporting circuitry for one or more DMA channels the number of which is selected during design of the integrated circuit . The compression decompression library of the API can include a component linked to an application program for the purposes of initializing and controlling compression and decompression channels through the acceleration logic.

In one example a library component can control writing the contents of registers that hold parameters associated with the acceleration logic including command registers status registers and transaction descriptor registers. For example illustrates an embodiment including four DMA compression channels A through D. A library function or functions can set and control a command and status register for the four channels. Each channel includes a set of descriptor registers e.g. descriptor register set A for compression channel A. illustrates an embodiment including four DMA decompression channels A through D complementary to the compression channels of . A library function or functions can set and control a command and status register set for the four channels. Each channel includes a set of descriptor registers e.g. descriptor register set A for decompression channel A.

Details of a compression and decompression status and descriptor register sets for a compression and decompression DMA channel are provided for a specific implementation referred to herein as APAX for Application Acceleration as an aid in understanding the types of parameters and operations that can be included in a compression decompression API. Persons of skill in the art will understand that details of the parameters will be adjusted as suits a particular implementation the types of data being compressed and decompressed the specifications of the compression decompression algorithms implemented by the compression decompression library the architecture of the hardware host supported by the compression decompression library and other considerations.

Thus representative compression channel control and status registers for an APAX API using the hardware accelerator of are illustrated in Table 1 set forth below.

Compression channel descriptors for an APAX API corresponding with those shown in that can be associated with a DMA operation using the compression functions are set out in Table 2 below. The register set e.g. A holding the compression function descriptors can be written and controlled by a component or components of a compression decompression library implementing the API.

The APAX SOURCE register contains the 32 bit or 64 bit start address of the array to be compressed. The APAX DEST register contains the 32 bit or 64 bit start address where compressed packets will be written. The APAX N PKTS register specifies how many packets will be compressed during the transaction from 1 to 65535 0 is invalid . APAX PKT LENGTH specifies the number of samples per packet a multiple of 4 samples from 64 to 16384 values below 64 are invalid . Note that APAX PKT LENGTH specifies a sample count the number of bytes to be compressed during the DMA transaction is a function of D TYPE PKT LENGTH and N PKTS. For imaging triplets the packet length is in units of pixels color planes i.e. APAX PKT LENGTH 768 for RGB implies that 256 3 768 samples per compressed packet. Similarly APAX PKT LENGTH 4320 for Bayer matrix pairs RGBG that carry 1080 4 4320 samples per compressed packet. APAX DTYPE specifies the uncompressed datatype input of an APAX COMP transaction or the output of an APAX DECOMP transaction . APAX DTYPE 15 13 specify six uncompressed datatypes unsigned integer uint signed integer int floating point number exponent mantissa float RGB pixel set YUV pixel set or Bayer matrix pixel set .

APAX DTYPE 12 10 specify the bit widths 8 10 12 14 16 32 or 64 bits of each uncompressed datum. Certain combinations of datatype and bit width can be prohibited including 8 bit or 16 bit floats or 64 bit ints or uints.

APAX DTYPE 5 4 control optional color space decimation none 4 4 4 4 2 2 or 4 4 4 4 2 0 . Similarly RGB YUV conversion prior to compression is enabled by APAX DTYPE 3 2 .

APAX VERSION specifies the APAX algorithm version number that can be used during the APAX transaction. APAX VERSION can be stored in the .sfy file header as described below with respect to . If the APAX COMP block does not support the algorithm version specified in APAX VERSION an error code can be returned in the block s associated APAX COMP STATUS bits.

APAX RR CONFIG configures the APAX redundancy remover RR for the compression operations described below. Three RR parameters DERIV ADD SUB and STRIDE1 can be configured for automatic or manual operation using bits APAX RR CONFIG 2 0 . A 0 in these bits indicates the parameter will be automatically selected by the center frequency estimator block see Section 4.7 while a 1 indicates a manual selection by the user.

APAX RR CONFIG bits 15 13 select manually from among five RR STRIDE2 values 1 2 3 4 or 6 . STRIDE2 is a fixed parameter for the duration of the transaction and for all packets in a .sfy file STRIDE2 is not modified by the contents of packet headers as STRIDE1 can be. APAX RR CONFIG bits 12 10 manually select from among six RR STRIDE1 values 1 2 3 4 6 or N FIFO . APAX RR CONFIG bit 9 specifies the ADD SUB operation 0 subtract 1 add . APAX RR CONFIG bits 8 7 specify the manual DERIV value 0 1 or 2 . RR AUTO MANUAL APAX RR CONFIG 2 0 determines whether DERIV ADD SUB and STRIDE1 are automatically or manually selected. APAX MODE 15 12 selects from among eight supported compression modes 

APAX MODE 11 0 also called C PARAM compression parameter for lossy modes is a multi purpose set of bits whose meaning and bit width depends on C MODE. For Average Rate and Constant Rate modes C PARAM is a 12 bit value specifying the number of 32 bit words in each compressed packet including the packet header bits . Because APAX PKT LENGTH in number of samples can reach 16384 14 bits and for DTYPE values as wide as 64 bits per sample the mapping from C PARAM is non linear. For instance 64 bit floats having the largest PKT LENGTH 16384 occupy 8 16384 131 072 Bytes or 32 768 32 bit words before compression. To express 1.1 1 compression for a packet of 16384 64 bit floats the target 32 bit compressed packet length would equal 29 789 which would require 15 bits and which would not fit directly into the 12 bit C PARAM field. In order to express target packet sizes up to 32 768 we use the non linear mapping which uses four different increment values 1 4 8 and 16 between C PARAM values. In addition a packet size of 32 768 32 bit floats per compressed packet is encoded as C PARAM 0xFFF. APAX RR CONFIG and APAX MODE registers might only be referenced during APAX compress transactions. These two registers are not used for the APAX DECOMP DMA descriptor but APAX RR CONFIG and APAX MODE are stored in each APAX compressed file header.

For 1 dimensional 1D data that repeats every N samples or two dimensional 2D data that has a fixed raster length APAX H DIM contains the number of samples per row or packet. For 3 color planes typical number of samples is 3 number of pixels per raster. For 2D data APAX V DIM contains the number of rasters rows per frame. The first packet in frame bit of the first packet in a frame will be set 1 in the packet header while the first packet in frame bit for all other packets in the frame will be clear 0 .

Representative decompression channel control and status registers for an APAX API corresponding with the register set of are illustrated in Table 3 set forth below.

Decompression channel descriptors for an APAX API corresponding with those shown in that can be associated with a DMA operation using the compression functions are set out in Table 4 below. The register set e.g. A holding the decompression function descriptors can be written and controlled by a component or in components of a compression decompression library.

The registers shown in Table 4 are like those of Table 2 with the exception of the APAX RR CONFIG and APAX MODE registers. The APAX RR CONFIG and APAX MODE registers are only referenced during APAX compress transactions. These two registers are not used for the APAX DECOMP DMA descriptor but rather the library function utilizing the channel can store the APAX RR CONFIG and APAX MODE parameters in each APAX compressed file header.

The group of context registers includes APAX ATTEN which is a 10 bit setting for the attenuator of the redundancy remover RR . APAX DERIV is the last chosen derivative order 0 1 or 2 . APAX FIFO1 MAX which is the length in samples of the FIFO buffer used for the application thread which may be less than or equal to the maximum buffer length N in . APAX FIFO1 PTR is the pointer into FIFO buffer specifying the FIFO sample that should be correlated with the next input sample in a new DMA COMP transaction. The group of nine APAX COMP statistics registers gathers information on both the input signal and the decompressed signal. The parameter APAX N SAMPS indicates the number of input samples used for calculating the statistics. Statistics on the input samples includes the minimum sample APAX SAMP MIN maximum sample APAX SAMP MAX the sum of samples APAX SAMP SUM and the sum of squared samples APAX SAMPSQD SUM. Since taking derivatives in the redundancy remover RR and performing bit packing in the bit packer are both lossless operations the attenuator is the only source of loss during compression see . Error computations for the statistics collection block may be performed after the attenuator . The redundancy remover amplifies the attenuated signal multiply by the inverse of the attenuation value to produce the identical signal that the signal regenerator will generate after the bit unpacking. Subtracting the amplified attenuated signal from the input signal provides an error signal used for the calculating the statistics for the compression statistics registers . The error statistics include minimum error APAX ERR MIN maximum error APAX ERR MAX sum of errors APAX ERR SUM and sum of squared errors APAX ERRSQD SUM. It is also possible to use the input and error signal statistics in an adaptive loop that adjusts various compression parameters to achieve certain signal quality levels.

An APAX Stream Header struct can be created and initialized to support the API compression decompression library functions compliant with the API. A function is compliant with the API if it accepts parameters specified by the API and when executed causes performance of the operations identified and or modified by the parameters. Such a header file for a C language implementation in an example in which to index a total of 2048 packets every 64 packets can be expressed as follows 

Lines 1 13 set up the Stream Header of an operation of the API including a number of indices in embodiments or in instances of the stream header in a single embodiment where random access to uncompressed data from a compressed file is implemented using the indexes.

For random access into a stream of compressed APAX packets the APAX transaction size determined by bits 15 . . . 1 of the APAX CMD register can correspond to the specified random access index granularity. If APAX transactions are executed one packet at a time by setting bits 15 . . . 1 of the APAX CMD register to 0x1 the index granularity will be 1 packet. For example if the packet size is 256 samples and the desired index granularity is 4 packets the APAX user will have a random access indexing granularity of 1024 samples.

In some embodiments a header file may not be used. For example in some systems using dynamic library functions such as JAVA based systems header files may not be used.

The following typedef s can be used to define the DMA compress and decompress transaction registers described above for implementations that extend a C or C standard library or other standard programming language library that supports the typedef keyword. Note that the APAX HW COMP and APAX HW DECOMP registers share of 8 registers and that this example implementation utilizes the APAX HW typedef for the shared registers.

For the APAX example a set of six C functions can be included in an APAX API i.e. comprise an API compliant set of functions for a system performing DMA operations with compression and decompression 

The operations of the API just listed use the parameters of the API and can be explained with reference to the line numbers as follows 

Lines 6 and 7 call an operation to create the APAX Stream Header data structure as explained above and discussed with reference to elements and .

Lines 11 17 call an operation to define the parameters of the API that are included in a descriptor register set as described in Table 2.

Lines 20 21 call an operation to initialize a DMA memory mapped register for a channel utilizing the parameters of the API.

Lines 25 27 call an operation to prepare the initialized channel for compression operation passing indicators of the locations of the compressed and uncompressed data sets setting up the hardware registers etc.

Lines 29 30 call an operation to cause execution of the compression operation according to the parameters of the API.

Lines 32 34 call an operation to prepare the initialized channel for decompression operation passing indicators of the locations of the compressed and uncompressed data sets setting up the hardware registers etc.

Lines 36 37 call an operation to cause execution of the decompression operation according to the parameters of the API.

APAX compressed packets can be stored in non persistent memory SRAM DRAM as well as in persistent storage flash disk . In non persistent memory APAX DMA descriptors typically also stored in SRAM or DRAM provide the context for decompressing APAX compressed packets. In persistent storage APAX DMA descriptors stored with the thread s compressed packets provide the same context.

Programs using the compression decompression API can include logic to perform some aspects of memory management as discussed below.

An APAX DMA Descriptor describes a single APAX compress or decompress transaction of one or more APAX packets. Using the APAX CMD register users can specify APAX compress or decompress transactions having 

If needed because of system constraints such as block oriented thread processing compression and decompression of large sample arrays can be divided into multiple APAX transactions one transaction per block.

Programs can be configured for managing memory for compressed transactions using the standard C language library functions malloc and free. Alternatively these functions can be included in the library files for the compression and decompression functions. For lossless compression an application can be set up to allocate 10 more memory than the uncompressed input array requires. For instance if the uncompressed input array contains 1M 32 bit floats 4 MB the application should reserve 4.4 MB via malloc for the compressed array. For example an application that uses the APAX API can include the following 

This segment of code is then followed in the application by calls that use the API set of operations and parameters for compression and decompression with reference to the allocated memory. The start address returned by malloc is copied to APAX DEST register prior to the first APAX compress transaction. Subsequent APAX compress transactions auto increment APAX SRC and APAX DEST registers so that by default compressed packets will be stored consecutively in memory.

If the packets are saved to files on flash or disk i.e. parameters that are not stored in each packet header many relevant contextual fields such as the uncompressed datatype the packet length and the APAX algorithm version number are stored in compress DMA descriptors several DMA descriptor fields must be stored with the compressed packets. A file format can be defined to support the API operations and hold API parameters.

One such file format suitable for the APAX example is shown in . In this example the format of a file includes a file header a file index for indexed files and a payload and comprises a plurality of packets. The file header corresponds to a descriptor register set and can be used by the decompression logic in the library functions and can be written by the compression logic in the library functions. The index is used for retrieving data within the compressed file where random access may be needed. The payload is organized into compressed packets in the APAX example. In a file system a file created according to this format can be identified by .syntax. For example a file created according to this format could have a identifier like APAX file.sfy where the file extension .sfy is recognizable by the library functions. As described in this example and in a .sfy file begins with the 12 byte ASCII string samplifyAPAX 12 characters .

The APAX MODE field can be used when a compressed file is appended added to so that the APAX compress block can determine what the APAX compression mode was so that newly compressed packets can be APAX compressed using those same parameters. Parameters that specify dimensions of two dimensional files can also be included as well as a parameter indicating the number of indices supported in the file.

When APAX users desire random access to their compressed data APAX compression provides random access by creating an index directory that points to the start of certain compressed packets. If random access is not desired the .sfy field N INDEXES 0 and the APAX index fields are not included in the .sfy file. When N INDEXES 0 a parameter called PKTS PER INDEX indicates how many packets occur between index pointers. For instance indexing every 64th packet PKTS PER INDEX 64 of an 8192 packet file APAX N PACKETS 8192 results in 8192 64 128 indices. PKTS PER INDEX is then followed by 128 64 bit pointers 8 Bytes per index . Index 0 points to the SYNC word of the first packet and always equals zero.

Application programs can perform compression and decompression using API compliant library functions that implement the parameter and operations of the API using the descriptors and file structures described above. An example using C language code illustrates how the API could be used in an application program for compression could comprise the following 

The portion of an application program just listed is commented thus no further description is provided. This just listed application program segment includes calls to the operations of the API explained above that use the parameters of the API along with memory management functions e.g. malloc that support the compression and decompression operations.

In implementations that do not include the hardware or include only a part of the hardware needed to run the compression function a library file can be called to execute all or parts of the compression operations using the parameters specified according to the API.

An example using C language code illustrates how the API could be used in an application program for decompressing an entire compressed file including all the compressed packets of the file comprise the following 

An example using C language code illustrates how the API could be used in an application program for decompressing only selected parts of a compressed file including all the compressed packets of the file comprises the following 

The random access decompress example just listed contains a detailed example including lines 17 30 of how APAX file header parameters and the APAX index support sample accurate random access into a .sfy file s compressed packet payload.

The three sample portions of application programs provided just above call operations of the API that use the parameters of the API. In addition the operations can move data using the DMA logic in the memory controller between an uncompressed location e.g. on chip direct access memory or cache memory on the same chip as a processor core and a compressed location e.g. DDR DRAM main memory on a separate chip or chips.

As illustrated in a module implemented as a library file for example or by hardware can be included for scheduling DMA operations using the descriptors described above. A basic DMA scheduler can include a compression queue and decompression queue each of which includes a pointer to a corresponding compression descriptor from a set including descriptors 0 1 2 . . . N or a pointer to a corresponding decompression descriptor from a set including descriptors 0 1 2 . . . N. As needed by the corresponding compression channel from the set of compression channels or corresponding decompression channel on the set and decompression channels the queues are delivered to the logic whether implemented by hardware or software or both according to the priorities established using the scheduler.

In general the compression resources include a preprocessor block and compressor block with associated control . The preprocessor block is adapted for a variety of different data types including integer data floating point data and image data in this example. Data to be compressed are input as represented by line and compressed packets are output as represented by line . In a hardware accelerated environment the lines and can correspond to on chip registers or the data buses. In a software embodiment lines and can correspond to the data read by or written by the processor that is executing library functions.

The preprocessor block includes a number aligner in embodiments including a hardware accelerator coupled to an internal bus on the integrated circuit. The number aligner aligns samples to be compressed of one width with the internal bus which may have a different width from that of the samples. In one example an internal bus may be a 64 bit wide interface to DDR memory DDR3 while the samples to be compressed are 16 bit integers. In this case the number aligner will map the data from the internal bus as follows 

In another example an internal bus may be a 128 bit wide bus and the samples to be compressed may be 32 bit single precision floating point data. In this case the number aligner will map the data from the internal bus as follows 

The output samples from the number aligner are delivered on four alternative paths in this example. When delivered on a first path the samples are delivered to a direct floating point compression engine which performs alternative types of lossy floating point compression explained in more detail below with reference to . On a second path the samples are delivered to a floating point preprocessor block which can perform such functions as floating point to integer conversion to enable compression using a compression engine designed for integer compression in compressor . On a third path the samples are delivered directly to a selector . On a fourth path the samples are delivered to an image preprocessor which can perform a variety of functions unique to image file encoding color space conversion color space decimation and the like. On a fifth path the samples can be delivered to a center frequency estimator which can be applied for sample streams that can benefit from a redundancy removal algorithm that depends on the center frequency of the sample stream. The output of the center frequency estimator is applied to the control block which utilizes the information in control of the compression process as discussed below.

More details concerning floating point to integer conversion in the floating point preprocessor and representative functions for the image preprocessor are discussed below.

As to center frequency estimation the illustrated logic can support compression of data having different center frequencies. The center frequency estimator determines a center frequency to be applied in redundancy removal as discussed below.

The inputs to the selector include the output of the floating point preprocessor the samples delivered on the third path directly from the number aligner and the output of the image preprocessor . The selector selects the appropriate data stream based on parameters applied by the control block which are determined from a descriptor compliant with the API delivered to the control block .

The compressor block can include a plurality of alternative compression modalities. In this example compressor block includes two alternative compression modalities. The first modality is a floating point lossy compression algorithm performed by the direct floating point compression engine . The second modality is an integer compression algorithm that can be configured for lossless and lossy compression in response to parameters provided in compliance with the API. The second modality performed using the redundancy remover and a bit packer . A header generator is included with the redundancy remover and the bit packer for use in the assembly of packets to be delivered on line including the compressed data after redundancy removal.

The output of the direct floating point compression engine and the bit packer are applied to an output selector which provides the compressed packets on line .

The control block receives a DMA COMP descriptor like that described above controls the routing of the samples through the various logic blocks and applies the parameters of the compression as needed to the various logic blocks. The control block also controls an attenuation factor utilized in some compression modes to control fixed rate or fixed quality operations for example those based on statistics fed back about the characteristics of compressed packets.

In general the decompression resources are complementary to the compression resources described with respect to and include a decompressor block a postprocessor block and a control block . Data packets to be decompressed are input as represented by line and decompressed data are output as represented by line . In a hardware accelerated environment the lines and can correspond to on chip registers or the data buses. In a software embodiment lines and can correspond to the data read by or written by the processor that is executing library functions.

The decompressor block includes a demultiplexer which routes the incoming data packets either to the direct floating point decompression engine or to resources corresponding to the integer compression engine that included the redundancy remover and bit packer of . The demultiplexer is controlled by the decompress control logic which implements the parameters specified according to the API. The decompression parameters may come from a file that conforms to the .sfy format described with or may come from a DMA decompress descriptor previously described with element A . In this example those parameters are specified using a DMA DECOMP descriptor as described above. When the API parameters specify that the incoming data packets are direct floating point compressed then the packets are routed to the corresponding direct floating point decompression engine . The control block responds to the parameters specified according to the API to configure the direct floating point decompression engine .

When the API parameters specify that the incoming data packets are compressed according to the alternative integer compression functions then the packets are routed to the bit unpacker . In the bit unpacker the headers of the packets are extracted and delivered to the control block . The parameters from the extracted packet header are used by the control block to control the signal regenerator as described in more detail below.

The output of the signal regenerator is applied to an appropriate unit of the postprocessor block . Depending on the incoming datatype the output of the signal regenerator can be routed through the floating point postprocessor or through the image postprocessor . The postprocessor includes a selector controlled by the control logic in response to the API parameters or parameters carried by the packets being decompressed. The inputs to the selector include the output of the direct floating point decompression engine the output of the floating point postprocessor the direct output of the signal regenerator or the output of the image postprocessor in this example. The output of the selector is then applied to a number aligner complementary to that discussed above connection when necessary to the output .

In light of the organization of the components shown in some details of the individual components of the compression and decompression functions are provided next.

The floating point preprocessor of can comprise a float to integer format converter in accordance with an embodiment of the floating point pre processor block can be understood as follows.

The float to integer format converter in floating point preprocessor may normalize a set of input floating point numbers by dividing by a scale factor to form a set of normalized floating point numbers. Normalization adapts the range of the fixed point integer samples to the range of a particular set of input floating point samples thus preserving more accuracy in a fixed point integer format. Alternatives for determining the scale factor for the set of input floating point numbers include the following 

The first option for the scale factor produces scaled floating point numbers where the maximum magnitude in the set is 1.0 or less so that floating point numbers in the set will have values in the range of 1.0 1.0. The second option reduces the computational latency for the current set. After normalization the float to integer format converter converts the scaled floating point numbers to integer numbers.

The input floating point data are represented in NB bits per sample. The number of bits per integer sample at the output is Nbits. A converter determines the maximum floating point value for a set of input floating point samples f max and then computes a scale factor F SCALE as follows  SCALE 2 1  max

The resulting value F SCALE can be multiplied with each floating point number in the set by to form a scaled floating point number. Logic then rounds each scaled floating point number to provide the output integer number. The integer number can be represented in a binary 2 s complement format having Nbit bits. The 2 s complement integer format is used for illustrative purposes. The particular integer format does not limit the scope of the invention as the floating point data may be converted to other integer formats.

In an alternative embodiment which can reduce the computational latency for the current set the float to integer format converter in the floating point preprocessor determines the maximum exponent value of the floating point numbers in the set. For this alternative the float to integer format converter may provide approximate normalization during format conversion without a multiplication by the floating point scale factor F SCALE. This reduces computational complexity by eliminating the floating point multiplier. The approximate normalization provides magnitude values less than 2.0 for the set. Alternatives for determining the maximum exponent value for the set include the following 

A float to integer format converter according to an alternative embodiment operates as follows. For this embodiment the sign bit exponent bits and mantissa bits of each floating point number are separately processed to produce an integer in 2 s complement format. For IEEE 754 single precision format the mantissa has NM 23 bits and the exponent has NE 8 bits. For IEEE 754 double precision format the mantissa has NM 32 bits and the exponent has NE 11 bits. The converter sets a hidden bit to 1 for the integer mantissa that corresponds to the leading 1 of the integer mantissa. The resulting mantissa may provide a positive mantissa pos mant . In 2 s complement format a negative number may be represented by inverting the bits of the positive mantissa and adding 1 . Then the converter inverts the bits of the positive mantissa and adds 1 to the inverted bits to provide a negative mantissa neg mant . The sign value pos mant and neg mant are provided to logic that selects pos mant if the sign value is 0 or neg mant if the sign value is 1 . The resulting selected mantissa is input to right shifter where the mantissa bits are shifted by a number of positions based on the exponent value exp of the input floating point number or alternatively by the difference of exp and EXP SCALE. The shift increment corresponding to the exponent value shifts the mantissa bits to the corresponding bit locations for the integer representation. The shift increment corresponding to EXP SCALE provides the approximate normalization by the value EXP SCALE as described above. Alternatively when the floating point number has already been scaled by F SCALE the EXP SCALE value need not be used. In this case the exponent value exp determines the number of right shifts for pos mant or neg mant. A shifter provides the 2 s complement integer representation having Nbits per sample.

The image preprocessor is used for handling image datatypes. For example three imaging datatypes may include 

These imaging datatypes are a special integer sub type. In many imaging subsystems RGB YUV and Bayer matrix samples are stored as interleaved N bit integers where N 8 10 12 or 16. In one example the image preprocessor can perform conversion between RGB and YUV imaging datatypes by averaging color components for instance 

Also the pixels represented by an image file can be arranged in different orders to facilitate compression. For example the image preprocessor can perform rearrangement in an RGB image so that the individual R G and B pixels can be organized into separate streams for compressed and upon decompression re interleaved to form the input stream form.

A variety of other preprocessing functions including handling decimation of YUV format so called 4 4 4 image data to 4 2 2 and 4 2 0 decimated image files can be implemented as hardware assisted library files or software only library files and specified using an API. See my co pending U.S. patent application Ser. No. 13 358 511 filed on 25 Jan. 2012 entitled RAW FORMAT IMAGE DATA PROCESSING which is incorporated by reference as if fully set forth herein.

The center frequency estimator in the compression system of is utilized for determining the center frequency of one dimensional input signals ints floats or images . As described in U.S. Pat. No. 7 009 533 issued 7 Mar. 2006 entitled Adaptive Compression and Decompression of Bandlimited Signals which is incorporated by reference as if fully set forth herein and describes operations and parameters than can be included in an API the sample spacing and the addition or subtraction operations may be selected to optimally compress the samples based on their center frequency. This value is utilized by the redundancy remover as described in more detail below. Typically two dimensional input data will not exhibit a center frequency. So for this and other data types and applications the center frequency estimator may not be needed and the control values can be specified using the API in the previously described APAX RR CONFIG register of . When the center frequency estimator is enabled it can determine for example a center frequency as falling into one of six bins DC fs 8 fs 6 fs 4 fs 3 or fs 2 where fs is the sampling frequency. These bins determine for one dimensional input signals the STRIDE1 STRIDE2 FIFO2 SEL and ADD SUB values described below with reference to that control the redundancy remover and add subtract elements. The center frequency estimator can be configured to operate over a programmable number of input samples such as 256 or 1024 and counts the number of positive going zero crossings in the input signal after any DC offset is removed.

Each of the functions of the hardware accelerator shown in and can be implemented as a software component of a library used to implement the API can be implemented solely in hardware with a supporting operation in the API library for initializing and allocating the hardware or can be implemented by a combination of software and hardware. The resources used to implement these functions whether in hardware software or a combination of hardware and software can be referred to as engines which implement the operations specified in the API.

For the embodiment in which the data move operation moves data between a compressed off chip memory to an uncompressed location on the same chip as a processor core used by application programs functions which consume greater processing resources are preferably implemented in hardware including for example a bit packer and bit unpacker . Also the image preprocessor and image postprocessor which can implement color space conversion and YUV decimation processes are preferably implemented in hardware. Likewise the redundancy remover which in this example is configured to monitor three separate streams for the purposes of determining which uses the fewest bits is preferably a hardware implemented function. The signal regenerator might be a software function that is assisted by hardware performing operations using software after the bit packer has recovered the mantissas of the floating point samples to integrate the mantissas back to the original signal samples. This hardware assisted implementation of the signal regenerator is suitable particularly where the underlying platform supports add functions used for integrating these values. Also the floating point to integer converter in the floating point preprocessor and the integer to floating point converter in the floating point postprocessor could be hardware assisted functions as many hardware platforms already include hardware support for these functions. Software only functions could comprise the locate operation that is used for accessing samples in compressed packet sets given a compressed .sfy file the function could operate most parameters that indicate a starting sample S1 and a number of samples N1 and output the identified packets along with values that indicate which samples to discard from the beginning packet s decompressed output samples in which samples to discard from the ending packet s decompressed output samples. Also the direct floating point compression engine and direct floating point decompression engine are functions that could be readily implemented using software.

Of course allocation of hardware and software resources to the operations to be executed by the API depends on the particular implementation details and design goals including the characteristics of the underlying hardware platform the variety of operations to be executed and so on.

The center frequency from the estimator or provided using a configuration parameter according to an API can be indicated as a fraction of the sample rate SR. A sample separation parameter may be used by selectors and . The selection parameter for the third selector is set to 1 for calculating second order derivatives. The add subtract configurations apply to both adder subtractors and . The selection of addition or subtraction is related to the positive or negative correlation of the samples separated by the sample separation parameter corresponding to the center frequency.

The block includes logic to determine which of alternatives x n x1 n or x2 n for the current packet would produce the least number of bits or most compression. The alternative with the most compression is provided to the fourth selector to be applied to samples for the next packet and stored in the packet header of the next packet. Determining the selection for the next packet based on the current packet data reduces the latency of compression processing. Alternatively the selection of x n x1 n or x2 n may be made during a training period and fixed for subsequent packets. When the compression processing uses the block floating point encoder in the bit packer the block logic may determine which of the alternatives x n x1 n and x2 n produces the most compression as follows 

While the above does not explicitly calculate the exact number of bits per compressed packet for each alternative the alternative producing the best compression is indicated by the lowest total. Alternatively the maximum magnitude sample max i in each block N GROUP samples for each alternative can be substituted for n exp i .

The configurable compressor supports compression of multidimensional data structures or multiplexed data structures. Certain parameter settings for the components in are appropriate for compression for two dimensional 2D data such as image samples. For example let N equal the number of samples representing a row of a 2D data set or an image so that a sequence of the integer samples x n represents row ordered samples of two or more rows of the 2D data set where x 0 to x N 1 is the first row x N to x 2N 1 is the second row etc. When the first selector is set to select x N and the first adder subtractor is configured to subtract the resulting x1 n x n x n N is the difference between samples in adjacent rows.

When the second selector is set to select 1 the third selector is set to select 0 and the second adder subtractor is configured to subtract the resulting x2 n x n x n 1 is the sample difference within the same row. The fourth selector would select the input sample x n the row difference sample x1 n or the sample difference x2 n for block floating point encoding. For multiplexed data a sequence of samples x n may represent multiple channels of data such as data from multiple sensors multiplexed together to form the sequence. For example N may represent the number of multiplexed channels where x n to x n N 1 represent one sample from each channel at a given time instant and x n N represents two temporally consecutive samples from the same channel. When the first selector is set to select x n N and the first adder subtractor is configured to subtract the resulting x1 n x n x n N is the difference between temporally consecutive samples from the same data channel. When the second selector selects samples from a second channel offset from the first channel and the second adder subtractor is configured to subtract the difference x2 n x n x n p is the difference between two different channels at a given time instant. The difference between channel data may provide compression when the different channels are correlated. The selector would select the input sample x n the intra channel difference x1 n or the inter channel difference x2 n for block floating point encoding.

The bit packer of defines blocks of N GROUP samples to be encoded together. The bit packer applies a block floating point encoding to the redundancy removed integer samples output from the redundancy remover . Aspects of block floating point encoding is described in my copending U.S. patent application Ser. No. 12 605 245 filed 23 Oct. 2009 entitled Block Floating Point Compression of Signal Data now Pub. No. US 2011 0099295 A1 which is incorporated by reference as if fully set forth herein. In the following description of the bits packer sample refers to an integer type sample an exponent of an integer sample will refer to the place value of the most significant or left most 1 in the integer s mantissa or exponent base 2 and mantissa will refer to the integer sample s mantissa. For the N GROUP samples the maximum exponent is encoded and the N GROUP mantissas are encoded according to the following steps.

For the first group of samples the exponent n exp 0 is directly encoded. For example the exponent n exp 0 can be encoded as follows where S is the original number of bits per sample 

For the ith group the exponent n exp i may be differentially encoded using a prefix code where no codeword is the prefix of another codeword. An example of differential encoding is as follows 

Huffman encoding of the exponent differences assigns tokens of different lengths to the exponent differences based on their frequencies of occurrence. Shorter Huffman tokens may be assigned to the more frequent values of exponent differences. The exponents n exp i may be directly encoded for example by Huffman encoding instead of being differentially encoded. Alternatives for encoding the block exponents are described below. The bit packer and other arrangements for assembling packets of compressed data can be supported by library functions compliant with the API.

The output compressed packets represent PKT LENGTH uncompressed integers or floating point values. Packet header fields describe parameters whose value could change with every packet or every few packets. When an APAX packet carries compressed 32 bit or 64 bit floating point values the first 32 bits of each packet header are followed by the floating point maximum exponent found in this packet stored in the 16 bit MAX EXP field. APAX packet headers thus contain either 32 or 48 bits. Table 5 summarizes the contents of APAX packet headers.

Each APAX compressed packet can be aligned on 32 bit doubleword 4 Byte boundaries. Aligning successive compressed packets allows detection of mis synchronization of compressed packets. Each packet header begins with a 12 bit SYNC word at PKT HDR 11 0 allowing the APAX decompressor to detect if any of the previous packet s variable length packet fields are incorrectly decoded. Since all packets begin on a 32 bit double word boundary and begin with the 12 bit value 0x97F this allows the detector to both detect synchronization errors and to re synchronize the compressed packet stream based on identifying the 0x97F SYNC word in the proper Dword aligned location.

The nine bit ATTEN field PKT HDR 21 12 specifies six integer and four fractional attenuation settings. APAX s 6.4 format expresses attenuation values for up to 64 integer bits although the APAX hardware could only support a 32 bit internal bit width except for the float to int converter which converts 64 bit floats to 32 bit ints . The four fractional ATTEN bits 0.4 are used as a 4 bit address into a 16 entry lookup table that contains a 16 bit integer multiplier. Each entry in the lookup table represents a 0.375 dB increment although the 16 bit lookup table values are calculated on a linear scale. The resulting attenuation value is applied by the attenuator .

The STRIDE1 parameter specifies the FIFO delay or sample distance where the APAX Redundancy Remover finds the most similar recent sample i.e. that sample most similar to the current sample. The STRIDE1 parameter corresponds to the sample separation used by the selector in .

The ADD SUB bit controls the operation of the two APAX Redundancy Remover adder subtractors and in 0 subtract 1 add . The DERIV field indicates which stream 1 of 3 is contained in this compressed packet 

The INT OR FLOAT bit indicates whether the MAX EXP field 16 bits is included in the APAX packet header. When INT OR FLOAT 0 integer input datatypes MAX EXP is not sent and the packet header contains just 32 bits. When INT OR FLOAT 1 floating point input datatypes MAX EXP carries the maximum exponent as a 16 bit signed integer value total of 48 bits in the packet header .

PKT1 IN FRAME PKT HDR bit 30 is set 1 when the packet contains the first samples or color components in a two dimensional frame such as for RGB YUV or Bayer encoded images or video. For one dimensional samples and for packets other than the first packet in a 2D frame PKT1 IN FRAME should be clear 0 .

After the packet payload a PKT CRC 31 0 OPTIONAL field enabled via the APAX GEN CRC32 bit can be included whose presence after the packet payload is indicated by a 1 in CRC32 FLAG PKT HDR 31 . The CRC 32 checksum can be generated for example on the following packet values 

The same library component or a different library component can control data transfers using the acceleration logic as initialized.

Turning to more details of the decompression resources represented by the decompressor decodes a stream of APAX compressed packets by first accessing the APAX control parameters in the APAX COMP DMA transaction which can also be stored in the .sfy file header and then by accessing additional APAX control parameters such as ATTEN DERIV STRIDE1 etc. in each APAX compressed packet header as described in Table 5 above. The APAX decompressor performs the converse operation of the APAX compressor generating the identical or substantially similar samples that the APAX compressor originally received.

The bit unpacker in the decompression resources of parses the header associated with each compressed packet and applies the parameters from the packet header and file header to recover the sequence of integers encoded by the packet. The integers are then applied to the signal regenerator for a final stage of decompression and then any applicable post processing.

The direct floating point decompression engine receives the bin compressed packets and reconstitutes floating point values for each sample in a manner discussed below with respect to .

The adaptive decompressor architecture supports decompression of multidimensional data structures or multiplexed data structures using API parameter settings. For the 2D data set example where N equals the number of samples representing a row of a 2D data set or an image the first selector is set to select s N and the first adder subtractor is configured to add the resulting s1 n s n s n N sums the decoded samples to reverse the difference operation of adjacent rows performed for compression. When the second selector is set to select 1 the third selector is set to select 0 and the second adder subtractor is configured to add the resulting s2 n s n s n 1 sums decoded samples to reverse the difference operation of samples within the same row performed for compression. For the multiplexed data example described above N represents the number of multiplexed channels. When the first selector is set to select s n N and the first adder subtractor is configured to add the resulting s1 n s n s n N reverses the difference between temporally consecutive samples from the same data channel performed for compression. When the second selector selects samples from the second channel offset from the first channel and the second adder subtractor is configured to add the difference s2 n s n s n p reverses the difference between two different channels performed for compression. The fourth selector selects from s n s1 n or s2 n based on the compression parameter from the compressed packet header.

The adaptive decompressor architecture supports decompression of data having different center frequencies. The selectors and select sample spacing and the addition or subtraction operations to reverse the operations performed by the adaptive compressor and the samples based on their center frequency. The selection parameter for the third selector is set to 1 for calculating second order integrals. The configurations of the adder subtractors and reverse the operations of the adder subtractors and .

The fourth selector makes selections of s n or s1 n corresponding to the initialized data of the compressed packet. When the first derivatives or differences x1 n are encoded for a particular compressed packet at least the initial sample for the packet will be absolutely encoded. For the initial decoded sample from the compressed packet the fourth selector may select s n as the initial sample. The fourth selector would select the first integral s1 n for the remaining decoded samples from the compressed packet. When the second derivatives x2 n are encoded for a particular compressed packet the fourth selector may select the sample s n for the initial sample and the first integral s1 n for the second sample and the second integral s2 n for the remaining decoded samples from the compressed packet. This initialization may be performed at least once for decoded samples from a compressed packet depending on the initialization performed during compression.

The decompression controller may provide the decompression parameters for the components of the adaptive decompressor including the gain factor for the multiplier the sample separation parameters for the selectors and add subtract configuration parameters for the adder subtractors and and selection parameters for the selectors and . The decompression controller may determine the decompression parameters based on the compression parameters from the compressed data packet header.

The floating point postprocessor may include an integer to float format converter to convert the integer output of the signal regenerator to a floating point format. A first alternative for integer to float format converter corresponds to the float to integer format converter that uses the F SCALE factor. This integer to float format conversion implements the following  samp int same  SCALE where fp samp indicates the reconstructed floating point sample and int samp indicates the decompressed integer sample output from signal regenerator .

An integer to float format converter in accordance with an alternative embodiment corresponds to the alternative float to integer format conversion described above. Each input sample comprises the sign and the decompressed integer mantissa in a 2 s complement format. An inverter is applied to the decompressed integer mantissa and then the engine adds 1 to the inverted mantissa to produce the mantissa neg mant for a negative number. The decompressed integer mantissa provides the mantissa pos mant for a positive number. The converter engine responds to the sign value to select pos mant if the sign value is 0 or neg mant if the sign value is 1 . The engine analyzes the decompressed integer mantissa to determine the leading 1 which is the leftmost nonzero bit that is not a sign extension bit. The bit position b is used to determine e shift by the following  shift bits 1 

To reconstruct the mantissa a left shifter shifts the selected mantissa based on the e shift value and the hidden bit is cleared. For the IEEE 754 standard the reconstructed mantissa would have 23 bits for single precision or 52 bits for double precision. To reconstruct the exponent the engine computes the difference of e shift and EXP SCALE. For the IEEE 754 standard the reconstructed exponent would have 8 bits for single precision or 11 bits for double precision. Alternatively when the original floating point number was scaled by F SCALE the EXP SCALE value is not used. In this case the e shift provides the exponent value exp and the reconstructed floating number is divided by F SCALE. Parameters EXP SCALE or F SCALE may be stored in one or more packet headers of the compressed packets.

The image postprocessor performs image encoding functions including the complement of functions performed at the image preprocessor such as realigning the R G and B components where they have been separated for compression and performing such image encoding as desired.

The number aligner aligns the outgoing data with the bus format in a manner complementary to that discussed above in connection with the number aligner in the compression resources of .

The function of the direct floating point compression engine in the compression resources of and the complementary function of direct floating point decompression engine can be understood with reference to .

The compressed packets can be formed from the binned samples as shown in . The logic accepts a sequence of floating point samples which in this example includes eight numerals. Each sample in the sequence is compared against an exponent threshold . The signal bit for each sample is placed in a signaling byte . The contents of the samples placed in the above threshold bin e.g. samples float i float i 5 and float i 6 out of the eight samples in a packet are placed in sequence in the packet. The contents of the samples placed in the below threshold bin are omitted.

The direct floating point compression engine can also implement a four bin process where the exponents are compared against three thresholds. A signaling code of two bits is used to indicate the bin for the sample. Samples below the lowest threshold can be encoded with zero bits plus the indicator bits. Samples below the second threshold and above the lowest threshold can be encoded with the indicator bits and only the exponent of the threshold or only the exponent of the sample for example. Samples between the second and third thresholds can also be encoded with the indicator bits and the exponent of the threshold the exponent of the sample or a combination of the exponent of the sample and the most significant bits of the mantissa. Samples above the third threshold can be included in full. In one example a four bin process can encode the values as follows 

The direct floating point decompression engine for the direct floating point compression algorithm simply reconstitutes the samples according to the input floating point format utilizing the available data. Thus for the two bin process the below threshold samples are reconstituted as a zero value in the floating point format. For the four bin process the reconstituted floating point format samples increase in accuracy for higher exponents in a manner complementary to the encoding process.

Some of the control parameters for the compression modes described above are encoded in the compression DMA descriptor Table 2 and the packet header of the compressed data packet Table 5 . For the compression DMA descriptor the parameters are related as follows 

Based on the foregoing it can be seen that compression and decompression resources are provided configured as an API that specifies a plurality of compression modes for a plurality of data types and application of those compression modes in a data path between a first memory which can have a relatively low latency and a second memory which can have a latency greater than that of the first memory. In the example discussed with reference to this data path runs between memory on the processor including cache memory and registry files and the like that are coupled to a bus or bus fabric that is coupled to a memory controller and off chip main memory such as can be implemented using high speed double data rate dynamic random access memory.

Compression modes that can be specified using an API and the resources described herein can include the following 

Thus the status register descriptor register packet header and file headers described above provide an API usable by compression and decompression engines implemented in a variety of settings on a variety of hardware platforms in a hardware assisted form on a variety of platforms in a software only form and for a variety of use cases. The API provides a framework against which compress resources can be designed and implemented in any underlying platform capable of executing the needed processes. Thus a system including API compliant compression operations as described herein can include library files for functions such as 

Memcpy c compress source operands and write compressed version to destination extending the standard C or C language library function memcpy using an API compliant compression function .

Memcpy d read compressed version from src and write uncompressed to destination extending the standard C or C language library function memcpy using an API compliant decompression function .

fopen c initializes a compressed file descriptor writes compressed DMA descriptor parameters into the compressed file header or reserves room for compressed file header and writes descriptor parameters during fclose extending the standard C or C language library function fopen using an API compliant compression function .

fwrite c performs compression prior to writing compressed array to disk extending the standard C or C language library function fwrite using an API compliant compression function .

fread c performs decompression after reading compressed array from disk extending the standard C or C language library function fread using an API compliant decompression function .

fseek c position file pointer at the start of a specific compressed packet works with a directory of packet pointers that support random access into a compressed stream extending the standard C or C language library function fseek using an API compliant compression function .

MPI SEND C MPI RECV C compress at transmitter and decompress at receiver extending the standard C or C language library functions MPI SEND and MPI RECV from the standard Message Passing Interface specification using API compliant compression and decompression functions .

MPI PACK C MPI UNPACK C compress at transmitter and decompress at receiver extending the standard C or C language library functions MPI PACK and MPI UNPACK using API compliant compression and decompression functions .

The API described herein can include new compiler supported compressed datatypes such as cInt cFloat cImage that correspond to uncompressed Int Float and Image data types. Thus an operation can declare the uncompressed original datatype to be compressed by API compliant library functions initialize compressed datatype compression mode parameters perform memWrites with special operation that compresses perform mem reads with special operation that decompresses and manage compressed memory and random access indexing to uncompressed data in the compressed memory.

The compression and decompression acceleration logic on the cache control block memory controller block and in the bus controller can comprise supporting circuitry for one or more channels the number of which is selected during design of the integrated circuit . A compression decompression library can include a component that is linked to an application program for the purposes of initializing and controlling compression and decompression channels through the acceleration logic. and represent in a simplified format a plurality of variant hardware architectures for which API compliant compression resources can be implemented using library files that operate using the API and are compiled for execution according to the underlying hardware platform.

While the present invention is disclosed by reference to the preferred embodiments and examples detailed above it is to be understood that these examples are intended in an illustrative rather than in a limiting sense. It is contemplated that modifications and combinations will readily occur to those skilled in the art which modifications and combinations will be within the spirit of the invention and the scope of the following claims.

