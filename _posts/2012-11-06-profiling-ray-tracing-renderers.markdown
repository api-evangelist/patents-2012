---

title: Profiling ray tracing renderers
abstract: A profiler for a ray tracing renderer interfaces with the renderer to collect rendering information, such as ray definition information, a pixel origin, objects hit, shader invocation, and related rays. In an interface, an artist views a simplified 3-D scene model and a rendered 2-D image. A pixel in the 2-D image is selectable; the profiler responds by populating the simplified 3-D scene with rays that contributed to that pixel. Rays can be displayed in the simplified 3-D scene to visually convey information about characteristics of each ray, such as whether the ray intersected an object, portions of the scene where it is occluded, and a direction. Statistics can be produced by the profiler that convey information such as relative computational complexity to render particular pixels. The profiler can step through multiple passes (e.g., multiple frames and passes of a multipass rendering), and the UI can allow pausing and stepping.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09235921&OS=09235921&RS=09235921
owner: Imagination Technologies Limited
number: 09235921
owner_city: Kings Langley
owner_country: GB
publication_date: 20121106
---
This application is a non provisional application of U.S. Prov. App. No. 61 557 056 entitled Systems and Methods for Profiling Ray Tracing Renderers filed on Nov. 8 2011 and which is incorporated by reference in its entirety herein.

Rendering photo realistic 2 D images from 3 D scene descriptions with ray tracing is well known in the computer graphics arts. Ray tracing is known to produce photo realistic images including realistic shadow and lighting effects because ray tracing can model the physical behavior of light interacting with elements of a scene. Ray tracing usually involves obtaining a scene description composed of geometric shapes which describe surfaces of structures in the scene and can be called primitives. A common primitive shape is a triangle. Objects can be composed of one or more such primitives. Objects can be composed of many thousands or even millions of such primitives. Scenes typically contain many objects. Resolution of displays and the media to be displayed thereon continue to increase. Ray tracing requires repeating a few calculations many times with different data e.g. intersection testing as well as executing special purpose code shading for identified ray intersections in addition to other processing.

Rendering of complex 3 D scenes can involve many different objects defined by geometry textures procedural modifications camera views animation effects and so on. All of these components to a successful rendering can also be of aberrant rendering outputs. Approaches to assisting graphics designers and developers in reaching desired results in ray tracing rendering therefor are desired.

The following disclosure relates to profilers for ray tracing renderers and to components thereof . A renderer can be composed of hardware configured by software as well as hardware that can perform fixed function tasks. Different renderers may have different physical implementations. A profiler according to the disclosure can interface with a renderer to access intermediate rendering data and can use hooks that are provided through an application programming interface API in order to gather such data. The profiler also can inject data to the renderer using such API in order to control the renderer through the profiler. The profiler provides a visual depiction of characteristics of rays that have been contributed to one or more pixels of a rendered image. In an implementation the profiler displays a view that shows the 3 D scene from a selected perspective and overlays rays that were emitted during rendering of a particular pixel in that scene so as to indicate attributes of the rays and how those rays contributed or did not contribute. A variety of statistics can be formulated using the gathered intermediate rendering data.

In an aspect a machine implemented method of characterizing constituent components of a ray tracing renderer comprises configuring a rendering system to generate a 2 D grid of pixels from a 3 D scene description. The configuring comprises accessing a 3 D scene description comprising geometry representative of objects in the 3 D scene and shader modules determining how those objects are to interact with light energy in the 3 D scene in order to generate a 2 D grid of pixels from the 3 D scene viewed from a first perspective. The method includes determining a portion of the 2 D grid of pixels and causing the rendering system to generate color outputs for the determined portion of the 2 D grid. The method includes recording intermediate state of the rendering system during generation of the color outputs which comprising definition information for rays emitted respective definitional information comprising a path for the ray through the 3 D scene. The method provides for outputting a representation of the 3 D scene rendered from a second perspective and respective representations of the rays emitted. Each ray representation comprises one or more visual characteristics determined according to a type of that ray a result of intersection testing of that ray and a relative spatial relationship of that ray with respect to the objects in the 3 D scene as viewed from the second perspective.

In an aspect a machine implemented method of assisting in the debug of ray tracing scene rendering programs comprising displaying a first window with a fully rendered 2 D image of a 3 D scene the fully rendered 2 D image being representative of actual output produced by a scene rendering program and generating statistics representative of computation performed during the rendering of the 2 D image the statistics indicative of relative computation complexity to render the 2 D image compared with other rendering passes in which a fully rendered 2 D image of the 3 D scene were produced.

A tangible machine readable medium storing machine executable instructions for performing a method comprising rendering using ray tracing a first framebuffer comprising color information for pixels in a viewport the first framebuffer rendered from a 3 D scene description comprising geometry defining objects in the scene respective shader code modules defining how the objects are to interact with light impinging on a surface of that object and one or more sources of light in the scene generating a second framebuffer with entries corresponding to pixels in the viewport the second framebuffer comprising color information for each entry of the second framebuffer the color information for each entry in the second framebuffer determined according to a relative computational complexity e.g. a number of rays that were used to render the pixel in determining the color information for the pixel in the first framebuffer corresponding to that entry in the second framebuffer.

A machine implemented method of assisting in the debug of ray tracing scene rendering programs comprising generating a fully rendered 2 D image of a 3 D scene the fully rendered 2 D image being representative of actual output produced by a scene rendering program in rendering the 3 D scene and generating statistics representative of computation performed during the rendering of the 2 D image the statistics indicative of relative computation complexity to render each of the pixels of the 2 D image.

A machine implemented method of assisting in the debug of ray tracing scene rendering programs comprising displaying a first window with a fully rendered 2 D image of a 3 D scene the fully rendered 2 D image being representative of actual output produced by a scene rendering program and stepping the scene rendering program through each pass of a multipass rendering wherein the 3 D scene is updated according to outputs of a previous pass and the displaying step is repeated according to the updated 3 D scene.

A machine implemented method of assisting in the debug of ray tracing scene rendering programs comprising accessing from a tangible machine readable medium data describing a ray tracing program to be executed the data defining an ordered series of rendering passes to be taken in rendering a 2 D image from a 3 D scene description receiving an indication to render a subsequent rendering pass of the ordered series of rendering passes and responsively rendering the subsequent rendering pass being one or more of a pass of a multipass rendering and a subsequent frame of a rendering.

A machine implemented method of assisting in the debug of ray tracing scene rendering programs comprising displaying a fully rendered 2 D image of a 3 D scene the fully rendered 2 D image being representative of actual output produced by a scene rendering program accepting an input indicative of selection of a pixel from the fully rendered 2 D image defining a viewport according to the pixel selection inputting the defined viewport as a definition of a 2 D image to render from the 3 D scene capturing statistics during the rendering of the 2 D image according to the defined viewport including information describing each ray generated by each portion of the scene rendering program during the rendering and outputting the captured statistics.

A machine implemented method of assisting in the debug of ray tracing scene rendering programs comprising displaying a fully rendered 2 D image of a 3 D scene the fully rendered 2 D image being representative of actual output produced by a scene rendering program displaying a 2 D debug image of the 3 D scene the 2 D debug image depicting objects and lights located in the 3 D scene without shadow effects and texture mapping operations displaying overlayed on the 2 D debug image of the 3 D scene a tree of rays that contributed to a state of a selected pixel of the fully rendered 2 D image of the 3 D scene accepting an input indicative of selection of a ray from the displayed tree of rays and responsive to the selection input determining a portion of the scene rendering program responsible for emitting that ray and displaying that portion of the scene rendering program in an editor.

In the above aspects each may be implemented with features according to the following. A feature that provides for receiving an input indicating a pause in the stepping of the scene rendering program generating a debug 2 D image with pixels corresponding to each pixel of the fully rendered 2 D image of the 3 D scene. A feature that provides for the color of each pixel of the 2 D debug image to be determined according to a measure of computation required to determine a final color of the corresponding pixel of the fully rendered 2 D image. The measure of computation may include counting a number of rays emitted during rendering of the corresponding pixel of the fully rendered 2 D image. The measure of computation may comprise a ratio of rays that hit any scene object or that missed all scene objects with the number of rays emitted during rendering of the corresponding pixel. The measure of computation may comprise establishing averages for statistics concerning a count of a number of rays emitted during rendering of the corresponding pixel of the fully rendered 2 D image. The measure of computation may include estimating time expended by a computation unit during rendering of the corresponding pixel of the fully rendered 2 D image. The measure of computation may include counting a number of elements of geometry acceleration data that were intersection tested during intersection testing of the rays emitted during rendering of the corresponding pixel of the fully rendered 2 D image.

Multiple measures of computation may be provided such as a selection of the above described measures. These measures can be presented with statistics comprising at least one of an average rays per pixel individual counts of rays emitted to rendering at least a selected subset of the pixels an amount of computation spent in executing shading code and amount of intersection tests spent in testing an acceleration structure.

Thus some aspects of this disclosure relate to systems and methods of profiling a ray tracing renderer and or components thereof. Such profiling can include tools for visualizing trees of rays that contribute to a selected pixel in a rendering output. Other examples of profiling can include production of visual depictions of resource use intensity to render particular pixels of a rendering output. Still further examples include counting numbers of rays that were emitted or used in generating a particular selected rendering output e.g. a pixel . Statistics concerning these profiled data points also can be produced. Statistics can summarize per pixel resource usage and be used to compare resource usage to render one pixel or a group of pixels with respect to other pixels or groups. Ray tree visualization can help an artist determine whether a particular pixel is aberrantly colored in that a ray is not going in a direction that was intended for example. These aspects are merely exemplary of functionality that can be implemented in profilers according to the disclosure.

Computation power continues to increase rapidly theoretically allowing ever more complicated visual effects. However programmatic complexity and debugging for complex visual rendering programs can be daunting. In the still more particular field of ray tracing many of the tools that may have been useful for debugging rasterization based rendering do not provide the kinds of information and visual aids useful in debugging a ray tracing renderer. In an example workflow an artist can design an animation that involves a 3 D scene which can change during the animation and objects which are located in the scene such objects also can be dynamic . The artist may be designing or using shaders to simulate different effects and materials such as simulating hair wood water smoke and so on. Designing the scene the objects in it and their relative arrangements is often an iterative process that involves the artist seeing a current state of rendering output from a current state of the program and the scene data and deciding to make further changes to any of the inputs that affect the current rendering output. One approach to assisting visualization of how a given ray tracing renderer is behaving performance characterization and artifact debugging is by providing tools that embody aspect s described below.

In some aspects tools according to the disclosure can work with an application programming interface API for abstracting hardware used in ray tracing such that programs can be written to the API instead of being targeted to particular hardware although some hardware specific optimizations may still be conducted . An example of an API for ray tracing is OpenRL from Caustic Graphics Inc a division of Imagination Technologies PLC.

In an example a profiler tool according to such aspects can connect to a running program written for a given API and pause that program between rendered frames to allow examination of various outputs and other metrics relating to that frame or a sequence of past frames. A more specific example of visual and functional characteristics of a Profiler according to these aspects is described below. As explained not all such visual or functional characteristics need be present in a particular embodiment and those of ordinary skill would be able to adapt these disclosures to select from among the visual and functional characteristics those that meet their particular needs. For example a profiler according to an aspect provides a capability to select such as by clicking on a pixel in a main viewport and see what rays were emitted for that pixel for those times when an artist may wonder why is that pixel red 

An example profiler interface has a toolbar and six main views which show various aspects of the state of the OpenRL part of a program. depicts an example composition of a profiler interface according to the disclosure and depicts an example block diagram of different windows and their relative arrangement as shown in . With reference to the six example views include objects view also known as Primitives in the nomenclature of OpenRL framebuffers e.g. in ray trees 3D Loupe and Viewport . These views or a subset thereof can be made dockable see e.g. so that they can be arranged and rearranged by a user.

An example toolbar comprises two buttons Play Pause and Framestep . A running OpenRL program connected to the Profiler will stream updates to the Profiler. The interface can reflect the state of the running program as that state is updated or at other intervals if so desired. Activation of the Pause button alternate with play button causes the Profiler to pause the running application allowing inspection of the available running program state. In one example implementation a function called pixel tracing is available when the running application is paused results of which can be displayed in 3D window . The term window is used for sake of convenience and not limitation. Any portion or region of a display can be used to display the contents described as being displayed in particular windows.

Framestep button when pressed unpauses the running program so that the running program can render exactly one frame in an example implementation . As such framestep is analogous to a step over command in a traditional source code debugger. In the context of ray tracing a framestep function can be helpful in debugging multi pass programs. An example multiphass program is an Adaptive Anti Aliasing program. In a situation where the running application is paused but the application does not happen to stop on a pass of interest the Framestep button can be used to arrive at the pass of interest. The example depiction of a interface element for stepping through frames of a sequence of frames to be ray traced is an example of disclosure that includes other approaches to frame stepping or other kinds of intermediate pausing stopping and continuing which include parameterized or scripted approaches where an interface can display elements according to this disclosure updated according to the script or parameters specified. A user can program the script or otherwise create or input parameters that cause desired stepping pausing and restarting behavior.

In an example a framebuffer selector pane shows all attached color buffers for the currently active bound framebuffer object. A selected color buffer will be displayed in a principal viewport view e.g .

The principal viewport displays contents of a currently selected color buffer from the Framebuffer pane implementations may also comprise a plurality of viewports such that there may not be a single principal viewport . In an example when the mouse is within the principal viewport a cursor can be displayed as a crosshair in depicted as vertical line and horizontal line that intersect . Loupe pane will show thus show a magnified view of a vicinity of a current cursor position. In an example a click inputted in the viewport causes the profiler to display e.g. in 3D information about rays that were traced to produce the color information represented by that pixel in that buffer. In an example if the application is not paused when a click is received the application is responsively paused. In an example the currently selected pixel will be marked by longer crosshairs that extend to the edges of the displayed viewport or to an end of an image such as where the image may not extent fully to the edges of the viewport .

A ray tree pane e.g. of of presents a list of all pixels clicked on for a displayed frame and presents each pixel as a tree of rays than can be examined. A ray tree also can be selected through the viewport and Loupe panes as was previously described.

3D pane shows visible geometry of the current frame as well as the rays of the currently selected pixel trace or traces such as those selected in the ray Trees pane . This view can be navigated by clicking in the view or using the w a s and d keys to go forward left back and right respectively as well as r and f to go up and down respectively. A viewpoint a perspective from which the geometry is viewed with the rays arranged spatially with respect to the geometry can be adjusted by clicking and dragging in the view. See with ray tree identified points to one ray in a ray tree and thus serves to identify both that ray and the other rays that are related to that ray . Note that a light can be represented as a colored shape indicative of a light rather than as a realistic depiction of a source of photon energy per se.

Example scene geometry in the Cornell box rendering includes a sphere see enumeration in object pane also and light . depict in further detail aspects of view window and introduced with respect to . These windows respectively show a fully rendered output and depicts a debug view where certain rendering features can be turned off e.g. by withholding contributions resulting from those rendering features from a final render buffer used to produce the view shown in . For example a shadow caused by sphere may not be depicted in although it is depicted in . A perspective or view point also may differ and be separately manipulated between these windows. For example window can be set to view the backside of sphere even as the scene is rendered from the same viewpoint as in .

In an example to make ray behavior easier to understand rays can be visually distinguished to show direction. In a particular example rays can be visually depicted with a color gradient to show direction e.g. from a saturated color to black or to white or from black to white . For example depicts examples of situations where rays may be visually distinguished from each other or a portion of a ray may be visually distinguished from another portion of that ray. depicts that a light can be a destination for rays and shown as emitted from surfaces respectively. In ray is behind object as viewed from a current viewpoint so that a visual depiction of ray is shown differently in portion and reverts to an unobstructed visual depiction in portion portion may be depicted differently from a portion near a ray origin in that rays can be depicted with a color or shade gradient to show direction . By contrast ray is shown as a ray that has a path completely visible from the viewpoint. Ray was occluded by object in the rendering of the actual rendering output i.e. not the debug view and is therefore visually depicted differently than ray and ray . Ray emitted from surface depicts a remaining possibility for occlusion rays in which ray was occluded in producing the actual rendering output and the ray also has a portion which is obscured by geometry object in the viewport such that a portion of ray is depicted differently than portion .

Based on the set up for the scene a 2 D image of the scene is rendered . Such 2 D image is rendered based on a viewpoint camera location and the pixel grid is interposed between the 3 D scene and the viewpoint. Typically the pixel grid is a predetermined height and width. The rendered 2 D image can be displayed in a viewport. Horizontal and vertical crosshairs can be overlaid on the displayed image. As described above such crosshairs can be used as an indication of a pixel that is currently selectable.

The method further comprises showing a magnified region of the displayed image in the vicinity of the intersection between the horizontal and vertical crosshairs with in a loop window. Input indicative of a selection of a pixel or pixels in the rendered and displayed image can be received . In one example the selected pixel s can be used in a database lookup to identify a tree of rays that contributed to a final rendering of that pixel in the displayed image. In some implementations a further step of determining rays that were shot during rendering of the displayed image but which did not contribute to the final rendering can be undertaken. However in other implementations all rays emitted during a rendering of the selected pixel can be stored and presented together regardless whether each ray contributed to the color of the selected pixel or not.

For the rays distinguishing visual characteristics for each ray to be displayed can be determined . In one example all rays are displayed whether or not they contribute to the pixel color itself. Subsequently each ray of the tree of rays is depicted according to its distinguishing visual characteristics in a window that also contains a display of the scene objects. This display is a three dimensional display viewed from a viewpoint which can be changed independently from a viewpoint used to render of the 2 D image . The method can return to allow a setup of the scene to be revised such as for a subsequent pass in a multipass rendering or for a subsequent frame.

In general ordinary rays can be displayed in an example in a black to white gradient. In a further example if a particular ray did not hit any scene object then that ray can be visually distinguished from rays that hit some scene object. In one example a dashed pattern can be used for one or the other. A currently selected ray also can be visually distinguished from other rays such as by showing such ray in a different color such as green.

In some implementations certain types of rays can be treated differently in order to better visually communicate characteristics particular to rays of such types. For example if a ray is an occlusion test ray it can drawn with a red to white gradient. As with ordinary rays occlusion test rays can further be visually distinguished based on hit or miss information such as by using a repeating gradient for either a hit or a miss. In an example if an occlusion test ray is occluded it is drawn with a blue to white repeating gradient but the ray still can be drawn to a termination point e.g. where information about which object caused the occlusion is unavailable . This disclosure refers to selecting pixels in order to determine a tree of rays to be displayed. This disclosure is exemplary in that implementations according to this disclosure can include a variety of mechanisms to determine selection of pixels to be examined. Such selection can include a determined list of pixels or flags that can be set by program components.

In an aspect where a ray is obscured by geometry from a current perspective of the view in the 3 D pane the ray can be drawn differently in areas where the ray is obscured e.g. using a black and white screen door pattern .

An object pane shows a list of all objects in the scene and various statistics about them. The currently selected primitive will be drawn in the 3D pane in a bright green color.

For any intersection identified one or more shader modules are identified and executed in order to determine what effect the identified intersection will have on the finally rendered color of the selected pixel. By particular example an intersected object can be associated with the shader module which is executed when that object is intersected. The executed shader module may emit one or more rays that will require intersection testing. For any such rays emitted traversal is repeated.

After all rays that were emitted by the camera shader and any shaders identified by traversal of any other rays emitted have been intersection tested and any shader modules so identified have completed their ray emission the rendering of the pixelized viewport can be considered complete . In most cases it would be expected that a contribution or effect of each ray shader to a color of a pixel would be too rapid to be able to detect each individual contribution. In some aspects a stepped execution of ray shaders also can be implemented such that progress in rendering a given pixel proceeds more slowly so that a user can observe such progress in color changes to the pixel in conjunction with identifications of a currently executing ray shader.

In each of these steps traversal and shader execution data concerning what was done during such steps is output to a store of debug status information . In one example such data is extracted by hooks that can monitor API calls made by the rendering program. Such data comprises information about the rays that were emitted and processed during the rendering such data can be accessed . The accessed ray data is used to determine appropriate visual displays for each ray depending on characteristics of such ray which may comprise a type of ray whether the ray intersected or missed and how the race spatially relates to objects located in the 3 D scene. These visual displays are then drawn in a 3 D model space with the 3 D scene objects. The tabulation of such ray tree data also can be displayed .

A framebuffer can be populated with color information derived from observations of pixels being rendered. For example a framebuffer can be created with per pixel color information representing how many rays were traced in order to produce the final render product for that pixel other types of color information also can be created which can each represent information about a computation cost to produce the final render product for a given pixel. In some cases the information can be provided for each pixel of the render output while in other situations only a subset of information for the pixels can be provided. In other situations other information relating to computation cost can be tracked and outputted such as outputted according to a visual colorized information output.

In order to process the scene a frame shader can begin to emit rays that will be traced in the scene by ray intersection testing . Frame shader also can output color information to a frame buffer . For the purposes of this disclosure how ray intersection testing is implemented is immaterial. An output of ray intersection testing is an indication whether the ray intersected something in the scene or missed. If the ray intersected something the output would also specify information that allows identification of a shader code module to be executed. In some implementations other information such as barycentric coordinates for the point of intersection can be outputted along with the intersection information.

Ray shader can be executed based on outputs from intersection testing . Execution of ray shader provides color outputs to frame buffer or buffers . Each of these functional units depicted can communicate outputs to debug data store during their operation. Debug configuration data can be used to indicate which data is sought to be captured for a particular debug cycle. According to one aspect debug configuration data can include inputs received through an interface such as a graphical interface displayed on a display examples of such user interface aspects were disclosed above .

Further in one example aspect such inputs can be used in identifying or defining operation of a frame shader to shade a frame consisting of pixels for which ray tree information is desired instead of all the pixels of a 2 D grid that is intended to be a final render output product. In some implementations each frame shader can shade a single pixel and where multiple pixels are selected see e.g. a list of pixels to be rendered can result in running a frame shader for each pixel. As such the system depicted in can operate in a number of iterations with different frame shaders.

By further example frame shaders can be implemented in order to produce computational complexity maps in which each map includes pixels corresponding to pixels of the final render product where the pixels of the map include information about computational complexity to render the corresponding pixel of the final render product. Examples of measures of computational complexity were disclosed as including a number of rays that were emitted or which actually contributed to the color of the final render pixel amount of time required to render the pixel a number of tests in the acceleration structure in order to render that pixel and so on. This data can be normalized according to averages or other normative statistics or measures for all the pixels of the final render product.

Aside from the above example aspects other aspects can include gathering of statistics concerning various aspects of the running application. In some examples a statistics gather tool can communicate with an application being monitored through TCP IP ports. In some aspects such communication can be enabled or disabled by passing attributes in an API call or otherwise setting values in a configuration or setup field or information store. In some examples a tree of available statistics can be displayed allowing selection of statistics of interest. Tables 1 6 depict various statistics that can be gathered or monitored by functionality according to the aspects disclosed herein.

As different types of statistics are selected their values can begin to be plotted in an interface element such as a window pane. In some examples these statistics are updated every frame. A given selection of statistics can be remembered across runs for a given program and for different rendering programs as well. In some implementations particular selections of statistics can be associated with a profile and saved for use with particular kinds of programs for example. depicts an example graphical interface by which statistics to be plotted can be selected and the selected statistics can be outputted.

In this disclosure a variety of techniques were disclosed to provide a visual depiction of numerical values relative values between and among different metrics as well as between and among different pixels of a rendering output. Such techniques can be used to visually distinguish different scene objects from each other as well as to set out metadata or other characteristics pertaining to the scene object or other detail sought to be communicated. The techniques disclosed herein are by way of example rather than limitation. Coloration cannot be visually depicted in black and white color drawings compliant with patent office drawing requirements. As such color information may be described in the specification and may in other instances be depicted as gray scale cross hatching or other drafting techniques. Still further a person of ordinary skill would be able to understand that these techniques are exemplary and devise a particular set of techniques and visually distinguishing features that meet the needs of a given situation or user. This specification frequently treats the display of various renderings and other information. However the concept of display is an example of kinds of output rather than limitation. For example any of these kinds of data renderings statistics and so on can be outputted for storage on a tangible computer readable medium.

The order of activities depicted in the diagrams is not by way of limitation that such activities must be or are preferred to be performed in that order. Additionally there may be situations where not all depicted activities are performed for a given synchronization operation. For example some data or table organization or formatting may already have been performed and so such activities would not need to be performed again.

As would be apparent from the disclosure some of the components and functionality disclosed may be implemented in hardware software firmware or any combination thereof. If implemented in firmware and or software the functions may be stored as one or more instructions or code on a computer readable medium in one example the media is non transitory. Examples include a computer readable medium encoded with a data structure and a computer readable medium encoded with a computer program. Machine readable media includes non transitory machine readable media. Other kinds of media include transmission media. A non transitory medium may be any tangible medium that can be accessed by a machine. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a machine.

Those of skill will also appreciate that the various illustrative logical blocks modules circuits and algorithm steps described in connection with the embodiments disclosed herein may be implemented as electronic hardware computer software in a computer readable medium or combinations of both. To clearly illustrate this interchangeability of hardware and software various illustrative components blocks modules circuits and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application but such implementation decisions should not be interpreted as causing a departure from the scope of the present invention.

The description of the aspects and features is provided to enable any person skilled in the art to make and use the systems apparatuses and perform the methods disclosed. Various modifications will be readily apparent to those skilled in the art and the principles described in this document may be applied to other aspects without departing from the spirit or scope of the disclosure. Thus the description is not intended to limit the claims. Rather the claims are to be accorded a scope consistent with the principles and novel features disclosed herein.

The drawings include relative arrangements of structure and ordering of process components solely as an aid in understanding the description. These relative arrangements and numbering is not an implicit disclosure of any specific limitation on ordering or arrangement of elements and steps in the claims. Process limitations may be interchanged sequentially without departing from the scope of the disclosure and means plus function clauses in the claims are intended to cover the structures described as performing the recited function that include not only structural equivalents but also equivalent structures.

Although a variety of examples and other information was used to explain aspects within the scope of the appended claims no limitation of the claims should be implied based on particular features or arrangements in such examples as one of ordinary skill would be able to use these examples to derive a wide variety of implementations. Further and although some subject matter may have been described in language specific to examples of structural features and or method steps it is to be understood that the subject matter defined in the appended claims is not necessarily limited to these described features or acts. For example such functionality can be distributed differently or performed in components other than additional to or less than those identified herein. Rather the described features and steps are disclosed as examples of components of systems and methods within the scope of the appended claims.

